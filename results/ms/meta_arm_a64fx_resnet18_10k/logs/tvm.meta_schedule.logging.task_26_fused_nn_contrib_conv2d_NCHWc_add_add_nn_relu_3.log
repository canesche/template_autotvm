2024-04-28 20:35:57 [INFO] [task_scheduler.cc:160] Initializing Task #26: "fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3"
2024-04-28 20:35:57 [INFO] [task_scheduler.cc:35] 
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(7), T.int64(7), T.int64(512)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(32)), "float32"), p3: T.Buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(9), T.int64(9), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)))
        T_add = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)))
        T_add_1 = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)))
        for i0, i1, i2, i3, i4 in T.grid(T.int64(1), T.int64(1), T.int64(9), T.int64(9), T.int64(512)):
            with T.block("data_pad"):
                v_i0, v_i1, v_i2, v_i3, v_i4 = T.axis.remap("SSSSS", [i0, i1, i2, i3, i4])
                T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(8) and T.int64(1) <= v_i3 and v_i3 < T.int64(8), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
        for n, oc_chunk, oh, ow, oc_block, ic, kh, kw in T.grid(T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32), T.int64(512), T.int64(3), T.int64(3)):
            with T.block("conv2d_NCHWc"):
                v_n, v_oc_chunk, v_oh, v_ow, v_oc_block, v_ic, v_kh, v_kw = T.axis.remap("SSSSSRRR", [n, oc_chunk, oh, ow, oc_block, ic, kh, kw])
                T.reads(data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                with T.init():
                    conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
        for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                T.writes(T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4]
        for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)):
            with T.block("T_add_1"):
                v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                T.reads(T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T.writes(T_add_1[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T_add_1[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4]
        for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)):
            with T.block("T_relu"):
                v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                T.reads(T_add_1[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(T_add_1[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
2024-04-28 20:35:58 [INFO] [task_scheduler.cc:164] Total 3 design space(s) generated
2024-04-28 20:35:58 [INFO] [task_scheduler.cc:170] Design space #0:
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(7), T.int64(7), T.int64(512)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(32)), "float32"), p3: T.Buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel": 768, "meta_schedule.unroll_explicit": 64, "meta_schedule.vectorize": 64})
            data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(9), T.int64(9), T.int64(512)))
            conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)))
            for n_0, oc_chunk_0, oh_0, ow_0, oc_block_0, n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(4), T.int64(1), T.int64(7), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2)):
                for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(9), T.int64(3), T.int64(512)):
                    with T.block("data_pad"):
                        v_i0, v_i1, v_i2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                        v_i3 = T.axis.spatial(T.int64(9), ow_0 + ax3)
                        v_i4 = T.axis.spatial(T.int64(512), ax4)
                        T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                        T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                        data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(8) and T.int64(1) <= v_i3 and v_i3 < T.int64(8), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(64), T.int64(1), T.int64(3), T.int64(1), T.int64(2), T.int64(7), T.int64(1), T.int64(1), T.int64(8), T.int64(3), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(16)):
                    with T.block("conv2d_NCHWc"):
                        v_n = T.axis.spatial(T.int64(1), n_0 + n_1 + n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(16), oc_chunk_0 * T.int64(4) + oc_chunk_1 * T.int64(4) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(7), oh_0 * T.int64(7) + oh_1 * T.int64(7) + oh_2 + oh_3)
                        v_ow = T.axis.spatial(T.int64(7), ow_0 + ow_1 + ow_2 + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_0 * T.int64(32) + oc_block_1 * T.int64(16) + oc_block_2 * T.int64(16) + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(8) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                        T.reads(data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        with T.init():
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)):
                with T.block("T_relu"):
                    v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                    T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[4, 1, 2, 2])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 7, 1])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[7, 1, 1, 1])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[1, 2, 1, 16])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[64, 8])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[3, 1])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=9)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
2024-04-28 20:35:58 [INFO] [task_scheduler.cc:170] Design space #1:
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(7), T.int64(7), T.int64(512)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(32)), "float32"), p3: T.Buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel": 768, "meta_schedule.unroll_explicit": 512, "meta_schedule.vectorize": 64})
            data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(9), T.int64(9), T.int64(512)))
            conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)))
            for n_0, oc_chunk_0, oh_0, ow_0, oc_block_0, n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(4), T.int64(1), T.int64(7), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2)):
                for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(9), T.int64(3), T.int64(512)):
                    with T.block("data_pad"):
                        v_i0, v_i1, v_i2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                        v_i3 = T.axis.spatial(T.int64(9), ow_0 + ax3)
                        v_i4 = T.axis.spatial(T.int64(512), ax4)
                        T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                        T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                        data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(8) and T.int64(1) <= v_i3 and v_i3 < T.int64(8), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(64), T.int64(1), T.int64(3), T.int64(1), T.int64(2), T.int64(7), T.int64(1), T.int64(1), T.int64(8), T.int64(3), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(16)):
                    with T.block("conv2d_NCHWc"):
                        v_n = T.axis.spatial(T.int64(1), n_0 + n_1 + n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(16), oc_chunk_0 * T.int64(4) + oc_chunk_1 * T.int64(4) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(7), oh_0 * T.int64(7) + oh_1 * T.int64(7) + oh_2 + oh_3)
                        v_ow = T.axis.spatial(T.int64(7), ow_0 + ow_1 + ow_2 + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_0 * T.int64(32) + oc_block_1 * T.int64(16) + oc_block_2 * T.int64(16) + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(8) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                        T.reads(data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        with T.init():
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
                for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(4), T.int64(7), T.int64(1), T.int64(16)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(16), oc_chunk_0 * T.int64(4) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(7), ax2)
                        v_ax3 = T.axis.spatial(T.int64(7), ow_0 + ax3)
                        v_ax4 = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(16) + ax4)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[4, 1, 2, 2])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 7, 1])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[7, 1, 1, 1])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[1, 2, 1, 16])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[64, 8])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[3, 1])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l50, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=9)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
2024-04-28 20:35:58 [INFO] [task_scheduler.cc:170] Design space #2:
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(7), T.int64(7), T.int64(512)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(32)), "float32"), p3: T.Buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel": 768, "meta_schedule.unroll_explicit": 16, "meta_schedule.vectorize": 64})
            conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)))
            for n_0, oc_chunk_0, oh_0, ow_0, oc_block_0 in T.grid(T.int64(1), T.int64(4), T.int64(1), T.int64(7), T.int64(1)):
                for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1, ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(64), T.int64(1), T.int64(3), T.int64(1), T.int64(2), T.int64(7), T.int64(1), T.int64(1), T.int64(8), T.int64(3), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(16)):
                    with T.block("conv2d_NCHWc"):
                        v_n = T.axis.spatial(T.int64(1), n_0 + n_1 + n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(16), oc_chunk_0 * T.int64(4) + oc_chunk_1 * T.int64(4) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(7), oh_0 * T.int64(7) + oh_1 * T.int64(7) + oh_2 + oh_3)
                        v_ow = T.axis.spatial(T.int64(7), ow_0 + ow_1 + ow_2 + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_0 * T.int64(32) + oc_block_1 * T.int64(16) + oc_block_2 * T.int64(16) + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(8) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                        T.reads(p0[v_n, v_ic // T.int64(512), v_oh + v_kh - T.int64(1), v_ow + v_kw - T.int64(1), v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        with T.init():
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + T.if_then_else(T.int64(1) <= v_oh + v_kh and v_oh + v_kh < T.int64(8) and T.int64(1) <= v_ow + v_kw and v_ow + v_kw < T.int64(8), p0[v_n, v_ic // T.int64(512), v_oh + v_kh - T.int64(1), v_ow + v_kw - T.int64(1), v_ic % T.int64(512)], T.float32(0)) * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
                for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(4), T.int64(7), T.int64(1), T.int64(32)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(16), oc_chunk_0 * T.int64(4) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(7), ax2)
                        v_ax3 = T.axis.spatial(T.int64(7), ow_0 + ax3)
                        v_ax4 = T.axis.spatial(T.int64(32), ax4)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[4, 1, 2, 2])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 7, 1])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[7, 1, 1, 1])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[1, 2, 1, 16])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[64, 8])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[3, 1])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=-2)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
2024-04-28 21:05:28 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-28 21:05:28 [INFO] [evolutionary_search.cc:715] Picked top 0 candidate(s) from database
2024-04-28 21:05:34 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f1e458)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x386def8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x36b1d38)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3108268)]: 0 failure(s)
2024-04-28 21:05:34 [INFO] [evolutionary_search.cc:723] Sampled 512 candidate(s)
2024-04-28 21:05:39 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f1e458)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x386def8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x36b1d38)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3108268)]: 0 failure(s)
2024-04-28 21:05:45 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f1e458)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x386def8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x36b1d38)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3108268)]: 0 failure(s)
2024-04-28 21:05:51 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f1e458)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x386def8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x36b1d38)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3108268)]: 0 failure(s)
2024-04-28 21:05:56 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f1e458)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x386def8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x36b1d38)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3108268)]: 0 failure(s)
2024-04-28 21:05:58 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9998  0.9997  0.9984  0.9971  0.9970  0.9965  0.9964  0.9961  0.9958  0.9954  0.9951  0.9941  0.9934  0.9932  0.9915  0.9913
[17 : 32]:	0.9912  0.9912  0.9904  0.9895  0.9890  0.9885  0.9881  0.9880  0.9877  0.9874  0.9871  0.9869  0.9869  0.9867  0.9866  0.9865
[33 : 48]:	0.9852  0.9849  0.9846  0.9844  0.9838  0.9836  0.9833  0.9832  0.9829  0.9826  0.9826  0.9818  0.9817  0.9815  0.9811  0.9792
[49 : 64]:	0.9789  0.9777  0.9750  0.9747  0.9746  0.9725  0.9724  0.9720  0.9717  0.9710  0.9707  0.9704  0.9696  0.9695  0.9694  0.9692
2024-04-28 21:05:58 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-28 21:05:58 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-28 21:12:59 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1: GFLOPs: 24.1951. Time: 9559.2234 us. Best GFLOPs: 24.1951
2024-04-28 21:12:59 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #2: GFLOPs: 10.8115. Time: 21392.6978 us. Best GFLOPs: 24.1951
2024-04-28 21:12:59 [INFO] [task_scheduler.cc:121] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #3: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(7), T.int64(7), T.int64(512)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(32)), "float32"), p3: T.Buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(9), T.int64(9), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_fused_fused in T.parallel(T.int64(28), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(3), T.int64(9), T.int64(512)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(9), n_0_oc_chunk_0_oh_0_fused_fused % T.int64(7) + ax2)
                    v_i3, v_i4 = T.axis.remap("SS", [ax3, ax4])
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(8) and T.int64(1) <= v_i3 and v_i3 < T.int64(8), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for ow_0, oc_block_0, n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(8), T.int64(1), T.int64(4), T.int64(1), T.int64(1)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(2)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_fused_fused // T.int64(7) * T.int64(4) + oc_chunk_1 * T.int64(4) + oc_chunk_2_init * T.int64(4) + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_fused_fused % T.int64(7) + oh_1 + oh_2_init + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(7), ow_0 * T.int64(7) + ow_1 + ow_2_init + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(32), oc_block_0 * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2_init * T.int64(2) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(512), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(8), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(4), T.int64(1), T.int64(1)):
                    for oc_block_3_fused in T.vectorized(T.int64(2)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_fused_fused // T.int64(7) * T.int64(4) + oc_chunk_1 * T.int64(4) + oc_chunk_2 * T.int64(4) + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_fused_fused % T.int64(7) + oh_1 + oh_2 + oh_3)
                            v_ow = T.axis.spatial(T.int64(7), ow_0 * T.int64(7) + ow_1 + ow_2 + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(32), oc_block_0 * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2 * T.int64(2) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(512), ic_0 + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(4), T.int64(1), T.int64(1)):
                    for ax4_fused in T.vectorized(T.int64(16)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_fused_fused // T.int64(7) * T.int64(4) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_fused_fused % T.int64(7) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(7), ow_1 + ax3)
                            v_ax4 = T.axis.spatial(T.int64(32), oc_block_0 * T.int64(16) + ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[4, 1, 1, 4])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[7, 1, 1, 1])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 7, 1, 1])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[2, 1, 8, 2])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[512, 1])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[3, 1])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l50, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=2)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79 = sch.get_loops(block=b69)
l80 = sch.fuse(l72, l73, l74, preserve_unit_iters=True)
sch.parallel(loop=l80)
l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b70)
l105 = sch.fuse(l81, preserve_unit_iters=True)
sch.parallel(loop=l105)
l106 = sch.fuse(l104, preserve_unit_iters=True)
sch.vectorize(loop=l106)
sch.annotate(block_or_loop=l105, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l105, ann_key="pragma_unroll_explicit", ann_val=1)
l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117, l118, l119 = sch.get_loops(block=b71)
l120 = sch.fuse(l119, preserve_unit_iters=True)
sch.vectorize(loop=l120)
b121 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141, l142, l143, l144, l145 = sch.get_loops(block=b121)
b146 = sch.decompose_reduction(block=b121, loop=l130)
2024-04-28 21:12:59 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #4: GFLOPs: 21.2225. Time: 10898.1794 us. Best GFLOPs: 24.1951
2024-04-28 21:12:59 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #5: GFLOPs: 52.7327. Time: 4386.0088 us. Best GFLOPs: 52.7327
2024-04-28 21:12:59 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #6: GFLOPs: 2.1192. Time: 109136.9067 us. Best GFLOPs: 52.7327
2024-04-28 21:12:59 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #7: GFLOPs: 50.1829. Time: 4608.8660 us. Best GFLOPs: 52.7327
2024-04-28 21:12:59 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #8: GFLOPs: 32.0635. Time: 7213.3789 us. Best GFLOPs: 52.7327
2024-04-28 21:12:59 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #9: GFLOPs: 26.3816. Time: 8766.9390 us. Best GFLOPs: 52.7327
2024-04-28 21:12:59 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #10: GFLOPs: 42.8358. Time: 5399.3691 us. Best GFLOPs: 52.7327
2024-04-28 21:12:59 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #11: GFLOPs: 5.1544. Time: 44871.9197 us. Best GFLOPs: 52.7327
2024-04-28 21:12:59 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #12: GFLOPs: 29.8485. Time: 7748.6678 us. Best GFLOPs: 52.7327
2024-04-28 21:12:59 [INFO] [task_scheduler.cc:121] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #13: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(7), T.int64(7), T.int64(512)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(32)), "float32"), p3: T.Buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_fused in T.parallel(T.int64(28), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for oc_block_0, n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(1), T.int64(4), T.int64(7), T.int64(1)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(8)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_fused // T.int64(7) * T.int64(4) + oc_chunk_1 * T.int64(4) + oc_chunk_2_init * T.int64(4) + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(7), oh_1 * T.int64(7) + oh_2_init * T.int64(7) + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_fused % T.int64(7) + ow_1 + ow_2_init + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(32), oc_block_0 * T.int64(32) + oc_block_1 * T.int64(32) + oc_block_2_init * T.int64(8) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(256), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(2), T.int64(3), T.int64(3), T.int64(1), T.int64(4), T.int64(7), T.int64(1)):
                    for oc_block_3_fused in T.vectorized(T.int64(8)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_fused // T.int64(7) * T.int64(4) + oc_chunk_1 * T.int64(4) + oc_chunk_2 * T.int64(4) + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(7), oh_1 * T.int64(7) + oh_2 * T.int64(7) + oh_3)
                            v_ow = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_fused % T.int64(7) + ow_1 + ow_2 + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(32), oc_block_0 * T.int64(32) + oc_block_1 * T.int64(32) + oc_block_2 * T.int64(8) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(2) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], p0[v_n, v_ic // T.int64(512), v_oh + v_kh - T.int64(1), v_ow + v_kw - T.int64(1), v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + T.if_then_else(T.int64(1) <= v_oh + v_kh and v_oh + v_kh < T.int64(8) and T.int64(1) <= v_ow + v_kw and v_ow + v_kw < T.int64(8), p0[v_n, v_ic // T.int64(512), v_oh + v_kh - T.int64(1), v_ow + v_kw - T.int64(1), v_ic % T.int64(512)], T.float32(0)) * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
        for ax0_ax1_ax2_ax3_ax4_fused_0 in T.parallel(T.int64(392)):
            for ax0_ax1_ax2_ax3_ax4_fused_1 in T.vectorized(T.int64(64)):
                with T.block("T_relu"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) // T.int64(1568))
                    v_ax2 = T.axis.spatial(T.int64(7), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(1568) // T.int64(224))
                    v_ax3 = T.axis.spatial(T.int64(7), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(224) // T.int64(32))
                    v_ax4 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(32))
                    T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[4, 1, 1, 4])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 1, 7])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[7, 1, 1, 1])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[1, 1, 4, 8])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[256, 2])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[1, 3])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=4)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=-2)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69 = sch.get_child_blocks(b67)
l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95 = sch.get_loops(block=b68)
l96 = sch.fuse(l70, l71, l72, l73, preserve_unit_iters=True)
sch.parallel(loop=l96)
l97 = sch.fuse(l95, preserve_unit_iters=True)
sch.vectorize(loop=l97)
sch.annotate(block_or_loop=l96, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l96, ann_key="pragma_unroll_explicit", ann_val=1)
l98, l99, l100, l101, l102 = sch.get_loops(block=b69)
l103 = sch.fuse(l98, l99, l100, l101, l102, preserve_unit_iters=True)
l104, l105 = sch.split(loop=l103, factors=[None, 64], preserve_unit_iters=True)
sch.parallel(loop=l104)
sch.vectorize(loop=l105)
b106 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129 = sch.get_loops(block=b106)
b130 = sch.decompose_reduction(block=b106, loop=l114)
2024-04-28 21:12:59 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #14: GFLOPs: 7.8492. Time: 29466.3872 us. Best GFLOPs: 52.7327
2024-04-28 21:12:59 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #15: GFLOPs: 20.3044. Time: 11390.9179 us. Best GFLOPs: 52.7327
2024-04-28 21:12:59 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #16: GFLOPs: 1.8002. Time: 128479.6630 us. Best GFLOPs: 52.7327
2024-04-28 21:12:59 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #17: GFLOPs: 7.6057. Time: 30409.5735 us. Best GFLOPs: 52.7327
2024-04-28 21:12:59 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #18: GFLOPs: 15.8505. Time: 14591.7793 us. Best GFLOPs: 52.7327
2024-04-28 21:12:59 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #19: GFLOPs: 55.3417. Time: 4179.2439 us. Best GFLOPs: 55.3417
2024-04-28 21:12:59 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #20: GFLOPs: 158.3163. Time: 1460.9129 us. Best GFLOPs: 158.3163
2024-04-28 21:12:59 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #21: GFLOPs: 1.1550. Time: 200254.1733 us. Best GFLOPs: 158.3163
2024-04-28 21:12:59 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #22: GFLOPs: 5.5092. Time: 41981.6930 us. Best GFLOPs: 158.3163
2024-04-28 21:12:59 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #23: GFLOPs: 1.4054. Time: 164570.6767 us. Best GFLOPs: 158.3163
2024-04-28 21:12:59 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #24: GFLOPs: 2.1572. Time: 107215.6463 us. Best GFLOPs: 158.3163
2024-04-28 21:12:59 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #25: GFLOPs: 15.6675. Time: 14762.1666 us. Best GFLOPs: 158.3163
2024-04-28 21:12:59 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #26: GFLOPs: 22.1010. Time: 10464.9659 us. Best GFLOPs: 158.3163
2024-04-28 21:12:59 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #27: GFLOPs: 11.3176. Time: 20436.0170 us. Best GFLOPs: 158.3163
2024-04-28 21:12:59 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #28: GFLOPs: 21.2897. Time: 10863.7838 us. Best GFLOPs: 158.3163
2024-04-28 21:12:59 [INFO] [task_scheduler.cc:121] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #29: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(7), T.int64(7), T.int64(512)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(32)), "float32"), p3: T.Buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(9), T.int64(9), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_fused_fused in T.parallel(T.int64(7), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(3), T.int64(9), T.int64(512)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(9), n_0_oc_chunk_0_oh_0_fused_fused + ax2)
                    v_i3, v_i4 = T.axis.remap("SS", [ax3, ax4])
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(8) and T.int64(1) <= v_i3 and v_i3 < T.int64(8), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for ow_0, oc_block_0 in T.grid(T.int64(1), T.int64(2)):
                for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(16)):
                    for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(1)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(16), oc_chunk_1 * T.int64(16) + oc_chunk_2_init * T.int64(16) + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_fused_fused + oh_1 + oh_2_init + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(7), ow_0 * T.int64(7) + ow_1 * T.int64(7) + ow_2_init + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(32), oc_block_0 * T.int64(16) + oc_block_1 + oc_block_2_init + oc_block_3_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                    for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(128), T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(1)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(16), oc_chunk_1 * T.int64(16) + oc_chunk_2 * T.int64(16) + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_fused_fused + oh_1 + oh_2 + oh_3)
                            v_ow = T.axis.spatial(T.int64(7), ow_0 * T.int64(7) + ow_1 * T.int64(7) + ow_2 + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(32), oc_block_0 * T.int64(16) + oc_block_1 + oc_block_2 + oc_block_3)
                            v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(4) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(16), T.int64(1), T.int64(7)):
                    for ax4_fused in T.vectorized(T.int64(16)):
                        with T.block("T_relu"):
                            v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                            v_ax2 = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_fused_fused + ax2)
                            v_ax3 = T.axis.spatial(T.int64(7), ax3)
                            v_ax4 = T.axis.spatial(T.int64(32), oc_block_0 * T.int64(16) + ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 1, 16])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[7, 1, 1, 1])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 7, 1])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[2, 16, 1, 1])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[128, 4])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[3, 1])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=2)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79 = sch.get_loops(block=b69)
l80 = sch.fuse(l72, l73, l74, preserve_unit_iters=True)
sch.parallel(loop=l80)
l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b70)
l105 = sch.fuse(l81, preserve_unit_iters=True)
sch.parallel(loop=l105)
sch.annotate(block_or_loop=l105, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l105, ann_key="pragma_unroll_explicit", ann_val=1)
l106, l107, l108, l109, l110, l111, l112, l113 = sch.get_loops(block=b71)
l114 = sch.fuse(l113, preserve_unit_iters=True)
sch.vectorize(loop=l114)
b115 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139 = sch.get_loops(block=b115)
b140 = sch.decompose_reduction(block=b115, loop=l124)
2024-04-28 21:12:59 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #30: GFLOPs: 36.1279. Time: 6401.8692 us. Best GFLOPs: 158.3163
2024-04-28 21:12:59 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #31: GFLOPs: 0.7468. Time: 309723.0127 us. Best GFLOPs: 158.3163
2024-04-28 21:12:59 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #32: GFLOPs: 58.6587. Time: 3942.9130 us. Best GFLOPs: 158.3163
2024-04-28 21:12:59 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #33: GFLOPs: 11.0084. Time: 21009.9808 us. Best GFLOPs: 158.3163
2024-04-28 21:13:00 [INFO] [task_scheduler.cc:121] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #34: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(7), T.int64(7), T.int64(512)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(32)), "float32"), p3: T.Buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(9), T.int64(9), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)))
        for n_0_oc_chunk_0_fused_fused in T.parallel(T.int64(2), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(9), T.int64(9), T.int64(512)):
                with T.block("data_pad"):
                    v_i0, v_i1, v_i2, v_i3, v_i4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(8) and T.int64(1) <= v_i3 and v_i3 < T.int64(8), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oh_0, ow_0, oc_block_0, n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(7), T.int64(2), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(1), T.int64(4), T.int64(7), T.int64(1)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_fused_fused * T.int64(8) + oc_chunk_1 * T.int64(4) + oc_chunk_2_init * T.int64(4) + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(7), oh_0 * T.int64(7) + oh_1 * T.int64(7) + oh_2_init * T.int64(7) + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(7), ow_0 + ow_1 + ow_2_init + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(32), oc_block_0 * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2_init * T.int64(4) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(128), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(4), T.int64(3), T.int64(3), T.int64(1), T.int64(4), T.int64(7), T.int64(1)):
                    for oc_block_3_fused in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_fused_fused * T.int64(8) + oc_chunk_1 * T.int64(4) + oc_chunk_2 * T.int64(4) + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(7), oh_0 * T.int64(7) + oh_1 * T.int64(7) + oh_2 * T.int64(7) + oh_3)
                            v_ow = T.axis.spatial(T.int64(7), ow_0 + ow_1 + ow_2 + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(32), oc_block_0 * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2 * T.int64(4) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(4) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
        for ax0_ax1_ax2_ax3_ax4_fused_0 in T.parallel(T.int64(392)):
            for ax0_ax1_ax2_ax3_ax4_fused_1 in T.vectorized(T.int64(64)):
                with T.block("T_relu"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) // T.int64(1568))
                    v_ax2 = T.axis.spatial(T.int64(7), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(1568) // T.int64(224))
                    v_ax3 = T.axis.spatial(T.int64(7), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(224) // T.int64(32))
                    v_ax4 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(32))
                    T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 2, 1, 4])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 1, 7])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[7, 1, 1, 1])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[2, 1, 4, 4])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[128, 4])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[1, 3])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=1)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77 = sch.get_loops(block=b68)
l78 = sch.fuse(l71, l72, preserve_unit_iters=True)
sch.parallel(loop=l78)
l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l79, preserve_unit_iters=True)
sch.parallel(loop=l104)
l105 = sch.fuse(l103, preserve_unit_iters=True)
sch.vectorize(loop=l105)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l106, l107, l108, l109, l110 = sch.get_loops(block=b70)
l111 = sch.fuse(l106, l107, l108, l109, l110, preserve_unit_iters=True)
l112, l113 = sch.split(loop=l111, factors=[None, 64], preserve_unit_iters=True)
sch.parallel(loop=l112)
sch.vectorize(loop=l113)
b114 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139 = sch.get_loops(block=b114)
b140 = sch.decompose_reduction(block=b114, loop=l124)
2024-04-28 21:13:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #35: GFLOPs: 3.7342. Time: 61937.5910 us. Best GFLOPs: 158.3163
2024-04-28 21:13:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #36: GFLOPs: 2.1788. Time: 106150.6963 us. Best GFLOPs: 158.3163
2024-04-28 21:13:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #37: GFLOPs: 63.5168. Time: 3641.3425 us. Best GFLOPs: 158.3163
2024-04-28 21:13:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #38: GFLOPs: 31.0347. Time: 7452.5044 us. Best GFLOPs: 158.3163
2024-04-28 21:13:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #39: GFLOPs: 2.1394. Time: 108107.4203 us. Best GFLOPs: 158.3163
2024-04-28 21:13:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #40: GFLOPs: 4.9157. Time: 47050.7610 us. Best GFLOPs: 158.3163
2024-04-28 21:13:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #41: GFLOPs: 70.9540. Time: 3259.6656 us. Best GFLOPs: 158.3163
2024-04-28 21:13:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #42: GFLOPs: 7.0604. Time: 32758.2618 us. Best GFLOPs: 158.3163
2024-04-28 21:13:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #43: GFLOPs: 43.5197. Time: 5314.5222 us. Best GFLOPs: 158.3163
2024-04-28 21:13:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #44: GFLOPs: 5.0059. Time: 46202.3363 us. Best GFLOPs: 158.3163
2024-04-28 21:13:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #45: GFLOPs: 0.5782. Time: 400011.6620 us. Best GFLOPs: 158.3163
2024-04-28 21:13:00 [INFO] [task_scheduler.cc:121] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #46: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(7), T.int64(7), T.int64(512)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(32)), "float32"), p3: T.Buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(9), T.int64(9), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused in T.parallel(T.int64(28), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1 in T.grid(T.int64(1), T.int64(4)):
                for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(3), T.int64(9), T.int64(512)):
                    with T.block("data_pad"):
                        v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                        v_i2 = T.axis.spatial(T.int64(9), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(7) + ax2)
                        v_i3, v_i4 = T.axis.remap("SS", [ax3, ax4])
                        T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                        T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                        data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(8) and T.int64(1) <= v_i3 and v_i3 < T.int64(8), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                for oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(7), T.int64(4)):
                    for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                        for oc_block_3_fused_init in T.vectorized(T.int64(4)):
                            with T.block("conv2d_NCHWc_init"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                                v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(7) * T.int64(4) + oc_chunk_1 + oc_chunk_2_init + oc_chunk_3_init)
                                v_oh = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(7) + oh_1 + oh_2_init + oh_3_init)
                                v_ow = T.axis.spatial(T.int64(7), ow_1 + ow_2_init + ow_3_init)
                                v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(8) + oc_block_2_init * T.int64(4) + oc_block_3_fused_init)
                                T.reads()
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                    for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(16), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(32), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                        for oc_block_3_fused in T.vectorized(T.int64(4)):
                            with T.block("conv2d_NCHWc_update"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                                v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(7) * T.int64(4) + oc_chunk_1 + oc_chunk_2 + oc_chunk_3)
                                v_oh = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(7) + oh_1 + oh_2 + oh_3)
                                v_ow = T.axis.spatial(T.int64(7), ow_1 + ow_2 + ow_3)
                                v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(8) + oc_block_2 * T.int64(4) + oc_block_3_fused)
                                v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(32) + ic_1)
                                v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                                v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                                T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(4), T.int64(1), T.int64(7)):
                for ax4_fused in T.vectorized(T.int64(32)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(7) * T.int64(4) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(7) + ax2)
                        v_ax3, v_ax4 = T.axis.remap("SS", [ax3, ax4_fused])
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[4, 4, 1, 1])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[7, 1, 1, 1])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 7, 1, 1])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[1, 4, 2, 4])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[16, 32])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[3, 1])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=6)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83 = sch.get_loops(block=b69)
l84 = sch.fuse(l72, l73, l74, l75, l76, preserve_unit_iters=True)
sch.parallel(loop=l84)
l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106 = sch.get_loops(block=b70)
l107 = sch.fuse(l85, preserve_unit_iters=True)
sch.parallel(loop=l107)
l108 = sch.fuse(l106, preserve_unit_iters=True)
sch.vectorize(loop=l108)
sch.annotate(block_or_loop=l107, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l107, ann_key="pragma_unroll_explicit", ann_val=1)
l109, l110, l111, l112, l113, l114 = sch.get_loops(block=b71)
l115 = sch.fuse(l114, preserve_unit_iters=True)
sch.vectorize(loop=l115)
b116 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138 = sch.get_loops(block=b116)
b139 = sch.decompose_reduction(block=b116, loop=l123)
2024-04-28 21:13:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #47: GFLOPs: 62.6412. Time: 3692.2407 us. Best GFLOPs: 158.3163
2024-04-28 21:13:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #48: GFLOPs: 68.7193. Time: 3365.6691 us. Best GFLOPs: 158.3163
2024-04-28 21:13:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #49: GFLOPs: 1.6616. Time: 139197.6630 us. Best GFLOPs: 158.3163
2024-04-28 21:13:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #50: GFLOPs: 18.5659. Time: 12457.5924 us. Best GFLOPs: 158.3163
2024-04-28 21:13:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #51: GFLOPs: 1.7874. Time: 129395.1220 us. Best GFLOPs: 158.3163
2024-04-28 21:13:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #52: GFLOPs: 18.6744. Time: 12385.2139 us. Best GFLOPs: 158.3163
2024-04-28 21:13:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #53: GFLOPs: 6.3895. Time: 36197.7683 us. Best GFLOPs: 158.3163
2024-04-28 21:13:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #54: GFLOPs: 6.5720. Time: 35192.9277 us. Best GFLOPs: 158.3163
2024-04-28 21:13:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #55: GFLOPs: 34.0178. Time: 6798.9737 us. Best GFLOPs: 158.3163
2024-04-28 21:13:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #56: GFLOPs: 19.8430. Time: 11655.8046 us. Best GFLOPs: 158.3163
2024-04-28 21:13:00 [INFO] [task_scheduler.cc:121] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #57: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(7), T.int64(7), T.int64(512)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(32)), "float32"), p3: T.Buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(9), T.int64(9), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)))
        for i0_i1_i2_i3_i4_fused in T.parallel(T.int64(41472)):
            with T.block("data_pad"):
                v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                v_i1 = T.axis.spatial(T.int64(1), T.int64(0))
                v_i2 = T.axis.spatial(T.int64(9), i0_i1_i2_i3_i4_fused // T.int64(4608))
                v_i3 = T.axis.spatial(T.int64(9), i0_i1_i2_i3_i4_fused % T.int64(4608) // T.int64(512))
                v_i4 = T.axis.spatial(T.int64(512), i0_i1_i2_i3_i4_fused % T.int64(512))
                T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(8) and T.int64(1) <= v_i3 and v_i3 < T.int64(8), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused in T.parallel(T.int64(2), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(2)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(7)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(16)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused * T.int64(8) + oc_chunk_1 + oc_chunk_2_init + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(7), oh_1 * T.int64(7) + oh_2_init * T.int64(7) + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(7), ow_1 * T.int64(7) + ow_2_init * T.int64(7) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(16) + oc_block_2_init * T.int64(16) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(512), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(7)):
                    for oc_block_3_fused in T.vectorized(T.int64(16)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused * T.int64(8) + oc_chunk_1 + oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(7), oh_1 * T.int64(7) + oh_2 * T.int64(7) + oh_3)
                            v_ow = T.axis.spatial(T.int64(7), ow_1 * T.int64(7) + ow_2 * T.int64(7) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(16) + oc_block_2 * T.int64(16) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(512), ic_0 + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(8), T.int64(7), T.int64(7)):
                for ax4_fused in T.vectorized(T.int64(32)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused * T.int64(8) + ax1)
                        v_ax2, v_ax3, v_ax4 = T.axis.remap("SSS", [ax2, ax3, ax4_fused])
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 8, 1, 1])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 1, 7])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 1, 7])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[1, 2, 1, 16])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[512, 1])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[3, 1])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=-1)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76 = sch.get_loops(block=b69)
l77 = sch.fuse(l72, l73, l74, l75, l76, preserve_unit_iters=True)
sch.parallel(loop=l77)
l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b70)
l104 = sch.fuse(l78, l79, l80, l81, l82, preserve_unit_iters=True)
sch.parallel(loop=l104)
l105 = sch.fuse(l103, preserve_unit_iters=True)
sch.vectorize(loop=l105)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l106, l107, l108, l109, l110, l111 = sch.get_loops(block=b71)
l112 = sch.fuse(l111, preserve_unit_iters=True)
sch.vectorize(loop=l112)
b113 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135 = sch.get_loops(block=b113)
b136 = sch.decompose_reduction(block=b113, loop=l120)
2024-04-28 21:13:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #58: GFLOPs: 2.7888. Time: 82934.7143 us. Best GFLOPs: 158.3163
2024-04-28 21:13:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #59: GFLOPs: 7.2165. Time: 32049.6570 us. Best GFLOPs: 158.3163
2024-04-28 21:13:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #60: GFLOPs: 2.0644. Time: 112035.4187 us. Best GFLOPs: 158.3163
2024-04-28 21:13:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #61: GFLOPs: 25.4718. Time: 9080.1060 us. Best GFLOPs: 158.3163
2024-04-28 21:13:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #62: GFLOPs: 19.8524. Time: 11650.2734 us. Best GFLOPs: 158.3163
2024-04-28 21:13:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #63: GFLOPs: 27.7222. Time: 8342.9915 us. Best GFLOPs: 158.3163
2024-04-28 21:13:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #64: GFLOPs: 1.8630. Time: 124150.1637 us. Best GFLOPs: 158.3163
2024-04-28 21:13:14 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-28 21:13:14 [INFO] [evolutionary_search.cc:715] Picked top 58 candidate(s) from database
2024-04-28 21:13:19 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f1e458)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x386def8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x36b1d38)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3108268)]: 0 failure(s)
2024-04-28 21:13:19 [INFO] [evolutionary_search.cc:723] Sampled 454 candidate(s)
2024-04-28 21:13:30 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f1e458)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x386def8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x36b1d38)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3108268)]: 0 failure(s)
2024-04-28 21:13:41 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f1e458)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x386def8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x36b1d38)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3108268)]: 0 failure(s)
2024-04-28 21:13:53 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f1e458)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x386def8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x36b1d38)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3108268)]: 0 failure(s)
2024-04-28 21:14:06 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f1e458)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x386def8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x36b1d38)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3108268)]: 0 failure(s)
2024-04-28 21:14:13 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	1.0238  1.0060  1.0060  1.0049  1.0049  1.0026  1.0026  0.9530  0.9287  0.9207  0.9086  0.8962  0.8949  0.8932  0.8839  0.8822
[17 : 32]:	0.8585  0.8533  0.8411  0.8395  0.8348  0.8322  0.8274  0.8043  0.8040  0.7970  0.7790  0.7789  0.7700  0.7602  0.7583  0.7545
[33 : 48]:	0.7537  0.7416  0.7400  0.7395  0.7328  0.7328  0.7317  0.7312  0.7296  0.7266  0.7172  0.7165  0.7130  0.7016  0.7011  0.7000
[49 : 64]:	0.6987  0.6929  0.6891  0.6891  0.6844  0.6837  0.6782  0.6732  0.6727  0.6726  0.6719  0.6697  0.6694  0.6694  0.6681  0.6678
2024-04-28 21:14:13 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-28 21:14:13 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-28 21:15:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #65: GFLOPs: 164.4958. Time: 1406.0318 us. Best GFLOPs: 164.4958
2024-04-28 21:15:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #66: GFLOPs: 127.9726. Time: 1807.3109 us. Best GFLOPs: 164.4958
2024-04-28 21:15:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #67: GFLOPs: 155.5190. Time: 1487.1896 us. Best GFLOPs: 164.4958
2024-04-28 21:15:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #68: GFLOPs: 98.8459. Time: 2339.8682 us. Best GFLOPs: 164.4958
2024-04-28 21:15:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #69: GFLOPs: 101.4307. Time: 2280.2396 us. Best GFLOPs: 164.4958
2024-04-28 21:15:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #70: GFLOPs: 164.2271. Time: 1408.3316 us. Best GFLOPs: 164.4958
2024-04-28 21:15:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #71: GFLOPs: 163.9496. Time: 1410.7156 us. Best GFLOPs: 164.4958
2024-04-28 21:15:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #72: GFLOPs: 171.1524. Time: 1351.3466 us. Best GFLOPs: 171.1524
2024-04-28 21:15:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #73: GFLOPs: 133.4806. Time: 1732.7334 us. Best GFLOPs: 171.1524
2024-04-28 21:15:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #74: GFLOPs: 106.8015. Time: 2165.5721 us. Best GFLOPs: 171.1524
2024-04-28 21:15:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #75: GFLOPs: 140.8194. Time: 1642.4317 us. Best GFLOPs: 171.1524
2024-04-28 21:15:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #76: GFLOPs: 113.2668. Time: 2041.9607 us. Best GFLOPs: 171.1524
2024-04-28 21:15:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #77: GFLOPs: 135.4165. Time: 1707.9619 us. Best GFLOPs: 171.1524
2024-04-28 21:15:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #78: GFLOPs: 171.5968. Time: 1347.8473 us. Best GFLOPs: 171.5968
2024-04-28 21:15:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #79: GFLOPs: 109.1321. Time: 2119.3237 us. Best GFLOPs: 171.5968
2024-04-28 21:15:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #80: GFLOPs: 128.4292. Time: 1800.8852 us. Best GFLOPs: 171.5968
2024-04-28 21:15:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #81: GFLOPs: 109.5346. Time: 2111.5357 us. Best GFLOPs: 171.5968
2024-04-28 21:15:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #82: GFLOPs: 90.9642. Time: 2542.6075 us. Best GFLOPs: 171.5968
2024-04-28 21:15:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #83: GFLOPs: 49.4700. Time: 4675.2863 us. Best GFLOPs: 171.5968
2024-04-28 21:15:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #84: GFLOPs: 113.1271. Time: 2044.4815 us. Best GFLOPs: 171.5968
2024-04-28 21:15:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #85: GFLOPs: 49.4925. Time: 4673.1590 us. Best GFLOPs: 171.5968
2024-04-28 21:15:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #86: GFLOPs: 115.4931. Time: 2002.5976 us. Best GFLOPs: 171.5968
2024-04-28 21:15:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #87: GFLOPs: 80.9822. Time: 2856.0147 us. Best GFLOPs: 171.5968
2024-04-28 21:15:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #88: GFLOPs: 140.9596. Time: 1640.7985 us. Best GFLOPs: 171.5968
2024-04-28 21:15:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #89: GFLOPs: 79.9772. Time: 2891.9029 us. Best GFLOPs: 171.5968
2024-04-28 21:15:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #90: GFLOPs: 128.2646. Time: 1803.1963 us. Best GFLOPs: 171.5968
2024-04-28 21:15:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #91: GFLOPs: 13.0352. Time: 17743.1985 us. Best GFLOPs: 171.5968
2024-04-28 21:15:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #92: GFLOPs: 65.2415. Time: 3545.0772 us. Best GFLOPs: 171.5968
2024-04-28 21:15:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #93: GFLOPs: 48.1987. Time: 4798.5967 us. Best GFLOPs: 171.5968
2024-04-28 21:15:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #94: GFLOPs: 74.7977. Time: 3092.1579 us. Best GFLOPs: 171.5968
2024-04-28 21:15:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #95: GFLOPs: 9.6750. Time: 23905.5596 us. Best GFLOPs: 171.5968
2024-04-28 21:15:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #96: GFLOPs: 17.7874. Time: 13002.8136 us. Best GFLOPs: 171.5968
2024-04-28 21:15:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #97: GFLOPs: 84.0343. Time: 2752.2849 us. Best GFLOPs: 171.5968
2024-04-28 21:15:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #98: GFLOPs: 150.1580. Time: 1540.2856 us. Best GFLOPs: 171.5968
2024-04-28 21:15:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #99: GFLOPs: 157.3817. Time: 1469.5881 us. Best GFLOPs: 171.5968
2024-04-28 21:15:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #100: GFLOPs: 58.1146. Time: 3979.8338 us. Best GFLOPs: 171.5968
2024-04-28 21:15:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #101: GFLOPs: 66.3532. Time: 3485.6837 us. Best GFLOPs: 171.5968
2024-04-28 21:15:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #102: GFLOPs: 44.8142. Time: 5161.0062 us. Best GFLOPs: 171.5968
2024-04-28 21:15:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #103: GFLOPs: 90.7516. Time: 2548.5633 us. Best GFLOPs: 171.5968
2024-04-28 21:15:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #104: GFLOPs: 75.4490. Time: 3065.4657 us. Best GFLOPs: 171.5968
2024-04-28 21:15:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #105: GFLOPs: 98.3515. Time: 2351.6283 us. Best GFLOPs: 171.5968
2024-04-28 21:15:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #106: GFLOPs: 25.5176. Time: 9063.7884 us. Best GFLOPs: 171.5968
2024-04-28 21:15:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #107: GFLOPs: 157.9610. Time: 1464.1987 us. Best GFLOPs: 171.5968
2024-04-28 21:15:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #108: GFLOPs: 86.0393. Time: 2688.1459 us. Best GFLOPs: 171.5968
2024-04-28 21:15:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #109: GFLOPs: 79.1292. Time: 2922.8945 us. Best GFLOPs: 171.5968
2024-04-28 21:15:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #110: GFLOPs: 90.5032. Time: 2555.5581 us. Best GFLOPs: 171.5968
2024-04-28 21:15:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #111: GFLOPs: 258.8257. Time: 893.5986 us. Best GFLOPs: 258.8257
2024-04-28 21:15:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #112: GFLOPs: 114.1828. Time: 2025.5796 us. Best GFLOPs: 258.8257
2024-04-28 21:15:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #113: GFLOPs: 60.6341. Time: 3814.4574 us. Best GFLOPs: 258.8257
2024-04-28 21:15:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #114: GFLOPs: 96.5115. Time: 2396.4638 us. Best GFLOPs: 258.8257
2024-04-28 21:15:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #115: GFLOPs: 88.3744. Time: 2617.1173 us. Best GFLOPs: 258.8257
2024-04-28 21:15:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #116: GFLOPs: 116.7614. Time: 1980.8452 us. Best GFLOPs: 258.8257
2024-04-28 21:15:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #117: GFLOPs: 68.1500. Time: 3393.7807 us. Best GFLOPs: 258.8257
2024-04-28 21:15:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #118: GFLOPs: 81.8025. Time: 2827.3736 us. Best GFLOPs: 258.8257
2024-04-28 21:15:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #119: GFLOPs: 145.2521. Time: 1592.3094 us. Best GFLOPs: 258.8257
2024-04-28 21:15:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #120: GFLOPs: 13.2518. Time: 17453.2335 us. Best GFLOPs: 258.8257
2024-04-28 21:15:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #121: GFLOPs: 81.3384. Time: 2843.5056 us. Best GFLOPs: 258.8257
2024-04-28 21:15:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #122: GFLOPs: 20.5854. Time: 11235.4473 us. Best GFLOPs: 258.8257
2024-04-28 21:15:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #123: GFLOPs: 71.3936. Time: 3239.5921 us. Best GFLOPs: 258.8257
2024-04-28 21:15:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #124: GFLOPs: 49.5853. Time: 4664.4161 us. Best GFLOPs: 258.8257
2024-04-28 21:15:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #125: GFLOPs: 23.1821. Time: 9976.9472 us. Best GFLOPs: 258.8257
2024-04-28 21:15:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #126: GFLOPs: 14.5319. Time: 15915.7553 us. Best GFLOPs: 258.8257
2024-04-28 21:15:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #127: GFLOPs: 31.8069. Time: 7271.5650 us. Best GFLOPs: 258.8257
2024-04-28 21:15:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #128: GFLOPs: 18.0511. Time: 12812.8790 us. Best GFLOPs: 258.8257
2024-04-28 21:30:35 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-28 21:30:36 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-28 21:30:40 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f1e458)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x386def8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x36b1d38)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3108268)]: 0 failure(s)
2024-04-28 21:30:40 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-28 21:30:51 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f1e458)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x386def8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x36b1d38)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3108268)]: 0 failure(s)
2024-04-28 21:31:03 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f1e458)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x386def8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x36b1d38)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3108268)]: 0 failure(s)
2024-04-28 21:31:15 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f1e458)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x386def8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x36b1d38)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3108268)]: 0 failure(s)
2024-04-28 21:31:27 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f1e458)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x386def8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x36b1d38)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3108268)]: 0 failure(s)
2024-04-28 21:31:34 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9897  0.9595  0.8892  0.8632  0.8163  0.8163  0.8163  0.8036  0.7810  0.7810  0.7810  0.7806  0.7806  0.7806  0.7777  0.7775
[17 : 32]:	0.7751  0.7631  0.7451  0.7209  0.7146  0.7028  0.6828  0.6736  0.6693  0.6617  0.6612  0.6606  0.6536  0.6536  0.6515  0.6488
[33 : 48]:	0.6370  0.6293  0.6246  0.6217  0.6217  0.6161  0.6161  0.6159  0.6098  0.6069  0.6041  0.6038  0.6038  0.6020  0.5980  0.5971
[49 : 64]:	0.5962  0.5953  0.5937  0.5908  0.5878  0.5844  0.5832  0.5829  0.5829  0.5824  0.5782  0.5744  0.5739  0.5675  0.5667  0.5646
2024-04-28 21:31:34 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-28 21:31:34 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-28 21:33:16 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #129: GFLOPs: 175.1001. Time: 1320.8800 us. Best GFLOPs: 258.8257
2024-04-28 21:33:16 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #130: GFLOPs: 278.5176. Time: 830.4189 us. Best GFLOPs: 278.5176
2024-04-28 21:33:16 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #131: GFLOPs: 178.3967. Time: 1296.4717 us. Best GFLOPs: 278.5176
2024-04-28 21:33:16 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #132: GFLOPs: 207.0773. Time: 1116.9077 us. Best GFLOPs: 278.5176
2024-04-28 21:33:16 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #133: GFLOPs: 114.2541. Time: 2024.3149 us. Best GFLOPs: 278.5176
2024-04-28 21:33:16 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #134: GFLOPs: 158.7736. Time: 1456.7050 us. Best GFLOPs: 278.5176
2024-04-28 21:33:16 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #135: GFLOPs: 96.3326. Time: 2400.9143 us. Best GFLOPs: 278.5176
2024-04-28 21:33:16 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #136: GFLOPs: 200.5009. Time: 1153.5423 us. Best GFLOPs: 278.5176
2024-04-28 21:33:16 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #137: GFLOPs: 136.2304. Time: 1697.7583 us. Best GFLOPs: 278.5176
2024-04-28 21:33:16 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #138: GFLOPs: 183.6217. Time: 1259.5803 us. Best GFLOPs: 278.5176
2024-04-28 21:33:16 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #139: GFLOPs: 153.8630. Time: 1503.1964 us. Best GFLOPs: 278.5176
2024-04-28 21:33:16 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #140: GFLOPs: 137.0428. Time: 1687.6943 us. Best GFLOPs: 278.5176
2024-04-28 21:33:16 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #141: GFLOPs: 109.6675. Time: 2108.9764 us. Best GFLOPs: 278.5176
2024-04-28 21:33:16 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #142: GFLOPs: 141.6652. Time: 1632.6259 us. Best GFLOPs: 278.5176
2024-04-28 21:33:16 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #143: GFLOPs: 263.5301. Time: 877.6465 us. Best GFLOPs: 278.5176
2024-04-28 21:33:16 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #144: GFLOPs: 172.7818. Time: 1338.6030 us. Best GFLOPs: 278.5176
2024-04-28 21:33:16 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #145: GFLOPs: 228.2168. Time: 1013.4497 us. Best GFLOPs: 278.5176
2024-04-28 21:33:16 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #146: GFLOPs: 203.2905. Time: 1137.7129 us. Best GFLOPs: 278.5176
2024-04-28 21:33:16 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #147: GFLOPs: 156.9207. Time: 1473.9050 us. Best GFLOPs: 278.5176
2024-04-28 21:33:16 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #148: GFLOPs: 102.5422. Time: 2255.5220 us. Best GFLOPs: 278.5176
2024-04-28 21:33:16 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #149: GFLOPs: 333.9768. Time: 692.5220 us. Best GFLOPs: 333.9768
2024-04-28 21:33:16 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #150: GFLOPs: 145.3519. Time: 1591.2164 us. Best GFLOPs: 333.9768
2024-04-28 21:33:16 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #151: GFLOPs: 96.2365. Time: 2403.3120 us. Best GFLOPs: 333.9768
2024-04-28 21:33:16 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #152: GFLOPs: 343.7615. Time: 672.8102 us. Best GFLOPs: 343.7615
2024-04-28 21:33:16 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #153: GFLOPs: 107.3419. Time: 2154.6685 us. Best GFLOPs: 343.7615
2024-04-28 21:33:16 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #154: GFLOPs: 201.6432. Time: 1147.0075 us. Best GFLOPs: 343.7615
2024-04-28 21:33:16 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #155: GFLOPs: 28.7883. Time: 8034.0379 us. Best GFLOPs: 343.7615
2024-04-28 21:33:16 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #156: GFLOPs: 163.4844. Time: 1414.7302 us. Best GFLOPs: 343.7615
2024-04-28 21:33:16 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #157: GFLOPs: 146.4802. Time: 1578.9593 us. Best GFLOPs: 343.7615
2024-04-28 21:33:16 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #158: GFLOPs: 148.3697. Time: 1558.8515 us. Best GFLOPs: 343.7615
2024-04-28 21:33:16 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #159: GFLOPs: 97.7770. Time: 2365.4457 us. Best GFLOPs: 343.7615
2024-04-28 21:33:16 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #160: GFLOPs: 170.1705. Time: 1359.1443 us. Best GFLOPs: 343.7615
2024-04-28 21:33:16 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #161: GFLOPs: 243.3661. Time: 950.3636 us. Best GFLOPs: 343.7615
2024-04-28 21:33:16 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #162: GFLOPs: 170.2546. Time: 1358.4726 us. Best GFLOPs: 343.7615
2024-04-28 21:33:16 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #163: GFLOPs: 129.8039. Time: 1781.8136 us. Best GFLOPs: 343.7615
2024-04-28 21:33:16 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #164: GFLOPs: 74.5830. Time: 3101.0603 us. Best GFLOPs: 343.7615
2024-04-28 21:33:16 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #165: GFLOPs: 161.7093. Time: 1430.2596 us. Best GFLOPs: 343.7615
2024-04-28 21:33:16 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #166: GFLOPs: 165.0300. Time: 1401.4806 us. Best GFLOPs: 343.7615
2024-04-28 21:33:16 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #167: GFLOPs: 164.0606. Time: 1409.7608 us. Best GFLOPs: 343.7615
2024-04-28 21:33:16 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #168: GFLOPs: 172.5445. Time: 1340.4442 us. Best GFLOPs: 343.7615
2024-04-28 21:33:16 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #169: GFLOPs: 102.4227. Time: 2258.1552 us. Best GFLOPs: 343.7615
2024-04-28 21:33:16 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #170: GFLOPs: 134.6920. Time: 1717.1490 us. Best GFLOPs: 343.7615
2024-04-28 21:33:16 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #171: GFLOPs: 129.7291. Time: 1782.8403 us. Best GFLOPs: 343.7615
2024-04-28 21:33:16 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #172: GFLOPs: 117.2664. Time: 1972.3143 us. Best GFLOPs: 343.7615
2024-04-28 21:33:16 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #173: GFLOPs: 122.4290. Time: 1889.1466 us. Best GFLOPs: 343.7615
2024-04-28 21:33:16 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #174: GFLOPs: 174.4028. Time: 1326.1617 us. Best GFLOPs: 343.7615
2024-04-28 21:33:16 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #175: GFLOPs: 77.1772. Time: 2996.8211 us. Best GFLOPs: 343.7615
2024-04-28 21:33:16 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #176: GFLOPs: 119.8799. Time: 1929.3158 us. Best GFLOPs: 343.7615
2024-04-28 21:33:16 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #177: GFLOPs: 94.3190. Time: 2452.1704 us. Best GFLOPs: 343.7615
2024-04-28 21:33:16 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #178: GFLOPs: 126.6323. Time: 1826.4392 us. Best GFLOPs: 343.7615
2024-04-28 21:33:16 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #179: GFLOPs: 166.0731. Time: 1392.6774 us. Best GFLOPs: 343.7615
2024-04-28 21:33:16 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #180: GFLOPs: 177.6485. Time: 1301.9319 us. Best GFLOPs: 343.7615
2024-04-28 21:33:16 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #181: GFLOPs: 112.0743. Time: 2063.6875 us. Best GFLOPs: 343.7615
2024-04-28 21:33:16 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #182: GFLOPs: 115.7645. Time: 1997.9029 us. Best GFLOPs: 343.7615
2024-04-28 21:33:16 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #183: GFLOPs: 80.7682. Time: 2863.5809 us. Best GFLOPs: 343.7615
2024-04-28 21:33:16 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #184: GFLOPs: 146.0733. Time: 1583.3571 us. Best GFLOPs: 343.7615
2024-04-28 21:33:16 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #185: GFLOPs: 155.3268. Time: 1489.0297 us. Best GFLOPs: 343.7615
2024-04-28 21:33:16 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #186: GFLOPs: 163.5525. Time: 1414.1409 us. Best GFLOPs: 343.7615
2024-04-28 21:33:16 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #187: GFLOPs: 77.8172. Time: 2972.1732 us. Best GFLOPs: 343.7615
2024-04-28 21:33:16 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #188: GFLOPs: 222.7609. Time: 1038.2715 us. Best GFLOPs: 343.7615
2024-04-28 21:33:16 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #189: GFLOPs: 102.4366. Time: 2257.8488 us. Best GFLOPs: 343.7615
2024-04-28 21:33:16 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #190: GFLOPs: 1.5386. Time: 150324.5213 us. Best GFLOPs: 343.7615
2024-04-28 21:33:16 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #191: GFLOPs: 5.8143. Time: 39779.0000 us. Best GFLOPs: 343.7615
2024-04-28 21:33:16 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #192: GFLOPs: 29.4516. Time: 7853.0994 us. Best GFLOPs: 343.7615
2024-04-28 21:54:51 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-28 21:54:52 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-28 21:54:56 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f1e458)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x386def8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x36b1d38)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3108268)]: 0 failure(s)
2024-04-28 21:54:56 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-28 21:55:08 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f1e458)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x386def8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x36b1d38)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3108268)]: 0 failure(s)
2024-04-28 21:55:20 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f1e458)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x386def8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x36b1d38)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3108268)]: 0 failure(s)
2024-04-28 21:55:33 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f1e458)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x386def8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x36b1d38)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3108268)]: 0 failure(s)
2024-04-28 21:55:45 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f1e458)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x386def8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x36b1d38)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3108268)]: 0 failure(s)
2024-04-28 21:55:53 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9333  0.9333  0.9125  0.9062  0.8532  0.8484  0.8484  0.8481  0.8264  0.8251  0.8206  0.8206  0.8206  0.8173  0.8002  0.7938
[17 : 32]:	0.7803  0.7756  0.7619  0.7593  0.7582  0.7533  0.7434  0.7398  0.7325  0.7279  0.7208  0.7082  0.7049  0.7037  0.7020  0.7015
[33 : 48]:	0.6924  0.6920  0.6903  0.6895  0.6799  0.6779  0.6758  0.6750  0.6749  0.6744  0.6636  0.6613  0.6597  0.6563  0.6528  0.6521
[49 : 64]:	0.6506  0.6476  0.6376  0.6367  0.6321  0.6299  0.6299  0.6271  0.6265  0.6247  0.6179  0.6111  0.6100  0.6054  0.6054  0.6017
2024-04-28 21:55:53 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-28 21:55:54 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-28 21:57:49 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #193: GFLOPs: 348.6363. Time: 663.4028 us. Best GFLOPs: 348.6363
2024-04-28 21:57:49 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #194: GFLOPs: 278.6042. Time: 830.1606 us. Best GFLOPs: 348.6363
2024-04-28 21:57:49 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #195: GFLOPs: 194.8656. Time: 1186.9013 us. Best GFLOPs: 348.6363
2024-04-28 21:57:49 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #196: GFLOPs: 361.0636. Time: 640.5693 us. Best GFLOPs: 361.0636
2024-04-28 21:57:49 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #197: GFLOPs: 246.6713. Time: 937.6295 us. Best GFLOPs: 361.0636
2024-04-28 21:57:49 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #198: GFLOPs: 263.3939. Time: 878.1003 us. Best GFLOPs: 361.0636
2024-04-28 21:57:49 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #199: GFLOPs: 222.2954. Time: 1040.4454 us. Best GFLOPs: 361.0636
2024-04-28 21:57:49 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #200: GFLOPs: 370.6176. Time: 624.0564 us. Best GFLOPs: 370.6176
2024-04-28 21:57:49 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #201: GFLOPs: 234.6131. Time: 985.8201 us. Best GFLOPs: 370.6176
2024-04-28 21:57:49 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #202: GFLOPs: 400.1530. Time: 577.9945 us. Best GFLOPs: 400.1530
2024-04-28 21:57:49 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #203: GFLOPs: 218.0987. Time: 1060.4662 us. Best GFLOPs: 400.1530
2024-04-28 21:57:49 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #204: GFLOPs: 249.1755. Time: 928.2064 us. Best GFLOPs: 400.1530
2024-04-28 21:57:49 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #205: GFLOPs: 221.3075. Time: 1045.0901 us. Best GFLOPs: 400.1530
2024-04-28 21:57:49 [INFO] [task_scheduler.cc:121] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #206: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(7), T.int64(7), T.int64(512)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(32)), "float32"), p3: T.Buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(9), T.int64(9), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused in T.parallel(T.int64(224), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(9), T.int64(3), T.int64(512)):
                with T.block("data_pad"):
                    v_i0, v_i1, v_i2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                    v_i3 = T.axis.spatial(T.int64(9), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(32) + ax3)
                    v_i4 = T.axis.spatial(T.int64(512), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(8) and T.int64(1) <= v_i3 and v_i3 < T.int64(8), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(16) + oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(7), oh_1 * T.int64(7) + oh_2_init * T.int64(7) + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(32) + ow_1 + ow_2_init + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(32) // T.int64(16) * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(64), T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(16), T.int64(8), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(16) + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(7), oh_1 * T.int64(7) + oh_2 * T.int64(7) + oh_3)
                        v_ow = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(32) + ow_1 + ow_2 + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(32) // T.int64(16) * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(8) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(7), T.int64(1)):
                    for ax4_fused in T.vectorized(T.int64(16)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(16) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(7), ax2)
                            v_ax3 = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(32) + ax3)
                            v_ax4 = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(32) // T.int64(16) * T.int64(16) + ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 16, 1, 1])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 1, 7])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[7, 1, 1, 1])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[2, 1, 16, 1])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[64, 8])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[3, 1])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l50, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=6)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83 = sch.get_loops(block=b69)
l84 = sch.fuse(l72, l73, l74, l75, l76, l77, l78, preserve_unit_iters=True)
sch.parallel(loop=l84)
l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b70)
l105 = sch.fuse(l85, preserve_unit_iters=True)
sch.parallel(loop=l105)
sch.annotate(block_or_loop=l105, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l105, ann_key="pragma_unroll_explicit", ann_val=1)
l106, l107, l108, l109, l110, l111, l112, l113, l114 = sch.get_loops(block=b71)
l115 = sch.fuse(l114, preserve_unit_iters=True)
sch.vectorize(loop=l115)
b116 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136 = sch.get_loops(block=b116)
b137 = sch.decompose_reduction(block=b116, loop=l121)
2024-04-28 21:57:49 [INFO] [task_scheduler.cc:121] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #207: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(7), T.int64(7), T.int64(512)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(32)), "float32"), p3: T.Buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(9), T.int64(9), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused in T.parallel(T.int64(224), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(9), T.int64(3), T.int64(512)):
                with T.block("data_pad"):
                    v_i0, v_i1, v_i2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                    v_i3 = T.axis.spatial(T.int64(9), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(32) + ax3)
                    v_i4 = T.axis.spatial(T.int64(512), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(8) and T.int64(1) <= v_i3 and v_i3 < T.int64(8), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(16) + oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(7), oh_1 * T.int64(7) + oh_2_init * T.int64(7) + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(32) + ow_1 + ow_2_init + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(32) // T.int64(16) * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(64), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(16), T.int64(8), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(16) + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(7), oh_1 * T.int64(7) + oh_2 * T.int64(7) + oh_3)
                        v_ow = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(32) + ow_1 + ow_2 + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(32) // T.int64(16) * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(8) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(7), T.int64(1)):
                    for ax4_fused in T.vectorized(T.int64(16)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(16) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(7), ax2)
                            v_ax3 = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(32) + ax3)
                            v_ax4 = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(32) // T.int64(16) * T.int64(16) + ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 16, 1, 1])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 1, 7])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[7, 1, 1, 1])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[2, 1, 16, 1])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[64, 8])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[1, 3])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l50, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=6)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83 = sch.get_loops(block=b69)
l84 = sch.fuse(l72, l73, l74, l75, l76, l77, l78, preserve_unit_iters=True)
sch.parallel(loop=l84)
l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b70)
l105 = sch.fuse(l85, preserve_unit_iters=True)
sch.parallel(loop=l105)
sch.annotate(block_or_loop=l105, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l105, ann_key="pragma_unroll_explicit", ann_val=1)
l106, l107, l108, l109, l110, l111, l112, l113, l114 = sch.get_loops(block=b71)
l115 = sch.fuse(l114, preserve_unit_iters=True)
sch.vectorize(loop=l115)
b116 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136 = sch.get_loops(block=b116)
b137 = sch.decompose_reduction(block=b116, loop=l121)
2024-04-28 21:57:49 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #208: GFLOPs: 257.1593. Time: 899.3890 us. Best GFLOPs: 400.1530
2024-04-28 21:57:49 [INFO] [task_scheduler.cc:121] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #209: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(7), T.int64(7), T.int64(512)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(32)), "float32"), p3: T.Buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(9), T.int64(9), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused in T.parallel(T.int64(224), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(9), T.int64(3), T.int64(512)):
                with T.block("data_pad"):
                    v_i0, v_i1, v_i2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                    v_i3 = T.axis.spatial(T.int64(9), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(112) // T.int64(16) + ax3)
                    v_i4 = T.axis.spatial(T.int64(512), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(8) and T.int64(1) <= v_i3 and v_i3 < T.int64(8), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(112) * T.int64(8) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(8) + oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(7), oh_1 * T.int64(7) + oh_2_init * T.int64(7) + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(112) // T.int64(16) + ow_1 + ow_2_init + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(16) // T.int64(8) * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(64), T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(16), T.int64(8), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(112) * T.int64(8) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(8) + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(7), oh_1 * T.int64(7) + oh_2 * T.int64(7) + oh_3)
                        v_ow = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(112) // T.int64(16) + ow_1 + ow_2 + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(16) // T.int64(8) * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(8) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(7), T.int64(1)):
                    for ax4_fused in T.vectorized(T.int64(16)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(112) * T.int64(8) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(8) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(7), ax2)
                            v_ax3 = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(112) // T.int64(16) + ax3)
                            v_ax4 = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(16) // T.int64(8) * T.int64(16) + ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 8, 1, 1])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 1, 7])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[7, 1, 1, 1])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[2, 1, 16, 1])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[64, 8])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[3, 1])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l50, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=6)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83 = sch.get_loops(block=b69)
l84 = sch.fuse(l72, l73, l74, l75, l76, l77, l78, preserve_unit_iters=True)
sch.parallel(loop=l84)
l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b70)
l105 = sch.fuse(l85, preserve_unit_iters=True)
sch.parallel(loop=l105)
sch.annotate(block_or_loop=l105, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l105, ann_key="pragma_unroll_explicit", ann_val=1)
l106, l107, l108, l109, l110, l111, l112, l113, l114 = sch.get_loops(block=b71)
l115 = sch.fuse(l114, preserve_unit_iters=True)
sch.vectorize(loop=l115)
b116 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136 = sch.get_loops(block=b116)
b137 = sch.decompose_reduction(block=b116, loop=l121)
2024-04-28 21:57:49 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #210: GFLOPs: 148.9335. Time: 1552.9504 us. Best GFLOPs: 400.1530
2024-04-28 21:57:49 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #211: GFLOPs: 330.2124. Time: 700.4166 us. Best GFLOPs: 400.1530
2024-04-28 21:57:49 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #212: GFLOPs: 261.7035. Time: 883.7721 us. Best GFLOPs: 400.1530
2024-04-28 21:57:49 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #213: GFLOPs: 282.5909. Time: 818.4492 us. Best GFLOPs: 400.1530
2024-04-28 21:57:49 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #214: GFLOPs: 91.4982. Time: 2527.7679 us. Best GFLOPs: 400.1530
2024-04-28 21:57:49 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #215: GFLOPs: 274.4575. Time: 842.7035 us. Best GFLOPs: 400.1530
2024-04-28 21:57:49 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #216: GFLOPs: 91.6095. Time: 2524.6971 us. Best GFLOPs: 400.1530
2024-04-28 21:57:49 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #217: GFLOPs: 306.9214. Time: 753.5685 us. Best GFLOPs: 400.1530
2024-04-28 21:57:49 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #218: GFLOPs: 280.9211. Time: 823.3139 us. Best GFLOPs: 400.1530
2024-04-28 21:57:49 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #219: GFLOPs: 20.9881. Time: 11019.8819 us. Best GFLOPs: 400.1530
2024-04-28 21:57:49 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #220: GFLOPs: 292.0229. Time: 792.0141 us. Best GFLOPs: 400.1530
2024-04-28 21:57:49 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #221: GFLOPs: 274.4204. Time: 842.8173 us. Best GFLOPs: 400.1530
2024-04-28 21:57:49 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #222: GFLOPs: 232.7410. Time: 993.7497 us. Best GFLOPs: 400.1530
2024-04-28 21:57:49 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #223: GFLOPs: 106.5696. Time: 2170.2845 us. Best GFLOPs: 400.1530
2024-04-28 21:57:49 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #224: GFLOPs: 25.0673. Time: 9226.6157 us. Best GFLOPs: 400.1530
2024-04-28 21:57:49 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #225: GFLOPs: 153.1909. Time: 1509.7911 us. Best GFLOPs: 400.1530
2024-04-28 21:57:49 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #226: GFLOPs: 240.9775. Time: 959.7836 us. Best GFLOPs: 400.1530
2024-04-28 21:57:49 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #227: GFLOPs: 255.1936. Time: 906.3167 us. Best GFLOPs: 400.1530
2024-04-28 21:57:49 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #228: GFLOPs: 151.8379. Time: 1523.2451 us. Best GFLOPs: 400.1530
2024-04-28 21:57:49 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #229: GFLOPs: 243.5652. Time: 949.5866 us. Best GFLOPs: 400.1530
2024-04-28 21:57:49 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #230: GFLOPs: 209.0883. Time: 1106.1656 us. Best GFLOPs: 400.1530
2024-04-28 21:57:49 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #231: GFLOPs: 76.8931. Time: 3007.8922 us. Best GFLOPs: 400.1530
2024-04-28 21:57:49 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #232: GFLOPs: 229.8170. Time: 1006.3933 us. Best GFLOPs: 400.1530
2024-04-28 21:57:49 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #233: GFLOPs: 279.4635. Time: 827.6082 us. Best GFLOPs: 400.1530
2024-04-28 21:57:49 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #234: GFLOPs: 60.2073. Time: 3841.5002 us. Best GFLOPs: 400.1530
2024-04-28 21:57:49 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #235: GFLOPs: 199.9931. Time: 1156.4713 us. Best GFLOPs: 400.1530
2024-04-28 21:57:49 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #236: GFLOPs: 99.3232. Time: 2328.6223 us. Best GFLOPs: 400.1530
2024-04-28 21:57:49 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #237: GFLOPs: 245.6688. Time: 941.4555 us. Best GFLOPs: 400.1530
2024-04-28 21:57:49 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #238: GFLOPs: 411.3454. Time: 562.2678 us. Best GFLOPs: 411.3454
2024-04-28 21:57:49 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #239: GFLOPs: 163.2139. Time: 1417.0742 us. Best GFLOPs: 411.3454
2024-04-28 21:57:49 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #240: GFLOPs: 143.8571. Time: 1607.7505 us. Best GFLOPs: 411.3454
2024-04-28 21:57:49 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #241: GFLOPs: 246.0196. Time: 940.1133 us. Best GFLOPs: 411.3454
2024-04-28 21:57:49 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #242: GFLOPs: 163.5255. Time: 1414.3745 us. Best GFLOPs: 411.3454
2024-04-28 21:57:49 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #243: GFLOPs: 66.9285. Time: 3455.7210 us. Best GFLOPs: 411.3454
2024-04-28 21:57:49 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #244: GFLOPs: 177.9643. Time: 1299.6214 us. Best GFLOPs: 411.3454
2024-04-28 21:57:49 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #245: GFLOPs: 109.0890. Time: 2120.1608 us. Best GFLOPs: 411.3454
2024-04-28 21:57:49 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #246: GFLOPs: 130.9191. Time: 1766.6353 us. Best GFLOPs: 411.3454
2024-04-28 21:57:49 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #247: GFLOPs: 198.1447. Time: 1167.2592 us. Best GFLOPs: 411.3454
2024-04-28 21:57:49 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #248: GFLOPs: 21.3483. Time: 10833.9616 us. Best GFLOPs: 411.3454
2024-04-28 21:57:49 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #249: GFLOPs: 291.2219. Time: 794.1926 us. Best GFLOPs: 411.3454
2024-04-28 21:57:49 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #250: GFLOPs: 168.3911. Time: 1373.5062 us. Best GFLOPs: 411.3454
2024-04-28 21:57:49 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #251: GFLOPs: 131.7084. Time: 1756.0484 us. Best GFLOPs: 411.3454
2024-04-28 21:57:49 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #252: GFLOPs: 731.7877. Time: 316.0565 us. Best GFLOPs: 731.7877
2024-04-28 21:57:49 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #253: GFLOPs: 214.8087. Time: 1076.7084 us. Best GFLOPs: 731.7877
2024-04-28 21:57:49 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #254: GFLOPs: 6.4682. Time: 35757.3787 us. Best GFLOPs: 731.7877
2024-04-28 21:57:49 [INFO] [task_scheduler.cc:121] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #255: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(7), T.int64(7), T.int64(512)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(32)), "float32"), p3: T.Buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(9), T.int64(9), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)))
        for n_0_oc_chunk_0_fused_fused in T.parallel(T.int64(2), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(9), T.int64(9), T.int64(512)):
                with T.block("data_pad"):
                    v_i0, v_i1, v_i2, v_i3, v_i4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(8) and T.int64(1) <= v_i3 and v_i3 < T.int64(8), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oh_0, ow_0, oc_block_0 in T.grid(T.int64(7), T.int64(1), T.int64(2)):
                for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(8)):
                    for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(4), T.int64(1), T.int64(7), T.int64(2), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_fused_fused * T.int64(8) + oc_chunk_1 * T.int64(8) + oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(7), oh_0 + oh_1 + oh_2_init + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(7), ow_0 * T.int64(7) + ow_1 * T.int64(7) + ow_2_init + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(32), oc_block_0 * T.int64(16) + oc_block_1 * T.int64(2) + oc_block_2_init + oc_block_3_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                    for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(64), T.int64(3), T.int64(3), T.int64(1), T.int64(4), T.int64(1), T.int64(7), T.int64(2), T.int64(8), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_fused_fused * T.int64(8) + oc_chunk_1 * T.int64(8) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(7), oh_0 + oh_1 + oh_2 + oh_3)
                            v_ow = T.axis.spatial(T.int64(7), ow_0 * T.int64(7) + ow_1 * T.int64(7) + ow_2 + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(32), oc_block_0 * T.int64(16) + oc_block_1 * T.int64(2) + oc_block_2 + oc_block_3)
                            v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(8) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(8), T.int64(1), T.int64(7)):
                    for ax4_fused in T.vectorized(T.int64(16)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_fused_fused * T.int64(8) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(7), oh_0 + ax2)
                            v_ax3 = T.axis.spatial(T.int64(7), ax3)
                            v_ax4 = T.axis.spatial(T.int64(32), oc_block_0 * T.int64(16) + ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 1, 4, 2])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[7, 1, 1, 1])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 7, 1])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[2, 8, 2, 1])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[64, 8])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[3, 1])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=1)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78 = sch.get_loops(block=b69)
l79 = sch.fuse(l72, l73, preserve_unit_iters=True)
sch.parallel(loop=l79)
l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b70)
l105 = sch.fuse(l80, preserve_unit_iters=True)
sch.parallel(loop=l105)
sch.annotate(block_or_loop=l105, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l105, ann_key="pragma_unroll_explicit", ann_val=1)
l106, l107, l108, l109, l110, l111, l112, l113, l114 = sch.get_loops(block=b71)
l115 = sch.fuse(l114, preserve_unit_iters=True)
sch.vectorize(loop=l115)
b116 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141 = sch.get_loops(block=b116)
b142 = sch.decompose_reduction(block=b116, loop=l126)
2024-04-28 21:57:49 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #256: GFLOPs: 4.8098. Time: 48086.2900 us. Best GFLOPs: 731.7877
2024-04-28 22:09:23 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-28 22:09:25 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-28 22:09:29 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f1e458)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x386def8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x36b1d38)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3108268)]: 0 failure(s)
2024-04-28 22:09:29 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-28 22:09:40 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f1e458)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x386def8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x36b1d38)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3108268)]: 0 failure(s)
2024-04-28 22:09:53 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f1e458)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x386def8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x36b1d38)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3108268)]: 0 failure(s)
2024-04-28 22:10:05 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f1e458)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x386def8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x36b1d38)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3108268)]: 0 failure(s)
2024-04-28 22:10:17 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f1e458)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x386def8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x36b1d38)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3108268)]: 0 failure(s)
2024-04-28 22:10:24 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9999  0.9696  0.8754  0.8580  0.8521  0.8521  0.8410  0.8091  0.7972  0.7972  0.7854  0.7828  0.7764  0.7764  0.7555  0.7555
[17 : 32]:	0.7396  0.7283  0.7283  0.7227  0.7203  0.7106  0.6986  0.6963  0.6896  0.6849  0.6612  0.6612  0.6609  0.6598  0.6570  0.6570
[33 : 48]:	0.6530  0.6530  0.6357  0.6323  0.6323  0.6283  0.6283  0.6273  0.6273  0.6196  0.6196  0.6170  0.6135  0.6080  0.6080  0.6080
[49 : 64]:	0.5959  0.5922  0.5880  0.5847  0.5839  0.5824  0.5812  0.5744  0.5733  0.5684  0.5631  0.5610  0.5532  0.5506  0.5473  0.5459
2024-04-28 22:10:24 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-28 22:10:24 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-28 22:12:13 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #257: GFLOPs: 621.1375. Time: 372.3592 us. Best GFLOPs: 731.7877
2024-04-28 22:12:13 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #258: GFLOPs: 738.2534. Time: 313.2885 us. Best GFLOPs: 738.2534
2024-04-28 22:12:13 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #259: GFLOPs: 623.2934. Time: 371.0713 us. Best GFLOPs: 738.2534
2024-04-28 22:12:13 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #260: GFLOPs: 102.6842. Time: 2252.4043 us. Best GFLOPs: 738.2534
2024-04-28 22:12:13 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #261: GFLOPs: 581.7038. Time: 397.6015 us. Best GFLOPs: 738.2534
2024-04-28 22:12:13 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #262: GFLOPs: 691.9807. Time: 334.2380 us. Best GFLOPs: 738.2534
2024-04-28 22:12:13 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #263: GFLOPs: 685.1851. Time: 337.5530 us. Best GFLOPs: 738.2534
2024-04-28 22:12:13 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #264: GFLOPs: 350.1398. Time: 660.5541 us. Best GFLOPs: 738.2534
2024-04-28 22:12:13 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #265: GFLOPs: 475.1439. Time: 486.7710 us. Best GFLOPs: 738.2534
2024-04-28 22:12:13 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #266: GFLOPs: 367.2301. Time: 629.8130 us. Best GFLOPs: 738.2534
2024-04-28 22:12:13 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #267: GFLOPs: 441.4022. Time: 523.9808 us. Best GFLOPs: 738.2534
2024-04-28 22:12:13 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #268: GFLOPs: 487.5727. Time: 474.3626 us. Best GFLOPs: 738.2534
2024-04-28 22:12:13 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #269: GFLOPs: 750.8773. Time: 308.0214 us. Best GFLOPs: 750.8773
2024-04-28 22:12:13 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #270: GFLOPs: 693.2495. Time: 333.6263 us. Best GFLOPs: 750.8773
2024-04-28 22:12:13 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #271: GFLOPs: 103.5009. Time: 2234.6310 us. Best GFLOPs: 750.8773
2024-04-28 22:12:13 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #272: GFLOPs: 106.7151. Time: 2167.3255 us. Best GFLOPs: 750.8773
2024-04-28 22:12:13 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #273: GFLOPs: 459.7649. Time: 503.0533 us. Best GFLOPs: 750.8773
2024-04-28 22:12:13 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #274: GFLOPs: 459.7602. Time: 503.0584 us. Best GFLOPs: 750.8773
2024-04-28 22:12:13 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #275: GFLOPs: 372.6185. Time: 620.7052 us. Best GFLOPs: 750.8773
2024-04-28 22:12:13 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #276: GFLOPs: 382.6581. Time: 604.4201 us. Best GFLOPs: 750.8773
2024-04-28 22:12:13 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #277: GFLOPs: 643.3112. Time: 359.5247 us. Best GFLOPs: 750.8773
2024-04-28 22:12:13 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #278: GFLOPs: 428.3531. Time: 539.9430 us. Best GFLOPs: 750.8773
2024-04-28 22:12:13 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #279: GFLOPs: 428.4104. Time: 539.8709 us. Best GFLOPs: 750.8773
2024-04-28 22:12:13 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #280: GFLOPs: 261.0945. Time: 885.8336 us. Best GFLOPs: 750.8773
2024-04-28 22:12:13 [INFO] [task_scheduler.cc:121] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #281: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(7), T.int64(7), T.int64(512)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(32)), "float32"), p3: T.Buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(9), T.int64(9), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused in T.parallel(T.int64(112), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(3), T.int64(9), T.int64(512)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(9), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(16) + ax2)
                    v_i3, v_i4 = T.axis.remap("SS", [ax3, ax4])
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(8) and T.int64(1) <= v_i3 and v_i3 < T.int64(8), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(16) + oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(16) + oh_1 + oh_2_init + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(7), ow_1 * T.int64(7) + ow_2_init * T.int64(7) + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(256), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(32), T.int64(2), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(16) + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(16) + oh_1 + oh_2 + oh_3)
                        v_ow = T.axis.spatial(T.int64(7), ow_1 * T.int64(7) + ow_2 * T.int64(7) + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(2) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                    for ax4_fused in T.vectorized(T.int64(32)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(16) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(16) + ax2)
                            v_ax3, v_ax4 = T.axis.remap("SS", [ax3, ax4_fused])
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 16, 1, 1])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[7, 1, 1, 1])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 1, 7])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[1, 1, 32, 1])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[256, 2])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[3, 1])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l50, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=6)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83 = sch.get_loops(block=b69)
l84 = sch.fuse(l72, l73, l74, l75, l76, l77, l78, preserve_unit_iters=True)
sch.parallel(loop=l84)
l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b70)
l105 = sch.fuse(l85, preserve_unit_iters=True)
sch.parallel(loop=l105)
sch.annotate(block_or_loop=l105, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l105, ann_key="pragma_unroll_explicit", ann_val=1)
l106, l107, l108, l109, l110, l111, l112, l113, l114 = sch.get_loops(block=b71)
l115 = sch.fuse(l114, preserve_unit_iters=True)
sch.vectorize(loop=l115)
b116 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136 = sch.get_loops(block=b116)
b137 = sch.decompose_reduction(block=b116, loop=l121)
2024-04-28 22:12:13 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #282: GFLOPs: 398.2005. Time: 580.8287 us. Best GFLOPs: 750.8773
2024-04-28 22:12:13 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #283: GFLOPs: 468.5463. Time: 493.6252 us. Best GFLOPs: 750.8773
2024-04-28 22:12:13 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #284: GFLOPs: 542.1550. Time: 426.6054 us. Best GFLOPs: 750.8773
2024-04-28 22:12:13 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #285: GFLOPs: 435.0359. Time: 531.6487 us. Best GFLOPs: 750.8773
2024-04-28 22:12:13 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #286: GFLOPs: 119.2479. Time: 1939.5414 us. Best GFLOPs: 750.8773
2024-04-28 22:12:13 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #287: GFLOPs: 451.6866. Time: 512.0503 us. Best GFLOPs: 750.8773
2024-04-28 22:12:13 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #288: GFLOPs: 419.5674. Time: 551.2493 us. Best GFLOPs: 750.8773
2024-04-28 22:12:13 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #289: GFLOPs: 364.7894. Time: 634.0269 us. Best GFLOPs: 750.8773
2024-04-28 22:12:13 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #290: GFLOPs: 481.0216. Time: 480.8230 us. Best GFLOPs: 750.8773
2024-04-28 22:12:13 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #291: GFLOPs: 419.4316. Time: 551.4279 us. Best GFLOPs: 750.8773
2024-04-28 22:12:13 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #292: GFLOPs: 103.6433. Time: 2231.5606 us. Best GFLOPs: 750.8773
2024-04-28 22:12:13 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #293: GFLOPs: 105.5768. Time: 2190.6931 us. Best GFLOPs: 750.8773
2024-04-28 22:12:13 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #294: GFLOPs: 450.9477. Time: 512.8894 us. Best GFLOPs: 750.8773
2024-04-28 22:12:13 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #295: GFLOPs: 401.1652. Time: 576.5362 us. Best GFLOPs: 750.8773
2024-04-28 22:12:13 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #296: GFLOPs: 68.8367. Time: 3359.9267 us. Best GFLOPs: 750.8773
2024-04-28 22:12:13 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #297: GFLOPs: 53.0588. Time: 4359.0589 us. Best GFLOPs: 750.8773
2024-04-28 22:12:13 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #298: GFLOPs: 462.3318. Time: 500.2603 us. Best GFLOPs: 750.8773
2024-04-28 22:12:13 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #299: GFLOPs: 454.9627. Time: 508.3632 us. Best GFLOPs: 750.8773
2024-04-28 22:12:13 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #300: GFLOPs: 379.3189. Time: 609.7409 us. Best GFLOPs: 750.8773
2024-04-28 22:12:13 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #301: GFLOPs: 605.1028. Time: 382.2264 us. Best GFLOPs: 750.8773
2024-04-28 22:12:13 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #302: GFLOPs: 99.6325. Time: 2321.3946 us. Best GFLOPs: 750.8773
2024-04-28 22:12:13 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #303: GFLOPs: 98.3398. Time: 2351.9087 us. Best GFLOPs: 750.8773
2024-04-28 22:12:13 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #304: GFLOPs: 100.9021. Time: 2292.1859 us. Best GFLOPs: 750.8773
2024-04-28 22:12:13 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #305: GFLOPs: 623.0933. Time: 371.1904 us. Best GFLOPs: 750.8773
2024-04-28 22:12:13 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #306: GFLOPs: 105.4183. Time: 2193.9865 us. Best GFLOPs: 750.8773
2024-04-28 22:12:13 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #307: GFLOPs: 54.4240. Time: 4249.7103 us. Best GFLOPs: 750.8773
2024-04-28 22:12:13 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #308: GFLOPs: 96.9444. Time: 2385.7620 us. Best GFLOPs: 750.8773
2024-04-28 22:12:13 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #309: GFLOPs: 628.2763. Time: 368.1283 us. Best GFLOPs: 750.8773
2024-04-28 22:12:13 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #310: GFLOPs: 372.1509. Time: 621.4851 us. Best GFLOPs: 750.8773
2024-04-28 22:12:13 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #311: GFLOPs: 95.4260. Time: 2423.7230 us. Best GFLOPs: 750.8773
2024-04-28 22:12:13 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #312: GFLOPs: 98.9386. Time: 2337.6757 us. Best GFLOPs: 750.8773
2024-04-28 22:12:13 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #313: GFLOPs: 326.0877. Time: 709.2763 us. Best GFLOPs: 750.8773
2024-04-28 22:12:13 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #314: GFLOPs: 261.5435. Time: 884.3128 us. Best GFLOPs: 750.8773
2024-04-28 22:12:13 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #315: GFLOPs: 111.7207. Time: 2070.2180 us. Best GFLOPs: 750.8773
2024-04-28 22:12:13 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #316: GFLOPs: 379.9270. Time: 608.7650 us. Best GFLOPs: 750.8773
2024-04-28 22:12:13 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #317: GFLOPs: 105.5237. Time: 2191.7950 us. Best GFLOPs: 750.8773
2024-04-28 22:12:13 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #318: GFLOPs: 61.8439. Time: 3739.8420 us. Best GFLOPs: 750.8773
2024-04-28 22:12:13 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #319: GFLOPs: 1.2600. Time: 183567.6813 us. Best GFLOPs: 750.8773
2024-04-28 22:12:13 [INFO] [task_scheduler.cc:121] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #320: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(7), T.int64(7), T.int64(512)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(32)), "float32"), p3: T.Buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(9), T.int64(9), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused in T.parallel(T.int64(7), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(2)):
                for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(9), T.int64(3), T.int64(512)):
                    with T.block("data_pad"):
                        v_i0, v_i1, v_i2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                        v_i3 = T.axis.spatial(T.int64(9), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused + ax3)
                        v_i4 = T.axis.spatial(T.int64(512), ax4)
                        T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                        T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                        data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(8) and T.int64(1) <= v_i3 and v_i3 < T.int64(8), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(1), T.int64(2), T.int64(7), T.int64(1)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(16), oc_chunk_1 * T.int64(2) + oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(7), oh_1 * T.int64(7) + oh_2_init * T.int64(7) + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused + ow_1 + ow_2_init + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(16) + oc_block_2_init * T.int64(4) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(256), T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(7), T.int64(1)):
                    for oc_block_3_fused in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(16), oc_chunk_1 * T.int64(2) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(7), oh_1 * T.int64(7) + oh_2 * T.int64(7) + oh_3)
                            v_ow = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused + ow_1 + ow_2 + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(16) + oc_block_2 * T.int64(4) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(2) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
            for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(16), T.int64(7)):
                for ax3_ax4_fused in T.vectorized(T.int64(32)):
                    with T.block("T_relu"):
                        v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused, ax3_ax4_fused])
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 8, 1, 2])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 1, 7])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[7, 1, 1, 1])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[1, 2, 4, 4])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[256, 2])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[3, 1])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=9)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86 = sch.get_loops(block=b69)
l87 = sch.fuse(l72, l73, l74, l75, l76, preserve_unit_iters=True)
sch.parallel(loop=l87)
l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107, l108, l109 = sch.get_loops(block=b70)
l110 = sch.fuse(l88, preserve_unit_iters=True)
sch.parallel(loop=l110)
l111 = sch.fuse(l109, preserve_unit_iters=True)
sch.vectorize(loop=l111)
sch.annotate(block_or_loop=l110, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l110, ann_key="pragma_unroll_explicit", ann_val=1)
l112, l113, l114, l115, l116, l117 = sch.get_loops(block=b71)
l118 = sch.fuse(l116, l117, preserve_unit_iters=True)
sch.vectorize(loop=l118)
b119 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141 = sch.get_loops(block=b119)
b142 = sch.decompose_reduction(block=b119, loop=l126)
2024-04-28 22:34:41 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-28 22:34:42 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-28 22:34:46 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f1e458)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x386def8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x36b1d38)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3108268)]: 0 failure(s)
2024-04-28 22:34:46 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-28 22:34:57 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f1e458)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x386def8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x36b1d38)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3108268)]: 0 failure(s)
2024-04-28 22:35:09 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f1e458)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x386def8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x36b1d38)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3108268)]: 0 failure(s)
2024-04-28 22:35:21 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f1e458)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x386def8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x36b1d38)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3108268)]: 0 failure(s)
2024-04-28 22:35:32 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f1e458)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x386def8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x36b1d38)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3108268)]: 0 failure(s)
2024-04-28 22:35:40 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9051  0.9051  0.8765  0.8685  0.8685  0.8625  0.8625  0.8507  0.8281  0.8096  0.7925  0.7843  0.7815  0.7790  0.7790  0.7785
[17 : 32]:	0.7777  0.7640  0.7501  0.7419  0.7304  0.7258  0.7207  0.7206  0.7197  0.7167  0.7167  0.7074  0.7069  0.7018  0.6967  0.6966
[33 : 48]:	0.6960  0.6841  0.6841  0.6774  0.6728  0.6723  0.6723  0.6719  0.6710  0.6698  0.6698  0.6693  0.6646  0.6619  0.6611  0.6558
[49 : 64]:	0.6558  0.6557  0.6479  0.6479  0.6477  0.6436  0.6433  0.6390  0.6384  0.6384  0.6362  0.6342  0.6342  0.6335  0.6331  0.6329
2024-04-28 22:35:40 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-28 22:35:40 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-28 22:37:27 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #321: GFLOPs: 677.1611. Time: 341.5528 us. Best GFLOPs: 750.8773
2024-04-28 22:37:27 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #322: GFLOPs: 713.5633. Time: 324.1286 us. Best GFLOPs: 750.8773
2024-04-28 22:37:27 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #323: GFLOPs: 518.4374. Time: 446.1219 us. Best GFLOPs: 750.8773
2024-04-28 22:37:27 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #324: GFLOPs: 753.1008. Time: 307.1120 us. Best GFLOPs: 753.1008
2024-04-28 22:37:27 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #325: GFLOPs: 716.1226. Time: 322.9702 us. Best GFLOPs: 753.1008
2024-04-28 22:37:27 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #326: GFLOPs: 633.0994. Time: 365.3238 us. Best GFLOPs: 753.1008
2024-04-28 22:37:27 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #327: GFLOPs: 658.4199. Time: 351.2747 us. Best GFLOPs: 753.1008
2024-04-28 22:37:27 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #328: GFLOPs: 556.2580. Time: 415.7896 us. Best GFLOPs: 753.1008
2024-04-28 22:37:27 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #329: GFLOPs: 446.8189. Time: 517.6287 us. Best GFLOPs: 753.1008
2024-04-28 22:37:27 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #330: GFLOPs: 692.7813. Time: 333.8518 us. Best GFLOPs: 753.1008
2024-04-28 22:37:27 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #331: GFLOPs: 758.3961. Time: 304.9676 us. Best GFLOPs: 758.3961
2024-04-28 22:37:27 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #332: GFLOPs: 485.7989. Time: 476.0947 us. Best GFLOPs: 758.3961
2024-04-28 22:37:27 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #333: GFLOPs: 642.0667. Time: 360.2216 us. Best GFLOPs: 758.3961
2024-04-28 22:37:27 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #334: GFLOPs: 504.9761. Time: 458.0143 us. Best GFLOPs: 758.3961
2024-04-28 22:37:27 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #335: GFLOPs: 512.2285. Time: 451.5295 us. Best GFLOPs: 758.3961
2024-04-28 22:37:27 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #336: GFLOPs: 582.4523. Time: 397.0905 us. Best GFLOPs: 758.3961
2024-04-28 22:37:27 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #337: GFLOPs: 677.1502. Time: 341.5583 us. Best GFLOPs: 758.3961
2024-04-28 22:37:27 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #338: GFLOPs: 355.8157. Time: 650.0170 us. Best GFLOPs: 758.3961
2024-04-28 22:37:27 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #339: GFLOPs: 651.1603. Time: 355.1910 us. Best GFLOPs: 758.3961
2024-04-28 22:37:27 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #340: GFLOPs: 468.7647. Time: 493.3952 us. Best GFLOPs: 758.3961
2024-04-28 22:37:27 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #341: GFLOPs: 585.2058. Time: 395.2221 us. Best GFLOPs: 758.3961
2024-04-28 22:37:27 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #342: GFLOPs: 99.1459. Time: 2332.7864 us. Best GFLOPs: 758.3961
2024-04-28 22:37:27 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #343: GFLOPs: 411.1359. Time: 562.5543 us. Best GFLOPs: 758.3961
2024-04-28 22:37:27 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #344: GFLOPs: 410.8212. Time: 562.9852 us. Best GFLOPs: 758.3961
2024-04-28 22:37:27 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #345: GFLOPs: 418.2942. Time: 552.9273 us. Best GFLOPs: 758.3961
2024-04-28 22:37:27 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #346: GFLOPs: 401.7205. Time: 575.7393 us. Best GFLOPs: 758.3961
2024-04-28 22:37:27 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #347: GFLOPs: 370.2720. Time: 624.6389 us. Best GFLOPs: 758.3961
2024-04-28 22:37:27 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #348: GFLOPs: 520.6391. Time: 444.2353 us. Best GFLOPs: 758.3961
2024-04-28 22:37:27 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #349: GFLOPs: 589.7140. Time: 392.2007 us. Best GFLOPs: 758.3961
2024-04-28 22:37:27 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #350: GFLOPs: 488.6098. Time: 473.3558 us. Best GFLOPs: 758.3961
2024-04-28 22:37:27 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #351: GFLOPs: 477.1919. Time: 484.6819 us. Best GFLOPs: 758.3961
2024-04-28 22:37:27 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #352: GFLOPs: 508.6338. Time: 454.7206 us. Best GFLOPs: 758.3961
2024-04-28 22:37:27 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #353: GFLOPs: 373.0860. Time: 619.9274 us. Best GFLOPs: 758.3961
2024-04-28 22:37:27 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #354: GFLOPs: 610.6410. Time: 378.7598 us. Best GFLOPs: 758.3961
2024-04-28 22:37:27 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #355: GFLOPs: 732.8451. Time: 315.6005 us. Best GFLOPs: 758.3961
2024-04-28 22:37:27 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #356: GFLOPs: 468.5285. Time: 493.6439 us. Best GFLOPs: 758.3961
2024-04-28 22:37:27 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #357: GFLOPs: 716.1948. Time: 322.9377 us. Best GFLOPs: 758.3961
2024-04-28 22:37:27 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #358: GFLOPs: 354.6123. Time: 652.2230 us. Best GFLOPs: 758.3961
2024-04-28 22:37:27 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #359: GFLOPs: 329.7407. Time: 701.4185 us. Best GFLOPs: 758.3961
2024-04-28 22:37:27 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #360: GFLOPs: 725.1807. Time: 318.9360 us. Best GFLOPs: 758.3961
2024-04-28 22:37:27 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #361: GFLOPs: 491.1150. Time: 470.9412 us. Best GFLOPs: 758.3961
2024-04-28 22:37:27 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #362: GFLOPs: 457.8349. Time: 505.1740 us. Best GFLOPs: 758.3961
2024-04-28 22:37:27 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #363: GFLOPs: 394.5834. Time: 586.1530 us. Best GFLOPs: 758.3961
2024-04-28 22:37:27 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #364: GFLOPs: 533.0731. Time: 433.8735 us. Best GFLOPs: 758.3961
2024-04-28 22:37:27 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #365: GFLOPs: 468.7864. Time: 493.3724 us. Best GFLOPs: 758.3961
2024-04-28 22:37:27 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #366: GFLOPs: 551.6363. Time: 419.2731 us. Best GFLOPs: 758.3961
2024-04-28 22:37:27 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #367: GFLOPs: 157.2056. Time: 1471.2345 us. Best GFLOPs: 758.3961
2024-04-28 22:37:27 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #368: GFLOPs: 407.7723. Time: 567.1947 us. Best GFLOPs: 758.3961
2024-04-28 22:37:27 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #369: GFLOPs: 238.4285. Time: 970.0447 us. Best GFLOPs: 758.3961
2024-04-28 22:37:27 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #370: GFLOPs: 98.3000. Time: 2352.8602 us. Best GFLOPs: 758.3961
2024-04-28 22:37:27 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #371: GFLOPs: 563.7128. Time: 410.2909 us. Best GFLOPs: 758.3961
2024-04-28 22:37:27 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #372: GFLOPs: 483.0623. Time: 478.7918 us. Best GFLOPs: 758.3961
2024-04-28 22:37:27 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #373: GFLOPs: 451.9759. Time: 511.7225 us. Best GFLOPs: 758.3961
2024-04-28 22:37:27 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #374: GFLOPs: 117.1857. Time: 1973.6729 us. Best GFLOPs: 758.3961
2024-04-28 22:37:27 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #375: GFLOPs: 293.2848. Time: 788.6065 us. Best GFLOPs: 758.3961
2024-04-28 22:37:27 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #376: GFLOPs: 444.8637. Time: 519.9037 us. Best GFLOPs: 758.3961
2024-04-28 22:37:27 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #377: GFLOPs: 390.0075. Time: 593.0303 us. Best GFLOPs: 758.3961
2024-04-28 22:37:27 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #378: GFLOPs: 388.2475. Time: 595.7187 us. Best GFLOPs: 758.3961
2024-04-28 22:37:27 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #379: GFLOPs: 368.1185. Time: 628.2931 us. Best GFLOPs: 758.3961
2024-04-28 22:37:27 [INFO] [task_scheduler.cc:121] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #380: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(7), T.int64(7), T.int64(512)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(32)), "float32"), p3: T.Buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(9), T.int64(9), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused in T.parallel(T.int64(112), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(3), T.int64(9), T.int64(512)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(9), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(7) + ax2)
                    v_i3, v_i4 = T.axis.remap("SS", [ax3, ax4])
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(8) and T.int64(1) <= v_i3 and v_i3 < T.int64(8), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(7) + oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(7) + oh_2_init + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(7), ow_1 * T.int64(7) + ow_2_init * T.int64(7) + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(256), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(32), T.int64(2), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(7) + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(7) + oh_2 + oh_3)
                        v_ow = T.axis.spatial(T.int64(7), ow_1 * T.int64(7) + ow_2 * T.int64(7) + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(2) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                    for ax4_fused in T.vectorized(T.int64(32)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(7) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(7) + ax2)
                            v_ax3, v_ax4 = T.axis.remap("SS", [ax3, ax4_fused])
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[16, 1, 1, 1])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 7, 1, 1])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 1, 7])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[1, 1, 32, 1])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[256, 2])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[1, 3])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l50, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=7)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b69)
l85 = sch.fuse(l72, l73, l74, l75, l76, l77, l78, l79, preserve_unit_iters=True)
sch.parallel(loop=l85)
l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b70)
l105 = sch.fuse(l86, preserve_unit_iters=True)
sch.parallel(loop=l105)
sch.annotate(block_or_loop=l105, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l105, ann_key="pragma_unroll_explicit", ann_val=1)
l106, l107, l108, l109, l110, l111, l112, l113 = sch.get_loops(block=b71)
l114 = sch.fuse(l113, preserve_unit_iters=True)
sch.vectorize(loop=l114)
b115 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134 = sch.get_loops(block=b115)
b135 = sch.decompose_reduction(block=b115, loop=l119)
2024-04-28 22:37:27 [INFO] [task_scheduler.cc:121] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #381: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(7), T.int64(7), T.int64(512)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(32)), "float32"), p3: T.Buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(9), T.int64(9), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_fused_fused in T.parallel(T.int64(112), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(3), T.int64(9), T.int64(512)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(9), n_0_oc_chunk_0_oh_0_fused_fused % T.int64(7) + ax2)
                    v_i3, v_i4 = T.axis.remap("SS", [ax3, ax4])
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(8) and T.int64(1) <= v_i3 and v_i3 < T.int64(8), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for ow_0, oc_block_0, n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_fused_fused // T.int64(7) + oc_chunk_1 + oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_fused_fused % T.int64(7) + oh_1 + oh_2_init + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(7), ow_0 * T.int64(7) + ow_1 * T.int64(7) + ow_2_init * T.int64(7) + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_0 * T.int64(32) + oc_block_1 * T.int64(32) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(256), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(32), T.int64(2), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_fused_fused // T.int64(7) + oc_chunk_1 + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_fused_fused % T.int64(7) + oh_1 + oh_2 + oh_3)
                        v_ow = T.axis.spatial(T.int64(7), ow_0 * T.int64(7) + ow_1 * T.int64(7) + ow_2 * T.int64(7) + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_0 * T.int64(32) + oc_block_1 * T.int64(32) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(2) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                    for ax4_fused in T.vectorized(T.int64(32)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_fused_fused // T.int64(7) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_fused_fused % T.int64(7) + ax2)
                            v_ax3, v_ax4 = T.axis.remap("SS", [ax3, ax4_fused])
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[16, 1, 1, 1])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[7, 1, 1, 1])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 1, 7])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[1, 1, 32, 1])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[256, 2])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[1, 3])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l50, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=2)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79 = sch.get_loops(block=b69)
l80 = sch.fuse(l72, l73, l74, preserve_unit_iters=True)
sch.parallel(loop=l80)
l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b70)
l105 = sch.fuse(l81, preserve_unit_iters=True)
sch.parallel(loop=l105)
sch.annotate(block_or_loop=l105, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l105, ann_key="pragma_unroll_explicit", ann_val=1)
l106, l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117, l118 = sch.get_loops(block=b71)
l119 = sch.fuse(l118, preserve_unit_iters=True)
sch.vectorize(loop=l119)
b120 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141, l142, l143, l144 = sch.get_loops(block=b120)
b145 = sch.decompose_reduction(block=b120, loop=l129)
2024-04-28 22:37:27 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #382: GFLOPs: 59.7947. Time: 3868.0072 us. Best GFLOPs: 758.3961
2024-04-28 22:37:27 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #383: GFLOPs: 116.5641. Time: 1984.1984 us. Best GFLOPs: 758.3961
2024-04-28 22:37:27 [INFO] [task_scheduler.cc:121] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #384: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(7), T.int64(7), T.int64(512)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(32)), "float32"), p3: T.Buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(9), T.int64(9), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused in T.parallel(T.int64(2), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1, ow_1 in T.grid(T.int64(1), T.int64(8), T.int64(1), T.int64(7)):
                for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(9), T.int64(3), T.int64(512)):
                    with T.block("data_pad"):
                        v_i0, v_i1, v_i2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                        v_i3 = T.axis.spatial(T.int64(9), ow_1 + ax3)
                        v_i4 = T.axis.spatial(T.int64(512), ax4)
                        T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                        T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                        data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(8) and T.int64(1) <= v_i3 and v_i3 < T.int64(8), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                for oc_block_1 in range(T.int64(4)):
                    for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(2), T.int64(7), T.int64(1)):
                        for oc_block_3_fused_init in T.vectorized(T.int64(2)):
                            with T.block("conv2d_NCHWc_init"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                                v_oc_chunk = T.axis.spatial(T.int64(16), oc_chunk_1 * T.int64(2) + oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                                v_oh = T.axis.spatial(T.int64(7), oh_1 * T.int64(7) + oh_2_init * T.int64(7) + oh_3_init)
                                v_ow = T.axis.spatial(T.int64(7), ow_1 + ow_2_init + ow_3_init)
                                v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused * T.int64(16) + oc_block_1 * T.int64(4) + oc_block_2_init * T.int64(2) + oc_block_3_fused_init)
                                T.reads()
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                    for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(32), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(16), T.int64(1), T.int64(3), T.int64(1), T.int64(2), T.int64(7), T.int64(1)):
                        for oc_block_3_fused in T.vectorized(T.int64(2)):
                            with T.block("conv2d_NCHWc_update"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                                v_oc_chunk = T.axis.spatial(T.int64(16), oc_chunk_1 * T.int64(2) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                                v_oh = T.axis.spatial(T.int64(7), oh_1 * T.int64(7) + oh_2 * T.int64(7) + oh_3)
                                v_ow = T.axis.spatial(T.int64(7), ow_1 + ow_2 + ow_3)
                                v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused * T.int64(16) + oc_block_1 * T.int64(4) + oc_block_2 * T.int64(2) + oc_block_3_fused)
                                v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(16) + ic_1)
                                v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                                v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                                T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(16), T.int64(7), T.int64(7)):
                for ax4_fused in T.vectorized(T.int64(16)):
                    with T.block("T_relu"):
                        v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                        v_ax4 = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused * T.int64(16) + ax4_fused)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 8, 1, 2])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 1, 7])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 7, 1, 1])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[2, 4, 2, 2])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[32, 16])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[1, 3])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=8)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85 = sch.get_loops(block=b69)
l86 = sch.fuse(l72, l73, l74, l75, l76, preserve_unit_iters=True)
sch.parallel(loop=l86)
l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107, l108 = sch.get_loops(block=b70)
l109 = sch.fuse(l87, preserve_unit_iters=True)
sch.parallel(loop=l109)
l110 = sch.fuse(l108, preserve_unit_iters=True)
sch.vectorize(loop=l110)
sch.annotate(block_or_loop=l109, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l109, ann_key="pragma_unroll_explicit", ann_val=1)
l111, l112, l113, l114, l115, l116 = sch.get_loops(block=b71)
l117 = sch.fuse(l116, preserve_unit_iters=True)
sch.vectorize(loop=l117)
b118 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140 = sch.get_loops(block=b118)
b141 = sch.decompose_reduction(block=b118, loop=l125)
2024-04-28 22:50:10 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-28 22:50:11 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-28 22:50:15 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f1e458)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x386def8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x36b1d38)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3108268)]: 0 failure(s)
2024-04-28 22:50:15 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-28 22:50:26 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f1e458)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x386def8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x36b1d38)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3108268)]: 0 failure(s)
2024-04-28 22:50:38 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f1e458)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x386def8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x36b1d38)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3108268)]: 0 failure(s)
2024-04-28 22:50:49 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f1e458)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x386def8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x36b1d38)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3108268)]: 0 failure(s)
2024-04-28 22:51:01 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f1e458)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x386def8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x36b1d38)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3108268)]: 0 failure(s)
2024-04-28 22:51:08 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9808  0.9689  0.9689  0.9294  0.9244  0.9142  0.9142  0.8897  0.8882  0.8882  0.8645  0.8645  0.8589  0.8589  0.8522  0.8519
[17 : 32]:	0.8357  0.8132  0.8016  0.7974  0.7974  0.7974  0.7729  0.7695  0.7695  0.7684  0.7531  0.7527  0.7500  0.7500  0.7324  0.7324
[33 : 48]:	0.7304  0.7276  0.7257  0.7175  0.7175  0.7161  0.7134  0.7015  0.7001  0.6966  0.6953  0.6931  0.6929  0.6928  0.6925  0.6900
[49 : 64]:	0.6893  0.6893  0.6893  0.6768  0.6768  0.6691  0.6673  0.6654  0.6617  0.6602  0.6562  0.6546  0.6546  0.6480  0.6480  0.6480
2024-04-28 22:51:09 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-28 22:51:09 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-28 22:53:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #385: GFLOPs: 826.6082. Time: 279.8016 us. Best GFLOPs: 826.6082
2024-04-28 22:53:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #386: GFLOPs: 765.5617. Time: 302.1132 us. Best GFLOPs: 826.6082
2024-04-28 22:53:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #387: GFLOPs: 704.7504. Time: 328.1818 us. Best GFLOPs: 826.6082
2024-04-28 22:53:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #388: GFLOPs: 792.2963. Time: 291.9189 us. Best GFLOPs: 826.6082
2024-04-28 22:53:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #389: GFLOPs: 756.8736. Time: 305.5811 us. Best GFLOPs: 826.6082
2024-04-28 22:53:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #390: GFLOPs: 733.1972. Time: 315.4489 us. Best GFLOPs: 826.6082
2024-04-28 22:53:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #391: GFLOPs: 776.7107. Time: 297.7766 us. Best GFLOPs: 826.6082
2024-04-28 22:53:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #392: GFLOPs: 729.9730. Time: 316.8422 us. Best GFLOPs: 826.6082
2024-04-28 22:53:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #393: GFLOPs: 623.0942. Time: 371.1899 us. Best GFLOPs: 826.6082
2024-04-28 22:53:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #394: GFLOPs: 755.4662. Time: 306.1504 us. Best GFLOPs: 826.6082
2024-04-28 22:53:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #395: GFLOPs: 626.4570. Time: 369.1974 us. Best GFLOPs: 826.6082
2024-04-28 22:53:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #396: GFLOPs: 630.0320. Time: 367.1024 us. Best GFLOPs: 826.6082
2024-04-28 22:53:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #397: GFLOPs: 750.3057. Time: 308.2560 us. Best GFLOPs: 826.6082
2024-04-28 22:53:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #398: GFLOPs: 758.0180. Time: 305.1198 us. Best GFLOPs: 826.6082
2024-04-28 22:53:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #399: GFLOPs: 720.5644. Time: 320.9793 us. Best GFLOPs: 826.6082
2024-04-28 22:53:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #400: GFLOPs: 671.8644. Time: 344.2455 us. Best GFLOPs: 826.6082
2024-04-28 22:53:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #401: GFLOPs: 725.1163. Time: 318.9644 us. Best GFLOPs: 826.6082
2024-04-28 22:53:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #402: GFLOPs: 471.1008. Time: 490.9486 us. Best GFLOPs: 826.6082
2024-04-28 22:53:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #403: GFLOPs: 303.9612. Time: 760.9071 us. Best GFLOPs: 826.6082
2024-04-28 22:53:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #404: GFLOPs: 606.4110. Time: 381.4018 us. Best GFLOPs: 826.6082
2024-04-28 22:53:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #405: GFLOPs: 579.8054. Time: 398.9033 us. Best GFLOPs: 826.6082
2024-04-28 22:53:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #406: GFLOPs: 606.8565. Time: 381.1219 us. Best GFLOPs: 826.6082
2024-04-28 22:53:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #407: GFLOPs: 591.4930. Time: 391.0212 us. Best GFLOPs: 826.6082
2024-04-28 22:53:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #408: GFLOPs: 537.7240. Time: 430.1208 us. Best GFLOPs: 826.6082
2024-04-28 22:53:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #409: GFLOPs: 538.5017. Time: 429.4996 us. Best GFLOPs: 826.6082
2024-04-28 22:53:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #410: GFLOPs: 515.7014. Time: 448.4887 us. Best GFLOPs: 826.6082
2024-04-28 22:53:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #411: GFLOPs: 563.8010. Time: 410.2268 us. Best GFLOPs: 826.6082
2024-04-28 22:53:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #412: GFLOPs: 361.9773. Time: 638.9525 us. Best GFLOPs: 826.6082
2024-04-28 22:53:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #413: GFLOPs: 428.3161. Time: 539.9897 us. Best GFLOPs: 826.6082
2024-04-28 22:53:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #414: GFLOPs: 468.5026. Time: 493.6712 us. Best GFLOPs: 826.6082
2024-04-28 22:53:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #415: GFLOPs: 353.0296. Time: 655.1470 us. Best GFLOPs: 826.6082
2024-04-28 22:53:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #416: GFLOPs: 404.6952. Time: 571.5074 us. Best GFLOPs: 826.6082
2024-04-28 22:53:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #417: GFLOPs: 53.8311. Time: 4296.5187 us. Best GFLOPs: 826.6082
2024-04-28 22:53:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #418: GFLOPs: 265.2093. Time: 872.0897 us. Best GFLOPs: 826.6082
2024-04-28 22:53:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #419: GFLOPs: 377.3412. Time: 612.9367 us. Best GFLOPs: 826.6082
2024-04-28 22:53:00 [INFO] [task_scheduler.cc:121] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #420: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(7), T.int64(7), T.int64(512)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(32)), "float32"), p3: T.Buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(9), T.int64(9), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_fused_fused in T.parallel(T.int64(112), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(3), T.int64(9), T.int64(512)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(9), n_0_oc_chunk_0_oh_0_fused_fused % T.int64(7) + ax2)
                    v_i3, v_i4 = T.axis.remap("SS", [ax3, ax4])
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(8) and T.int64(1) <= v_i3 and v_i3 < T.int64(8), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for ow_0, oc_block_0, n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_fused_fused // T.int64(7) + oc_chunk_1 + oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_fused_fused % T.int64(7) + oh_1 + oh_2_init + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(7), ow_0 * T.int64(7) + ow_1 * T.int64(7) + ow_2_init * T.int64(7) + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_0 * T.int64(32) + oc_block_1 * T.int64(32) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(32), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(32), T.int64(16), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_fused_fused // T.int64(7) + oc_chunk_1 + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_fused_fused % T.int64(7) + oh_1 + oh_2 + oh_3)
                        v_ow = T.axis.spatial(T.int64(7), ow_0 * T.int64(7) + ow_1 * T.int64(7) + ow_2 * T.int64(7) + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_0 * T.int64(32) + oc_block_1 * T.int64(32) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(16) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                    for ax4_fused in T.vectorized(T.int64(32)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_fused_fused // T.int64(7) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_fused_fused % T.int64(7) + ax2)
                            v_ax3, v_ax4 = T.axis.remap("SS", [ax3, ax4_fused])
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[16, 1, 1, 1])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[7, 1, 1, 1])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 1, 7])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[1, 1, 32, 1])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[32, 16])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[1, 3])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l50, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=112)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=2)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79 = sch.get_loops(block=b69)
l80 = sch.fuse(l72, l73, l74, preserve_unit_iters=True)
sch.parallel(loop=l80)
l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b70)
l105 = sch.fuse(l81, preserve_unit_iters=True)
sch.parallel(loop=l105)
sch.annotate(block_or_loop=l105, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l105, ann_key="pragma_unroll_explicit", ann_val=1)
l106, l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117, l118 = sch.get_loops(block=b71)
l119 = sch.fuse(l118, preserve_unit_iters=True)
sch.vectorize(loop=l119)
b120 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141, l142, l143, l144 = sch.get_loops(block=b120)
b145 = sch.decompose_reduction(block=b120, loop=l129)
2024-04-28 22:53:00 [INFO] [task_scheduler.cc:121] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #421: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(7), T.int64(7), T.int64(512)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(32)), "float32"), p3: T.Buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(9), T.int64(9), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused in T.parallel(T.int64(112), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(3), T.int64(9), T.int64(512)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(9), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(7) + ax2)
                    v_i3, v_i4 = T.axis.remap("SS", [ax3, ax4])
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(8) and T.int64(1) <= v_i3 and v_i3 < T.int64(8), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(7) + oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(7) + oh_2_init + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(7), ow_1 * T.int64(7) + ow_2_init * T.int64(7) + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(32), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(32), T.int64(16), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(7) + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(7) + oh_2 + oh_3)
                        v_ow = T.axis.spatial(T.int64(7), ow_1 * T.int64(7) + ow_2 * T.int64(7) + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(16) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                    for ax4_fused in T.vectorized(T.int64(32)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(7) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(7) + ax2)
                            v_ax3, v_ax4 = T.axis.remap("SS", [ax3, ax4_fused])
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[16, 1, 1, 1])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 7, 1, 1])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 1, 7])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[1, 1, 32, 1])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[32, 16])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[1, 3])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l50, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=7)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b69)
l85 = sch.fuse(l72, l73, l74, l75, l76, l77, l78, l79, preserve_unit_iters=True)
sch.parallel(loop=l85)
l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b70)
l105 = sch.fuse(l86, preserve_unit_iters=True)
sch.parallel(loop=l105)
sch.annotate(block_or_loop=l105, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l105, ann_key="pragma_unroll_explicit", ann_val=1)
l106, l107, l108, l109, l110, l111, l112, l113 = sch.get_loops(block=b71)
l114 = sch.fuse(l113, preserve_unit_iters=True)
sch.vectorize(loop=l114)
b115 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134 = sch.get_loops(block=b115)
b135 = sch.decompose_reduction(block=b115, loop=l119)
2024-04-28 22:53:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #422: GFLOPs: 418.5739. Time: 552.5578 us. Best GFLOPs: 826.6082
2024-04-28 22:53:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #423: GFLOPs: 463.8242. Time: 498.6508 us. Best GFLOPs: 826.6082
2024-04-28 22:53:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #424: GFLOPs: 527.1639. Time: 438.7369 us. Best GFLOPs: 826.6082
2024-04-28 22:53:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #425: GFLOPs: 490.9610. Time: 471.0889 us. Best GFLOPs: 826.6082
2024-04-28 22:53:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #426: GFLOPs: 502.3311. Time: 460.4260 us. Best GFLOPs: 826.6082
2024-04-28 22:53:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #427: GFLOPs: 489.2251. Time: 472.7604 us. Best GFLOPs: 826.6082
2024-04-28 22:53:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #428: GFLOPs: 363.3818. Time: 636.4828 us. Best GFLOPs: 826.6082
2024-04-28 22:53:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #429: GFLOPs: 350.5038. Time: 659.8680 us. Best GFLOPs: 826.6082
2024-04-28 22:53:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #430: GFLOPs: 558.9089. Time: 413.8175 us. Best GFLOPs: 826.6082
2024-04-28 22:53:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #431: GFLOPs: 497.8779. Time: 464.5442 us. Best GFLOPs: 826.6082
2024-04-28 22:53:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #432: GFLOPs: 602.8694. Time: 383.6424 us. Best GFLOPs: 826.6082
2024-04-28 22:53:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #433: GFLOPs: 290.5264. Time: 796.0939 us. Best GFLOPs: 826.6082
2024-04-28 22:53:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #434: GFLOPs: 290.5492. Time: 796.0315 us. Best GFLOPs: 826.6082
2024-04-28 22:53:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #435: GFLOPs: 290.4355. Time: 796.3431 us. Best GFLOPs: 826.6082
2024-04-28 22:53:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #436: GFLOPs: 472.7210. Time: 489.2660 us. Best GFLOPs: 826.6082
2024-04-28 22:53:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #437: GFLOPs: 474.0175. Time: 487.9277 us. Best GFLOPs: 826.6082
2024-04-28 22:53:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #438: GFLOPs: 106.7133. Time: 2167.3611 us. Best GFLOPs: 826.6082
2024-04-28 22:53:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #439: GFLOPs: 524.3981. Time: 441.0510 us. Best GFLOPs: 826.6082
2024-04-28 22:53:00 [INFO] [task_scheduler.cc:121] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #440: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(7), T.int64(7), T.int64(512)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(32)), "float32"), p3: T.Buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(9), T.int64(9), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)))
        for n_0_oc_chunk_0_fused_fused in T.parallel(T.int64(16), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(9), T.int64(9), T.int64(512)):
                with T.block("data_pad"):
                    v_i0, v_i1, v_i2, v_i3, v_i4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(8) and T.int64(1) <= v_i3 and v_i3 < T.int64(8), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oh_0, ow_0, oc_block_0, n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_fused_fused + oc_chunk_1 + oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(7), oh_0 * T.int64(7) + oh_1 + oh_2_init + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(7), ow_0 * T.int64(7) + ow_1 * T.int64(7) + ow_2_init * T.int64(7) + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_0 * T.int64(32) + oc_block_1 * T.int64(32) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(32), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(32), T.int64(16), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_fused_fused + oc_chunk_1 + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(7), oh_0 * T.int64(7) + oh_1 + oh_2 + oh_3)
                        v_ow = T.axis.spatial(T.int64(7), ow_0 * T.int64(7) + ow_1 * T.int64(7) + ow_2 * T.int64(7) + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_0 * T.int64(32) + oc_block_1 * T.int64(32) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(16) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                    for ax4_fused in T.vectorized(T.int64(32)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_fused_fused + ax1)
                            v_ax2 = T.axis.spatial(T.int64(7), oh_1 + ax2)
                            v_ax3, v_ax4 = T.axis.remap("SS", [ax3, ax4_fused])
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[16, 1, 1, 1])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 7, 1, 1])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 1, 7])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[1, 1, 32, 1])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[32, 16])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[1, 3])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l50, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=112)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=1)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78 = sch.get_loops(block=b69)
l79 = sch.fuse(l72, l73, preserve_unit_iters=True)
sch.parallel(loop=l79)
l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b70)
l105 = sch.fuse(l80, preserve_unit_iters=True)
sch.parallel(loop=l105)
sch.annotate(block_or_loop=l105, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l105, ann_key="pragma_unroll_explicit", ann_val=1)
l106, l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117, l118, l119 = sch.get_loops(block=b71)
l120 = sch.fuse(l119, preserve_unit_iters=True)
sch.vectorize(loop=l120)
b121 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141, l142, l143, l144, l145, l146 = sch.get_loops(block=b121)
b147 = sch.decompose_reduction(block=b121, loop=l131)
2024-04-28 22:53:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #441: GFLOPs: 540.1650. Time: 428.1770 us. Best GFLOPs: 826.6082
2024-04-28 22:53:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #442: GFLOPs: 64.7240. Time: 3573.4240 us. Best GFLOPs: 826.6082
2024-04-28 22:53:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #443: GFLOPs: 531.8169. Time: 434.8983 us. Best GFLOPs: 826.6082
2024-04-28 22:53:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #444: GFLOPs: 487.4365. Time: 474.4952 us. Best GFLOPs: 826.6082
2024-04-28 22:53:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #445: GFLOPs: 508.8497. Time: 454.5277 us. Best GFLOPs: 826.6082
2024-04-28 22:53:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #446: GFLOPs: 14.1362. Time: 16361.3221 us. Best GFLOPs: 826.6082
2024-04-28 22:53:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #447: GFLOPs: 8.5317. Time: 27109.0472 us. Best GFLOPs: 826.6082
2024-04-28 22:53:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #448: GFLOPs: 8.4467. Time: 27381.8920 us. Best GFLOPs: 826.6082
2024-04-28 23:42:29 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-28 23:42:30 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-28 23:42:34 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f1e458)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x386def8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x36b1d38)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3108268)]: 0 failure(s)
2024-04-28 23:42:34 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-28 23:42:45 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f1e458)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x386def8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x36b1d38)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3108268)]: 0 failure(s)
2024-04-28 23:42:57 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f1e458)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x386def8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x36b1d38)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3108268)]: 0 failure(s)
2024-04-28 23:43:09 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f1e458)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x386def8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x36b1d38)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3108268)]: 0 failure(s)
2024-04-28 23:43:21 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f1e458)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x386def8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x36b1d38)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3108268)]: 0 failure(s)
2024-04-28 23:43:28 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9386  0.9386  0.8993  0.8970  0.8894  0.8872  0.8872  0.8490  0.8445  0.8351  0.8117  0.8018  0.8018  0.8018  0.7910  0.7910
[17 : 32]:	0.7890  0.7862  0.7759  0.7727  0.7727  0.7727  0.7689  0.7574  0.7521  0.7502  0.7502  0.7502  0.7395  0.7277  0.7256  0.7232
[33 : 48]:	0.7181  0.7181  0.7129  0.7129  0.7006  0.6803  0.6761  0.6739  0.6730  0.6719  0.6717  0.6717  0.6712  0.6705  0.6615  0.6591
[49 : 64]:	0.6565  0.6565  0.6519  0.6506  0.6461  0.6461  0.6436  0.6282  0.6282  0.6167  0.6160  0.6138  0.6132  0.6098  0.6090  0.6082
2024-04-28 23:43:29 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-28 23:43:29 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-28 23:45:17 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #449: GFLOPs: 379.8345. Time: 608.9132 us. Best GFLOPs: 826.6082
2024-04-28 23:45:17 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #450: GFLOPs: 769.5311. Time: 300.5548 us. Best GFLOPs: 826.6082
2024-04-28 23:45:17 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #451: GFLOPs: 734.4098. Time: 314.9281 us. Best GFLOPs: 826.6082
2024-04-28 23:45:17 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #452: GFLOPs: 770.3804. Time: 300.2235 us. Best GFLOPs: 826.6082
2024-04-28 23:45:17 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #453: GFLOPs: 790.5795. Time: 292.5528 us. Best GFLOPs: 826.6082
2024-04-28 23:45:17 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #454: GFLOPs: 759.1864. Time: 304.6502 us. Best GFLOPs: 826.6082
2024-04-28 23:45:17 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #455: GFLOPs: 747.9097. Time: 309.2436 us. Best GFLOPs: 826.6082
2024-04-28 23:45:17 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #456: GFLOPs: 681.8030. Time: 339.2274 us. Best GFLOPs: 826.6082
2024-04-28 23:45:17 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #457: GFLOPs: 636.8103. Time: 363.1949 us. Best GFLOPs: 826.6082
2024-04-28 23:45:17 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #458: GFLOPs: 627.8190. Time: 368.3964 us. Best GFLOPs: 826.6082
2024-04-28 23:45:17 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #459: GFLOPs: 590.7571. Time: 391.5082 us. Best GFLOPs: 826.6082
2024-04-28 23:45:17 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #460: GFLOPs: 632.6059. Time: 365.6088 us. Best GFLOPs: 826.6082
2024-04-28 23:45:17 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #461: GFLOPs: 628.2113. Time: 368.1664 us. Best GFLOPs: 826.6082
2024-04-28 23:45:17 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #462: GFLOPs: 616.9252. Time: 374.9017 us. Best GFLOPs: 826.6082
2024-04-28 23:45:17 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #463: GFLOPs: 619.2755. Time: 373.4788 us. Best GFLOPs: 826.6082
2024-04-28 23:45:17 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #464: GFLOPs: 601.0760. Time: 384.7871 us. Best GFLOPs: 826.6082
2024-04-28 23:45:17 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #465: GFLOPs: 616.5993. Time: 375.0998 us. Best GFLOPs: 826.6082
2024-04-28 23:45:17 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #466: GFLOPs: 739.3470. Time: 312.8250 us. Best GFLOPs: 826.6082
2024-04-28 23:45:17 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #467: GFLOPs: 612.1819. Time: 377.8065 us. Best GFLOPs: 826.6082
2024-04-28 23:45:17 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #468: GFLOPs: 712.6017. Time: 324.5660 us. Best GFLOPs: 826.6082
2024-04-28 23:45:17 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #469: GFLOPs: 604.2873. Time: 382.7423 us. Best GFLOPs: 826.6082
2024-04-28 23:45:17 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #470: GFLOPs: 604.2550. Time: 382.7627 us. Best GFLOPs: 826.6082
2024-04-28 23:45:17 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #471: GFLOPs: 565.6749. Time: 408.8678 us. Best GFLOPs: 826.6082
2024-04-28 23:45:17 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #472: GFLOPs: 624.5102. Time: 370.3482 us. Best GFLOPs: 826.6082
2024-04-28 23:45:17 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #473: GFLOPs: 547.2175. Time: 422.6588 us. Best GFLOPs: 826.6082
2024-04-28 23:45:17 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #474: GFLOPs: 622.7373. Time: 371.4027 us. Best GFLOPs: 826.6082
2024-04-28 23:45:17 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #475: GFLOPs: 638.8246. Time: 362.0497 us. Best GFLOPs: 826.6082
2024-04-28 23:45:17 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #476: GFLOPs: 521.1405. Time: 443.8079 us. Best GFLOPs: 826.6082
2024-04-28 23:45:17 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #477: GFLOPs: 367.0061. Time: 630.1974 us. Best GFLOPs: 826.6082
2024-04-28 23:45:17 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #478: GFLOPs: 593.2864. Time: 389.8391 us. Best GFLOPs: 826.6082
2024-04-28 23:45:17 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #479: GFLOPs: 592.0365. Time: 390.6622 us. Best GFLOPs: 826.6082
2024-04-28 23:45:17 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #480: GFLOPs: 600.2828. Time: 385.2955 us. Best GFLOPs: 826.6082
2024-04-28 23:45:17 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #481: GFLOPs: 626.1377. Time: 369.3856 us. Best GFLOPs: 826.6082
2024-04-28 23:45:17 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #482: GFLOPs: 627.8489. Time: 368.3788 us. Best GFLOPs: 826.6082
2024-04-28 23:45:17 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #483: GFLOPs: 615.7732. Time: 375.6030 us. Best GFLOPs: 826.6082
2024-04-28 23:45:17 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #484: GFLOPs: 578.8679. Time: 399.5493 us. Best GFLOPs: 826.6082
2024-04-28 23:45:17 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #485: GFLOPs: 720.2384. Time: 321.1246 us. Best GFLOPs: 826.6082
2024-04-28 23:45:17 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #486: GFLOPs: 589.9419. Time: 392.0492 us. Best GFLOPs: 826.6082
2024-04-28 23:45:17 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #487: GFLOPs: 660.9702. Time: 349.9194 us. Best GFLOPs: 826.6082
2024-04-28 23:45:17 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #488: GFLOPs: 549.4739. Time: 420.9231 us. Best GFLOPs: 826.6082
2024-04-28 23:45:17 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #489: GFLOPs: 528.4681. Time: 437.6542 us. Best GFLOPs: 826.6082
2024-04-28 23:45:17 [INFO] [task_scheduler.cc:121] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #490: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(7), T.int64(7), T.int64(512)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(32)), "float32"), p3: T.Buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(9), T.int64(9), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_fused_fused in T.parallel(T.int64(112), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(3), T.int64(9), T.int64(512)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(9), n_0_oc_chunk_0_oh_0_fused_fused % T.int64(7) + ax2)
                    v_i3, v_i4 = T.axis.remap("SS", [ax3, ax4])
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(8) and T.int64(1) <= v_i3 and v_i3 < T.int64(8), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for ow_0, oc_block_0, n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_fused_fused // T.int64(7) + oc_chunk_1 + oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_fused_fused % T.int64(7) + oh_1 + oh_2_init + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(7), ow_0 * T.int64(7) + ow_1 * T.int64(7) + ow_2_init * T.int64(7) + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_0 * T.int64(32) + oc_block_1 * T.int64(32) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(64), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(32), T.int64(8), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_fused_fused // T.int64(7) + oc_chunk_1 + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_fused_fused % T.int64(7) + oh_1 + oh_2 + oh_3)
                        v_ow = T.axis.spatial(T.int64(7), ow_0 * T.int64(7) + ow_1 * T.int64(7) + ow_2 * T.int64(7) + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_0 * T.int64(32) + oc_block_1 * T.int64(32) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(8) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                    for ax4_fused in T.vectorized(T.int64(32)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_fused_fused // T.int64(7) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_fused_fused % T.int64(7) + ax2)
                            v_ax3, v_ax4 = T.axis.remap("SS", [ax3, ax4_fused])
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[16, 1, 1, 1])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[7, 1, 1, 1])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 1, 7])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[1, 1, 32, 1])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[64, 8])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[1, 3])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l50, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=112)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=2)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79 = sch.get_loops(block=b69)
l80 = sch.fuse(l72, l73, l74, preserve_unit_iters=True)
sch.parallel(loop=l80)
l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b70)
l105 = sch.fuse(l81, preserve_unit_iters=True)
sch.parallel(loop=l105)
sch.annotate(block_or_loop=l105, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l105, ann_key="pragma_unroll_explicit", ann_val=1)
l106, l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117, l118 = sch.get_loops(block=b71)
l119 = sch.fuse(l118, preserve_unit_iters=True)
sch.vectorize(loop=l119)
b120 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141, l142, l143, l144 = sch.get_loops(block=b120)
b145 = sch.decompose_reduction(block=b120, loop=l129)
2024-04-28 23:45:17 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #491: GFLOPs: 582.6180. Time: 396.9776 us. Best GFLOPs: 826.6082
2024-04-28 23:45:17 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #492: GFLOPs: 566.2669. Time: 408.4404 us. Best GFLOPs: 826.6082
2024-04-28 23:45:17 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #493: GFLOPs: 565.8122. Time: 408.7686 us. Best GFLOPs: 826.6082
2024-04-28 23:45:17 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #494: GFLOPs: 490.8567. Time: 471.1890 us. Best GFLOPs: 826.6082
2024-04-28 23:45:17 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #495: GFLOPs: 700.6216. Time: 330.1158 us. Best GFLOPs: 826.6082
2024-04-28 23:45:17 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #496: GFLOPs: 544.4857. Time: 424.7794 us. Best GFLOPs: 826.6082
2024-04-28 23:45:17 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #497: GFLOPs: 664.7742. Time: 347.9171 us. Best GFLOPs: 826.6082
2024-04-28 23:45:17 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #498: GFLOPs: 621.6645. Time: 372.0436 us. Best GFLOPs: 826.6082
2024-04-28 23:45:17 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #499: GFLOPs: 566.8567. Time: 408.0154 us. Best GFLOPs: 826.6082
2024-04-28 23:45:17 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #500: GFLOPs: 53.1100. Time: 4354.8528 us. Best GFLOPs: 826.6082
2024-04-28 23:45:17 [INFO] [task_scheduler.cc:121] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #501: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(7), T.int64(7), T.int64(512)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(32)), "float32"), p3: T.Buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(9), T.int64(9), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused in T.parallel(T.int64(112), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(3), T.int64(9), T.int64(512)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(9), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(16) + ax2)
                    v_i3, v_i4 = T.axis.remap("SS", [ax3, ax4])
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(8) and T.int64(1) <= v_i3 and v_i3 < T.int64(8), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(16) + oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(16) + oh_1 + oh_2_init + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(7), ow_1 * T.int64(7) + ow_2_init * T.int64(7) + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(128), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(32), T.int64(4), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(16) + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(16) + oh_1 + oh_2 + oh_3)
                        v_ow = T.axis.spatial(T.int64(7), ow_1 * T.int64(7) + ow_2 * T.int64(7) + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(4) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                    for ax4_fused in T.vectorized(T.int64(32)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(16) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(16) + ax2)
                            v_ax3, v_ax4 = T.axis.remap("SS", [ax3, ax4_fused])
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 16, 1, 1])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[7, 1, 1, 1])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 1, 7])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[1, 1, 32, 1])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[128, 4])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[1, 3])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l50, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=112)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=6)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83 = sch.get_loops(block=b69)
l84 = sch.fuse(l72, l73, l74, l75, l76, l77, l78, preserve_unit_iters=True)
sch.parallel(loop=l84)
l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b70)
l105 = sch.fuse(l85, preserve_unit_iters=True)
sch.parallel(loop=l105)
sch.annotate(block_or_loop=l105, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l105, ann_key="pragma_unroll_explicit", ann_val=1)
l106, l107, l108, l109, l110, l111, l112, l113, l114 = sch.get_loops(block=b71)
l115 = sch.fuse(l114, preserve_unit_iters=True)
sch.vectorize(loop=l115)
b116 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136 = sch.get_loops(block=b116)
b137 = sch.decompose_reduction(block=b116, loop=l121)
2024-04-28 23:45:17 [INFO] [task_scheduler.cc:121] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #502: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(7), T.int64(7), T.int64(512)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(32)), "float32"), p3: T.Buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(9), T.int64(9), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused in T.parallel(T.int64(112), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(3), T.int64(9), T.int64(512)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(9), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(7) + ax2)
                    v_i3, v_i4 = T.axis.remap("SS", [ax3, ax4])
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(8) and T.int64(1) <= v_i3 and v_i3 < T.int64(8), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(7) + oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(7) + oh_2_init + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(7), ow_1 * T.int64(7) + ow_2_init * T.int64(7) + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(128), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(32), T.int64(4), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(7) + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(7) + oh_2 + oh_3)
                        v_ow = T.axis.spatial(T.int64(7), ow_1 * T.int64(7) + ow_2 * T.int64(7) + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(4) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                    for ax4_fused in T.vectorized(T.int64(32)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(7) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(7) + ax2)
                            v_ax3, v_ax4 = T.axis.remap("SS", [ax3, ax4_fused])
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[4, 4, 1, 1])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 7, 1, 1])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 1, 7])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[1, 1, 32, 1])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[128, 4])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[1, 3])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l50, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=7)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b69)
l85 = sch.fuse(l72, l73, l74, l75, l76, l77, l78, l79, preserve_unit_iters=True)
sch.parallel(loop=l85)
l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b70)
l105 = sch.fuse(l86, preserve_unit_iters=True)
sch.parallel(loop=l105)
sch.annotate(block_or_loop=l105, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l105, ann_key="pragma_unroll_explicit", ann_val=1)
l106, l107, l108, l109, l110, l111, l112, l113 = sch.get_loops(block=b71)
l114 = sch.fuse(l113, preserve_unit_iters=True)
sch.vectorize(loop=l114)
b115 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134 = sch.get_loops(block=b115)
b135 = sch.decompose_reduction(block=b115, loop=l119)
2024-04-28 23:45:17 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #503: GFLOPs: 467.2246. Time: 495.0216 us. Best GFLOPs: 826.6082
2024-04-28 23:45:17 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #504: GFLOPs: 579.6660. Time: 398.9992 us. Best GFLOPs: 826.6082
2024-04-28 23:45:17 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #505: GFLOPs: 579.3421. Time: 399.2223 us. Best GFLOPs: 826.6082
2024-04-28 23:45:17 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #506: GFLOPs: 489.5893. Time: 472.4088 us. Best GFLOPs: 826.6082
2024-04-28 23:45:17 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #507: GFLOPs: 710.1027. Time: 325.7082 us. Best GFLOPs: 826.6082
2024-04-28 23:45:17 [INFO] [task_scheduler.cc:121] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #508: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(7), T.int64(7), T.int64(512)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(32)), "float32"), p3: T.Buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(9), T.int64(9), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused in T.parallel(T.int64(112), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(3), T.int64(9), T.int64(512)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(9), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(14) // T.int64(2) + ax2)
                    v_i3, v_i4 = T.axis.remap("SS", [ax3, ax4])
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(8) and T.int64(1) <= v_i3 and v_i3 < T.int64(8), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(14) * T.int64(2) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(2) + oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(14) // T.int64(2) + oh_1 + oh_2_init + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(7), ow_1 * T.int64(7) + ow_2_init * T.int64(7) + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(32), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(32), T.int64(16), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(14) * T.int64(2) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(2) + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(14) // T.int64(2) + oh_1 + oh_2 + oh_3)
                        v_ow = T.axis.spatial(T.int64(7), ow_1 * T.int64(7) + ow_2 * T.int64(7) + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(16) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                    for ax4_fused in T.vectorized(T.int64(32)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(14) * T.int64(2) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(2) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(14) // T.int64(2) + ax2)
                            v_ax3, v_ax4 = T.axis.remap("SS", [ax3, ax4_fused])
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[8, 2, 1, 1])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[7, 1, 1, 1])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 1, 7])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[1, 1, 32, 1])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[32, 16])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[1, 3])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l50, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=6)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83 = sch.get_loops(block=b69)
l84 = sch.fuse(l72, l73, l74, l75, l76, l77, l78, preserve_unit_iters=True)
sch.parallel(loop=l84)
l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b70)
l105 = sch.fuse(l85, preserve_unit_iters=True)
sch.parallel(loop=l105)
sch.annotate(block_or_loop=l105, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l105, ann_key="pragma_unroll_explicit", ann_val=1)
l106, l107, l108, l109, l110, l111, l112, l113, l114 = sch.get_loops(block=b71)
l115 = sch.fuse(l114, preserve_unit_iters=True)
sch.vectorize(loop=l115)
b116 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136 = sch.get_loops(block=b116)
b137 = sch.decompose_reduction(block=b116, loop=l121)
2024-04-28 23:45:17 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #509: GFLOPs: 446.0399. Time: 518.5327 us. Best GFLOPs: 826.6082
2024-04-28 23:45:17 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #510: GFLOPs: 86.2324. Time: 2682.1259 us. Best GFLOPs: 826.6082
2024-04-28 23:45:17 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #511: GFLOPs: 19.7025. Time: 11738.9433 us. Best GFLOPs: 826.6082
2024-04-28 23:45:17 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #512: GFLOPs: 2.9661. Time: 77976.1410 us. Best GFLOPs: 826.6082
2024-04-29 00:07:46 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 00:07:47 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-29 00:07:52 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f1e458)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x386def8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x36b1d38)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3108268)]: 0 failure(s)
2024-04-29 00:07:52 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-29 00:08:03 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f1e458)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x386def8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x36b1d38)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3108268)]: 0 failure(s)
2024-04-29 00:08:14 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f1e458)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x386def8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x36b1d38)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3108268)]: 0 failure(s)
2024-04-29 00:08:26 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f1e458)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x386def8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x36b1d38)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3108268)]: 0 failure(s)
2024-04-29 00:08:38 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f1e458)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x386def8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x36b1d38)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3108268)]: 0 failure(s)
2024-04-29 00:08:45 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.8877  0.8830  0.8744  0.8579  0.8417  0.8285  0.8049  0.8036  0.7992  0.7929  0.7929  0.7929  0.7653  0.7604  0.7589  0.7589
[17 : 32]:	0.7424  0.7343  0.7312  0.7299  0.7299  0.7278  0.7259  0.7188  0.7181  0.7181  0.7143  0.7084  0.7049  0.7025  0.7025  0.7001
[33 : 48]:	0.6995  0.6995  0.6995  0.6978  0.6909  0.6891  0.6881  0.6881  0.6878  0.6859  0.6858  0.6842  0.6784  0.6674  0.6536  0.6536
[49 : 64]:	0.6470  0.6450  0.6450  0.6397  0.6397  0.6384  0.6304  0.6301  0.6301  0.6296  0.6243  0.6218  0.6214  0.6194  0.6146  0.6140
2024-04-29 00:08:45 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 00:08:45 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 00:10:47 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #513: GFLOPs: 703.4401. Time: 328.7931 us. Best GFLOPs: 826.6082
2024-04-29 00:10:47 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #514: GFLOPs: 743.6873. Time: 310.9994 us. Best GFLOPs: 826.6082
2024-04-29 00:10:47 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #515: GFLOPs: 694.6849. Time: 332.9369 us. Best GFLOPs: 826.6082
2024-04-29 00:10:47 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #516: GFLOPs: 723.6112. Time: 319.6278 us. Best GFLOPs: 826.6082
2024-04-29 00:10:47 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #517: GFLOPs: 621.5974. Time: 372.0837 us. Best GFLOPs: 826.6082
2024-04-29 00:10:47 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #518: GFLOPs: 635.3346. Time: 364.0385 us. Best GFLOPs: 826.6082
2024-04-29 00:10:47 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #519: GFLOPs: 642.5246. Time: 359.9648 us. Best GFLOPs: 826.6082
2024-04-29 00:10:47 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #520: GFLOPs: 671.7439. Time: 344.3072 us. Best GFLOPs: 826.6082
2024-04-29 00:10:47 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #521: GFLOPs: 611.5137. Time: 378.2193 us. Best GFLOPs: 826.6082
2024-04-29 00:10:47 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #522: GFLOPs: 630.1190. Time: 367.0518 us. Best GFLOPs: 826.6082
2024-04-29 00:10:47 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #523: GFLOPs: 633.5224. Time: 365.0799 us. Best GFLOPs: 826.6082
2024-04-29 00:10:47 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #524: GFLOPs: 604.2231. Time: 382.7829 us. Best GFLOPs: 826.6082
2024-04-29 00:10:47 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #525: GFLOPs: 687.5697. Time: 336.3823 us. Best GFLOPs: 826.6082
2024-04-29 00:10:47 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #526: GFLOPs: 589.2872. Time: 392.4848 us. Best GFLOPs: 826.6082
2024-04-29 00:10:47 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #527: GFLOPs: 654.6890. Time: 353.2765 us. Best GFLOPs: 826.6082
2024-04-29 00:10:47 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #528: GFLOPs: 629.8061. Time: 367.2341 us. Best GFLOPs: 826.6082
2024-04-29 00:10:47 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #529: GFLOPs: 536.9860. Time: 430.7119 us. Best GFLOPs: 826.6082
2024-04-29 00:10:47 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #530: GFLOPs: 629.6428. Time: 367.3294 us. Best GFLOPs: 826.6082
2024-04-29 00:10:47 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #531: GFLOPs: 601.6895. Time: 384.3948 us. Best GFLOPs: 826.6082
2024-04-29 00:10:47 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #532: GFLOPs: 601.3853. Time: 384.5891 us. Best GFLOPs: 826.6082
2024-04-29 00:10:47 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #533: GFLOPs: 575.5192. Time: 401.8741 us. Best GFLOPs: 826.6082
2024-04-29 00:10:47 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #534: GFLOPs: 566.0379. Time: 408.6056 us. Best GFLOPs: 826.6082
2024-04-29 00:10:47 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #535: GFLOPs: 605.6206. Time: 381.8996 us. Best GFLOPs: 826.6082
2024-04-29 00:10:47 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #536: GFLOPs: 548.3796. Time: 421.7631 us. Best GFLOPs: 826.6082
2024-04-29 00:10:47 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #537: GFLOPs: 595.3748. Time: 388.4717 us. Best GFLOPs: 826.6082
2024-04-29 00:10:47 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #538: GFLOPs: 593.5663. Time: 389.6553 us. Best GFLOPs: 826.6082
2024-04-29 00:10:47 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #539: GFLOPs: 555.5567. Time: 416.3144 us. Best GFLOPs: 826.6082
2024-04-29 00:10:47 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #540: GFLOPs: 48.3988. Time: 4778.7632 us. Best GFLOPs: 826.6082
2024-04-29 00:10:47 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #541: GFLOPs: 539.3094. Time: 428.8563 us. Best GFLOPs: 826.6082
2024-04-29 00:10:47 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #542: GFLOPs: 553.6860. Time: 417.7210 us. Best GFLOPs: 826.6082
2024-04-29 00:10:47 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #543: GFLOPs: 568.4712. Time: 406.8566 us. Best GFLOPs: 826.6082
2024-04-29 00:10:47 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #544: GFLOPs: 567.7163. Time: 407.3976 us. Best GFLOPs: 826.6082
2024-04-29 00:10:47 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #545: GFLOPs: 553.4415. Time: 417.9055 us. Best GFLOPs: 826.6082
2024-04-29 00:10:47 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #546: GFLOPs: 536.6248. Time: 431.0019 us. Best GFLOPs: 826.6082
2024-04-29 00:10:47 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #547: GFLOPs: 541.8715. Time: 426.8286 us. Best GFLOPs: 826.6082
2024-04-29 00:10:47 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #548: GFLOPs: 534.5219. Time: 432.6975 us. Best GFLOPs: 826.6082
2024-04-29 00:10:47 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #549: GFLOPs: 746.9403. Time: 309.6449 us. Best GFLOPs: 826.6082
2024-04-29 00:10:47 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #550: GFLOPs: 223.9826. Time: 1032.6081 us. Best GFLOPs: 826.6082
2024-04-29 00:10:47 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #551: GFLOPs: 236.5041. Time: 977.9378 us. Best GFLOPs: 826.6082
2024-04-29 00:10:47 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #552: GFLOPs: 291.0653. Time: 794.6200 us. Best GFLOPs: 826.6082
2024-04-29 00:10:47 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #553: GFLOPs: 296.7302. Time: 779.4498 us. Best GFLOPs: 826.6082
2024-04-29 00:10:47 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #554: GFLOPs: 310.3730. Time: 745.1881 us. Best GFLOPs: 826.6082
2024-04-29 00:10:47 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #555: GFLOPs: 291.5653. Time: 793.2571 us. Best GFLOPs: 826.6082
2024-04-29 00:10:47 [INFO] [task_scheduler.cc:121] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #556: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(7), T.int64(7), T.int64(512)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(32)), "float32"), p3: T.Buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(9), T.int64(9), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused in T.parallel(T.int64(112), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(3), T.int64(9), T.int64(512)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(9), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(16) + ax2)
                    v_i3, v_i4 = T.axis.remap("SS", [ax3, ax4])
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(8) and T.int64(1) <= v_i3 and v_i3 < T.int64(8), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(16) + oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(16) + oh_1 + oh_2_init + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(7), ow_1 * T.int64(7) + ow_2_init * T.int64(7) + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(32), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(32), T.int64(16), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(16) + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(16) + oh_1 + oh_2 + oh_3)
                        v_ow = T.axis.spatial(T.int64(7), ow_1 * T.int64(7) + ow_2 * T.int64(7) + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(16) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                    for ax4_fused in T.vectorized(T.int64(32)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(16) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(16) + ax2)
                            v_ax3, v_ax4 = T.axis.remap("SS", [ax3, ax4_fused])
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 16, 1, 1])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[7, 1, 1, 1])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 1, 7])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[1, 1, 32, 1])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[32, 16])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[1, 3])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l50, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=6)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83 = sch.get_loops(block=b69)
l84 = sch.fuse(l72, l73, l74, l75, l76, l77, l78, preserve_unit_iters=True)
sch.parallel(loop=l84)
l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b70)
l105 = sch.fuse(l85, preserve_unit_iters=True)
sch.parallel(loop=l105)
sch.annotate(block_or_loop=l105, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l105, ann_key="pragma_unroll_explicit", ann_val=1)
l106, l107, l108, l109, l110, l111, l112, l113, l114 = sch.get_loops(block=b71)
l115 = sch.fuse(l114, preserve_unit_iters=True)
sch.vectorize(loop=l115)
b116 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136 = sch.get_loops(block=b116)
b137 = sch.decompose_reduction(block=b116, loop=l121)
2024-04-29 00:10:47 [INFO] [task_scheduler.cc:121] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #557: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(7), T.int64(7), T.int64(512)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(32)), "float32"), p3: T.Buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(9), T.int64(9), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused in T.parallel(T.int64(112), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(9), T.int64(3), T.int64(512)):
                with T.block("data_pad"):
                    v_i0, v_i1, v_i2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                    v_i3 = T.axis.spatial(T.int64(9), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(7) + ax3)
                    v_i4 = T.axis.spatial(T.int64(512), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(8) and T.int64(1) <= v_i3 and v_i3 < T.int64(8), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oc_block_1 in range(T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(7) + oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(7), oh_2_init * T.int64(7) + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(7) + ow_2_init + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(256), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(32), T.int64(2), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(7) + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(7), oh_2 * T.int64(7) + oh_3)
                        v_ow = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(7) + ow_2 + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(2) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
                for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(1), T.int64(7)):
                    for ax3_ax4_fused in T.vectorized(T.int64(32)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(7) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(7), ax2)
                            v_ax3 = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(7))
                            v_ax4 = T.axis.spatial(T.int64(32), ax3_ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 16, 1, 1])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 1, 7])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 7, 1, 1])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[1, 1, 32, 1])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[256, 2])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[3, 1])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l50, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=112)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=8)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85 = sch.get_loops(block=b69)
l86 = sch.fuse(l72, l73, l74, l75, l76, l77, l78, l79, l80, preserve_unit_iters=True)
sch.parallel(loop=l86)
l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b70)
l105 = sch.fuse(l87, preserve_unit_iters=True)
sch.parallel(loop=l105)
sch.annotate(block_or_loop=l105, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l105, ann_key="pragma_unroll_explicit", ann_val=1)
l106, l107, l108, l109, l110, l111, l112 = sch.get_loops(block=b71)
l113 = sch.fuse(l111, l112, preserve_unit_iters=True)
sch.vectorize(loop=l113)
b114 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132 = sch.get_loops(block=b114)
b133 = sch.decompose_reduction(block=b114, loop=l117)
2024-04-29 00:10:47 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #558: GFLOPs: 415.2094. Time: 557.0353 us. Best GFLOPs: 826.6082
2024-04-29 00:10:47 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #559: GFLOPs: 25.5766. Time: 9042.8996 us. Best GFLOPs: 826.6082
2024-04-29 00:10:47 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #560: GFLOPs: 25.6178. Time: 9028.3310 us. Best GFLOPs: 826.6082
2024-04-29 00:10:47 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #561: GFLOPs: 573.0626. Time: 403.5969 us. Best GFLOPs: 826.6082
2024-04-29 00:10:47 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #562: GFLOPs: 26.6076. Time: 8692.5001 us. Best GFLOPs: 826.6082
2024-04-29 00:10:47 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #563: GFLOPs: 27.2915. Time: 8474.6663 us. Best GFLOPs: 826.6082
2024-04-29 00:10:47 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #564: GFLOPs: 371.4231. Time: 622.7030 us. Best GFLOPs: 826.6082
2024-04-29 00:10:47 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #565: GFLOPs: 350.6646. Time: 659.5655 us. Best GFLOPs: 826.6082
2024-04-29 00:10:47 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #566: GFLOPs: 469.3954. Time: 492.7323 us. Best GFLOPs: 826.6082
2024-04-29 00:10:47 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #567: GFLOPs: 475.4753. Time: 486.4317 us. Best GFLOPs: 826.6082
2024-04-29 00:10:47 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #568: GFLOPs: 484.3272. Time: 477.5414 us. Best GFLOPs: 826.6082
2024-04-29 00:10:47 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #569: GFLOPs: 542.8713. Time: 426.0425 us. Best GFLOPs: 826.6082
2024-04-29 00:10:47 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #570: GFLOPs: 346.8403. Time: 666.8379 us. Best GFLOPs: 826.6082
2024-04-29 00:10:47 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #571: GFLOPs: 785.0553. Time: 294.6114 us. Best GFLOPs: 826.6082
2024-04-29 00:10:47 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #572: GFLOPs: 500.0169. Time: 462.5569 us. Best GFLOPs: 826.6082
2024-04-29 00:10:47 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #573: GFLOPs: 353.0692. Time: 655.0735 us. Best GFLOPs: 826.6082
2024-04-29 00:10:47 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #574: GFLOPs: 63.0467. Time: 3668.4887 us. Best GFLOPs: 826.6082
2024-04-29 00:10:47 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #575: GFLOPs: 1.6759. Time: 138005.3830 us. Best GFLOPs: 826.6082
2024-04-29 00:10:47 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #576: GFLOPs: 10.6108. Time: 21797.2984 us. Best GFLOPs: 826.6082
2024-04-29 00:23:31 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 00:23:32 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-29 00:23:36 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f1e458)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x386def8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x36b1d38)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3108268)]: 0 failure(s)
2024-04-29 00:23:36 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-29 00:23:47 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f1e458)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x386def8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x36b1d38)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3108268)]: 0 failure(s)
2024-04-29 00:23:59 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f1e458)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x386def8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x36b1d38)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3108268)]: 0 failure(s)
2024-04-29 00:24:11 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f1e458)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x386def8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x36b1d38)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3108268)]: 0 failure(s)
2024-04-29 00:24:23 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f1e458)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x386def8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x36b1d38)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3108268)]: 0 failure(s)
2024-04-29 00:24:30 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9091  0.9091  0.9034  0.9034  0.8603  0.8562  0.8298  0.8287  0.8287  0.7960  0.7801  0.7800  0.7796  0.7796  0.7648  0.7630
[17 : 32]:	0.7630  0.7630  0.7625  0.7625  0.7557  0.7543  0.7362  0.7321  0.7287  0.7171  0.7023  0.7023  0.6982  0.6825  0.6568  0.6541
[33 : 48]:	0.6510  0.6483  0.6458  0.6387  0.6271  0.6203  0.6164  0.6112  0.6112  0.6106  0.6105  0.6105  0.6086  0.6086  0.6015  0.6006
[49 : 64]:	0.5997  0.5928  0.5901  0.5900  0.5900  0.5900  0.5897  0.5886  0.5871  0.5863  0.5863  0.5840  0.5840  0.5818  0.5800  0.5746
2024-04-29 00:24:31 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 00:24:31 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 00:26:27 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #577: GFLOPs: 738.7730. Time: 313.0681 us. Best GFLOPs: 826.6082
2024-04-29 00:26:27 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #578: GFLOPs: 754.4398. Time: 306.5669 us. Best GFLOPs: 826.6082
2024-04-29 00:26:27 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #579: GFLOPs: 747.2957. Time: 309.4976 us. Best GFLOPs: 826.6082
2024-04-29 00:26:27 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #580: GFLOPs: 743.0028. Time: 311.2859 us. Best GFLOPs: 826.6082
2024-04-29 00:26:27 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #581: GFLOPs: 687.5795. Time: 336.3775 us. Best GFLOPs: 826.6082
2024-04-29 00:26:27 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #582: GFLOPs: 705.4160. Time: 327.8722 us. Best GFLOPs: 826.6082
2024-04-29 00:26:27 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #583: GFLOPs: 668.4218. Time: 346.0184 us. Best GFLOPs: 826.6082
2024-04-29 00:26:27 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #584: GFLOPs: 620.2138. Time: 372.9138 us. Best GFLOPs: 826.6082
2024-04-29 00:26:27 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #585: GFLOPs: 737.3979. Time: 313.6519 us. Best GFLOPs: 826.6082
2024-04-29 00:26:27 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #586: GFLOPs: 622.3433. Time: 371.6378 us. Best GFLOPs: 826.6082
2024-04-29 00:26:27 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #587: GFLOPs: 622.2531. Time: 371.6916 us. Best GFLOPs: 826.6082
2024-04-29 00:26:27 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #588: GFLOPs: 727.7991. Time: 317.7886 us. Best GFLOPs: 826.6082
2024-04-29 00:26:27 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #589: GFLOPs: 807.3739. Time: 286.4674 us. Best GFLOPs: 826.6082
2024-04-29 00:26:27 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #590: GFLOPs: 774.4077. Time: 298.6622 us. Best GFLOPs: 826.6082
2024-04-29 00:26:27 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #591: GFLOPs: 627.8095. Time: 368.4020 us. Best GFLOPs: 826.6082
2024-04-29 00:26:27 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #592: GFLOPs: 316.9587. Time: 729.7047 us. Best GFLOPs: 826.6082
2024-04-29 00:26:27 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #593: GFLOPs: 340.4950. Time: 679.2648 us. Best GFLOPs: 826.6082
2024-04-29 00:26:27 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #594: GFLOPs: 640.5953. Time: 361.0490 us. Best GFLOPs: 826.6082
2024-04-29 00:26:27 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #595: GFLOPs: 648.3077. Time: 356.7538 us. Best GFLOPs: 826.6082
2024-04-29 00:26:27 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #596: GFLOPs: 617.8642. Time: 374.3319 us. Best GFLOPs: 826.6082
2024-04-29 00:26:27 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #597: GFLOPs: 620.3543. Time: 372.8293 us. Best GFLOPs: 826.6082
2024-04-29 00:26:27 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #598: GFLOPs: 593.5226. Time: 389.6840 us. Best GFLOPs: 826.6082
2024-04-29 00:26:27 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #599: GFLOPs: 561.2991. Time: 412.0553 us. Best GFLOPs: 826.6082
2024-04-29 00:26:27 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #600: GFLOPs: 563.7398. Time: 410.2713 us. Best GFLOPs: 826.6082
2024-04-29 00:26:27 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #601: GFLOPs: 473.8106. Time: 488.1408 us. Best GFLOPs: 826.6082
2024-04-29 00:26:27 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #602: GFLOPs: 537.3076. Time: 430.4541 us. Best GFLOPs: 826.6082
2024-04-29 00:26:27 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #603: GFLOPs: 582.1485. Time: 397.2977 us. Best GFLOPs: 826.6082
2024-04-29 00:26:27 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #604: GFLOPs: 609.4720. Time: 379.4863 us. Best GFLOPs: 826.6082
2024-04-29 00:26:27 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #605: GFLOPs: 578.2641. Time: 399.9665 us. Best GFLOPs: 826.6082
2024-04-29 00:26:27 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #606: GFLOPs: 676.8440. Time: 341.7128 us. Best GFLOPs: 826.6082
2024-04-29 00:26:27 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #607: GFLOPs: 582.2352. Time: 397.2386 us. Best GFLOPs: 826.6082
2024-04-29 00:26:27 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #608: GFLOPs: 555.9847. Time: 415.9940 us. Best GFLOPs: 826.6082
2024-04-29 00:26:27 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #609: GFLOPs: 615.7522. Time: 375.6159 us. Best GFLOPs: 826.6082
2024-04-29 00:26:27 [INFO] [task_scheduler.cc:121] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #610: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(7), T.int64(7), T.int64(512)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(32)), "float32"), p3: T.Buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(9), T.int64(9), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused in T.parallel(T.int64(112), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(3), T.int64(9), T.int64(512)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(9), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(7) + ax2)
                    v_i3, v_i4 = T.axis.remap("SS", [ax3, ax4])
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(8) and T.int64(1) <= v_i3 and v_i3 < T.int64(8), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(7) + oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(7) + oh_2_init + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(7), ow_1 * T.int64(7) + ow_2_init * T.int64(7) + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(64), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(32), T.int64(8), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(7) + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(7) + oh_2 + oh_3)
                        v_ow = T.axis.spatial(T.int64(7), ow_1 * T.int64(7) + ow_2 * T.int64(7) + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(8) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                    for ax4_fused in T.vectorized(T.int64(32)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(7) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(7) + ax2)
                            v_ax3, v_ax4 = T.axis.remap("SS", [ax3, ax4_fused])
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[16, 1, 1, 1])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 7, 1, 1])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 1, 7])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[1, 1, 32, 1])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[64, 8])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[1, 3])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l50, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=16)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=7)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b69)
l85 = sch.fuse(l72, l73, l74, l75, l76, l77, l78, l79, preserve_unit_iters=True)
sch.parallel(loop=l85)
l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b70)
l105 = sch.fuse(l86, preserve_unit_iters=True)
sch.parallel(loop=l105)
sch.annotate(block_or_loop=l105, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l105, ann_key="pragma_unroll_explicit", ann_val=1)
l106, l107, l108, l109, l110, l111, l112, l113 = sch.get_loops(block=b71)
l114 = sch.fuse(l113, preserve_unit_iters=True)
sch.vectorize(loop=l114)
b115 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134 = sch.get_loops(block=b115)
b135 = sch.decompose_reduction(block=b115, loop=l119)
2024-04-29 00:26:27 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #611: GFLOPs: 523.7192. Time: 441.6227 us. Best GFLOPs: 826.6082
2024-04-29 00:26:27 [INFO] [task_scheduler.cc:121] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #612: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(7), T.int64(7), T.int64(512)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(32)), "float32"), p3: T.Buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(9), T.int64(9), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_fused_fused in T.parallel(T.int64(112), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(3), T.int64(9), T.int64(512)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(9), n_0_oc_chunk_0_oh_0_fused_fused % T.int64(7) + ax2)
                    v_i3, v_i4 = T.axis.remap("SS", [ax3, ax4])
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(8) and T.int64(1) <= v_i3 and v_i3 < T.int64(8), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for ow_0, oc_block_0, n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_fused_fused // T.int64(7) + oc_chunk_1 + oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_fused_fused % T.int64(7) + oh_1 + oh_2_init + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(7), ow_0 * T.int64(7) + ow_1 * T.int64(7) + ow_2_init * T.int64(7) + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_0 * T.int64(32) + oc_block_1 * T.int64(32) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(128), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(32), T.int64(4), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_fused_fused // T.int64(7) + oc_chunk_1 + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_fused_fused % T.int64(7) + oh_1 + oh_2 + oh_3)
                        v_ow = T.axis.spatial(T.int64(7), ow_0 * T.int64(7) + ow_1 * T.int64(7) + ow_2 * T.int64(7) + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_0 * T.int64(32) + oc_block_1 * T.int64(32) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(4) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                    for ax4_fused in T.vectorized(T.int64(32)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_fused_fused // T.int64(7) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_fused_fused % T.int64(7) + ax2)
                            v_ax3, v_ax4 = T.axis.remap("SS", [ax3, ax4_fused])
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[16, 1, 1, 1])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[7, 1, 1, 1])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 1, 7])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[1, 1, 32, 1])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[128, 4])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[1, 3])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l50, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=2)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79 = sch.get_loops(block=b69)
l80 = sch.fuse(l72, l73, l74, preserve_unit_iters=True)
sch.parallel(loop=l80)
l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b70)
l105 = sch.fuse(l81, preserve_unit_iters=True)
sch.parallel(loop=l105)
sch.annotate(block_or_loop=l105, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l105, ann_key="pragma_unroll_explicit", ann_val=1)
l106, l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117, l118 = sch.get_loops(block=b71)
l119 = sch.fuse(l118, preserve_unit_iters=True)
sch.vectorize(loop=l119)
b120 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141, l142, l143, l144 = sch.get_loops(block=b120)
b145 = sch.decompose_reduction(block=b120, loop=l129)
2024-04-29 00:26:27 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #613: GFLOPs: 394.0981. Time: 586.8749 us. Best GFLOPs: 826.6082
2024-04-29 00:26:27 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #614: GFLOPs: 462.8878. Time: 499.6594 us. Best GFLOPs: 826.6082
2024-04-29 00:26:27 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #615: GFLOPs: 517.8777. Time: 446.6040 us. Best GFLOPs: 826.6082
2024-04-29 00:26:27 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #616: GFLOPs: 494.7435. Time: 467.4872 us. Best GFLOPs: 826.6082
2024-04-29 00:26:28 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #617: GFLOPs: 538.3355. Time: 429.6322 us. Best GFLOPs: 826.6082
2024-04-29 00:26:28 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #618: GFLOPs: 508.6881. Time: 454.6720 us. Best GFLOPs: 826.6082
2024-04-29 00:26:28 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #619: GFLOPs: 576.6565. Time: 401.0815 us. Best GFLOPs: 826.6082
2024-04-29 00:26:28 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #620: GFLOPs: 582.7811. Time: 396.8664 us. Best GFLOPs: 826.6082
2024-04-29 00:26:28 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #621: GFLOPs: 456.8296. Time: 506.2857 us. Best GFLOPs: 826.6082
2024-04-29 00:26:28 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #622: GFLOPs: 463.6723. Time: 498.8141 us. Best GFLOPs: 826.6082
2024-04-29 00:26:28 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #623: GFLOPs: 457.2713. Time: 505.7966 us. Best GFLOPs: 826.6082
2024-04-29 00:26:28 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #624: GFLOPs: 502.0596. Time: 460.6749 us. Best GFLOPs: 826.6082
2024-04-29 00:26:28 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #625: GFLOPs: 441.8729. Time: 523.4226 us. Best GFLOPs: 826.6082
2024-04-29 00:26:28 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #626: GFLOPs: 401.0513. Time: 576.7000 us. Best GFLOPs: 826.6082
2024-04-29 00:26:28 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #627: GFLOPs: 491.1324. Time: 470.9245 us. Best GFLOPs: 826.6082
2024-04-29 00:26:28 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #628: GFLOPs: 469.4748. Time: 492.6489 us. Best GFLOPs: 826.6082
2024-04-29 00:26:28 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #629: GFLOPs: 468.2300. Time: 493.9587 us. Best GFLOPs: 826.6082
2024-04-29 00:26:28 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #630: GFLOPs: 487.7228. Time: 474.2166 us. Best GFLOPs: 826.6082
2024-04-29 00:26:28 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #631: GFLOPs: 460.6169. Time: 502.1228 us. Best GFLOPs: 826.6082
2024-04-29 00:26:28 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #632: GFLOPs: 476.2232. Time: 485.6678 us. Best GFLOPs: 826.6082
2024-04-29 00:26:28 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #633: GFLOPs: 454.4215. Time: 508.9686 us. Best GFLOPs: 826.6082
2024-04-29 00:26:28 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #634: GFLOPs: 407.3754. Time: 567.7473 us. Best GFLOPs: 826.6082
2024-04-29 00:26:28 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #635: GFLOPs: 391.6316. Time: 590.5710 us. Best GFLOPs: 826.6082
2024-04-29 00:26:28 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #636: GFLOPs: 30.6008. Time: 7558.1857 us. Best GFLOPs: 826.6082
2024-04-29 00:26:28 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #637: GFLOPs: 59.5481. Time: 3884.0255 us. Best GFLOPs: 826.6082
2024-04-29 00:26:28 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #638: GFLOPs: 11.7229. Time: 19729.4780 us. Best GFLOPs: 826.6082
2024-04-29 00:26:28 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #639: GFLOPs: 11.0423. Time: 20945.4320 us. Best GFLOPs: 826.6082
2024-04-29 00:26:28 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #640: GFLOPs: 5.6835. Time: 40694.2110 us. Best GFLOPs: 826.6082
2024-04-29 00:37:09 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 00:37:10 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-29 00:37:14 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f1e458)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x386def8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x36b1d38)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3108268)]: 0 failure(s)
2024-04-29 00:37:14 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-29 00:37:25 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f1e458)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x386def8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x36b1d38)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3108268)]: 0 failure(s)
2024-04-29 00:37:36 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f1e458)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x386def8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x36b1d38)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3108268)]: 0 failure(s)
2024-04-29 00:37:48 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f1e458)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x386def8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x36b1d38)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3108268)]: 0 failure(s)
2024-04-29 00:37:59 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f1e458)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x386def8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x36b1d38)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3108268)]: 0 failure(s)
2024-04-29 00:38:07 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9706  0.9706  0.9214  0.9195  0.9085  0.9085  0.8560  0.8259  0.8245  0.8245  0.8225  0.8160  0.8070  0.7791  0.7691  0.7495
[17 : 32]:	0.7469  0.7459  0.7402  0.7402  0.7374  0.7371  0.7371  0.7365  0.7336  0.7260  0.7173  0.7128  0.7128  0.6977  0.6903  0.6800
[33 : 48]:	0.6731  0.6660  0.6641  0.6623  0.6623  0.6597  0.6572  0.6499  0.6342  0.6342  0.6325  0.6320  0.6239  0.6237  0.6172  0.6154
[49 : 64]:	0.6134  0.6133  0.6092  0.6087  0.6043  0.6030  0.5975  0.5969  0.5951  0.5940  0.5937  0.5923  0.5915  0.5912  0.5911  0.5910
2024-04-29 00:38:07 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 00:38:07 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 00:40:04 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #641: GFLOPs: 819.1373. Time: 282.3535 us. Best GFLOPs: 826.6082
2024-04-29 00:40:04 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #642: GFLOPs: 778.5283. Time: 297.0814 us. Best GFLOPs: 826.6082
2024-04-29 00:40:04 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #643: GFLOPs: 660.5375. Time: 350.1486 us. Best GFLOPs: 826.6082
2024-04-29 00:40:04 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #644: GFLOPs: 729.6906. Time: 316.9648 us. Best GFLOPs: 826.6082
2024-04-29 00:40:04 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #645: GFLOPs: 765.1492. Time: 302.2760 us. Best GFLOPs: 826.6082
2024-04-29 00:40:04 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #646: GFLOPs: 766.9517. Time: 301.5656 us. Best GFLOPs: 826.6082
2024-04-29 00:40:04 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #647: GFLOPs: 817.4943. Time: 282.9210 us. Best GFLOPs: 826.6082
2024-04-29 00:40:04 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #648: GFLOPs: 627.2057. Time: 368.7566 us. Best GFLOPs: 826.6082
2024-04-29 00:40:04 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #649: GFLOPs: 695.1032. Time: 332.7366 us. Best GFLOPs: 826.6082
2024-04-29 00:40:04 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #650: GFLOPs: 691.3290. Time: 334.5531 us. Best GFLOPs: 826.6082
2024-04-29 00:40:04 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #651: GFLOPs: 676.3294. Time: 341.9728 us. Best GFLOPs: 826.6082
2024-04-29 00:40:04 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #652: GFLOPs: 636.5368. Time: 363.3510 us. Best GFLOPs: 826.6082
2024-04-29 00:40:04 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #653: GFLOPs: 343.5342. Time: 673.2555 us. Best GFLOPs: 826.6082
2024-04-29 00:40:04 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #654: GFLOPs: 683.8914. Time: 338.1915 us. Best GFLOPs: 826.6082
2024-04-29 00:40:04 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #655: GFLOPs: 627.1467. Time: 368.7914 us. Best GFLOPs: 826.6082
2024-04-29 00:40:04 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #656: GFLOPs: 669.0547. Time: 345.6911 us. Best GFLOPs: 826.6082
2024-04-29 00:40:04 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #657: GFLOPs: 677.9404. Time: 341.1602 us. Best GFLOPs: 826.6082
2024-04-29 00:40:04 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #658: GFLOPs: 551.3312. Time: 419.5051 us. Best GFLOPs: 826.6082
2024-04-29 00:40:04 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #659: GFLOPs: 597.2352. Time: 387.2616 us. Best GFLOPs: 826.6082
2024-04-29 00:40:04 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #660: GFLOPs: 583.1259. Time: 396.6318 us. Best GFLOPs: 826.6082
2024-04-29 00:40:04 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #661: GFLOPs: 649.8173. Time: 355.9251 us. Best GFLOPs: 826.6082
2024-04-29 00:40:04 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #662: GFLOPs: 524.2617. Time: 441.1657 us. Best GFLOPs: 826.6082
2024-04-29 00:40:04 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #663: GFLOPs: 639.1785. Time: 361.8493 us. Best GFLOPs: 826.6082
2024-04-29 00:40:04 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #664: GFLOPs: 615.5697. Time: 375.7272 us. Best GFLOPs: 826.6082
2024-04-29 00:40:04 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #665: GFLOPs: 723.5798. Time: 319.6417 us. Best GFLOPs: 826.6082
2024-04-29 00:40:04 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #666: GFLOPs: 418.8842. Time: 552.1484 us. Best GFLOPs: 826.6082
2024-04-29 00:40:04 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #667: GFLOPs: 100.0415. Time: 2311.9028 us. Best GFLOPs: 826.6082
2024-04-29 00:40:04 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #668: GFLOPs: 680.9459. Time: 339.6544 us. Best GFLOPs: 826.6082
2024-04-29 00:40:04 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #669: GFLOPs: 593.7319. Time: 389.5466 us. Best GFLOPs: 826.6082
2024-04-29 00:40:04 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #670: GFLOPs: 579.6214. Time: 399.0299 us. Best GFLOPs: 826.6082
2024-04-29 00:40:04 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #671: GFLOPs: 553.8547. Time: 417.5938 us. Best GFLOPs: 826.6082
2024-04-29 00:40:04 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #672: GFLOPs: 534.0370. Time: 433.0903 us. Best GFLOPs: 826.6082
2024-04-29 00:40:04 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #673: GFLOPs: 571.7384. Time: 404.5316 us. Best GFLOPs: 826.6082
2024-04-29 00:40:04 [INFO] [task_scheduler.cc:121] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #674: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(7), T.int64(7), T.int64(512)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(32)), "float32"), p3: T.Buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(9), T.int64(9), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused in T.parallel(T.int64(112), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(3), T.int64(9), T.int64(512)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(9), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(28) // T.int64(4) + ax2)
                    v_i3, v_i4 = T.axis.remap("SS", [ax3, ax4])
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(8) and T.int64(1) <= v_i3 and v_i3 < T.int64(8), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(28) * T.int64(4) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(4) + oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(28) // T.int64(4) + oh_1 + oh_2_init + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(7), ow_1 * T.int64(7) + ow_2_init * T.int64(7) + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(32), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(32), T.int64(16), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(28) * T.int64(4) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(4) + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(28) // T.int64(4) + oh_1 + oh_2 + oh_3)
                        v_ow = T.axis.spatial(T.int64(7), ow_1 * T.int64(7) + ow_2 * T.int64(7) + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(16) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                    for ax4_fused in T.vectorized(T.int64(32)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(28) * T.int64(4) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(4) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(28) // T.int64(4) + ax2)
                            v_ax3, v_ax4 = T.axis.remap("SS", [ax3, ax4_fused])
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[4, 4, 1, 1])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[7, 1, 1, 1])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 1, 7])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[1, 1, 32, 1])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[32, 16])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[1, 3])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l50, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=28)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=6)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83 = sch.get_loops(block=b69)
l84 = sch.fuse(l72, l73, l74, l75, l76, l77, l78, preserve_unit_iters=True)
sch.parallel(loop=l84)
l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b70)
l105 = sch.fuse(l85, preserve_unit_iters=True)
sch.parallel(loop=l105)
sch.annotate(block_or_loop=l105, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l105, ann_key="pragma_unroll_explicit", ann_val=1)
l106, l107, l108, l109, l110, l111, l112, l113, l114 = sch.get_loops(block=b71)
l115 = sch.fuse(l114, preserve_unit_iters=True)
sch.vectorize(loop=l115)
b116 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136 = sch.get_loops(block=b116)
b137 = sch.decompose_reduction(block=b116, loop=l121)
2024-04-29 00:40:04 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #675: GFLOPs: 681.1397. Time: 339.5578 us. Best GFLOPs: 826.6082
2024-04-29 00:40:04 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #676: GFLOPs: 685.2107. Time: 337.5404 us. Best GFLOPs: 826.6082
2024-04-29 00:40:04 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #677: GFLOPs: 551.7969. Time: 419.1511 us. Best GFLOPs: 826.6082
2024-04-29 00:40:04 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #678: GFLOPs: 259.7265. Time: 890.4993 us. Best GFLOPs: 826.6082
2024-04-29 00:40:04 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #679: GFLOPs: 560.2137. Time: 412.8537 us. Best GFLOPs: 826.6082
2024-04-29 00:40:04 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #680: GFLOPs: 635.8352. Time: 363.7519 us. Best GFLOPs: 826.6082
2024-04-29 00:40:04 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #681: GFLOPs: 336.4275. Time: 687.4772 us. Best GFLOPs: 826.6082
2024-04-29 00:40:04 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #682: GFLOPs: 339.0636. Time: 682.1324 us. Best GFLOPs: 826.6082
2024-04-29 00:40:04 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #683: GFLOPs: 346.0037. Time: 668.4503 us. Best GFLOPs: 826.6082
2024-04-29 00:40:04 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #684: GFLOPs: 549.6705. Time: 420.7725 us. Best GFLOPs: 826.6082
2024-04-29 00:40:04 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #685: GFLOPs: 350.6234. Time: 659.6429 us. Best GFLOPs: 826.6082
2024-04-29 00:40:04 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #686: GFLOPs: 485.8331. Time: 476.0612 us. Best GFLOPs: 826.6082
2024-04-29 00:40:04 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #687: GFLOPs: 420.4912. Time: 550.0384 us. Best GFLOPs: 826.6082
2024-04-29 00:40:04 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #688: GFLOPs: 333.3187. Time: 693.8892 us. Best GFLOPs: 826.6082
2024-04-29 00:40:04 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #689: GFLOPs: 527.4077. Time: 438.5341 us. Best GFLOPs: 826.6082
2024-04-29 00:40:04 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #690: GFLOPs: 454.9486. Time: 508.3789 us. Best GFLOPs: 826.6082
2024-04-29 00:40:04 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #691: GFLOPs: 438.0767. Time: 527.9584 us. Best GFLOPs: 826.6082
2024-04-29 00:40:04 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #692: GFLOPs: 545.4766. Time: 424.0077 us. Best GFLOPs: 826.6082
2024-04-29 00:40:04 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #693: GFLOPs: 511.6281. Time: 452.0594 us. Best GFLOPs: 826.6082
2024-04-29 00:40:04 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #694: GFLOPs: 34.2357. Time: 6755.7083 us. Best GFLOPs: 826.6082
2024-04-29 00:40:04 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #695: GFLOPs: 523.3045. Time: 441.9727 us. Best GFLOPs: 826.6082
2024-04-29 00:40:04 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #696: GFLOPs: 338.9840. Time: 682.2925 us. Best GFLOPs: 826.6082
2024-04-29 00:40:04 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #697: GFLOPs: 414.3522. Time: 558.1876 us. Best GFLOPs: 826.6082
2024-04-29 00:40:04 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #698: GFLOPs: 498.8642. Time: 463.6257 us. Best GFLOPs: 826.6082
2024-04-29 00:40:04 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #699: GFLOPs: 540.7138. Time: 427.7425 us. Best GFLOPs: 826.6082
2024-04-29 00:40:04 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #700: GFLOPs: 457.7981. Time: 505.2145 us. Best GFLOPs: 826.6082
2024-04-29 00:40:04 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #701: GFLOPs: 100.6597. Time: 2297.7046 us. Best GFLOPs: 826.6082
2024-04-29 00:40:04 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #702: GFLOPs: 28.9710. Time: 7983.3637 us. Best GFLOPs: 826.6082
2024-04-29 00:40:04 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #703: GFLOPs: 9.9279. Time: 23296.6520 us. Best GFLOPs: 826.6082
2024-04-29 00:40:04 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #704: GFLOPs: 11.2346. Time: 20586.9906 us. Best GFLOPs: 826.6082
2024-04-29 01:06:08 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 01:06:09 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-29 01:06:13 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f1e458)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x386def8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x36b1d38)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3108268)]: 0 failure(s)
2024-04-29 01:06:13 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-29 01:06:24 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f1e458)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x386def8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x36b1d38)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3108268)]: 0 failure(s)
2024-04-29 01:06:35 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f1e458)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x386def8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x36b1d38)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3108268)]: 0 failure(s)
2024-04-29 01:06:47 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f1e458)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x386def8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x36b1d38)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3108268)]: 0 failure(s)
2024-04-29 01:06:59 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f1e458)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x386def8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x36b1d38)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3108268)]: 0 failure(s)
2024-04-29 01:07:06 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9716  0.9546  0.9546  0.9484  0.8551  0.8539  0.8539  0.8121  0.8076  0.7796  0.7776  0.7764  0.7764  0.7757  0.7681  0.7589
[17 : 32]:	0.7508  0.7508  0.7489  0.7489  0.7489  0.7459  0.7368  0.7355  0.7348  0.7224  0.6952  0.6885  0.6885  0.6883  0.6872  0.6752
[33 : 48]:	0.6731  0.6682  0.6664  0.6664  0.6569  0.6519  0.6519  0.6503  0.6474  0.6472  0.6394  0.6394  0.6317  0.6314  0.6314  0.6307
[49 : 64]:	0.6282  0.6272  0.6257  0.6242  0.6187  0.6180  0.6180  0.6125  0.6093  0.6076  0.6009  0.5984  0.5897  0.5877  0.5864  0.5841
2024-04-29 01:07:06 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 01:07:06 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 01:08:58 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #705: GFLOPs: 806.1477. Time: 286.9031 us. Best GFLOPs: 826.6082
2024-04-29 01:08:58 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #706: GFLOPs: 791.0230. Time: 292.3888 us. Best GFLOPs: 826.6082
2024-04-29 01:08:58 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #707: GFLOPs: 565.7155. Time: 408.8385 us. Best GFLOPs: 826.6082
2024-04-29 01:08:58 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #708: GFLOPs: 746.7901. Time: 309.7072 us. Best GFLOPs: 826.6082
2024-04-29 01:08:58 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #709: GFLOPs: 722.6987. Time: 320.0314 us. Best GFLOPs: 826.6082
2024-04-29 01:08:58 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #710: GFLOPs: 680.9002. Time: 339.6772 us. Best GFLOPs: 826.6082
2024-04-29 01:08:58 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #711: GFLOPs: 740.0569. Time: 312.5250 us. Best GFLOPs: 826.6082
2024-04-29 01:08:58 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #712: GFLOPs: 674.3867. Time: 342.9579 us. Best GFLOPs: 826.6082
2024-04-29 01:08:58 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #713: GFLOPs: 706.5756. Time: 327.3341 us. Best GFLOPs: 826.6082
2024-04-29 01:08:58 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #714: GFLOPs: 564.2922. Time: 409.8697 us. Best GFLOPs: 826.6082
2024-04-29 01:08:58 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #715: GFLOPs: 569.4442. Time: 406.1614 us. Best GFLOPs: 826.6082
2024-04-29 01:08:58 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #716: GFLOPs: 669.4525. Time: 345.4857 us. Best GFLOPs: 826.6082
2024-04-29 01:08:58 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #717: GFLOPs: 677.1994. Time: 341.5335 us. Best GFLOPs: 826.6082
2024-04-29 01:08:58 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #718: GFLOPs: 653.6113. Time: 353.8591 us. Best GFLOPs: 826.6082
2024-04-29 01:08:58 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #719: GFLOPs: 604.2202. Time: 382.7848 us. Best GFLOPs: 826.6082
2024-04-29 01:08:58 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #720: GFLOPs: 339.4982. Time: 681.2593 us. Best GFLOPs: 826.6082
2024-04-29 01:08:58 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #721: GFLOPs: 349.1227. Time: 662.4784 us. Best GFLOPs: 826.6082
2024-04-29 01:08:58 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #722: GFLOPs: 344.1053. Time: 672.1381 us. Best GFLOPs: 826.6082
2024-04-29 01:08:58 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #723: GFLOPs: 658.7441. Time: 351.1018 us. Best GFLOPs: 826.6082
2024-04-29 01:08:58 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #724: GFLOPs: 677.2478. Time: 341.5091 us. Best GFLOPs: 826.6082
2024-04-29 01:08:58 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #725: GFLOPs: 315.5324. Time: 733.0032 us. Best GFLOPs: 826.6082
2024-04-29 01:08:58 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #726: GFLOPs: 633.8423. Time: 364.8956 us. Best GFLOPs: 826.6082
2024-04-29 01:08:58 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #727: GFLOPs: 680.0532. Time: 340.1003 us. Best GFLOPs: 826.6082
2024-04-29 01:08:58 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #728: GFLOPs: 615.8185. Time: 375.5754 us. Best GFLOPs: 826.6082
2024-04-29 01:08:58 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #729: GFLOPs: 609.0469. Time: 379.7512 us. Best GFLOPs: 826.6082
2024-04-29 01:08:58 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #730: GFLOPs: 561.6049. Time: 411.8310 us. Best GFLOPs: 826.6082
2024-04-29 01:08:58 [INFO] [task_scheduler.cc:121] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #731: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(7), T.int64(7), T.int64(512)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(32)), "float32"), p3: T.Buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(9), T.int64(9), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused in T.parallel(T.int64(112), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(3), T.int64(9), T.int64(512)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(9), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(56) // T.int64(8) + ax2)
                    v_i3, v_i4 = T.axis.remap("SS", [ax3, ax4])
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(8) and T.int64(1) <= v_i3 and v_i3 < T.int64(8), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(56) * T.int64(8) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(8) + oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(56) // T.int64(8) + oh_1 + oh_2_init + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(7), ow_1 * T.int64(7) + ow_2_init * T.int64(7) + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(32), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(32), T.int64(16), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(56) * T.int64(8) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(8) + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(56) // T.int64(8) + oh_1 + oh_2 + oh_3)
                        v_ow = T.axis.spatial(T.int64(7), ow_1 * T.int64(7) + ow_2 * T.int64(7) + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(16) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                    for ax4_fused in T.vectorized(T.int64(32)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(56) * T.int64(8) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(8) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(56) // T.int64(8) + ax2)
                            v_ax3, v_ax4 = T.axis.remap("SS", [ax3, ax4_fused])
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 8, 1, 1])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[7, 1, 1, 1])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 1, 7])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[1, 1, 32, 1])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[32, 16])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[1, 3])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l50, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=16)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=6)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83 = sch.get_loops(block=b69)
l84 = sch.fuse(l72, l73, l74, l75, l76, l77, l78, preserve_unit_iters=True)
sch.parallel(loop=l84)
l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b70)
l105 = sch.fuse(l85, preserve_unit_iters=True)
sch.parallel(loop=l105)
sch.annotate(block_or_loop=l105, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l105, ann_key="pragma_unroll_explicit", ann_val=1)
l106, l107, l108, l109, l110, l111, l112, l113, l114 = sch.get_loops(block=b71)
l115 = sch.fuse(l114, preserve_unit_iters=True)
sch.vectorize(loop=l115)
b116 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136 = sch.get_loops(block=b116)
b137 = sch.decompose_reduction(block=b116, loop=l121)
2024-04-29 01:08:58 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #732: GFLOPs: 525.8393. Time: 439.8421 us. Best GFLOPs: 826.6082
2024-04-29 01:08:58 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #733: GFLOPs: 584.7548. Time: 395.5270 us. Best GFLOPs: 826.6082
2024-04-29 01:08:58 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #734: GFLOPs: 671.6149. Time: 344.3733 us. Best GFLOPs: 826.6082
2024-04-29 01:08:58 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #735: GFLOPs: 532.5530. Time: 434.2972 us. Best GFLOPs: 826.6082
2024-04-29 01:08:58 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #736: GFLOPs: 413.0092. Time: 560.0026 us. Best GFLOPs: 826.6082
2024-04-29 01:08:58 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #737: GFLOPs: 384.7056. Time: 601.2032 us. Best GFLOPs: 826.6082
2024-04-29 01:08:58 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #738: GFLOPs: 576.3447. Time: 401.2985 us. Best GFLOPs: 826.6082
2024-04-29 01:08:58 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #739: GFLOPs: 602.9451. Time: 383.5943 us. Best GFLOPs: 826.6082
2024-04-29 01:08:58 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #740: GFLOPs: 590.4722. Time: 391.6972 us. Best GFLOPs: 826.6082
2024-04-29 01:08:58 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #741: GFLOPs: 783.0712. Time: 295.3579 us. Best GFLOPs: 826.6082
2024-04-29 01:08:58 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #742: GFLOPs: 615.3243. Time: 375.8770 us. Best GFLOPs: 826.6082
2024-04-29 01:08:58 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #743: GFLOPs: 602.8348. Time: 383.6644 us. Best GFLOPs: 826.6082
2024-04-29 01:08:58 [INFO] [task_scheduler.cc:121] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #744: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(7), T.int64(7), T.int64(512)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(32)), "float32"), p3: T.Buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(9), T.int64(9), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused in T.parallel(T.int64(112), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(3), T.int64(9), T.int64(512)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(9), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(28) // T.int64(4) + ax2)
                    v_i3, v_i4 = T.axis.remap("SS", [ax3, ax4])
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(8) and T.int64(1) <= v_i3 and v_i3 < T.int64(8), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(28) * T.int64(4) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(4) + oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(28) // T.int64(4) + oh_1 + oh_2_init + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(7), ow_1 * T.int64(7) + ow_2_init * T.int64(7) + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(128), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(32), T.int64(4), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(28) * T.int64(4) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(4) + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(28) // T.int64(4) + oh_1 + oh_2 + oh_3)
                        v_ow = T.axis.spatial(T.int64(7), ow_1 * T.int64(7) + ow_2 * T.int64(7) + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(4) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                    for ax4_fused in T.vectorized(T.int64(32)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(28) * T.int64(4) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(4) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(28) // T.int64(4) + ax2)
                            v_ax3, v_ax4 = T.axis.remap("SS", [ax3, ax4_fused])
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[4, 4, 1, 1])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[7, 1, 1, 1])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 1, 7])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[1, 1, 32, 1])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[128, 4])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[1, 3])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l50, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=6)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83 = sch.get_loops(block=b69)
l84 = sch.fuse(l72, l73, l74, l75, l76, l77, l78, preserve_unit_iters=True)
sch.parallel(loop=l84)
l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b70)
l105 = sch.fuse(l85, preserve_unit_iters=True)
sch.parallel(loop=l105)
sch.annotate(block_or_loop=l105, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l105, ann_key="pragma_unroll_explicit", ann_val=1)
l106, l107, l108, l109, l110, l111, l112, l113, l114 = sch.get_loops(block=b71)
l115 = sch.fuse(l114, preserve_unit_iters=True)
sch.vectorize(loop=l115)
b116 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136 = sch.get_loops(block=b116)
b137 = sch.decompose_reduction(block=b116, loop=l121)
2024-04-29 01:08:58 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #745: GFLOPs: 539.8783. Time: 428.4045 us. Best GFLOPs: 826.6082
2024-04-29 01:08:58 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #746: GFLOPs: 436.5933. Time: 529.7523 us. Best GFLOPs: 826.6082
2024-04-29 01:08:58 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #747: GFLOPs: 685.2418. Time: 337.5251 us. Best GFLOPs: 826.6082
2024-04-29 01:08:58 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #748: GFLOPs: 598.6092. Time: 386.3727 us. Best GFLOPs: 826.6082
2024-04-29 01:08:58 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #749: GFLOPs: 507.3491. Time: 455.8721 us. Best GFLOPs: 826.6082
2024-04-29 01:08:58 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #750: GFLOPs: 28.7658. Time: 8040.3343 us. Best GFLOPs: 826.6082
2024-04-29 01:08:58 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #751: GFLOPs: 29.3085. Time: 7891.4472 us. Best GFLOPs: 826.6082
2024-04-29 01:08:58 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #752: GFLOPs: 530.2789. Time: 436.1596 us. Best GFLOPs: 826.6082
2024-04-29 01:08:58 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #753: GFLOPs: 524.6027. Time: 440.8789 us. Best GFLOPs: 826.6082
2024-04-29 01:08:58 [INFO] [task_scheduler.cc:121] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #754: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(7), T.int64(7), T.int64(512)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(32)), "float32"), p3: T.Buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(9), T.int64(9), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused in T.parallel(T.int64(112), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(3), T.int64(9), T.int64(512)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(9), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(14) // T.int64(2) + ax2)
                    v_i3, v_i4 = T.axis.remap("SS", [ax3, ax4])
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(8) and T.int64(1) <= v_i3 and v_i3 < T.int64(8), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(14) * T.int64(2) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(2) + oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(14) // T.int64(2) + oh_1 + oh_2_init + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(7), ow_1 * T.int64(7) + ow_2_init * T.int64(7) + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(64), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(32), T.int64(8), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(14) * T.int64(2) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(2) + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(14) // T.int64(2) + oh_1 + oh_2 + oh_3)
                        v_ow = T.axis.spatial(T.int64(7), ow_1 * T.int64(7) + ow_2 * T.int64(7) + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(8) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                    for ax4_fused in T.vectorized(T.int64(32)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(14) * T.int64(2) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(2) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(14) // T.int64(2) + ax2)
                            v_ax3, v_ax4 = T.axis.remap("SS", [ax3, ax4_fused])
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[8, 2, 1, 1])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[7, 1, 1, 1])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 1, 7])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[1, 1, 32, 1])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[64, 8])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[1, 3])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l50, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=6)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83 = sch.get_loops(block=b69)
l84 = sch.fuse(l72, l73, l74, l75, l76, l77, l78, preserve_unit_iters=True)
sch.parallel(loop=l84)
l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b70)
l105 = sch.fuse(l85, preserve_unit_iters=True)
sch.parallel(loop=l105)
sch.annotate(block_or_loop=l105, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l105, ann_key="pragma_unroll_explicit", ann_val=1)
l106, l107, l108, l109, l110, l111, l112, l113, l114 = sch.get_loops(block=b71)
l115 = sch.fuse(l114, preserve_unit_iters=True)
sch.vectorize(loop=l115)
b116 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136 = sch.get_loops(block=b116)
b137 = sch.decompose_reduction(block=b116, loop=l121)
2024-04-29 01:08:58 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #755: GFLOPs: 32.2968. Time: 7161.2832 us. Best GFLOPs: 826.6082
2024-04-29 01:08:58 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #756: GFLOPs: 156.3648. Time: 1479.1452 us. Best GFLOPs: 826.6082
2024-04-29 01:08:58 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #757: GFLOPs: 483.6767. Time: 478.1836 us. Best GFLOPs: 826.6082
2024-04-29 01:08:58 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #758: GFLOPs: 29.0377. Time: 7965.0346 us. Best GFLOPs: 826.6082
2024-04-29 01:08:58 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #759: GFLOPs: 31.7272. Time: 7289.8518 us. Best GFLOPs: 826.6082
2024-04-29 01:08:58 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #760: GFLOPs: 582.0243. Time: 397.3825 us. Best GFLOPs: 826.6082
2024-04-29 01:08:58 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #761: GFLOPs: 546.2306. Time: 423.4224 us. Best GFLOPs: 826.6082
2024-04-29 01:08:58 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #762: GFLOPs: 515.5549. Time: 448.6162 us. Best GFLOPs: 826.6082
2024-04-29 01:08:58 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #763: GFLOPs: 31.0550. Time: 7447.6259 us. Best GFLOPs: 826.6082
2024-04-29 01:08:58 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #764: GFLOPs: 514.5634. Time: 449.4807 us. Best GFLOPs: 826.6082
2024-04-29 01:08:58 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #765: GFLOPs: 598.4521. Time: 386.4742 us. Best GFLOPs: 826.6082
2024-04-29 01:08:58 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #766: GFLOPs: 19.0473. Time: 12142.7573 us. Best GFLOPs: 826.6082
2024-04-29 01:08:58 [INFO] [task_scheduler.cc:121] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #767: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(7), T.int64(7), T.int64(512)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(32)), "float32"), p3: T.Buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(9), T.int64(9), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused in T.parallel(T.int64(8), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(2)):
                for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(9), T.int64(3), T.int64(512)):
                    with T.block("data_pad"):
                        v_i0, v_i1, v_i2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                        v_i3 = T.axis.spatial(T.int64(9), ow_1 + ax3)
                        v_i4 = T.axis.spatial(T.int64(512), ax4)
                        T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                        T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                        data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(8) and T.int64(1) <= v_i3 and v_i3 < T.int64(8), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(8), T.int64(7), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(16), oc_chunk_1 * T.int64(16) + oc_chunk_2_init * T.int64(8) + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(7), oh_1 * T.int64(7) + oh_2_init * T.int64(7) + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(7), ow_1 + ow_2_init + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused * T.int64(4) + oc_block_1 * T.int64(2) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(8), T.int64(1), T.int64(3), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(2), T.int64(64), T.int64(3), T.int64(1), T.int64(1), T.int64(8), T.int64(7), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(16), oc_chunk_1 * T.int64(16) + oc_chunk_2 * T.int64(8) + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(7), oh_1 * T.int64(7) + oh_2 * T.int64(7) + oh_3)
                        v_ow = T.axis.spatial(T.int64(7), ow_1 + ow_2 + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused * T.int64(4) + oc_block_1 * T.int64(2) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(64) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(16), T.int64(7), T.int64(7)):
                for ax4_fused in T.vectorized(T.int64(4)):
                    with T.block("T_relu"):
                        v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                        v_ax4 = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused * T.int64(4) + ax4_fused)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 2, 8])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 1, 7])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 7, 1, 1])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[8, 2, 2, 1])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[8, 64])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[3, 1])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=9)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86 = sch.get_loops(block=b69)
l87 = sch.fuse(l72, l73, l74, l75, l76, preserve_unit_iters=True)
sch.parallel(loop=l87)
l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107, l108, l109 = sch.get_loops(block=b70)
l110 = sch.fuse(l88, preserve_unit_iters=True)
sch.parallel(loop=l110)
sch.annotate(block_or_loop=l110, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l110, ann_key="pragma_unroll_explicit", ann_val=1)
l111, l112, l113, l114, l115, l116 = sch.get_loops(block=b71)
l117 = sch.fuse(l116, preserve_unit_iters=True)
sch.vectorize(loop=l117)
b118 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140 = sch.get_loops(block=b118)
b141 = sch.decompose_reduction(block=b118, loop=l125)
2024-04-29 01:08:58 [INFO] [task_scheduler.cc:121] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #768: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(7), T.int64(7), T.int64(512)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(32)), "float32"), p3: T.Buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(9), T.int64(9), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused in T.parallel(T.int64(448), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1, ow_1 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(3), T.int64(3), T.int64(512)):
                    with T.block("data_pad"):
                        v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                        v_i2 = T.axis.spatial(T.int64(9), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(28) // T.int64(4) + ax2)
                        v_i3 = T.axis.spatial(T.int64(9), ow_1 + ax3)
                        v_i4 = T.axis.spatial(T.int64(512), ax4)
                        T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                        T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                        data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(8) and T.int64(1) <= v_i3 and v_i3 < T.int64(8), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                for oc_block_1 in range(T.int64(1)):
                    for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                        for oc_block_3_fused_init in T.vectorized(T.int64(4)):
                            with T.block("conv2d_NCHWc_init"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                                v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(28) + oc_chunk_1 + oc_chunk_2_init + oc_chunk_3_init)
                                v_oh = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(28) // T.int64(4) + oh_1 + oh_2_init + oh_3_init)
                                v_ow = T.axis.spatial(T.int64(7), ow_1 + ow_2_init + ow_3_init)
                                v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(4) * T.int64(8) + oc_block_1 * T.int64(8) + oc_block_2_init * T.int64(4) + oc_block_3_fused_init)
                                T.reads()
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                    for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(16), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(32), T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                        for oc_block_3_fused in T.vectorized(T.int64(4)):
                            with T.block("conv2d_NCHWc_update"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                                v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(28) + oc_chunk_1 + oc_chunk_2 + oc_chunk_3)
                                v_oh = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(28) // T.int64(4) + oh_1 + oh_2 + oh_3)
                                v_ow = T.axis.spatial(T.int64(7), ow_1 + ow_2 + ow_3)
                                v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(4) * T.int64(8) + oc_block_1 * T.int64(8) + oc_block_2 * T.int64(4) + oc_block_3_fused)
                                v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(32) + ic_1)
                                v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                                v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                                T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                for ax4_fused in T.vectorized(T.int64(8)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(28) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(28) // T.int64(4) + ax2)
                        v_ax3 = T.axis.spatial(T.int64(7), ax3)
                        v_ax4 = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(4) * T.int64(8) + ax4_fused)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[16, 1, 1, 1])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[7, 1, 1, 1])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 7, 1, 1])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[4, 1, 2, 4])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[16, 32])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[1, 3])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=8)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85 = sch.get_loops(block=b69)
l86 = sch.fuse(l72, l73, l74, l75, l76, preserve_unit_iters=True)
sch.parallel(loop=l86)
l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107, l108 = sch.get_loops(block=b70)
l109 = sch.fuse(l87, preserve_unit_iters=True)
sch.parallel(loop=l109)
l110 = sch.fuse(l108, preserve_unit_iters=True)
sch.vectorize(loop=l110)
sch.annotate(block_or_loop=l109, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l109, ann_key="pragma_unroll_explicit", ann_val=1)
l111, l112, l113, l114, l115, l116 = sch.get_loops(block=b71)
l117 = sch.fuse(l116, preserve_unit_iters=True)
sch.vectorize(loop=l117)
b118 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140 = sch.get_loops(block=b118)
b141 = sch.decompose_reduction(block=b118, loop=l125)
2024-04-29 01:14:11 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 01:14:12 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-29 01:14:16 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f1e458)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x386def8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x36b1d38)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3108268)]: 0 failure(s)
2024-04-29 01:14:16 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-29 01:14:27 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f1e458)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x386def8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x36b1d38)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3108268)]: 0 failure(s)
2024-04-29 01:14:39 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f1e458)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x386def8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x36b1d38)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3108268)]: 0 failure(s)
2024-04-29 01:14:50 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f1e458)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x386def8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x36b1d38)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3108268)]: 0 failure(s)
2024-04-29 01:15:01 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f1e458)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x386def8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x36b1d38)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3108268)]: 0 failure(s)
2024-04-29 01:15:08 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.8940  0.8610  0.8610  0.8560  0.8560  0.8324  0.8295  0.8245  0.8245  0.8060  0.7903  0.7795  0.7693  0.7559  0.7552  0.7517
[17 : 32]:	0.7428  0.7422  0.7422  0.7414  0.7400  0.7392  0.7382  0.7331  0.7312  0.7280  0.7222  0.7221  0.7220  0.7105  0.7103  0.7103
[33 : 48]:	0.7042  0.7040  0.7040  0.7031  0.7012  0.6928  0.6928  0.6926  0.6919  0.6895  0.6762  0.6740  0.6717  0.6687  0.6687  0.6674
[49 : 64]:	0.6662  0.6653  0.6616  0.6598  0.6564  0.6557  0.6538  0.6494  0.6490  0.6396  0.6370  0.6255  0.6255  0.6255  0.6225  0.6206
2024-04-29 01:15:09 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 01:15:09 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 01:17:02 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #769: GFLOPs: 810.9787. Time: 285.1940 us. Best GFLOPs: 826.6082
2024-04-29 01:17:02 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #770: GFLOPs: 709.6627. Time: 325.9101 us. Best GFLOPs: 826.6082
2024-04-29 01:17:02 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #771: GFLOPs: 715.8131. Time: 323.1099 us. Best GFLOPs: 826.6082
2024-04-29 01:17:02 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #772: GFLOPs: 771.6629. Time: 299.7245 us. Best GFLOPs: 826.6082
2024-04-29 01:17:02 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #773: GFLOPs: 515.5936. Time: 448.5826 us. Best GFLOPs: 826.6082
2024-04-29 01:17:02 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #774: GFLOPs: 682.4333. Time: 338.9141 us. Best GFLOPs: 826.6082
2024-04-29 01:17:02 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #775: GFLOPs: 684.7367. Time: 337.7740 us. Best GFLOPs: 826.6082
2024-04-29 01:17:02 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #776: GFLOPs: 678.1267. Time: 341.0664 us. Best GFLOPs: 826.6082
2024-04-29 01:17:02 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #777: GFLOPs: 678.0377. Time: 341.1112 us. Best GFLOPs: 826.6082
2024-04-29 01:17:02 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #778: GFLOPs: 693.3858. Time: 333.5607 us. Best GFLOPs: 826.6082
2024-04-29 01:17:02 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #779: GFLOPs: 650.9076. Time: 355.3289 us. Best GFLOPs: 826.6082
2024-04-29 01:17:02 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #780: GFLOPs: 669.2534. Time: 345.5885 us. Best GFLOPs: 826.6082
2024-04-29 01:17:02 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #781: GFLOPs: 719.0198. Time: 321.6689 us. Best GFLOPs: 826.6082
2024-04-29 01:17:02 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #782: GFLOPs: 429.5432. Time: 538.4470 us. Best GFLOPs: 826.6082
2024-04-29 01:17:02 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #783: GFLOPs: 667.0257. Time: 346.7427 us. Best GFLOPs: 826.6082
2024-04-29 01:17:02 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #784: GFLOPs: 624.6450. Time: 370.2683 us. Best GFLOPs: 826.6082
2024-04-29 01:17:02 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #785: GFLOPs: 581.2216. Time: 397.9313 us. Best GFLOPs: 826.6082
2024-04-29 01:17:02 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #786: GFLOPs: 643.8111. Time: 359.2456 us. Best GFLOPs: 826.6082
2024-04-29 01:17:02 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #787: GFLOPs: 532.7104. Time: 434.1688 us. Best GFLOPs: 826.6082
2024-04-29 01:17:02 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #788: GFLOPs: 610.4511. Time: 378.8777 us. Best GFLOPs: 826.6082
2024-04-29 01:17:02 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #789: GFLOPs: 555.0500. Time: 416.6944 us. Best GFLOPs: 826.6082
2024-04-29 01:17:02 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #790: GFLOPs: 273.9503. Time: 844.2636 us. Best GFLOPs: 826.6082
2024-04-29 01:17:02 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #791: GFLOPs: 643.0720. Time: 359.6584 us. Best GFLOPs: 826.6082
2024-04-29 01:17:02 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #792: GFLOPs: 694.8142. Time: 332.8750 us. Best GFLOPs: 826.6082
2024-04-29 01:17:02 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #793: GFLOPs: 680.1017. Time: 340.0760 us. Best GFLOPs: 826.6082
2024-04-29 01:17:02 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #794: GFLOPs: 538.8002. Time: 429.2617 us. Best GFLOPs: 826.6082
2024-04-29 01:17:02 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #795: GFLOPs: 626.6308. Time: 369.0949 us. Best GFLOPs: 826.6082
2024-04-29 01:17:02 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #796: GFLOPs: 616.7594. Time: 375.0024 us. Best GFLOPs: 826.6082
2024-04-29 01:17:02 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #797: GFLOPs: 615.7511. Time: 375.6165 us. Best GFLOPs: 826.6082
2024-04-29 01:17:02 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #798: GFLOPs: 525.3461. Time: 440.2550 us. Best GFLOPs: 826.6082
2024-04-29 01:17:02 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #799: GFLOPs: 63.0555. Time: 3667.9778 us. Best GFLOPs: 826.6082
2024-04-29 01:17:02 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #800: GFLOPs: 60.4375. Time: 3826.8670 us. Best GFLOPs: 826.6082
2024-04-29 01:17:02 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #801: GFLOPs: 679.7752. Time: 340.2394 us. Best GFLOPs: 826.6082
2024-04-29 01:17:02 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #802: GFLOPs: 623.3647. Time: 371.0288 us. Best GFLOPs: 826.6082
2024-04-29 01:17:02 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #803: GFLOPs: 608.9266. Time: 379.8262 us. Best GFLOPs: 826.6082
2024-04-29 01:17:02 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #804: GFLOPs: 601.7629. Time: 384.3478 us. Best GFLOPs: 826.6082
2024-04-29 01:17:02 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #805: GFLOPs: 584.6725. Time: 395.5826 us. Best GFLOPs: 826.6082
2024-04-29 01:17:02 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #806: GFLOPs: 554.9330. Time: 416.7824 us. Best GFLOPs: 826.6082
2024-04-29 01:17:02 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #807: GFLOPs: 625.2626. Time: 369.9026 us. Best GFLOPs: 826.6082
2024-04-29 01:17:02 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #808: GFLOPs: 617.5756. Time: 374.5068 us. Best GFLOPs: 826.6082
2024-04-29 01:17:02 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #809: GFLOPs: 619.0013. Time: 373.6443 us. Best GFLOPs: 826.6082
2024-04-29 01:17:02 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #810: GFLOPs: 548.2038. Time: 421.8983 us. Best GFLOPs: 826.6082
2024-04-29 01:17:02 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #811: GFLOPs: 538.8300. Time: 429.2379 us. Best GFLOPs: 826.6082
2024-04-29 01:17:02 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #812: GFLOPs: 476.6351. Time: 485.2480 us. Best GFLOPs: 826.6082
2024-04-29 01:17:02 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #813: GFLOPs: 467.3457. Time: 494.8933 us. Best GFLOPs: 826.6082
2024-04-29 01:17:02 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #814: GFLOPs: 573.9633. Time: 402.9635 us. Best GFLOPs: 826.6082
2024-04-29 01:17:02 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #815: GFLOPs: 545.1905. Time: 424.2302 us. Best GFLOPs: 826.6082
2024-04-29 01:17:02 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #816: GFLOPs: 577.6825. Time: 400.3692 us. Best GFLOPs: 826.6082
2024-04-29 01:17:02 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #817: GFLOPs: 459.9623. Time: 502.8375 us. Best GFLOPs: 826.6082
2024-04-29 01:17:02 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #818: GFLOPs: 565.7645. Time: 408.8030 us. Best GFLOPs: 826.6082
2024-04-29 01:17:02 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #819: GFLOPs: 69.3672. Time: 3334.2305 us. Best GFLOPs: 826.6082
2024-04-29 01:17:02 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #820: GFLOPs: 453.4989. Time: 510.0041 us. Best GFLOPs: 826.6082
2024-04-29 01:17:02 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #821: GFLOPs: 552.4969. Time: 418.6200 us. Best GFLOPs: 826.6082
2024-04-29 01:17:02 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #822: GFLOPs: 502.9935. Time: 459.8196 us. Best GFLOPs: 826.6082
2024-04-29 01:17:02 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #823: GFLOPs: 523.1264. Time: 442.1231 us. Best GFLOPs: 826.6082
2024-04-29 01:17:02 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #824: GFLOPs: 548.2321. Time: 421.8766 us. Best GFLOPs: 826.6082
2024-04-29 01:17:02 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #825: GFLOPs: 677.3301. Time: 341.4676 us. Best GFLOPs: 826.6082
2024-04-29 01:17:02 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #826: GFLOPs: 526.5540. Time: 439.2452 us. Best GFLOPs: 826.6082
2024-04-29 01:17:02 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #827: GFLOPs: 415.3731. Time: 556.8157 us. Best GFLOPs: 826.6082
2024-04-29 01:17:02 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #828: GFLOPs: 519.0101. Time: 445.6296 us. Best GFLOPs: 826.6082
2024-04-29 01:17:02 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #829: GFLOPs: 506.7858. Time: 456.3788 us. Best GFLOPs: 826.6082
2024-04-29 01:17:02 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #830: GFLOPs: 35.3441. Time: 6543.8489 us. Best GFLOPs: 826.6082
2024-04-29 01:17:02 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #831: GFLOPs: 89.0971. Time: 2595.8898 us. Best GFLOPs: 826.6082
2024-04-29 01:17:02 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #832: GFLOPs: 14.5491. Time: 15896.9869 us. Best GFLOPs: 826.6082
2024-04-29 01:28:01 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 01:28:02 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-29 01:28:06 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f1e458)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x386def8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x36b1d38)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3108268)]: 0 failure(s)
2024-04-29 01:28:06 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-29 01:28:17 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f1e458)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x386def8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x36b1d38)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3108268)]: 0 failure(s)
2024-04-29 01:28:29 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f1e458)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x386def8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x36b1d38)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3108268)]: 0 failure(s)
2024-04-29 01:28:40 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f1e458)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x386def8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x36b1d38)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3108268)]: 0 failure(s)
2024-04-29 01:28:52 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f1e458)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x386def8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x36b1d38)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3108268)]: 0 failure(s)
2024-04-29 01:28:59 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9685  0.9685  0.9116  0.9116  0.9020  0.8933  0.8923  0.8745  0.8745  0.8479  0.8447  0.8447  0.8256  0.8149  0.8092  0.7895
[17 : 32]:	0.7890  0.7873  0.7754  0.7711  0.7547  0.7394  0.7394  0.7389  0.7365  0.7324  0.7264  0.7097  0.6947  0.6931  0.6921  0.6902
[33 : 48]:	0.6828  0.6778  0.6778  0.6597  0.6573  0.6573  0.6492  0.6421  0.6419  0.6406  0.6406  0.6342  0.6338  0.6213  0.6204  0.6161
[49 : 64]:	0.6117  0.6116  0.6116  0.6115  0.6091  0.6042  0.6040  0.6029  0.6025  0.6025  0.5983  0.5944  0.5900  0.5880  0.5874  0.5845
2024-04-29 01:28:59 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 01:28:59 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 01:30:58 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #833: GFLOPs: 776.7212. Time: 297.7726 us. Best GFLOPs: 826.6082
2024-04-29 01:30:58 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #834: GFLOPs: 816.4467. Time: 283.2840 us. Best GFLOPs: 826.6082
2024-04-29 01:30:58 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #835: GFLOPs: 757.4539. Time: 305.3470 us. Best GFLOPs: 826.6082
2024-04-29 01:30:58 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #836: GFLOPs: 757.3855. Time: 305.3746 us. Best GFLOPs: 826.6082
2024-04-29 01:30:58 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #837: GFLOPs: 758.7640. Time: 304.8198 us. Best GFLOPs: 826.6082
2024-04-29 01:30:58 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #838: GFLOPs: 751.1924. Time: 307.8922 us. Best GFLOPs: 826.6082
2024-04-29 01:30:58 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #839: GFLOPs: 724.5787. Time: 319.2010 us. Best GFLOPs: 826.6082
2024-04-29 01:30:58 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #840: GFLOPs: 776.0056. Time: 298.0472 us. Best GFLOPs: 826.6082
2024-04-29 01:30:58 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #841: GFLOPs: 715.8951. Time: 323.0729 us. Best GFLOPs: 826.6082
2024-04-29 01:30:58 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #842: GFLOPs: 680.9018. Time: 339.6764 us. Best GFLOPs: 826.6082
2024-04-29 01:30:58 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #843: GFLOPs: 751.7750. Time: 307.6536 us. Best GFLOPs: 826.6082
2024-04-29 01:30:58 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #844: GFLOPs: 735.7143. Time: 314.3697 us. Best GFLOPs: 826.6082
2024-04-29 01:30:58 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #845: GFLOPs: 712.7712. Time: 324.4888 us. Best GFLOPs: 826.6082
2024-04-29 01:30:58 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #846: GFLOPs: 702.3568. Time: 329.3002 us. Best GFLOPs: 826.6082
2024-04-29 01:30:58 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #847: GFLOPs: 613.8792. Time: 376.7619 us. Best GFLOPs: 826.6082
2024-04-29 01:30:58 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #848: GFLOPs: 651.1621. Time: 355.1900 us. Best GFLOPs: 826.6082
2024-04-29 01:30:58 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #849: GFLOPs: 656.9614. Time: 352.0546 us. Best GFLOPs: 826.6082
2024-04-29 01:30:58 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #850: GFLOPs: 683.6278. Time: 338.3219 us. Best GFLOPs: 826.6082
2024-04-29 01:30:58 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #851: GFLOPs: 360.8876. Time: 640.8818 us. Best GFLOPs: 826.6082
2024-04-29 01:30:58 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #852: GFLOPs: 664.3769. Time: 348.1251 us. Best GFLOPs: 826.6082
2024-04-29 01:30:58 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #853: GFLOPs: 687.2397. Time: 336.5438 us. Best GFLOPs: 826.6082
2024-04-29 01:30:58 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #854: GFLOPs: 612.3160. Time: 377.7237 us. Best GFLOPs: 826.6082
2024-04-29 01:30:58 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #855: GFLOPs: 643.1480. Time: 359.6160 us. Best GFLOPs: 826.6082
2024-04-29 01:30:58 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #856: GFLOPs: 333.5040. Time: 693.5038 us. Best GFLOPs: 826.6082
2024-04-29 01:30:58 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #857: GFLOPs: 591.7780. Time: 390.8328 us. Best GFLOPs: 826.6082
2024-04-29 01:30:58 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #858: GFLOPs: 576.6184. Time: 401.1081 us. Best GFLOPs: 826.6082
2024-04-29 01:30:58 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #859: GFLOPs: 557.2117. Time: 415.0779 us. Best GFLOPs: 826.6082
2024-04-29 01:30:58 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #860: GFLOPs: 552.9480. Time: 418.2786 us. Best GFLOPs: 826.6082
2024-04-29 01:30:58 [INFO] [task_scheduler.cc:121] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #861: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(7), T.int64(7), T.int64(512)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(32)), "float32"), p3: T.Buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(9), T.int64(9), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused in T.parallel(T.int64(112), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(3), T.int64(9), T.int64(512)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(9), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(16) + ax2)
                    v_i3, v_i4 = T.axis.remap("SS", [ax3, ax4])
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(8) and T.int64(1) <= v_i3 and v_i3 < T.int64(8), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(16) + oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(16) + oh_1 + oh_2_init + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(7), ow_1 * T.int64(7) + ow_2_init * T.int64(7) + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(256), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(32), T.int64(2), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(16) + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(16) + oh_1 + oh_2 + oh_3)
                        v_ow = T.axis.spatial(T.int64(7), ow_1 * T.int64(7) + ow_2 * T.int64(7) + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(2) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                    for ax4_fused in T.vectorized(T.int64(32)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(16) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(16) + ax2)
                            v_ax3, v_ax4 = T.axis.remap("SS", [ax3, ax4_fused])
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 16, 1, 1])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[7, 1, 1, 1])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 1, 7])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[1, 1, 32, 1])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[256, 2])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[1, 3])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l50, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=7)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=6)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83 = sch.get_loops(block=b69)
l84 = sch.fuse(l72, l73, l74, l75, l76, l77, l78, preserve_unit_iters=True)
sch.parallel(loop=l84)
l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b70)
l105 = sch.fuse(l85, preserve_unit_iters=True)
sch.parallel(loop=l105)
sch.annotate(block_or_loop=l105, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l105, ann_key="pragma_unroll_explicit", ann_val=1)
l106, l107, l108, l109, l110, l111, l112, l113, l114 = sch.get_loops(block=b71)
l115 = sch.fuse(l114, preserve_unit_iters=True)
sch.vectorize(loop=l115)
b116 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136 = sch.get_loops(block=b116)
b137 = sch.decompose_reduction(block=b116, loop=l121)
2024-04-29 01:30:58 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #862: GFLOPs: 669.0476. Time: 345.6948 us. Best GFLOPs: 826.6082
2024-04-29 01:30:58 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #863: GFLOPs: 324.7067. Time: 712.2930 us. Best GFLOPs: 826.6082
2024-04-29 01:30:58 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #864: GFLOPs: 553.1281. Time: 418.1424 us. Best GFLOPs: 826.6082
2024-04-29 01:30:58 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #865: GFLOPs: 576.9097. Time: 400.9055 us. Best GFLOPs: 826.6082
2024-04-29 01:30:58 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #866: GFLOPs: 567.6055. Time: 407.4771 us. Best GFLOPs: 826.6082
2024-04-29 01:30:58 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #867: GFLOPs: 573.1092. Time: 403.5640 us. Best GFLOPs: 826.6082
2024-04-29 01:30:58 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #868: GFLOPs: 540.9502. Time: 427.5556 us. Best GFLOPs: 826.6082
2024-04-29 01:30:58 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #869: GFLOPs: 523.9050. Time: 441.4661 us. Best GFLOPs: 826.6082
2024-04-29 01:30:58 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #870: GFLOPs: 553.3582. Time: 417.9684 us. Best GFLOPs: 826.6082
2024-04-29 01:30:58 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #871: GFLOPs: 547.8539. Time: 422.1678 us. Best GFLOPs: 826.6082
2024-04-29 01:30:58 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #872: GFLOPs: 534.3983. Time: 432.7975 us. Best GFLOPs: 826.6082
2024-04-29 01:30:58 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #873: GFLOPs: 532.7041. Time: 434.1740 us. Best GFLOPs: 826.6082
2024-04-29 01:30:58 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #874: GFLOPs: 476.1747. Time: 485.7173 us. Best GFLOPs: 826.6082
2024-04-29 01:30:59 [INFO] [task_scheduler.cc:121] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #875: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(7), T.int64(7), T.int64(512)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(32)), "float32"), p3: T.Buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(9), T.int64(9), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused in T.parallel(T.int64(112), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(3), T.int64(9), T.int64(512)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(9), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(16) + ax2)
                    v_i3, v_i4 = T.axis.remap("SS", [ax3, ax4])
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(8) and T.int64(1) <= v_i3 and v_i3 < T.int64(8), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(16) + oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(16) + oh_1 + oh_2_init + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(7), ow_1 * T.int64(7) + ow_2_init * T.int64(7) + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(512), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(16) + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(16) + oh_1 + oh_2 + oh_3)
                        v_ow = T.axis.spatial(T.int64(7), ow_1 * T.int64(7) + ow_2 * T.int64(7) + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(512), ic_0 + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                    for ax4_fused in T.vectorized(T.int64(32)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(16) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(16) + ax2)
                            v_ax3, v_ax4 = T.axis.remap("SS", [ax3, ax4_fused])
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 16, 1, 1])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[7, 1, 1, 1])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 1, 7])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[1, 1, 32, 1])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[512, 1])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[1, 3])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l50, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=7)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=6)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83 = sch.get_loops(block=b69)
l84 = sch.fuse(l72, l73, l74, l75, l76, l77, l78, preserve_unit_iters=True)
sch.parallel(loop=l84)
l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b70)
l105 = sch.fuse(l85, preserve_unit_iters=True)
sch.parallel(loop=l105)
sch.annotate(block_or_loop=l105, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l105, ann_key="pragma_unroll_explicit", ann_val=1)
l106, l107, l108, l109, l110, l111, l112, l113, l114 = sch.get_loops(block=b71)
l115 = sch.fuse(l114, preserve_unit_iters=True)
sch.vectorize(loop=l115)
b116 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136 = sch.get_loops(block=b116)
b137 = sch.decompose_reduction(block=b116, loop=l121)
2024-04-29 01:30:59 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #876: GFLOPs: 550.6490. Time: 420.0249 us. Best GFLOPs: 826.6082
2024-04-29 01:30:59 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #877: GFLOPs: 501.1079. Time: 461.5499 us. Best GFLOPs: 826.6082
2024-04-29 01:30:59 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #878: GFLOPs: 531.3162. Time: 435.3081 us. Best GFLOPs: 826.6082
2024-04-29 01:30:59 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #879: GFLOPs: 510.3965. Time: 453.1502 us. Best GFLOPs: 826.6082
2024-04-29 01:30:59 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #880: GFLOPs: 536.1813. Time: 431.3583 us. Best GFLOPs: 826.6082
2024-04-29 01:30:59 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #881: GFLOPs: 402.2502. Time: 574.9811 us. Best GFLOPs: 826.6082
2024-04-29 01:30:59 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #882: GFLOPs: 615.1271. Time: 375.9976 us. Best GFLOPs: 826.6082
2024-04-29 01:30:59 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #883: GFLOPs: 604.1872. Time: 382.8057 us. Best GFLOPs: 826.6082
2024-04-29 01:30:59 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #884: GFLOPs: 484.2126. Time: 477.6544 us. Best GFLOPs: 826.6082
2024-04-29 01:30:59 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #885: GFLOPs: 542.6275. Time: 426.2339 us. Best GFLOPs: 826.6082
2024-04-29 01:30:59 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #886: GFLOPs: 510.9019. Time: 452.7019 us. Best GFLOPs: 826.6082
2024-04-29 01:30:59 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #887: GFLOPs: 480.9031. Time: 480.9415 us. Best GFLOPs: 826.6082
2024-04-29 01:30:59 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #888: GFLOPs: 467.2046. Time: 495.0428 us. Best GFLOPs: 826.6082
2024-04-29 01:30:59 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #889: GFLOPs: 446.6900. Time: 517.7780 us. Best GFLOPs: 826.6082
2024-04-29 01:30:59 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #890: GFLOPs: 517.5232. Time: 446.9100 us. Best GFLOPs: 826.6082
2024-04-29 01:30:59 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #891: GFLOPs: 472.4604. Time: 489.5358 us. Best GFLOPs: 826.6082
2024-04-29 01:30:59 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #892: GFLOPs: 53.5585. Time: 4318.3887 us. Best GFLOPs: 826.6082
2024-04-29 01:30:59 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #893: GFLOPs: 544.7519. Time: 424.5718 us. Best GFLOPs: 826.6082
2024-04-29 01:30:59 [INFO] [task_scheduler.cc:121] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #894: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(7), T.int64(7), T.int64(512)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(32)), "float32"), p3: T.Buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(9), T.int64(9), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused in T.parallel(T.int64(448), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(3), T.int64(9), T.int64(512)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(9), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(64) + ax2)
                    v_i3, v_i4 = T.axis.remap("SS", [ax3, ax4])
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(8) and T.int64(1) <= v_i3 and v_i3 < T.int64(8), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(7)):
                for oc_block_3_fused_init in T.vectorized(T.int64(4)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(16) // T.int64(2) * T.int64(2) + oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(64) + oh_2_init + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(7), ow_2_init * T.int64(7) + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(64) // T.int64(16) * T.int64(8) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(2) * T.int64(4) + oc_block_2_init * T.int64(4) + oc_block_3_fused_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
            for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(64), T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(7)):
                for oc_block_3_fused in T.vectorized(T.int64(4)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(16) // T.int64(2) * T.int64(2) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(64) + oh_2 + oh_3)
                        v_ow = T.axis.spatial(T.int64(7), ow_2 * T.int64(7) + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(64) // T.int64(16) * T.int64(8) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(2) * T.int64(4) + oc_block_2 * T.int64(4) + oc_block_3_fused)
                        v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(8) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(7)):
                for ax4_fused in T.vectorized(T.int64(4)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(16) // T.int64(2) * T.int64(2) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(64) + ax2)
                        v_ax3 = T.axis.spatial(T.int64(7), ax3)
                        v_ax4 = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(64) // T.int64(16) * T.int64(8) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(2) * T.int64(4) + ax4_fused)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 8, 1, 2])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[7, 1, 1, 1])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 1, 7])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[4, 2, 1, 4])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[64, 8])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[3, 1])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l50, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=9)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86 = sch.get_loops(block=b69)
l87 = sch.fuse(l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, preserve_unit_iters=True)
sch.parallel(loop=l87)
l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b70)
l105 = sch.fuse(l88, preserve_unit_iters=True)
sch.parallel(loop=l105)
l106 = sch.fuse(l104, preserve_unit_iters=True)
sch.vectorize(loop=l106)
sch.annotate(block_or_loop=l105, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l105, ann_key="pragma_unroll_explicit", ann_val=1)
l107, l108, l109, l110, l111, l112 = sch.get_loops(block=b71)
l113 = sch.fuse(l112, preserve_unit_iters=True)
sch.vectorize(loop=l113)
b114 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131 = sch.get_loops(block=b114)
b132 = sch.decompose_reduction(block=b114, loop=l116)
2024-04-29 01:30:59 [INFO] [task_scheduler.cc:121] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #895: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(7), T.int64(7), T.int64(512)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(32)), "float32"), p3: T.Buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(9), T.int64(9), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)))
        for n_0 in T.serial(T.int64(1), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for oc_chunk_0, oh_0, ow_0, oc_block_0 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                for n_1, oc_chunk_1 in T.grid(T.int64(1), T.int64(4)):
                    for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(9), T.int64(9), T.int64(512)):
                        with T.block("data_pad"):
                            v_i0, v_i1, v_i2, v_i3, v_i4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                            T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                            T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                            data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(8) and T.int64(1) <= v_i3 and v_i3 < T.int64(8), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                    for oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(4)):
                        for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(8), T.int64(1), T.int64(4), T.int64(7), T.int64(1), T.int64(1)):
                            with T.block("conv2d_NCHWc_init"):
                                v_n = T.axis.spatial(T.int64(1), n_0 + n_1 + n_2_init + n_3_init)
                                v_oc_chunk = T.axis.spatial(T.int64(16), oc_chunk_0 * T.int64(16) + oc_chunk_1 * T.int64(4) + oc_chunk_2_init * T.int64(4) + oc_chunk_3_init)
                                v_oh = T.axis.spatial(T.int64(7), oh_0 * T.int64(7) + oh_1 * T.int64(7) + oh_2_init * T.int64(7) + oh_3_init)
                                v_ow = T.axis.spatial(T.int64(7), ow_0 * T.int64(7) + ow_1 * T.int64(7) + ow_2_init + ow_3_init)
                                v_oc_block = T.axis.spatial(T.int64(32), oc_block_0 * T.int64(32) + oc_block_1 * T.int64(8) + oc_block_2_init + oc_block_3_init)
                                T.reads()
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                        for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(256), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(8), T.int64(2), T.int64(3), T.int64(1), T.int64(1), T.int64(4), T.int64(7), T.int64(1), T.int64(1)):
                            with T.block("conv2d_NCHWc_update"):
                                v_n = T.axis.spatial(T.int64(1), n_0 + n_1 + n_2 + n_3)
                                v_oc_chunk = T.axis.spatial(T.int64(16), oc_chunk_0 * T.int64(16) + oc_chunk_1 * T.int64(4) + oc_chunk_2 * T.int64(4) + oc_chunk_3)
                                v_oh = T.axis.spatial(T.int64(7), oh_0 * T.int64(7) + oh_1 * T.int64(7) + oh_2 * T.int64(7) + oh_3)
                                v_ow = T.axis.spatial(T.int64(7), ow_0 * T.int64(7) + ow_1 * T.int64(7) + ow_2 + ow_3)
                                v_oc_block = T.axis.spatial(T.int64(32), oc_block_0 * T.int64(32) + oc_block_1 * T.int64(8) + oc_block_2 + oc_block_3)
                                v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(2) + ic_1)
                                v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                                v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                                T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(16), T.int64(7), T.int64(7)):
                    for ax4_fused in T.vectorized(T.int64(32)):
                        with T.block("T_relu"):
                            v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4_fused])
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 4, 1, 4])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 1, 7])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 7, 1])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[1, 4, 8, 1])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[256, 2])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[3, 1])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=6)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83 = sch.get_loops(block=b69)
l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107, l108, l109 = sch.get_loops(block=b70)
sch.annotate(block_or_loop=l84, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l84, ann_key="pragma_unroll_explicit", ann_val=1)
l110, l111, l112, l113, l114, l115, l116, l117, l118, l119 = sch.get_loops(block=b71)
l120 = sch.fuse(l119, preserve_unit_iters=True)
sch.vectorize(loop=l120)
b121 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141, l142, l143, l144, l145, l146, l147 = sch.get_loops(block=b121)
b148 = sch.decompose_reduction(block=b121, loop=l132)
2024-04-29 01:30:59 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #896: GFLOPs: 64.0202. Time: 3612.7055 us. Best GFLOPs: 826.6082
2024-04-29 01:41:56 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 01:41:57 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-29 01:42:01 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f1e458)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x386def8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x36b1d38)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3108268)]: 0 failure(s)
2024-04-29 01:42:01 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-29 01:42:13 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f1e458)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x386def8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x36b1d38)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3108268)]: 0 failure(s)
2024-04-29 01:42:24 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f1e458)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x386def8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x36b1d38)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3108268)]: 0 failure(s)
2024-04-29 01:42:36 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f1e458)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x386def8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x36b1d38)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3108268)]: 0 failure(s)
2024-04-29 01:42:48 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f1e458)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x386def8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x36b1d38)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3108268)]: 0 failure(s)
2024-04-29 01:42:55 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.8736  0.8736  0.8736  0.8695  0.8581  0.8358  0.8358  0.8020  0.7930  0.7930  0.7884  0.7647  0.7505  0.7450  0.7287  0.7217
[17 : 32]:	0.7188  0.7092  0.6923  0.6899  0.6828  0.6819  0.6791  0.6664  0.6664  0.6640  0.6327  0.6304  0.6184  0.6157  0.6157  0.6117
[33 : 48]:	0.6063  0.6022  0.6009  0.6001  0.5983  0.5856  0.5769  0.5767  0.5767  0.5767  0.5767  0.5765  0.5758  0.5752  0.5752  0.5752
[49 : 64]:	0.5743  0.5739  0.5735  0.5728  0.5720  0.5691  0.5668  0.5661  0.5642  0.5642  0.5642  0.5641  0.5641  0.5641  0.5639  0.5602
2024-04-29 01:42:55 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 01:42:55 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 01:44:55 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #897: GFLOPs: 717.0560. Time: 322.5498 us. Best GFLOPs: 826.6082
2024-04-29 01:44:55 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #898: GFLOPs: 743.7269. Time: 310.9828 us. Best GFLOPs: 826.6082
2024-04-29 01:44:55 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #899: GFLOPs: 741.2977. Time: 312.0019 us. Best GFLOPs: 826.6082
2024-04-29 01:44:55 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #900: GFLOPs: 719.2612. Time: 321.5609 us. Best GFLOPs: 826.6082
2024-04-29 01:44:55 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #901: GFLOPs: 699.6723. Time: 330.5637 us. Best GFLOPs: 826.6082
2024-04-29 01:44:55 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #902: GFLOPs: 371.8488. Time: 621.9901 us. Best GFLOPs: 826.6082
2024-04-29 01:44:55 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #903: GFLOPs: 695.0651. Time: 332.7548 us. Best GFLOPs: 826.6082
2024-04-29 01:44:55 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #904: GFLOPs: 637.4333. Time: 362.8400 us. Best GFLOPs: 826.6082
2024-04-29 01:44:55 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #905: GFLOPs: 669.7988. Time: 345.3071 us. Best GFLOPs: 826.6082
2024-04-29 01:44:55 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #906: GFLOPs: 669.7884. Time: 345.3124 us. Best GFLOPs: 826.6082
2024-04-29 01:44:55 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #907: GFLOPs: 639.4999. Time: 361.6674 us. Best GFLOPs: 826.6082
2024-04-29 01:44:55 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #908: GFLOPs: 649.1345. Time: 356.2995 us. Best GFLOPs: 826.6082
2024-04-29 01:44:55 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #909: GFLOPs: 595.9513. Time: 388.0959 us. Best GFLOPs: 826.6082
2024-04-29 01:44:55 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #910: GFLOPs: 620.4430. Time: 372.7760 us. Best GFLOPs: 826.6082
2024-04-29 01:44:55 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #911: GFLOPs: 629.3829. Time: 367.4810 us. Best GFLOPs: 826.6082
2024-04-29 01:44:55 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #912: GFLOPs: 551.3810. Time: 419.4673 us. Best GFLOPs: 826.6082
2024-04-29 01:44:55 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #913: GFLOPs: 585.7621. Time: 394.8467 us. Best GFLOPs: 826.6082
2024-04-29 01:44:55 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #914: GFLOPs: 542.3516. Time: 426.4508 us. Best GFLOPs: 826.6082
2024-04-29 01:44:55 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #915: GFLOPs: 495.2689. Time: 466.9914 us. Best GFLOPs: 826.6082
2024-04-29 01:44:55 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #916: GFLOPs: 664.2978. Time: 348.1665 us. Best GFLOPs: 826.6082
2024-04-29 01:44:55 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #917: GFLOPs: 555.5582. Time: 416.3133 us. Best GFLOPs: 826.6082
2024-04-29 01:44:55 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #918: GFLOPs: 580.2399. Time: 398.6045 us. Best GFLOPs: 826.6082
2024-04-29 01:44:55 [INFO] [task_scheduler.cc:121] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #919: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(7), T.int64(7), T.int64(512)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(32)), "float32"), p3: T.Buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(9), T.int64(9), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused in T.parallel(T.int64(112), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(9), T.int64(3), T.int64(512)):
                with T.block("data_pad"):
                    v_i0, v_i1, v_i2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                    v_i3 = T.axis.spatial(T.int64(9), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(56) // T.int64(8) + ax3)
                    v_i4 = T.axis.spatial(T.int64(512), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(8) and T.int64(1) <= v_i3 and v_i3 < T.int64(8), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(56) * T.int64(8) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(8) + oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(7), oh_1 * T.int64(7) + oh_2_init * T.int64(7) + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(56) // T.int64(8) + ow_1 + ow_2_init + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(128), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(32), T.int64(4), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(56) * T.int64(8) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(8) + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(7), oh_1 * T.int64(7) + oh_2 * T.int64(7) + oh_3)
                        v_ow = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(56) // T.int64(8) + ow_1 + ow_2 + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(4) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
                for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(1), T.int64(7)):
                    for ax3_ax4_fused in T.vectorized(T.int64(32)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(56) * T.int64(8) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(8) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(7), ax2)
                            v_ax3 = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(56) // T.int64(8))
                            v_ax4 = T.axis.spatial(T.int64(32), ax3_ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 8, 1, 1])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 1, 7])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[7, 1, 1, 1])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[1, 1, 32, 1])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[128, 4])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[3, 1])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l50, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=6)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83 = sch.get_loops(block=b69)
l84 = sch.fuse(l72, l73, l74, l75, l76, l77, l78, preserve_unit_iters=True)
sch.parallel(loop=l84)
l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b70)
l105 = sch.fuse(l85, preserve_unit_iters=True)
sch.parallel(loop=l105)
sch.annotate(block_or_loop=l105, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l105, ann_key="pragma_unroll_explicit", ann_val=1)
l106, l107, l108, l109, l110, l111, l112, l113, l114 = sch.get_loops(block=b71)
l115 = sch.fuse(l113, l114, preserve_unit_iters=True)
sch.vectorize(loop=l115)
b116 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136 = sch.get_loops(block=b116)
b137 = sch.decompose_reduction(block=b116, loop=l121)
2024-04-29 01:44:55 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #920: GFLOPs: 585.3509. Time: 395.1241 us. Best GFLOPs: 826.6082
2024-04-29 01:44:55 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #921: GFLOPs: 547.4641. Time: 422.4684 us. Best GFLOPs: 826.6082
2024-04-29 01:44:55 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #922: GFLOPs: 527.4921. Time: 438.4640 us. Best GFLOPs: 826.6082
2024-04-29 01:44:55 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #923: GFLOPs: 521.7288. Time: 443.3074 us. Best GFLOPs: 826.6082
2024-04-29 01:44:55 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #924: GFLOPs: 39.9717. Time: 5786.2467 us. Best GFLOPs: 826.6082
2024-04-29 01:44:55 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #925: GFLOPs: 458.3426. Time: 504.6144 us. Best GFLOPs: 826.6082
2024-04-29 01:44:55 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #926: GFLOPs: 469.4076. Time: 492.7195 us. Best GFLOPs: 826.6082
2024-04-29 01:44:55 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #927: GFLOPs: 324.5289. Time: 712.6831 us. Best GFLOPs: 826.6082
2024-04-29 01:44:55 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #928: GFLOPs: 417.4070. Time: 554.1026 us. Best GFLOPs: 826.6082
2024-04-29 01:44:55 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #929: GFLOPs: 537.7359. Time: 430.1113 us. Best GFLOPs: 826.6082
2024-04-29 01:44:55 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #930: GFLOPs: 473.9684. Time: 487.9783 us. Best GFLOPs: 826.6082
2024-04-29 01:44:55 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #931: GFLOPs: 434.2446. Time: 532.6175 us. Best GFLOPs: 826.6082
2024-04-29 01:44:55 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #932: GFLOPs: 181.8528. Time: 1271.8320 us. Best GFLOPs: 826.6082
2024-04-29 01:44:55 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #933: GFLOPs: 477.4825. Time: 484.3869 us. Best GFLOPs: 826.6082
2024-04-29 01:44:55 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #934: GFLOPs: 472.3773. Time: 489.6219 us. Best GFLOPs: 826.6082
2024-04-29 01:44:55 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #935: GFLOPs: 444.3967. Time: 520.4500 us. Best GFLOPs: 826.6082
2024-04-29 01:44:55 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #936: GFLOPs: 356.4103. Time: 648.9325 us. Best GFLOPs: 826.6082
2024-04-29 01:44:55 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #937: GFLOPs: 393.5433. Time: 587.7023 us. Best GFLOPs: 826.6082
2024-04-29 01:44:55 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #938: GFLOPs: 484.9257. Time: 476.9520 us. Best GFLOPs: 826.6082
2024-04-29 01:44:55 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #939: GFLOPs: 394.0908. Time: 586.8858 us. Best GFLOPs: 826.6082
2024-04-29 01:44:55 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #940: GFLOPs: 482.2007. Time: 479.6474 us. Best GFLOPs: 826.6082
2024-04-29 01:44:55 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #941: GFLOPs: 32.7886. Time: 7053.8535 us. Best GFLOPs: 826.6082
2024-04-29 01:44:55 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #942: GFLOPs: 473.4239. Time: 488.5395 us. Best GFLOPs: 826.6082
2024-04-29 01:44:55 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #943: GFLOPs: 269.1424. Time: 859.3454 us. Best GFLOPs: 826.6082
2024-04-29 01:44:55 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #944: GFLOPs: 475.7282. Time: 486.1731 us. Best GFLOPs: 826.6082
2024-04-29 01:44:55 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #945: GFLOPs: 40.3633. Time: 5730.1199 us. Best GFLOPs: 826.6082
2024-04-29 01:44:55 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #946: GFLOPs: 281.5891. Time: 821.3609 us. Best GFLOPs: 826.6082
2024-04-29 01:44:55 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #947: GFLOPs: 464.3482. Time: 498.0881 us. Best GFLOPs: 826.6082
2024-04-29 01:44:55 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #948: GFLOPs: 508.1126. Time: 455.1870 us. Best GFLOPs: 826.6082
2024-04-29 01:44:55 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #949: GFLOPs: 431.7812. Time: 535.6561 us. Best GFLOPs: 826.6082
2024-04-29 01:44:55 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #950: GFLOPs: 79.5890. Time: 2906.0075 us. Best GFLOPs: 826.6082
2024-04-29 01:44:55 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #951: GFLOPs: 433.5227. Time: 533.5044 us. Best GFLOPs: 826.6082
2024-04-29 01:44:55 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #952: GFLOPs: 486.3731. Time: 475.5326 us. Best GFLOPs: 826.6082
2024-04-29 01:44:55 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #953: GFLOPs: 459.7575. Time: 503.0615 us. Best GFLOPs: 826.6082
2024-04-29 01:44:55 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #954: GFLOPs: 455.3169. Time: 507.9677 us. Best GFLOPs: 826.6082
2024-04-29 01:44:55 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #955: GFLOPs: 460.6668. Time: 502.0685 us. Best GFLOPs: 826.6082
2024-04-29 01:44:55 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #956: GFLOPs: 457.7721. Time: 505.2433 us. Best GFLOPs: 826.6082
2024-04-29 01:44:55 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #957: GFLOPs: 448.4061. Time: 515.7964 us. Best GFLOPs: 826.6082
2024-04-29 01:44:55 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #958: GFLOPs: 61.4217. Time: 3765.5449 us. Best GFLOPs: 826.6082
2024-04-29 01:44:55 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #959: GFLOPs: 122.4774. Time: 1888.4003 us. Best GFLOPs: 826.6082
2024-04-29 01:44:55 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #960: GFLOPs: 30.0034. Time: 7708.6790 us. Best GFLOPs: 826.6082
2024-04-29 02:01:17 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 02:01:18 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-29 02:01:22 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f1e458)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x386def8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x36b1d38)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3108268)]: 0 failure(s)
2024-04-29 02:01:22 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-29 02:01:33 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f1e458)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x386def8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x36b1d38)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3108268)]: 0 failure(s)
2024-04-29 02:01:45 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f1e458)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x386def8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x36b1d38)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3108268)]: 0 failure(s)
2024-04-29 02:01:56 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f1e458)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x386def8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x36b1d38)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3108268)]: 0 failure(s)
2024-04-29 02:02:08 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f1e458)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x386def8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x36b1d38)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3108268)]: 0 failure(s)
2024-04-29 02:02:15 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.8858  0.8777  0.8497  0.8331  0.8215  0.8215  0.7881  0.7851  0.7816  0.7698  0.7698  0.7698  0.7615  0.7601  0.7601  0.7371
[17 : 32]:	0.7179  0.7009  0.7009  0.7009  0.7004  0.7004  0.6985  0.6909  0.6887  0.6879  0.6851  0.6795  0.6767  0.6747  0.6614  0.6551
[33 : 48]:	0.6469  0.6410  0.6392  0.6391  0.6369  0.6346  0.6346  0.6258  0.6114  0.6079  0.5949  0.5949  0.5949  0.5949  0.5936  0.5900
[49 : 64]:	0.5900  0.5877  0.5852  0.5841  0.5839  0.5806  0.5806  0.5791  0.5791  0.5787  0.5747  0.5727  0.5669  0.5669  0.5643  0.5627
2024-04-29 02:02:16 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 02:02:16 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 02:04:16 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #961: GFLOPs: 812.1078. Time: 284.7975 us. Best GFLOPs: 826.6082
2024-04-29 02:04:16 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #962: GFLOPs: 747.2925. Time: 309.4990 us. Best GFLOPs: 826.6082
2024-04-29 02:04:16 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #963: GFLOPs: 713.2339. Time: 324.2783 us. Best GFLOPs: 826.6082
2024-04-29 02:04:16 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #964: GFLOPs: 791.1371. Time: 292.3466 us. Best GFLOPs: 826.6082
2024-04-29 02:04:16 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #965: GFLOPs: 682.7358. Time: 338.7639 us. Best GFLOPs: 826.6082
2024-04-29 02:04:16 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #966: GFLOPs: 654.1764. Time: 353.5534 us. Best GFLOPs: 826.6082
2024-04-29 02:04:16 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #967: GFLOPs: 618.2992. Time: 374.0686 us. Best GFLOPs: 826.6082
2024-04-29 02:04:16 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #968: GFLOPs: 626.0821. Time: 369.4185 us. Best GFLOPs: 826.6082
2024-04-29 02:04:16 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #969: GFLOPs: 625.7824. Time: 369.5954 us. Best GFLOPs: 826.6082
2024-04-29 02:04:16 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #970: GFLOPs: 725.1647. Time: 318.9431 us. Best GFLOPs: 826.6082
2024-04-29 02:04:16 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #971: GFLOPs: 766.4864. Time: 301.7487 us. Best GFLOPs: 826.6082
2024-04-29 02:04:16 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #972: GFLOPs: 538.3874. Time: 429.5908 us. Best GFLOPs: 826.6082
2024-04-29 02:04:16 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #973: GFLOPs: 652.5592. Time: 354.4296 us. Best GFLOPs: 826.6082
2024-04-29 02:04:16 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #974: GFLOPs: 567.9834. Time: 407.2060 us. Best GFLOPs: 826.6082
2024-04-29 02:04:16 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #975: GFLOPs: 571.7658. Time: 404.5122 us. Best GFLOPs: 826.6082
2024-04-29 02:04:16 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #976: GFLOPs: 619.8577. Time: 373.1280 us. Best GFLOPs: 826.6082
2024-04-29 02:04:16 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #977: GFLOPs: 628.1124. Time: 368.2243 us. Best GFLOPs: 826.6082
2024-04-29 02:04:16 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #978: GFLOPs: 608.0000. Time: 380.4050 us. Best GFLOPs: 826.6082
2024-04-29 02:04:16 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #979: GFLOPs: 769.1737. Time: 300.6945 us. Best GFLOPs: 826.6082
2024-04-29 02:04:16 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #980: GFLOPs: 751.3124. Time: 307.8430 us. Best GFLOPs: 826.6082
2024-04-29 02:04:16 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #981: GFLOPs: 360.3735. Time: 641.7960 us. Best GFLOPs: 826.6082
2024-04-29 02:04:16 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #982: GFLOPs: 620.7991. Time: 372.5622 us. Best GFLOPs: 826.6082
2024-04-29 02:04:16 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #983: GFLOPs: 585.4124. Time: 395.0827 us. Best GFLOPs: 826.6082
2024-04-29 02:04:16 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #984: GFLOPs: 553.4838. Time: 417.8736 us. Best GFLOPs: 826.6082
2024-04-29 02:04:16 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #985: GFLOPs: 573.9047. Time: 403.0047 us. Best GFLOPs: 826.6082
2024-04-29 02:04:16 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #986: GFLOPs: 631.4055. Time: 366.3038 us. Best GFLOPs: 826.6082
2024-04-29 02:04:16 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #987: GFLOPs: 630.7594. Time: 366.6791 us. Best GFLOPs: 826.6082
2024-04-29 02:04:16 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #988: GFLOPs: 545.8286. Time: 423.7343 us. Best GFLOPs: 826.6082
2024-04-29 02:04:16 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #989: GFLOPs: 562.3574. Time: 411.2798 us. Best GFLOPs: 826.6082
2024-04-29 02:04:16 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #990: GFLOPs: 546.7939. Time: 422.9862 us. Best GFLOPs: 826.6082
2024-04-29 02:04:16 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #991: GFLOPs: 604.4067. Time: 382.6666 us. Best GFLOPs: 826.6082
2024-04-29 02:04:16 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #992: GFLOPs: 551.2105. Time: 419.5970 us. Best GFLOPs: 826.6082
2024-04-29 02:04:16 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #993: GFLOPs: 543.0110. Time: 425.9330 us. Best GFLOPs: 826.6082
2024-04-29 02:04:16 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #994: GFLOPs: 516.5755. Time: 447.7299 us. Best GFLOPs: 826.6082
2024-04-29 02:04:16 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #995: GFLOPs: 617.2375. Time: 374.7120 us. Best GFLOPs: 826.6082
2024-04-29 02:04:16 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #996: GFLOPs: 513.5408. Time: 450.3756 us. Best GFLOPs: 826.6082
2024-04-29 02:04:16 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #997: GFLOPs: 416.4489. Time: 555.3773 us. Best GFLOPs: 826.6082
2024-04-29 02:04:16 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #998: GFLOPs: 735.2387. Time: 314.5731 us. Best GFLOPs: 826.6082
2024-04-29 02:04:16 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #999: GFLOPs: 770.6333. Time: 300.1250 us. Best GFLOPs: 826.6082
2024-04-29 02:04:16 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1000: GFLOPs: 754.5259. Time: 306.5319 us. Best GFLOPs: 826.6082
2024-04-29 02:04:16 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1001: GFLOPs: 515.0213. Time: 449.0809 us. Best GFLOPs: 826.6082
2024-04-29 02:04:16 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1002: GFLOPs: 579.9564. Time: 398.7994 us. Best GFLOPs: 826.6082
2024-04-29 02:04:16 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1003: GFLOPs: 633.0679. Time: 365.3420 us. Best GFLOPs: 826.6082
2024-04-29 02:04:16 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1004: GFLOPs: 619.7405. Time: 373.1986 us. Best GFLOPs: 826.6082
2024-04-29 02:04:16 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1005: GFLOPs: 618.1189. Time: 374.1776 us. Best GFLOPs: 826.6082
2024-04-29 02:04:16 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1006: GFLOPs: 596.8866. Time: 387.4878 us. Best GFLOPs: 826.6082
2024-04-29 02:04:16 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1007: GFLOPs: 527.6460. Time: 438.3361 us. Best GFLOPs: 826.6082
2024-04-29 02:04:16 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1008: GFLOPs: 360.0146. Time: 642.4358 us. Best GFLOPs: 826.6082
2024-04-29 02:04:16 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1009: GFLOPs: 376.7473. Time: 613.9029 us. Best GFLOPs: 826.6082
2024-04-29 02:04:16 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1010: GFLOPs: 459.2138. Time: 503.6570 us. Best GFLOPs: 826.6082
2024-04-29 02:04:16 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1011: GFLOPs: 748.6728. Time: 308.9284 us. Best GFLOPs: 826.6082
2024-04-29 02:04:16 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1012: GFLOPs: 358.7273. Time: 644.7412 us. Best GFLOPs: 826.6082
2024-04-29 02:04:16 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1013: GFLOPs: 451.4813. Time: 512.2832 us. Best GFLOPs: 826.6082
2024-04-29 02:04:16 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1014: GFLOPs: 596.7848. Time: 387.5539 us. Best GFLOPs: 826.6082
2024-04-29 02:04:16 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1015: GFLOPs: 577.7611. Time: 400.3147 us. Best GFLOPs: 826.6082
2024-04-29 02:04:16 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1016: GFLOPs: 376.3261. Time: 614.5901 us. Best GFLOPs: 826.6082
2024-04-29 02:04:16 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1017: GFLOPs: 358.0377. Time: 645.9831 us. Best GFLOPs: 826.6082
2024-04-29 02:04:16 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1018: GFLOPs: 550.9622. Time: 419.7861 us. Best GFLOPs: 826.6082
2024-04-29 02:04:16 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1019: GFLOPs: 474.5257. Time: 487.4051 us. Best GFLOPs: 826.6082
2024-04-29 02:04:16 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1020: GFLOPs: 442.3742. Time: 522.8295 us. Best GFLOPs: 826.6082
2024-04-29 02:04:16 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1021: GFLOPs: 503.1058. Time: 459.7170 us. Best GFLOPs: 826.6082
2024-04-29 02:04:16 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1022: GFLOPs: 1.5890. Time: 145551.6270 us. Best GFLOPs: 826.6082
2024-04-29 02:04:16 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1023: GFLOPs: 6.6813. Time: 34616.7237 us. Best GFLOPs: 826.6082
2024-04-29 02:04:16 [INFO] [task_scheduler.cc:121] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1024: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(7), T.int64(7), T.int64(512)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(32)), "float32"), p3: T.Buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(9), T.int64(9), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)))
        for n_0_oc_chunk_0_fused_fused in T.parallel(T.int64(4), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(9), T.int64(9), T.int64(512)):
                with T.block("data_pad"):
                    v_i0, v_i1, v_i2, v_i3, v_i4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(8) and T.int64(1) <= v_i3 and v_i3 < T.int64(8), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oh_0, ow_0, oc_block_0 in T.grid(T.int64(1), T.int64(1), T.int64(16)):
                for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(4), T.int64(1), T.int64(7), T.int64(1)):
                    for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                        for oc_block_3_fused_init in T.vectorized(T.int64(2)):
                            with T.block("conv2d_NCHWc_init"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                                v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_fused_fused * T.int64(4) + oc_chunk_1 + oc_chunk_2_init + oc_chunk_3_init)
                                v_oh = T.axis.spatial(T.int64(7), oh_0 * T.int64(7) + oh_1 * T.int64(7) + oh_2_init + oh_3_init)
                                v_ow = T.axis.spatial(T.int64(7), ow_0 * T.int64(7) + ow_1 + ow_2_init + ow_3_init)
                                v_oc_block = T.axis.spatial(T.int64(32), oc_block_0 * T.int64(2) + oc_block_1 * T.int64(2) + oc_block_2_init * T.int64(2) + oc_block_3_fused_init)
                                T.reads()
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                    for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(128), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(1), T.int64(4), T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                        for oc_block_3_fused in T.vectorized(T.int64(2)):
                            with T.block("conv2d_NCHWc_update"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                                v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_fused_fused * T.int64(4) + oc_chunk_1 + oc_chunk_2 + oc_chunk_3)
                                v_oh = T.axis.spatial(T.int64(7), oh_0 * T.int64(7) + oh_1 * T.int64(7) + oh_2 + oh_3)
                                v_ow = T.axis.spatial(T.int64(7), ow_0 * T.int64(7) + ow_1 + ow_2 + ow_3)
                                v_oc_block = T.axis.spatial(T.int64(32), oc_block_0 * T.int64(2) + oc_block_1 * T.int64(2) + oc_block_2 * T.int64(2) + oc_block_3_fused)
                                v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(4) + ic_1)
                                v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                                v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                                T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(4), T.int64(7), T.int64(7)):
                    for ax4_fused in T.vectorized(T.int64(2)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_fused_fused * T.int64(4) + ax1)
                            v_ax2, v_ax3 = T.axis.remap("SS", [ax2, ax3])
                            v_ax4 = T.axis.spatial(T.int64(32), oc_block_0 * T.int64(2) + ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[4, 4, 1, 1])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 7, 1])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 7, 1, 1])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[16, 1, 1, 2])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[128, 4])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[1, 3])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=1)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78 = sch.get_loops(block=b69)
l79 = sch.fuse(l72, l73, preserve_unit_iters=True)
sch.parallel(loop=l79)
l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b70)
l105 = sch.fuse(l80, preserve_unit_iters=True)
sch.parallel(loop=l105)
l106 = sch.fuse(l104, preserve_unit_iters=True)
sch.vectorize(loop=l106)
sch.annotate(block_or_loop=l105, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l105, ann_key="pragma_unroll_explicit", ann_val=1)
l107, l108, l109, l110, l111, l112, l113, l114, l115 = sch.get_loops(block=b71)
l116 = sch.fuse(l115, preserve_unit_iters=True)
sch.vectorize(loop=l116)
b117 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141, l142 = sch.get_loops(block=b117)
b143 = sch.decompose_reduction(block=b117, loop=l127)
2024-04-29 02:23:21 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 02:23:23 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-29 02:23:27 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f1e458)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x386def8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x36b1d38)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3108268)]: 0 failure(s)
2024-04-29 02:23:27 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-29 02:23:38 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f1e458)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x386def8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x36b1d38)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3108268)]: 0 failure(s)
2024-04-29 02:23:49 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f1e458)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x386def8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x36b1d38)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3108268)]: 0 failure(s)
2024-04-29 02:24:01 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f1e458)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x386def8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x36b1d38)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3108268)]: 0 failure(s)
2024-04-29 02:24:13 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f1e458)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x386def8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x36b1d38)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3108268)]: 0 failure(s)
2024-04-29 02:24:20 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9641  0.9122  0.9122  0.8986  0.8926  0.8904  0.8624  0.8624  0.8588  0.8550  0.8486  0.8486  0.8313  0.7925  0.7898  0.7734
[17 : 32]:	0.7654  0.7646  0.7467  0.7418  0.7392  0.7343  0.7342  0.7325  0.7304  0.7266  0.7187  0.7148  0.7145  0.7119  0.7119  0.7107
[33 : 48]:	0.7107  0.7107  0.7062  0.7062  0.7062  0.7054  0.6923  0.6874  0.6852  0.6829  0.6823  0.6823  0.6783  0.6783  0.6783  0.6783
[49 : 64]:	0.6665  0.6610  0.6609  0.6609  0.6609  0.6578  0.6578  0.6524  0.6486  0.6450  0.6439  0.6315  0.6315  0.6315  0.6173  0.6173
2024-04-29 02:24:20 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 02:24:20 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 02:26:24 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1025: GFLOPs: 813.0355. Time: 284.4725 us. Best GFLOPs: 826.6082
2024-04-29 02:26:24 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1026: GFLOPs: 755.8019. Time: 306.0144 us. Best GFLOPs: 826.6082
2024-04-29 02:26:24 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1027: GFLOPs: 757.1605. Time: 305.4653 us. Best GFLOPs: 826.6082
2024-04-29 02:26:24 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1028: GFLOPs: 778.6194. Time: 297.0466 us. Best GFLOPs: 826.6082
2024-04-29 02:26:24 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1029: GFLOPs: 772.4835. Time: 299.4061 us. Best GFLOPs: 826.6082
2024-04-29 02:26:24 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1030: GFLOPs: 744.3982. Time: 310.7024 us. Best GFLOPs: 826.6082
2024-04-29 02:26:24 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1031: GFLOPs: 613.5521. Time: 376.9627 us. Best GFLOPs: 826.6082
2024-04-29 02:26:24 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1032: GFLOPs: 582.9219. Time: 396.7706 us. Best GFLOPs: 826.6082
2024-04-29 02:26:24 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1033: GFLOPs: 786.1545. Time: 294.1995 us. Best GFLOPs: 826.6082
2024-04-29 02:26:24 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1034: GFLOPs: 733.5821. Time: 315.2834 us. Best GFLOPs: 826.6082
2024-04-29 02:26:24 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1035: GFLOPs: 713.8949. Time: 323.9780 us. Best GFLOPs: 826.6082
2024-04-29 02:26:24 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1036: GFLOPs: 762.4506. Time: 303.3459 us. Best GFLOPs: 826.6082
2024-04-29 02:26:24 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1037: GFLOPs: 710.5158. Time: 325.5188 us. Best GFLOPs: 826.6082
2024-04-29 02:26:24 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1038: GFLOPs: 660.9050. Time: 349.9539 us. Best GFLOPs: 826.6082
2024-04-29 02:26:24 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1039: GFLOPs: 662.7594. Time: 348.9747 us. Best GFLOPs: 826.6082
2024-04-29 02:26:24 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1040: GFLOPs: 799.1643. Time: 289.4102 us. Best GFLOPs: 826.6082
2024-04-29 02:26:24 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1041: GFLOPs: 722.9321. Time: 319.9280 us. Best GFLOPs: 826.6082
2024-04-29 02:26:24 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1042: GFLOPs: 589.2731. Time: 392.4942 us. Best GFLOPs: 826.6082
2024-04-29 02:26:24 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1043: GFLOPs: 624.5577. Time: 370.3201 us. Best GFLOPs: 826.6082
2024-04-29 02:26:24 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1044: GFLOPs: 611.5860. Time: 378.1746 us. Best GFLOPs: 826.6082
2024-04-29 02:26:24 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1045: GFLOPs: 632.7772. Time: 365.5098 us. Best GFLOPs: 826.6082
2024-04-29 02:26:24 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1046: GFLOPs: 568.7774. Time: 406.6376 us. Best GFLOPs: 826.6082
2024-04-29 02:26:24 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1047: GFLOPs: 117.4858. Time: 1968.6325 us. Best GFLOPs: 826.6082
2024-04-29 02:26:24 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1048: GFLOPs: 330.5466. Time: 699.7084 us. Best GFLOPs: 826.6082
2024-04-29 02:26:24 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1049: GFLOPs: 587.1337. Time: 393.9244 us. Best GFLOPs: 826.6082
2024-04-29 02:26:24 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1050: GFLOPs: 643.0167. Time: 359.6894 us. Best GFLOPs: 826.6082
2024-04-29 02:26:24 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1051: GFLOPs: 592.0741. Time: 390.6374 us. Best GFLOPs: 826.6082
2024-04-29 02:26:24 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1052: GFLOPs: 688.5818. Time: 335.8879 us. Best GFLOPs: 826.6082
2024-04-29 02:26:24 [INFO] [task_scheduler.cc:121] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1053: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(7), T.int64(7), T.int64(512)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(32)), "float32"), p3: T.Buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(9), T.int64(9), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused in T.parallel(T.int64(112), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(9), T.int64(3), T.int64(512)):
                with T.block("data_pad"):
                    v_i0, v_i1, v_i2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                    v_i3 = T.axis.spatial(T.int64(9), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(16) + ax3)
                    v_i4 = T.axis.spatial(T.int64(512), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(8) and T.int64(1) <= v_i3 and v_i3 < T.int64(8), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(16) + oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(7), oh_1 * T.int64(7) + oh_2_init * T.int64(7) + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(16) + ow_1 + ow_2_init + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(128), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(32), T.int64(4), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(16) + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(7), oh_1 * T.int64(7) + oh_2 * T.int64(7) + oh_3)
                        v_ow = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(16) + ow_1 + ow_2 + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(4) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
                for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(1), T.int64(7)):
                    for ax3_ax4_fused in T.vectorized(T.int64(32)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(16) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(7), ax2)
                            v_ax3 = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(16))
                            v_ax4 = T.axis.spatial(T.int64(32), ax3_ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 16, 1, 1])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 1, 7])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[7, 1, 1, 1])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[1, 1, 32, 1])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[128, 4])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[3, 1])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l50, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=14)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=6)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83 = sch.get_loops(block=b69)
l84 = sch.fuse(l72, l73, l74, l75, l76, l77, l78, preserve_unit_iters=True)
sch.parallel(loop=l84)
l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b70)
l105 = sch.fuse(l85, preserve_unit_iters=True)
sch.parallel(loop=l105)
sch.annotate(block_or_loop=l105, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l105, ann_key="pragma_unroll_explicit", ann_val=1)
l106, l107, l108, l109, l110, l111, l112, l113, l114 = sch.get_loops(block=b71)
l115 = sch.fuse(l113, l114, preserve_unit_iters=True)
sch.vectorize(loop=l115)
b116 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136 = sch.get_loops(block=b116)
b137 = sch.decompose_reduction(block=b116, loop=l121)
2024-04-29 02:26:24 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1054: GFLOPs: 549.1119. Time: 421.2006 us. Best GFLOPs: 826.6082
2024-04-29 02:26:24 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1055: GFLOPs: 665.6593. Time: 347.4544 us. Best GFLOPs: 826.6082
2024-04-29 02:26:24 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1056: GFLOPs: 626.3641. Time: 369.2521 us. Best GFLOPs: 826.6082
2024-04-29 02:26:24 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1057: GFLOPs: 531.9080. Time: 434.8238 us. Best GFLOPs: 826.6082
2024-04-29 02:26:24 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1058: GFLOPs: 629.0885. Time: 367.6530 us. Best GFLOPs: 826.6082
2024-04-29 02:26:24 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1059: GFLOPs: 407.7846. Time: 567.1776 us. Best GFLOPs: 826.6082
2024-04-29 02:26:24 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1060: GFLOPs: 546.8257. Time: 422.9616 us. Best GFLOPs: 826.6082
2024-04-29 02:26:24 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1061: GFLOPs: 549.6273. Time: 420.8056 us. Best GFLOPs: 826.6082
2024-04-29 02:26:24 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1062: GFLOPs: 563.7393. Time: 410.2717 us. Best GFLOPs: 826.6082
2024-04-29 02:26:24 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1063: GFLOPs: 565.1061. Time: 409.2794 us. Best GFLOPs: 826.6082
2024-04-29 02:26:24 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1064: GFLOPs: 554.4080. Time: 417.1770 us. Best GFLOPs: 826.6082
2024-04-29 02:26:24 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1065: GFLOPs: 537.8772. Time: 429.9983 us. Best GFLOPs: 826.6082
2024-04-29 02:26:24 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1066: GFLOPs: 574.7092. Time: 402.4405 us. Best GFLOPs: 826.6082
2024-04-29 02:26:24 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1067: GFLOPs: 578.2918. Time: 399.9473 us. Best GFLOPs: 826.6082
2024-04-29 02:26:24 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1068: GFLOPs: 580.2824. Time: 398.5754 us. Best GFLOPs: 826.6082
2024-04-29 02:26:24 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1069: GFLOPs: 453.9080. Time: 509.5444 us. Best GFLOPs: 826.6082
2024-04-29 02:26:24 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1070: GFLOPs: 451.9339. Time: 511.7702 us. Best GFLOPs: 826.6082
2024-04-29 02:26:24 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1071: GFLOPs: 427.0662. Time: 541.5701 us. Best GFLOPs: 826.6082
2024-04-29 02:26:24 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1072: GFLOPs: 438.8226. Time: 527.0610 us. Best GFLOPs: 826.6082
2024-04-29 02:26:24 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1073: GFLOPs: 519.6523. Time: 445.0789 us. Best GFLOPs: 826.6082
2024-04-29 02:26:24 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1074: GFLOPs: 527.5674. Time: 438.4013 us. Best GFLOPs: 826.6082
2024-04-29 02:26:24 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1075: GFLOPs: 558.1221. Time: 414.4008 us. Best GFLOPs: 826.6082
2024-04-29 02:26:24 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1076: GFLOPs: 551.3816. Time: 419.4668 us. Best GFLOPs: 826.6082
2024-04-29 02:26:24 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1077: GFLOPs: 552.7535. Time: 418.4257 us. Best GFLOPs: 826.6082
2024-04-29 02:26:24 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1078: GFLOPs: 625.2048. Time: 369.9368 us. Best GFLOPs: 826.6082
2024-04-29 02:26:24 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1079: GFLOPs: 708.9343. Time: 326.2450 us. Best GFLOPs: 826.6082
2024-04-29 02:26:24 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1080: GFLOPs: 567.6065. Time: 407.4764 us. Best GFLOPs: 826.6082
2024-04-29 02:26:24 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1081: GFLOPs: 541.3343. Time: 427.2522 us. Best GFLOPs: 826.6082
2024-04-29 02:26:24 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1082: GFLOPs: 583.2747. Time: 396.5306 us. Best GFLOPs: 826.6082
2024-04-29 02:26:24 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1083: GFLOPs: 727.1551. Time: 318.0701 us. Best GFLOPs: 826.6082
2024-04-29 02:26:24 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1084: GFLOPs: 576.2683. Time: 401.3517 us. Best GFLOPs: 826.6082
2024-04-29 02:26:24 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1085: GFLOPs: 478.0798. Time: 483.7817 us. Best GFLOPs: 826.6082
2024-04-29 02:26:24 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1086: GFLOPs: 6.0608. Time: 38160.7770 us. Best GFLOPs: 826.6082
2024-04-29 02:26:24 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1087: GFLOPs: 27.1693. Time: 8512.7897 us. Best GFLOPs: 826.6082
2024-04-29 02:26:24 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1088: GFLOPs: 12.8465. Time: 18003.8532 us. Best GFLOPs: 826.6082
2024-04-29 02:37:35 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 02:37:36 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-29 02:37:40 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f1e458)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x386def8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x36b1d38)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3108268)]: 0 failure(s)
2024-04-29 02:37:40 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-29 02:37:51 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f1e458)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x386def8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x36b1d38)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3108268)]: 0 failure(s)
2024-04-29 02:38:03 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f1e458)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x386def8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x36b1d38)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3108268)]: 0 failure(s)
2024-04-29 02:38:15 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f1e458)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x386def8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x36b1d38)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3108268)]: 0 failure(s)
2024-04-29 02:38:27 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f1e458)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x386def8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x36b1d38)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3108268)]: 0 failure(s)
2024-04-29 02:38:34 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9734  0.9191  0.9183  0.9132  0.9109  0.9071  0.8959  0.8945  0.8521  0.8364  0.8364  0.8364  0.8364  0.8364  0.8364  0.8303
[17 : 32]:	0.8303  0.8303  0.8286  0.8286  0.8244  0.8244  0.8167  0.8164  0.8139  0.7849  0.7849  0.7829  0.7829  0.7737  0.7684  0.7651
[33 : 48]:	0.7612  0.7468  0.7255  0.7224  0.7200  0.7124  0.7110  0.7080  0.7031  0.7031  0.7027  0.7000  0.7000  0.6993  0.6993  0.6962
[49 : 64]:	0.6913  0.6874  0.6864  0.6793  0.6784  0.6775  0.6737  0.6721  0.6707  0.6667  0.6620  0.6589  0.6444  0.6421  0.6421  0.6389
2024-04-29 02:38:34 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 02:38:35 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 02:40:40 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1089: GFLOPs: 764.6380. Time: 302.4781 us. Best GFLOPs: 826.6082
2024-04-29 02:40:40 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1090: GFLOPs: 800.0661. Time: 289.0840 us. Best GFLOPs: 826.6082
2024-04-29 02:40:40 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1091: GFLOPs: 758.6651. Time: 304.8595 us. Best GFLOPs: 826.6082
2024-04-29 02:40:40 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1092: GFLOPs: 756.2048. Time: 305.8513 us. Best GFLOPs: 826.6082
2024-04-29 02:40:40 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1093: GFLOPs: 762.6354. Time: 303.2724 us. Best GFLOPs: 826.6082
2024-04-29 02:40:40 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1094: GFLOPs: 703.1452. Time: 328.9310 us. Best GFLOPs: 826.6082
2024-04-29 02:40:40 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1095: GFLOPs: 722.8487. Time: 319.9650 us. Best GFLOPs: 826.6082
2024-04-29 02:40:40 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1096: GFLOPs: 740.1691. Time: 312.4776 us. Best GFLOPs: 826.6082
2024-04-29 02:40:40 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1097: GFLOPs: 793.5672. Time: 291.4514 us. Best GFLOPs: 826.6082
2024-04-29 02:40:40 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1098: GFLOPs: 718.4752. Time: 321.9127 us. Best GFLOPs: 826.6082
2024-04-29 02:40:40 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1099: GFLOPs: 726.7644. Time: 318.2410 us. Best GFLOPs: 826.6082
2024-04-29 02:40:40 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1100: GFLOPs: 738.5797. Time: 313.1500 us. Best GFLOPs: 826.6082
2024-04-29 02:40:40 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1101: GFLOPs: 718.5816. Time: 321.8650 us. Best GFLOPs: 826.6082
2024-04-29 02:40:40 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1102: GFLOPs: 739.7729. Time: 312.6449 us. Best GFLOPs: 826.6082
2024-04-29 02:40:40 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1103: GFLOPs: 722.4506. Time: 320.1413 us. Best GFLOPs: 826.6082
2024-04-29 02:40:40 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1104: GFLOPs: 748.3648. Time: 309.0555 us. Best GFLOPs: 826.6082
2024-04-29 02:40:40 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1105: GFLOPs: 580.7529. Time: 398.2525 us. Best GFLOPs: 826.6082
2024-04-29 02:40:40 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1106: GFLOPs: 764.7319. Time: 302.4410 us. Best GFLOPs: 826.6082
2024-04-29 02:40:40 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1107: GFLOPs: 749.0257. Time: 308.7828 us. Best GFLOPs: 826.6082
2024-04-29 02:40:40 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1108: GFLOPs: 766.2809. Time: 301.8296 us. Best GFLOPs: 826.6082
2024-04-29 02:40:40 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1109: GFLOPs: 716.2119. Time: 322.9299 us. Best GFLOPs: 826.6082
2024-04-29 02:40:40 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1110: GFLOPs: 738.7002. Time: 313.0990 us. Best GFLOPs: 826.6082
2024-04-29 02:40:40 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1111: GFLOPs: 621.9121. Time: 371.8954 us. Best GFLOPs: 826.6082
2024-04-29 02:40:40 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1112: GFLOPs: 702.1319. Time: 329.4057 us. Best GFLOPs: 826.6082
2024-04-29 02:40:40 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1113: GFLOPs: 722.7191. Time: 320.0224 us. Best GFLOPs: 826.6082
2024-04-29 02:40:40 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1114: GFLOPs: 636.3727. Time: 363.4447 us. Best GFLOPs: 826.6082
2024-04-29 02:40:40 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1115: GFLOPs: 647.0538. Time: 357.4452 us. Best GFLOPs: 826.6082
2024-04-29 02:40:40 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1116: GFLOPs: 641.4713. Time: 360.5559 us. Best GFLOPs: 826.6082
2024-04-29 02:40:40 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1117: GFLOPs: 795.5607. Time: 290.7211 us. Best GFLOPs: 826.6082
2024-04-29 02:40:40 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1118: GFLOPs: 633.7355. Time: 364.9571 us. Best GFLOPs: 826.6082
2024-04-29 02:40:40 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1119: GFLOPs: 665.4264. Time: 347.5760 us. Best GFLOPs: 826.6082
2024-04-29 02:40:40 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1120: GFLOPs: 682.0306. Time: 339.1142 us. Best GFLOPs: 826.6082
2024-04-29 02:40:40 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1121: GFLOPs: 350.3446. Time: 660.1679 us. Best GFLOPs: 826.6082
2024-04-29 02:40:40 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1122: GFLOPs: 582.7731. Time: 396.8719 us. Best GFLOPs: 826.6082
2024-04-29 02:40:40 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1123: GFLOPs: 659.3651. Time: 350.7712 us. Best GFLOPs: 826.6082
2024-04-29 02:40:40 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1124: GFLOPs: 640.4492. Time: 361.1314 us. Best GFLOPs: 826.6082
2024-04-29 02:40:40 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1125: GFLOPs: 565.4941. Time: 408.9986 us. Best GFLOPs: 826.6082
2024-04-29 02:40:40 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1126: GFLOPs: 594.2570. Time: 389.2024 us. Best GFLOPs: 826.6082
2024-04-29 02:40:40 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1127: GFLOPs: 565.1862. Time: 409.2214 us. Best GFLOPs: 826.6082
2024-04-29 02:40:40 [INFO] [task_scheduler.cc:121] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1128: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(7), T.int64(7), T.int64(512)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(32)), "float32"), p3: T.Buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(9), T.int64(9), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_fused_fused in T.parallel(T.int64(112), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(9), T.int64(3), T.int64(512)):
                with T.block("data_pad"):
                    v_i0, v_i1, v_i2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                    v_i3 = T.axis.spatial(T.int64(9), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(7) + ax3)
                    v_i4 = T.axis.spatial(T.int64(512), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(8) and T.int64(1) <= v_i3 and v_i3 < T.int64(8), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oc_block_0, n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(7) + oc_chunk_1 + oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(7), oh_1 * T.int64(7) + oh_2_init * T.int64(7) + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(7) + ow_1 + ow_2_init + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_0 * T.int64(32) + oc_block_1 * T.int64(32) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(128), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(32), T.int64(4), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(7) + oc_chunk_1 + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(7), oh_1 * T.int64(7) + oh_2 * T.int64(7) + oh_3)
                        v_ow = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(7) + ow_1 + ow_2 + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_0 * T.int64(32) + oc_block_1 * T.int64(32) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(4) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
                for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(1), T.int64(7)):
                    for ax3_ax4_fused in T.vectorized(T.int64(32)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(7) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(7), ax2)
                            v_ax3 = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(7))
                            v_ax4 = T.axis.spatial(T.int64(32), ax3_ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[16, 1, 1, 1])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 1, 7])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[7, 1, 1, 1])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[1, 1, 32, 1])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[128, 4])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[3, 1])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l50, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=3)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79, l80 = sch.get_loops(block=b69)
l81 = sch.fuse(l72, l73, l74, l75, preserve_unit_iters=True)
sch.parallel(loop=l81)
l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b70)
l105 = sch.fuse(l82, preserve_unit_iters=True)
sch.parallel(loop=l105)
sch.annotate(block_or_loop=l105, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l105, ann_key="pragma_unroll_explicit", ann_val=1)
l106, l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117 = sch.get_loops(block=b71)
l118 = sch.fuse(l116, l117, preserve_unit_iters=True)
sch.vectorize(loop=l118)
b119 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141, l142 = sch.get_loops(block=b119)
b143 = sch.decompose_reduction(block=b119, loop=l127)
2024-04-29 02:40:40 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1129: GFLOPs: 588.3389. Time: 393.1174 us. Best GFLOPs: 826.6082
2024-04-29 02:40:40 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1130: GFLOPs: 636.3697. Time: 363.4464 us. Best GFLOPs: 826.6082
2024-04-29 02:40:40 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1131: GFLOPs: 572.9555. Time: 403.6723 us. Best GFLOPs: 826.6082
2024-04-29 02:40:40 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1132: GFLOPs: 584.6298. Time: 395.6115 us. Best GFLOPs: 826.6082
2024-04-29 02:40:40 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1133: GFLOPs: 584.2432. Time: 395.8733 us. Best GFLOPs: 826.6082
2024-04-29 02:40:40 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1134: GFLOPs: 618.3664. Time: 374.0279 us. Best GFLOPs: 826.6082
2024-04-29 02:40:40 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1135: GFLOPs: 600.7608. Time: 384.9890 us. Best GFLOPs: 826.6082
2024-04-29 02:40:40 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1136: GFLOPs: 484.8200. Time: 477.0560 us. Best GFLOPs: 826.6082
2024-04-29 02:40:40 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1137: GFLOPs: 551.9769. Time: 419.0144 us. Best GFLOPs: 826.6082
2024-04-29 02:40:40 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1138: GFLOPs: 261.7272. Time: 883.6921 us. Best GFLOPs: 826.6082
2024-04-29 02:40:40 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1139: GFLOPs: 617.1920. Time: 374.7396 us. Best GFLOPs: 826.6082
2024-04-29 02:40:40 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1140: GFLOPs: 561.0006. Time: 412.2745 us. Best GFLOPs: 826.6082
2024-04-29 02:40:40 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1141: GFLOPs: 279.1706. Time: 828.4764 us. Best GFLOPs: 826.6082
2024-04-29 02:40:40 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1142: GFLOPs: 574.6488. Time: 402.4828 us. Best GFLOPs: 826.6082
2024-04-29 02:40:40 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1143: GFLOPs: 611.6892. Time: 378.1107 us. Best GFLOPs: 826.6082
2024-04-29 02:40:40 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1144: GFLOPs: 554.6965. Time: 416.9600 us. Best GFLOPs: 826.6082
2024-04-29 02:40:40 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1145: GFLOPs: 555.5761. Time: 416.2999 us. Best GFLOPs: 826.6082
2024-04-29 02:40:40 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1146: GFLOPs: 556.8747. Time: 415.3291 us. Best GFLOPs: 826.6082
2024-04-29 02:40:40 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1147: GFLOPs: 597.3679. Time: 387.1756 us. Best GFLOPs: 826.6082
2024-04-29 02:40:40 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1148: GFLOPs: 575.1185. Time: 402.1541 us. Best GFLOPs: 826.6082
2024-04-29 02:40:40 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1149: GFLOPs: 542.0195. Time: 426.7121 us. Best GFLOPs: 826.6082
2024-04-29 02:40:40 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1150: GFLOPs: 34.0036. Time: 6801.8190 us. Best GFLOPs: 826.6082
2024-04-29 02:40:40 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1151: GFLOPs: 4.4019. Time: 52542.1863 us. Best GFLOPs: 826.6082
2024-04-29 02:40:40 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1152: GFLOPs: 5.7740. Time: 40056.4587 us. Best GFLOPs: 826.6082
2024-04-29 02:54:20 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 02:54:21 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-29 02:54:25 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f1e458)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x386def8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x36b1d38)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3108268)]: 0 failure(s)
2024-04-29 02:54:25 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-29 02:54:36 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f1e458)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x386def8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x36b1d38)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3108268)]: 0 failure(s)
2024-04-29 02:54:48 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f1e458)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x386def8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x36b1d38)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3108268)]: 0 failure(s)
2024-04-29 02:55:00 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f1e458)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x386def8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x36b1d38)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3108268)]: 0 failure(s)
2024-04-29 02:55:12 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f1e458)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x386def8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x36b1d38)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3108268)]: 0 failure(s)
2024-04-29 02:55:19 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9079  0.9026  0.8713  0.8713  0.8581  0.8581  0.8581  0.8542  0.8518  0.8473  0.8373  0.8336  0.8242  0.8199  0.8199  0.8137
[17 : 32]:	0.7644  0.7555  0.7532  0.7510  0.7455  0.7382  0.7320  0.7157  0.7155  0.7155  0.7141  0.7141  0.7106  0.7106  0.7062  0.7060
[33 : 48]:	0.7047  0.7007  0.6985  0.6985  0.6904  0.6883  0.6861  0.6834  0.6813  0.6802  0.6766  0.6731  0.6731  0.6731  0.6695  0.6695
[49 : 64]:	0.6691  0.6672  0.6628  0.6625  0.6464  0.6464  0.6310  0.6310  0.6269  0.6269  0.6269  0.6269  0.6259  0.6169  0.6161  0.6161
2024-04-29 02:55:19 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 02:55:19 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 02:57:23 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1153: GFLOPs: 778.2721. Time: 297.1792 us. Best GFLOPs: 826.6082
2024-04-29 02:57:23 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1154: GFLOPs: 753.4419. Time: 306.9729 us. Best GFLOPs: 826.6082
2024-04-29 02:57:23 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1155: GFLOPs: 712.9824. Time: 324.3927 us. Best GFLOPs: 826.6082
2024-04-29 02:57:23 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1156: GFLOPs: 724.0310. Time: 319.4425 us. Best GFLOPs: 826.6082
2024-04-29 02:57:23 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1157: GFLOPs: 707.4224. Time: 326.9422 us. Best GFLOPs: 826.6082
2024-04-29 02:57:23 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1158: GFLOPs: 457.5263. Time: 505.5147 us. Best GFLOPs: 826.6082
2024-04-29 02:57:23 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1159: GFLOPs: 772.9506. Time: 299.2252 us. Best GFLOPs: 826.6082
2024-04-29 02:57:23 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1160: GFLOPs: 690.8723. Time: 334.7743 us. Best GFLOPs: 826.6082
2024-04-29 02:57:23 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1161: GFLOPs: 364.0646. Time: 635.2891 us. Best GFLOPs: 826.6082
2024-04-29 02:57:23 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1162: GFLOPs: 774.1820. Time: 298.7492 us. Best GFLOPs: 826.6082
2024-04-29 02:57:23 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1163: GFLOPs: 633.9093. Time: 364.8570 us. Best GFLOPs: 826.6082
2024-04-29 02:57:23 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1164: GFLOPs: 631.7987. Time: 366.0759 us. Best GFLOPs: 826.6082
2024-04-29 02:57:23 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1165: GFLOPs: 752.3629. Time: 307.4132 us. Best GFLOPs: 826.6082
2024-04-29 02:57:23 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1166: GFLOPs: 758.1460. Time: 305.0683 us. Best GFLOPs: 826.6082
2024-04-29 02:57:23 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1167: GFLOPs: 796.8574. Time: 290.2480 us. Best GFLOPs: 826.6082
2024-04-29 02:57:23 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1168: GFLOPs: 668.7557. Time: 345.8457 us. Best GFLOPs: 826.6082
2024-04-29 02:57:23 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1169: GFLOPs: 626.4939. Time: 369.1756 us. Best GFLOPs: 826.6082
2024-04-29 02:57:23 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1170: GFLOPs: 612.4967. Time: 377.6122 us. Best GFLOPs: 826.6082
2024-04-29 02:57:23 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1171: GFLOPs: 609.5741. Time: 379.4228 us. Best GFLOPs: 826.6082
2024-04-29 02:57:23 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1172: GFLOPs: 662.3580. Time: 349.1862 us. Best GFLOPs: 826.6082
2024-04-29 02:57:23 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1173: GFLOPs: 618.3680. Time: 374.0269 us. Best GFLOPs: 826.6082
2024-04-29 02:57:23 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1174: GFLOPs: 605.1191. Time: 382.2161 us. Best GFLOPs: 826.6082
2024-04-29 02:57:23 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1175: GFLOPs: 589.5492. Time: 392.3104 us. Best GFLOPs: 826.6082
2024-04-29 02:57:23 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1176: GFLOPs: 578.1489. Time: 400.0462 us. Best GFLOPs: 826.6082
2024-04-29 02:57:23 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1177: GFLOPs: 654.6493. Time: 353.2980 us. Best GFLOPs: 826.6082
2024-04-29 02:57:23 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1178: GFLOPs: 657.6540. Time: 351.6838 us. Best GFLOPs: 826.6082
2024-04-29 02:57:23 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1179: GFLOPs: 654.0327. Time: 353.6311 us. Best GFLOPs: 826.6082
2024-04-29 02:57:23 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1180: GFLOPs: 658.4981. Time: 351.2330 us. Best GFLOPs: 826.6082
2024-04-29 02:57:23 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1181: GFLOPs: 613.4829. Time: 377.0052 us. Best GFLOPs: 826.6082
2024-04-29 02:57:23 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1182: GFLOPs: 637.9925. Time: 362.5219 us. Best GFLOPs: 826.6082
2024-04-29 02:57:23 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1183: GFLOPs: 553.2043. Time: 418.0848 us. Best GFLOPs: 826.6082
2024-04-29 02:57:23 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1184: GFLOPs: 619.6415. Time: 373.2582 us. Best GFLOPs: 826.6082
2024-04-29 02:57:23 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1185: GFLOPs: 620.2073. Time: 372.9177 us. Best GFLOPs: 826.6082
2024-04-29 02:57:23 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1186: GFLOPs: 582.8728. Time: 396.8040 us. Best GFLOPs: 826.6082
2024-04-29 02:57:23 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1187: GFLOPs: 543.5685. Time: 425.4961 us. Best GFLOPs: 826.6082
2024-04-29 02:57:23 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1188: GFLOPs: 490.6393. Time: 471.3978 us. Best GFLOPs: 826.6082
2024-04-29 02:57:23 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1189: GFLOPs: 559.4269. Time: 413.4343 us. Best GFLOPs: 826.6082
2024-04-29 02:57:23 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1190: GFLOPs: 423.1474. Time: 546.5855 us. Best GFLOPs: 826.6082
2024-04-29 02:57:23 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1191: GFLOPs: 551.8006. Time: 419.1483 us. Best GFLOPs: 826.6082
2024-04-29 02:57:23 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1192: GFLOPs: 570.4702. Time: 405.4309 us. Best GFLOPs: 826.6082
2024-04-29 02:57:23 [INFO] [task_scheduler.cc:121] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1193: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(7), T.int64(7), T.int64(512)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(32)), "float32"), p3: T.Buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(9), T.int64(9), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused in T.parallel(T.int64(112), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(9), T.int64(3), T.int64(512)):
                with T.block("data_pad"):
                    v_i0, v_i1, v_i2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                    v_i3 = T.axis.spatial(T.int64(9), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(16) + ax3)
                    v_i4 = T.axis.spatial(T.int64(512), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(8) and T.int64(1) <= v_i3 and v_i3 < T.int64(8), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(16) + oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(7), oh_1 * T.int64(7) + oh_2_init * T.int64(7) + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(16) + ow_1 + ow_2_init + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(512), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(32), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(16) + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(7), oh_1 * T.int64(7) + oh_2 * T.int64(7) + oh_3)
                        v_ow = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(16) + ow_1 + ow_2 + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(512), ic_0 + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
                for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(1), T.int64(7)):
                    for ax3_ax4_fused in T.vectorized(T.int64(32)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(16) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(7), ax2)
                            v_ax3 = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(16))
                            v_ax4 = T.axis.spatial(T.int64(32), ax3_ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 16, 1, 1])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 1, 7])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[7, 1, 1, 1])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[1, 1, 32, 1])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[512, 1])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[3, 1])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l50, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=14)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=6)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83 = sch.get_loops(block=b69)
l84 = sch.fuse(l72, l73, l74, l75, l76, l77, l78, preserve_unit_iters=True)
sch.parallel(loop=l84)
l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b70)
l105 = sch.fuse(l85, preserve_unit_iters=True)
sch.parallel(loop=l105)
sch.annotate(block_or_loop=l105, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l105, ann_key="pragma_unroll_explicit", ann_val=1)
l106, l107, l108, l109, l110, l111, l112, l113, l114 = sch.get_loops(block=b71)
l115 = sch.fuse(l113, l114, preserve_unit_iters=True)
sch.vectorize(loop=l115)
b116 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136 = sch.get_loops(block=b116)
b137 = sch.decompose_reduction(block=b116, loop=l121)
2024-04-29 02:57:23 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1194: GFLOPs: 565.0666. Time: 409.3080 us. Best GFLOPs: 826.6082
2024-04-29 02:57:23 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1195: GFLOPs: 573.3498. Time: 403.3947 us. Best GFLOPs: 826.6082
2024-04-29 02:57:23 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1196: GFLOPs: 568.7559. Time: 406.6530 us. Best GFLOPs: 826.6082
2024-04-29 02:57:23 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1197: GFLOPs: 590.7606. Time: 391.5059 us. Best GFLOPs: 826.6082
2024-04-29 02:57:23 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1198: GFLOPs: 568.6632. Time: 406.7192 us. Best GFLOPs: 826.6082
2024-04-29 02:57:23 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1199: GFLOPs: 417.3564. Time: 554.1697 us. Best GFLOPs: 826.6082
2024-04-29 02:57:23 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1200: GFLOPs: 486.1437. Time: 475.7570 us. Best GFLOPs: 826.6082
2024-04-29 02:57:23 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1201: GFLOPs: 531.8311. Time: 434.8867 us. Best GFLOPs: 826.6082
2024-04-29 02:57:23 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1202: GFLOPs: 514.7693. Time: 449.3008 us. Best GFLOPs: 826.6082
2024-04-29 02:57:23 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1203: GFLOPs: 582.6441. Time: 396.9598 us. Best GFLOPs: 826.6082
2024-04-29 02:57:23 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1204: GFLOPs: 558.4057. Time: 414.1904 us. Best GFLOPs: 826.6082
2024-04-29 02:57:23 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1205: GFLOPs: 463.0406. Time: 499.4946 us. Best GFLOPs: 826.6082
2024-04-29 02:57:23 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1206: GFLOPs: 492.9476. Time: 469.1904 us. Best GFLOPs: 826.6082
2024-04-29 02:57:23 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1207: GFLOPs: 565.5640. Time: 408.9480 us. Best GFLOPs: 826.6082
2024-04-29 02:57:23 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1208: GFLOPs: 580.8463. Time: 398.1884 us. Best GFLOPs: 826.6082
2024-04-29 02:57:23 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1209: GFLOPs: 453.7187. Time: 509.7570 us. Best GFLOPs: 826.6082
2024-04-29 02:57:23 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1210: GFLOPs: 429.6842. Time: 538.2703 us. Best GFLOPs: 826.6082
2024-04-29 02:57:23 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1211: GFLOPs: 428.5082. Time: 539.7476 us. Best GFLOPs: 826.6082
2024-04-29 02:57:23 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1212: GFLOPs: 453.7219. Time: 509.7534 us. Best GFLOPs: 826.6082
2024-04-29 02:57:23 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1213: GFLOPs: 544.4984. Time: 424.7694 us. Best GFLOPs: 826.6082
2024-04-29 02:57:23 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1214: GFLOPs: 3.0365. Time: 76168.3293 us. Best GFLOPs: 826.6082
2024-04-29 02:57:23 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1215: GFLOPs: 49.5515. Time: 4667.5964 us. Best GFLOPs: 826.6082
2024-04-29 02:57:23 [INFO] [task_scheduler.cc:121] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1216: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(7), T.int64(7), T.int64(512)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(32)), "float32"), p3: T.Buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(9), T.int64(9), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)))
        for i0_i1_i2_i3_i4_fused in T.parallel(T.int64(41472)):
            with T.block("data_pad"):
                v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                v_i1 = T.axis.spatial(T.int64(1), T.int64(0))
                v_i2 = T.axis.spatial(T.int64(9), i0_i1_i2_i3_i4_fused // T.int64(4608))
                v_i3 = T.axis.spatial(T.int64(9), i0_i1_i2_i3_i4_fused % T.int64(4608) // T.int64(512))
                v_i4 = T.axis.spatial(T.int64(512), i0_i1_i2_i3_i4_fused % T.int64(512))
                T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(8) and T.int64(1) <= v_i3 and v_i3 < T.int64(8), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused in T.parallel(T.int64(16), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(4), T.int64(7), T.int64(7), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(2), T.int64(1), T.int64(1)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(2)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused // T.int64(8) * T.int64(8) + oc_chunk_1 * T.int64(2) + oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(7), oh_1 + oh_2_init + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(7), ow_1 + ow_2_init + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused % T.int64(8) * T.int64(4) + oc_block_1 * T.int64(4) + oc_block_2_init * T.int64(2) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(512), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(3), T.int64(3), T.int64(1), T.int64(2), T.int64(1), T.int64(1)):
                    for oc_block_3_fused in T.vectorized(T.int64(2)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused // T.int64(8) * T.int64(8) + oc_chunk_1 * T.int64(2) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(7), oh_1 + oh_2 + oh_3)
                            v_ow = T.axis.spatial(T.int64(7), ow_1 + ow_2 + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused % T.int64(8) * T.int64(4) + oc_block_1 * T.int64(4) + oc_block_2 * T.int64(2) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(512), ic_0 + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(8), T.int64(7), T.int64(7)):
                for ax4_fused in T.vectorized(T.int64(4)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused // T.int64(8) * T.int64(8) + ax1)
                        v_ax2, v_ax3 = T.axis.remap("SS", [ax2, ax3])
                        v_ax4 = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused % T.int64(8) * T.int64(4) + ax4_fused)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 4, 1, 2])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 7, 1, 1])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 7, 1, 1])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[8, 1, 2, 2])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[512, 1])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[1, 3])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=-1)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76 = sch.get_loops(block=b69)
l77 = sch.fuse(l72, l73, l74, l75, l76, preserve_unit_iters=True)
sch.parallel(loop=l77)
l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b70)
l104 = sch.fuse(l78, l79, l80, l81, l82, preserve_unit_iters=True)
sch.parallel(loop=l104)
l105 = sch.fuse(l103, preserve_unit_iters=True)
sch.vectorize(loop=l105)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l106, l107, l108, l109, l110, l111 = sch.get_loops(block=b71)
l112 = sch.fuse(l111, preserve_unit_iters=True)
sch.vectorize(loop=l112)
b113 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135 = sch.get_loops(block=b113)
b136 = sch.decompose_reduction(block=b113, loop=l120)
2024-04-29 03:10:55 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 03:10:56 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-29 03:11:00 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f1e458)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x386def8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x36b1d38)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3108268)]: 0 failure(s)
2024-04-29 03:11:00 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-29 03:11:11 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f1e458)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x386def8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x36b1d38)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3108268)]: 0 failure(s)
2024-04-29 03:11:23 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f1e458)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x386def8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x36b1d38)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3108268)]: 0 failure(s)
2024-04-29 03:11:35 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f1e458)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x386def8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x36b1d38)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3108268)]: 0 failure(s)
2024-04-29 03:11:46 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f1e458)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x386def8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x36b1d38)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3108268)]: 0 failure(s)
2024-04-29 03:11:53 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.8675  0.8640  0.8553  0.8539  0.8357  0.8332  0.8332  0.8265  0.8185  0.8181  0.7816  0.7688  0.7688  0.7530  0.7298  0.7273
[17 : 32]:	0.7246  0.7126  0.6965  0.6927  0.6904  0.6766  0.6731  0.6650  0.6648  0.6625  0.6596  0.6567  0.6511  0.6497  0.6491  0.6488
[33 : 48]:	0.6475  0.6450  0.6392  0.6389  0.6337  0.6310  0.6309  0.6297  0.6297  0.6297  0.6208  0.6199  0.6194  0.6176  0.6176  0.6087
[49 : 64]:	0.6087  0.6077  0.6077  0.6074  0.6074  0.6072  0.6072  0.5983  0.5937  0.5898  0.5898  0.5893  0.5883  0.5877  0.5871  0.5867
2024-04-29 03:11:54 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 03:11:54 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 03:14:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1217: GFLOPs: 749.9078. Time: 308.4196 us. Best GFLOPs: 826.6082
2024-04-29 03:14:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1218: GFLOPs: 731.0539. Time: 316.3738 us. Best GFLOPs: 826.6082
2024-04-29 03:14:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1219: GFLOPs: 765.4331. Time: 302.1639 us. Best GFLOPs: 826.6082
2024-04-29 03:14:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1220: GFLOPs: 627.3298. Time: 368.6837 us. Best GFLOPs: 826.6082
2024-04-29 03:14:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1221: GFLOPs: 729.5544. Time: 317.0240 us. Best GFLOPs: 826.6082
2024-04-29 03:14:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1222: GFLOPs: 607.8047. Time: 380.5273 us. Best GFLOPs: 826.6082
2024-04-29 03:14:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1223: GFLOPs: 617.6241. Time: 374.4774 us. Best GFLOPs: 826.6082
2024-04-29 03:14:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1224: GFLOPs: 766.8617. Time: 301.6010 us. Best GFLOPs: 826.6082
2024-04-29 03:14:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1225: GFLOPs: 757.4653. Time: 305.3424 us. Best GFLOPs: 826.6082
2024-04-29 03:14:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1226: GFLOPs: 667.6000. Time: 346.4444 us. Best GFLOPs: 826.6082
2024-04-29 03:14:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1227: GFLOPs: 634.7160. Time: 364.3933 us. Best GFLOPs: 826.6082
2024-04-29 03:14:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1228: GFLOPs: 737.3482. Time: 313.6731 us. Best GFLOPs: 826.6082
2024-04-29 03:14:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1229: GFLOPs: 757.4346. Time: 305.3548 us. Best GFLOPs: 826.6082
2024-04-29 03:14:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1230: GFLOPs: 616.5647. Time: 375.1209 us. Best GFLOPs: 826.6082
2024-04-29 03:14:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1231: GFLOPs: 611.6796. Time: 378.1167 us. Best GFLOPs: 826.6082
2024-04-29 03:14:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1232: GFLOPs: 615.1725. Time: 375.9698 us. Best GFLOPs: 826.6082
2024-04-29 03:14:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1233: GFLOPs: 613.3967. Time: 377.0583 us. Best GFLOPs: 826.6082
2024-04-29 03:14:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1234: GFLOPs: 619.2651. Time: 373.4851 us. Best GFLOPs: 826.6082
2024-04-29 03:14:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1235: GFLOPs: 579.1711. Time: 399.3402 us. Best GFLOPs: 826.6082
2024-04-29 03:14:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1236: GFLOPs: 552.0084. Time: 418.9905 us. Best GFLOPs: 826.6082
2024-04-29 03:14:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1237: GFLOPs: 576.6231. Time: 401.1048 us. Best GFLOPs: 826.6082
2024-04-29 03:14:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1238: GFLOPs: 562.7319. Time: 411.0062 us. Best GFLOPs: 826.6082
2024-04-29 03:14:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1239: GFLOPs: 568.6393. Time: 406.7364 us. Best GFLOPs: 826.6082
2024-04-29 03:14:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1240: GFLOPs: 517.8704. Time: 446.6103 us. Best GFLOPs: 826.6082
2024-04-29 03:14:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1241: GFLOPs: 574.8317. Time: 402.3548 us. Best GFLOPs: 826.6082
2024-04-29 03:14:00 [INFO] [task_scheduler.cc:121] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1242: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(7), T.int64(7), T.int64(512)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(32)), "float32"), p3: T.Buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(9), T.int64(9), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused in T.parallel(T.int64(112), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(9), T.int64(3), T.int64(512)):
                with T.block("data_pad"):
                    v_i0, v_i1, v_i2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                    v_i3 = T.axis.spatial(T.int64(9), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(16) + ax3)
                    v_i4 = T.axis.spatial(T.int64(512), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(8) and T.int64(1) <= v_i3 and v_i3 < T.int64(8), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(16) + oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(7), oh_1 * T.int64(7) + oh_2_init * T.int64(7) + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(16) + ow_1 + ow_2_init + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(64), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(32), T.int64(8), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(16) + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(7), oh_1 * T.int64(7) + oh_2 * T.int64(7) + oh_3)
                        v_ow = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(16) + ow_1 + ow_2 + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(8) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
                for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(1), T.int64(7)):
                    for ax3_ax4_fused in T.vectorized(T.int64(32)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(16) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(7), ax2)
                            v_ax3 = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(16))
                            v_ax4 = T.axis.spatial(T.int64(32), ax3_ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 16, 1, 1])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 1, 7])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[7, 1, 1, 1])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[1, 1, 32, 1])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[64, 8])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[3, 1])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l50, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=14)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=6)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83 = sch.get_loops(block=b69)
l84 = sch.fuse(l72, l73, l74, l75, l76, l77, l78, preserve_unit_iters=True)
sch.parallel(loop=l84)
l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b70)
l105 = sch.fuse(l85, preserve_unit_iters=True)
sch.parallel(loop=l105)
sch.annotate(block_or_loop=l105, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l105, ann_key="pragma_unroll_explicit", ann_val=1)
l106, l107, l108, l109, l110, l111, l112, l113, l114 = sch.get_loops(block=b71)
l115 = sch.fuse(l113, l114, preserve_unit_iters=True)
sch.vectorize(loop=l115)
b116 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136 = sch.get_loops(block=b116)
b137 = sch.decompose_reduction(block=b116, loop=l121)
2024-04-29 03:14:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1243: GFLOPs: 562.2058. Time: 411.3908 us. Best GFLOPs: 826.6082
2024-04-29 03:14:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1244: GFLOPs: 583.9717. Time: 396.0573 us. Best GFLOPs: 826.6082
2024-04-29 03:14:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1245: GFLOPs: 509.6216. Time: 453.8392 us. Best GFLOPs: 826.6082
2024-04-29 03:14:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1246: GFLOPs: 605.0415. Time: 382.2651 us. Best GFLOPs: 826.6082
2024-04-29 03:14:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1247: GFLOPs: 543.8214. Time: 425.2982 us. Best GFLOPs: 826.6082
2024-04-29 03:14:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1248: GFLOPs: 97.1060. Time: 2381.7923 us. Best GFLOPs: 826.6082
2024-04-29 03:14:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1249: GFLOPs: 549.4624. Time: 420.9319 us. Best GFLOPs: 826.6082
2024-04-29 03:14:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1250: GFLOPs: 532.7303. Time: 434.1526 us. Best GFLOPs: 826.6082
2024-04-29 03:14:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1251: GFLOPs: 530.0652. Time: 436.3355 us. Best GFLOPs: 826.6082
2024-04-29 03:14:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1252: GFLOPs: 573.1863. Time: 403.5097 us. Best GFLOPs: 826.6082
2024-04-29 03:14:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1253: GFLOPs: 480.7213. Time: 481.1234 us. Best GFLOPs: 826.6082
2024-04-29 03:14:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1254: GFLOPs: 513.9177. Time: 450.0454 us. Best GFLOPs: 826.6082
2024-04-29 03:14:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1255: GFLOPs: 526.8388. Time: 439.0077 us. Best GFLOPs: 826.6082
2024-04-29 03:14:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1256: GFLOPs: 543.1183. Time: 425.8488 us. Best GFLOPs: 826.6082
2024-04-29 03:14:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1257: GFLOPs: 556.5679. Time: 415.5581 us. Best GFLOPs: 826.6082
2024-04-29 03:14:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1258: GFLOPs: 558.2579. Time: 414.3000 us. Best GFLOPs: 826.6082
2024-04-29 03:14:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1259: GFLOPs: 524.1530. Time: 441.2572 us. Best GFLOPs: 826.6082
2024-04-29 03:14:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1260: GFLOPs: 466.6958. Time: 495.5825 us. Best GFLOPs: 826.6082
2024-04-29 03:14:00 [INFO] [task_scheduler.cc:121] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1261: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(7), T.int64(7), T.int64(512)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(32)), "float32"), p3: T.Buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(9), T.int64(9), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused in T.parallel(T.int64(112), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(9), T.int64(3), T.int64(512)):
                with T.block("data_pad"):
                    v_i0, v_i1, v_i2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                    v_i3 = T.axis.spatial(T.int64(9), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(56) // T.int64(8) + ax3)
                    v_i4 = T.axis.spatial(T.int64(512), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(8) and T.int64(1) <= v_i3 and v_i3 < T.int64(8), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(56) * T.int64(8) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(8) + oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(7), oh_1 * T.int64(7) + oh_2_init * T.int64(7) + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(56) // T.int64(8) + ow_1 + ow_2_init + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(64), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(32), T.int64(8), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(56) * T.int64(8) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(8) + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(7), oh_1 * T.int64(7) + oh_2 * T.int64(7) + oh_3)
                        v_ow = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(56) // T.int64(8) + ow_1 + ow_2 + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(8) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
                for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(1), T.int64(7)):
                    for ax3_ax4_fused in T.vectorized(T.int64(32)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(56) * T.int64(8) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(8) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(7), ax2)
                            v_ax3 = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(56) // T.int64(8))
                            v_ax4 = T.axis.spatial(T.int64(32), ax3_ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 8, 1, 1])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 1, 7])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[7, 1, 1, 1])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[1, 1, 32, 1])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[64, 8])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[3, 1])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l50, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=14)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=6)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83 = sch.get_loops(block=b69)
l84 = sch.fuse(l72, l73, l74, l75, l76, l77, l78, preserve_unit_iters=True)
sch.parallel(loop=l84)
l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b70)
l105 = sch.fuse(l85, preserve_unit_iters=True)
sch.parallel(loop=l105)
sch.annotate(block_or_loop=l105, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l105, ann_key="pragma_unroll_explicit", ann_val=1)
l106, l107, l108, l109, l110, l111, l112, l113, l114 = sch.get_loops(block=b71)
l115 = sch.fuse(l113, l114, preserve_unit_iters=True)
sch.vectorize(loop=l115)
b116 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136 = sch.get_loops(block=b116)
b137 = sch.decompose_reduction(block=b116, loop=l121)
2024-04-29 03:14:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1262: GFLOPs: 555.9854. Time: 415.9934 us. Best GFLOPs: 826.6082
2024-04-29 03:14:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1263: GFLOPs: 567.6613. Time: 407.4371 us. Best GFLOPs: 826.6082
2024-04-29 03:14:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1264: GFLOPs: 538.6432. Time: 429.3868 us. Best GFLOPs: 826.6082
2024-04-29 03:14:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1265: GFLOPs: 537.7624. Time: 430.0901 us. Best GFLOPs: 826.6082
2024-04-29 03:14:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1266: GFLOPs: 549.0765. Time: 421.2278 us. Best GFLOPs: 826.6082
2024-04-29 03:14:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1267: GFLOPs: 548.2445. Time: 421.8670 us. Best GFLOPs: 826.6082
2024-04-29 03:14:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1268: GFLOPs: 437.2791. Time: 528.9214 us. Best GFLOPs: 826.6082
2024-04-29 03:14:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1269: GFLOPs: 555.6871. Time: 416.2167 us. Best GFLOPs: 826.6082
2024-04-29 03:14:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1270: GFLOPs: 511.7758. Time: 451.9289 us. Best GFLOPs: 826.6082
2024-04-29 03:14:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1271: GFLOPs: 506.9875. Time: 456.1972 us. Best GFLOPs: 826.6082
2024-04-29 03:14:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1272: GFLOPs: 515.5209. Time: 448.6457 us. Best GFLOPs: 826.6082
2024-04-29 03:14:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1273: GFLOPs: 473.9386. Time: 488.0090 us. Best GFLOPs: 826.6082
2024-04-29 03:14:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1274: GFLOPs: 539.4173. Time: 428.7706 us. Best GFLOPs: 826.6082
2024-04-29 03:14:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1275: GFLOPs: 450.4303. Time: 513.4785 us. Best GFLOPs: 826.6082
2024-04-29 03:14:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1276: GFLOPs: 436.0861. Time: 530.3683 us. Best GFLOPs: 826.6082
2024-04-29 03:14:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1277: GFLOPs: 485.2053. Time: 476.6771 us. Best GFLOPs: 826.6082
2024-04-29 03:14:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1278: GFLOPs: 4.4544. Time: 51923.0747 us. Best GFLOPs: 826.6082
2024-04-29 03:14:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1279: GFLOPs: 34.8457. Time: 6637.4448 us. Best GFLOPs: 826.6082
2024-04-29 03:14:00 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3] Trial #1280: GFLOPs: 96.6174. Time: 2393.8364 us. Best GFLOPs: 826.6082
