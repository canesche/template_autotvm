2024-04-30 05:29:47 [INFO] [task_scheduler.cc:160] Initializing Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2024-04-30 05:29:47 [INFO] [task_scheduler.cc:35] 
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(56), T.int64(56), T.int64(256)), "float32"), p1: T.Buffer((T.int64(8), T.int64(1), T.int64(3), T.int64(3), T.int64(256), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(58), T.int64(58), T.int64(256)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)))
        T_add = T.alloc_buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)))
        for i0, i1, i2, i3, i4 in T.grid(T.int64(1), T.int64(1), T.int64(58), T.int64(58), T.int64(256)):
            with T.block("data_pad"):
                v_i0, v_i1, v_i2, v_i3, v_i4 = T.axis.remap("SSSSS", [i0, i1, i2, i3, i4])
                T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(57) and T.int64(1) <= v_i3 and v_i3 < T.int64(57), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
        for n, oc_chunk, oh, ow, oc_block, ic, kh, kw in T.grid(T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32), T.int64(256), T.int64(3), T.int64(3)):
            with T.block("conv2d_NCHWc"):
                v_n, v_oc_chunk, v_oh, v_ow, v_oc_block, v_ic, v_kh, v_kw = T.axis.remap("SSSSSRRR", [n, oc_chunk, oh, ow, oc_block, ic, kh, kw])
                T.reads(data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)], p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block])
                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                with T.init():
                    conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)] * p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block]
        for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                T.writes(T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4]
        for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)):
            with T.block("T_relu"):
                v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                T.reads(T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
2024-04-30 05:29:47 [INFO] [task_scheduler.cc:164] Total 3 design space(s) generated
2024-04-30 05:29:47 [INFO] [task_scheduler.cc:170] Design space #0:
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(56), T.int64(56), T.int64(256)), "float32"), p1: T.Buffer((T.int64(8), T.int64(1), T.int64(3), T.int64(3), T.int64(256), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel": 768, "meta_schedule.unroll_explicit": 16, "meta_schedule.vectorize": 64})
            data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(58), T.int64(58), T.int64(256)))
            conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)))
            for n_0, oc_chunk_0, oh_0, ow_0, oc_block_0, n_1, oc_chunk_1, oh_1 in T.grid(T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2)):
                for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(16), T.int64(58), T.int64(256)):
                    with T.block("data_pad"):
                        v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                        v_i2 = T.axis.spatial(T.int64(58), oh_0 * T.int64(28) + oh_1 * T.int64(14) + ax2)
                        v_i3, v_i4 = T.axis.remap("SS", [ax3, ax4])
                        T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                        T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                        data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(57) and T.int64(1) <= v_i3 and v_i3 < T.int64(57), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                for ow_1, oc_block_1, ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(1), T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(1), T.int64(8), T.int64(2), T.int64(7), T.int64(1), T.int64(8), T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(7), T.int64(8), T.int64(32)):
                    with T.block("conv2d_NCHWc"):
                        v_n = T.axis.spatial(T.int64(1), n_0 + n_1 + n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(8), oc_chunk_0 * T.int64(8) + oc_chunk_1 * T.int64(8) + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(56), oh_0 * T.int64(28) + oh_1 * T.int64(14) + oh_2 * T.int64(7) + oh_3)
                        v_ow = T.axis.spatial(T.int64(56), ow_0 * T.int64(56) + ow_1 * T.int64(56) + ow_2 * T.int64(8) + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_0 * T.int64(32) + oc_block_1 * T.int64(32) + oc_block_2 * T.int64(32) + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(8) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                        T.reads(data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)], p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        with T.init():
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)] * p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block]
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)):
                with T.block("T_relu"):
                    v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                    T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                    T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 8, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 2, 2, 7])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 7, 8])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 1, 32])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[32, 8])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
l65 = sch.sample_compute_location(block=b0, decision=7)
sch.compute_at(block=b0, loop=l65, preserve_unit_loops=True, index=-1)
2024-04-30 05:29:47 [INFO] [task_scheduler.cc:170] Design space #1:
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(56), T.int64(56), T.int64(256)), "float32"), p1: T.Buffer((T.int64(8), T.int64(1), T.int64(3), T.int64(3), T.int64(256), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel": 768, "meta_schedule.unroll_explicit": 64, "meta_schedule.vectorize": 64})
            data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(58), T.int64(58), T.int64(256)))
            conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)))
            for n_0, oc_chunk_0, oh_0 in T.grid(T.int64(1), T.int64(1), T.int64(2)):
                for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(30), T.int64(58), T.int64(256)):
                    with T.block("data_pad"):
                        v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                        v_i2 = T.axis.spatial(T.int64(58), oh_0 * T.int64(28) + ax2)
                        v_i3, v_i4 = T.axis.remap("SS", [ax3, ax4])
                        T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                        T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                        data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(57) and T.int64(1) <= v_i3 and v_i3 < T.int64(57), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                for ow_0, oc_block_0, n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1)):
                    for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(32), T.int64(1), T.int64(1), T.int64(1), T.int64(8), T.int64(2), T.int64(7), T.int64(1), T.int64(8), T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(7), T.int64(8), T.int64(32)):
                        with T.block("conv2d_NCHWc"):
                            v_n = T.axis.spatial(T.int64(1), n_0 + n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(8), oc_chunk_0 * T.int64(8) + oc_chunk_1 * T.int64(8) + oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(56), oh_0 * T.int64(28) + oh_1 * T.int64(14) + oh_2 * T.int64(7) + oh_3)
                            v_ow = T.axis.spatial(T.int64(56), ow_0 * T.int64(56) + ow_1 * T.int64(56) + ow_2 * T.int64(8) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(32), oc_block_0 * T.int64(32) + oc_block_1 * T.int64(32) + oc_block_2 * T.int64(32) + oc_block_3)
                            v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(8) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                            T.reads(data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)], p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            with T.init():
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)] * p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block]
                    for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(8), T.int64(14), T.int64(56), T.int64(32)):
                        with T.block("T_relu"):
                            v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                            v_ax2 = T.axis.spatial(T.int64(56), oh_0 * T.int64(28) + oh_1 * T.int64(14) + ax2)
                            v_ax3, v_ax4 = T.axis.remap("SS", [ax3, ax4])
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 8, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 2, 2, 7])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 7, 8])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 1, 32])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[32, 8])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=2)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
2024-04-30 05:29:47 [INFO] [task_scheduler.cc:170] Design space #2:
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(56), T.int64(56), T.int64(256)), "float32"), p1: T.Buffer((T.int64(8), T.int64(1), T.int64(3), T.int64(3), T.int64(256), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel": 768, "meta_schedule.unroll_explicit": 512, "meta_schedule.vectorize": 64})
            data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(58), T.int64(58), T.int64(256)))
            conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)))
            for i0, i1, i2, i3, i4 in T.grid(T.int64(1), T.int64(1), T.int64(58), T.int64(58), T.int64(256)):
                with T.block("data_pad"):
                    v_i0, v_i1, v_i2, v_i3, v_i4 = T.axis.remap("SSSSS", [i0, i1, i2, i3, i4])
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(57) and T.int64(1) <= v_i3 and v_i3 < T.int64(57), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for n_0, oc_chunk_0, oh_0, ow_0, oc_block_0 in T.grid(T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1)):
                for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1, ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(1), T.int64(8), T.int64(2), T.int64(7), T.int64(1), T.int64(8), T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(7), T.int64(8), T.int64(32)):
                    with T.block("conv2d_NCHWc"):
                        v_n = T.axis.spatial(T.int64(1), n_0 + n_1 + n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(8), oc_chunk_0 * T.int64(8) + oc_chunk_1 * T.int64(8) + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(56), oh_0 * T.int64(28) + oh_1 * T.int64(14) + oh_2 * T.int64(7) + oh_3)
                        v_ow = T.axis.spatial(T.int64(56), ow_0 * T.int64(56) + ow_1 * T.int64(56) + ow_2 * T.int64(8) + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_0 * T.int64(32) + oc_block_1 * T.int64(32) + oc_block_2 * T.int64(32) + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(8) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                        T.reads(data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)], p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        with T.init():
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)] * p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block]
                for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(8), T.int64(28), T.int64(56), T.int64(32)):
                    with T.block("T_relu"):
                        v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                        v_ax2 = T.axis.spatial(T.int64(56), oh_0 * T.int64(28) + ax2)
                        v_ax3, v_ax4 = T.axis.remap("SS", [ax3, ax4])
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 8, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 2, 2, 7])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 7, 8])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 1, 32])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[32, 8])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=-1)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
2024-04-30 05:52:12 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-30 05:52:12 [INFO] [evolutionary_search.cc:715] Picked top 0 candidate(s) from database
2024-04-30 05:52:18 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 05:52:18 [INFO] [evolutionary_search.cc:723] Sampled 512 candidate(s)
2024-04-30 05:52:24 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 05:52:30 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 05:52:36 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 05:52:42 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 05:52:43 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9998  0.9997  0.9988  0.9988  0.9973  0.9964  0.9954  0.9935  0.9920  0.9916  0.9910  0.9909  0.9907  0.9902  0.9900  0.9890
[17 : 32]:	0.9888  0.9886  0.9884  0.9882  0.9878  0.9878  0.9873  0.9867  0.9864  0.9858  0.9854  0.9851  0.9834  0.9833  0.9833  0.9830
[33 : 48]:	0.9820  0.9819  0.9810  0.9809  0.9802  0.9800  0.9800  0.9794  0.9791  0.9787  0.9779  0.9779  0.9776  0.9773  0.9767  0.9763
[49 : 64]:	0.9748  0.9745  0.9741  0.9734  0.9729  0.9720  0.9715  0.9710  0.9710  0.9704  0.9701  0.9699  0.9696  0.9685  0.9684  0.9675
2024-04-30 05:52:43 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-30 05:52:44 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-30 06:42:16 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1: GFLOPs: 18.8700. Time: 196130.3527 us. Best GFLOPs: 18.8700
2024-04-30 06:42:16 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #2: GFLOPs: 112.6449. Time: 32855.2870 us. Best GFLOPs: 112.6449
2024-04-30 06:42:16 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #3: GFLOPs: 49.5747. Time: 74654.6773 us. Best GFLOPs: 112.6449
2024-04-30 06:42:16 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #4: GFLOPs: 20.7358. Time: 178482.3637 us. Best GFLOPs: 112.6449
2024-04-30 06:42:16 [INFO] [task_scheduler.cc:121] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #5: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(56), T.int64(56), T.int64(256)), "float32"), p1: T.Buffer((T.int64(8), T.int64(1), T.int64(3), T.int64(3), T.int64(256), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused in T.parallel(T.int64(896), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for oc_block_1 in range(T.int64(2)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(1), T.int64(4), T.int64(2), T.int64(1)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(8)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(8), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused % T.int64(56) // T.int64(28) * T.int64(4) + oc_chunk_2_init * T.int64(4) + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused // T.int64(448) * T.int64(28) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused % T.int64(28) // T.int64(2) * T.int64(2) + oh_2_init * T.int64(2) + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused % T.int64(448) // T.int64(112) * T.int64(14) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused % T.int64(2) * T.int64(7) + ow_2_init + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused % T.int64(112) // T.int64(56) * T.int64(16) + oc_block_1 * T.int64(8) + oc_block_2_init * T.int64(8) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(16), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(16), T.int64(3), T.int64(1), T.int64(1), T.int64(4), T.int64(2), T.int64(1)):
                    for oc_block_3_fused in T.vectorized(T.int64(8)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(8), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused % T.int64(56) // T.int64(28) * T.int64(4) + oc_chunk_2 * T.int64(4) + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused // T.int64(448) * T.int64(28) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused % T.int64(28) // T.int64(2) * T.int64(2) + oh_2 * T.int64(2) + oh_3)
                            v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused % T.int64(448) // T.int64(112) * T.int64(14) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused % T.int64(2) * T.int64(7) + ow_2 + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused % T.int64(112) // T.int64(56) * T.int64(16) + oc_block_1 * T.int64(8) + oc_block_2 * T.int64(8) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(16) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], p0[v_n, v_ic // T.int64(256), v_oh + v_kh - T.int64(1), v_ow + v_kw - T.int64(1), v_ic % T.int64(256)], p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + T.if_then_else(T.int64(1) <= v_oh + v_kh and v_oh + v_kh < T.int64(57) and T.int64(1) <= v_ow + v_kw and v_ow + v_kw < T.int64(57), p0[v_n, v_ic // T.int64(256), v_oh + v_kh - T.int64(1), v_ow + v_kw - T.int64(1), v_ic % T.int64(256)], T.float32(0)) * p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block]
        for ax0_ax1_ax2_ax3_ax4_fused_0 in T.parallel(T.int64(12544)):
            for ax0_ax1_ax2_ax3_ax4_fused_1 in T.vectorized(T.int64(64)):
                with T.block("T_relu"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(8), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) // T.int64(100352))
                    v_ax2 = T.axis.spatial(T.int64(56), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(100352) // T.int64(1792))
                    v_ax3 = T.axis.spatial(T.int64(56), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(1792) // T.int64(32))
                    v_ax4 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(32))
                    T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                    T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 2, 1, 4])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 14, 1, 2])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[4, 2, 7, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[2, 2, 1, 8])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[16, 16])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
l65 = sch.sample_compute_location(block=b0, decision=-2)
sch.compute_at(block=b0, loop=l65, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b66 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.unroll_explicit")
b67, b68 = sch.get_child_blocks(b66)
l69, l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94 = sch.get_loops(block=b67)
l95 = sch.fuse(l69, l70, l71, l72, l73, l74, l75, l76, l77, preserve_unit_iters=True)
sch.parallel(loop=l95)
l96 = sch.fuse(l94, preserve_unit_iters=True)
sch.vectorize(loop=l96)
sch.annotate(block_or_loop=l95, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l95, ann_key="pragma_unroll_explicit", ann_val=1)
l97, l98, l99, l100, l101 = sch.get_loops(block=b68)
l102 = sch.fuse(l97, l98, l99, l100, l101, preserve_unit_iters=True)
l103, l104 = sch.split(loop=l102, factors=[None, 64], preserve_unit_iters=True)
sch.parallel(loop=l103)
sch.vectorize(loop=l104)
b105 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l106, l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117, l118, l119, l120, l121, l122, l123 = sch.get_loops(block=b105)
b124 = sch.decompose_reduction(block=b105, loop=l108)
2024-04-30 06:42:16 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #6: GFLOPs: 1.7682. Time: 2093121.8107 us. Best GFLOPs: 112.6449
2024-04-30 06:42:16 [INFO] [task_scheduler.cc:121] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #7: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(56), T.int64(56), T.int64(256)), "float32"), p1: T.Buffer((T.int64(8), T.int64(1), T.int64(3), T.int64(3), T.int64(256), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(58), T.int64(58), T.int64(256)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused in T.parallel(T.int64(8), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1, ow_1 in T.grid(T.int64(1), T.int64(2), T.int64(56), T.int64(7)):
                for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(3), T.int64(4), T.int64(256)):
                    with T.block("data_pad"):
                        v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                        v_i2 = T.axis.spatial(T.int64(58), oh_1 + ax2)
                        v_i3 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(2) * T.int64(14) + ow_1 * T.int64(2) + ax3)
                        v_i4 = T.axis.spatial(T.int64(256), ax4)
                        T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                        T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                        data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(57) and T.int64(1) <= v_i3 and v_i3 < T.int64(57), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                for oc_block_1 in range(T.int64(1)):
                    for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(8), T.int64(1), T.int64(2), T.int64(1), T.int64(2)):
                        for oc_block_3_fused_init in T.vectorized(T.int64(2)):
                            with T.block("conv2d_NCHWc_init"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                                v_oc_chunk = T.axis.spatial(T.int64(8), oc_chunk_1 * T.int64(4) + oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                                v_oh = T.axis.spatial(T.int64(56), oh_1 + oh_2_init + oh_3_init)
                                v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(2) * T.int64(14) + ow_1 * T.int64(2) + ow_2_init * T.int64(2) + ow_3_init)
                                v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(2) * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2_init * T.int64(2) + oc_block_3_fused_init)
                                T.reads()
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                    for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(256), T.int64(3), T.int64(3), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(2)):
                        for oc_block_3_fused in T.vectorized(T.int64(2)):
                            with T.block("conv2d_NCHWc_update"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                                v_oc_chunk = T.axis.spatial(T.int64(8), oc_chunk_1 * T.int64(4) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                                v_oh = T.axis.spatial(T.int64(56), oh_1 + oh_2 + oh_3)
                                v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(2) * T.int64(14) + ow_1 * T.int64(2) + ow_2 * T.int64(2) + ow_3)
                                v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(2) * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2 * T.int64(2) + oc_block_3_fused)
                                v_ic = T.axis.reduce(T.int64(256), ic_0 + ic_1)
                                v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                                v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                                T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)], p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block])
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)] * p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(8), T.int64(56), T.int64(14)):
                for ax4_fused in T.vectorized(T.int64(16)):
                    with T.block("T_relu"):
                        v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                        v_ax3 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(2) * T.int64(14) + ax3)
                        v_ax4 = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(2) * T.int64(16) + ax4_fused)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 2, 2, 2])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 56, 1, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[4, 7, 1, 2])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[2, 1, 8, 2])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[256, 1])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=8)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b68)
l85 = sch.fuse(l71, l72, l73, l74, l75, preserve_unit_iters=True)
sch.parallel(loop=l85)
l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107 = sch.get_loops(block=b69)
l108 = sch.fuse(l86, preserve_unit_iters=True)
sch.parallel(loop=l108)
l109 = sch.fuse(l107, preserve_unit_iters=True)
sch.vectorize(loop=l109)
sch.annotate(block_or_loop=l108, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l108, ann_key="pragma_unroll_explicit", ann_val=1)
l110, l111, l112, l113, l114, l115 = sch.get_loops(block=b70)
l116 = sch.fuse(l115, preserve_unit_iters=True)
sch.vectorize(loop=l116)
b117 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139 = sch.get_loops(block=b117)
b140 = sch.decompose_reduction(block=b117, loop=l124)
2024-04-30 06:42:16 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #8: GFLOPs: 63.9714. Time: 57853.7360 us. Best GFLOPs: 112.6449
2024-04-30 06:42:16 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #9: GFLOPs: 64.4412. Time: 57431.9457 us. Best GFLOPs: 112.6449
2024-04-30 06:42:16 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #10: GFLOPs: 45.3033. Time: 81693.4093 us. Best GFLOPs: 112.6449
2024-04-30 06:42:16 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #11: GFLOPs: 54.1605. Time: 68333.6110 us. Best GFLOPs: 112.6449
2024-04-30 06:42:16 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #12: GFLOPs: 67.2398. Time: 55041.5510 us. Best GFLOPs: 112.6449
2024-04-30 06:42:16 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #13: GFLOPs: 73.0385. Time: 50671.6813 us. Best GFLOPs: 112.6449
2024-04-30 06:42:16 [INFO] [task_scheduler.cc:121] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #14: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(56), T.int64(56), T.int64(256)), "float32"), p1: T.Buffer((T.int64(8), T.int64(1), T.int64(3), T.int64(3), T.int64(256), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(58), T.int64(58), T.int64(256)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused in T.parallel(T.int64(28), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1, ow_1 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(2)):
                for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(16), T.int64(4), T.int64(256)):
                    with T.block("data_pad"):
                        v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                        v_i2 = T.axis.spatial(T.int64(58), oh_1 * T.int64(14) + ax2)
                        v_i3 = T.axis.spatial(T.int64(58), ow_1 * T.int64(2) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(14) * T.int64(4) + ax3)
                        v_i4 = T.axis.spatial(T.int64(256), ax4)
                        T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                        T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                        data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(57) and T.int64(1) <= v_i3 and v_i3 < T.int64(57), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                for oc_block_1 in range(T.int64(1)):
                    for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(4), T.int64(7), T.int64(2), T.int64(16), T.int64(1), T.int64(1), T.int64(2), T.int64(1)):
                        for oc_block_3_fused_init in T.vectorized(T.int64(2)):
                            with T.block("conv2d_NCHWc_init"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                                v_oc_chunk = T.axis.spatial(T.int64(8), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(14) * T.int64(4) + oc_chunk_1 * T.int64(4) + oc_chunk_2_init + oc_chunk_3_init)
                                v_oh = T.axis.spatial(T.int64(56), oh_1 * T.int64(14) + oh_2_init * T.int64(2) + oh_3_init)
                                v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(14) * T.int64(4) + ow_1 * T.int64(2) + ow_2_init + ow_3_init)
                                v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2_init * T.int64(2) + oc_block_3_fused_init)
                                T.reads()
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                    for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(7), T.int64(2), T.int64(16), T.int64(64), T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(2), T.int64(1)):
                        for oc_block_3_fused in T.vectorized(T.int64(2)):
                            with T.block("conv2d_NCHWc_update"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                                v_oc_chunk = T.axis.spatial(T.int64(8), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(14) * T.int64(4) + oc_chunk_1 * T.int64(4) + oc_chunk_2 + oc_chunk_3)
                                v_oh = T.axis.spatial(T.int64(56), oh_1 * T.int64(14) + oh_2 * T.int64(2) + oh_3)
                                v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(14) * T.int64(4) + ow_1 * T.int64(2) + ow_2 + ow_3)
                                v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2 * T.int64(2) + oc_block_3_fused)
                                v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(64) + ic_1)
                                v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                                v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                                T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)], p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block])
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)] * p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(4), T.int64(56), T.int64(4)):
                for ax4_fused in T.vectorized(T.int64(32)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(8), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(14) * T.int64(4) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(56), ax2)
                        v_ax3 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(14) * T.int64(4) + ax3)
                        v_ax4 = T.axis.spatial(T.int64(32), ax4_fused)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[2, 1, 4, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 4, 7, 2])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[14, 2, 2, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 16, 2])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[4, 64])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=8)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b68)
l85 = sch.fuse(l71, l72, l73, l74, l75, preserve_unit_iters=True)
sch.parallel(loop=l85)
l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107 = sch.get_loops(block=b69)
l108 = sch.fuse(l86, preserve_unit_iters=True)
sch.parallel(loop=l108)
l109 = sch.fuse(l107, preserve_unit_iters=True)
sch.vectorize(loop=l109)
sch.annotate(block_or_loop=l108, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l108, ann_key="pragma_unroll_explicit", ann_val=1)
l110, l111, l112, l113, l114, l115 = sch.get_loops(block=b70)
l116 = sch.fuse(l115, preserve_unit_iters=True)
sch.vectorize(loop=l116)
b117 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139 = sch.get_loops(block=b117)
b140 = sch.decompose_reduction(block=b117, loop=l124)
2024-04-30 06:42:16 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #15: GFLOPs: 47.2133. Time: 78388.5987 us. Best GFLOPs: 112.6449
2024-04-30 06:42:16 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #16: GFLOPs: 193.3065. Time: 19145.6687 us. Best GFLOPs: 193.3065
2024-04-30 06:42:16 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #17: GFLOPs: 4.7034. Time: 786873.1390 us. Best GFLOPs: 193.3065
2024-04-30 06:42:16 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #18: GFLOPs: 37.0504. Time: 99890.5717 us. Best GFLOPs: 193.3065
2024-04-30 06:42:16 [INFO] [task_scheduler.cc:121] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #19: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(56), T.int64(56), T.int64(256)), "float32"), p1: T.Buffer((T.int64(8), T.int64(1), T.int64(3), T.int64(3), T.int64(256), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(58), T.int64(58), T.int64(256)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused in T.parallel(T.int64(896), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1 in T.grid(T.int64(1), T.int64(2)):
                for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(16), T.int64(4), T.int64(256)):
                    with T.block("data_pad"):
                        v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                        v_i2 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(224) * T.int64(14) + ax2)
                        v_i3 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(224) // T.int64(8) * T.int64(2) + ax3)
                        v_i4 = T.axis.spatial(T.int64(256), ax4)
                        T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                        T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                        data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(57) and T.int64(1) <= v_i3 and v_i3 < T.int64(57), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                for oh_1, ow_1, oc_block_1 in T.grid(T.int64(14), T.int64(1), T.int64(1)):
                    for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(1), T.int64(4), T.int64(1), T.int64(2), T.int64(1)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(8), oc_chunk_1 * T.int64(4) + oc_chunk_2_init * T.int64(4) + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(224) * T.int64(14) + oh_1 + oh_2_init + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(224) // T.int64(8) * T.int64(2) + ow_1 * T.int64(2) + ow_2_init * T.int64(2) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(8) * T.int64(4) + oc_block_1 * T.int64(4) + oc_block_2_init + oc_block_3_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                    for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(128), T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(1), T.int64(2), T.int64(1)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(8), oc_chunk_1 * T.int64(4) + oc_chunk_2 * T.int64(4) + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(224) * T.int64(14) + oh_1 + oh_2 + oh_3)
                            v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(224) // T.int64(8) * T.int64(2) + ow_1 * T.int64(2) + ow_2 * T.int64(2) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(8) * T.int64(4) + oc_block_1 * T.int64(4) + oc_block_2 + oc_block_3)
                            v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(2) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)], p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)] * p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(8), T.int64(14), T.int64(2)):
                for ax4_fused in T.vectorized(T.int64(4)):
                    with T.block("T_relu"):
                        v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                        v_ax2 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(224) * T.int64(14) + ax2)
                        v_ax3 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(224) // T.int64(8) * T.int64(2) + ax3)
                        v_ax4 = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(8) * T.int64(4) + ax4_fused)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 2, 1, 4])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[4, 14, 1, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[28, 1, 1, 2])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[8, 1, 4, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[128, 2])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=6)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82 = sch.get_loops(block=b68)
l83 = sch.fuse(l71, l72, l73, l74, l75, preserve_unit_iters=True)
sch.parallel(loop=l83)
l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105 = sch.get_loops(block=b69)
l106 = sch.fuse(l84, preserve_unit_iters=True)
sch.parallel(loop=l106)
sch.annotate(block_or_loop=l106, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l106, ann_key="pragma_unroll_explicit", ann_val=1)
l107, l108, l109, l110, l111, l112 = sch.get_loops(block=b70)
l113 = sch.fuse(l112, preserve_unit_iters=True)
sch.vectorize(loop=l113)
b114 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136 = sch.get_loops(block=b114)
b137 = sch.decompose_reduction(block=b114, loop=l121)
2024-04-30 06:42:16 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #20: GFLOPs: 76.9315. Time: 48107.4840 us. Best GFLOPs: 193.3065
2024-04-30 06:42:16 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #21: GFLOPs: 26.5542. Time: 139374.6990 us. Best GFLOPs: 193.3065
2024-04-30 06:42:16 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #22: GFLOPs: 129.5712. Time: 28563.3150 us. Best GFLOPs: 193.3065
2024-04-30 06:42:16 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #23: GFLOPs: 203.4790. Time: 18188.5237 us. Best GFLOPs: 203.4790
2024-04-30 06:42:16 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #24: GFLOPs: 32.3277. Time: 114483.2177 us. Best GFLOPs: 203.4790
2024-04-30 06:42:16 [INFO] [task_scheduler.cc:121] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #25: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(56), T.int64(56), T.int64(256)), "float32"), p1: T.Buffer((T.int64(8), T.int64(1), T.int64(3), T.int64(3), T.int64(256), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(58), T.int64(58), T.int64(256)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused in T.parallel(T.int64(112), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(30), T.int64(6), T.int64(256)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(56) * T.int64(28) + ax2)
                    v_i3 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(56) // T.int64(8) * T.int64(8) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(4) // T.int64(2) * T.int64(4) + ax3)
                    v_i4 = T.axis.spatial(T.int64(256), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(57) and T.int64(1) <= v_i3 and v_i3 < T.int64(57), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(2), T.int64(4), T.int64(2), T.int64(1), T.int64(1), T.int64(4), T.int64(7), T.int64(2)):
                for oc_block_3_fused_init in T.vectorized(T.int64(8)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(8), oc_chunk_2_init * T.int64(4) + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(56) * T.int64(28) + oh_2_init * T.int64(7) + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(56) // T.int64(8) * T.int64(8) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(4) // T.int64(2) * T.int64(4) + ow_2_init * T.int64(2) + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(8) // T.int64(4) * T.int64(16) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(2) * T.int64(8) + oc_block_2_init * T.int64(8) + oc_block_3_fused_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
            for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(16), T.int64(3), T.int64(3), T.int64(1), T.int64(2), T.int64(4), T.int64(2), T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(7), T.int64(2)):
                for oc_block_3_fused in T.vectorized(T.int64(8)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(8), oc_chunk_2 * T.int64(4) + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(56) * T.int64(28) + oh_2 * T.int64(7) + oh_3)
                        v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(56) // T.int64(8) * T.int64(8) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(4) // T.int64(2) * T.int64(4) + ow_2 * T.int64(2) + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(8) // T.int64(4) * T.int64(16) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(2) * T.int64(8) + oc_block_2 * T.int64(8) + oc_block_3_fused)
                        v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(16) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)], p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)] * p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block]
        for ax0_ax1_ax2_ax3_ax4_fused_0 in T.parallel(T.int64(12544)):
            for ax0_ax1_ax2_ax3_ax4_fused_1 in T.vectorized(T.int64(64)):
                with T.block("T_relu"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(8), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) // T.int64(100352))
                    v_ax2 = T.axis.spatial(T.int64(56), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(100352) // T.int64(1792))
                    v_ax3 = T.axis.spatial(T.int64(56), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(1792) // T.int64(32))
                    v_ax4 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(32))
                    T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                    T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 2, 4])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 1, 4, 7])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[7, 2, 2, 2])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[2, 2, 1, 8])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[16, 16])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
l65 = sch.sample_compute_location(block=b0, decision=9)
sch.compute_at(block=b0, loop=l65, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b66 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.unroll_explicit")
b67, b68, b69 = sch.get_child_blocks(b66)
l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b67)
l85 = sch.fuse(l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, preserve_unit_iters=True)
sch.parallel(loop=l85)
l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102 = sch.get_loops(block=b68)
l103 = sch.fuse(l86, preserve_unit_iters=True)
sch.parallel(loop=l103)
l104 = sch.fuse(l102, preserve_unit_iters=True)
sch.vectorize(loop=l104)
sch.annotate(block_or_loop=l103, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l103, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109 = sch.get_loops(block=b69)
l110 = sch.fuse(l105, l106, l107, l108, l109, preserve_unit_iters=True)
l111, l112 = sch.split(loop=l110, factors=[None, 64], preserve_unit_iters=True)
sch.parallel(loop=l111)
sch.vectorize(loop=l112)
b113 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130 = sch.get_loops(block=b113)
b131 = sch.decompose_reduction(block=b113, loop=l115)
2024-04-30 06:42:16 [INFO] [task_scheduler.cc:121] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #26: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(56), T.int64(56), T.int64(256)), "float32"), p1: T.Buffer((T.int64(8), T.int64(1), T.int64(3), T.int64(3), T.int64(256), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(58), T.int64(58), T.int64(256)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_fused_fused in T.parallel(T.int64(112), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(6), T.int64(9), T.int64(256)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(8) * T.int64(4) + ax2)
                    v_i3 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(8) * T.int64(7) + ax3)
                    v_i4 = T.axis.spatial(T.int64(256), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(57) and T.int64(1) <= v_i3 and v_i3 < T.int64(57), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oc_block_0 in range(T.int64(1)):
                for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2)):
                    for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(2), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(2), T.int64(7)):
                        for oc_block_3_fused_init in T.vectorized(T.int64(16)):
                            with T.block("conv2d_NCHWc_init"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                                v_oc_chunk = T.axis.spatial(T.int64(8), oc_chunk_1 * T.int64(8) + oc_chunk_2_init * T.int64(4) + oc_chunk_3_init)
                                v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(8) * T.int64(4) + oh_1 * T.int64(4) + oh_2_init * T.int64(2) + oh_3_init)
                                v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(8) * T.int64(7) + ow_1 * T.int64(7) + ow_2_init * T.int64(7) + ow_3_init)
                                v_oc_block = T.axis.spatial(T.int64(32), oc_block_0 * T.int64(32) + oc_block_1 * T.int64(16) + oc_block_2_init * T.int64(16) + oc_block_3_fused_init)
                                T.reads()
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                    for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(64), T.int64(1), T.int64(3), T.int64(1), T.int64(2), T.int64(2), T.int64(1), T.int64(1), T.int64(4), T.int64(3), T.int64(1), T.int64(1), T.int64(4), T.int64(2), T.int64(7)):
                        for oc_block_3_fused in T.vectorized(T.int64(16)):
                            with T.block("conv2d_NCHWc_update"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                                v_oc_chunk = T.axis.spatial(T.int64(8), oc_chunk_1 * T.int64(8) + oc_chunk_2 * T.int64(4) + oc_chunk_3)
                                v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(8) * T.int64(4) + oh_1 * T.int64(4) + oh_2 * T.int64(2) + oh_3)
                                v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(8) * T.int64(7) + ow_1 * T.int64(7) + ow_2 * T.int64(7) + ow_3)
                                v_oc_block = T.axis.spatial(T.int64(32), oc_block_0 * T.int64(32) + oc_block_1 * T.int64(16) + oc_block_2 * T.int64(16) + oc_block_3_fused)
                                v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(4) + ic_1)
                                v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                                v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                                T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)], p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block])
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)] * p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(8), T.int64(4), T.int64(7)):
                    for ax4_fused in T.vectorized(T.int64(32)):
                        with T.block("T_relu"):
                            v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                            v_ax2 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(8) * T.int64(4) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(8) * T.int64(7) + ax3)
                            v_ax4 = T.axis.spatial(T.int64(32), ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 2, 4])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[14, 1, 2, 2])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[8, 1, 1, 7])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 2, 1, 16])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[64, 4])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=3)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79 = sch.get_loops(block=b68)
l80 = sch.fuse(l71, l72, l73, l74, preserve_unit_iters=True)
sch.parallel(loop=l80)
l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l81, preserve_unit_iters=True)
sch.parallel(loop=l104)
l105 = sch.fuse(l103, preserve_unit_iters=True)
sch.vectorize(loop=l105)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l106, l107, l108, l109, l110, l111, l112 = sch.get_loops(block=b70)
l113 = sch.fuse(l112, preserve_unit_iters=True)
sch.vectorize(loop=l113)
b114 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137 = sch.get_loops(block=b114)
b138 = sch.decompose_reduction(block=b114, loop=l122)
2024-04-30 06:42:16 [INFO] [task_scheduler.cc:121] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #27: Error in running:
LocalRunner: Timeout, killed after 30 seconds

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(56), T.int64(56), T.int64(256)), "float32"), p1: T.Buffer((T.int64(8), T.int64(1), T.int64(3), T.int64(3), T.int64(256), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(58), T.int64(58), T.int64(256)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_fused_fused_fused in T.parallel(T.int64(4)):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(30), T.int64(58), T.int64(256)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_fused_fused_fused % T.int64(2) * T.int64(28) + ax2)
                    v_i3, v_i4 = T.axis.remap("SS", [ax3, ax4])
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(57) and T.int64(1) <= v_i3 and v_i3 < T.int64(57), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for ow_0, oc_block_0 in T.grid(T.int64(2), T.int64(1)):
                for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                    for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(2), T.int64(14), T.int64(28), T.int64(32), T.int64(1), T.int64(2), T.int64(2), T.int64(1), T.int64(1)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(8), n_0_oc_chunk_0_oh_0_fused_fused_fused // T.int64(2) * T.int64(4) + oc_chunk_1 * T.int64(4) + oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_fused_fused_fused % T.int64(2) * T.int64(28) + oh_1 * T.int64(28) + oh_2_init * T.int64(2) + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(56), ow_0 * T.int64(28) + ow_1 * T.int64(28) + ow_2_init + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(32), oc_block_0 * T.int64(32) + oc_block_1 * T.int64(32) + oc_block_2_init + oc_block_3_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                    for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(16), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(14), T.int64(28), T.int64(32), T.int64(16), T.int64(3), T.int64(3), T.int64(1), T.int64(2), T.int64(2), T.int64(1), T.int64(1)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(8), n_0_oc_chunk_0_oh_0_fused_fused_fused // T.int64(2) * T.int64(4) + oc_chunk_1 * T.int64(4) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_fused_fused_fused % T.int64(2) * T.int64(28) + oh_1 * T.int64(28) + oh_2 * T.int64(2) + oh_3)
                            v_ow = T.axis.spatial(T.int64(56), ow_0 * T.int64(28) + ow_1 * T.int64(28) + ow_2 + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(32), oc_block_0 * T.int64(32) + oc_block_1 * T.int64(32) + oc_block_2 + oc_block_3)
                            v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(16) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)], p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)] * p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(4), T.int64(28), T.int64(28)):
                    for ax4_fused in T.vectorized(T.int64(32)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(8), n_0_oc_chunk_0_oh_0_fused_fused_fused // T.int64(2) * T.int64(4) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_fused_fused_fused % T.int64(2) * T.int64(28) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(56), ow_0 * T.int64(28) + ax3)
                            v_ax4 = T.axis.spatial(T.int64(32), ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[2, 1, 2, 2])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 1, 14, 2])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[2, 1, 28, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 32, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[16, 16])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=2)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78 = sch.get_loops(block=b68)
l79 = sch.fuse(l71, l72, l73, preserve_unit_iters=True)
sch.parallel(loop=l79)
l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l80, preserve_unit_iters=True)
sch.parallel(loop=l104)
l105, l106, l107, l108, l109, l110, l111, l112 = sch.get_loops(block=b70)
l113 = sch.fuse(l105, preserve_unit_iters=True)
sch.parallel(loop=l113)
l114 = sch.fuse(l112, preserve_unit_iters=True)
sch.vectorize(loop=l114)
b115 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139 = sch.get_loops(block=b115)
b140 = sch.decompose_reduction(block=b115, loop=l124)
2024-04-30 06:42:16 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #28: GFLOPs: 191.8107. Time: 19294.9747 us. Best GFLOPs: 203.4790
2024-04-30 06:42:16 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #29: GFLOPs: 5.7746. Time: 640911.1057 us. Best GFLOPs: 203.4790
2024-04-30 06:42:16 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #30: GFLOPs: 15.6516. Time: 236459.8900 us. Best GFLOPs: 203.4790
2024-04-30 06:42:16 [INFO] [task_scheduler.cc:121] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #31: Error in running:
LocalRunner: Timeout, killed after 30 seconds

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(56), T.int64(56), T.int64(256)), "float32"), p1: T.Buffer((T.int64(8), T.int64(1), T.int64(3), T.int64(3), T.int64(256), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(58), T.int64(58), T.int64(256)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_fused_fused_fused in T.parallel(T.int64(4)):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(30), T.int64(58), T.int64(256)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_fused_fused_fused % T.int64(2) * T.int64(28) + ax2)
                    v_i3, v_i4 = T.axis.remap("SS", [ax3, ax4])
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(57) and T.int64(1) <= v_i3 and v_i3 < T.int64(57), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for ow_0, oc_block_0 in T.grid(T.int64(2), T.int64(1)):
                for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(8)):
                    for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(2), T.int64(14), T.int64(28), T.int64(4), T.int64(1), T.int64(2), T.int64(2), T.int64(1), T.int64(1)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(8), n_0_oc_chunk_0_oh_0_fused_fused_fused // T.int64(2) * T.int64(4) + oc_chunk_1 * T.int64(4) + oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_fused_fused_fused % T.int64(2) * T.int64(28) + oh_1 * T.int64(28) + oh_2_init * T.int64(2) + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(56), ow_0 * T.int64(28) + ow_1 * T.int64(28) + ow_2_init + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(32), oc_block_0 * T.int64(32) + oc_block_1 * T.int64(4) + oc_block_2_init + oc_block_3_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                    for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(16), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(14), T.int64(28), T.int64(4), T.int64(16), T.int64(3), T.int64(3), T.int64(1), T.int64(2), T.int64(2), T.int64(1), T.int64(1)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(8), n_0_oc_chunk_0_oh_0_fused_fused_fused // T.int64(2) * T.int64(4) + oc_chunk_1 * T.int64(4) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_fused_fused_fused % T.int64(2) * T.int64(28) + oh_1 * T.int64(28) + oh_2 * T.int64(2) + oh_3)
                            v_ow = T.axis.spatial(T.int64(56), ow_0 * T.int64(28) + ow_1 * T.int64(28) + ow_2 + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(32), oc_block_0 * T.int64(32) + oc_block_1 * T.int64(4) + oc_block_2 + oc_block_3)
                            v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(16) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)], p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)] * p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(4), T.int64(28), T.int64(28)):
                    for ax4_fused in T.vectorized(T.int64(32)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(8), n_0_oc_chunk_0_oh_0_fused_fused_fused // T.int64(2) * T.int64(4) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_fused_fused_fused % T.int64(2) * T.int64(28) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(56), ow_0 * T.int64(28) + ax3)
                            v_ax4 = T.axis.spatial(T.int64(32), ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[2, 1, 2, 2])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 1, 14, 2])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[2, 1, 28, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 8, 4, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[16, 16])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=2)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78 = sch.get_loops(block=b68)
l79 = sch.fuse(l71, l72, l73, preserve_unit_iters=True)
sch.parallel(loop=l79)
l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l80, preserve_unit_iters=True)
sch.parallel(loop=l104)
l105, l106, l107, l108, l109, l110, l111, l112 = sch.get_loops(block=b70)
l113 = sch.fuse(l105, preserve_unit_iters=True)
sch.parallel(loop=l113)
l114 = sch.fuse(l112, preserve_unit_iters=True)
sch.vectorize(loop=l114)
b115 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139 = sch.get_loops(block=b115)
b140 = sch.decompose_reduction(block=b115, loop=l124)
2024-04-30 06:42:16 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #32: GFLOPs: 16.6125. Time: 222782.5047 us. Best GFLOPs: 203.4790
2024-04-30 06:42:16 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #33: GFLOPs: 512.9850. Time: 7214.6004 us. Best GFLOPs: 512.9850
2024-04-30 06:42:16 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #34: GFLOPs: 69.6821. Time: 53112.3603 us. Best GFLOPs: 512.9850
2024-04-30 06:42:16 [INFO] [task_scheduler.cc:121] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #35: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(56), T.int64(56), T.int64(256)), "float32"), p1: T.Buffer((T.int64(8), T.int64(1), T.int64(3), T.int64(3), T.int64(256), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(58), T.int64(58), T.int64(256)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)))
        for n_0_oc_chunk_0_fused_fused in T.parallel(T.int64(2), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(58), T.int64(58), T.int64(256)):
                with T.block("data_pad"):
                    v_i0, v_i1, v_i2, v_i3, v_i4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(57) and T.int64(1) <= v_i3 and v_i3 < T.int64(57), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oh_0, ow_0, oc_block_0, n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(32)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(14), T.int64(28), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(8), n_0_oc_chunk_0_fused_fused * T.int64(4) + oc_chunk_1 * T.int64(4) + oc_chunk_2_init * T.int64(4) + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(56), oh_0 * T.int64(56) + oh_1 * T.int64(56) + oh_2_init * T.int64(14) + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(56), ow_0 * T.int64(28) + ow_1 * T.int64(28) + ow_2_init * T.int64(28) + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_0 * T.int64(32) + oc_block_1 + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(32), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(8), T.int64(3), T.int64(3), T.int64(1), T.int64(4), T.int64(14), T.int64(28), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(8), n_0_oc_chunk_0_fused_fused * T.int64(4) + oc_chunk_1 * T.int64(4) + oc_chunk_2 * T.int64(4) + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(56), oh_0 * T.int64(56) + oh_1 * T.int64(56) + oh_2 * T.int64(14) + oh_3)
                        v_ow = T.axis.spatial(T.int64(56), ow_0 * T.int64(28) + ow_1 * T.int64(28) + ow_2 * T.int64(28) + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_0 * T.int64(32) + oc_block_1 + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(8) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)], p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)] * p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block]
                for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(4), T.int64(56), T.int64(28), T.int64(1)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(8), n_0_oc_chunk_0_fused_fused * T.int64(4) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(56), ax2)
                        v_ax3 = T.axis.spatial(T.int64(56), ow_0 * T.int64(28) + ax3)
                        v_ax4 = T.axis.spatial(T.int64(32), oc_block_1 + ax4)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[2, 1, 1, 4])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 4, 14])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[2, 1, 1, 28])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 32, 1, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[32, 8])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=1)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77 = sch.get_loops(block=b68)
l78 = sch.fuse(l71, l72, preserve_unit_iters=True)
sch.parallel(loop=l78)
l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l79, preserve_unit_iters=True)
sch.parallel(loop=l104)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117, l118 = sch.get_loops(block=b70)
b119 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141, l142, l143, l144 = sch.get_loops(block=b119)
b145 = sch.decompose_reduction(block=b119, loop=l129)
2024-04-30 06:42:16 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #36: GFLOPs: 22.9040. Time: 161586.9503 us. Best GFLOPs: 512.9850
2024-04-30 06:42:16 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #37: GFLOPs: 59.0948. Time: 62627.8927 us. Best GFLOPs: 512.9850
2024-04-30 06:42:16 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #38: GFLOPs: 11.6046. Time: 318922.7367 us. Best GFLOPs: 512.9850
2024-04-30 06:42:16 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #39: GFLOPs: 19.3778. Time: 190990.7950 us. Best GFLOPs: 512.9850
2024-04-30 06:42:16 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #40: GFLOPs: 18.0550. Time: 204983.6117 us. Best GFLOPs: 512.9850
2024-04-30 06:42:16 [INFO] [task_scheduler.cc:121] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #41: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(56), T.int64(56), T.int64(256)), "float32"), p1: T.Buffer((T.int64(8), T.int64(1), T.int64(3), T.int64(3), T.int64(256), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(58), T.int64(58), T.int64(256)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused in T.parallel(T.int64(14), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(10), T.int64(58), T.int64(256)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(7) * T.int64(8) + ax2)
                    v_i3, v_i4 = T.axis.remap("SS", [ax3, ax4])
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(57) and T.int64(1) <= v_i3 and v_i3 < T.int64(57), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(2)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(8), T.int64(2), T.int64(56), T.int64(2), T.int64(1), T.int64(1), T.int64(4), T.int64(1)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(8), oc_chunk_2_init + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(7) * T.int64(8) + oh_2_init * T.int64(4) + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(56), ow_1 * T.int64(56) + ow_2_init + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(7) * T.int64(16) + oc_block_1 * T.int64(8) + oc_block_2_init * T.int64(4) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(4), T.int64(3), T.int64(1), T.int64(1), T.int64(8), T.int64(2), T.int64(56), T.int64(2), T.int64(64), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(4), T.int64(1)):
                    for oc_block_3_fused in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(8), oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(7) * T.int64(8) + oh_2 * T.int64(4) + oh_3)
                            v_ow = T.axis.spatial(T.int64(56), ow_1 * T.int64(56) + ow_2 + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(7) * T.int64(16) + oc_block_1 * T.int64(8) + oc_block_2 * T.int64(4) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(64) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)], p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)] * p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(8), T.int64(8), T.int64(56)):
                    for ax4_fused in T.vectorized(T.int64(8)):
                        with T.block("T_relu"):
                            v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                            v_ax2 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(7) * T.int64(8) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(56), ax3)
                            v_ax4 = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(7) * T.int64(16) + oc_block_1 * T.int64(8) + ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 8, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 7, 2, 4])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 56, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[2, 2, 2, 4])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[4, 64])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=7)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83 = sch.get_loops(block=b68)
l84 = sch.fuse(l71, l72, l73, l74, l75, l76, l77, l78, preserve_unit_iters=True)
sch.parallel(loop=l84)
l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l85, preserve_unit_iters=True)
sch.parallel(loop=l104)
l105 = sch.fuse(l103, preserve_unit_iters=True)
sch.vectorize(loop=l105)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l106, l107, l108, l109, l110, l111, l112, l113 = sch.get_loops(block=b70)
l114 = sch.fuse(l113, preserve_unit_iters=True)
sch.vectorize(loop=l114)
b115 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134 = sch.get_loops(block=b115)
b135 = sch.decompose_reduction(block=b115, loop=l119)
2024-04-30 06:42:16 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #42: GFLOPs: 1.2824. Time: 2885941.2457 us. Best GFLOPs: 512.9850
2024-04-30 06:42:16 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #43: GFLOPs: 6.4223. Time: 576274.7923 us. Best GFLOPs: 512.9850
2024-04-30 06:42:16 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #44: GFLOPs: 29.8091. Time: 124156.2793 us. Best GFLOPs: 512.9850
2024-04-30 06:42:16 [INFO] [task_scheduler.cc:121] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #45: Error in running:
LocalRunner: Timeout, killed after 30 seconds

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(56), T.int64(56), T.int64(256)), "float32"), p1: T.Buffer((T.int64(8), T.int64(1), T.int64(3), T.int64(3), T.int64(256), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)))
        for n_0 in T.serial(T.int64(1), annotations={"pragma_auto_unroll_max_step": 16, "pragma_unroll_explicit": 1}):
            for oc_chunk_0, oh_0, ow_0, oc_block_0 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(14), T.int64(16)):
                    for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(4), T.int64(2), T.int64(2), T.int64(1), T.int64(1), T.int64(2), T.int64(28), T.int64(2)):
                        for oc_block_3_fused_init in T.vectorized(T.int64(2)):
                            with T.block("conv2d_NCHWc_init"):
                                v_n = T.axis.spatial(T.int64(1), n_0 + n_1 + n_2_init + n_3_init)
                                v_oc_chunk = T.axis.spatial(T.int64(8), oc_chunk_0 * T.int64(8) + oc_chunk_1 * T.int64(8) + oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                                v_oh = T.axis.spatial(T.int64(56), oh_0 * T.int64(56) + oh_1 * T.int64(56) + oh_2_init * T.int64(28) + oh_3_init)
                                v_ow = T.axis.spatial(T.int64(56), ow_0 * T.int64(56) + ow_1 * T.int64(4) + ow_2_init * T.int64(2) + ow_3_init)
                                v_oc_block = T.axis.spatial(T.int64(32), oc_block_0 * T.int64(32) + oc_block_1 * T.int64(2) + oc_block_2_init * T.int64(2) + oc_block_3_fused_init)
                                T.reads()
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                    for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(64), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(2), T.int64(2), T.int64(1), T.int64(4), T.int64(3), T.int64(3), T.int64(1), T.int64(2), T.int64(28), T.int64(2)):
                        for oc_block_3_fused in T.vectorized(T.int64(2)):
                            with T.block("conv2d_NCHWc_update"):
                                v_n = T.axis.spatial(T.int64(1), n_0 + n_1 + n_2 + n_3)
                                v_oc_chunk = T.axis.spatial(T.int64(8), oc_chunk_0 * T.int64(8) + oc_chunk_1 * T.int64(8) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                                v_oh = T.axis.spatial(T.int64(56), oh_0 * T.int64(56) + oh_1 * T.int64(56) + oh_2 * T.int64(28) + oh_3)
                                v_ow = T.axis.spatial(T.int64(56), ow_0 * T.int64(56) + ow_1 * T.int64(4) + ow_2 * T.int64(2) + ow_3)
                                v_oc_block = T.axis.spatial(T.int64(32), oc_block_0 * T.int64(32) + oc_block_1 * T.int64(2) + oc_block_2 * T.int64(2) + oc_block_3_fused)
                                v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(4) + ic_1)
                                v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                                v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                                T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], p0[v_n, v_ic // T.int64(256), v_oh + v_kh - T.int64(1), v_ow + v_kw - T.int64(1), v_ic % T.int64(256)], p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block])
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + T.if_then_else(T.int64(1) <= v_oh + v_kh and v_oh + v_kh < T.int64(57) and T.int64(1) <= v_ow + v_kw and v_ow + v_kw < T.int64(57), p0[v_n, v_ic // T.int64(256), v_oh + v_kh - T.int64(1), v_ow + v_kw - T.int64(1), v_ic % T.int64(256)], T.float32(0)) * p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(8), T.int64(56), T.int64(56)):
                    for ax4_fused in T.vectorized(T.int64(32)):
                        with T.block("T_relu"):
                            v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4_fused])
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 4, 2])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 2, 28])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 14, 2, 2])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 16, 1, 2])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[64, 4])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=-2)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69 = sch.get_child_blocks(b67)
l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95 = sch.get_loops(block=b68)
l96 = sch.fuse(l95, preserve_unit_iters=True)
sch.vectorize(loop=l96)
sch.annotate(block_or_loop=l70, ann_key="pragma_auto_unroll_max_step", ann_val=16)
sch.annotate(block_or_loop=l70, ann_key="pragma_unroll_explicit", ann_val=1)
l97, l98, l99, l100, l101, l102, l103, l104, l105, l106 = sch.get_loops(block=b69)
l107 = sch.fuse(l106, preserve_unit_iters=True)
sch.vectorize(loop=l107)
b108 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l109, l110, l111, l112, l113, l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134 = sch.get_loops(block=b108)
b135 = sch.decompose_reduction(block=b108, loop=l119)
2024-04-30 06:42:16 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #46: GFLOPs: 15.7080. Time: 235611.6283 us. Best GFLOPs: 512.9850
2024-04-30 06:42:16 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #47: GFLOPs: 108.0291. Time: 34259.1117 us. Best GFLOPs: 512.9850
2024-04-30 06:42:16 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #48: GFLOPs: 21.0729. Time: 175627.4667 us. Best GFLOPs: 512.9850
2024-04-30 06:42:16 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #49: GFLOPs: 4.6401. Time: 797612.7577 us. Best GFLOPs: 512.9850
2024-04-30 06:42:16 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #50: GFLOPs: 68.4142. Time: 54096.6797 us. Best GFLOPs: 512.9850
2024-04-30 06:42:16 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #51: GFLOPs: 67.9490. Time: 54467.0623 us. Best GFLOPs: 512.9850
2024-04-30 06:42:16 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #52: GFLOPs: 170.6523. Time: 21687.2626 us. Best GFLOPs: 512.9850
2024-04-30 06:42:16 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #53: GFLOPs: 27.6888. Time: 133663.6510 us. Best GFLOPs: 512.9850
2024-04-30 06:42:16 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #54: GFLOPs: 143.8308. Time: 25731.4920 us. Best GFLOPs: 512.9850
2024-04-30 06:42:16 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #55: GFLOPs: 16.9837. Time: 217913.5043 us. Best GFLOPs: 512.9850
2024-04-30 06:42:16 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #56: GFLOPs: 2.5718. Time: 1439041.1460 us. Best GFLOPs: 512.9850
2024-04-30 06:42:16 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #57: GFLOPs: 97.9747. Time: 37774.8893 us. Best GFLOPs: 512.9850
2024-04-30 06:42:16 [INFO] [task_scheduler.cc:121] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #58: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(56), T.int64(56), T.int64(256)), "float32"), p1: T.Buffer((T.int64(8), T.int64(1), T.int64(3), T.int64(3), T.int64(256), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(58), T.int64(58), T.int64(256)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_fused_fused in T.parallel(T.int64(112), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(6), T.int64(9), T.int64(256)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(8) * T.int64(4) + ax2)
                    v_i3 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(8) * T.int64(7) + ax3)
                    v_i4 = T.axis.spatial(T.int64(256), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(57) and T.int64(1) <= v_i3 and v_i3 < T.int64(57), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oc_block_0 in range(T.int64(1)):
                for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                    for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(2), T.int64(2), T.int64(1), T.int64(4), T.int64(1), T.int64(4), T.int64(2), T.int64(7)):
                        for oc_block_3_fused_init in T.vectorized(T.int64(8)):
                            with T.block("conv2d_NCHWc_init"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                                v_oc_chunk = T.axis.spatial(T.int64(8), oc_chunk_1 * T.int64(8) + oc_chunk_2_init * T.int64(4) + oc_chunk_3_init)
                                v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(8) * T.int64(4) + oh_1 * T.int64(4) + oh_2_init * T.int64(2) + oh_3_init)
                                v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(8) * T.int64(7) + ow_1 * T.int64(7) + ow_2_init * T.int64(7) + ow_3_init)
                                v_oc_block = T.axis.spatial(T.int64(32), oc_block_0 * T.int64(32) + oc_block_1 * T.int64(32) + oc_block_2_init * T.int64(8) + oc_block_3_fused_init)
                                T.reads()
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                    for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(64), T.int64(3), T.int64(3), T.int64(1), T.int64(2), T.int64(2), T.int64(1), T.int64(4), T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(2), T.int64(7)):
                        for oc_block_3_fused in T.vectorized(T.int64(8)):
                            with T.block("conv2d_NCHWc_update"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                                v_oc_chunk = T.axis.spatial(T.int64(8), oc_chunk_1 * T.int64(8) + oc_chunk_2 * T.int64(4) + oc_chunk_3)
                                v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(8) * T.int64(4) + oh_1 * T.int64(4) + oh_2 * T.int64(2) + oh_3)
                                v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(8) * T.int64(7) + ow_1 * T.int64(7) + ow_2 * T.int64(7) + ow_3)
                                v_oc_block = T.axis.spatial(T.int64(32), oc_block_0 * T.int64(32) + oc_block_1 * T.int64(32) + oc_block_2 * T.int64(8) + oc_block_3_fused)
                                v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(4) + ic_1)
                                v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                                v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                                T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)], p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block])
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)] * p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(8), T.int64(4), T.int64(7)):
                    for ax4_fused in T.vectorized(T.int64(32)):
                        with T.block("T_relu"):
                            v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                            v_ax2 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(8) * T.int64(4) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(8) * T.int64(7) + ax3)
                            v_ax4 = T.axis.spatial(T.int64(32), ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 2, 4])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[14, 1, 2, 2])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[8, 1, 1, 7])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 4, 8])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[64, 4])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=3)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79 = sch.get_loops(block=b68)
l80 = sch.fuse(l71, l72, l73, l74, preserve_unit_iters=True)
sch.parallel(loop=l80)
l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l81, preserve_unit_iters=True)
sch.parallel(loop=l104)
l105 = sch.fuse(l103, preserve_unit_iters=True)
sch.vectorize(loop=l105)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l106, l107, l108, l109, l110, l111, l112 = sch.get_loops(block=b70)
l113 = sch.fuse(l112, preserve_unit_iters=True)
sch.vectorize(loop=l113)
b114 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137 = sch.get_loops(block=b114)
b138 = sch.decompose_reduction(block=b114, loop=l122)
2024-04-30 06:42:16 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #59: GFLOPs: 5.6572. Time: 654212.6283 us. Best GFLOPs: 512.9850
2024-04-30 06:42:16 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #60: GFLOPs: 14.9466. Time: 247613.9550 us. Best GFLOPs: 512.9850
2024-04-30 06:42:16 [INFO] [task_scheduler.cc:121] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #61: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(56), T.int64(56), T.int64(256)), "float32"), p1: T.Buffer((T.int64(8), T.int64(1), T.int64(3), T.int64(3), T.int64(256), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(58), T.int64(58), T.int64(256)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused in T.parallel(T.int64(448), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1 in T.grid(T.int64(1), T.int64(2)):
                for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(16), T.int64(10), T.int64(256)):
                    with T.block("data_pad"):
                        v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                        v_i2 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(224) // T.int64(56) * T.int64(14) + ax2)
                        v_i3 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(56) // T.int64(8) * T.int64(8) + ax3)
                        v_i4 = T.axis.spatial(T.int64(256), ax4)
                        T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                        T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                        data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(57) and T.int64(1) <= v_i3 and v_i3 < T.int64(57), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                for oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(8), T.int64(2)):
                    for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(2), T.int64(1), T.int64(2), T.int64(7), T.int64(1), T.int64(1)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(8), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(224) * T.int64(4) + oc_chunk_1 * T.int64(2) + oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(224) // T.int64(56) * T.int64(14) + oh_1 * T.int64(14) + oh_2_init * T.int64(7) + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(56) // T.int64(8) * T.int64(8) + ow_1 + ow_2_init + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(8) * T.int64(4) + oc_block_1 * T.int64(2) + oc_block_2_init + oc_block_3_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                    for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(32), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(2), T.int64(8), T.int64(3), T.int64(1), T.int64(1), T.int64(2), T.int64(7), T.int64(1), T.int64(1)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(8), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(224) * T.int64(4) + oc_chunk_1 * T.int64(2) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(224) // T.int64(56) * T.int64(14) + oh_1 * T.int64(14) + oh_2 * T.int64(7) + oh_3)
                            v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(56) // T.int64(8) * T.int64(8) + ow_1 + ow_2 + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(8) * T.int64(4) + oc_block_1 * T.int64(2) + oc_block_2 + oc_block_3)
                            v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(8) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)], p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)] * p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(4), T.int64(14), T.int64(8)):
                for ax4_fused in T.vectorized(T.int64(4)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(8), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(224) * T.int64(4) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(224) // T.int64(56) * T.int64(14) + ax2)
                        v_ax3 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(56) // T.int64(8) * T.int64(8) + ax3)
                        v_ax4 = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(8) * T.int64(4) + ax4_fused)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[2, 2, 1, 2])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[4, 1, 2, 7])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[7, 8, 1, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[8, 2, 2, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[32, 8])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=6)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82 = sch.get_loops(block=b68)
l83 = sch.fuse(l71, l72, l73, l74, l75, preserve_unit_iters=True)
sch.parallel(loop=l83)
l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105 = sch.get_loops(block=b69)
l106 = sch.fuse(l84, preserve_unit_iters=True)
sch.parallel(loop=l106)
sch.annotate(block_or_loop=l106, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l106, ann_key="pragma_unroll_explicit", ann_val=1)
l107, l108, l109, l110, l111, l112 = sch.get_loops(block=b70)
l113 = sch.fuse(l112, preserve_unit_iters=True)
sch.vectorize(loop=l113)
b114 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136 = sch.get_loops(block=b114)
b137 = sch.decompose_reduction(block=b114, loop=l121)
2024-04-30 06:42:16 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #62: GFLOPs: 56.5116. Time: 65490.6777 us. Best GFLOPs: 512.9850
2024-04-30 06:42:16 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #63: GFLOPs: 6.2825. Time: 589095.1707 us. Best GFLOPs: 512.9850
2024-04-30 06:42:16 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #64: GFLOPs: 19.9700. Time: 185326.9293 us. Best GFLOPs: 512.9850
2024-04-30 06:52:21 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-30 06:52:21 [INFO] [evolutionary_search.cc:715] Picked top 51 candidate(s) from database
2024-04-30 06:52:26 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 06:52:26 [INFO] [evolutionary_search.cc:723] Sampled 461 candidate(s)
2024-04-30 06:52:39 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 06:52:53 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 06:53:10 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 06:53:23 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 06:53:32 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9956  0.9956  0.9956  0.9956  0.9956  0.9956  0.9956  0.9871  0.9871  0.9502  0.9502  0.9502  0.9489  0.9457  0.9457  0.9457
[17 : 32]:	0.9428  0.9371  0.9298  0.9240  0.9155  0.9155  0.8856  0.8856  0.8757  0.8354  0.8267  0.8183  0.7827  0.7813  0.7584  0.7584
[33 : 48]:	0.7345  0.7342  0.7342  0.7342  0.7310  0.7297  0.7270  0.7006  0.7001  0.6862  0.6862  0.6838  0.6838  0.6838  0.6798  0.6697
[49 : 64]:	0.6655  0.6628  0.6624  0.6620  0.6603  0.6583  0.6572  0.6566  0.6546  0.6546  0.6546  0.6510  0.6382  0.6382  0.6382  0.6354
2024-04-30 06:53:32 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-30 06:53:32 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-30 06:55:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #65: GFLOPs: 203.5220. Time: 18184.6733 us. Best GFLOPs: 512.9850
2024-04-30 06:55:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #66: GFLOPs: 515.4999. Time: 7179.4029 us. Best GFLOPs: 515.4999
2024-04-30 06:55:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #67: GFLOPs: 395.9689. Time: 9346.6474 us. Best GFLOPs: 515.4999
2024-04-30 06:55:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #68: GFLOPs: 114.8053. Time: 32237.0335 us. Best GFLOPs: 515.4999
2024-04-30 06:55:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #69: GFLOPs: 114.5280. Time: 32315.0847 us. Best GFLOPs: 515.4999
2024-04-30 06:55:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #70: GFLOPs: 395.8624. Time: 9349.1620 us. Best GFLOPs: 515.4999
2024-04-30 06:55:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #71: GFLOPs: 114.5019. Time: 32322.4598 us. Best GFLOPs: 515.4999
2024-04-30 06:55:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #72: GFLOPs: 148.0899. Time: 24991.4530 us. Best GFLOPs: 515.4999
2024-04-30 06:55:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #73: GFLOPs: 147.0791. Time: 25163.2108 us. Best GFLOPs: 515.4999
2024-04-30 06:55:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #74: GFLOPs: 278.6709. Time: 13280.8314 us. Best GFLOPs: 515.4999
2024-04-30 06:55:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #75: GFLOPs: 69.1589. Time: 53514.1603 us. Best GFLOPs: 515.4999
2024-04-30 06:55:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #76: GFLOPs: 254.5593. Time: 14538.7804 us. Best GFLOPs: 515.4999
2024-04-30 06:55:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #77: GFLOPs: 143.6547. Time: 25763.0413 us. Best GFLOPs: 515.4999
2024-04-30 06:55:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #78: GFLOPs: 29.9395. Time: 123615.4613 us. Best GFLOPs: 515.4999
2024-04-30 06:55:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #79: GFLOPs: 146.5202. Time: 25259.1850 us. Best GFLOPs: 515.4999
2024-04-30 06:55:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #80: GFLOPs: 141.2724. Time: 26197.4888 us. Best GFLOPs: 515.4999
2024-04-30 06:55:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #81: GFLOPs: 418.0733. Time: 8852.4705 us. Best GFLOPs: 515.4999
2024-04-30 06:55:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #82: GFLOPs: 212.8491. Time: 17387.8197 us. Best GFLOPs: 515.4999
2024-04-30 06:55:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #83: GFLOPs: 396.9568. Time: 9323.3878 us. Best GFLOPs: 515.4999
2024-04-30 06:55:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #84: GFLOPs: 409.5230. Time: 9037.2999 us. Best GFLOPs: 515.4999
2024-04-30 06:55:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #85: GFLOPs: 146.9119. Time: 25191.8515 us. Best GFLOPs: 515.4999
2024-04-30 06:55:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #86: GFLOPs: 149.7573. Time: 24713.1960 us. Best GFLOPs: 515.4999
2024-04-30 06:55:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #87: GFLOPs: 113.5342. Time: 32597.9345 us. Best GFLOPs: 515.4999
2024-04-30 06:55:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #88: GFLOPs: 116.8870. Time: 31662.8910 us. Best GFLOPs: 515.4999
2024-04-30 06:55:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #89: GFLOPs: 107.0483. Time: 34573.0057 us. Best GFLOPs: 515.4999
2024-04-30 06:55:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #90: GFLOPs: 108.7175. Time: 34042.1963 us. Best GFLOPs: 515.4999
2024-04-30 06:55:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #91: GFLOPs: 389.6752. Time: 9497.6073 us. Best GFLOPs: 515.4999
2024-04-30 06:55:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #92: GFLOPs: 264.2227. Time: 14007.0551 us. Best GFLOPs: 515.4999
2024-04-30 06:55:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #93: GFLOPs: 147.9672. Time: 25012.1732 us. Best GFLOPs: 515.4999
2024-04-30 06:55:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #94: GFLOPs: 226.1337. Time: 16366.3407 us. Best GFLOPs: 515.4999
2024-04-30 06:55:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #95: GFLOPs: 99.4773. Time: 37204.2980 us. Best GFLOPs: 515.4999
2024-04-30 06:55:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #96: GFLOPs: 64.0401. Time: 57791.6410 us. Best GFLOPs: 515.4999
2024-04-30 06:55:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #97: GFLOPs: 273.3811. Time: 13537.8095 us. Best GFLOPs: 515.4999
2024-04-30 06:55:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #98: GFLOPs: 436.7348. Time: 8474.2084 us. Best GFLOPs: 515.4999
2024-04-30 06:55:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #99: GFLOPs: 565.5617. Time: 6543.9039 us. Best GFLOPs: 565.5617
2024-04-30 06:55:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #100: GFLOPs: 118.8735. Time: 31133.7818 us. Best GFLOPs: 565.5617
2024-04-30 06:55:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #101: GFLOPs: 464.2431. Time: 7972.0773 us. Best GFLOPs: 565.5617
2024-04-30 06:55:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #102: GFLOPs: 181.5095. Time: 20390.0212 us. Best GFLOPs: 565.5617
2024-04-30 06:55:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #103: GFLOPs: 152.4280. Time: 24280.1966 us. Best GFLOPs: 565.5617
2024-04-30 06:55:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #104: GFLOPs: 413.3057. Time: 8954.5859 us. Best GFLOPs: 565.5617
2024-04-30 06:55:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #105: GFLOPs: 291.1724. Time: 12710.6189 us. Best GFLOPs: 565.5617
2024-04-30 06:55:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #106: GFLOPs: 76.5348. Time: 48356.8443 us. Best GFLOPs: 565.5617
2024-04-30 06:55:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #107: GFLOPs: 101.0559. Time: 36623.1210 us. Best GFLOPs: 565.5617
2024-04-30 06:55:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #108: GFLOPs: 211.6034. Time: 17490.1797 us. Best GFLOPs: 565.5617
2024-04-30 06:55:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #109: GFLOPs: 38.5918. Time: 95900.6207 us. Best GFLOPs: 565.5617
2024-04-30 06:55:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #110: GFLOPs: 291.0271. Time: 12716.9652 us. Best GFLOPs: 565.5617
2024-04-30 06:55:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #111: GFLOPs: 105.8814. Time: 34954.0353 us. Best GFLOPs: 565.5617
2024-04-30 06:55:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #112: GFLOPs: 42.4597. Time: 87164.4793 us. Best GFLOPs: 565.5617
2024-04-30 06:55:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #113: GFLOPs: 160.1426. Time: 23110.5342 us. Best GFLOPs: 565.5617
2024-04-30 06:55:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #114: GFLOPs: 57.6614. Time: 64184.7717 us. Best GFLOPs: 565.5617
2024-04-30 06:55:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #115: GFLOPs: 183.8883. Time: 20126.2506 us. Best GFLOPs: 565.5617
2024-04-30 06:55:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #116: GFLOPs: 97.5636. Time: 37934.0337 us. Best GFLOPs: 565.5617
2024-04-30 06:55:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #117: GFLOPs: 37.6218. Time: 98373.3407 us. Best GFLOPs: 565.5617
2024-04-30 06:55:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #118: GFLOPs: 134.6501. Time: 27485.9210 us. Best GFLOPs: 565.5617
2024-04-30 06:55:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #119: GFLOPs: 138.2867. Time: 26763.1010 us. Best GFLOPs: 565.5617
2024-04-30 06:55:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #120: GFLOPs: 189.4131. Time: 19539.2018 us. Best GFLOPs: 565.5617
2024-04-30 06:55:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #121: GFLOPs: 138.7008. Time: 26683.2048 us. Best GFLOPs: 565.5617
2024-04-30 06:55:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #122: GFLOPs: 146.8576. Time: 25201.1515 us. Best GFLOPs: 565.5617
2024-04-30 06:55:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #123: GFLOPs: 181.4927. Time: 20391.9010 us. Best GFLOPs: 565.5617
2024-04-30 06:55:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #124: GFLOPs: 385.4057. Time: 9602.8199 us. Best GFLOPs: 565.5617
2024-04-30 06:55:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #125: GFLOPs: 177.1531. Time: 20891.4358 us. Best GFLOPs: 565.5617
2024-04-30 06:55:31 [INFO] [task_scheduler.cc:121] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #126: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(56), T.int64(56), T.int64(256)), "float32"), p1: T.Buffer((T.int64(8), T.int64(1), T.int64(3), T.int64(3), T.int64(256), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(58), T.int64(58), T.int64(256)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused in T.parallel(T.int64(224), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(1), T.int64(4), T.int64(2), T.int64(28)):
                for oc_block_3_fused_init in T.vectorized(T.int64(4)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(8), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(112) * T.int64(4) + oc_chunk_2_init * T.int64(4) + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(112) // T.int64(4) * T.int64(2) + oh_2_init * T.int64(2) + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(4) // T.int64(2) * T.int64(28) + ow_2_init * T.int64(28) + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(2) * T.int64(16) + oc_block_2_init * T.int64(4) + oc_block_3_fused_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
            for ic_0, kh_0 in T.grid(T.int64(256), T.int64(3)):
                for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(2), T.int64(30), T.int64(1)):
                    with T.block("data_pad"):
                        v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                        v_i2 = T.axis.spatial(T.int64(58), kh_0 + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(112) // T.int64(4) * T.int64(2) + ax2)
                        v_i3 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(4) // T.int64(2) * T.int64(28) + ax3)
                        v_i4 = T.axis.spatial(T.int64(256), ic_0 + ax4)
                        T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                        T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                        data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(57) and T.int64(1) <= v_i3 and v_i3 < T.int64(57), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                for kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(2), T.int64(28)):
                    for oc_block_3_fused in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(8), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(112) * T.int64(4) + oc_chunk_2 * T.int64(4) + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(112) // T.int64(4) * T.int64(2) + oh_2 * T.int64(2) + oh_3)
                            v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(4) // T.int64(2) * T.int64(28) + ow_2 * T.int64(28) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(2) * T.int64(16) + oc_block_2 * T.int64(4) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(256), ic_0 + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)], p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)] * p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(4), T.int64(2), T.int64(28)):
                for ax4_fused in T.vectorized(T.int64(16)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(8), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(112) * T.int64(4) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(112) // T.int64(4) * T.int64(2) + ax2)
                        v_ax3 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(4) // T.int64(2) * T.int64(28) + ax3)
                        v_ax4 = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(2) * T.int64(16) + ax4_fused)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 2, 1, 4])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 28, 1, 2])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 2, 1, 28])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 2, 4, 4])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[256, 1])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=11)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87 = sch.get_loops(block=b68)
l88 = sch.fuse(l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, preserve_unit_iters=True)
sch.parallel(loop=l88)
l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105 = sch.get_loops(block=b69)
l106 = sch.fuse(l89, preserve_unit_iters=True)
sch.parallel(loop=l106)
l107 = sch.fuse(l105, preserve_unit_iters=True)
sch.vectorize(loop=l107)
sch.annotate(block_or_loop=l106, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l106, ann_key="pragma_unroll_explicit", ann_val=1)
l108, l109, l110, l111, l112, l113 = sch.get_loops(block=b70)
l114 = sch.fuse(l113, preserve_unit_iters=True)
sch.vectorize(loop=l114)
b115 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132 = sch.get_loops(block=b115)
b133 = sch.decompose_reduction(block=b115, loop=l117)
2024-04-30 06:55:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #127: GFLOPs: 80.6799. Time: 45872.4313 us. Best GFLOPs: 565.5617
2024-04-30 06:55:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #128: GFLOPs: 2.7553. Time: 1343209.6327 us. Best GFLOPs: 565.5617
2024-04-30 06:55:31 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-30 06:55:32 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-30 06:55:37 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 06:55:37 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-30 06:55:50 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 06:56:03 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 06:56:17 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 06:56:31 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 06:56:40 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.8746  0.8377  0.8377  0.8377  0.8377  0.8377  0.7954  0.7954  0.7929  0.7878  0.7848  0.7848  0.7848  0.7690  0.7690  0.7673
[17 : 32]:	0.7586  0.7586  0.7549  0.7464  0.7374  0.7374  0.7374  0.7340  0.7340  0.7308  0.7285  0.7281  0.7281  0.7281  0.7035  0.7035
[33 : 48]:	0.7035  0.7011  0.6982  0.6969  0.6946  0.6946  0.6937  0.6937  0.6937  0.6923  0.6923  0.6923  0.6911  0.6911  0.6899  0.6883
[49 : 64]:	0.6852  0.6852  0.6841  0.6841  0.6831  0.6774  0.6764  0.6759  0.6749  0.6749  0.6749  0.6749  0.6700  0.6700  0.6700  0.6691
2024-04-30 06:56:40 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-30 06:56:40 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-30 06:58:29 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #129: GFLOPs: 247.1076. Time: 14977.2094 us. Best GFLOPs: 565.5617
2024-04-30 06:58:29 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #130: GFLOPs: 315.1184. Time: 11744.7357 us. Best GFLOPs: 565.5617
2024-04-30 06:58:29 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #131: GFLOPs: 477.0986. Time: 7757.2674 us. Best GFLOPs: 565.5617
2024-04-30 06:58:29 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #132: GFLOPs: 111.0764. Time: 33319.2445 us. Best GFLOPs: 565.5617
2024-04-30 06:58:29 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #133: GFLOPs: 113.5856. Time: 32583.2043 us. Best GFLOPs: 565.5617
2024-04-30 06:58:29 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #134: GFLOPs: 422.0846. Time: 8768.3419 us. Best GFLOPs: 565.5617
2024-04-30 06:58:29 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #135: GFLOPs: 118.8682. Time: 31135.1640 us. Best GFLOPs: 565.5617
2024-04-30 06:58:29 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #136: GFLOPs: 436.4456. Time: 8479.8243 us. Best GFLOPs: 565.5617
2024-04-30 06:58:29 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #137: GFLOPs: 310.4607. Time: 11920.9342 us. Best GFLOPs: 565.5617
2024-04-30 06:58:29 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #138: GFLOPs: 173.3969. Time: 21343.9938 us. Best GFLOPs: 565.5617
2024-04-30 06:58:29 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #139: GFLOPs: 299.1296. Time: 12372.5010 us. Best GFLOPs: 565.5617
2024-04-30 06:58:29 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #140: GFLOPs: 412.5632. Time: 8970.7028 us. Best GFLOPs: 565.5617
2024-04-30 06:58:29 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #141: GFLOPs: 65.8606. Time: 56194.1463 us. Best GFLOPs: 565.5617
2024-04-30 06:58:29 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #142: GFLOPs: 75.5801. Time: 48967.6613 us. Best GFLOPs: 565.5617
2024-04-30 06:58:29 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #143: GFLOPs: 445.2911. Time: 8311.3755 us. Best GFLOPs: 565.5617
2024-04-30 06:58:29 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #144: GFLOPs: 440.9291. Time: 8393.5978 us. Best GFLOPs: 565.5617
2024-04-30 06:58:29 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #145: GFLOPs: 284.0420. Time: 13029.6994 us. Best GFLOPs: 565.5617
2024-04-30 06:58:29 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #146: GFLOPs: 103.7281. Time: 35679.6447 us. Best GFLOPs: 565.5617
2024-04-30 06:58:29 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #147: GFLOPs: 390.8340. Time: 9469.4467 us. Best GFLOPs: 565.5617
2024-04-30 06:58:29 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #148: GFLOPs: 588.0290. Time: 6293.8765 us. Best GFLOPs: 588.0290
2024-04-30 06:58:29 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #149: GFLOPs: 467.1808. Time: 7921.9472 us. Best GFLOPs: 588.0290
2024-04-30 06:58:29 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #150: GFLOPs: 113.3707. Time: 32644.9655 us. Best GFLOPs: 588.0290
2024-04-30 06:58:29 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #151: GFLOPs: 368.4199. Time: 10045.5540 us. Best GFLOPs: 588.0290
2024-04-30 06:58:29 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #152: GFLOPs: 505.5592. Time: 7320.5704 us. Best GFLOPs: 588.0290
2024-04-30 06:58:29 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #153: GFLOPs: 116.9832. Time: 31636.8678 us. Best GFLOPs: 588.0290
2024-04-30 06:58:29 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #154: GFLOPs: 193.4313. Time: 19133.3180 us. Best GFLOPs: 588.0290
2024-04-30 06:58:29 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #155: GFLOPs: 348.0616. Time: 10633.1221 us. Best GFLOPs: 588.0290
2024-04-30 06:58:29 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #156: GFLOPs: 121.1283. Time: 30554.2368 us. Best GFLOPs: 588.0290
2024-04-30 06:58:29 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #157: GFLOPs: 429.1620. Time: 8623.7402 us. Best GFLOPs: 588.0290
2024-04-30 06:58:29 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #158: GFLOPs: 122.0543. Time: 30322.4253 us. Best GFLOPs: 588.0290
2024-04-30 06:58:29 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #159: GFLOPs: 553.0390. Time: 6692.0806 us. Best GFLOPs: 588.0290
2024-04-30 06:58:29 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #160: GFLOPs: 402.5074. Time: 9194.8165 us. Best GFLOPs: 588.0290
2024-04-30 06:58:29 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #161: GFLOPs: 61.6009. Time: 60080.0303 us. Best GFLOPs: 588.0290
2024-04-30 06:58:29 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #162: GFLOPs: 97.4267. Time: 37987.3480 us. Best GFLOPs: 588.0290
2024-04-30 06:58:29 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #163: GFLOPs: 189.5598. Time: 19524.0832 us. Best GFLOPs: 588.0290
2024-04-30 06:58:29 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #164: GFLOPs: 348.0528. Time: 10633.3912 us. Best GFLOPs: 588.0290
2024-04-30 06:58:29 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #165: GFLOPs: 514.7261. Time: 7190.1966 us. Best GFLOPs: 588.0290
2024-04-30 06:58:29 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #166: GFLOPs: 114.6417. Time: 32283.0240 us. Best GFLOPs: 588.0290
2024-04-30 06:58:29 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #167: GFLOPs: 84.8564. Time: 43614.6320 us. Best GFLOPs: 588.0290
2024-04-30 06:58:29 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #168: GFLOPs: 418.5911. Time: 8841.5197 us. Best GFLOPs: 588.0290
2024-04-30 06:58:29 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #169: GFLOPs: 531.9759. Time: 6957.0478 us. Best GFLOPs: 588.0290
2024-04-30 06:58:29 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #170: GFLOPs: 279.6831. Time: 13232.7666 us. Best GFLOPs: 588.0290
2024-04-30 06:58:29 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #171: GFLOPs: 286.7357. Time: 12907.2936 us. Best GFLOPs: 588.0290
2024-04-30 06:58:29 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #172: GFLOPs: 59.9843. Time: 61699.1513 us. Best GFLOPs: 588.0290
2024-04-30 06:58:29 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #173: GFLOPs: 69.4699. Time: 53274.6253 us. Best GFLOPs: 588.0290
2024-04-30 06:58:29 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #174: GFLOPs: 472.0197. Time: 7840.7357 us. Best GFLOPs: 588.0290
2024-04-30 06:58:29 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #175: GFLOPs: 119.4935. Time: 30972.2335 us. Best GFLOPs: 588.0290
2024-04-30 06:58:29 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #176: GFLOPs: 98.4159. Time: 37605.5273 us. Best GFLOPs: 588.0290
2024-04-30 06:58:29 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #177: GFLOPs: 204.8880. Time: 18063.4351 us. Best GFLOPs: 588.0290
2024-04-30 06:58:29 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #178: GFLOPs: 118.8610. Time: 31137.0665 us. Best GFLOPs: 588.0290
2024-04-30 06:58:29 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #179: GFLOPs: 104.2144. Time: 35513.1380 us. Best GFLOPs: 588.0290
2024-04-30 06:58:29 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #180: GFLOPs: 605.8353. Time: 6108.8904 us. Best GFLOPs: 605.8353
2024-04-30 06:58:29 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #181: GFLOPs: 351.0190. Time: 10543.5375 us. Best GFLOPs: 605.8353
2024-04-30 06:58:29 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #182: GFLOPs: 542.4372. Time: 6822.8755 us. Best GFLOPs: 605.8353
2024-04-30 06:58:29 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #183: GFLOPs: 122.2708. Time: 30268.7390 us. Best GFLOPs: 605.8353
2024-04-30 06:58:29 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #184: GFLOPs: 392.8804. Time: 9420.1239 us. Best GFLOPs: 605.8353
2024-04-30 06:58:29 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #185: GFLOPs: 86.9504. Time: 42564.2800 us. Best GFLOPs: 605.8353
2024-04-30 06:58:29 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #186: GFLOPs: 380.6801. Time: 9722.0265 us. Best GFLOPs: 605.8353
2024-04-30 06:58:29 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #187: GFLOPs: 86.8734. Time: 42602.0007 us. Best GFLOPs: 605.8353
2024-04-30 06:58:29 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #188: GFLOPs: 376.5843. Time: 9827.7637 us. Best GFLOPs: 605.8353
2024-04-30 06:58:29 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #189: GFLOPs: 61.1622. Time: 60510.8870 us. Best GFLOPs: 605.8353
2024-04-30 06:58:29 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #190: GFLOPs: 17.1988. Time: 215188.5873 us. Best GFLOPs: 605.8353
2024-04-30 06:58:29 [INFO] [task_scheduler.cc:121] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #191: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(56), T.int64(56), T.int64(256)), "float32"), p1: T.Buffer((T.int64(8), T.int64(1), T.int64(3), T.int64(3), T.int64(256), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(58), T.int64(58), T.int64(256)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused in T.parallel(T.int64(56), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1 in T.grid(T.int64(1), T.int64(2)):
                for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(58), T.int64(10), T.int64(256)):
                    with T.block("data_pad"):
                        v_i0, v_i1, v_i2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                        v_i3 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(8) * T.int64(8) + ax3)
                        v_i4 = T.axis.spatial(T.int64(256), ax4)
                        T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                        T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                        data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(57) and T.int64(1) <= v_i3 and v_i3 < T.int64(57), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                for oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(2), T.int64(1)):
                    for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(4), T.int64(2), T.int64(2), T.int64(2), T.int64(1), T.int64(1), T.int64(28), T.int64(2)):
                        for oc_block_3_fused_init in T.vectorized(T.int64(2)):
                            with T.block("conv2d_NCHWc_init"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                                v_oc_chunk = T.axis.spatial(T.int64(8), oc_chunk_1 * T.int64(4) + oc_chunk_2_init + oc_chunk_3_init)
                                v_oh = T.axis.spatial(T.int64(56), oh_1 * T.int64(56) + oh_2_init * T.int64(28) + oh_3_init)
                                v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(8) * T.int64(8) + ow_1 * T.int64(4) + ow_2_init * T.int64(2) + ow_3_init)
                                v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(8) * T.int64(4) + oc_block_1 * T.int64(4) + oc_block_2_init * T.int64(2) + oc_block_3_fused_init)
                                T.reads()
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                    for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(128), T.int64(3), T.int64(1), T.int64(1), T.int64(4), T.int64(2), T.int64(2), T.int64(2), T.int64(2), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(28), T.int64(2)):
                        for oc_block_3_fused in T.vectorized(T.int64(2)):
                            with T.block("conv2d_NCHWc_update"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                                v_oc_chunk = T.axis.spatial(T.int64(8), oc_chunk_1 * T.int64(4) + oc_chunk_2 + oc_chunk_3)
                                v_oh = T.axis.spatial(T.int64(56), oh_1 * T.int64(56) + oh_2 * T.int64(28) + oh_3)
                                v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(8) * T.int64(8) + ow_1 * T.int64(4) + ow_2 * T.int64(2) + ow_3)
                                v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(8) * T.int64(4) + oc_block_1 * T.int64(4) + oc_block_2 * T.int64(2) + oc_block_3_fused)
                                v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(2) + ic_1)
                                v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                                v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                                T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)], p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block])
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)] * p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(8), T.int64(56), T.int64(8)):
                for ax4_fused in T.vectorized(T.int64(4)):
                    with T.block("T_relu"):
                        v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                        v_ax3 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(8) * T.int64(8) + ax3)
                        v_ax4 = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(8) * T.int64(4) + ax4_fused)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 2, 4, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 2, 28])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[7, 2, 2, 2])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[8, 1, 2, 2])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[128, 2])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=6)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82 = sch.get_loops(block=b68)
l83 = sch.fuse(l71, l72, l73, l74, l75, preserve_unit_iters=True)
sch.parallel(loop=l83)
l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105 = sch.get_loops(block=b69)
l106 = sch.fuse(l84, preserve_unit_iters=True)
sch.parallel(loop=l106)
l107 = sch.fuse(l105, preserve_unit_iters=True)
sch.vectorize(loop=l107)
sch.annotate(block_or_loop=l106, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l106, ann_key="pragma_unroll_explicit", ann_val=1)
l108, l109, l110, l111, l112, l113 = sch.get_loops(block=b70)
l114 = sch.fuse(l113, preserve_unit_iters=True)
sch.vectorize(loop=l114)
b115 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137 = sch.get_loops(block=b115)
b138 = sch.decompose_reduction(block=b115, loop=l122)
2024-04-30 06:58:29 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #192: GFLOPs: 9.7892. Time: 378067.4560 us. Best GFLOPs: 605.8353
2024-04-30 07:20:41 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-30 07:20:42 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-30 07:20:46 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 07:20:46 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-30 07:20:59 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 07:21:13 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 07:21:27 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 07:21:41 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 07:21:50 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.8921  0.8921  0.8857  0.8721  0.8721  0.8656  0.8470  0.8095  0.8095  0.8057  0.7656  0.7384  0.7384  0.7384  0.7384  0.7149
[17 : 32]:	0.7135  0.7085  0.7073  0.7037  0.6994  0.6935  0.6935  0.6913  0.6913  0.6887  0.6825  0.6815  0.6694  0.6692  0.6645  0.6645
[33 : 48]:	0.6645  0.6644  0.6558  0.6558  0.6532  0.6532  0.6497  0.6497  0.6497  0.6497  0.6492  0.6492  0.6481  0.6480  0.6435  0.6435
[49 : 64]:	0.6435  0.6435  0.6407  0.6407  0.6346  0.6346  0.6254  0.6240  0.6233  0.6233  0.6218  0.6218  0.6200  0.6129  0.6094  0.6094
2024-04-30 07:21:50 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-30 07:21:50 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-30 07:23:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #193: GFLOPs: 389.1023. Time: 9511.5915 us. Best GFLOPs: 605.8353
2024-04-30 07:23:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #194: GFLOPs: 122.6732. Time: 30169.4435 us. Best GFLOPs: 605.8353
2024-04-30 07:23:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #195: GFLOPs: 593.4660. Time: 6236.2154 us. Best GFLOPs: 605.8353
2024-04-30 07:23:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #196: GFLOPs: 238.6558. Time: 15507.6150 us. Best GFLOPs: 605.8353
2024-04-30 07:23:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #197: GFLOPs: 578.2032. Time: 6400.8324 us. Best GFLOPs: 605.8353
2024-04-30 07:23:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #198: GFLOPs: 239.2190. Time: 15471.1001 us. Best GFLOPs: 605.8353
2024-04-30 07:23:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #199: GFLOPs: 94.5084. Time: 39160.3397 us. Best GFLOPs: 605.8353
2024-04-30 07:23:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #200: GFLOPs: 163.8947. Time: 22581.4640 us. Best GFLOPs: 605.8353
2024-04-30 07:23:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #201: GFLOPs: 287.8481. Time: 12857.4146 us. Best GFLOPs: 605.8353
2024-04-30 07:23:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #202: GFLOPs: 309.9792. Time: 11939.4533 us. Best GFLOPs: 605.8353
2024-04-30 07:23:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #203: GFLOPs: 119.1734. Time: 31055.4412 us. Best GFLOPs: 605.8353
2024-04-30 07:23:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #204: GFLOPs: 560.0910. Time: 6607.8223 us. Best GFLOPs: 605.8353
2024-04-30 07:23:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #205: GFLOPs: 116.5619. Time: 31751.2258 us. Best GFLOPs: 605.8353
2024-04-30 07:23:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #206: GFLOPs: 449.7859. Time: 8228.3191 us. Best GFLOPs: 605.8353
2024-04-30 07:23:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #207: GFLOPs: 116.6497. Time: 31727.3030 us. Best GFLOPs: 605.8353
2024-04-30 07:23:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #208: GFLOPs: 564.7259. Time: 6553.5901 us. Best GFLOPs: 605.8353
2024-04-30 07:23:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #209: GFLOPs: 284.5031. Time: 13008.5834 us. Best GFLOPs: 605.8353
2024-04-30 07:23:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #210: GFLOPs: 102.2302. Time: 36202.4387 us. Best GFLOPs: 605.8353
2024-04-30 07:23:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #211: GFLOPs: 270.8958. Time: 13662.0146 us. Best GFLOPs: 605.8353
2024-04-30 07:23:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #212: GFLOPs: 118.9353. Time: 31117.6025 us. Best GFLOPs: 605.8353
2024-04-30 07:23:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #213: GFLOPs: 560.0191. Time: 6608.6710 us. Best GFLOPs: 605.8353
2024-04-30 07:23:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #214: GFLOPs: 418.3540. Time: 8846.5320 us. Best GFLOPs: 605.8353
2024-04-30 07:23:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #215: GFLOPs: 100.9139. Time: 36674.6435 us. Best GFLOPs: 605.8353
2024-04-30 07:23:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #216: GFLOPs: 391.6802. Time: 9448.9895 us. Best GFLOPs: 605.8353
2024-04-30 07:23:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #217: GFLOPs: 117.3548. Time: 31536.6923 us. Best GFLOPs: 605.8353
2024-04-30 07:23:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #218: GFLOPs: 395.2556. Time: 9363.5154 us. Best GFLOPs: 605.8353
2024-04-30 07:23:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #219: GFLOPs: 122.3988. Time: 30237.0747 us. Best GFLOPs: 605.8353
2024-04-30 07:23:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #220: GFLOPs: 507.6394. Time: 7290.5724 us. Best GFLOPs: 605.8353
2024-04-30 07:23:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #221: GFLOPs: 103.6800. Time: 35696.1933 us. Best GFLOPs: 605.8353
2024-04-30 07:23:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #222: GFLOPs: 436.6392. Time: 8476.0631 us. Best GFLOPs: 605.8353
2024-04-30 07:23:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #223: GFLOPs: 608.0816. Time: 6086.3240 us. Best GFLOPs: 608.0816
2024-04-30 07:23:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #224: GFLOPs: 102.3921. Time: 36145.2010 us. Best GFLOPs: 608.0816
2024-04-30 07:23:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #225: GFLOPs: 457.5882. Time: 8088.0182 us. Best GFLOPs: 608.0816
2024-04-30 07:23:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #226: GFLOPs: 534.7381. Time: 6921.1115 us. Best GFLOPs: 608.0816
2024-04-30 07:23:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #227: GFLOPs: 434.6913. Time: 8514.0454 us. Best GFLOPs: 608.0816
2024-04-30 07:23:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #228: GFLOPs: 123.1500. Time: 30052.6390 us. Best GFLOPs: 608.0816
2024-04-30 07:23:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #229: GFLOPs: 109.8382. Time: 33694.8587 us. Best GFLOPs: 608.0816
2024-04-30 07:23:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #230: GFLOPs: 513.3376. Time: 7209.6453 us. Best GFLOPs: 608.0816
2024-04-30 07:23:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #231: GFLOPs: 66.6159. Time: 55557.0160 us. Best GFLOPs: 608.0816
2024-04-30 07:23:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #232: GFLOPs: 396.3582. Time: 9337.4676 us. Best GFLOPs: 608.0816
2024-04-30 07:23:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #233: GFLOPs: 108.3216. Time: 34166.6203 us. Best GFLOPs: 608.0816
2024-04-30 07:23:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #234: GFLOPs: 529.2156. Time: 6993.3341 us. Best GFLOPs: 608.0816
2024-04-30 07:23:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #235: GFLOPs: 353.5551. Time: 10467.9058 us. Best GFLOPs: 608.0816
2024-04-30 07:23:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #236: GFLOPs: 482.3291. Time: 7673.1469 us. Best GFLOPs: 608.0816
2024-04-30 07:23:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #237: GFLOPs: 498.0102. Time: 7431.5376 us. Best GFLOPs: 608.0816
2024-04-30 07:23:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #238: GFLOPs: 388.0142. Time: 9538.2647 us. Best GFLOPs: 608.0816
2024-04-30 07:23:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #239: GFLOPs: 152.2821. Time: 24303.4518 us. Best GFLOPs: 608.0816
2024-04-30 07:23:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #240: GFLOPs: 90.9089. Time: 40710.8763 us. Best GFLOPs: 608.0816
2024-04-30 07:23:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #241: GFLOPs: 177.9165. Time: 20801.7912 us. Best GFLOPs: 608.0816
2024-04-30 07:23:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #242: GFLOPs: 195.0169. Time: 18977.7443 us. Best GFLOPs: 608.0816
2024-04-30 07:23:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #243: GFLOPs: 101.0253. Time: 36634.2127 us. Best GFLOPs: 608.0816
2024-04-30 07:23:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #244: GFLOPs: 406.9750. Time: 9093.8807 us. Best GFLOPs: 608.0816
2024-04-30 07:23:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #245: GFLOPs: 96.2727. Time: 38442.6973 us. Best GFLOPs: 608.0816
2024-04-30 07:23:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #246: GFLOPs: 416.8361. Time: 8878.7468 us. Best GFLOPs: 608.0816
2024-04-30 07:23:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #247: GFLOPs: 391.7598. Time: 9447.0686 us. Best GFLOPs: 608.0816
2024-04-30 07:23:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #248: GFLOPs: 393.6471. Time: 9401.7761 us. Best GFLOPs: 608.0816
2024-04-30 07:23:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #249: GFLOPs: 81.4310. Time: 45449.2717 us. Best GFLOPs: 608.0816
2024-04-30 07:23:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #250: GFLOPs: 540.0550. Time: 6852.9717 us. Best GFLOPs: 608.0816
2024-04-30 07:23:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #251: GFLOPs: 343.8357. Time: 10763.8089 us. Best GFLOPs: 608.0816
2024-04-30 07:23:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #252: GFLOPs: 352.1155. Time: 10510.7036 us. Best GFLOPs: 608.0816
2024-04-30 07:23:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #253: GFLOPs: 407.2936. Time: 9086.7664 us. Best GFLOPs: 608.0816
2024-04-30 07:23:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #254: GFLOPs: 24.2481. Time: 152629.6097 us. Best GFLOPs: 608.0816
2024-04-30 07:23:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #255: GFLOPs: 2.5643. Time: 1443294.9423 us. Best GFLOPs: 608.0816
2024-04-30 07:23:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #256: GFLOPs: 27.8488. Time: 132895.5923 us. Best GFLOPs: 608.0816
2024-04-30 07:29:41 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-30 07:29:42 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-30 07:29:47 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 07:29:47 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-30 07:30:00 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 07:30:13 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 07:30:27 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 07:30:41 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 07:30:50 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9402  0.9402  0.8835  0.8251  0.8251  0.8251  0.8206  0.8206  0.8206  0.8174  0.8046  0.8046  0.8008  0.7945  0.7945  0.7945
[17 : 32]:	0.7945  0.7943  0.7943  0.7943  0.7826  0.7826  0.7646  0.7646  0.7646  0.7646  0.7593  0.7592  0.7592  0.7546  0.7546  0.7494
[33 : 48]:	0.7494  0.7494  0.7494  0.7494  0.7494  0.7494  0.7481  0.7481  0.7441  0.7441  0.7404  0.7400  0.7400  0.7349  0.7334  0.7334
[49 : 64]:	0.7291  0.7291  0.7142  0.7053  0.6963  0.6862  0.6789  0.6787  0.6787  0.6787  0.6640  0.6640  0.6634  0.6629  0.6629  0.6582
2024-04-30 07:30:50 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-30 07:30:50 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-30 07:32:19 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #257: GFLOPs: 593.2481. Time: 6238.5064 us. Best GFLOPs: 608.0816
2024-04-30 07:32:19 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #258: GFLOPs: 495.2101. Time: 7473.5588 us. Best GFLOPs: 608.0816
2024-04-30 07:32:19 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #259: GFLOPs: 85.0295. Time: 43525.8643 us. Best GFLOPs: 608.0816
2024-04-30 07:32:19 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #260: GFLOPs: 430.4375. Time: 8598.1857 us. Best GFLOPs: 608.0816
2024-04-30 07:32:19 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #261: GFLOPs: 435.8624. Time: 8491.1705 us. Best GFLOPs: 608.0816
2024-04-30 07:32:19 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #262: GFLOPs: 441.5138. Time: 8382.4819 us. Best GFLOPs: 608.0816
2024-04-30 07:32:19 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #263: GFLOPs: 252.1951. Time: 14675.0729 us. Best GFLOPs: 608.0816
2024-04-30 07:32:19 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #264: GFLOPs: 564.5490. Time: 6555.6436 us. Best GFLOPs: 608.0816
2024-04-30 07:32:19 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #265: GFLOPs: 410.5226. Time: 9015.2937 us. Best GFLOPs: 608.0816
2024-04-30 07:32:19 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #266: GFLOPs: 512.3764. Time: 7223.1701 us. Best GFLOPs: 608.0816
2024-04-30 07:32:19 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #267: GFLOPs: 372.3231. Time: 9940.2414 us. Best GFLOPs: 608.0816
2024-04-30 07:32:19 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #268: GFLOPs: 85.9971. Time: 43036.1023 us. Best GFLOPs: 608.0816
2024-04-30 07:32:19 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #269: GFLOPs: 523.3839. Time: 7071.2565 us. Best GFLOPs: 608.0816
2024-04-30 07:32:19 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #270: GFLOPs: 536.6339. Time: 6896.6601 us. Best GFLOPs: 608.0816
2024-04-30 07:32:19 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #271: GFLOPs: 125.7166. Time: 29439.0925 us. Best GFLOPs: 608.0816
2024-04-30 07:32:19 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #272: GFLOPs: 442.6230. Time: 8361.4766 us. Best GFLOPs: 608.0816
2024-04-30 07:32:19 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #273: GFLOPs: 382.8225. Time: 9667.6185 us. Best GFLOPs: 608.0816
2024-04-30 07:32:19 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #274: GFLOPs: 98.0493. Time: 37746.1443 us. Best GFLOPs: 608.0816
2024-04-30 07:32:19 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #275: GFLOPs: 434.9041. Time: 8509.8800 us. Best GFLOPs: 608.0816
2024-04-30 07:32:19 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #276: GFLOPs: 429.4384. Time: 8618.1911 us. Best GFLOPs: 608.0816
2024-04-30 07:32:19 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #277: GFLOPs: 79.2305. Time: 46711.5830 us. Best GFLOPs: 608.0816
2024-04-30 07:32:19 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #278: GFLOPs: 441.8334. Time: 8376.4193 us. Best GFLOPs: 608.0816
2024-04-30 07:32:19 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #279: GFLOPs: 582.1568. Time: 6357.3621 us. Best GFLOPs: 608.0816
2024-04-30 07:32:19 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #280: GFLOPs: 446.0142. Time: 8297.9015 us. Best GFLOPs: 608.0816
2024-04-30 07:32:19 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #281: GFLOPs: 103.0699. Time: 35907.4957 us. Best GFLOPs: 608.0816
2024-04-30 07:32:19 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #282: GFLOPs: 587.4863. Time: 6299.6904 us. Best GFLOPs: 608.0816
2024-04-30 07:32:19 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #283: GFLOPs: 445.7568. Time: 8302.6932 us. Best GFLOPs: 608.0816
2024-04-30 07:32:19 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #284: GFLOPs: 114.3676. Time: 32360.4135 us. Best GFLOPs: 608.0816
2024-04-30 07:32:19 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #285: GFLOPs: 369.0955. Time: 10027.1658 us. Best GFLOPs: 608.0816
2024-04-30 07:32:19 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #286: GFLOPs: 101.1897. Time: 36574.7003 us. Best GFLOPs: 608.0816
2024-04-30 07:32:19 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #287: GFLOPs: 60.7952. Time: 60876.2517 us. Best GFLOPs: 608.0816
2024-04-30 07:32:19 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #288: GFLOPs: 102.0603. Time: 36262.6950 us. Best GFLOPs: 608.0816
2024-04-30 07:32:19 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #289: GFLOPs: 584.5056. Time: 6331.8154 us. Best GFLOPs: 608.0816
2024-04-30 07:32:19 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #290: GFLOPs: 588.0154. Time: 6294.0216 us. Best GFLOPs: 608.0816
2024-04-30 07:32:19 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #291: GFLOPs: 103.2171. Time: 35856.2913 us. Best GFLOPs: 608.0816
2024-04-30 07:32:19 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #292: GFLOPs: 103.1108. Time: 35893.2487 us. Best GFLOPs: 608.0816
2024-04-30 07:32:19 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #293: GFLOPs: 444.7043. Time: 8322.3435 us. Best GFLOPs: 608.0816
2024-04-30 07:32:19 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #294: GFLOPs: 586.4187. Time: 6311.1594 us. Best GFLOPs: 608.0816
2024-04-30 07:32:19 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #295: GFLOPs: 415.2246. Time: 8913.2036 us. Best GFLOPs: 608.0816
2024-04-30 07:32:19 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #296: GFLOPs: 427.9673. Time: 8647.8148 us. Best GFLOPs: 608.0816
2024-04-30 07:32:19 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #297: GFLOPs: 452.5309. Time: 8178.4072 us. Best GFLOPs: 608.0816
2024-04-30 07:32:19 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #298: GFLOPs: 102.0359. Time: 36271.3620 us. Best GFLOPs: 608.0816
2024-04-30 07:32:19 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #299: GFLOPs: 571.4946. Time: 6475.9698 us. Best GFLOPs: 608.0816
2024-04-30 07:32:19 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #300: GFLOPs: 86.4154. Time: 42827.8220 us. Best GFLOPs: 608.0816
2024-04-30 07:32:19 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #301: GFLOPs: 356.4756. Time: 10382.1449 us. Best GFLOPs: 608.0816
2024-04-30 07:32:19 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #302: GFLOPs: 530.1486. Time: 6981.0277 us. Best GFLOPs: 608.0816
2024-04-30 07:32:19 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #303: GFLOPs: 83.3049. Time: 44426.9233 us. Best GFLOPs: 608.0816
2024-04-30 07:32:19 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #304: GFLOPs: 573.2608. Time: 6456.0177 us. Best GFLOPs: 608.0816
2024-04-30 07:32:19 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #305: GFLOPs: 303.3443. Time: 12200.5970 us. Best GFLOPs: 608.0816
2024-04-30 07:32:19 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #306: GFLOPs: 421.1069. Time: 8788.6990 us. Best GFLOPs: 608.0816
2024-04-30 07:32:19 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #307: GFLOPs: 473.1564. Time: 7821.8994 us. Best GFLOPs: 608.0816
2024-04-30 07:32:19 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #308: GFLOPs: 494.3031. Time: 7487.2726 us. Best GFLOPs: 608.0816
2024-04-30 07:32:19 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #309: GFLOPs: 391.4806. Time: 9453.8075 us. Best GFLOPs: 608.0816
2024-04-30 07:32:19 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #310: GFLOPs: 183.9103. Time: 20123.8448 us. Best GFLOPs: 608.0816
2024-04-30 07:32:19 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #311: GFLOPs: 396.3281. Time: 9338.1764 us. Best GFLOPs: 608.0816
2024-04-30 07:32:19 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #312: GFLOPs: 75.5322. Time: 48998.7423 us. Best GFLOPs: 608.0816
2024-04-30 07:32:19 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #313: GFLOPs: 420.0582. Time: 8810.6402 us. Best GFLOPs: 608.0816
2024-04-30 07:32:19 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #314: GFLOPs: 339.8822. Time: 10889.0117 us. Best GFLOPs: 608.0816
2024-04-30 07:32:19 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #315: GFLOPs: 267.7730. Time: 13821.3383 us. Best GFLOPs: 608.0816
2024-04-30 07:32:19 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #316: GFLOPs: 406.2004. Time: 9111.2206 us. Best GFLOPs: 608.0816
2024-04-30 07:32:19 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #317: GFLOPs: 397.0039. Time: 9322.2806 us. Best GFLOPs: 608.0816
2024-04-30 07:32:19 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #318: GFLOPs: 14.3181. Time: 258483.0397 us. Best GFLOPs: 608.0816
2024-04-30 07:32:19 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #319: GFLOPs: 30.8277. Time: 120053.9003 us. Best GFLOPs: 608.0816
2024-04-30 07:32:19 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #320: GFLOPs: 45.9339. Time: 80571.8263 us. Best GFLOPs: 608.0816
2024-04-30 07:32:19 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-30 07:32:20 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-30 07:32:25 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 07:32:25 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-30 07:32:38 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 07:32:52 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 07:33:06 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 07:33:20 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 07:33:29 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9055  0.8466  0.8466  0.8276  0.8276  0.8276  0.8276  0.8276  0.8276  0.8101  0.8038  0.8038  0.8038  0.8038  0.8038  0.8038
[17 : 32]:	0.8024  0.8020  0.7964  0.7958  0.7958  0.7958  0.7958  0.7915  0.7896  0.7896  0.7836  0.7836  0.7771  0.7771  0.7771  0.7745
[33 : 48]:	0.7648  0.7648  0.7648  0.7648  0.7637  0.7569  0.7569  0.7561  0.7541  0.7393  0.7393  0.7382  0.7382  0.7382  0.7341  0.7341
[49 : 64]:	0.7341  0.7341  0.7341  0.7265  0.7265  0.7265  0.7265  0.7265  0.7260  0.7260  0.7260  0.7260  0.7162  0.7162  0.7162  0.7162
2024-04-30 07:33:29 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-30 07:33:29 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-30 07:35:16 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #321: GFLOPs: 129.1545. Time: 28655.4713 us. Best GFLOPs: 608.0816
2024-04-30 07:35:16 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #322: GFLOPs: 80.7391. Time: 45838.7603 us. Best GFLOPs: 608.0816
2024-04-30 07:35:16 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #323: GFLOPs: 516.0179. Time: 7172.1964 us. Best GFLOPs: 608.0816
2024-04-30 07:35:16 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #324: GFLOPs: 575.0871. Time: 6435.5152 us. Best GFLOPs: 608.0816
2024-04-30 07:35:16 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #325: GFLOPs: 452.0805. Time: 8186.5556 us. Best GFLOPs: 608.0816
2024-04-30 07:35:16 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #326: GFLOPs: 456.3765. Time: 8109.4920 us. Best GFLOPs: 608.0816
2024-04-30 07:35:16 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #327: GFLOPs: 102.0961. Time: 36249.9710 us. Best GFLOPs: 608.0816
2024-04-30 07:35:16 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #328: GFLOPs: 451.8321. Time: 8191.0549 us. Best GFLOPs: 608.0816
2024-04-30 07:35:16 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #329: GFLOPs: 96.1296. Time: 38499.9000 us. Best GFLOPs: 608.0816
2024-04-30 07:35:16 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #330: GFLOPs: 128.7423. Time: 28747.2028 us. Best GFLOPs: 608.0816
2024-04-30 07:35:16 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #331: GFLOPs: 116.5529. Time: 31753.6547 us. Best GFLOPs: 608.0816
2024-04-30 07:35:16 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #332: GFLOPs: 584.6580. Time: 6330.1653 us. Best GFLOPs: 608.0816
2024-04-30 07:35:16 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #333: GFLOPs: 582.9741. Time: 6348.4493 us. Best GFLOPs: 608.0816
2024-04-30 07:35:16 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #334: GFLOPs: 103.0165. Time: 35926.1153 us. Best GFLOPs: 608.0816
2024-04-30 07:35:16 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #335: GFLOPs: 583.7855. Time: 6339.6260 us. Best GFLOPs: 608.0816
2024-04-30 07:35:16 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #336: GFLOPs: 587.1832. Time: 6302.9423 us. Best GFLOPs: 608.0816
2024-04-30 07:35:16 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #337: GFLOPs: 375.6983. Time: 9850.9405 us. Best GFLOPs: 608.0816
2024-04-30 07:35:16 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #338: GFLOPs: 514.9963. Time: 7186.4244 us. Best GFLOPs: 608.0816
2024-04-30 07:35:16 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #339: GFLOPs: 102.9392. Time: 35953.0993 us. Best GFLOPs: 608.0816
2024-04-30 07:35:16 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #340: GFLOPs: 351.5880. Time: 10526.4733 us. Best GFLOPs: 608.0816
2024-04-30 07:35:16 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #341: GFLOPs: 115.4096. Time: 32068.2378 us. Best GFLOPs: 608.0816
2024-04-30 07:35:16 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #342: GFLOPs: 440.1653. Time: 8408.1625 us. Best GFLOPs: 608.0816
2024-04-30 07:35:16 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #343: GFLOPs: 101.7742. Time: 36364.6463 us. Best GFLOPs: 608.0816
2024-04-30 07:35:16 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #344: GFLOPs: 106.2015. Time: 34848.6800 us. Best GFLOPs: 608.0816
2024-04-30 07:35:16 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #345: GFLOPs: 98.6106. Time: 37531.2700 us. Best GFLOPs: 608.0816
2024-04-30 07:35:16 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #346: GFLOPs: 424.4049. Time: 8720.4027 us. Best GFLOPs: 608.0816
2024-04-30 07:35:16 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #347: GFLOPs: 337.3335. Time: 10971.2839 us. Best GFLOPs: 608.0816
2024-04-30 07:35:16 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #348: GFLOPs: 127.1025. Time: 29118.0990 us. Best GFLOPs: 608.0816
2024-04-30 07:35:16 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #349: GFLOPs: 117.0809. Time: 31610.4647 us. Best GFLOPs: 608.0816
2024-04-30 07:35:16 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #350: GFLOPs: 438.9373. Time: 8431.6860 us. Best GFLOPs: 608.0816
2024-04-30 07:35:16 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #351: GFLOPs: 552.9146. Time: 6693.5866 us. Best GFLOPs: 608.0816
2024-04-30 07:35:16 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #352: GFLOPs: 128.2433. Time: 28859.0747 us. Best GFLOPs: 608.0816
2024-04-30 07:35:16 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #353: GFLOPs: 61.1749. Time: 60498.4103 us. Best GFLOPs: 608.0816
2024-04-30 07:35:16 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #354: GFLOPs: 588.9180. Time: 6284.3757 us. Best GFLOPs: 608.0816
2024-04-30 07:35:16 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #355: GFLOPs: 119.1251. Time: 31068.0377 us. Best GFLOPs: 608.0816
2024-04-30 07:35:16 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #356: GFLOPs: 437.8461. Time: 8452.6997 us. Best GFLOPs: 608.0816
2024-04-30 07:35:16 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #357: GFLOPs: 549.0668. Time: 6740.4940 us. Best GFLOPs: 608.0816
2024-04-30 07:35:16 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #358: GFLOPs: 318.4064. Time: 11623.4512 us. Best GFLOPs: 608.0816
2024-04-30 07:35:16 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #359: GFLOPs: 134.1712. Time: 27584.0223 us. Best GFLOPs: 608.0816
2024-04-30 07:35:16 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #360: GFLOPs: 556.2460. Time: 6653.4983 us. Best GFLOPs: 608.0816
2024-04-30 07:35:16 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #361: GFLOPs: 606.0283. Time: 6106.9457 us. Best GFLOPs: 608.0816
2024-04-30 07:35:16 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #362: GFLOPs: 255.0449. Time: 14511.0970 us. Best GFLOPs: 608.0816
2024-04-30 07:35:16 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #363: GFLOPs: 541.2149. Time: 6838.2850 us. Best GFLOPs: 608.0816
2024-04-30 07:35:16 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #364: GFLOPs: 87.5819. Time: 42257.3583 us. Best GFLOPs: 608.0816
2024-04-30 07:35:16 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #365: GFLOPs: 60.7279. Time: 60943.6983 us. Best GFLOPs: 608.0816
2024-04-30 07:35:16 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #366: GFLOPs: 577.5951. Time: 6407.5716 us. Best GFLOPs: 608.0816
2024-04-30 07:35:16 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #367: GFLOPs: 102.1927. Time: 36215.7237 us. Best GFLOPs: 608.0816
2024-04-30 07:35:16 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #368: GFLOPs: 441.9866. Time: 8373.5157 us. Best GFLOPs: 608.0816
2024-04-30 07:35:16 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #369: GFLOPs: 70.8297. Time: 52251.8377 us. Best GFLOPs: 608.0816
2024-04-30 07:35:16 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #370: GFLOPs: 89.0208. Time: 41574.3263 us. Best GFLOPs: 608.0816
2024-04-30 07:35:16 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #371: GFLOPs: 435.0551. Time: 8506.9256 us. Best GFLOPs: 608.0816
2024-04-30 07:35:16 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #372: GFLOPs: 102.0066. Time: 36281.7983 us. Best GFLOPs: 608.0816
2024-04-30 07:35:16 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #373: GFLOPs: 425.7048. Time: 8693.7747 us. Best GFLOPs: 608.0816
2024-04-30 07:35:16 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #374: GFLOPs: 125.7523. Time: 29430.7293 us. Best GFLOPs: 608.0816
2024-04-30 07:35:16 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #375: GFLOPs: 385.3397. Time: 9604.4645 us. Best GFLOPs: 608.0816
2024-04-30 07:35:16 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #376: GFLOPs: 419.3838. Time: 8824.8086 us. Best GFLOPs: 608.0816
2024-04-30 07:35:16 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #377: GFLOPs: 73.5315. Time: 50331.9343 us. Best GFLOPs: 608.0816
2024-04-30 07:35:16 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #378: GFLOPs: 450.2936. Time: 8219.0423 us. Best GFLOPs: 608.0816
2024-04-30 07:35:16 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #379: GFLOPs: 424.3049. Time: 8722.4577 us. Best GFLOPs: 608.0816
2024-04-30 07:35:16 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #380: GFLOPs: 109.8102. Time: 33703.4467 us. Best GFLOPs: 608.0816
2024-04-30 07:35:16 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #381: GFLOPs: 539.7367. Time: 6857.0134 us. Best GFLOPs: 608.0816
2024-04-30 07:35:16 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #382: GFLOPs: 49.7436. Time: 74401.1780 us. Best GFLOPs: 608.0816
2024-04-30 07:35:16 [INFO] [task_scheduler.cc:121] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #383: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(56), T.int64(56), T.int64(256)), "float32"), p1: T.Buffer((T.int64(8), T.int64(1), T.int64(3), T.int64(3), T.int64(256), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(58), T.int64(58), T.int64(256)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused in T.parallel(T.int64(64)):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(9), T.int64(16), T.int64(256)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(32) * T.int64(28) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(4) * T.int64(7) + ax2)
                    v_i3 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(32) // T.int64(8) * T.int64(14) + ax3)
                    v_i4 = T.axis.spatial(T.int64(256), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(57) and T.int64(1) <= v_i3 and v_i3 < T.int64(57), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for ow_1, oc_block_1 in T.grid(T.int64(2), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(4), T.int64(7), T.int64(1), T.int64(16), T.int64(1), T.int64(2), T.int64(1), T.int64(7), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(8), oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(32) * T.int64(28) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(4) * T.int64(7) + oh_2_init + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(32) // T.int64(8) * T.int64(14) + ow_1 * T.int64(7) + ow_2_init * T.int64(7) + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(8) // T.int64(4) * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(64), T.int64(3), T.int64(1), T.int64(1), T.int64(4), T.int64(7), T.int64(1), T.int64(16), T.int64(4), T.int64(1), T.int64(3), T.int64(1), T.int64(2), T.int64(1), T.int64(7), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(8), oc_chunk_2 * T.int64(2) + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(32) * T.int64(28) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(4) * T.int64(7) + oh_2 + oh_3)
                        v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(32) // T.int64(8) * T.int64(14) + ow_1 * T.int64(7) + ow_2 * T.int64(7) + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(8) // T.int64(4) * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(4) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)], p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)] * p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block]
        for ax0_ax1_ax2_ax3_ax4_fused_0 in T.parallel(T.int64(12544)):
            for ax0_ax1_ax2_ax3_ax4_fused_1 in T.vectorized(T.int64(64)):
                with T.block("T_relu"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(8), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) // T.int64(100352))
                    v_ax2 = T.axis.spatial(T.int64(56), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(100352) // T.int64(1792))
                    v_ax3 = T.axis.spatial(T.int64(56), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(1792) // T.int64(32))
                    v_ax4 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(32))
                    T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                    T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 4, 2])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 4, 7, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[4, 2, 1, 7])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[2, 1, 16, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[64, 4])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
l65 = sch.sample_compute_location(block=b0, decision=7)
sch.compute_at(block=b0, loop=l65, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b66 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.unroll_explicit")
b67, b68, b69 = sch.get_child_blocks(b66)
l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82 = sch.get_loops(block=b67)
l83 = sch.fuse(l70, l71, l72, l73, l74, l75, l76, l77, preserve_unit_iters=True)
sch.parallel(loop=l83)
l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102 = sch.get_loops(block=b68)
l103 = sch.fuse(l84, preserve_unit_iters=True)
sch.parallel(loop=l103)
l104, l105, l106, l107, l108 = sch.get_loops(block=b69)
l109 = sch.fuse(l104, l105, l106, l107, l108, preserve_unit_iters=True)
l110, l111 = sch.split(loop=l109, factors=[None, 64], preserve_unit_iters=True)
sch.parallel(loop=l110)
sch.vectorize(loop=l111)
b112 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l113, l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131 = sch.get_loops(block=b112)
b132 = sch.decompose_reduction(block=b112, loop=l116)
2024-04-30 07:35:16 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #384: GFLOPs: 16.4345. Time: 225196.4547 us. Best GFLOPs: 608.0816
2024-04-30 07:43:49 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-30 07:43:50 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-30 07:43:55 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 07:43:55 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-30 07:44:08 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 07:44:21 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 07:44:35 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 07:44:49 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 07:44:58 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9496  0.9496  0.9102  0.8570  0.8570  0.8479  0.8479  0.8479  0.8385  0.8385  0.8176  0.8176  0.8155  0.8155  0.8155  0.8155
[17 : 32]:	0.8130  0.7745  0.7745  0.7745  0.7711  0.7683  0.7683  0.7683  0.7573  0.7559  0.7559  0.7536  0.7517  0.7496  0.7496  0.7496
[33 : 48]:	0.7496  0.7496  0.7496  0.7472  0.7440  0.7402  0.7390  0.7330  0.7265  0.7265  0.7239  0.7232  0.7227  0.7227  0.7227  0.7174
[49 : 64]:	0.7135  0.7135  0.7135  0.7091  0.7091  0.7021  0.7017  0.6966  0.6966  0.6945  0.6917  0.6865  0.6848  0.6845  0.6845  0.6831
2024-04-30 07:44:59 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-30 07:44:59 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-30 07:46:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #385: GFLOPs: 103.5111. Time: 35754.4317 us. Best GFLOPs: 608.0816
2024-04-30 07:46:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #386: GFLOPs: 516.8477. Time: 7160.6812 us. Best GFLOPs: 608.0816
2024-04-30 07:46:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #387: GFLOPs: 641.4955. Time: 5769.3026 us. Best GFLOPs: 641.4955
2024-04-30 07:46:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #388: GFLOPs: 551.2410. Time: 6713.9081 us. Best GFLOPs: 641.4955
2024-04-30 07:46:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #389: GFLOPs: 555.5961. Time: 6661.2808 us. Best GFLOPs: 641.4955
2024-04-30 07:46:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #390: GFLOPs: 445.7704. Time: 8302.4398 us. Best GFLOPs: 641.4955
2024-04-30 07:46:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #391: GFLOPs: 545.6617. Time: 6782.5573 us. Best GFLOPs: 641.4955
2024-04-30 07:46:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #392: GFLOPs: 258.2610. Time: 14330.3936 us. Best GFLOPs: 641.4955
2024-04-30 07:46:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #393: GFLOPs: 465.0543. Time: 7958.1715 us. Best GFLOPs: 641.4955
2024-04-30 07:46:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #394: GFLOPs: 260.3358. Time: 14216.1821 us. Best GFLOPs: 641.4955
2024-04-30 07:46:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #395: GFLOPs: 303.3166. Time: 12201.7100 us. Best GFLOPs: 641.4955
2024-04-30 07:46:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #396: GFLOPs: 590.1882. Time: 6270.8503 us. Best GFLOPs: 641.4955
2024-04-30 07:46:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #397: GFLOPs: 101.9620. Time: 36297.6643 us. Best GFLOPs: 641.4955
2024-04-30 07:46:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #398: GFLOPs: 116.1778. Time: 31856.1935 us. Best GFLOPs: 641.4955
2024-04-30 07:46:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #399: GFLOPs: 444.0728. Time: 8334.1775 us. Best GFLOPs: 641.4955
2024-04-30 07:46:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #400: GFLOPs: 585.1353. Time: 6325.0019 us. Best GFLOPs: 641.4955
2024-04-30 07:46:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #401: GFLOPs: 510.2209. Time: 7253.6854 us. Best GFLOPs: 641.4955
2024-04-30 07:46:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #402: GFLOPs: 80.4395. Time: 46009.5090 us. Best GFLOPs: 641.4955
2024-04-30 07:46:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #403: GFLOPs: 86.6394. Time: 42717.0987 us. Best GFLOPs: 641.4955
2024-04-30 07:46:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #404: GFLOPs: 90.4021. Time: 40939.1313 us. Best GFLOPs: 641.4955
2024-04-30 07:46:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #405: GFLOPs: 566.0305. Time: 6538.4843 us. Best GFLOPs: 641.4955
2024-04-30 07:46:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #406: GFLOPs: 384.2150. Time: 9632.5797 us. Best GFLOPs: 641.4955
2024-04-30 07:46:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #407: GFLOPs: 102.0917. Time: 36251.5303 us. Best GFLOPs: 641.4955
2024-04-30 07:46:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #408: GFLOPs: 451.5653. Time: 8195.8941 us. Best GFLOPs: 641.4955
2024-04-30 07:46:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #409: GFLOPs: 446.3763. Time: 8291.1703 us. Best GFLOPs: 641.4955
2024-04-30 07:46:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #410: GFLOPs: 513.9003. Time: 7201.7509 us. Best GFLOPs: 641.4955
2024-04-30 07:46:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #411: GFLOPs: 432.9644. Time: 8548.0053 us. Best GFLOPs: 641.4955
2024-04-30 07:46:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #412: GFLOPs: 570.8249. Time: 6483.5671 us. Best GFLOPs: 641.4955
2024-04-30 07:46:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #413: GFLOPs: 80.4896. Time: 45980.8853 us. Best GFLOPs: 641.4955
2024-04-30 07:46:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #414: GFLOPs: 539.3432. Time: 6862.0160 us. Best GFLOPs: 641.4955
2024-04-30 07:46:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #415: GFLOPs: 453.1251. Time: 8167.6820 us. Best GFLOPs: 641.4955
2024-04-30 07:46:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #416: GFLOPs: 506.2409. Time: 7310.7129 us. Best GFLOPs: 641.4955
2024-04-30 07:46:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #417: GFLOPs: 134.4368. Time: 27529.5363 us. Best GFLOPs: 641.4955
2024-04-30 07:46:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #418: GFLOPs: 156.3543. Time: 23670.4854 us. Best GFLOPs: 641.4955
2024-04-30 07:46:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #419: GFLOPs: 545.5633. Time: 6783.7807 us. Best GFLOPs: 641.4955
2024-04-30 07:46:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #420: GFLOPs: 445.7334. Time: 8303.1290 us. Best GFLOPs: 641.4955
2024-04-30 07:46:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #421: GFLOPs: 452.6151. Time: 8176.8853 us. Best GFLOPs: 641.4955
2024-04-30 07:46:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #422: GFLOPs: 379.6343. Time: 9748.8077 us. Best GFLOPs: 641.4955
2024-04-30 07:46:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #423: GFLOPs: 536.0475. Time: 6904.2047 us. Best GFLOPs: 641.4955
2024-04-30 07:46:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #424: GFLOPs: 335.4676. Time: 11032.3069 us. Best GFLOPs: 641.4955
2024-04-30 07:46:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #425: GFLOPs: 546.3289. Time: 6774.2738 us. Best GFLOPs: 641.4955
2024-04-30 07:46:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #426: GFLOPs: 67.9749. Time: 54446.2817 us. Best GFLOPs: 641.4955
2024-04-30 07:46:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #427: GFLOPs: 132.4250. Time: 27947.7533 us. Best GFLOPs: 641.4955
2024-04-30 07:46:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #428: GFLOPs: 477.5460. Time: 7750.0010 us. Best GFLOPs: 641.4955
2024-04-30 07:46:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #429: GFLOPs: 490.2372. Time: 7549.3691 us. Best GFLOPs: 641.4955
2024-04-30 07:46:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #430: GFLOPs: 589.7172. Time: 6275.8585 us. Best GFLOPs: 641.4955
2024-04-30 07:46:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #431: GFLOPs: 102.9310. Time: 35955.9653 us. Best GFLOPs: 641.4955
2024-04-30 07:46:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #432: GFLOPs: 549.2680. Time: 6738.0252 us. Best GFLOPs: 641.4955
2024-04-30 07:46:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #433: GFLOPs: 98.5362. Time: 37559.5997 us. Best GFLOPs: 641.4955
2024-04-30 07:46:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #434: GFLOPs: 551.2506. Time: 6713.7921 us. Best GFLOPs: 641.4955
2024-04-30 07:46:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #435: GFLOPs: 408.6323. Time: 9056.9982 us. Best GFLOPs: 641.4955
2024-04-30 07:46:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #436: GFLOPs: 316.6021. Time: 11689.6944 us. Best GFLOPs: 641.4955
2024-04-30 07:46:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #437: GFLOPs: 337.0084. Time: 10981.8669 us. Best GFLOPs: 641.4955
2024-04-30 07:46:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #438: GFLOPs: 588.3761. Time: 6290.1638 us. Best GFLOPs: 641.4955
2024-04-30 07:46:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #439: GFLOPs: 123.0716. Time: 30071.7853 us. Best GFLOPs: 641.4955
2024-04-30 07:46:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #440: GFLOPs: 446.6406. Time: 8286.2642 us. Best GFLOPs: 641.4955
2024-04-30 07:46:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #441: GFLOPs: 117.2162. Time: 31573.9760 us. Best GFLOPs: 641.4955
2024-04-30 07:46:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #442: GFLOPs: 145.9174. Time: 25363.5310 us. Best GFLOPs: 641.4955
2024-04-30 07:46:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #443: GFLOPs: 261.6793. Time: 14143.1946 us. Best GFLOPs: 641.4955
2024-04-30 07:46:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #444: GFLOPs: 534.5989. Time: 6922.9137 us. Best GFLOPs: 641.4955
2024-04-30 07:46:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #445: GFLOPs: 200.3975. Time: 18468.1994 us. Best GFLOPs: 641.4955
2024-04-30 07:46:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #446: GFLOPs: 4.6342. Time: 798618.0460 us. Best GFLOPs: 641.4955
2024-04-30 07:46:52 [INFO] [task_scheduler.cc:121] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #447: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(56), T.int64(56), T.int64(256)), "float32"), p1: T.Buffer((T.int64(8), T.int64(1), T.int64(3), T.int64(3), T.int64(256), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused in T.parallel(T.int64(1568), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for oc_block_1 in range(T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4), T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(2)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(8), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused // T.int64(196) + oc_chunk_2_init + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused % T.int64(196) // T.int64(98) * T.int64(28) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused % T.int64(49) // T.int64(7) * T.int64(4) + oh_2_init + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused % T.int64(7) * T.int64(8) + ow_2_init * T.int64(2) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused % T.int64(98) // T.int64(49) * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2_init * T.int64(4) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(64), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(4), T.int64(4), T.int64(4), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(2)):
                    for oc_block_3_fused in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(8), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused // T.int64(196) + oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused % T.int64(196) // T.int64(98) * T.int64(28) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused % T.int64(49) // T.int64(7) * T.int64(4) + oh_2 + oh_3)
                            v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused % T.int64(7) * T.int64(8) + ow_2 * T.int64(2) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused % T.int64(98) // T.int64(49) * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2 * T.int64(4) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(4) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], p0[v_n, v_ic // T.int64(256), v_oh + v_kh - T.int64(1), v_ow + v_kw - T.int64(1), v_ic % T.int64(256)], p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + T.if_then_else(T.int64(1) <= v_oh + v_kh and v_oh + v_kh < T.int64(57) and T.int64(1) <= v_ow + v_kw and v_ow + v_kw < T.int64(57), p0[v_n, v_ic // T.int64(256), v_oh + v_kh - T.int64(1), v_ow + v_kw - T.int64(1), v_ic % T.int64(256)], T.float32(0)) * p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block]
        for ax0_ax1_ax2_ax3_ax4_fused_0 in T.parallel(T.int64(12544)):
            for ax0_ax1_ax2_ax3_ax4_fused_1 in T.vectorized(T.int64(64)):
                with T.block("T_relu"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(8), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) // T.int64(100352))
                    v_ax2 = T.axis.spatial(T.int64(56), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(100352) // T.int64(1792))
                    v_ax3 = T.axis.spatial(T.int64(56), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(1792) // T.int64(32))
                    v_ax4 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(32))
                    T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                    T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[8, 1, 1, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 7, 4, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 7, 4, 2])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[2, 1, 4, 4])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[64, 4])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
l65 = sch.sample_compute_location(block=b0, decision=-2)
sch.compute_at(block=b0, loop=l65, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b66 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.unroll_explicit")
b67, b68 = sch.get_child_blocks(b66)
l69, l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94 = sch.get_loops(block=b67)
l95 = sch.fuse(l69, l70, l71, l72, l73, l74, l75, l76, l77, preserve_unit_iters=True)
sch.parallel(loop=l95)
l96 = sch.fuse(l94, preserve_unit_iters=True)
sch.vectorize(loop=l96)
sch.annotate(block_or_loop=l95, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l95, ann_key="pragma_unroll_explicit", ann_val=1)
l97, l98, l99, l100, l101 = sch.get_loops(block=b68)
l102 = sch.fuse(l97, l98, l99, l100, l101, preserve_unit_iters=True)
l103, l104 = sch.split(loop=l102, factors=[None, 64], preserve_unit_iters=True)
sch.parallel(loop=l103)
sch.vectorize(loop=l104)
b105 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l106, l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117, l118, l119, l120, l121, l122, l123 = sch.get_loops(block=b105)
b124 = sch.decompose_reduction(block=b105, loop=l108)
2024-04-30 07:46:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #448: GFLOPs: 25.4360. Time: 145501.6967 us. Best GFLOPs: 641.4955
2024-04-30 07:56:33 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-30 07:56:34 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-30 07:56:39 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 07:56:39 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-30 07:56:52 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 07:57:06 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 07:57:20 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 07:57:34 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 07:57:43 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.8168  0.8168  0.8168  0.7902  0.7902  0.7902  0.7860  0.7860  0.7860  0.7860  0.7718  0.7718  0.7677  0.7663  0.7651  0.7634
[17 : 32]:	0.7604  0.7604  0.7604  0.7604  0.7604  0.7469  0.7437  0.7437  0.7431  0.7347  0.7322  0.7322  0.7322  0.7270  0.7263  0.7242
[33 : 48]:	0.7187  0.7176  0.7176  0.7126  0.7126  0.7111  0.7094  0.7094  0.7094  0.7094  0.7094  0.7094  0.7094  0.7094  0.7094  0.7093
[49 : 64]:	0.7092  0.7092  0.7050  0.7050  0.7000  0.6957  0.6942  0.6942  0.6942  0.6931  0.6900  0.6900  0.6830  0.6697  0.6694  0.6668
2024-04-30 07:57:44 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-30 07:57:44 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-30 07:59:34 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #449: GFLOPs: 480.3536. Time: 7704.7032 us. Best GFLOPs: 641.4955
2024-04-30 07:59:34 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #450: GFLOPs: 129.1848. Time: 28648.7327 us. Best GFLOPs: 641.4955
2024-04-30 07:59:34 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #451: GFLOPs: 129.1727. Time: 28651.4330 us. Best GFLOPs: 641.4955
2024-04-30 07:59:34 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #452: GFLOPs: 508.5612. Time: 7277.3584 us. Best GFLOPs: 641.4955
2024-04-30 07:59:34 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #453: GFLOPs: 121.2550. Time: 30522.3077 us. Best GFLOPs: 641.4955
2024-04-30 07:59:34 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #454: GFLOPs: 424.9451. Time: 8709.3165 us. Best GFLOPs: 641.4955
2024-04-30 07:59:34 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #455: GFLOPs: 80.5677. Time: 45936.3243 us. Best GFLOPs: 641.4955
2024-04-30 07:59:34 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #456: GFLOPs: 598.5710. Time: 6183.0293 us. Best GFLOPs: 641.4955
2024-04-30 07:59:34 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #457: GFLOPs: 482.5376. Time: 7669.8305 us. Best GFLOPs: 641.4955
2024-04-30 07:59:34 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #458: GFLOPs: 102.9074. Time: 35964.2050 us. Best GFLOPs: 641.4955
2024-04-30 07:59:34 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #459: GFLOPs: 522.2395. Time: 7086.7525 us. Best GFLOPs: 641.4955
2024-04-30 07:59:34 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #460: GFLOPs: 316.3172. Time: 11700.2222 us. Best GFLOPs: 641.4955
2024-04-30 07:59:34 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #461: GFLOPs: 115.7666. Time: 31969.3402 us. Best GFLOPs: 641.4955
2024-04-30 07:59:34 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #462: GFLOPs: 517.9740. Time: 7145.1106 us. Best GFLOPs: 641.4955
2024-04-30 07:59:34 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #463: GFLOPs: 459.8715. Time: 8047.8607 us. Best GFLOPs: 641.4955
2024-04-30 07:59:34 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #464: GFLOPs: 322.9534. Time: 11459.8028 us. Best GFLOPs: 641.4955
2024-04-30 07:59:34 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #465: GFLOPs: 446.0684. Time: 8296.8935 us. Best GFLOPs: 641.4955
2024-04-30 07:59:34 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #466: GFLOPs: 589.3692. Time: 6279.5642 us. Best GFLOPs: 641.4955
2024-04-30 07:59:34 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #467: GFLOPs: 103.3757. Time: 35801.2723 us. Best GFLOPs: 641.4955
2024-04-30 07:59:34 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #468: GFLOPs: 588.7872. Time: 6285.7712 us. Best GFLOPs: 641.4955
2024-04-30 07:59:34 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #469: GFLOPs: 445.4642. Time: 8308.1468 us. Best GFLOPs: 641.4955
2024-04-30 07:59:34 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #470: GFLOPs: 589.9889. Time: 6272.9684 us. Best GFLOPs: 641.4955
2024-04-30 07:59:34 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #471: GFLOPs: 576.9226. Time: 6415.0403 us. Best GFLOPs: 641.4955
2024-04-30 07:59:34 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #472: GFLOPs: 573.5672. Time: 6452.5684 us. Best GFLOPs: 641.4955
2024-04-30 07:59:34 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #473: GFLOPs: 479.0740. Time: 7725.2812 us. Best GFLOPs: 641.4955
2024-04-30 07:59:34 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #474: GFLOPs: 575.4810. Time: 6431.1106 us. Best GFLOPs: 641.4955
2024-04-30 07:59:34 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #475: GFLOPs: 101.8552. Time: 36335.7233 us. Best GFLOPs: 641.4955
2024-04-30 07:59:34 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #476: GFLOPs: 502.1692. Time: 7369.9903 us. Best GFLOPs: 641.4955
2024-04-30 07:59:34 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #477: GFLOPs: 452.4428. Time: 8179.9984 us. Best GFLOPs: 641.4955
2024-04-30 07:59:34 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #478: GFLOPs: 596.7955. Time: 6201.4237 us. Best GFLOPs: 641.4955
2024-04-30 07:59:34 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #479: GFLOPs: 462.4890. Time: 8002.3130 us. Best GFLOPs: 641.4955
2024-04-30 07:59:34 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #480: GFLOPs: 624.4200. Time: 5927.0713 us. Best GFLOPs: 641.4955
2024-04-30 07:59:34 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #481: GFLOPs: 539.1298. Time: 6864.7320 us. Best GFLOPs: 641.4955
2024-04-30 07:59:34 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #482: GFLOPs: 365.0903. Time: 10137.1673 us. Best GFLOPs: 641.4955
2024-04-30 07:59:34 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #483: GFLOPs: 129.9529. Time: 28479.4175 us. Best GFLOPs: 641.4955
2024-04-30 07:59:34 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #484: GFLOPs: 255.2097. Time: 14501.7293 us. Best GFLOPs: 641.4955
2024-04-30 07:59:34 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #485: GFLOPs: 449.2495. Time: 8238.1440 us. Best GFLOPs: 641.4955
2024-04-30 07:59:34 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #486: GFLOPs: 481.5558. Time: 7685.4686 us. Best GFLOPs: 641.4955
2024-04-30 07:59:34 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #487: GFLOPs: 100.8324. Time: 36704.2813 us. Best GFLOPs: 641.4955
2024-04-30 07:59:34 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #488: GFLOPs: 457.0561. Time: 8097.4346 us. Best GFLOPs: 641.4955
2024-04-30 07:59:34 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #489: GFLOPs: 573.3886. Time: 6454.5785 us. Best GFLOPs: 641.4955
2024-04-30 07:59:34 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #490: GFLOPs: 575.0788. Time: 6435.6081 us. Best GFLOPs: 641.4955
2024-04-30 07:59:34 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #491: GFLOPs: 453.0841. Time: 8168.4220 us. Best GFLOPs: 641.4955
2024-04-30 07:59:34 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #492: GFLOPs: 575.5183. Time: 6430.6931 us. Best GFLOPs: 641.4955
2024-04-30 07:59:34 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #493: GFLOPs: 102.0502. Time: 36266.2770 us. Best GFLOPs: 641.4955
2024-04-30 07:59:34 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #494: GFLOPs: 102.0957. Time: 36250.1403 us. Best GFLOPs: 641.4955
2024-04-30 07:59:34 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #495: GFLOPs: 572.7132. Time: 6462.1899 us. Best GFLOPs: 641.4955
2024-04-30 07:59:34 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #496: GFLOPs: 478.6369. Time: 7732.3368 us. Best GFLOPs: 641.4955
2024-04-30 07:59:34 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #497: GFLOPs: 475.7365. Time: 7779.4784 us. Best GFLOPs: 641.4955
2024-04-30 07:59:34 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #498: GFLOPs: 397.9084. Time: 9301.0890 us. Best GFLOPs: 641.4955
2024-04-30 07:59:34 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #499: GFLOPs: 462.3256. Time: 8005.1408 us. Best GFLOPs: 641.4955
2024-04-30 07:59:34 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #500: GFLOPs: 526.2267. Time: 7033.0563 us. Best GFLOPs: 641.4955
2024-04-30 07:59:34 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #501: GFLOPs: 461.8851. Time: 8012.7755 us. Best GFLOPs: 641.4955
2024-04-30 07:59:34 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #502: GFLOPs: 77.0738. Time: 48018.6503 us. Best GFLOPs: 641.4955
2024-04-30 07:59:34 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #503: GFLOPs: 492.6658. Time: 7512.1542 us. Best GFLOPs: 641.4955
2024-04-30 07:59:34 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #504: GFLOPs: 101.8928. Time: 36322.3080 us. Best GFLOPs: 641.4955
2024-04-30 07:59:34 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #505: GFLOPs: 492.4836. Time: 7514.9335 us. Best GFLOPs: 641.4955
2024-04-30 07:59:34 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #506: GFLOPs: 599.5017. Time: 6173.4303 us. Best GFLOPs: 641.4955
2024-04-30 07:59:34 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #507: GFLOPs: 447.7563. Time: 8265.6161 us. Best GFLOPs: 641.4955
2024-04-30 07:59:34 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #508: GFLOPs: 255.3899. Time: 14491.4934 us. Best GFLOPs: 641.4955
2024-04-30 07:59:34 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #509: GFLOPs: 521.2117. Time: 7100.7268 us. Best GFLOPs: 641.4955
2024-04-30 07:59:34 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #510: GFLOPs: 59.7513. Time: 61939.7443 us. Best GFLOPs: 641.4955
2024-04-30 07:59:34 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #511: GFLOPs: 5.9138. Time: 625818.3773 us. Best GFLOPs: 641.4955
2024-04-30 07:59:34 [INFO] [task_scheduler.cc:121] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #512: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(56), T.int64(56), T.int64(256)), "float32"), p1: T.Buffer((T.int64(8), T.int64(1), T.int64(3), T.int64(3), T.int64(256), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(58), T.int64(58), T.int64(256)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused in T.parallel(T.int64(112), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(58), T.int64(10), T.int64(256)):
                with T.block("data_pad"):
                    v_i0, v_i1, v_i2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                    v_i3 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(56) // T.int64(8) * T.int64(8) + ax3)
                    v_i4 = T.axis.spatial(T.int64(256), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(57) and T.int64(1) <= v_i3 and v_i3 < T.int64(57), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(2)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(4), T.int64(8)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(2)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(8), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(56) * T.int64(4) + oc_chunk_1 * T.int64(4) + oc_chunk_2_init * T.int64(4) + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(56), oh_1 * T.int64(8) + oh_2_init * T.int64(4) + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(56) // T.int64(8) * T.int64(8) + ow_1 * T.int64(8) + ow_2_init * T.int64(8) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(8) * T.int64(4) + oc_block_1 * T.int64(2) + oc_block_2_init * T.int64(2) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(8), T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(4), T.int64(8)):
                    for oc_block_3_fused in T.vectorized(T.int64(2)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(8), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(56) * T.int64(4) + oc_chunk_1 * T.int64(4) + oc_chunk_2 * T.int64(4) + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(56), oh_1 * T.int64(8) + oh_2 * T.int64(4) + oh_3)
                            v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(56) // T.int64(8) * T.int64(8) + ow_1 * T.int64(8) + ow_2 * T.int64(8) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(8) * T.int64(4) + oc_block_1 * T.int64(2) + oc_block_2 * T.int64(2) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(32) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)], p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)] * p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(4), T.int64(8), T.int64(8)):
                    for ax4_fused in T.vectorized(T.int64(2)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(8), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(56) * T.int64(4) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(56), oh_1 * T.int64(8) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(56) // T.int64(8) * T.int64(8) + ax3)
                            v_ax4 = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(8) * T.int64(4) + oc_block_1 * T.int64(2) + ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[2, 1, 1, 4])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 7, 2, 4])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[7, 1, 1, 8])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[8, 2, 1, 2])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[8, 32])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=4)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80 = sch.get_loops(block=b68)
l81 = sch.fuse(l71, l72, l73, l74, l75, preserve_unit_iters=True)
sch.parallel(loop=l81)
l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l82, preserve_unit_iters=True)
sch.parallel(loop=l104)
l105 = sch.fuse(l103, preserve_unit_iters=True)
sch.vectorize(loop=l105)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l106, l107, l108, l109, l110, l111, l112, l113, l114, l115, l116 = sch.get_loops(block=b70)
l117 = sch.fuse(l116, preserve_unit_iters=True)
sch.vectorize(loop=l117)
b118 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140 = sch.get_loops(block=b118)
b141 = sch.decompose_reduction(block=b118, loop=l125)
2024-04-30 08:05:11 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-30 08:05:12 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-30 08:05:17 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 08:05:17 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-30 08:05:30 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 08:05:44 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 08:05:58 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 08:06:13 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 08:06:22 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.8461  0.8461  0.8461  0.8202  0.8202  0.8202  0.8202  0.8202  0.8202  0.8202  0.8070  0.7786  0.7786  0.7786  0.7772  0.7772
[17 : 32]:	0.7772  0.7772  0.7723  0.7712  0.7712  0.7712  0.7679  0.7676  0.7676  0.7676  0.7676  0.7570  0.7570  0.7567  0.7567  0.7443
[33 : 48]:	0.7403  0.7403  0.7403  0.7403  0.7403  0.7403  0.7403  0.7391  0.7391  0.7391  0.7385  0.7379  0.7379  0.7379  0.7375  0.7375
[49 : 64]:	0.7375  0.7369  0.7317  0.7317  0.7269  0.7262  0.7227  0.7227  0.7226  0.7226  0.7178  0.7178  0.7178  0.7148  0.7096  0.7096
2024-04-30 08:06:22 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-30 08:06:22 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-30 08:08:09 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #513: GFLOPs: 471.5290. Time: 7848.8956 us. Best GFLOPs: 641.4955
2024-04-30 08:08:09 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #514: GFLOPs: 599.1874. Time: 6176.6685 us. Best GFLOPs: 641.4955
2024-04-30 08:08:09 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #515: GFLOPs: 515.1698. Time: 7184.0034 us. Best GFLOPs: 641.4955
2024-04-30 08:08:09 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #516: GFLOPs: 474.5465. Time: 7798.9871 us. Best GFLOPs: 641.4955
2024-04-30 08:08:09 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #517: GFLOPs: 579.4057. Time: 6387.5485 us. Best GFLOPs: 641.4955
2024-04-30 08:08:09 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #518: GFLOPs: 476.1067. Time: 7773.4289 us. Best GFLOPs: 641.4955
2024-04-30 08:08:09 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #519: GFLOPs: 113.4569. Time: 32620.1562 us. Best GFLOPs: 641.4955
2024-04-30 08:08:09 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #520: GFLOPs: 54.3704. Time: 68069.7930 us. Best GFLOPs: 641.4955
2024-04-30 08:08:09 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #521: GFLOPs: 481.4136. Time: 7687.7378 us. Best GFLOPs: 641.4955
2024-04-30 08:08:09 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #522: GFLOPs: 105.9162. Time: 34942.5303 us. Best GFLOPs: 641.4955
2024-04-30 08:08:09 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #523: GFLOPs: 560.1335. Time: 6607.3211 us. Best GFLOPs: 641.4955
2024-04-30 08:08:09 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #524: GFLOPs: 506.1005. Time: 7312.7405 us. Best GFLOPs: 641.4955
2024-04-30 08:08:09 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #525: GFLOPs: 515.2481. Time: 7182.9126 us. Best GFLOPs: 641.4955
2024-04-30 08:08:09 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #526: GFLOPs: 128.5108. Time: 28798.9853 us. Best GFLOPs: 641.4955
2024-04-30 08:08:09 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #527: GFLOPs: 93.1955. Time: 39712.0330 us. Best GFLOPs: 641.4955
2024-04-30 08:08:09 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #528: GFLOPs: 594.8794. Time: 6221.3987 us. Best GFLOPs: 641.4955
2024-04-30 08:08:09 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #529: GFLOPs: 596.8276. Time: 6201.0901 us. Best GFLOPs: 641.4955
2024-04-30 08:08:09 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #530: GFLOPs: 515.4067. Time: 7180.7012 us. Best GFLOPs: 641.4955
2024-04-30 08:08:09 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #531: GFLOPs: 102.9415. Time: 35952.2847 us. Best GFLOPs: 641.4955
2024-04-30 08:08:09 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #532: GFLOPs: 76.0317. Time: 48676.8110 us. Best GFLOPs: 641.4955
2024-04-30 08:08:09 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #533: GFLOPs: 76.5280. Time: 48361.1623 us. Best GFLOPs: 641.4955
2024-04-30 08:08:09 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #534: GFLOPs: 586.0135. Time: 6315.5235 us. Best GFLOPs: 641.4955
2024-04-30 08:08:09 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #535: GFLOPs: 1378.1069. Time: 2685.5548 us. Best GFLOPs: 1378.1069
2024-04-30 08:08:09 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #536: GFLOPs: 373.3881. Time: 9911.8912 us. Best GFLOPs: 1378.1069
2024-04-30 08:08:09 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #537: GFLOPs: 127.8208. Time: 28954.4453 us. Best GFLOPs: 1378.1069
2024-04-30 08:08:09 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #538: GFLOPs: 376.3475. Time: 9833.9472 us. Best GFLOPs: 1378.1069
2024-04-30 08:08:09 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #539: GFLOPs: 542.2211. Time: 6825.5953 us. Best GFLOPs: 1378.1069
2024-04-30 08:08:09 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #540: GFLOPs: 129.1980. Time: 28645.8075 us. Best GFLOPs: 1378.1069
2024-04-30 08:08:09 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #541: GFLOPs: 554.9887. Time: 6668.5710 us. Best GFLOPs: 1378.1069
2024-04-30 08:08:09 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #542: GFLOPs: 437.8727. Time: 8452.1868 us. Best GFLOPs: 1378.1069
2024-04-30 08:08:09 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #543: GFLOPs: 445.2057. Time: 8312.9698 us. Best GFLOPs: 1378.1069
2024-04-30 08:08:09 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #544: GFLOPs: 258.1174. Time: 14338.3636 us. Best GFLOPs: 1378.1069
2024-04-30 08:08:09 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #545: GFLOPs: 577.7402. Time: 6405.9623 us. Best GFLOPs: 1378.1069
2024-04-30 08:08:09 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #546: GFLOPs: 452.2990. Time: 8182.5998 us. Best GFLOPs: 1378.1069
2024-04-30 08:08:09 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #547: GFLOPs: 101.9712. Time: 36294.4003 us. Best GFLOPs: 1378.1069
2024-04-30 08:08:09 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #548: GFLOPs: 453.0963. Time: 8168.2004 us. Best GFLOPs: 1378.1069
2024-04-30 08:08:09 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #549: GFLOPs: 455.5897. Time: 8123.4980 us. Best GFLOPs: 1378.1069
2024-04-30 08:08:09 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #550: GFLOPs: 102.1626. Time: 36226.3960 us. Best GFLOPs: 1378.1069
2024-04-30 08:08:09 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #551: GFLOPs: 102.1273. Time: 36238.8960 us. Best GFLOPs: 1378.1069
2024-04-30 08:08:09 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #552: GFLOPs: 510.3540. Time: 7251.7931 us. Best GFLOPs: 1378.1069
2024-04-30 08:08:09 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #553: GFLOPs: 255.7611. Time: 14470.4657 us. Best GFLOPs: 1378.1069
2024-04-30 08:08:09 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #554: GFLOPs: 449.7549. Time: 8228.8868 us. Best GFLOPs: 1378.1069
2024-04-30 08:08:09 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #555: GFLOPs: 597.4894. Time: 6194.2211 us. Best GFLOPs: 1378.1069
2024-04-30 08:08:09 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #556: GFLOPs: 458.7760. Time: 8067.0778 us. Best GFLOPs: 1378.1069
2024-04-30 08:08:09 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #557: GFLOPs: 120.9181. Time: 30607.3538 us. Best GFLOPs: 1378.1069
2024-04-30 08:08:09 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #558: GFLOPs: 556.5379. Time: 6650.0087 us. Best GFLOPs: 1378.1069
2024-04-30 08:08:09 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #559: GFLOPs: 559.8044. Time: 6611.2049 us. Best GFLOPs: 1378.1069
2024-04-30 08:08:09 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #560: GFLOPs: 553.3868. Time: 6687.8749 us. Best GFLOPs: 1378.1069
2024-04-30 08:08:09 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #561: GFLOPs: 119.2094. Time: 31046.0690 us. Best GFLOPs: 1378.1069
2024-04-30 08:08:09 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #562: GFLOPs: 260.9307. Time: 14183.7701 us. Best GFLOPs: 1378.1069
2024-04-30 08:08:09 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #563: GFLOPs: 520.7914. Time: 7106.4568 us. Best GFLOPs: 1378.1069
2024-04-30 08:08:09 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #564: GFLOPs: 128.4782. Time: 28806.2953 us. Best GFLOPs: 1378.1069
2024-04-30 08:08:09 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #565: GFLOPs: 528.2132. Time: 7006.6057 us. Best GFLOPs: 1378.1069
2024-04-30 08:08:09 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #566: GFLOPs: 258.6973. Time: 14306.2273 us. Best GFLOPs: 1378.1069
2024-04-30 08:08:09 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #567: GFLOPs: 256.6570. Time: 14419.9520 us. Best GFLOPs: 1378.1069
2024-04-30 08:08:09 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #568: GFLOPs: 461.5992. Time: 8017.7385 us. Best GFLOPs: 1378.1069
2024-04-30 08:08:09 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #569: GFLOPs: 511.7891. Time: 7231.4592 us. Best GFLOPs: 1378.1069
2024-04-30 08:08:09 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #570: GFLOPs: 101.8757. Time: 36328.3943 us. Best GFLOPs: 1378.1069
2024-04-30 08:08:09 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #571: GFLOPs: 529.1938. Time: 6993.6229 us. Best GFLOPs: 1378.1069
2024-04-30 08:08:09 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #572: GFLOPs: 574.5757. Time: 6441.2426 us. Best GFLOPs: 1378.1069
2024-04-30 08:08:09 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #573: GFLOPs: 117.0559. Time: 31617.2038 us. Best GFLOPs: 1378.1069
2024-04-30 08:08:09 [INFO] [task_scheduler.cc:121] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #574: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(56), T.int64(56), T.int64(256)), "float32"), p1: T.Buffer((T.int64(8), T.int64(1), T.int64(3), T.int64(3), T.int64(256), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(58), T.int64(58), T.int64(256)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)))
        for n_0_oc_chunk_0_fused_fused in T.parallel(T.int64(8), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(58), T.int64(58), T.int64(256)):
                with T.block("data_pad"):
                    v_i0, v_i1, v_i2, v_i3, v_i4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(57) and T.int64(1) <= v_i3 and v_i3 < T.int64(57), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oh_0, ow_0, oc_block_0 in T.grid(T.int64(1), T.int64(8), T.int64(4)):
                for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(1), T.int64(2)):
                    for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(1), T.int64(14), T.int64(7), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                        for oc_block_3_fused_init in T.vectorized(T.int64(4)):
                            with T.block("conv2d_NCHWc_init"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                                v_oc_chunk = T.axis.spatial(T.int64(8), n_0_oc_chunk_0_fused_fused + oc_chunk_1 + oc_chunk_2_init + oc_chunk_3_init)
                                v_oh = T.axis.spatial(T.int64(56), oh_0 * T.int64(56) + oh_1 * T.int64(14) + oh_2_init + oh_3_init)
                                v_ow = T.axis.spatial(T.int64(56), ow_0 * T.int64(7) + ow_1 * T.int64(7) + ow_2_init + ow_3_init)
                                v_oc_block = T.axis.spatial(T.int64(32), oc_block_0 * T.int64(8) + oc_block_1 * T.int64(4) + oc_block_2_init * T.int64(4) + oc_block_3_fused_init)
                                T.reads()
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                    for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(64), T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(14), T.int64(7), T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                        for oc_block_3_fused in T.vectorized(T.int64(4)):
                            with T.block("conv2d_NCHWc_update"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                                v_oc_chunk = T.axis.spatial(T.int64(8), n_0_oc_chunk_0_fused_fused + oc_chunk_1 + oc_chunk_2 + oc_chunk_3)
                                v_oh = T.axis.spatial(T.int64(56), oh_0 * T.int64(56) + oh_1 * T.int64(14) + oh_2 + oh_3)
                                v_ow = T.axis.spatial(T.int64(56), ow_0 * T.int64(7) + ow_1 * T.int64(7) + ow_2 + ow_3)
                                v_oc_block = T.axis.spatial(T.int64(32), oc_block_0 * T.int64(8) + oc_block_1 * T.int64(4) + oc_block_2 * T.int64(4) + oc_block_3_fused)
                                v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(4) + ic_1)
                                v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                                v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                                T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)], p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block])
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)] * p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(56), T.int64(7)):
                    for ax4_fused in T.vectorized(T.int64(8)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(8), n_0_oc_chunk_0_fused_fused + ax1)
                            v_ax2 = T.axis.spatial(T.int64(56), ax2)
                            v_ax3 = T.axis.spatial(T.int64(56), ow_0 * T.int64(7) + ax3)
                            v_ax4 = T.axis.spatial(T.int64(32), oc_block_0 * T.int64(8) + ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[8, 1, 1, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 4, 14, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[8, 1, 7, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[4, 2, 1, 4])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[64, 4])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=1)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77 = sch.get_loops(block=b68)
l78 = sch.fuse(l71, l72, preserve_unit_iters=True)
sch.parallel(loop=l78)
l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l79, preserve_unit_iters=True)
sch.parallel(loop=l104)
l105 = sch.fuse(l103, preserve_unit_iters=True)
sch.vectorize(loop=l105)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l106, l107, l108, l109, l110, l111, l112, l113, l114 = sch.get_loops(block=b70)
l115 = sch.fuse(l114, preserve_unit_iters=True)
sch.vectorize(loop=l115)
b116 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141 = sch.get_loops(block=b116)
b142 = sch.decompose_reduction(block=b116, loop=l126)
2024-04-30 08:08:09 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #575: GFLOPs: 42.4106. Time: 87265.5377 us. Best GFLOPs: 1378.1069
2024-04-30 08:08:09 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #576: GFLOPs: 25.6580. Time: 144242.9623 us. Best GFLOPs: 1378.1069
2024-04-30 08:11:36 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-30 08:11:37 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-30 08:11:42 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 08:11:42 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-30 08:11:55 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 08:12:09 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 08:12:23 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 08:12:38 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 08:12:47 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	1.0060  1.0060  1.0060  0.9951  0.9918  0.9384  0.9384  0.9364  0.9362  0.9362  0.9251  0.9061  0.8886  0.8886  0.8864  0.8757
[17 : 32]:	0.8494  0.8494  0.8448  0.8446  0.8349  0.8349  0.8188  0.7809  0.7781  0.7651  0.7634  0.7508  0.7500  0.7267  0.7267  0.7245
[33 : 48]:	0.7089  0.7075  0.7044  0.7014  0.6784  0.6784  0.6783  0.6770  0.6752  0.6598  0.6518  0.6515  0.6389  0.6324  0.6278  0.6278
[49 : 64]:	0.6278  0.6210  0.6177  0.6169  0.6167  0.6160  0.6125  0.6111  0.6107  0.6107  0.6067  0.6025  0.6003  0.5997  0.5983  0.5977
2024-04-30 08:12:47 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-30 08:12:47 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-30 08:15:04 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #577: GFLOPs: 1335.7877. Time: 2770.6362 us. Best GFLOPs: 1378.1069
2024-04-30 08:15:04 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #578: GFLOPs: 1346.4520. Time: 2748.6918 us. Best GFLOPs: 1378.1069
2024-04-30 08:15:04 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #579: GFLOPs: 1332.2864. Time: 2777.9176 us. Best GFLOPs: 1378.1069
2024-04-30 08:15:04 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #580: GFLOPs: 1360.6270. Time: 2720.0561 us. Best GFLOPs: 1378.1069
2024-04-30 08:15:04 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #581: GFLOPs: 1296.7992. Time: 2853.9359 us. Best GFLOPs: 1378.1069
2024-04-30 08:15:04 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #582: GFLOPs: 938.3137. Time: 3944.2903 us. Best GFLOPs: 1378.1069
2024-04-30 08:15:04 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #583: GFLOPs: 931.8175. Time: 3971.7881 us. Best GFLOPs: 1378.1069
2024-04-30 08:15:04 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #584: GFLOPs: 941.5474. Time: 3930.7439 us. Best GFLOPs: 1378.1069
2024-04-30 08:15:04 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #585: GFLOPs: 938.9451. Time: 3941.6380 us. Best GFLOPs: 1378.1069
2024-04-30 08:15:04 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #586: GFLOPs: 938.8419. Time: 3942.0714 us. Best GFLOPs: 1378.1069
2024-04-30 08:15:04 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #587: GFLOPs: 1298.0859. Time: 2851.1069 us. Best GFLOPs: 1378.1069
2024-04-30 08:15:04 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #588: GFLOPs: 129.5831. Time: 28560.6895 us. Best GFLOPs: 1378.1069
2024-04-30 08:15:04 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #589: GFLOPs: 71.5753. Time: 51707.5427 us. Best GFLOPs: 1378.1069
2024-04-30 08:15:04 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #590: GFLOPs: 84.0065. Time: 44055.9083 us. Best GFLOPs: 1378.1069
2024-04-30 08:15:04 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #591: GFLOPs: 88.3748. Time: 41878.2610 us. Best GFLOPs: 1378.1069
2024-04-30 08:15:04 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #592: GFLOPs: 1290.1716. Time: 2868.5966 us. Best GFLOPs: 1378.1069
2024-04-30 08:15:04 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #593: GFLOPs: 1179.5661. Time: 3137.5791 us. Best GFLOPs: 1378.1069
2024-04-30 08:15:04 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #594: GFLOPs: 1237.5071. Time: 2990.6751 us. Best GFLOPs: 1378.1069
2024-04-30 08:15:04 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #595: GFLOPs: 623.5581. Time: 5935.2641 us. Best GFLOPs: 1378.1069
2024-04-30 08:15:04 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #596: GFLOPs: 829.3453. Time: 4462.5343 us. Best GFLOPs: 1378.1069
2024-04-30 08:15:04 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #597: GFLOPs: 1177.8103. Time: 3142.2563 us. Best GFLOPs: 1378.1069
2024-04-30 08:15:04 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #598: GFLOPs: 1219.7133. Time: 3034.3047 us. Best GFLOPs: 1378.1069
2024-04-30 08:15:04 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #599: GFLOPs: 666.7276. Time: 5550.9656 us. Best GFLOPs: 1378.1069
2024-04-30 08:15:04 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #600: GFLOPs: 40.5321. Time: 91309.9517 us. Best GFLOPs: 1378.1069
2024-04-30 08:15:04 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #601: GFLOPs: 1105.0931. Time: 3349.0227 us. Best GFLOPs: 1378.1069
2024-04-30 08:15:04 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #602: GFLOPs: 1080.2846. Time: 3425.9321 us. Best GFLOPs: 1378.1069
2024-04-30 08:15:04 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #603: GFLOPs: 518.9584. Time: 7131.5575 us. Best GFLOPs: 1378.1069
2024-04-30 08:15:04 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #604: GFLOPs: 914.6169. Time: 4046.4829 us. Best GFLOPs: 1378.1069
2024-04-30 08:15:04 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #605: GFLOPs: 994.3567. Time: 3721.9860 us. Best GFLOPs: 1378.1069
2024-04-30 08:15:04 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #606: GFLOPs: 153.7477. Time: 24071.7926 us. Best GFLOPs: 1378.1069
2024-04-30 08:15:04 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #607: GFLOPs: 153.7081. Time: 24077.9888 us. Best GFLOPs: 1378.1069
2024-04-30 08:15:04 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #608: GFLOPs: 153.4574. Time: 24117.3312 us. Best GFLOPs: 1378.1069
2024-04-30 08:15:04 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #609: GFLOPs: 933.8611. Time: 3963.0968 us. Best GFLOPs: 1378.1069
2024-04-30 08:15:04 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #610: GFLOPs: 863.9122. Time: 4283.9792 us. Best GFLOPs: 1378.1069
2024-04-30 08:15:04 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #611: GFLOPs: 969.4988. Time: 3817.4176 us. Best GFLOPs: 1378.1069
2024-04-30 08:15:04 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #612: GFLOPs: 864.2593. Time: 4282.2584 us. Best GFLOPs: 1378.1069
2024-04-30 08:15:04 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #613: GFLOPs: 553.0452. Time: 6692.0059 us. Best GFLOPs: 1378.1069
2024-04-30 08:15:04 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #614: GFLOPs: 1049.8769. Time: 3525.1577 us. Best GFLOPs: 1378.1069
2024-04-30 08:15:04 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #615: GFLOPs: 1036.3908. Time: 3571.0293 us. Best GFLOPs: 1378.1069
2024-04-30 08:15:04 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #616: GFLOPs: 1059.5958. Time: 3492.8240 us. Best GFLOPs: 1378.1069
2024-04-30 08:15:04 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #617: GFLOPs: 582.9657. Time: 6348.5413 us. Best GFLOPs: 1378.1069
2024-04-30 08:15:04 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #618: GFLOPs: 570.4436. Time: 6487.9018 us. Best GFLOPs: 1378.1069
2024-04-30 08:15:04 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #619: GFLOPs: 447.6815. Time: 8266.9978 us. Best GFLOPs: 1378.1069
2024-04-30 08:15:04 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #620: GFLOPs: 1062.4764. Time: 3483.3542 us. Best GFLOPs: 1378.1069
2024-04-30 08:15:04 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #621: GFLOPs: 587.3684. Time: 6300.9549 us. Best GFLOPs: 1378.1069
2024-04-30 08:15:04 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #622: GFLOPs: 856.9500. Time: 4318.7840 us. Best GFLOPs: 1378.1069
2024-04-30 08:15:04 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #623: GFLOPs: 752.9161. Time: 4915.5300 us. Best GFLOPs: 1378.1069
2024-04-30 08:15:04 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #624: GFLOPs: 857.7051. Time: 4314.9819 us. Best GFLOPs: 1378.1069
2024-04-30 08:15:04 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #625: GFLOPs: 752.7276. Time: 4916.7614 us. Best GFLOPs: 1378.1069
2024-04-30 08:15:04 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #626: GFLOPs: 194.1767. Time: 19059.8667 us. Best GFLOPs: 1378.1069
2024-04-30 08:15:04 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #627: GFLOPs: 33.9587. Time: 108984.6710 us. Best GFLOPs: 1378.1069
2024-04-30 08:15:04 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #628: GFLOPs: 859.0847. Time: 4308.0521 us. Best GFLOPs: 1378.1069
2024-04-30 08:15:04 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #629: GFLOPs: 129.1748. Time: 28650.9660 us. Best GFLOPs: 1378.1069
2024-04-30 08:15:04 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #630: GFLOPs: 1003.6842. Time: 3687.3968 us. Best GFLOPs: 1378.1069
2024-04-30 08:15:04 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #631: GFLOPs: 873.9583. Time: 4234.7351 us. Best GFLOPs: 1378.1069
2024-04-30 08:15:04 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #632: GFLOPs: 676.5936. Time: 5470.0222 us. Best GFLOPs: 1378.1069
2024-04-30 08:15:04 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #633: GFLOPs: 527.6532. Time: 7014.0415 us. Best GFLOPs: 1378.1069
2024-04-30 08:15:04 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #634: GFLOPs: 1006.8055. Time: 3675.9651 us. Best GFLOPs: 1378.1069
2024-04-30 08:15:04 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #635: GFLOPs: 787.2531. Time: 4701.1333 us. Best GFLOPs: 1378.1069
2024-04-30 08:15:04 [INFO] [task_scheduler.cc:121] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #636: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(56), T.int64(56), T.int64(256)), "float32"), p1: T.Buffer((T.int64(8), T.int64(1), T.int64(3), T.int64(3), T.int64(256), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(58), T.int64(58), T.int64(256)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused in T.parallel(T.int64(224), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(14), T.int64(1), T.int64(1)):
                with T.block("conv2d_NCHWc_init"):
                    v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                    v_oc_chunk = T.axis.spatial(T.int64(8), oc_chunk_2_init + oc_chunk_3_init)
                    v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(112) * T.int64(28) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(56) // T.int64(28) * T.int64(14) + oh_2_init * T.int64(14) + oh_3_init)
                    v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(112) // T.int64(56) * T.int64(28) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(28) + ow_2_init + ow_3_init)
                    v_oc_block = T.axis.spatial(T.int64(32), oc_block_2_init + oc_block_3_init)
                    T.reads()
                    T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                    T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                    conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
            for ic_0 in range(T.int64(256)):
                for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(16), T.int64(3), T.int64(1)):
                    with T.block("data_pad"):
                        v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                        v_i2 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(112) * T.int64(28) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(56) // T.int64(28) * T.int64(14) + ax2)
                        v_i3 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(112) // T.int64(56) * T.int64(28) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(28) + ax3)
                        v_i4 = T.axis.spatial(T.int64(256), ic_0 + ax4)
                        T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                        T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                        data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(57) and T.int64(1) <= v_i3 and v_i3 < T.int64(57), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                for kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(3), T.int64(3), T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(14), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(8), oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(112) * T.int64(28) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(56) // T.int64(28) * T.int64(14) + oh_2 * T.int64(14) + oh_3)
                        v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(112) // T.int64(56) * T.int64(28) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(28) + ow_2 + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(256), ic_0 + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)], p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)] * p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block]
            for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(8), T.int64(14)):
                for ax3_ax4_fused in T.vectorized(T.int64(32)):
                    with T.block("T_relu"):
                        v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                        v_ax2 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(112) * T.int64(28) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(56) // T.int64(28) * T.int64(14) + ax2)
                        v_ax3 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(112) // T.int64(56) * T.int64(28) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(28))
                        v_ax4 = T.axis.spatial(T.int64(32), ax3_ax4_fused)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 8, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 2, 1, 14])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[2, 28, 1, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 32, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[256, 1])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=10)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86 = sch.get_loops(block=b68)
l87 = sch.fuse(l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, preserve_unit_iters=True)
sch.parallel(loop=l87)
l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b69)
l105 = sch.fuse(l88, preserve_unit_iters=True)
sch.parallel(loop=l105)
sch.annotate(block_or_loop=l105, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l105, ann_key="pragma_unroll_explicit", ann_val=1)
l106, l107, l108, l109, l110, l111 = sch.get_loops(block=b70)
l112 = sch.fuse(l110, l111, preserve_unit_iters=True)
sch.vectorize(loop=l112)
b113 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130 = sch.get_loops(block=b113)
b131 = sch.decompose_reduction(block=b113, loop=l115)
2024-04-30 08:15:04 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #637: GFLOPs: 89.9471. Time: 41146.1983 us. Best GFLOPs: 1378.1069
2024-04-30 08:15:04 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #638: GFLOPs: 2.0710. Time: 1787029.4343 us. Best GFLOPs: 1378.1069
2024-04-30 08:15:04 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #639: GFLOPs: 2.6637. Time: 1389389.1067 us. Best GFLOPs: 1378.1069
2024-04-30 08:15:04 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #640: GFLOPs: 20.2858. Time: 182441.5963 us. Best GFLOPs: 1378.1069
2024-04-30 08:18:10 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-30 08:18:11 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-30 08:18:15 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 08:18:15 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-30 08:18:29 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 08:18:43 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 08:18:57 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 08:19:12 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 08:19:21 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9738  0.9738  0.9406  0.9406  0.9370  0.9367  0.9330  0.9296  0.9272  0.8534  0.8534  0.8510  0.8270  0.8038  0.7820  0.7799
[17 : 32]:	0.7746  0.7746  0.7718  0.7668  0.7623  0.7603  0.7603  0.7603  0.7587  0.7550  0.7547  0.7397  0.7335  0.7236  0.7192  0.7186
[33 : 48]:	0.7148  0.7126  0.7126  0.7125  0.7112  0.7036  0.7023  0.6992  0.6955  0.6949  0.6841  0.6835  0.6832  0.6820  0.6792  0.6767
[49 : 64]:	0.6767  0.6716  0.6713  0.6658  0.6628  0.6614  0.6595  0.6594  0.6573  0.6542  0.6527  0.6523  0.6514  0.6506  0.6496  0.6493
2024-04-30 08:19:21 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-30 08:19:21 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-30 08:21:09 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #641: GFLOPs: 1328.4554. Time: 2785.9285 us. Best GFLOPs: 1378.1069
2024-04-30 08:21:09 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #642: GFLOPs: 1357.5107. Time: 2726.3003 us. Best GFLOPs: 1378.1069
2024-04-30 08:21:09 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #643: GFLOPs: 1296.6474. Time: 2854.2700 us. Best GFLOPs: 1378.1069
2024-04-30 08:21:09 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #644: GFLOPs: 1367.9051. Time: 2705.5838 us. Best GFLOPs: 1378.1069
2024-04-30 08:21:09 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #645: GFLOPs: 476.8538. Time: 7761.2504 us. Best GFLOPs: 1378.1069
2024-04-30 08:21:09 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #646: GFLOPs: 1399.5549. Time: 2644.3991 us. Best GFLOPs: 1399.5549
2024-04-30 08:21:09 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #647: GFLOPs: 1302.0473. Time: 2842.4327 us. Best GFLOPs: 1399.5549
2024-04-30 08:21:09 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #648: GFLOPs: 1387.1392. Time: 2668.0679 us. Best GFLOPs: 1399.5549
2024-04-30 08:21:09 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #649: GFLOPs: 1207.9476. Time: 3063.8595 us. Best GFLOPs: 1399.5549
2024-04-30 08:21:09 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #650: GFLOPs: 1228.0857. Time: 3013.6185 us. Best GFLOPs: 1399.5549
2024-04-30 08:21:09 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #651: GFLOPs: 844.0106. Time: 4384.9942 us. Best GFLOPs: 1399.5549
2024-04-30 08:21:09 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #652: GFLOPs: 1225.3500. Time: 3020.3466 us. Best GFLOPs: 1399.5549
2024-04-30 08:21:09 [INFO] [task_scheduler.cc:121] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #653: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(56), T.int64(56), T.int64(256)), "float32"), p1: T.Buffer((T.int64(8), T.int64(1), T.int64(3), T.int64(3), T.int64(256), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(58), T.int64(58), T.int64(256)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused in T.parallel(T.int64(224), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(16), T.int64(3), T.int64(256)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(112) * T.int64(28) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(4) // T.int64(2) * T.int64(14) + ax2)
                    v_i3 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(2) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(112) // T.int64(4) * T.int64(2) + ax3)
                    v_i4 = T.axis.spatial(T.int64(256), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(57) and T.int64(1) <= v_i3 and v_i3 < T.int64(57), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oc_block_1 in range(T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(14), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(8), oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(112) * T.int64(28) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(4) // T.int64(2) * T.int64(14) + oh_2_init * T.int64(14) + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(112) // T.int64(4) * T.int64(2) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(2) + ow_2_init + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(128), T.int64(1), T.int64(3), T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(32), T.int64(2), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(14), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(8), oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(112) * T.int64(28) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(4) // T.int64(2) * T.int64(14) + oh_2 * T.int64(14) + oh_3)
                        v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(112) // T.int64(4) * T.int64(2) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(2) + ow_2 + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(2) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)], p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)] * p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block]
                for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(8), T.int64(14)):
                    for ax3_ax4_fused in T.vectorized(T.int64(32)):
                        with T.block("T_relu"):
                            v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                            v_ax2 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(112) * T.int64(28) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(4) // T.int64(2) * T.int64(14) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(112) // T.int64(4) * T.int64(2) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(2))
                            v_ax4 = T.axis.spatial(T.int64(32), ax3_ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 8, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 2, 1, 14])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[28, 2, 1, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 32, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[128, 2])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=8)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b68)
l85 = sch.fuse(l71, l72, l73, l74, l75, l76, l77, l78, l79, preserve_unit_iters=True)
sch.parallel(loop=l85)
l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l86, preserve_unit_iters=True)
sch.parallel(loop=l104)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109, l110, l111 = sch.get_loops(block=b70)
l112 = sch.fuse(l110, l111, preserve_unit_iters=True)
sch.vectorize(loop=l112)
b113 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131 = sch.get_loops(block=b113)
b132 = sch.decompose_reduction(block=b113, loop=l116)
2024-04-30 08:21:09 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #654: GFLOPs: 1090.1891. Time: 3394.8073 us. Best GFLOPs: 1399.5549
2024-04-30 08:21:09 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #655: GFLOPs: 1060.2779. Time: 3490.5772 us. Best GFLOPs: 1399.5549
2024-04-30 08:21:09 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #656: GFLOPs: 1075.0789. Time: 3442.5212 us. Best GFLOPs: 1399.5549
2024-04-30 08:21:09 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #657: GFLOPs: 1062.2501. Time: 3484.0964 us. Best GFLOPs: 1399.5549
2024-04-30 08:21:09 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #658: GFLOPs: 1069.0197. Time: 3462.0332 us. Best GFLOPs: 1399.5549
2024-04-30 08:21:09 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #659: GFLOPs: 1031.3451. Time: 3588.4999 us. Best GFLOPs: 1399.5549
2024-04-30 08:21:09 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #660: GFLOPs: 1248.1286. Time: 2965.2248 us. Best GFLOPs: 1399.5549
2024-04-30 08:21:09 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #661: GFLOPs: 1062.5777. Time: 3483.0222 us. Best GFLOPs: 1399.5549
2024-04-30 08:21:09 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #662: GFLOPs: 190.4054. Time: 19437.3790 us. Best GFLOPs: 1399.5549
2024-04-30 08:21:09 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #663: GFLOPs: 184.5734. Time: 20051.5465 us. Best GFLOPs: 1399.5549
2024-04-30 08:21:09 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #664: GFLOPs: 189.3448. Time: 19546.2527 us. Best GFLOPs: 1399.5549
2024-04-30 08:21:09 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #665: GFLOPs: 1078.8920. Time: 3430.3543 us. Best GFLOPs: 1399.5549
2024-04-30 08:21:09 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #666: GFLOPs: 1101.6006. Time: 3359.6404 us. Best GFLOPs: 1399.5549
2024-04-30 08:21:09 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #667: GFLOPs: 1079.1818. Time: 3429.4329 us. Best GFLOPs: 1399.5549
2024-04-30 08:21:09 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #668: GFLOPs: 960.1307. Time: 3854.6647 us. Best GFLOPs: 1399.5549
2024-04-30 08:21:09 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #669: GFLOPs: 824.2268. Time: 4490.2467 us. Best GFLOPs: 1399.5549
2024-04-30 08:21:09 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #670: GFLOPs: 931.5341. Time: 3972.9967 us. Best GFLOPs: 1399.5549
2024-04-30 08:21:09 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #671: GFLOPs: 936.2858. Time: 3952.8333 us. Best GFLOPs: 1399.5549
2024-04-30 08:21:09 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #672: GFLOPs: 1064.6101. Time: 3476.3728 us. Best GFLOPs: 1399.5549
2024-04-30 08:21:09 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #673: GFLOPs: 900.9255. Time: 4107.9774 us. Best GFLOPs: 1399.5549
2024-04-30 08:21:09 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #674: GFLOPs: 1000.4067. Time: 3699.4771 us. Best GFLOPs: 1399.5549
2024-04-30 08:21:09 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #675: GFLOPs: 1020.9027. Time: 3625.2051 us. Best GFLOPs: 1399.5549
2024-04-30 08:21:09 [INFO] [task_scheduler.cc:121] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #676: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(56), T.int64(56), T.int64(256)), "float32"), p1: T.Buffer((T.int64(8), T.int64(1), T.int64(3), T.int64(3), T.int64(256), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(58), T.int64(58), T.int64(256)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused in T.parallel(T.int64(224), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(16), T.int64(3), T.int64(256)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(112) * T.int64(28) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(4) // T.int64(2) * T.int64(14) + ax2)
                    v_i3 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(2) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(112) // T.int64(4) * T.int64(2) + ax3)
                    v_i4 = T.axis.spatial(T.int64(256), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(57) and T.int64(1) <= v_i3 and v_i3 < T.int64(57), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oc_block_1 in range(T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(14), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(8), oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(112) * T.int64(28) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(4) // T.int64(2) * T.int64(14) + oh_2_init * T.int64(14) + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(112) // T.int64(4) * T.int64(2) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(2) + ow_2_init + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(128), T.int64(3), T.int64(1), T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(32), T.int64(2), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(14), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(8), oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(112) * T.int64(28) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(4) // T.int64(2) * T.int64(14) + oh_2 * T.int64(14) + oh_3)
                        v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(112) // T.int64(4) * T.int64(2) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(2) + ow_2 + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(2) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)], p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)] * p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block]
                for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(8), T.int64(14)):
                    for ax3_ax4_fused in T.vectorized(T.int64(32)):
                        with T.block("T_relu"):
                            v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                            v_ax2 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(112) * T.int64(28) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(4) // T.int64(2) * T.int64(14) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(112) // T.int64(4) * T.int64(2) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(2))
                            v_ax4 = T.axis.spatial(T.int64(32), ax3_ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 8, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 2, 1, 14])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[28, 2, 1, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 32, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[128, 2])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=8)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b68)
l85 = sch.fuse(l71, l72, l73, l74, l75, l76, l77, l78, l79, preserve_unit_iters=True)
sch.parallel(loop=l85)
l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l86, preserve_unit_iters=True)
sch.parallel(loop=l104)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109, l110, l111 = sch.get_loops(block=b70)
l112 = sch.fuse(l110, l111, preserve_unit_iters=True)
sch.vectorize(loop=l112)
b113 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131 = sch.get_loops(block=b113)
b132 = sch.decompose_reduction(block=b113, loop=l116)
2024-04-30 08:21:09 [INFO] [task_scheduler.cc:121] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #677: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(56), T.int64(56), T.int64(256)), "float32"), p1: T.Buffer((T.int64(8), T.int64(1), T.int64(3), T.int64(3), T.int64(256), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(58), T.int64(58), T.int64(256)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused in T.parallel(T.int64(224), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(16), T.int64(3), T.int64(256)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(112) // T.int64(28) * T.int64(14) + ax2)
                    v_i3 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(112) * T.int64(28) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(28) + ax3)
                    v_i4 = T.axis.spatial(T.int64(256), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(57) and T.int64(1) <= v_i3 and v_i3 < T.int64(57), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oc_block_1 in range(T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(14), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(8), oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(112) // T.int64(28) * T.int64(14) + oh_2_init * T.int64(14) + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(112) * T.int64(28) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(28) + ow_2_init + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(128), T.int64(3), T.int64(1), T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(32), T.int64(2), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(14), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(8), oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(112) // T.int64(28) * T.int64(14) + oh_2 * T.int64(14) + oh_3)
                        v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(112) * T.int64(28) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(28) + ow_2 + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(2) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)], p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)] * p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block]
                for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(8), T.int64(14)):
                    for ax3_ax4_fused in T.vectorized(T.int64(32)):
                        with T.block("T_relu"):
                            v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                            v_ax2 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(112) // T.int64(28) * T.int64(14) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(112) * T.int64(28) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(28))
                            v_ax4 = T.axis.spatial(T.int64(32), ax3_ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 8, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 4, 1, 14])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[2, 28, 1, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 32, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[128, 2])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=8)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b68)
l85 = sch.fuse(l71, l72, l73, l74, l75, l76, l77, l78, l79, preserve_unit_iters=True)
sch.parallel(loop=l85)
l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l86, preserve_unit_iters=True)
sch.parallel(loop=l104)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109, l110, l111 = sch.get_loops(block=b70)
l112 = sch.fuse(l110, l111, preserve_unit_iters=True)
sch.vectorize(loop=l112)
b113 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131 = sch.get_loops(block=b113)
b132 = sch.decompose_reduction(block=b113, loop=l116)
2024-04-30 08:21:09 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #678: GFLOPs: 959.5311. Time: 3857.0732 us. Best GFLOPs: 1399.5549
2024-04-30 08:21:09 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #679: GFLOPs: 1275.6531. Time: 2901.2447 us. Best GFLOPs: 1399.5549
2024-04-30 08:21:09 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #680: GFLOPs: 1152.6189. Time: 3210.9327 us. Best GFLOPs: 1399.5549
2024-04-30 08:21:09 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #681: GFLOPs: 955.9138. Time: 3871.6688 us. Best GFLOPs: 1399.5549
2024-04-30 08:21:09 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #682: GFLOPs: 1032.8658. Time: 3583.2165 us. Best GFLOPs: 1399.5549
2024-04-30 08:21:09 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #683: GFLOPs: 158.3355. Time: 23374.2958 us. Best GFLOPs: 1399.5549
2024-04-30 08:21:09 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #684: GFLOPs: 886.7970. Time: 4173.4263 us. Best GFLOPs: 1399.5549
2024-04-30 08:21:09 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #685: GFLOPs: 1048.2464. Time: 3530.6410 us. Best GFLOPs: 1399.5549
2024-04-30 08:21:09 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #686: GFLOPs: 644.2193. Time: 5744.9100 us. Best GFLOPs: 1399.5549
2024-04-30 08:21:09 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #687: GFLOPs: 1214.9697. Time: 3046.1514 us. Best GFLOPs: 1399.5549
2024-04-30 08:21:09 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #688: GFLOPs: 854.7263. Time: 4330.0198 us. Best GFLOPs: 1399.5549
2024-04-30 08:21:09 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #689: GFLOPs: 885.9666. Time: 4177.3376 us. Best GFLOPs: 1399.5549
2024-04-30 08:21:09 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #690: GFLOPs: 959.9252. Time: 3855.4896 us. Best GFLOPs: 1399.5549
2024-04-30 08:21:09 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #691: GFLOPs: 1099.6440. Time: 3365.6182 us. Best GFLOPs: 1399.5549
2024-04-30 08:21:09 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #692: GFLOPs: 792.4712. Time: 4670.1780 us. Best GFLOPs: 1399.5549
2024-04-30 08:21:09 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #693: GFLOPs: 930.9753. Time: 3975.3813 us. Best GFLOPs: 1399.5549
2024-04-30 08:21:09 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #694: GFLOPs: 876.1100. Time: 4224.3346 us. Best GFLOPs: 1399.5549
2024-04-30 08:21:09 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #695: GFLOPs: 902.8991. Time: 4098.9980 us. Best GFLOPs: 1399.5549
2024-04-30 08:21:09 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #696: GFLOPs: 76.1781. Time: 48583.3063 us. Best GFLOPs: 1399.5549
2024-04-30 08:21:09 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #697: GFLOPs: 75.5145. Time: 49010.2300 us. Best GFLOPs: 1399.5549
2024-04-30 08:21:09 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #698: GFLOPs: 979.2586. Time: 3779.3713 us. Best GFLOPs: 1399.5549
2024-04-30 08:21:09 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #699: GFLOPs: 188.7962. Time: 19603.0520 us. Best GFLOPs: 1399.5549
2024-04-30 08:21:09 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #700: GFLOPs: 907.2523. Time: 4079.3301 us. Best GFLOPs: 1399.5549
2024-04-30 08:21:09 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #701: GFLOPs: 782.9389. Time: 4727.0376 us. Best GFLOPs: 1399.5549
2024-04-30 08:21:09 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #702: GFLOPs: 6.5486. Time: 565153.4273 us. Best GFLOPs: 1399.5549
2024-04-30 08:21:09 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #703: GFLOPs: 51.4205. Time: 71974.7800 us. Best GFLOPs: 1399.5549
2024-04-30 08:21:09 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #704: GFLOPs: 32.3433. Time: 114428.1403 us. Best GFLOPs: 1399.5549
2024-04-30 08:21:09 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-30 08:21:10 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-30 08:21:15 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 08:21:15 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-30 08:21:28 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 08:21:42 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 08:21:56 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 08:22:10 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 08:22:18 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9582  0.9582  0.9568  0.9568  0.9568  0.9517  0.9517  0.9517  0.9459  0.9442  0.9442  0.9413  0.9125  0.9019  0.9005  0.9005
[17 : 32]:	0.8927  0.8927  0.8875  0.8875  0.8846  0.8836  0.8237  0.8178  0.8178  0.8149  0.8067  0.8067  0.8024  0.7994  0.7950  0.7907
[33 : 48]:	0.7874  0.7845  0.7823  0.7724  0.7707  0.7697  0.7647  0.7645  0.7630  0.7630  0.7598  0.7574  0.7562  0.7562  0.7562  0.7515
[49 : 64]:	0.7439  0.7348  0.7304  0.7304  0.7270  0.7251  0.7251  0.7221  0.7210  0.7130  0.7130  0.7117  0.7108  0.7108  0.7074  0.7058
2024-04-30 08:22:19 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-30 08:22:19 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-30 08:24:04 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #705: GFLOPs: 1324.5847. Time: 2794.0696 us. Best GFLOPs: 1399.5549
2024-04-30 08:24:04 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #706: GFLOPs: 1292.6211. Time: 2863.1606 us. Best GFLOPs: 1399.5549
2024-04-30 08:24:04 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #707: GFLOPs: 1320.7750. Time: 2802.1289 us. Best GFLOPs: 1399.5549
2024-04-30 08:24:04 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #708: GFLOPs: 1285.6265. Time: 2878.7379 us. Best GFLOPs: 1399.5549
2024-04-30 08:24:04 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #709: GFLOPs: 1265.9777. Time: 2923.4179 us. Best GFLOPs: 1399.5549
2024-04-30 08:24:04 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #710: GFLOPs: 1294.7848. Time: 2858.3759 us. Best GFLOPs: 1399.5549
2024-04-30 08:24:04 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #711: GFLOPs: 1318.7103. Time: 2806.5162 us. Best GFLOPs: 1399.5549
2024-04-30 08:24:04 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #712: GFLOPs: 1297.5115. Time: 2852.3692 us. Best GFLOPs: 1399.5549
2024-04-30 08:24:04 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #713: GFLOPs: 1373.6840. Time: 2694.2018 us. Best GFLOPs: 1399.5549
2024-04-30 08:24:04 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #714: GFLOPs: 1332.1747. Time: 2778.1504 us. Best GFLOPs: 1399.5549
2024-04-30 08:24:04 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #715: GFLOPs: 726.9860. Time: 5090.8571 us. Best GFLOPs: 1399.5549
2024-04-30 08:24:04 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #716: GFLOPs: 646.0237. Time: 5728.8639 us. Best GFLOPs: 1399.5549
2024-04-30 08:24:04 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #717: GFLOPs: 1390.0077. Time: 2662.5620 us. Best GFLOPs: 1399.5549
2024-04-30 08:24:04 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #718: GFLOPs: 1230.5448. Time: 3007.5960 us. Best GFLOPs: 1399.5549
2024-04-30 08:24:04 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #719: GFLOPs: 1385.8075. Time: 2670.6319 us. Best GFLOPs: 1399.5549
2024-04-30 08:24:04 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #720: GFLOPs: 1297.9150. Time: 2851.4823 us. Best GFLOPs: 1399.5549
2024-04-30 08:24:04 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #721: GFLOPs: 1285.3430. Time: 2879.3729 us. Best GFLOPs: 1399.5549
2024-04-30 08:24:04 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #722: GFLOPs: 1255.3795. Time: 2948.0980 us. Best GFLOPs: 1399.5549
2024-04-30 08:24:04 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #723: GFLOPs: 1270.3702. Time: 2913.3097 us. Best GFLOPs: 1399.5549
2024-04-30 08:24:04 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #724: GFLOPs: 1208.8871. Time: 3061.4783 us. Best GFLOPs: 1399.5549
2024-04-30 08:24:04 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #725: GFLOPs: 1347.5226. Time: 2746.5082 us. Best GFLOPs: 1399.5549
2024-04-30 08:24:04 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #726: GFLOPs: 1051.5748. Time: 3519.4659 us. Best GFLOPs: 1399.5549
2024-04-30 08:24:04 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #727: GFLOPs: 1209.4104. Time: 3060.1537 us. Best GFLOPs: 1399.5549
2024-04-30 08:24:04 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #728: GFLOPs: 1187.6447. Time: 3116.2365 us. Best GFLOPs: 1399.5549
2024-04-30 08:24:04 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #729: GFLOPs: 1227.9818. Time: 3013.8734 us. Best GFLOPs: 1399.5549
2024-04-30 08:24:04 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #730: GFLOPs: 1315.4024. Time: 2813.5739 us. Best GFLOPs: 1399.5549
2024-04-30 08:24:04 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #731: GFLOPs: 1339.3780. Time: 2763.2093 us. Best GFLOPs: 1399.5549
2024-04-30 08:24:04 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #732: GFLOPs: 1254.8026. Time: 2949.4533 us. Best GFLOPs: 1399.5549
2024-04-30 08:24:04 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #733: GFLOPs: 1162.2733. Time: 3184.2612 us. Best GFLOPs: 1399.5549
2024-04-30 08:24:04 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #734: GFLOPs: 1244.2787. Time: 2974.3993 us. Best GFLOPs: 1399.5549
2024-04-30 08:24:04 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #735: GFLOPs: 1305.8274. Time: 2834.2045 us. Best GFLOPs: 1399.5549
2024-04-30 08:24:04 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #736: GFLOPs: 1256.9775. Time: 2944.3499 us. Best GFLOPs: 1399.5549
2024-04-30 08:24:04 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #737: GFLOPs: 1378.7612. Time: 2684.2806 us. Best GFLOPs: 1399.5549
2024-04-30 08:24:04 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #738: GFLOPs: 810.9287. Time: 4563.8806 us. Best GFLOPs: 1399.5549
2024-04-30 08:24:04 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #739: GFLOPs: 1385.2586. Time: 2671.6901 us. Best GFLOPs: 1399.5549
2024-04-30 08:24:04 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #740: GFLOPs: 1090.2673. Time: 3394.5636 us. Best GFLOPs: 1399.5549
2024-04-30 08:24:04 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #741: GFLOPs: 1031.5415. Time: 3587.8166 us. Best GFLOPs: 1399.5549
2024-04-30 08:24:04 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #742: GFLOPs: 1190.4288. Time: 3108.9485 us. Best GFLOPs: 1399.5549
2024-04-30 08:24:04 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #743: GFLOPs: 1151.9558. Time: 3212.7811 us. Best GFLOPs: 1399.5549
2024-04-30 08:24:04 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #744: GFLOPs: 874.6764. Time: 4231.2582 us. Best GFLOPs: 1399.5549
2024-04-30 08:24:04 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #745: GFLOPs: 1065.3545. Time: 3473.9438 us. Best GFLOPs: 1399.5549
2024-04-30 08:24:04 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #746: GFLOPs: 1044.5636. Time: 3543.0891 us. Best GFLOPs: 1399.5549
2024-04-30 08:24:04 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #747: GFLOPs: 1067.0356. Time: 3468.4706 us. Best GFLOPs: 1399.5549
2024-04-30 08:24:04 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #748: GFLOPs: 1197.5678. Time: 3090.4152 us. Best GFLOPs: 1399.5549
2024-04-30 08:24:04 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #749: GFLOPs: 1258.9596. Time: 2939.7146 us. Best GFLOPs: 1399.5549
2024-04-30 08:24:04 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #750: GFLOPs: 1193.1602. Time: 3101.8314 us. Best GFLOPs: 1399.5549
2024-04-30 08:24:04 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #751: GFLOPs: 1264.2135. Time: 2927.4974 us. Best GFLOPs: 1399.5549
2024-04-30 08:24:04 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #752: GFLOPs: 888.5180. Time: 4165.3423 us. Best GFLOPs: 1399.5549
2024-04-30 08:24:04 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #753: GFLOPs: 1050.0284. Time: 3524.6491 us. Best GFLOPs: 1399.5549
2024-04-30 08:24:04 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #754: GFLOPs: 1267.3899. Time: 2920.1604 us. Best GFLOPs: 1399.5549
2024-04-30 08:24:04 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #755: GFLOPs: 1049.1691. Time: 3527.5361 us. Best GFLOPs: 1399.5549
2024-04-30 08:24:04 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #756: GFLOPs: 1079.4480. Time: 3428.5872 us. Best GFLOPs: 1399.5549
2024-04-30 08:24:04 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #757: GFLOPs: 1040.8961. Time: 3555.5728 us. Best GFLOPs: 1399.5549
2024-04-30 08:24:04 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #758: GFLOPs: 933.3523. Time: 3965.2569 us. Best GFLOPs: 1399.5549
2024-04-30 08:24:04 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #759: GFLOPs: 937.6470. Time: 3947.0951 us. Best GFLOPs: 1399.5549
2024-04-30 08:24:04 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #760: GFLOPs: 920.8405. Time: 4019.1346 us. Best GFLOPs: 1399.5549
2024-04-30 08:24:04 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #761: GFLOPs: 940.5951. Time: 3934.7237 us. Best GFLOPs: 1399.5549
2024-04-30 08:24:04 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #762: GFLOPs: 933.5652. Time: 3964.3527 us. Best GFLOPs: 1399.5549
2024-04-30 08:24:04 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #763: GFLOPs: 952.2806. Time: 3886.4402 us. Best GFLOPs: 1399.5549
2024-04-30 08:24:04 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #764: GFLOPs: 933.4538. Time: 3964.8258 us. Best GFLOPs: 1399.5549
2024-04-30 08:24:04 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #765: GFLOPs: 639.2451. Time: 5789.6133 us. Best GFLOPs: 1399.5549
2024-04-30 08:24:04 [INFO] [task_scheduler.cc:121] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #766: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(56), T.int64(56), T.int64(256)), "float32"), p1: T.Buffer((T.int64(8), T.int64(1), T.int64(3), T.int64(3), T.int64(256), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(58), T.int64(58), T.int64(256)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused in T.parallel(T.int64(64), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(1), T.int64(2), T.int64(2), T.int64(1), T.int64(1), T.int64(4), T.int64(28), T.int64(14)):
                for oc_block_3_fused_init in T.vectorized(T.int64(2)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(8), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(32) * T.int64(4) + oc_chunk_2_init * T.int64(4) + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(56), oh_2_init * T.int64(28) + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(2) * T.int64(28) + ow_2_init * T.int64(14) + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(32) // T.int64(2) * T.int64(2) + oc_block_2_init * T.int64(2) + oc_block_3_fused_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
            for ic_0, kh_0 in T.grid(T.int64(16), T.int64(3)):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(56), T.int64(30)):
                    for ax4_fused in T.vectorized(T.int64(16)):
                        with T.block("data_pad"):
                            v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                            v_i2 = T.axis.spatial(T.int64(58), kh_0 + ax2)
                            v_i3 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(2) * T.int64(28) + ax3)
                            v_i4 = T.axis.spatial(T.int64(256), ic_0 * T.int64(16) + ax4_fused)
                            T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                            T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                            data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(57) and T.int64(1) <= v_i3 and v_i3 < T.int64(57), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                for kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(2), T.int64(1), T.int64(16), T.int64(1), T.int64(3), T.int64(1), T.int64(4), T.int64(28), T.int64(14)):
                    for oc_block_3_fused in T.vectorized(T.int64(2)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(8), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(32) * T.int64(4) + oc_chunk_2 * T.int64(4) + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(56), oh_2 * T.int64(28) + oh_3)
                            v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(2) * T.int64(28) + ow_2 * T.int64(14) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(32) // T.int64(2) * T.int64(2) + oc_block_2 * T.int64(2) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(16) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)], p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)] * p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(4), T.int64(56), T.int64(28)):
                for ax4_fused in T.vectorized(T.int64(2)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(8), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(32) * T.int64(4) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(56), ax2)
                        v_ax3 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(2) * T.int64(28) + ax3)
                        v_ax4 = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(32) // T.int64(2) * T.int64(2) + ax4_fused)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[2, 1, 1, 4])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 2, 28])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 2, 2, 14])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[16, 1, 1, 2])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[16, 16])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=11)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87 = sch.get_loops(block=b68)
l88 = sch.fuse(l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, preserve_unit_iters=True)
sch.parallel(loop=l88)
l89 = sch.fuse(l87, preserve_unit_iters=True)
sch.vectorize(loop=l89)
l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106 = sch.get_loops(block=b69)
l107 = sch.fuse(l90, preserve_unit_iters=True)
sch.parallel(loop=l107)
l108 = sch.fuse(l106, preserve_unit_iters=True)
sch.vectorize(loop=l108)
sch.annotate(block_or_loop=l107, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l107, ann_key="pragma_unroll_explicit", ann_val=1)
l109, l110, l111, l112, l113, l114 = sch.get_loops(block=b70)
l115 = sch.fuse(l114, preserve_unit_iters=True)
sch.vectorize(loop=l115)
b116 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133 = sch.get_loops(block=b116)
b134 = sch.decompose_reduction(block=b116, loop=l118)
2024-04-30 08:24:04 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #767: GFLOPs: 25.6684. Time: 144184.2327 us. Best GFLOPs: 1399.5549
2024-04-30 08:24:04 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #768: GFLOPs: 58.5127. Time: 63250.9520 us. Best GFLOPs: 1399.5549
2024-04-30 09:57:13 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-30 09:57:14 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-30 09:57:19 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 09:57:19 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-30 09:57:32 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 09:57:46 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 09:58:00 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 09:58:14 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 09:58:22 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9492  0.9392  0.9365  0.9329  0.9308  0.9308  0.9294  0.9257  0.9250  0.9236  0.9214  0.9214  0.9114  0.9114  0.9089  0.9089
[17 : 32]:	0.9017  0.9017  0.8947  0.8868  0.8847  0.8824  0.8771  0.8739  0.8708  0.8708  0.8681  0.8659  0.8648  0.8635  0.8635  0.8635
[33 : 48]:	0.8635  0.8444  0.8412  0.8369  0.8369  0.8369  0.8305  0.8288  0.8276  0.7972  0.7808  0.7808  0.7752  0.7652  0.7595  0.7593
[49 : 64]:	0.7593  0.7581  0.7576  0.7566  0.7562  0.7561  0.7535  0.7533  0.7521  0.7459  0.7456  0.7430  0.7390  0.7365  0.7344  0.7344
2024-04-30 09:58:23 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-30 09:58:23 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-30 10:00:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #769: GFLOPs: 1317.5874. Time: 2808.9081 us. Best GFLOPs: 1399.5549
2024-04-30 10:00:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #770: GFLOPs: 1414.1215. Time: 2617.1597 us. Best GFLOPs: 1414.1215
2024-04-30 10:00:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #771: GFLOPs: 1312.9178. Time: 2818.8983 us. Best GFLOPs: 1414.1215
2024-04-30 10:00:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #772: GFLOPs: 1354.4637. Time: 2732.4332 us. Best GFLOPs: 1414.1215
2024-04-30 10:00:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #773: GFLOPs: 1230.8082. Time: 3006.9524 us. Best GFLOPs: 1414.1215
2024-04-30 10:00:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #774: GFLOPs: 1292.3270. Time: 2863.8121 us. Best GFLOPs: 1414.1215
2024-04-30 10:00:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #775: GFLOPs: 1251.5483. Time: 2957.1227 us. Best GFLOPs: 1414.1215
2024-04-30 10:00:03 [INFO] [task_scheduler.cc:121] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #776: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(56), T.int64(56), T.int64(256)), "float32"), p1: T.Buffer((T.int64(8), T.int64(1), T.int64(3), T.int64(3), T.int64(256), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(58), T.int64(58), T.int64(256)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused in T.parallel(T.int64(224), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(16), T.int64(3), T.int64(256)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(4) * T.int64(14) + ax2)
                    v_i3 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(4) + ax3)
                    v_i4 = T.axis.spatial(T.int64(256), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(57) and T.int64(1) <= v_i3 and v_i3 < T.int64(57), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(14), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(8), oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(4) * T.int64(14) + oh_2_init * T.int64(14) + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(4) + ow_1 + ow_2_init + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(128), T.int64(1), T.int64(3), T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(32), T.int64(2), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(14), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(8), oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(4) * T.int64(14) + oh_2 * T.int64(14) + oh_3)
                        v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(4) + ow_1 + ow_2 + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(2) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)], p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)] * p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block]
                for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(8), T.int64(14)):
                    for ax3_ax4_fused in T.vectorized(T.int64(32)):
                        with T.block("T_relu"):
                            v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                            v_ax2 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(4) * T.int64(14) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(4))
                            v_ax4 = T.axis.spatial(T.int64(32), ax3_ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 8, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 4, 1, 14])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[56, 1, 1, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 32, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[128, 2])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=7)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83 = sch.get_loops(block=b68)
l84 = sch.fuse(l71, l72, l73, l74, l75, l76, l77, l78, preserve_unit_iters=True)
sch.parallel(loop=l84)
l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l85, preserve_unit_iters=True)
sch.parallel(loop=l104)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109, l110, l111, l112 = sch.get_loops(block=b70)
l113 = sch.fuse(l111, l112, preserve_unit_iters=True)
sch.vectorize(loop=l113)
b114 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133 = sch.get_loops(block=b114)
b134 = sch.decompose_reduction(block=b114, loop=l118)
2024-04-30 10:00:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #777: GFLOPs: 1392.9876. Time: 2656.8663 us. Best GFLOPs: 1414.1215
2024-04-30 10:00:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #778: GFLOPs: 1397.0407. Time: 2649.1582 us. Best GFLOPs: 1414.1215
2024-04-30 10:00:03 [INFO] [task_scheduler.cc:121] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #779: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(56), T.int64(56), T.int64(256)), "float32"), p1: T.Buffer((T.int64(8), T.int64(1), T.int64(3), T.int64(3), T.int64(256), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(58), T.int64(58), T.int64(256)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused in T.parallel(T.int64(224), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(16), T.int64(3), T.int64(256)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(112) * T.int64(28) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(2) * T.int64(14) + ax2)
                    v_i3 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(112) // T.int64(2) + ax3)
                    v_i4 = T.axis.spatial(T.int64(256), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(57) and T.int64(1) <= v_i3 and v_i3 < T.int64(57), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(14), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(8), oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(112) * T.int64(28) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(2) * T.int64(14) + oh_2_init * T.int64(14) + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(112) // T.int64(2) + ow_1 + ow_2_init + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(128), T.int64(1), T.int64(3), T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(32), T.int64(2), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(14), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(8), oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(112) * T.int64(28) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(2) * T.int64(14) + oh_2 * T.int64(14) + oh_3)
                        v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(112) // T.int64(2) + ow_1 + ow_2 + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(2) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)], p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)] * p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block]
                for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(8), T.int64(14)):
                    for ax3_ax4_fused in T.vectorized(T.int64(32)):
                        with T.block("T_relu"):
                            v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                            v_ax2 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(112) * T.int64(28) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(2) * T.int64(14) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(112) // T.int64(2))
                            v_ax4 = T.axis.spatial(T.int64(32), ax3_ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 8, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 2, 1, 14])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[56, 1, 1, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 32, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[128, 2])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=7)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83 = sch.get_loops(block=b68)
l84 = sch.fuse(l71, l72, l73, l74, l75, l76, l77, l78, preserve_unit_iters=True)
sch.parallel(loop=l84)
l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l85, preserve_unit_iters=True)
sch.parallel(loop=l104)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109, l110, l111, l112 = sch.get_loops(block=b70)
l113 = sch.fuse(l111, l112, preserve_unit_iters=True)
sch.vectorize(loop=l113)
b114 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133 = sch.get_loops(block=b114)
b134 = sch.decompose_reduction(block=b114, loop=l118)
2024-04-30 10:00:03 [INFO] [task_scheduler.cc:121] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #780: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(56), T.int64(56), T.int64(256)), "float32"), p1: T.Buffer((T.int64(8), T.int64(1), T.int64(3), T.int64(3), T.int64(256), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(58), T.int64(58), T.int64(256)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused in T.parallel(T.int64(224), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(16), T.int64(3), T.int64(256)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(112) // T.int64(28) * T.int64(14) + ax2)
                    v_i3 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(112) * T.int64(28) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(28) + ax3)
                    v_i4 = T.axis.spatial(T.int64(256), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(57) and T.int64(1) <= v_i3 and v_i3 < T.int64(57), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oc_block_1 in range(T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(14), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(8), oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(112) // T.int64(28) * T.int64(14) + oh_2_init * T.int64(14) + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(112) * T.int64(28) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(28) + ow_2_init + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(128), T.int64(1), T.int64(3), T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(32), T.int64(2), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(14), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(8), oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(112) // T.int64(28) * T.int64(14) + oh_2 * T.int64(14) + oh_3)
                        v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(112) * T.int64(28) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(28) + ow_2 + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(2) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)], p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)] * p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block]
                for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(8), T.int64(14)):
                    for ax3_ax4_fused in T.vectorized(T.int64(32)):
                        with T.block("T_relu"):
                            v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                            v_ax2 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(112) // T.int64(28) * T.int64(14) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(112) * T.int64(28) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(28))
                            v_ax4 = T.axis.spatial(T.int64(32), ax3_ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 8, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 4, 1, 14])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[2, 28, 1, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 32, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[128, 2])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=112)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=8)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b68)
l85 = sch.fuse(l71, l72, l73, l74, l75, l76, l77, l78, l79, preserve_unit_iters=True)
sch.parallel(loop=l85)
l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l86, preserve_unit_iters=True)
sch.parallel(loop=l104)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109, l110, l111 = sch.get_loops(block=b70)
l112 = sch.fuse(l110, l111, preserve_unit_iters=True)
sch.vectorize(loop=l112)
b113 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131 = sch.get_loops(block=b113)
b132 = sch.decompose_reduction(block=b113, loop=l116)
2024-04-30 10:00:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #781: GFLOPs: 1421.0261. Time: 2604.4433 us. Best GFLOPs: 1421.0261
2024-04-30 10:00:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #782: GFLOPs: 1441.9763. Time: 2566.6037 us. Best GFLOPs: 1441.9763
2024-04-30 10:00:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #783: GFLOPs: 1414.3327. Time: 2616.7689 us. Best GFLOPs: 1441.9763
2024-04-30 10:00:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #784: GFLOPs: 1353.3494. Time: 2734.6831 us. Best GFLOPs: 1441.9763
2024-04-30 10:00:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #785: GFLOPs: 1201.4350. Time: 3080.4678 us. Best GFLOPs: 1441.9763
2024-04-30 10:00:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #786: GFLOPs: 1211.6805. Time: 3054.4205 us. Best GFLOPs: 1441.9763
2024-04-30 10:00:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #787: GFLOPs: 1223.4533. Time: 3025.0291 us. Best GFLOPs: 1441.9763
2024-04-30 10:00:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #788: GFLOPs: 1217.4770. Time: 3039.8781 us. Best GFLOPs: 1441.9763
2024-04-30 10:00:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #789: GFLOPs: 1290.4738. Time: 2867.9247 us. Best GFLOPs: 1441.9763
2024-04-30 10:00:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #790: GFLOPs: 1218.5933. Time: 3037.0934 us. Best GFLOPs: 1441.9763
2024-04-30 10:00:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #791: GFLOPs: 1229.3002. Time: 3010.6412 us. Best GFLOPs: 1441.9763
2024-04-30 10:00:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #792: GFLOPs: 1321.5354. Time: 2800.5165 us. Best GFLOPs: 1441.9763
2024-04-30 10:00:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #793: GFLOPs: 1215.1710. Time: 3045.6470 us. Best GFLOPs: 1441.9763
2024-04-30 10:00:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #794: GFLOPs: 1233.2656. Time: 3000.9608 us. Best GFLOPs: 1441.9763
2024-04-30 10:00:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #795: GFLOPs: 1213.2472. Time: 3050.4761 us. Best GFLOPs: 1441.9763
2024-04-30 10:00:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #796: GFLOPs: 1213.3172. Time: 3050.3004 us. Best GFLOPs: 1441.9763
2024-04-30 10:00:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #797: GFLOPs: 1218.8678. Time: 3036.4095 us. Best GFLOPs: 1441.9763
2024-04-30 10:00:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #798: GFLOPs: 1241.5088. Time: 2981.0354 us. Best GFLOPs: 1441.9763
2024-04-30 10:00:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #799: GFLOPs: 1190.9908. Time: 3107.4814 us. Best GFLOPs: 1441.9763
2024-04-30 10:00:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #800: GFLOPs: 1242.3935. Time: 2978.9128 us. Best GFLOPs: 1441.9763
2024-04-30 10:00:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #801: GFLOPs: 1180.6629. Time: 3134.6643 us. Best GFLOPs: 1441.9763
2024-04-30 10:00:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #802: GFLOPs: 1241.9459. Time: 2979.9863 us. Best GFLOPs: 1441.9763
2024-04-30 10:00:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #803: GFLOPs: 1115.3293. Time: 3318.2862 us. Best GFLOPs: 1441.9763
2024-04-30 10:00:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #804: GFLOPs: 1228.5182. Time: 3012.5574 us. Best GFLOPs: 1441.9763
2024-04-30 10:00:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #805: GFLOPs: 1210.4461. Time: 3057.5353 us. Best GFLOPs: 1441.9763
2024-04-30 10:00:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #806: GFLOPs: 1191.2678. Time: 3106.7589 us. Best GFLOPs: 1441.9763
2024-04-30 10:00:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #807: GFLOPs: 1309.0389. Time: 2827.2512 us. Best GFLOPs: 1441.9763
2024-04-30 10:00:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #808: GFLOPs: 1206.6342. Time: 3067.1946 us. Best GFLOPs: 1441.9763
2024-04-30 10:00:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #809: GFLOPs: 866.7432. Time: 4269.9864 us. Best GFLOPs: 1441.9763
2024-04-30 10:00:03 [INFO] [task_scheduler.cc:121] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #810: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(56), T.int64(56), T.int64(256)), "float32"), p1: T.Buffer((T.int64(8), T.int64(1), T.int64(3), T.int64(3), T.int64(256), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(58), T.int64(58), T.int64(256)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused in T.parallel(T.int64(224), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(9), T.int64(4), T.int64(256)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(28) * T.int64(7) + ax2)
                    v_i3 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(28) * T.int64(2) + ax3)
                    v_i4 = T.axis.spatial(T.int64(256), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(57) and T.int64(1) <= v_i3 and v_i3 < T.int64(57), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oc_block_1 in range(T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(7), T.int64(2), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(8), oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(28) * T.int64(7) + oh_2_init * T.int64(7) + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(28) * T.int64(2) + ow_2_init * T.int64(2) + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(128), T.int64(1), T.int64(3), T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(32), T.int64(2), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(2), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(8), oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(28) * T.int64(7) + oh_2 * T.int64(7) + oh_3)
                        v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(28) * T.int64(2) + ow_2 * T.int64(2) + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(2) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)], p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)] * p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block]
                for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(8), T.int64(7)):
                    for ax3_ax4_fused in T.vectorized(T.int64(64)):
                        with T.block("T_relu"):
                            v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                            v_ax2 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(28) * T.int64(7) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(28) * T.int64(2) + ax3_ax4_fused // T.int64(32))
                            v_ax4 = T.axis.spatial(T.int64(32), ax3_ax4_fused % T.int64(32))
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 8, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 4, 1, 7])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 28, 1, 2])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 32, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[128, 2])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=8)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b68)
l85 = sch.fuse(l71, l72, l73, l74, l75, l76, l77, l78, l79, preserve_unit_iters=True)
sch.parallel(loop=l85)
l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l86, preserve_unit_iters=True)
sch.parallel(loop=l104)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109, l110, l111 = sch.get_loops(block=b70)
l112 = sch.fuse(l110, l111, preserve_unit_iters=True)
sch.vectorize(loop=l112)
b113 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131 = sch.get_loops(block=b113)
b132 = sch.decompose_reduction(block=b113, loop=l116)
2024-04-30 10:00:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #811: GFLOPs: 370.1934. Time: 9997.4275 us. Best GFLOPs: 1441.9763
2024-04-30 10:00:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #812: GFLOPs: 893.6722. Time: 4141.3189 us. Best GFLOPs: 1441.9763
2024-04-30 10:00:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #813: GFLOPs: 1082.7629. Time: 3418.0906 us. Best GFLOPs: 1441.9763
2024-04-30 10:00:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #814: GFLOPs: 792.9053. Time: 4667.6213 us. Best GFLOPs: 1441.9763
2024-04-30 10:00:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #815: GFLOPs: 1314.1417. Time: 2816.2729 us. Best GFLOPs: 1441.9763
2024-04-30 10:00:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #816: GFLOPs: 1051.9270. Time: 3518.2878 us. Best GFLOPs: 1441.9763
2024-04-30 10:00:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #817: GFLOPs: 1105.2956. Time: 3348.4090 us. Best GFLOPs: 1441.9763
2024-04-30 10:00:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #818: GFLOPs: 1061.5314. Time: 3486.4552 us. Best GFLOPs: 1441.9763
2024-04-30 10:00:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #819: GFLOPs: 1130.3946. Time: 3274.0618 us. Best GFLOPs: 1441.9763
2024-04-30 10:00:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #820: GFLOPs: 1089.7980. Time: 3396.0254 us. Best GFLOPs: 1441.9763
2024-04-30 10:00:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #821: GFLOPs: 1143.2757. Time: 3237.1735 us. Best GFLOPs: 1441.9763
2024-04-30 10:00:03 [INFO] [task_scheduler.cc:121] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #822: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(56), T.int64(56), T.int64(256)), "float32"), p1: T.Buffer((T.int64(8), T.int64(1), T.int64(3), T.int64(3), T.int64(256), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(58), T.int64(58), T.int64(256)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused in T.parallel(T.int64(896), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(16), T.int64(3), T.int64(256)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(448) * T.int64(28) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(4) // T.int64(2) * T.int64(14) + ax2)
                    v_i3 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(2) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(448) // T.int64(16) * T.int64(2) + ax3)
                    v_i4 = T.axis.spatial(T.int64(256), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(57) and T.int64(1) <= v_i3 and v_i3 < T.int64(57), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oc_block_1 in range(T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(14), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(8), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(16) // T.int64(4) * T.int64(2) + oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(448) * T.int64(28) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(4) // T.int64(2) * T.int64(14) + oh_2_init * T.int64(14) + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(448) // T.int64(16) * T.int64(2) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(2) + ow_2_init + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(128), T.int64(1), T.int64(3), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(32), T.int64(2), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(14), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(8), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(16) // T.int64(4) * T.int64(2) + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(448) * T.int64(28) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(4) // T.int64(2) * T.int64(14) + oh_2 * T.int64(14) + oh_3)
                        v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(448) // T.int64(16) * T.int64(2) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(2) + ow_2 + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(2) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)], p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)] * p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block]
                for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(2), T.int64(14)):
                    for ax3_ax4_fused in T.vectorized(T.int64(32)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(8), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(16) // T.int64(4) * T.int64(2) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(448) * T.int64(28) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(4) // T.int64(2) * T.int64(14) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(448) // T.int64(16) * T.int64(2) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(2))
                            v_ax4 = T.axis.spatial(T.int64(32), ax3_ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 4, 2, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 2, 1, 14])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[28, 2, 1, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 32, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[128, 2])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=8)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b68)
l85 = sch.fuse(l71, l72, l73, l74, l75, l76, l77, l78, l79, preserve_unit_iters=True)
sch.parallel(loop=l85)
l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l86, preserve_unit_iters=True)
sch.parallel(loop=l104)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109, l110, l111 = sch.get_loops(block=b70)
l112 = sch.fuse(l110, l111, preserve_unit_iters=True)
sch.vectorize(loop=l112)
b113 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131 = sch.get_loops(block=b113)
b132 = sch.decompose_reduction(block=b113, loop=l116)
2024-04-30 10:00:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #823: GFLOPs: 1238.2687. Time: 2988.8359 us. Best GFLOPs: 1441.9763
2024-04-30 10:00:03 [INFO] [task_scheduler.cc:121] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #824: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(56), T.int64(56), T.int64(256)), "float32"), p1: T.Buffer((T.int64(8), T.int64(1), T.int64(3), T.int64(3), T.int64(256), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(58), T.int64(58), T.int64(256)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused in T.parallel(T.int64(448), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(9), T.int64(4), T.int64(256)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(224) // T.int64(28) * T.int64(7) + ax2)
                    v_i3 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(28) * T.int64(2) + ax3)
                    v_i4 = T.axis.spatial(T.int64(256), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(57) and T.int64(1) <= v_i3 and v_i3 < T.int64(57), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oc_block_1 in range(T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(7), T.int64(2), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(8), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(224) * T.int64(4) + oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(224) // T.int64(28) * T.int64(7) + oh_2_init * T.int64(7) + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(28) * T.int64(2) + ow_2_init * T.int64(2) + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(128), T.int64(1), T.int64(3), T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(32), T.int64(2), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(2), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(8), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(224) * T.int64(4) + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(224) // T.int64(28) * T.int64(7) + oh_2 * T.int64(7) + oh_3)
                        v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(28) * T.int64(2) + ow_2 * T.int64(2) + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(2) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)], p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)] * p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block]
                for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(4), T.int64(7)):
                    for ax3_ax4_fused in T.vectorized(T.int64(64)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(8), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(224) * T.int64(4) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(224) // T.int64(28) * T.int64(7) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(28) * T.int64(2) + ax3_ax4_fused // T.int64(32))
                            v_ax4 = T.axis.spatial(T.int64(32), ax3_ax4_fused % T.int64(32))
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[2, 1, 4, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 4, 1, 7])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 28, 1, 2])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 32, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[128, 2])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=8)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b68)
l85 = sch.fuse(l71, l72, l73, l74, l75, l76, l77, l78, l79, preserve_unit_iters=True)
sch.parallel(loop=l85)
l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l86, preserve_unit_iters=True)
sch.parallel(loop=l104)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109, l110, l111 = sch.get_loops(block=b70)
l112 = sch.fuse(l110, l111, preserve_unit_iters=True)
sch.vectorize(loop=l112)
b113 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131 = sch.get_loops(block=b113)
b132 = sch.decompose_reduction(block=b113, loop=l116)
2024-04-30 10:00:03 [INFO] [task_scheduler.cc:121] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #825: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(56), T.int64(56), T.int64(256)), "float32"), p1: T.Buffer((T.int64(8), T.int64(1), T.int64(3), T.int64(3), T.int64(256), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(58), T.int64(58), T.int64(256)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused in T.parallel(T.int64(896), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(16), T.int64(3), T.int64(256)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(448) * T.int64(28) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(2) * T.int64(14) + ax2)
                    v_i3 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(448) // T.int64(8) + ax3)
                    v_i4 = T.axis.spatial(T.int64(256), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(57) and T.int64(1) <= v_i3 and v_i3 < T.int64(57), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(14), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(8), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(8) // T.int64(2) * T.int64(2) + oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(448) * T.int64(28) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(2) * T.int64(14) + oh_2_init * T.int64(14) + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(448) // T.int64(8) + ow_1 + ow_2_init + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(128), T.int64(1), T.int64(3), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(32), T.int64(2), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(14), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(8), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(8) // T.int64(2) * T.int64(2) + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(448) * T.int64(28) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(2) * T.int64(14) + oh_2 * T.int64(14) + oh_3)
                        v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(448) // T.int64(8) + ow_1 + ow_2 + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(2) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)], p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)] * p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block]
                for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(2), T.int64(14)):
                    for ax3_ax4_fused in T.vectorized(T.int64(32)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(8), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(8) // T.int64(2) * T.int64(2) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(448) * T.int64(28) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(2) * T.int64(14) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(448) // T.int64(8))
                            v_ax4 = T.axis.spatial(T.int64(32), ax3_ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 4, 2, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 2, 1, 14])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[56, 1, 1, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 32, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[128, 2])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=7)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83 = sch.get_loops(block=b68)
l84 = sch.fuse(l71, l72, l73, l74, l75, l76, l77, l78, preserve_unit_iters=True)
sch.parallel(loop=l84)
l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l85, preserve_unit_iters=True)
sch.parallel(loop=l104)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109, l110, l111, l112 = sch.get_loops(block=b70)
l113 = sch.fuse(l111, l112, preserve_unit_iters=True)
sch.vectorize(loop=l113)
b114 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133 = sch.get_loops(block=b114)
b134 = sch.decompose_reduction(block=b114, loop=l118)
2024-04-30 10:00:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #826: GFLOPs: 1055.4201. Time: 3506.6431 us. Best GFLOPs: 1441.9763
2024-04-30 10:00:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #827: GFLOPs: 954.2093. Time: 3878.5848 us. Best GFLOPs: 1441.9763
2024-04-30 10:00:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #828: GFLOPs: 1079.0524. Time: 3429.8444 us. Best GFLOPs: 1441.9763
2024-04-30 10:00:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #829: GFLOPs: 1137.3897. Time: 3253.9260 us. Best GFLOPs: 1441.9763
2024-04-30 10:00:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #830: GFLOPs: 64.5275. Time: 57355.1263 us. Best GFLOPs: 1441.9763
2024-04-30 10:00:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #831: GFLOPs: 52.4498. Time: 70562.3650 us. Best GFLOPs: 1441.9763
2024-04-30 10:00:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #832: GFLOPs: 26.7581. Time: 138312.4710 us. Best GFLOPs: 1441.9763
2024-04-30 10:03:25 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-30 10:03:26 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-30 10:03:31 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 10:03:31 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-30 10:03:44 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 10:03:58 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 10:04:11 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 10:04:25 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 10:04:33 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9268  0.9268  0.9268  0.9268  0.9229  0.9229  0.9201  0.9173  0.9142  0.9028  0.9011  0.8972  0.8953  0.8953  0.8934  0.8908
[17 : 32]:	0.8877  0.8853  0.8847  0.8847  0.8810  0.8772  0.8760  0.8708  0.8708  0.8704  0.8623  0.8598  0.8573  0.8559  0.8557  0.8557
[33 : 48]:	0.8552  0.8552  0.8545  0.8528  0.8528  0.8511  0.8484  0.8466  0.8432  0.8382  0.8347  0.8347  0.8338  0.8338  0.8338  0.8173
[49 : 64]:	0.8173  0.8147  0.7911  0.7711  0.7711  0.7711  0.7650  0.7634  0.7634  0.7622  0.7613  0.7613  0.7598  0.7598  0.7598  0.7586
2024-04-30 10:04:33 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-30 10:04:33 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-30 10:06:48 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #833: GFLOPs: 1400.4204. Time: 2642.7648 us. Best GFLOPs: 1441.9763
2024-04-30 10:06:48 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #834: GFLOPs: 1291.5691. Time: 2865.4927 us. Best GFLOPs: 1441.9763
2024-04-30 10:06:48 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #835: GFLOPs: 1318.2525. Time: 2807.4909 us. Best GFLOPs: 1441.9763
2024-04-30 10:06:48 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #836: GFLOPs: 1408.5641. Time: 2627.4856 us. Best GFLOPs: 1441.9763
2024-04-30 10:06:48 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #837: GFLOPs: 1349.0863. Time: 2743.3247 us. Best GFLOPs: 1441.9763
2024-04-30 10:06:48 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #838: GFLOPs: 1289.8009. Time: 2869.4209 us. Best GFLOPs: 1441.9763
2024-04-30 10:06:48 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #839: GFLOPs: 1295.7215. Time: 2856.3095 us. Best GFLOPs: 1441.9763
2024-04-30 10:06:48 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #840: GFLOPs: 1369.9867. Time: 2701.4728 us. Best GFLOPs: 1441.9763
2024-04-30 10:06:48 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #841: GFLOPs: 1301.2169. Time: 2844.2467 us. Best GFLOPs: 1441.9763
2024-04-30 10:06:48 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #842: GFLOPs: 1383.8270. Time: 2674.4541 us. Best GFLOPs: 1441.9763
2024-04-30 10:06:48 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #843: GFLOPs: 1270.1256. Time: 2913.8706 us. Best GFLOPs: 1441.9763
2024-04-30 10:06:48 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #844: GFLOPs: 1332.2401. Time: 2778.0141 us. Best GFLOPs: 1441.9763
2024-04-30 10:06:48 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #845: GFLOPs: 1310.8584. Time: 2823.3268 us. Best GFLOPs: 1441.9763
2024-04-30 10:06:48 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #846: GFLOPs: 1451.0855. Time: 2550.4918 us. Best GFLOPs: 1451.0855
2024-04-30 10:06:48 [INFO] [task_scheduler.cc:121] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #847: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(56), T.int64(56), T.int64(256)), "float32"), p1: T.Buffer((T.int64(8), T.int64(1), T.int64(3), T.int64(3), T.int64(256), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(58), T.int64(58), T.int64(256)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused in T.parallel(T.int64(224), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(16), T.int64(3), T.int64(256)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(28) // T.int64(7) * T.int64(14) + ax2)
                    v_i3 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(28) * T.int64(7) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(7) + ax3)
                    v_i4 = T.axis.spatial(T.int64(256), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(57) and T.int64(1) <= v_i3 and v_i3 < T.int64(57), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oc_block_1 in range(T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(14), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(8), oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(28) // T.int64(7) * T.int64(14) + oh_2_init * T.int64(14) + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(28) * T.int64(7) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(7) + ow_2_init + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(128), T.int64(1), T.int64(3), T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(32), T.int64(2), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(14), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(8), oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(28) // T.int64(7) * T.int64(14) + oh_2 * T.int64(14) + oh_3)
                        v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(28) * T.int64(7) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(7) + ow_2 + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(2) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)], p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)] * p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block]
                for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(8), T.int64(14)):
                    for ax3_ax4_fused in T.vectorized(T.int64(32)):
                        with T.block("T_relu"):
                            v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                            v_ax2 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(28) // T.int64(7) * T.int64(14) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(28) * T.int64(7) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(7))
                            v_ax4 = T.axis.spatial(T.int64(32), ax3_ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 8, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 4, 1, 14])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[8, 7, 1, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 32, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[128, 2])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=112)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=8)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b68)
l85 = sch.fuse(l71, l72, l73, l74, l75, l76, l77, l78, l79, preserve_unit_iters=True)
sch.parallel(loop=l85)
l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l86, preserve_unit_iters=True)
sch.parallel(loop=l104)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109, l110, l111 = sch.get_loops(block=b70)
l112 = sch.fuse(l110, l111, preserve_unit_iters=True)
sch.vectorize(loop=l112)
b113 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131 = sch.get_loops(block=b113)
b132 = sch.decompose_reduction(block=b113, loop=l116)
2024-04-30 10:06:48 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #848: GFLOPs: 1248.3630. Time: 2964.6679 us. Best GFLOPs: 1451.0855
2024-04-30 10:06:48 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #849: GFLOPs: 1278.4667. Time: 2894.8597 us. Best GFLOPs: 1451.0855
2024-04-30 10:06:48 [INFO] [task_scheduler.cc:121] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #850: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(56), T.int64(56), T.int64(256)), "float32"), p1: T.Buffer((T.int64(8), T.int64(1), T.int64(3), T.int64(3), T.int64(256), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(58), T.int64(58), T.int64(256)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused in T.parallel(T.int64(224), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(16), T.int64(3), T.int64(256)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(56) * T.int64(14) + ax2)
                    v_i3 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(56) + ax3)
                    v_i4 = T.axis.spatial(T.int64(256), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(57) and T.int64(1) <= v_i3 and v_i3 < T.int64(57), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oc_block_1 in range(T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(14), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(8), oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(56) * T.int64(14) + oh_2_init * T.int64(14) + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(56) + ow_2_init + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(128), T.int64(1), T.int64(3), T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(32), T.int64(2), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(14), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(8), oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(56) * T.int64(14) + oh_2 * T.int64(14) + oh_3)
                        v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(56) + ow_2 + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(2) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)], p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)] * p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block]
                for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(8), T.int64(14)):
                    for ax3_ax4_fused in T.vectorized(T.int64(32)):
                        with T.block("T_relu"):
                            v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                            v_ax2 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(56) * T.int64(14) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(56))
                            v_ax4 = T.axis.spatial(T.int64(32), ax3_ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 8, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 2, 1, 14])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 56, 1, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 32, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[128, 2])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=112)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=8)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b68)
l85 = sch.fuse(l71, l72, l73, l74, l75, l76, l77, l78, l79, preserve_unit_iters=True)
sch.parallel(loop=l85)
l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l86, preserve_unit_iters=True)
sch.parallel(loop=l104)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109, l110, l111 = sch.get_loops(block=b70)
l112 = sch.fuse(l110, l111, preserve_unit_iters=True)
sch.vectorize(loop=l112)
b113 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131 = sch.get_loops(block=b113)
b132 = sch.decompose_reduction(block=b113, loop=l116)
2024-04-30 10:06:48 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #851: GFLOPs: 1237.3098. Time: 2991.1521 us. Best GFLOPs: 1451.0855
2024-04-30 10:06:48 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #852: GFLOPs: 1238.7983. Time: 2987.5581 us. Best GFLOPs: 1451.0855
2024-04-30 10:06:48 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #853: GFLOPs: 1113.7006. Time: 3323.1388 us. Best GFLOPs: 1451.0855
2024-04-30 10:06:48 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #854: GFLOPs: 161.8352. Time: 22868.8370 us. Best GFLOPs: 1451.0855
2024-04-30 10:06:48 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #855: GFLOPs: 1231.6030. Time: 3005.0119 us. Best GFLOPs: 1451.0855
2024-04-30 10:06:48 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #856: GFLOPs: 1249.1379. Time: 2962.8288 us. Best GFLOPs: 1451.0855
2024-04-30 10:06:48 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #857: GFLOPs: 1332.4685. Time: 2777.5379 us. Best GFLOPs: 1451.0855
2024-04-30 10:06:48 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #858: GFLOPs: 1215.4236. Time: 3045.0138 us. Best GFLOPs: 1451.0855
2024-04-30 10:06:48 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #859: GFLOPs: 1289.5008. Time: 2870.0887 us. Best GFLOPs: 1451.0855
2024-04-30 10:06:48 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #860: GFLOPs: 1042.3311. Time: 3550.6778 us. Best GFLOPs: 1451.0855
2024-04-30 10:06:48 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #861: GFLOPs: 1234.8592. Time: 2997.0879 us. Best GFLOPs: 1451.0855
2024-04-30 10:06:48 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #862: GFLOPs: 1347.4584. Time: 2746.6391 us. Best GFLOPs: 1451.0855
2024-04-30 10:06:48 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #863: GFLOPs: 1277.3381. Time: 2897.4175 us. Best GFLOPs: 1451.0855
2024-04-30 10:06:48 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #864: GFLOPs: 1248.3441. Time: 2964.7127 us. Best GFLOPs: 1451.0855
2024-04-30 10:06:48 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #865: GFLOPs: 1233.3342. Time: 3000.7939 us. Best GFLOPs: 1451.0855
2024-04-30 10:06:48 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #866: GFLOPs: 1331.8479. Time: 2778.8321 us. Best GFLOPs: 1451.0855
2024-04-30 10:06:48 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #867: GFLOPs: 1253.8881. Time: 2951.6045 us. Best GFLOPs: 1451.0855
2024-04-30 10:06:48 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #868: GFLOPs: 1305.4231. Time: 2835.0823 us. Best GFLOPs: 1451.0855
2024-04-30 10:06:48 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #869: GFLOPs: 978.8601. Time: 3780.9098 us. Best GFLOPs: 1451.0855
2024-04-30 10:06:48 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #870: GFLOPs: 1219.3647. Time: 3035.1721 us. Best GFLOPs: 1451.0855
2024-04-30 10:06:48 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #871: GFLOPs: 1283.2076. Time: 2884.1644 us. Best GFLOPs: 1451.0855
2024-04-30 10:06:48 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #872: GFLOPs: 1207.6755. Time: 3064.5499 us. Best GFLOPs: 1451.0855
2024-04-30 10:06:48 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #873: GFLOPs: 1217.1794. Time: 3040.6213 us. Best GFLOPs: 1451.0855
2024-04-30 10:06:48 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #874: GFLOPs: 1201.9516. Time: 3079.1438 us. Best GFLOPs: 1451.0855
2024-04-30 10:06:48 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #875: GFLOPs: 1266.1585. Time: 2923.0005 us. Best GFLOPs: 1451.0855
2024-04-30 10:06:48 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #876: GFLOPs: 1207.7634. Time: 3064.3268 us. Best GFLOPs: 1451.0855
2024-04-30 10:06:48 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #877: GFLOPs: 1251.6646. Time: 2956.8478 us. Best GFLOPs: 1451.0855
2024-04-30 10:06:48 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #878: GFLOPs: 1208.2533. Time: 3063.0844 us. Best GFLOPs: 1451.0855
2024-04-30 10:06:48 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #879: GFLOPs: 1205.8260. Time: 3069.2503 us. Best GFLOPs: 1451.0855
2024-04-30 10:06:48 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #880: GFLOPs: 1245.2738. Time: 2972.0225 us. Best GFLOPs: 1451.0855
2024-04-30 10:06:48 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #881: GFLOPs: 1208.2040. Time: 3063.2092 us. Best GFLOPs: 1451.0855
2024-04-30 10:06:48 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #882: GFLOPs: 1208.0489. Time: 3063.6026 us. Best GFLOPs: 1451.0855
2024-04-30 10:06:48 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #883: GFLOPs: 1244.8823. Time: 2972.9572 us. Best GFLOPs: 1451.0855
2024-04-30 10:06:48 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #884: GFLOPs: 1138.7611. Time: 3250.0071 us. Best GFLOPs: 1451.0855
2024-04-30 10:06:48 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #885: GFLOPs: 1040.4379. Time: 3557.1387 us. Best GFLOPs: 1451.0855
2024-04-30 10:06:48 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #886: GFLOPs: 1058.6893. Time: 3495.8148 us. Best GFLOPs: 1451.0855
2024-04-30 10:06:48 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #887: GFLOPs: 988.8226. Time: 3742.8169 us. Best GFLOPs: 1451.0855
2024-04-30 10:06:48 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #888: GFLOPs: 616.1945. Time: 6006.1908 us. Best GFLOPs: 1451.0855
2024-04-30 10:06:48 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #889: GFLOPs: 1246.4517. Time: 2969.2139 us. Best GFLOPs: 1451.0855
2024-04-30 10:06:48 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #890: GFLOPs: 1058.2035. Time: 3497.4197 us. Best GFLOPs: 1451.0855
2024-04-30 10:06:48 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #891: GFLOPs: 1011.0785. Time: 3660.4296 us. Best GFLOPs: 1451.0855
2024-04-30 10:06:48 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #892: GFLOPs: 1013.7263. Time: 3650.8688 us. Best GFLOPs: 1451.0855
2024-04-30 10:06:48 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #893: GFLOPs: 163.9915. Time: 22568.1378 us. Best GFLOPs: 1451.0855
2024-04-30 10:06:48 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #894: GFLOPs: 96.2894. Time: 38436.0277 us. Best GFLOPs: 1451.0855
2024-04-30 10:06:48 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #895: GFLOPs: 124.1358. Time: 29813.9825 us. Best GFLOPs: 1451.0855
2024-04-30 10:06:48 [INFO] [task_scheduler.cc:121] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #896: Error in running:
LocalRunner: Timeout, killed after 30 seconds

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(56), T.int64(56), T.int64(256)), "float32"), p1: T.Buffer((T.int64(8), T.int64(1), T.int64(3), T.int64(3), T.int64(256), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(58), T.int64(58), T.int64(256)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused_fused in T.parallel(T.int64(8)):
            for n_1, oc_chunk_1, oh_1 in T.grid(T.int64(1), T.int64(2), T.int64(2)):
                for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(30), T.int64(58), T.int64(256)):
                    with T.block("data_pad"):
                        v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                        v_i2 = T.axis.spatial(T.int64(58), oh_1 * T.int64(28) + ax2)
                        v_i3, v_i4 = T.axis.remap("SS", [ax3, ax4])
                        T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                        T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                        data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(57) and T.int64(1) <= v_i3 and v_i3 < T.int64(57), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                for ow_1, oc_block_1 in T.grid(T.int64(2), T.int64(8)):
                    for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(2), T.int64(4), T.int64(2), T.int64(1), T.int64(1), T.int64(14), T.int64(7), T.int64(1)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(8), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused_fused // T.int64(2) * T.int64(2) + oc_chunk_1 + oc_chunk_2_init + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(56), oh_1 * T.int64(28) + oh_2_init * T.int64(14) + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(56), ow_1 * T.int64(28) + ow_2_init * T.int64(7) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused_fused % T.int64(2) * T.int64(16) + oc_block_1 * T.int64(2) + oc_block_2_init + oc_block_3_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                    for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(64), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(4), T.int64(2), T.int64(4), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(14), T.int64(7), T.int64(1)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(8), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused_fused // T.int64(2) * T.int64(2) + oc_chunk_1 + oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(56), oh_1 * T.int64(28) + oh_2 * T.int64(14) + oh_3)
                            v_ow = T.axis.spatial(T.int64(56), ow_1 * T.int64(28) + ow_2 * T.int64(7) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused_fused % T.int64(2) * T.int64(16) + oc_block_1 * T.int64(2) + oc_block_2 + oc_block_3)
                            v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(4) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)], p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)] * p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(2), T.int64(56), T.int64(56)):
                for ax4_fused in T.vectorized(T.int64(16)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(8), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused_fused // T.int64(2) * T.int64(2) + ax1)
                        v_ax2, v_ax3 = T.axis.remap("SS", [ax2, ax3])
                        v_ax4 = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused_fused % T.int64(2) * T.int64(16) + ax4_fused)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[4, 2, 1, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 2, 2, 14])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 2, 4, 7])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[2, 8, 2, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[64, 4])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=7)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83 = sch.get_loops(block=b68)
l84 = sch.fuse(l71, l72, l73, l74, l75, preserve_unit_iters=True)
sch.parallel(loop=l84)
l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106 = sch.get_loops(block=b69)
l107 = sch.fuse(l85, preserve_unit_iters=True)
sch.parallel(loop=l107)
l108, l109, l110, l111, l112, l113 = sch.get_loops(block=b70)
l114 = sch.fuse(l108, preserve_unit_iters=True)
sch.parallel(loop=l114)
l115 = sch.fuse(l113, preserve_unit_iters=True)
sch.vectorize(loop=l115)
b116 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138 = sch.get_loops(block=b116)
b139 = sch.decompose_reduction(block=b116, loop=l123)
2024-04-30 10:16:31 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-30 10:16:32 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-30 10:16:36 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 10:16:36 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-30 10:16:50 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 10:17:03 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 10:17:17 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 10:17:30 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 10:17:38 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9205  0.9168  0.9136  0.9049  0.9049  0.9049  0.9038  0.9030  0.8966  0.8966  0.8864  0.8850  0.8807  0.8776  0.8714  0.8702
[17 : 32]:	0.8696  0.8692  0.8646  0.8642  0.8611  0.8582  0.8562  0.8539  0.8491  0.8491  0.8420  0.8416  0.8408  0.8379  0.8379  0.8350
[33 : 48]:	0.8344  0.8194  0.8139  0.8133  0.8110  0.8093  0.8072  0.8061  0.7620  0.7599  0.7537  0.7534  0.7487  0.7487  0.7478  0.7455
[49 : 64]:	0.7440  0.7424  0.7414  0.7374  0.7369  0.7360  0.7360  0.7360  0.7351  0.7320  0.7320  0.7317  0.7287  0.7287  0.7273  0.7265
2024-04-30 10:17:39 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-30 10:17:39 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-30 10:19:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #897: GFLOPs: 1396.0628. Time: 2651.0138 us. Best GFLOPs: 1451.0855
2024-04-30 10:19:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #898: GFLOPs: 1344.4549. Time: 2752.7750 us. Best GFLOPs: 1451.0855
2024-04-30 10:19:31 [INFO] [task_scheduler.cc:121] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #899: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(56), T.int64(56), T.int64(256)), "float32"), p1: T.Buffer((T.int64(8), T.int64(1), T.int64(3), T.int64(3), T.int64(256), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(58), T.int64(58), T.int64(256)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused in T.parallel(T.int64(224), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(16), T.int64(3), T.int64(256)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(112) * T.int64(28) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(56) // T.int64(28) * T.int64(14) + ax2)
                    v_i3 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(112) // T.int64(56) * T.int64(28) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(28) + ax3)
                    v_i4 = T.axis.spatial(T.int64(256), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(57) and T.int64(1) <= v_i3 and v_i3 < T.int64(57), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oc_block_1 in range(T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(14), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(8), oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(112) * T.int64(28) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(56) // T.int64(28) * T.int64(14) + oh_2_init * T.int64(14) + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(112) // T.int64(56) * T.int64(28) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(28) + ow_2_init + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(128), T.int64(1), T.int64(3), T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(32), T.int64(2), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(14), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(8), oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(112) * T.int64(28) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(56) // T.int64(28) * T.int64(14) + oh_2 * T.int64(14) + oh_3)
                        v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(112) // T.int64(56) * T.int64(28) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(28) + ow_2 + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(2) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)], p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)] * p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block]
                for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(8), T.int64(14)):
                    for ax3_ax4_fused in T.vectorized(T.int64(32)):
                        with T.block("T_relu"):
                            v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                            v_ax2 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(112) * T.int64(28) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(56) // T.int64(28) * T.int64(14) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(112) // T.int64(56) * T.int64(28) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(28))
                            v_ax4 = T.axis.spatial(T.int64(32), ax3_ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 8, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 2, 1, 14])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[2, 28, 1, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 32, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[128, 2])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=8)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=8)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b68)
l85 = sch.fuse(l71, l72, l73, l74, l75, l76, l77, l78, l79, preserve_unit_iters=True)
sch.parallel(loop=l85)
l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l86, preserve_unit_iters=True)
sch.parallel(loop=l104)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109, l110, l111 = sch.get_loops(block=b70)
l112 = sch.fuse(l110, l111, preserve_unit_iters=True)
sch.vectorize(loop=l112)
b113 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131 = sch.get_loops(block=b113)
b132 = sch.decompose_reduction(block=b113, loop=l116)
2024-04-30 10:19:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #900: GFLOPs: 1286.8408. Time: 2876.0215 us. Best GFLOPs: 1451.0855
2024-04-30 10:19:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #901: GFLOPs: 1379.0707. Time: 2683.6781 us. Best GFLOPs: 1451.0855
2024-04-30 10:19:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #902: GFLOPs: 1479.3654. Time: 2501.7361 us. Best GFLOPs: 1479.3654
2024-04-30 10:19:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #903: GFLOPs: 1308.8686. Time: 2827.6189 us. Best GFLOPs: 1479.3654
2024-04-30 10:19:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #904: GFLOPs: 1292.6272. Time: 2863.1470 us. Best GFLOPs: 1479.3654
2024-04-30 10:19:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #905: GFLOPs: 1349.3848. Time: 2742.7178 us. Best GFLOPs: 1479.3654
2024-04-30 10:19:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #906: GFLOPs: 1265.5444. Time: 2924.4186 us. Best GFLOPs: 1479.3654
2024-04-30 10:19:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #907: GFLOPs: 1274.5661. Time: 2903.7189 us. Best GFLOPs: 1479.3654
2024-04-30 10:19:31 [INFO] [task_scheduler.cc:121] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #908: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(56), T.int64(56), T.int64(256)), "float32"), p1: T.Buffer((T.int64(8), T.int64(1), T.int64(3), T.int64(3), T.int64(256), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(58), T.int64(58), T.int64(256)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused in T.parallel(T.int64(448), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(16), T.int64(3), T.int64(256)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(112) * T.int64(14) + ax2)
                    v_i3 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(2) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(112) // T.int64(4) * T.int64(2) + ax3)
                    v_i4 = T.axis.spatial(T.int64(256), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(57) and T.int64(1) <= v_i3 and v_i3 < T.int64(57), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oc_block_1 in range(T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(14), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(8), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(4) // T.int64(2) * T.int64(4) + oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(112) * T.int64(14) + oh_2_init * T.int64(14) + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(112) // T.int64(4) * T.int64(2) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(2) + ow_2_init + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(128), T.int64(1), T.int64(3), T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(32), T.int64(2), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(14), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(8), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(4) // T.int64(2) * T.int64(4) + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(112) * T.int64(14) + oh_2 * T.int64(14) + oh_3)
                        v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(112) // T.int64(4) * T.int64(2) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(2) + ow_2 + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(2) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)], p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)] * p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block]
                for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(4), T.int64(14)):
                    for ax3_ax4_fused in T.vectorized(T.int64(32)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(8), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(4) // T.int64(2) * T.int64(4) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(112) * T.int64(14) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(112) // T.int64(4) * T.int64(2) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(2))
                            v_ax4 = T.axis.spatial(T.int64(32), ax3_ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 2, 4, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[4, 1, 1, 14])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[28, 2, 1, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 32, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[128, 2])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=8)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b68)
l85 = sch.fuse(l71, l72, l73, l74, l75, l76, l77, l78, l79, preserve_unit_iters=True)
sch.parallel(loop=l85)
l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l86, preserve_unit_iters=True)
sch.parallel(loop=l104)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109, l110, l111 = sch.get_loops(block=b70)
l112 = sch.fuse(l110, l111, preserve_unit_iters=True)
sch.vectorize(loop=l112)
b113 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131 = sch.get_loops(block=b113)
b132 = sch.decompose_reduction(block=b113, loop=l116)
2024-04-30 10:19:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #909: GFLOPs: 1253.6226. Time: 2952.2296 us. Best GFLOPs: 1479.3654
2024-04-30 10:19:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #910: GFLOPs: 1231.2690. Time: 3005.8272 us. Best GFLOPs: 1479.3654
2024-04-30 10:19:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #911: GFLOPs: 1262.3773. Time: 2931.7556 us. Best GFLOPs: 1479.3654
2024-04-30 10:19:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #912: GFLOPs: 1234.1474. Time: 2998.8166 us. Best GFLOPs: 1479.3654
2024-04-30 10:19:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #913: GFLOPs: 1320.4314. Time: 2802.8580 us. Best GFLOPs: 1479.3654
2024-04-30 10:19:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #914: GFLOPs: 1235.5683. Time: 2995.3681 us. Best GFLOPs: 1479.3654
2024-04-30 10:19:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #915: GFLOPs: 1247.3772. Time: 2967.0108 us. Best GFLOPs: 1479.3654
2024-04-30 10:19:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #916: GFLOPs: 1259.6838. Time: 2938.0245 us. Best GFLOPs: 1479.3654
2024-04-30 10:19:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #917: GFLOPs: 1224.5468. Time: 3022.3276 us. Best GFLOPs: 1479.3654
2024-04-30 10:19:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #918: GFLOPs: 1272.9125. Time: 2907.4912 us. Best GFLOPs: 1479.3654
2024-04-30 10:19:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #919: GFLOPs: 700.2966. Time: 5284.8774 us. Best GFLOPs: 1479.3654
2024-04-30 10:19:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #920: GFLOPs: 1255.5775. Time: 2947.6331 us. Best GFLOPs: 1479.3654
2024-04-30 10:19:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #921: GFLOPs: 1214.9147. Time: 3046.2894 us. Best GFLOPs: 1479.3654
2024-04-30 10:19:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #922: GFLOPs: 1195.6291. Time: 3095.4263 us. Best GFLOPs: 1479.3654
2024-04-30 10:19:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #923: GFLOPs: 1256.7973. Time: 2944.7722 us. Best GFLOPs: 1479.3654
2024-04-30 10:19:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #924: GFLOPs: 652.0120. Time: 5676.2483 us. Best GFLOPs: 1479.3654
2024-04-30 10:19:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #925: GFLOPs: 1203.8857. Time: 3074.1969 us. Best GFLOPs: 1479.3654
2024-04-30 10:19:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #926: GFLOPs: 1196.4696. Time: 3093.2518 us. Best GFLOPs: 1479.3654
2024-04-30 10:19:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #927: GFLOPs: 1182.0275. Time: 3131.0455 us. Best GFLOPs: 1479.3654
2024-04-30 10:19:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #928: GFLOPs: 1181.3565. Time: 3132.8239 us. Best GFLOPs: 1479.3654
2024-04-30 10:19:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #929: GFLOPs: 1195.5580. Time: 3095.6103 us. Best GFLOPs: 1479.3654
2024-04-30 10:19:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #930: GFLOPs: 1222.8982. Time: 3026.4021 us. Best GFLOPs: 1479.3654
2024-04-30 10:19:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #931: GFLOPs: 1084.1733. Time: 3413.6441 us. Best GFLOPs: 1479.3654
2024-04-30 10:19:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #932: GFLOPs: 1185.8804. Time: 3120.8728 us. Best GFLOPs: 1479.3654
2024-04-30 10:19:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #933: GFLOPs: 1172.2437. Time: 3157.1778 us. Best GFLOPs: 1479.3654
2024-04-30 10:19:31 [INFO] [task_scheduler.cc:121] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #934: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(56), T.int64(56), T.int64(256)), "float32"), p1: T.Buffer((T.int64(8), T.int64(1), T.int64(3), T.int64(3), T.int64(256), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(58), T.int64(58), T.int64(256)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused in T.parallel(T.int64(224), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(16), T.int64(3), T.int64(256)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(56) * T.int64(14) + ax2)
                    v_i3 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(56) + ax3)
                    v_i4 = T.axis.spatial(T.int64(256), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(57) and T.int64(1) <= v_i3 and v_i3 < T.int64(57), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oc_block_1 in range(T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(8), T.int64(2), T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(8), oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(56) * T.int64(14) + oh_2_init * T.int64(7) + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(56) + ow_2_init + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(256), T.int64(1), T.int64(3), T.int64(1), T.int64(8), T.int64(2), T.int64(1), T.int64(32), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(8), oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(56) * T.int64(14) + oh_2 * T.int64(7) + oh_3)
                        v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(56) + ow_2 + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(256), ic_0 + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)], p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)] * p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block]
                for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(8), T.int64(14)):
                    for ax3_ax4_fused in T.vectorized(T.int64(32)):
                        with T.block("T_relu"):
                            v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                            v_ax2 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(56) * T.int64(14) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(56))
                            v_ax4 = T.axis.spatial(T.int64(32), ax3_ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 8, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 4, 2, 7])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 56, 1, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 32, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[256, 1])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=8)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b68)
l85 = sch.fuse(l71, l72, l73, l74, l75, l76, l77, l78, l79, preserve_unit_iters=True)
sch.parallel(loop=l85)
l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l86, preserve_unit_iters=True)
sch.parallel(loop=l104)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109, l110, l111 = sch.get_loops(block=b70)
l112 = sch.fuse(l110, l111, preserve_unit_iters=True)
sch.vectorize(loop=l112)
b113 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131 = sch.get_loops(block=b113)
b132 = sch.decompose_reduction(block=b113, loop=l116)
2024-04-30 10:19:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #935: GFLOPs: 937.5290. Time: 3947.5918 us. Best GFLOPs: 1479.3654
2024-04-30 10:19:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #936: GFLOPs: 930.8989. Time: 3975.7077 us. Best GFLOPs: 1479.3654
2024-04-30 10:19:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #937: GFLOPs: 1019.5451. Time: 3630.0325 us. Best GFLOPs: 1479.3654
2024-04-30 10:19:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #938: GFLOPs: 1046.8624. Time: 3535.3088 us. Best GFLOPs: 1479.3654
2024-04-30 10:19:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #939: GFLOPs: 909.7666. Time: 4068.0564 us. Best GFLOPs: 1479.3654
2024-04-30 10:19:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #940: GFLOPs: 1107.2674. Time: 3342.4462 us. Best GFLOPs: 1479.3654
2024-04-30 10:19:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #941: GFLOPs: 1063.8909. Time: 3478.7230 us. Best GFLOPs: 1479.3654
2024-04-30 10:19:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #942: GFLOPs: 1076.9159. Time: 3436.6488 us. Best GFLOPs: 1479.3654
2024-04-30 10:19:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #943: GFLOPs: 1051.0183. Time: 3521.3296 us. Best GFLOPs: 1479.3654
2024-04-30 10:19:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #944: GFLOPs: 921.3757. Time: 4016.8000 us. Best GFLOPs: 1479.3654
2024-04-30 10:19:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #945: GFLOPs: 1067.5900. Time: 3466.6697 us. Best GFLOPs: 1479.3654
2024-04-30 10:19:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #946: GFLOPs: 1176.4215. Time: 3145.9657 us. Best GFLOPs: 1479.3654
2024-04-30 10:19:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #947: GFLOPs: 904.0687. Time: 4093.6953 us. Best GFLOPs: 1479.3654
2024-04-30 10:19:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #948: GFLOPs: 1038.6659. Time: 3563.2072 us. Best GFLOPs: 1479.3654
2024-04-30 10:19:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #949: GFLOPs: 1039.3172. Time: 3560.9743 us. Best GFLOPs: 1479.3654
2024-04-30 10:19:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #950: GFLOPs: 1078.8206. Time: 3430.5814 us. Best GFLOPs: 1479.3654
2024-04-30 10:19:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #951: GFLOPs: 1119.2571. Time: 3306.6415 us. Best GFLOPs: 1479.3654
2024-04-30 10:19:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #952: GFLOPs: 1129.3348. Time: 3277.1342 us. Best GFLOPs: 1479.3654
2024-04-30 10:19:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #953: GFLOPs: 1049.9167. Time: 3525.0241 us. Best GFLOPs: 1479.3654
2024-04-30 10:19:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #954: GFLOPs: 1209.6051. Time: 3059.6612 us. Best GFLOPs: 1479.3654
2024-04-30 10:19:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #955: GFLOPs: 1211.6188. Time: 3054.5759 us. Best GFLOPs: 1479.3654
2024-04-30 10:19:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #956: GFLOPs: 1045.8275. Time: 3538.8071 us. Best GFLOPs: 1479.3654
2024-04-30 10:19:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #957: GFLOPs: 1053.5580. Time: 3512.8412 us. Best GFLOPs: 1479.3654
2024-04-30 10:19:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #958: GFLOPs: 221.2035. Time: 16731.1198 us. Best GFLOPs: 1479.3654
2024-04-30 10:19:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #959: GFLOPs: 207.0308. Time: 17876.4830 us. Best GFLOPs: 1479.3654
2024-04-30 10:19:31 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #960: GFLOPs: 3.6434. Time: 1015801.3487 us. Best GFLOPs: 1479.3654
2024-04-30 10:31:53 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-30 10:31:54 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-30 10:31:59 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 10:31:59 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-30 10:32:12 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 10:32:25 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 10:32:39 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 10:32:53 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 10:33:01 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9137  0.9068  0.9004  0.9004  0.9004  0.9004  0.9004  0.8974  0.8894  0.8842  0.8842  0.8842  0.8804  0.8577  0.8577  0.8572
[17 : 32]:	0.8480  0.8479  0.8447  0.8425  0.8400  0.8400  0.8400  0.8389  0.8349  0.8349  0.8320  0.8298  0.8266  0.8266  0.8227  0.8227
[33 : 48]:	0.8221  0.8185  0.8168  0.8128  0.8125  0.8070  0.8044  0.7941  0.7761  0.7761  0.7735  0.7636  0.7532  0.7519  0.7463  0.7460
[49 : 64]:	0.7439  0.7423  0.7401  0.7401  0.7375  0.7360  0.7360  0.7332  0.7282  0.7248  0.7242  0.7229  0.7229  0.7209  0.7209  0.7205
2024-04-30 10:33:01 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-30 10:33:01 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-30 10:35:30 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #961: GFLOPs: 759.5773. Time: 4872.4230 us. Best GFLOPs: 1479.3654
2024-04-30 10:35:30 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #962: GFLOPs: 1216.1352. Time: 3043.2321 us. Best GFLOPs: 1479.3654
2024-04-30 10:35:30 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #963: GFLOPs: 1422.1953. Time: 2602.3020 us. Best GFLOPs: 1479.3654
2024-04-30 10:35:30 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #964: GFLOPs: 1240.3446. Time: 2983.8334 us. Best GFLOPs: 1479.3654
2024-04-30 10:35:30 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #965: GFLOPs: 1391.9500. Time: 2658.8468 us. Best GFLOPs: 1479.3654
2024-04-30 10:35:30 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #966: GFLOPs: 1285.3792. Time: 2879.2919 us. Best GFLOPs: 1479.3654
2024-04-30 10:35:30 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #967: GFLOPs: 1392.0722. Time: 2658.6134 us. Best GFLOPs: 1479.3654
2024-04-30 10:35:30 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #968: GFLOPs: 1206.9572. Time: 3066.3737 us. Best GFLOPs: 1479.3654
2024-04-30 10:35:30 [INFO] [task_scheduler.cc:121] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #969: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(56), T.int64(56), T.int64(256)), "float32"), p1: T.Buffer((T.int64(8), T.int64(1), T.int64(3), T.int64(3), T.int64(256), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(58), T.int64(58), T.int64(256)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_fused_fused in T.parallel(T.int64(224), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(16), T.int64(3), T.int64(256)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(56) * T.int64(14) + ax2)
                    v_i3 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(56) + ax3)
                    v_i4 = T.axis.spatial(T.int64(256), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(57) and T.int64(1) <= v_i3 and v_i3 < T.int64(57), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oc_block_0, n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(14), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(8), oc_chunk_1 * T.int64(8) + oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(56) * T.int64(14) + oh_1 * T.int64(14) + oh_2_init * T.int64(14) + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(56) + ow_1 + ow_2_init + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_0 * T.int64(32) + oc_block_1 * T.int64(32) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(128), T.int64(1), T.int64(3), T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(32), T.int64(2), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(14), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(8), oc_chunk_1 * T.int64(8) + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(56) * T.int64(14) + oh_1 * T.int64(14) + oh_2 * T.int64(14) + oh_3)
                        v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(56) + ow_1 + ow_2 + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_0 * T.int64(32) + oc_block_1 * T.int64(32) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(2) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)], p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)] * p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block]
                for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(8), T.int64(14)):
                    for ax3_ax4_fused in T.vectorized(T.int64(32)):
                        with T.block("T_relu"):
                            v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                            v_ax2 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(56) * T.int64(14) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(56))
                            v_ax4 = T.axis.spatial(T.int64(32), ax3_ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 8, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[4, 1, 1, 14])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[56, 1, 1, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 32, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[128, 2])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=112)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=3)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79 = sch.get_loops(block=b68)
l80 = sch.fuse(l71, l72, l73, l74, preserve_unit_iters=True)
sch.parallel(loop=l80)
l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l81, preserve_unit_iters=True)
sch.parallel(loop=l104)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109, l110, l111, l112, l113, l114, l115, l116 = sch.get_loops(block=b70)
l117 = sch.fuse(l115, l116, preserve_unit_iters=True)
sch.vectorize(loop=l117)
b118 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141 = sch.get_loops(block=b118)
b142 = sch.decompose_reduction(block=b118, loop=l126)
2024-04-30 10:35:30 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #970: GFLOPs: 1346.0602. Time: 2749.4919 us. Best GFLOPs: 1479.3654
2024-04-30 10:35:30 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #971: GFLOPs: 1265.1143. Time: 2925.4130 us. Best GFLOPs: 1479.3654
2024-04-30 10:35:30 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #972: GFLOPs: 1438.8015. Time: 2572.2671 us. Best GFLOPs: 1479.3654
2024-04-30 10:35:30 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #973: GFLOPs: 1276.8280. Time: 2898.5751 us. Best GFLOPs: 1479.3654
2024-04-30 10:35:30 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #974: GFLOPs: 1330.5830. Time: 2781.4737 us. Best GFLOPs: 1479.3654
2024-04-30 10:35:30 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #975: GFLOPs: 1201.2660. Time: 3080.9012 us. Best GFLOPs: 1479.3654
2024-04-30 10:35:30 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #976: GFLOPs: 1354.9497. Time: 2731.4533 us. Best GFLOPs: 1479.3654
2024-04-30 10:35:30 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #977: GFLOPs: 1239.9425. Time: 2984.8011 us. Best GFLOPs: 1479.3654
2024-04-30 10:35:30 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #978: GFLOPs: 1299.3305. Time: 2848.3760 us. Best GFLOPs: 1479.3654
2024-04-30 10:35:30 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #979: GFLOPs: 1040.8818. Time: 3555.6216 us. Best GFLOPs: 1479.3654
2024-04-30 10:35:30 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #980: GFLOPs: 1323.3297. Time: 2796.7193 us. Best GFLOPs: 1479.3654
2024-04-30 10:35:30 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #981: GFLOPs: 1146.7372. Time: 3227.4019 us. Best GFLOPs: 1479.3654
2024-04-30 10:35:30 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #982: GFLOPs: 1379.1422. Time: 2683.5388 us. Best GFLOPs: 1479.3654
2024-04-30 10:35:30 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #983: GFLOPs: 1194.2837. Time: 3098.9135 us. Best GFLOPs: 1479.3654
2024-04-30 10:35:30 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #984: GFLOPs: 1355.9670. Time: 2729.4040 us. Best GFLOPs: 1479.3654
2024-04-30 10:35:30 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #985: GFLOPs: 1243.8132. Time: 2975.5124 us. Best GFLOPs: 1479.3654
2024-04-30 10:35:30 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #986: GFLOPs: 1283.3952. Time: 2883.7428 us. Best GFLOPs: 1479.3654
2024-04-30 10:35:30 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #987: GFLOPs: 1142.6558. Time: 3238.9296 us. Best GFLOPs: 1479.3654
2024-04-30 10:35:30 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #988: GFLOPs: 1285.4172. Time: 2879.2067 us. Best GFLOPs: 1479.3654
2024-04-30 10:35:30 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #989: GFLOPs: 1047.0748. Time: 3534.5916 us. Best GFLOPs: 1479.3654
2024-04-30 10:35:30 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #990: GFLOPs: 1368.9566. Time: 2703.5055 us. Best GFLOPs: 1479.3654
2024-04-30 10:35:30 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #991: GFLOPs: 1203.2504. Time: 3075.8202 us. Best GFLOPs: 1479.3654
2024-04-30 10:35:30 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #992: GFLOPs: 1288.0911. Time: 2873.2298 us. Best GFLOPs: 1479.3654
2024-04-30 10:35:30 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #993: GFLOPs: 1208.3451. Time: 3062.8515 us. Best GFLOPs: 1479.3654
2024-04-30 10:35:30 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #994: GFLOPs: 985.0293. Time: 3757.2301 us. Best GFLOPs: 1479.3654
2024-04-30 10:35:30 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #995: GFLOPs: 1206.2521. Time: 3068.1662 us. Best GFLOPs: 1479.3654
2024-04-30 10:35:30 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #996: GFLOPs: 1255.4978. Time: 2947.8202 us. Best GFLOPs: 1479.3654
2024-04-30 10:35:30 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #997: GFLOPs: 1118.3511. Time: 3309.3202 us. Best GFLOPs: 1479.3654
2024-04-30 10:35:30 [INFO] [task_scheduler.cc:121] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #998: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(56), T.int64(56), T.int64(256)), "float32"), p1: T.Buffer((T.int64(8), T.int64(1), T.int64(3), T.int64(3), T.int64(256), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(58), T.int64(58), T.int64(256)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused in T.parallel(T.int64(224), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(16), T.int64(3), T.int64(256)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(56) // T.int64(14) * T.int64(14) + ax2)
                    v_i3 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(56) * T.int64(14) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(14) + ax3)
                    v_i4 = T.axis.spatial(T.int64(256), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(57) and T.int64(1) <= v_i3 and v_i3 < T.int64(57), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oc_block_1 in range(T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(8), T.int64(2), T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(8), oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(56) // T.int64(14) * T.int64(14) + oh_2_init * T.int64(7) + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(56) * T.int64(14) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(14) + ow_2_init + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(128), T.int64(1), T.int64(3), T.int64(1), T.int64(8), T.int64(2), T.int64(1), T.int64(32), T.int64(2), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(8), oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(56) // T.int64(14) * T.int64(14) + oh_2 * T.int64(7) + oh_3)
                        v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(56) * T.int64(14) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(14) + ow_2 + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(2) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)], p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)] * p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block]
                for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(8), T.int64(14)):
                    for ax3_ax4_fused in T.vectorized(T.int64(32)):
                        with T.block("T_relu"):
                            v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                            v_ax2 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(56) // T.int64(14) * T.int64(14) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(56) * T.int64(14) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(14))
                            v_ax4 = T.axis.spatial(T.int64(32), ax3_ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 8, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 4, 2, 7])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[4, 14, 1, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 32, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[128, 2])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=8)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b68)
l85 = sch.fuse(l71, l72, l73, l74, l75, l76, l77, l78, l79, preserve_unit_iters=True)
sch.parallel(loop=l85)
l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l86, preserve_unit_iters=True)
sch.parallel(loop=l104)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109, l110, l111 = sch.get_loops(block=b70)
l112 = sch.fuse(l110, l111, preserve_unit_iters=True)
sch.vectorize(loop=l112)
b113 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131 = sch.get_loops(block=b113)
b132 = sch.decompose_reduction(block=b113, loop=l116)
2024-04-30 10:35:30 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #999: GFLOPs: 1257.4693. Time: 2943.1986 us. Best GFLOPs: 1479.3654
2024-04-30 10:35:30 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1000: GFLOPs: 1139.0012. Time: 3249.3222 us. Best GFLOPs: 1479.3654
2024-04-30 10:35:30 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1001: GFLOPs: 1283.9816. Time: 2882.4257 us. Best GFLOPs: 1479.3654
2024-04-30 10:35:30 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1002: GFLOPs: 1212.9496. Time: 3051.2247 us. Best GFLOPs: 1479.3654
2024-04-30 10:35:30 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1003: GFLOPs: 1273.5271. Time: 2906.0880 us. Best GFLOPs: 1479.3654
2024-04-30 10:35:30 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1004: GFLOPs: 1244.9806. Time: 2972.7224 us. Best GFLOPs: 1479.3654
2024-04-30 10:35:30 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1005: GFLOPs: 1280.9485. Time: 2889.2509 us. Best GFLOPs: 1479.3654
2024-04-30 10:35:30 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1006: GFLOPs: 966.5478. Time: 3829.0726 us. Best GFLOPs: 1479.3654
2024-04-30 10:35:30 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1007: GFLOPs: 769.2967. Time: 4810.8642 us. Best GFLOPs: 1479.3654
2024-04-30 10:35:30 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1008: GFLOPs: 1083.3925. Time: 3416.1041 us. Best GFLOPs: 1479.3654
2024-04-30 10:35:30 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1009: GFLOPs: 1244.9760. Time: 2972.7335 us. Best GFLOPs: 1479.3654
2024-04-30 10:35:30 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1010: GFLOPs: 952.4370. Time: 3885.8023 us. Best GFLOPs: 1479.3654
2024-04-30 10:35:30 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1011: GFLOPs: 1202.0380. Time: 3078.9224 us. Best GFLOPs: 1479.3654
2024-04-30 10:35:30 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1012: GFLOPs: 1124.1569. Time: 3292.2289 us. Best GFLOPs: 1479.3654
2024-04-30 10:35:30 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1013: GFLOPs: 1275.6417. Time: 2901.2705 us. Best GFLOPs: 1479.3654
2024-04-30 10:35:30 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1014: GFLOPs: 1078.1992. Time: 3432.5585 us. Best GFLOPs: 1479.3654
2024-04-30 10:35:30 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1015: GFLOPs: 1053.3743. Time: 3513.4536 us. Best GFLOPs: 1479.3654
2024-04-30 10:35:30 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1016: GFLOPs: 1030.3303. Time: 3592.0343 us. Best GFLOPs: 1479.3654
2024-04-30 10:35:30 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1017: GFLOPs: 904.2701. Time: 4092.7837 us. Best GFLOPs: 1479.3654
2024-04-30 10:35:30 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1018: GFLOPs: 1100.7357. Time: 3362.2802 us. Best GFLOPs: 1479.3654
2024-04-30 10:35:30 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1019: GFLOPs: 1023.4461. Time: 3616.1962 us. Best GFLOPs: 1479.3654
2024-04-30 10:35:30 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1020: GFLOPs: 1095.5925. Time: 3378.0642 us. Best GFLOPs: 1479.3654
2024-04-30 10:35:30 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1021: GFLOPs: 1051.3651. Time: 3520.1679 us. Best GFLOPs: 1479.3654
2024-04-30 10:35:30 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1022: GFLOPs: 28.3183. Time: 130692.2733 us. Best GFLOPs: 1479.3654
2024-04-30 10:35:30 [INFO] [task_scheduler.cc:121] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1023: Error in running:
LocalRunner: Timeout, killed after 30 seconds

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(56), T.int64(56), T.int64(256)), "float32"), p1: T.Buffer((T.int64(8), T.int64(1), T.int64(3), T.int64(3), T.int64(256), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(58), T.int64(58), T.int64(256)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)))
        for n_0_oc_chunk_0_fused_fused in T.parallel(T.int64(2), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(58), T.int64(58), T.int64(256)):
                with T.block("data_pad"):
                    v_i0, v_i1, v_i2, v_i3, v_i4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(57) and T.int64(1) <= v_i3 and v_i3 < T.int64(57), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oh_0, ow_0, oc_block_0 in T.grid(T.int64(1), T.int64(14), T.int64(2)):
                for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(7), T.int64(2), T.int64(1)):
                    for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(1), T.int64(8), T.int64(2), T.int64(4), T.int64(1), T.int64(4), T.int64(1), T.int64(1)):
                        for oc_block_3_fused_init in T.vectorized(T.int64(4)):
                            with T.block("conv2d_NCHWc_init"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                                v_oc_chunk = T.axis.spatial(T.int64(8), n_0_oc_chunk_0_fused_fused * T.int64(4) + oc_chunk_1 * T.int64(4) + oc_chunk_2_init * T.int64(4) + oc_chunk_3_init)
                                v_oh = T.axis.spatial(T.int64(56), oh_0 * T.int64(56) + oh_1 * T.int64(8) + oh_2_init + oh_3_init)
                                v_ow = T.axis.spatial(T.int64(56), ow_0 * T.int64(4) + ow_1 * T.int64(2) + ow_2_init + ow_3_init)
                                v_oc_block = T.axis.spatial(T.int64(32), oc_block_0 * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2_init * T.int64(4) + oc_block_3_fused_init)
                                T.reads()
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                    for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(8), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(8), T.int64(2), T.int64(4), T.int64(32), T.int64(3), T.int64(3), T.int64(1), T.int64(4), T.int64(1), T.int64(1)):
                        for oc_block_3_fused in T.vectorized(T.int64(4)):
                            with T.block("conv2d_NCHWc_update"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                                v_oc_chunk = T.axis.spatial(T.int64(8), n_0_oc_chunk_0_fused_fused * T.int64(4) + oc_chunk_1 * T.int64(4) + oc_chunk_2 * T.int64(4) + oc_chunk_3)
                                v_oh = T.axis.spatial(T.int64(56), oh_0 * T.int64(56) + oh_1 * T.int64(8) + oh_2 + oh_3)
                                v_ow = T.axis.spatial(T.int64(56), ow_0 * T.int64(4) + ow_1 * T.int64(2) + ow_2 + ow_3)
                                v_oc_block = T.axis.spatial(T.int64(32), oc_block_0 * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2 * T.int64(4) + oc_block_3_fused)
                                v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(32) + ic_1)
                                v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                                v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                                T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)], p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block])
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)] * p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(4), T.int64(56), T.int64(4)):
                    for ax4_fused in T.vectorized(T.int64(16)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(8), n_0_oc_chunk_0_fused_fused * T.int64(4) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(56), ax2)
                            v_ax3 = T.axis.spatial(T.int64(56), ow_0 * T.int64(4) + ax3)
                            v_ax4 = T.axis.spatial(T.int64(32), oc_block_0 * T.int64(16) + ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[2, 1, 1, 4])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 7, 8, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[14, 2, 2, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[2, 1, 4, 4])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[8, 32])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=1)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77 = sch.get_loops(block=b68)
l78 = sch.fuse(l71, l72, preserve_unit_iters=True)
sch.parallel(loop=l78)
l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l79, preserve_unit_iters=True)
sch.parallel(loop=l104)
l105 = sch.fuse(l103, preserve_unit_iters=True)
sch.vectorize(loop=l105)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l106, l107, l108, l109, l110, l111, l112, l113, l114 = sch.get_loops(block=b70)
l115 = sch.fuse(l114, preserve_unit_iters=True)
sch.vectorize(loop=l115)
b116 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141 = sch.get_loops(block=b116)
b142 = sch.decompose_reduction(block=b116, loop=l126)
2024-04-30 10:35:30 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1024: GFLOPs: 3.0828. Time: 1200522.3150 us. Best GFLOPs: 1479.3654
2024-04-30 11:07:19 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-30 11:07:20 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-30 11:07:25 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 11:07:25 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-30 11:07:38 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 11:07:52 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 11:08:05 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 11:08:19 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 11:08:27 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.8992  0.8986  0.8901  0.8843  0.8771  0.8646  0.8639  0.8621  0.8605  0.8531  0.8529  0.8512  0.8512  0.8512  0.8483  0.8452
[17 : 32]:	0.8433  0.8427  0.8404  0.8340  0.8285  0.8278  0.8232  0.8226  0.8225  0.8225  0.8225  0.8219  0.8219  0.8188  0.8184  0.8134
[33 : 48]:	0.8038  0.7899  0.7842  0.7799  0.7773  0.7773  0.7648  0.7626  0.7609  0.7592  0.7586  0.7586  0.7586  0.7447  0.7379  0.7346
[49 : 64]:	0.7338  0.7338  0.7338  0.7274  0.7268  0.7263  0.7257  0.7244  0.7244  0.7238  0.7223  0.7189  0.7174  0.7170  0.7152  0.7149
2024-04-30 11:08:27 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-30 11:08:27 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-30 11:10:35 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1025: GFLOPs: 718.4946. Time: 5151.0225 us. Best GFLOPs: 1479.3654
2024-04-30 11:10:35 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1026: GFLOPs: 1394.9802. Time: 2653.0711 us. Best GFLOPs: 1479.3654
2024-04-30 11:10:35 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1027: GFLOPs: 1315.0217. Time: 2814.3884 us. Best GFLOPs: 1479.3654
2024-04-30 11:10:35 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1028: GFLOPs: 1349.2127. Time: 2743.0677 us. Best GFLOPs: 1479.3654
2024-04-30 11:10:35 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1029: GFLOPs: 1385.3101. Time: 2671.5909 us. Best GFLOPs: 1479.3654
2024-04-30 11:10:35 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1030: GFLOPs: 1272.3470. Time: 2908.7834 us. Best GFLOPs: 1479.3654
2024-04-30 11:10:35 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1031: GFLOPs: 1213.1356. Time: 3050.7570 us. Best GFLOPs: 1479.3654
2024-04-30 11:10:35 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1032: GFLOPs: 1352.3687. Time: 2736.6662 us. Best GFLOPs: 1479.3654
2024-04-30 11:10:35 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1033: GFLOPs: 1322.8677. Time: 2797.6961 us. Best GFLOPs: 1479.3654
2024-04-30 11:10:35 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1034: GFLOPs: 1264.2036. Time: 2927.5203 us. Best GFLOPs: 1479.3654
2024-04-30 11:10:35 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1035: GFLOPs: 1341.5180. Time: 2758.8015 us. Best GFLOPs: 1479.3654
2024-04-30 11:10:35 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1036: GFLOPs: 1231.1125. Time: 3006.2093 us. Best GFLOPs: 1479.3654
2024-04-30 11:10:35 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1037: GFLOPs: 1226.3973. Time: 3017.7675 us. Best GFLOPs: 1479.3654
2024-04-30 11:10:35 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1038: GFLOPs: 1301.1776. Time: 2844.3325 us. Best GFLOPs: 1479.3654
2024-04-30 11:10:35 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1039: GFLOPs: 1206.4547. Time: 3067.6509 us. Best GFLOPs: 1479.3654
2024-04-30 11:10:35 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1040: GFLOPs: 1255.6803. Time: 2947.3917 us. Best GFLOPs: 1479.3654
2024-04-30 11:10:35 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1041: GFLOPs: 1346.5733. Time: 2748.4443 us. Best GFLOPs: 1479.3654
2024-04-30 11:10:35 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1042: GFLOPs: 1244.6350. Time: 2973.5479 us. Best GFLOPs: 1479.3654
2024-04-30 11:10:35 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1043: GFLOPs: 1218.1482. Time: 3038.2031 us. Best GFLOPs: 1479.3654
2024-04-30 11:10:35 [INFO] [task_scheduler.cc:121] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1044: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(56), T.int64(56), T.int64(256)), "float32"), p1: T.Buffer((T.int64(8), T.int64(1), T.int64(3), T.int64(3), T.int64(256), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(58), T.int64(58), T.int64(256)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused in T.parallel(T.int64(448), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(16), T.int64(3), T.int64(256)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(224) // T.int64(112) * T.int64(28) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(4) // T.int64(2) * T.int64(14) + ax2)
                    v_i3 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(2) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(112) // T.int64(4) * T.int64(2) + ax3)
                    v_i4 = T.axis.spatial(T.int64(256), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(57) and T.int64(1) <= v_i3 and v_i3 < T.int64(57), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oc_block_1 in range(T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(14), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(8), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(224) * T.int64(4) + oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(224) // T.int64(112) * T.int64(28) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(4) // T.int64(2) * T.int64(14) + oh_2_init * T.int64(14) + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(112) // T.int64(4) * T.int64(2) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(2) + ow_2_init + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(128), T.int64(1), T.int64(3), T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(32), T.int64(2), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(14), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(8), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(224) * T.int64(4) + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(224) // T.int64(112) * T.int64(28) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(4) // T.int64(2) * T.int64(14) + oh_2 * T.int64(14) + oh_3)
                        v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(112) // T.int64(4) * T.int64(2) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(2) + ow_2 + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(2) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)], p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)] * p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block]
                for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(4), T.int64(14)):
                    for ax3_ax4_fused in T.vectorized(T.int64(32)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(8), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(224) * T.int64(4) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(224) // T.int64(112) * T.int64(28) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(4) // T.int64(2) * T.int64(14) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(112) // T.int64(4) * T.int64(2) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(2))
                            v_ax4 = T.axis.spatial(T.int64(32), ax3_ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[2, 1, 4, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 2, 1, 14])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[28, 2, 1, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 32, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[128, 2])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=8)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b68)
l85 = sch.fuse(l71, l72, l73, l74, l75, l76, l77, l78, l79, preserve_unit_iters=True)
sch.parallel(loop=l85)
l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l86, preserve_unit_iters=True)
sch.parallel(loop=l104)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109, l110, l111 = sch.get_loops(block=b70)
l112 = sch.fuse(l110, l111, preserve_unit_iters=True)
sch.vectorize(loop=l112)
b113 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131 = sch.get_loops(block=b113)
b132 = sch.decompose_reduction(block=b113, loop=l116)
2024-04-30 11:10:35 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1045: GFLOPs: 1352.9272. Time: 2735.5365 us. Best GFLOPs: 1479.3654
2024-04-30 11:10:35 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1046: GFLOPs: 1215.6351. Time: 3044.4842 us. Best GFLOPs: 1479.3654
2024-04-30 11:10:35 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1047: GFLOPs: 1201.6702. Time: 3079.8648 us. Best GFLOPs: 1479.3654
2024-04-30 11:10:35 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1048: GFLOPs: 1356.6363. Time: 2728.0574 us. Best GFLOPs: 1479.3654
2024-04-30 11:10:35 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1049: GFLOPs: 1204.1614. Time: 3073.4931 us. Best GFLOPs: 1479.3654
2024-04-30 11:10:35 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1050: GFLOPs: 1203.5577. Time: 3075.0347 us. Best GFLOPs: 1479.3654
2024-04-30 11:10:35 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1051: GFLOPs: 1271.2920. Time: 2911.1972 us. Best GFLOPs: 1479.3654
2024-04-30 11:10:35 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1052: GFLOPs: 1204.2237. Time: 3073.3340 us. Best GFLOPs: 1479.3654
2024-04-30 11:10:35 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1053: GFLOPs: 1200.9520. Time: 3081.7066 us. Best GFLOPs: 1479.3654
2024-04-30 11:10:35 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1054: GFLOPs: 1232.2719. Time: 3003.3807 us. Best GFLOPs: 1479.3654
2024-04-30 11:10:35 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1055: GFLOPs: 1210.3395. Time: 3057.8047 us. Best GFLOPs: 1479.3654
2024-04-30 11:10:35 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1056: GFLOPs: 1178.4973. Time: 3140.4246 us. Best GFLOPs: 1479.3654
2024-04-30 11:10:35 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1057: GFLOPs: 914.1681. Time: 4048.4696 us. Best GFLOPs: 1479.3654
2024-04-30 11:10:35 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1058: GFLOPs: 608.3481. Time: 6083.6581 us. Best GFLOPs: 1479.3654
2024-04-30 11:10:35 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1059: GFLOPs: 1196.1004. Time: 3094.2065 us. Best GFLOPs: 1479.3654
2024-04-30 11:10:35 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1060: GFLOPs: 1245.6468. Time: 2971.1326 us. Best GFLOPs: 1479.3654
2024-04-30 11:10:35 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1061: GFLOPs: 1188.4533. Time: 3114.1162 us. Best GFLOPs: 1479.3654
2024-04-30 11:10:35 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1062: GFLOPs: 1197.3661. Time: 3090.9358 us. Best GFLOPs: 1479.3654
2024-04-30 11:10:35 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1063: GFLOPs: 1189.2368. Time: 3112.0647 us. Best GFLOPs: 1479.3654
2024-04-30 11:10:35 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1064: GFLOPs: 1239.8736. Time: 2984.9669 us. Best GFLOPs: 1479.3654
2024-04-30 11:10:35 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1065: GFLOPs: 1112.9345. Time: 3325.4265 us. Best GFLOPs: 1479.3654
2024-04-30 11:10:35 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1066: GFLOPs: 154.8507. Time: 23900.3192 us. Best GFLOPs: 1479.3654
2024-04-30 11:10:35 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1067: GFLOPs: 196.9169. Time: 18794.6365 us. Best GFLOPs: 1479.3654
2024-04-30 11:10:35 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1068: GFLOPs: 196.9769. Time: 18788.9097 us. Best GFLOPs: 1479.3654
2024-04-30 11:10:35 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1069: GFLOPs: 198.0017. Time: 18691.6632 us. Best GFLOPs: 1479.3654
2024-04-30 11:10:35 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1070: GFLOPs: 1057.5519. Time: 3499.5747 us. Best GFLOPs: 1479.3654
2024-04-30 11:10:35 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1071: GFLOPs: 1098.6386. Time: 3368.6982 us. Best GFLOPs: 1479.3654
2024-04-30 11:10:35 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1072: GFLOPs: 1244.9155. Time: 2972.8779 us. Best GFLOPs: 1479.3654
2024-04-30 11:10:35 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1073: GFLOPs: 925.7768. Time: 3997.7041 us. Best GFLOPs: 1479.3654
2024-04-30 11:10:35 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1074: GFLOPs: 925.4218. Time: 3999.2379 us. Best GFLOPs: 1479.3654
2024-04-30 11:10:35 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1075: GFLOPs: 909.1653. Time: 4070.7468 us. Best GFLOPs: 1479.3654
2024-04-30 11:10:35 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1076: GFLOPs: 1117.7151. Time: 3311.2030 us. Best GFLOPs: 1479.3654
2024-04-30 11:10:35 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1077: GFLOPs: 1128.5768. Time: 3279.3354 us. Best GFLOPs: 1479.3654
2024-04-30 11:10:35 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1078: GFLOPs: 1111.4122. Time: 3329.9811 us. Best GFLOPs: 1479.3654
2024-04-30 11:10:35 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1079: GFLOPs: 1038.0468. Time: 3565.3323 us. Best GFLOPs: 1479.3654
2024-04-30 11:10:35 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1080: GFLOPs: 1109.1598. Time: 3336.7435 us. Best GFLOPs: 1479.3654
2024-04-30 11:10:35 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1081: GFLOPs: 566.7184. Time: 6530.5486 us. Best GFLOPs: 1479.3654
2024-04-30 11:10:35 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1082: GFLOPs: 1071.1913. Time: 3455.0149 us. Best GFLOPs: 1479.3654
2024-04-30 11:10:35 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1083: GFLOPs: 1035.4677. Time: 3574.2125 us. Best GFLOPs: 1479.3654
2024-04-30 11:10:35 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1084: GFLOPs: 1063.0111. Time: 3481.6023 us. Best GFLOPs: 1479.3654
2024-04-30 11:10:35 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1085: GFLOPs: 1048.5027. Time: 3529.7779 us. Best GFLOPs: 1479.3654
2024-04-30 11:10:35 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1086: GFLOPs: 24.6130. Time: 150367.0497 us. Best GFLOPs: 1479.3654
2024-04-30 11:10:35 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1087: GFLOPs: 53.6245. Time: 69016.6300 us. Best GFLOPs: 1479.3654
2024-04-30 11:10:35 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1088: GFLOPs: 3.1795. Time: 1163997.2470 us. Best GFLOPs: 1479.3654
2024-04-30 11:26:51 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-30 11:26:52 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-30 11:26:56 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 11:26:56 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-30 11:27:09 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 11:27:23 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 11:27:37 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 11:27:50 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 11:27:58 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9028  0.9028  0.8875  0.8801  0.8782  0.8717  0.8685  0.8685  0.8629  0.8539  0.8525  0.8489  0.8432  0.8430  0.8389  0.8318
[17 : 32]:	0.8304  0.8272  0.8168  0.8085  0.8072  0.8031  0.7939  0.7896  0.7770  0.7690  0.7573  0.7536  0.7535  0.7489  0.7360  0.7344
[33 : 48]:	0.7290  0.7290  0.7265  0.7257  0.7253  0.7249  0.7242  0.7211  0.7192  0.7177  0.7141  0.7138  0.7125  0.7125  0.7015  0.7008
[49 : 64]:	0.6999  0.6986  0.6986  0.6982  0.6980  0.6963  0.6932  0.6932  0.6932  0.6921  0.6921  0.6849  0.6842  0.6815  0.6800  0.6794
2024-04-30 11:27:59 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-30 11:27:59 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-30 11:29:57 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1089: GFLOPs: 1417.3948. Time: 2611.1157 us. Best GFLOPs: 1479.3654
2024-04-30 11:29:57 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1090: GFLOPs: 1294.8794. Time: 2858.1672 us. Best GFLOPs: 1479.3654
2024-04-30 11:29:57 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1091: GFLOPs: 1318.6590. Time: 2806.6252 us. Best GFLOPs: 1479.3654
2024-04-30 11:29:57 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1092: GFLOPs: 1373.2752. Time: 2695.0038 us. Best GFLOPs: 1479.3654
2024-04-30 11:29:57 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1093: GFLOPs: 1308.7628. Time: 2827.8476 us. Best GFLOPs: 1479.3654
2024-04-30 11:29:57 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1094: GFLOPs: 1291.7495. Time: 2865.0924 us. Best GFLOPs: 1479.3654
2024-04-30 11:29:57 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1095: GFLOPs: 1362.4195. Time: 2716.4773 us. Best GFLOPs: 1479.3654
2024-04-30 11:29:57 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1096: GFLOPs: 1255.5934. Time: 2947.5957 us. Best GFLOPs: 1479.3654
2024-04-30 11:29:57 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1097: GFLOPs: 1325.6397. Time: 2791.8458 us. Best GFLOPs: 1479.3654
2024-04-30 11:29:57 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1098: GFLOPs: 1309.6324. Time: 2825.9700 us. Best GFLOPs: 1479.3654
2024-04-30 11:29:57 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1099: GFLOPs: 1232.2636. Time: 3003.4011 us. Best GFLOPs: 1479.3654
2024-04-30 11:29:57 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1100: GFLOPs: 1352.1802. Time: 2737.0477 us. Best GFLOPs: 1479.3654
2024-04-30 11:29:57 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1101: GFLOPs: 1253.9405. Time: 2951.4811 us. Best GFLOPs: 1479.3654
2024-04-30 11:29:57 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1102: GFLOPs: 1260.3185. Time: 2936.5448 us. Best GFLOPs: 1479.3654
2024-04-30 11:29:57 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1103: GFLOPs: 1400.5033. Time: 2642.6084 us. Best GFLOPs: 1479.3654
2024-04-30 11:29:57 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1104: GFLOPs: 932.4249. Time: 3969.2010 us. Best GFLOPs: 1479.3654
2024-04-30 11:29:57 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1105: GFLOPs: 1205.2860. Time: 3070.6253 us. Best GFLOPs: 1479.3654
2024-04-30 11:29:57 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1106: GFLOPs: 1315.2600. Time: 2813.8784 us. Best GFLOPs: 1479.3654
2024-04-30 11:29:57 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1107: GFLOPs: 1204.9324. Time: 3071.5265 us. Best GFLOPs: 1479.3654
2024-04-30 11:29:57 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1108: GFLOPs: 1247.7490. Time: 2966.1269 us. Best GFLOPs: 1479.3654
2024-04-30 11:29:57 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1109: GFLOPs: 1177.4033. Time: 3143.3425 us. Best GFLOPs: 1479.3654
2024-04-30 11:29:57 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1110: GFLOPs: 1219.9747. Time: 3033.6546 us. Best GFLOPs: 1479.3654
2024-04-30 11:29:57 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1111: GFLOPs: 1188.3449. Time: 3114.4003 us. Best GFLOPs: 1479.3654
2024-04-30 11:29:57 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1112: GFLOPs: 1079.1789. Time: 3429.4424 us. Best GFLOPs: 1479.3654
2024-04-30 11:29:57 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1113: GFLOPs: 1246.4207. Time: 2969.2879 us. Best GFLOPs: 1479.3654
2024-04-30 11:29:57 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1114: GFLOPs: 1220.9854. Time: 3031.1434 us. Best GFLOPs: 1479.3654
2024-04-30 11:29:57 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1115: GFLOPs: 1209.0178. Time: 3061.1475 us. Best GFLOPs: 1479.3654
2024-04-30 11:29:57 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1116: GFLOPs: 1055.2403. Time: 3507.2407 us. Best GFLOPs: 1479.3654
2024-04-30 11:29:57 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1117: GFLOPs: 1082.6654. Time: 3418.3985 us. Best GFLOPs: 1479.3654
2024-04-30 11:29:57 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1118: GFLOPs: 823.1374. Time: 4496.1896 us. Best GFLOPs: 1479.3654
2024-04-30 11:29:57 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1119: GFLOPs: 1111.1669. Time: 3330.7164 us. Best GFLOPs: 1479.3654
2024-04-30 11:29:57 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1120: GFLOPs: 1071.0975. Time: 3455.3174 us. Best GFLOPs: 1479.3654
2024-04-30 11:29:57 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1121: GFLOPs: 586.4070. Time: 6311.2848 us. Best GFLOPs: 1479.3654
2024-04-30 11:29:57 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1122: GFLOPs: 1108.3853. Time: 3339.0751 us. Best GFLOPs: 1479.3654
2024-04-30 11:29:57 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1123: GFLOPs: 1084.8017. Time: 3411.6667 us. Best GFLOPs: 1479.3654
2024-04-30 11:29:57 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1124: GFLOPs: 1010.9511. Time: 3660.8909 us. Best GFLOPs: 1479.3654
2024-04-30 11:29:57 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1125: GFLOPs: 977.5571. Time: 3785.9493 us. Best GFLOPs: 1479.3654
2024-04-30 11:29:57 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1126: GFLOPs: 1074.2565. Time: 3445.1566 us. Best GFLOPs: 1479.3654
2024-04-30 11:29:57 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1127: GFLOPs: 1010.5857. Time: 3662.2148 us. Best GFLOPs: 1479.3654
2024-04-30 11:29:57 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1128: GFLOPs: 954.9859. Time: 3875.4309 us. Best GFLOPs: 1479.3654
2024-04-30 11:29:57 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1129: GFLOPs: 849.9462. Time: 4354.3720 us. Best GFLOPs: 1479.3654
2024-04-30 11:29:57 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1130: GFLOPs: 1094.8920. Time: 3380.2255 us. Best GFLOPs: 1479.3654
2024-04-30 11:29:57 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1131: GFLOPs: 1143.7942. Time: 3235.7060 us. Best GFLOPs: 1479.3654
2024-04-30 11:29:57 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1132: GFLOPs: 1086.1475. Time: 3407.4393 us. Best GFLOPs: 1479.3654
2024-04-30 11:29:57 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1133: GFLOPs: 1093.1256. Time: 3385.6876 us. Best GFLOPs: 1479.3654
2024-04-30 11:29:57 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1134: GFLOPs: 1185.5014. Time: 3121.8705 us. Best GFLOPs: 1479.3654
2024-04-30 11:29:57 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1135: GFLOPs: 928.4337. Time: 3986.2640 us. Best GFLOPs: 1479.3654
2024-04-30 11:29:57 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1136: GFLOPs: 989.7885. Time: 3739.1643 us. Best GFLOPs: 1479.3654
2024-04-30 11:29:57 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1137: GFLOPs: 868.8352. Time: 4259.7050 us. Best GFLOPs: 1479.3654
2024-04-30 11:29:57 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1138: GFLOPs: 977.3796. Time: 3786.6370 us. Best GFLOPs: 1479.3654
2024-04-30 11:29:57 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1139: GFLOPs: 1047.7920. Time: 3532.1722 us. Best GFLOPs: 1479.3654
2024-04-30 11:29:57 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1140: GFLOPs: 1178.2454. Time: 3141.0959 us. Best GFLOPs: 1479.3654
2024-04-30 11:29:57 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1141: GFLOPs: 589.8707. Time: 6274.2255 us. Best GFLOPs: 1479.3654
2024-04-30 11:29:57 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1142: GFLOPs: 158.8640. Time: 23296.5352 us. Best GFLOPs: 1479.3654
2024-04-30 11:29:57 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1143: GFLOPs: 1182.9128. Time: 3128.7020 us. Best GFLOPs: 1479.3654
2024-04-30 11:29:57 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1144: GFLOPs: 1062.0597. Time: 3484.7210 us. Best GFLOPs: 1479.3654
2024-04-30 11:29:57 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1145: GFLOPs: 1058.5655. Time: 3496.2236 us. Best GFLOPs: 1479.3654
2024-04-30 11:29:57 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1146: GFLOPs: 1053.4276. Time: 3513.2760 us. Best GFLOPs: 1479.3654
2024-04-30 11:29:57 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1147: GFLOPs: 1054.7817. Time: 3508.7656 us. Best GFLOPs: 1479.3654
2024-04-30 11:29:57 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1148: GFLOPs: 894.3591. Time: 4138.1384 us. Best GFLOPs: 1479.3654
2024-04-30 11:29:57 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1149: GFLOPs: 1039.5211. Time: 3560.2758 us. Best GFLOPs: 1479.3654
2024-04-30 11:29:57 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1150: GFLOPs: 6.6771. Time: 554282.0867 us. Best GFLOPs: 1479.3654
2024-04-30 11:29:57 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1151: GFLOPs: 145.3335. Time: 25465.4407 us. Best GFLOPs: 1479.3654
2024-04-30 11:29:57 [INFO] [task_scheduler.cc:121] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1152: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(56), T.int64(56), T.int64(256)), "float32"), p1: T.Buffer((T.int64(8), T.int64(1), T.int64(3), T.int64(3), T.int64(256), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(58), T.int64(58), T.int64(256)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_fused_fused in T.parallel(T.int64(16), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(16), T.int64(58), T.int64(256)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_fused_fused % T.int64(4) * T.int64(14) + ax2)
                    v_i3, v_i4 = T.axis.remap("SS", [ax3, ax4])
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(57) and T.int64(1) <= v_i3 and v_i3 < T.int64(57), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for ow_0, oc_block_0, n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(2), T.int64(2), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(16), T.int64(1), T.int64(2), T.int64(7), T.int64(14), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(8), n_0_oc_chunk_0_oh_0_fused_fused // T.int64(4) * T.int64(2) + oc_chunk_1 * T.int64(2) + oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_fused_fused % T.int64(4) * T.int64(14) + oh_1 * T.int64(7) + oh_2_init * T.int64(7) + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(56), ow_0 * T.int64(56) + ow_1 * T.int64(28) + ow_2_init * T.int64(14) + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_0 * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(32), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(16), T.int64(8), T.int64(3), T.int64(3), T.int64(1), T.int64(2), T.int64(7), T.int64(14), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(8), n_0_oc_chunk_0_oh_0_fused_fused // T.int64(4) * T.int64(2) + oc_chunk_1 * T.int64(2) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_fused_fused % T.int64(4) * T.int64(14) + oh_1 * T.int64(7) + oh_2 * T.int64(7) + oh_3)
                        v_ow = T.axis.spatial(T.int64(56), ow_0 * T.int64(56) + ow_1 * T.int64(28) + ow_2 * T.int64(14) + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_0 * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(8) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)], p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)] * p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block]
        for ax0_ax1_ax2_ax3_ax4_fused_0 in T.parallel(T.int64(12544)):
            for ax0_ax1_ax2_ax3_ax4_fused_1 in T.vectorized(T.int64(64)):
                with T.block("T_relu"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(8), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) // T.int64(100352))
                    v_ax2 = T.axis.spatial(T.int64(56), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(100352) // T.int64(1792))
                    v_ax3 = T.axis.spatial(T.int64(56), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(1792) // T.int64(32))
                    v_ax4 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(32))
                    T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                    T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[4, 1, 1, 2])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[4, 2, 1, 7])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 2, 2, 14])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[2, 1, 16, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[32, 8])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
l65 = sch.sample_compute_location(block=b0, decision=2)
sch.compute_at(block=b0, loop=l65, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b66 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.unroll_explicit")
b67, b68, b69 = sch.get_child_blocks(b66)
l70, l71, l72, l73, l74, l75, l76, l77 = sch.get_loops(block=b67)
l78 = sch.fuse(l70, l71, l72, preserve_unit_iters=True)
sch.parallel(loop=l78)
l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102 = sch.get_loops(block=b68)
l103 = sch.fuse(l79, preserve_unit_iters=True)
sch.parallel(loop=l103)
sch.annotate(block_or_loop=l103, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l103, ann_key="pragma_unroll_explicit", ann_val=1)
l104, l105, l106, l107, l108 = sch.get_loops(block=b69)
l109 = sch.fuse(l104, l105, l106, l107, l108, preserve_unit_iters=True)
l110, l111 = sch.split(loop=l109, factors=[None, 64], preserve_unit_iters=True)
sch.parallel(loop=l110)
sch.vectorize(loop=l111)
b112 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l113, l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136 = sch.get_loops(block=b112)
b137 = sch.decompose_reduction(block=b112, loop=l121)
2024-04-30 11:46:11 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-30 11:46:12 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-30 11:46:17 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 11:46:17 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-30 11:46:29 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 11:46:42 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 11:46:56 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 11:47:09 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 11:47:17 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9076  0.8990  0.8884  0.8780  0.8674  0.8671  0.8671  0.8659  0.8625  0.8587  0.8574  0.8574  0.8554  0.8554  0.8471  0.8471
[17 : 32]:	0.8468  0.8461  0.8424  0.8423  0.8339  0.8323  0.8286  0.8208  0.8138  0.8138  0.8031  0.7770  0.7728  0.7673  0.7592  0.7542
[33 : 48]:	0.7454  0.7454  0.7425  0.7394  0.7364  0.7344  0.7328  0.7328  0.7294  0.7294  0.7294  0.7272  0.7253  0.7200  0.7196  0.7179
[49 : 64]:	0.7149  0.7111  0.7104  0.7086  0.7074  0.7060  0.7048  0.7026  0.7026  0.6987  0.6987  0.6969  0.6960  0.6939  0.6927  0.6847
2024-04-30 11:47:18 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-30 11:47:18 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-30 11:49:01 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1153: GFLOPs: 1290.1878. Time: 2868.5605 us. Best GFLOPs: 1479.3654
2024-04-30 11:49:01 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1154: GFLOPs: 1289.7889. Time: 2869.4476 us. Best GFLOPs: 1479.3654
2024-04-30 11:49:01 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1155: GFLOPs: 1373.9839. Time: 2693.6137 us. Best GFLOPs: 1479.3654
2024-04-30 11:49:01 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1156: GFLOPs: 1393.3433. Time: 2656.1881 us. Best GFLOPs: 1479.3654
2024-04-30 11:49:01 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1157: GFLOPs: 1289.3678. Time: 2870.3848 us. Best GFLOPs: 1479.3654
2024-04-30 11:49:01 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1158: GFLOPs: 1240.6295. Time: 2983.1484 us. Best GFLOPs: 1479.3654
2024-04-30 11:49:01 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1159: GFLOPs: 712.6405. Time: 5193.3361 us. Best GFLOPs: 1479.3654
2024-04-30 11:49:01 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1160: GFLOPs: 1342.0188. Time: 2757.7720 us. Best GFLOPs: 1479.3654
2024-04-30 11:49:02 [INFO] [task_scheduler.cc:121] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1161: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(56), T.int64(56), T.int64(256)), "float32"), p1: T.Buffer((T.int64(8), T.int64(1), T.int64(3), T.int64(3), T.int64(256), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(58), T.int64(58), T.int64(256)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused in T.parallel(T.int64(448), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(16), T.int64(3), T.int64(256)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(224) * T.int64(28) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(8) // T.int64(4) * T.int64(14) + ax2)
                    v_i3 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(224) // T.int64(16) * T.int64(4) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(4) + ax3)
                    v_i4 = T.axis.spatial(T.int64(256), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(57) and T.int64(1) <= v_i3 and v_i3 < T.int64(57), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oc_block_1 in range(T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(14), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(8), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(16) // T.int64(8) * T.int64(4) + oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(224) * T.int64(28) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(8) // T.int64(4) * T.int64(14) + oh_2_init * T.int64(14) + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(224) // T.int64(16) * T.int64(4) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(4) + ow_2_init + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(128), T.int64(1), T.int64(3), T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(32), T.int64(2), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(14), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(8), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(16) // T.int64(8) * T.int64(4) + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(224) * T.int64(28) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(8) // T.int64(4) * T.int64(14) + oh_2 * T.int64(14) + oh_3)
                        v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(224) // T.int64(16) * T.int64(4) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(4) + ow_2 + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(2) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)], p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)] * p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block]
                for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(4), T.int64(14)):
                    for ax3_ax4_fused in T.vectorized(T.int64(32)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(8), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(16) // T.int64(8) * T.int64(4) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(224) * T.int64(28) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(8) // T.int64(4) * T.int64(14) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(224) // T.int64(16) * T.int64(4) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(4))
                            v_ax4 = T.axis.spatial(T.int64(32), ax3_ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 2, 4, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 2, 1, 14])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[14, 4, 1, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 32, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[128, 2])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=8)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b68)
l85 = sch.fuse(l71, l72, l73, l74, l75, l76, l77, l78, l79, preserve_unit_iters=True)
sch.parallel(loop=l85)
l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l86, preserve_unit_iters=True)
sch.parallel(loop=l104)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109, l110, l111 = sch.get_loops(block=b70)
l112 = sch.fuse(l110, l111, preserve_unit_iters=True)
sch.vectorize(loop=l112)
b113 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131 = sch.get_loops(block=b113)
b132 = sch.decompose_reduction(block=b113, loop=l116)
2024-04-30 11:49:02 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1162: GFLOPs: 1252.7917. Time: 2954.1875 us. Best GFLOPs: 1479.3654
2024-04-30 11:49:02 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1163: GFLOPs: 1273.0335. Time: 2907.2148 us. Best GFLOPs: 1479.3654
2024-04-30 11:49:02 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1164: GFLOPs: 1135.0363. Time: 3260.6727 us. Best GFLOPs: 1479.3654
2024-04-30 11:49:02 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1165: GFLOPs: 1243.7184. Time: 2975.7394 us. Best GFLOPs: 1479.3654
2024-04-30 11:49:02 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1166: GFLOPs: 1261.0712. Time: 2934.7922 us. Best GFLOPs: 1479.3654
2024-04-30 11:49:02 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1167: GFLOPs: 1230.0102. Time: 3008.9032 us. Best GFLOPs: 1479.3654
2024-04-30 11:49:02 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1168: GFLOPs: 1313.1405. Time: 2818.4201 us. Best GFLOPs: 1479.3654
2024-04-30 11:49:02 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1169: GFLOPs: 1207.7920. Time: 3064.2542 us. Best GFLOPs: 1479.3654
2024-04-30 11:49:02 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1170: GFLOPs: 1322.6548. Time: 2798.1464 us. Best GFLOPs: 1479.3654
2024-04-30 11:49:02 [INFO] [task_scheduler.cc:121] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1171: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(56), T.int64(56), T.int64(256)), "float32"), p1: T.Buffer((T.int64(8), T.int64(1), T.int64(3), T.int64(3), T.int64(256), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(58), T.int64(58), T.int64(256)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused in T.parallel(T.int64(224), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(16), T.int64(3), T.int64(256)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(16) // T.int64(4) * T.int64(14) + ax2)
                    v_i3 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(16) * T.int64(4) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(4) + ax3)
                    v_i4 = T.axis.spatial(T.int64(256), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(57) and T.int64(1) <= v_i3 and v_i3 < T.int64(57), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oc_block_1 in range(T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(14), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(8), oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(16) // T.int64(4) * T.int64(14) + oh_2_init * T.int64(14) + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(16) * T.int64(4) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(4) + ow_2_init + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(128), T.int64(1), T.int64(3), T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(32), T.int64(2), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(14), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(8), oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(16) // T.int64(4) * T.int64(14) + oh_2 * T.int64(14) + oh_3)
                        v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(16) * T.int64(4) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(4) + ow_2 + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(2) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)], p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)] * p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block]
                for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(8), T.int64(14)):
                    for ax3_ax4_fused in T.vectorized(T.int64(32)):
                        with T.block("T_relu"):
                            v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                            v_ax2 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(16) // T.int64(4) * T.int64(14) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(16) * T.int64(4) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(4))
                            v_ax4 = T.axis.spatial(T.int64(32), ax3_ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 8, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 4, 1, 14])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[14, 4, 1, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 32, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[128, 2])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=112)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=8)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b68)
l85 = sch.fuse(l71, l72, l73, l74, l75, l76, l77, l78, l79, preserve_unit_iters=True)
sch.parallel(loop=l85)
l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l86, preserve_unit_iters=True)
sch.parallel(loop=l104)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109, l110, l111 = sch.get_loops(block=b70)
l112 = sch.fuse(l110, l111, preserve_unit_iters=True)
sch.vectorize(loop=l112)
b113 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131 = sch.get_loops(block=b113)
b132 = sch.decompose_reduction(block=b113, loop=l116)
2024-04-30 11:49:02 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1172: GFLOPs: 1225.6098. Time: 3019.7065 us. Best GFLOPs: 1479.3654
2024-04-30 11:49:02 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1173: GFLOPs: 1325.2367. Time: 2792.6949 us. Best GFLOPs: 1479.3654
2024-04-30 11:49:02 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1174: GFLOPs: 1290.5349. Time: 2867.7890 us. Best GFLOPs: 1479.3654
2024-04-30 11:49:02 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1175: GFLOPs: 1211.3090. Time: 3055.3574 us. Best GFLOPs: 1479.3654
2024-04-30 11:49:02 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1176: GFLOPs: 1192.0682. Time: 3104.6728 us. Best GFLOPs: 1479.3654
2024-04-30 11:49:02 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1177: GFLOPs: 1120.0453. Time: 3304.3143 us. Best GFLOPs: 1479.3654
2024-04-30 11:49:02 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1178: GFLOPs: 1151.7768. Time: 3213.2802 us. Best GFLOPs: 1479.3654
2024-04-30 11:49:02 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1179: GFLOPs: 1186.9339. Time: 3118.1027 us. Best GFLOPs: 1479.3654
2024-04-30 11:49:02 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1180: GFLOPs: 1176.1925. Time: 3146.5782 us. Best GFLOPs: 1479.3654
2024-04-30 11:49:02 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1181: GFLOPs: 1077.9001. Time: 3433.5110 us. Best GFLOPs: 1479.3654
2024-04-30 11:49:02 [INFO] [task_scheduler.cc:121] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1182: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(56), T.int64(56), T.int64(256)), "float32"), p1: T.Buffer((T.int64(8), T.int64(1), T.int64(3), T.int64(3), T.int64(256), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(58), T.int64(58), T.int64(256)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused in T.parallel(T.int64(224), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(16), T.int64(3), T.int64(256)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(56) * T.int64(14) + ax2)
                    v_i3 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(56) + ax3)
                    v_i4 = T.axis.spatial(T.int64(256), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(57) and T.int64(1) <= v_i3 and v_i3 < T.int64(57), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oc_block_1 in range(T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(8), T.int64(2), T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(8), oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(56) * T.int64(14) + oh_2_init * T.int64(7) + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(56) + ow_2_init + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(128), T.int64(1), T.int64(3), T.int64(1), T.int64(8), T.int64(2), T.int64(1), T.int64(32), T.int64(2), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(8), oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(56) * T.int64(14) + oh_2 * T.int64(7) + oh_3)
                        v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(56) + ow_2 + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(2) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)], p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)] * p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block]
                for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(8), T.int64(14)):
                    for ax3_ax4_fused in T.vectorized(T.int64(32)):
                        with T.block("T_relu"):
                            v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                            v_ax2 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(56) * T.int64(14) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(56))
                            v_ax4 = T.axis.spatial(T.int64(32), ax3_ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 8, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[4, 1, 2, 7])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[4, 14, 1, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 32, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[128, 2])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=8)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b68)
l85 = sch.fuse(l71, l72, l73, l74, l75, l76, l77, l78, l79, preserve_unit_iters=True)
sch.parallel(loop=l85)
l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l86, preserve_unit_iters=True)
sch.parallel(loop=l104)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109, l110, l111 = sch.get_loops(block=b70)
l112 = sch.fuse(l110, l111, preserve_unit_iters=True)
sch.vectorize(loop=l112)
b113 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131 = sch.get_loops(block=b113)
b132 = sch.decompose_reduction(block=b113, loop=l116)
2024-04-30 11:49:02 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1183: GFLOPs: 1288.7222. Time: 2871.8228 us. Best GFLOPs: 1479.3654
2024-04-30 11:49:02 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1184: GFLOPs: 1089.0608. Time: 3398.3244 us. Best GFLOPs: 1479.3654
2024-04-30 11:49:02 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1185: GFLOPs: 1072.6150. Time: 3450.4290 us. Best GFLOPs: 1479.3654
2024-04-30 11:49:02 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1186: GFLOPs: 1084.1768. Time: 3413.6330 us. Best GFLOPs: 1479.3654
2024-04-30 11:49:02 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1187: GFLOPs: 1054.8525. Time: 3508.5300 us. Best GFLOPs: 1479.3654
2024-04-30 11:49:02 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1188: GFLOPs: 988.2832. Time: 3744.8596 us. Best GFLOPs: 1479.3654
2024-04-30 11:49:02 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1189: GFLOPs: 1038.8765. Time: 3562.4847 us. Best GFLOPs: 1479.3654
2024-04-30 11:49:02 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1190: GFLOPs: 1075.9894. Time: 3439.6081 us. Best GFLOPs: 1479.3654
2024-04-30 11:49:02 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1191: GFLOPs: 1062.2461. Time: 3484.1096 us. Best GFLOPs: 1479.3654
2024-04-30 11:49:02 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1192: GFLOPs: 1060.8706. Time: 3488.6269 us. Best GFLOPs: 1479.3654
2024-04-30 11:49:02 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1193: GFLOPs: 1063.9340. Time: 3478.5822 us. Best GFLOPs: 1479.3654
2024-04-30 11:49:02 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1194: GFLOPs: 1066.7130. Time: 3469.5197 us. Best GFLOPs: 1479.3654
2024-04-30 11:49:02 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1195: GFLOPs: 1064.2476. Time: 3477.5570 us. Best GFLOPs: 1479.3654
2024-04-30 11:49:02 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1196: GFLOPs: 1027.6795. Time: 3601.2994 us. Best GFLOPs: 1479.3654
2024-04-30 11:49:02 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1197: GFLOPs: 1099.8287. Time: 3365.0529 us. Best GFLOPs: 1479.3654
2024-04-30 11:49:02 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1198: GFLOPs: 892.2264. Time: 4148.0300 us. Best GFLOPs: 1479.3654
2024-04-30 11:49:02 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1199: GFLOPs: 1093.2084. Time: 3385.4312 us. Best GFLOPs: 1479.3654
2024-04-30 11:49:02 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1200: GFLOPs: 1130.1932. Time: 3274.6453 us. Best GFLOPs: 1479.3654
2024-04-30 11:49:02 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1201: GFLOPs: 830.0813. Time: 4458.5775 us. Best GFLOPs: 1479.3654
2024-04-30 11:49:02 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1202: GFLOPs: 976.0171. Time: 3791.9230 us. Best GFLOPs: 1479.3654
2024-04-30 11:49:02 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1203: GFLOPs: 1024.5716. Time: 3612.2235 us. Best GFLOPs: 1479.3654
2024-04-30 11:49:02 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1204: GFLOPs: 1197.9782. Time: 3089.3565 us. Best GFLOPs: 1479.3654
2024-04-30 11:49:02 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1205: GFLOPs: 1062.4817. Time: 3483.3368 us. Best GFLOPs: 1479.3654
2024-04-30 11:49:02 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1206: GFLOPs: 1139.5064. Time: 3247.8816 us. Best GFLOPs: 1479.3654
2024-04-30 11:49:02 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1207: GFLOPs: 1035.6501. Time: 3573.5832 us. Best GFLOPs: 1479.3654
2024-04-30 11:49:02 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1208: GFLOPs: 1038.4119. Time: 3564.0789 us. Best GFLOPs: 1479.3654
2024-04-30 11:49:02 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1209: GFLOPs: 1068.4364. Time: 3463.9233 us. Best GFLOPs: 1479.3654
2024-04-30 11:49:02 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1210: GFLOPs: 1141.7569. Time: 3241.4796 us. Best GFLOPs: 1479.3654
2024-04-30 11:49:02 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1211: GFLOPs: 1089.0927. Time: 3398.2248 us. Best GFLOPs: 1479.3654
2024-04-30 11:49:02 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1212: GFLOPs: 1056.5602. Time: 3502.8592 us. Best GFLOPs: 1479.3654
2024-04-30 11:49:02 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1213: GFLOPs: 1014.1293. Time: 3649.4179 us. Best GFLOPs: 1479.3654
2024-04-30 11:49:02 [INFO] [task_scheduler.cc:121] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1214: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(56), T.int64(56), T.int64(256)), "float32"), p1: T.Buffer((T.int64(8), T.int64(1), T.int64(3), T.int64(3), T.int64(256), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(58), T.int64(58), T.int64(256)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)))
        for i0_i1_i2_i3_fused in T.parallel(T.int64(3364)):
            for i4 in range(T.int64(256)):
                with T.block("data_pad"):
                    v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_i1 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_i2 = T.axis.spatial(T.int64(58), i0_i1_i2_i3_fused // T.int64(58))
                    v_i3 = T.axis.spatial(T.int64(58), i0_i1_i2_i3_fused % T.int64(58))
                    v_i4 = T.axis.spatial(T.int64(256), i4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(57) and T.int64(1) <= v_i3 and v_i3 < T.int64(57), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
        for n_0_oc_chunk_0_oh_0_ow_0_fused in T.parallel(T.int64(784), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for oc_block_0 in range(T.int64(1)):
                for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(4)):
                    for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(4), T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                        for oc_block_3_fused_init in T.vectorized(T.int64(8)):
                            with T.block("conv2d_NCHWc_init"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                                v_oc_chunk = T.axis.spatial(T.int64(8), n_0_oc_chunk_0_oh_0_ow_0_fused // T.int64(392) * T.int64(4) + oc_chunk_1 * T.int64(4) + oc_chunk_2_init + oc_chunk_3_init)
                                v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_fused % T.int64(392) // T.int64(56) * T.int64(8) + oh_1 * T.int64(4) + oh_2_init + oh_3_init)
                                v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_fused % T.int64(56) + ow_1 + ow_2_init + ow_3_init)
                                v_oc_block = T.axis.spatial(T.int64(32), oc_block_0 * T.int64(32) + oc_block_1 * T.int64(8) + oc_block_2_init * T.int64(8) + oc_block_3_fused_init)
                                T.reads()
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                    for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(8), T.int64(3), T.int64(3), T.int64(1), T.int64(4), T.int64(4), T.int64(1), T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                        for oc_block_3_fused in T.vectorized(T.int64(8)):
                            with T.block("conv2d_NCHWc_update"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                                v_oc_chunk = T.axis.spatial(T.int64(8), n_0_oc_chunk_0_oh_0_ow_0_fused // T.int64(392) * T.int64(4) + oc_chunk_1 * T.int64(4) + oc_chunk_2 + oc_chunk_3)
                                v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_fused % T.int64(392) // T.int64(56) * T.int64(8) + oh_1 * T.int64(4) + oh_2 + oh_3)
                                v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_fused % T.int64(56) + ow_1 + ow_2 + ow_3)
                                v_oc_block = T.axis.spatial(T.int64(32), oc_block_0 * T.int64(32) + oc_block_1 * T.int64(8) + oc_block_2 * T.int64(8) + oc_block_3_fused)
                                v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(32) + ic_1)
                                v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                                v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                                T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)], p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block])
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)] * p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block]
                for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(4), T.int64(8)):
                    for ax3_ax4_fused in T.vectorized(T.int64(32)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(8), n_0_oc_chunk_0_oh_0_ow_0_fused // T.int64(392) * T.int64(4) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_fused % T.int64(392) // T.int64(56) * T.int64(8) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_fused % T.int64(56))
                            v_ax4 = T.axis.spatial(T.int64(32), ax3_ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[2, 1, 4, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[7, 2, 4, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[56, 1, 1, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 4, 1, 8])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[8, 32])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=-1)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75 = sch.get_loops(block=b68)
l76 = sch.fuse(l71, l72, l73, l74, preserve_unit_iters=True)
sch.parallel(loop=l76)
l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102 = sch.get_loops(block=b69)
l103 = sch.fuse(l77, l78, l79, l80, preserve_unit_iters=True)
sch.parallel(loop=l103)
l104 = sch.fuse(l102, preserve_unit_iters=True)
sch.vectorize(loop=l104)
sch.annotate(block_or_loop=l103, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l103, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109, l110, l111 = sch.get_loops(block=b70)
l112 = sch.fuse(l110, l111, preserve_unit_iters=True)
sch.vectorize(loop=l112)
b113 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136 = sch.get_loops(block=b113)
b137 = sch.decompose_reduction(block=b113, loop=l121)
2024-04-30 11:49:02 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1215: GFLOPs: 39.9287. Time: 92689.6863 us. Best GFLOPs: 1479.3654
2024-04-30 11:49:02 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1216: GFLOPs: 44.5625. Time: 83051.4130 us. Best GFLOPs: 1479.3654
2024-04-30 11:55:27 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-30 11:55:28 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-30 11:55:33 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 11:55:33 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-30 11:55:46 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 11:55:59 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 11:56:13 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 11:56:26 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 11:56:34 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9020  0.8942  0.8848  0.8819  0.8819  0.8690  0.8632  0.8612  0.8612  0.8602  0.8602  0.8577  0.8567  0.8378  0.8378  0.8343
[17 : 32]:	0.8217  0.8170  0.8050  0.8050  0.8032  0.8007  0.7940  0.7908  0.7883  0.7632  0.7578  0.7385  0.7327  0.7316  0.7304  0.7253
[33 : 48]:	0.7234  0.7186  0.7167  0.7128  0.7088  0.7088  0.7088  0.7088  0.7077  0.7077  0.7072  0.7000  0.6972  0.6972  0.6936  0.6925
[49 : 64]:	0.6890  0.6890  0.6838  0.6827  0.6785  0.6785  0.6761  0.6757  0.6755  0.6746  0.6746  0.6746  0.6732  0.6706  0.6682  0.6658
2024-04-30 11:56:34 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-30 11:56:34 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-30 11:58:29 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1217: GFLOPs: 653.3462. Time: 5664.6561 us. Best GFLOPs: 1479.3654
2024-04-30 11:58:29 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1218: GFLOPs: 662.7186. Time: 5584.5447 us. Best GFLOPs: 1479.3654
2024-04-30 11:58:29 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1219: GFLOPs: 1311.6419. Time: 2821.6404 us. Best GFLOPs: 1479.3654
2024-04-30 11:58:29 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1220: GFLOPs: 1374.5893. Time: 2692.4273 us. Best GFLOPs: 1479.3654
2024-04-30 11:58:29 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1221: GFLOPs: 1011.2798. Time: 3659.7010 us. Best GFLOPs: 1479.3654
2024-04-30 11:58:29 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1222: GFLOPs: 1262.2860. Time: 2931.9678 us. Best GFLOPs: 1479.3654
2024-04-30 11:58:29 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1223: GFLOPs: 1270.5646. Time: 2912.8640 us. Best GFLOPs: 1479.3654
2024-04-30 11:58:29 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1224: GFLOPs: 707.1066. Time: 5233.9800 us. Best GFLOPs: 1479.3654
2024-04-30 11:58:29 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1225: GFLOPs: 711.5768. Time: 5201.0992 us. Best GFLOPs: 1479.3654
2024-04-30 11:58:29 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1226: GFLOPs: 682.1706. Time: 5425.3027 us. Best GFLOPs: 1479.3654
2024-04-30 11:58:29 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1227: GFLOPs: 739.9989. Time: 5001.3340 us. Best GFLOPs: 1479.3654
2024-04-30 11:58:29 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1228: GFLOPs: 1222.6042. Time: 3027.1300 us. Best GFLOPs: 1479.3654
2024-04-30 11:58:29 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1229: GFLOPs: 1359.4376. Time: 2722.4359 us. Best GFLOPs: 1479.3654
2024-04-30 11:58:29 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1230: GFLOPs: 1216.0913. Time: 3043.3419 us. Best GFLOPs: 1479.3654
2024-04-30 11:58:29 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1231: GFLOPs: 993.4375. Time: 3725.4300 us. Best GFLOPs: 1479.3654
2024-04-30 11:58:29 [INFO] [task_scheduler.cc:121] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1232: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(56), T.int64(56), T.int64(256)), "float32"), p1: T.Buffer((T.int64(8), T.int64(1), T.int64(3), T.int64(3), T.int64(256), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(58), T.int64(58), T.int64(256)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused in T.parallel(T.int64(224), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(16), T.int64(3), T.int64(256)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(112) * T.int64(28) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(28) // T.int64(14) * T.int64(14) + ax2)
                    v_i3 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(112) // T.int64(28) * T.int64(14) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(14) + ax3)
                    v_i4 = T.axis.spatial(T.int64(256), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(57) and T.int64(1) <= v_i3 and v_i3 < T.int64(57), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oc_block_1 in range(T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(14), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(8), oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(112) * T.int64(28) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(28) // T.int64(14) * T.int64(14) + oh_2_init * T.int64(14) + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(112) // T.int64(28) * T.int64(14) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(14) + ow_2_init + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(128), T.int64(1), T.int64(3), T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(32), T.int64(2), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(14), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(8), oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(112) * T.int64(28) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(28) // T.int64(14) * T.int64(14) + oh_2 * T.int64(14) + oh_3)
                        v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(112) // T.int64(28) * T.int64(14) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(14) + ow_2 + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(2) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)], p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)] * p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block]
                for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(8), T.int64(14)):
                    for ax3_ax4_fused in T.vectorized(T.int64(32)):
                        with T.block("T_relu"):
                            v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                            v_ax2 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(112) * T.int64(28) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(28) // T.int64(14) * T.int64(14) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(112) // T.int64(28) * T.int64(14) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(14))
                            v_ax4 = T.axis.spatial(T.int64(32), ax3_ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 8, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 2, 1, 14])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[4, 14, 1, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 32, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[128, 2])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=8)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b68)
l85 = sch.fuse(l71, l72, l73, l74, l75, l76, l77, l78, l79, preserve_unit_iters=True)
sch.parallel(loop=l85)
l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l86, preserve_unit_iters=True)
sch.parallel(loop=l104)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109, l110, l111 = sch.get_loops(block=b70)
l112 = sch.fuse(l110, l111, preserve_unit_iters=True)
sch.vectorize(loop=l112)
b113 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131 = sch.get_loops(block=b113)
b132 = sch.decompose_reduction(block=b113, loop=l116)
2024-04-30 11:58:29 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1233: GFLOPs: 1243.0255. Time: 2977.3982 us. Best GFLOPs: 1479.3654
2024-04-30 11:58:29 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1234: GFLOPs: 1272.5916. Time: 2908.2242 us. Best GFLOPs: 1479.3654
2024-04-30 11:58:29 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1235: GFLOPs: 1202.1429. Time: 3078.6538 us. Best GFLOPs: 1479.3654
2024-04-30 11:58:29 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1236: GFLOPs: 1364.7478. Time: 2711.8430 us. Best GFLOPs: 1479.3654
2024-04-30 11:58:29 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1237: GFLOPs: 1193.3749. Time: 3101.2732 us. Best GFLOPs: 1479.3654
2024-04-30 11:58:29 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1238: GFLOPs: 1183.8390. Time: 3126.2543 us. Best GFLOPs: 1479.3654
2024-04-30 11:58:29 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1239: GFLOPs: 1347.3071. Time: 2746.9474 us. Best GFLOPs: 1479.3654
2024-04-30 11:58:29 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1240: GFLOPs: 1217.1438. Time: 3040.7104 us. Best GFLOPs: 1479.3654
2024-04-30 11:58:29 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1241: GFLOPs: 1066.4980. Time: 3470.2191 us. Best GFLOPs: 1479.3654
2024-04-30 11:58:29 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1242: GFLOPs: 1400.4785. Time: 2642.6551 us. Best GFLOPs: 1479.3654
2024-04-30 11:58:29 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1243: GFLOPs: 1189.7609. Time: 3110.6937 us. Best GFLOPs: 1479.3654
2024-04-30 11:58:29 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1244: GFLOPs: 1141.7932. Time: 3241.3766 us. Best GFLOPs: 1479.3654
2024-04-30 11:58:29 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1245: GFLOPs: 646.7188. Time: 5722.7062 us. Best GFLOPs: 1479.3654
2024-04-30 11:58:29 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1246: GFLOPs: 1177.2902. Time: 3143.6443 us. Best GFLOPs: 1479.3654
2024-04-30 11:58:29 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1247: GFLOPs: 1080.1835. Time: 3426.2528 us. Best GFLOPs: 1479.3654
2024-04-30 11:58:29 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1248: GFLOPs: 440.9168. Time: 8393.8332 us. Best GFLOPs: 1479.3654
2024-04-30 11:58:29 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1249: GFLOPs: 733.3104. Time: 5046.9511 us. Best GFLOPs: 1479.3654
2024-04-30 11:58:29 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1250: GFLOPs: 811.2855. Time: 4561.8733 us. Best GFLOPs: 1479.3654
2024-04-30 11:58:29 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1251: GFLOPs: 1090.2765. Time: 3394.5349 us. Best GFLOPs: 1479.3654
2024-04-30 11:58:29 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1252: GFLOPs: 1014.0185. Time: 3649.8169 us. Best GFLOPs: 1479.3654
2024-04-30 11:58:29 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1253: GFLOPs: 1008.9746. Time: 3668.0623 us. Best GFLOPs: 1479.3654
2024-04-30 11:58:29 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1254: GFLOPs: 997.2451. Time: 3711.2059 us. Best GFLOPs: 1479.3654
2024-04-30 11:58:29 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1255: GFLOPs: 1121.0478. Time: 3301.3596 us. Best GFLOPs: 1479.3654
2024-04-30 11:58:29 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1256: GFLOPs: 1050.9324. Time: 3521.6173 us. Best GFLOPs: 1479.3654
2024-04-30 11:58:29 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1257: GFLOPs: 1087.3385. Time: 3403.7071 us. Best GFLOPs: 1479.3654
2024-04-30 11:58:29 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1258: GFLOPs: 1055.7516. Time: 3505.5422 us. Best GFLOPs: 1479.3654
2024-04-30 11:58:29 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1259: GFLOPs: 1058.7290. Time: 3495.6838 us. Best GFLOPs: 1479.3654
2024-04-30 11:58:29 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1260: GFLOPs: 1171.5063. Time: 3159.1652 us. Best GFLOPs: 1479.3654
2024-04-30 11:58:29 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1261: GFLOPs: 882.2921. Time: 4194.7353 us. Best GFLOPs: 1479.3654
2024-04-30 11:58:29 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1262: GFLOPs: 904.8726. Time: 4090.0582 us. Best GFLOPs: 1479.3654
2024-04-30 11:58:29 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1263: GFLOPs: 1099.8738. Time: 3364.9151 us. Best GFLOPs: 1479.3654
2024-04-30 11:58:29 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1264: GFLOPs: 1049.6560. Time: 3525.8998 us. Best GFLOPs: 1479.3654
2024-04-30 11:58:29 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1265: GFLOPs: 903.2633. Time: 4097.3456 us. Best GFLOPs: 1479.3654
2024-04-30 11:58:29 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1266: GFLOPs: 882.7897. Time: 4192.3707 us. Best GFLOPs: 1479.3654
2024-04-30 11:58:29 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1267: GFLOPs: 579.7028. Time: 6384.2746 us. Best GFLOPs: 1479.3654
2024-04-30 11:58:29 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1268: GFLOPs: 1066.7814. Time: 3469.2971 us. Best GFLOPs: 1479.3654
2024-04-30 11:58:29 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1269: GFLOPs: 805.2172. Time: 4596.2530 us. Best GFLOPs: 1479.3654
2024-04-30 11:58:29 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1270: GFLOPs: 874.2968. Time: 4233.0956 us. Best GFLOPs: 1479.3654
2024-04-30 11:58:29 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1271: GFLOPs: 722.0730. Time: 5125.4950 us. Best GFLOPs: 1479.3654
2024-04-30 11:58:29 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1272: GFLOPs: 976.0506. Time: 3791.7929 us. Best GFLOPs: 1479.3654
2024-04-30 11:58:29 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1273: GFLOPs: 500.6381. Time: 7392.5294 us. Best GFLOPs: 1479.3654
2024-04-30 11:58:29 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1274: GFLOPs: 1110.3076. Time: 3333.2940 us. Best GFLOPs: 1479.3654
2024-04-30 11:58:29 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1275: GFLOPs: 1013.1854. Time: 3652.8180 us. Best GFLOPs: 1479.3654
2024-04-30 11:58:29 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1276: GFLOPs: 1071.1255. Time: 3455.2270 us. Best GFLOPs: 1479.3654
2024-04-30 11:58:29 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1277: GFLOPs: 822.4264. Time: 4500.0763 us. Best GFLOPs: 1479.3654
2024-04-30 11:58:29 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1278: GFLOPs: 16.0066. Time: 231216.0180 us. Best GFLOPs: 1479.3654
2024-04-30 11:58:29 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1279: GFLOPs: 142.1492. Time: 26035.8995 us. Best GFLOPs: 1479.3654
2024-04-30 11:58:29 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1280: GFLOPs: 28.7664. Time: 128656.3407 us. Best GFLOPs: 1479.3654
2024-04-30 12:08:37 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-30 12:08:38 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-30 12:08:43 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 12:08:43 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-30 12:08:56 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 12:09:09 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 12:09:23 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 12:09:36 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 12:09:44 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.8907  0.8903  0.8691  0.8643  0.8620  0.8587  0.8587  0.8580  0.8564  0.8452  0.8372  0.8318  0.8299  0.8286  0.8201  0.8201
[17 : 32]:	0.8201  0.8201  0.8189  0.8189  0.8180  0.8127  0.8127  0.8086  0.7959  0.7942  0.7940  0.7916  0.7916  0.7910  0.7906  0.7871
[33 : 48]:	0.7841  0.7754  0.7661  0.7649  0.7649  0.7647  0.7535  0.7503  0.7465  0.7465  0.7379  0.7331  0.7331  0.7317  0.7315  0.7302
[49 : 64]:	0.7302  0.7284  0.7269  0.7238  0.7117  0.7047  0.7020  0.6995  0.6986  0.6985  0.6985  0.6985  0.6977  0.6941  0.6921  0.6914
2024-04-30 12:09:45 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-30 12:09:45 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-30 12:12:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1281: GFLOPs: 1272.1393. Time: 2909.2583 us. Best GFLOPs: 1479.3654
2024-04-30 12:12:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1282: GFLOPs: 1309.1572. Time: 2826.9956 us. Best GFLOPs: 1479.3654
2024-04-30 12:12:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1283: GFLOPs: 1299.3637. Time: 2848.3032 us. Best GFLOPs: 1479.3654
2024-04-30 12:12:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1284: GFLOPs: 1292.3538. Time: 2863.7527 us. Best GFLOPs: 1479.3654
2024-04-30 12:12:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1285: GFLOPs: 1253.5363. Time: 2952.4329 us. Best GFLOPs: 1479.3654
2024-04-30 12:12:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1286: GFLOPs: 711.1311. Time: 5204.3596 us. Best GFLOPs: 1479.3654
2024-04-30 12:12:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1287: GFLOPs: 1245.2908. Time: 2971.9820 us. Best GFLOPs: 1479.3654
2024-04-30 12:12:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1288: GFLOPs: 1322.3478. Time: 2798.7959 us. Best GFLOPs: 1479.3654
2024-04-30 12:12:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1289: GFLOPs: 1234.1850. Time: 2998.7254 us. Best GFLOPs: 1479.3654
2024-04-30 12:12:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1290: GFLOPs: 1290.7520. Time: 2867.3066 us. Best GFLOPs: 1479.3654
2024-04-30 12:12:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1291: GFLOPs: 1257.1997. Time: 2943.8298 us. Best GFLOPs: 1479.3654
2024-04-30 12:12:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1292: GFLOPs: 1288.5114. Time: 2872.2925 us. Best GFLOPs: 1479.3654
2024-04-30 12:12:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1293: GFLOPs: 1291.2266. Time: 2866.2527 us. Best GFLOPs: 1479.3654
2024-04-30 12:12:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1294: GFLOPs: 1329.0781. Time: 2784.6232 us. Best GFLOPs: 1479.3654
2024-04-30 12:12:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1295: GFLOPs: 1207.2448. Time: 3065.6431 us. Best GFLOPs: 1479.3654
2024-04-30 12:12:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1296: GFLOPs: 1201.1374. Time: 3081.2309 us. Best GFLOPs: 1479.3654
2024-04-30 12:12:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1297: GFLOPs: 1267.1114. Time: 2920.8022 us. Best GFLOPs: 1479.3654
2024-04-30 12:12:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1298: GFLOPs: 1208.8733. Time: 3061.5133 us. Best GFLOPs: 1479.3654
2024-04-30 12:12:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1299: GFLOPs: 1270.5810. Time: 2912.8264 us. Best GFLOPs: 1479.3654
2024-04-30 12:12:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1300: GFLOPs: 1376.8089. Time: 2688.0868 us. Best GFLOPs: 1479.3654
2024-04-30 12:12:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1301: GFLOPs: 1203.3701. Time: 3075.5141 us. Best GFLOPs: 1479.3654
2024-04-30 12:12:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1302: GFLOPs: 1195.6048. Time: 3095.4893 us. Best GFLOPs: 1479.3654
2024-04-30 12:12:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1303: GFLOPs: 1374.0389. Time: 2693.5058 us. Best GFLOPs: 1479.3654
2024-04-30 12:12:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1304: GFLOPs: 1180.8093. Time: 3134.2755 us. Best GFLOPs: 1479.3654
2024-04-30 12:12:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1305: GFLOPs: 1235.3583. Time: 2995.8771 us. Best GFLOPs: 1479.3654
2024-04-30 12:12:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1306: GFLOPs: 1200.3977. Time: 3083.1297 us. Best GFLOPs: 1479.3654
2024-04-30 12:12:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1307: GFLOPs: 1350.3341. Time: 2740.7896 us. Best GFLOPs: 1479.3654
2024-04-30 12:12:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1308: GFLOPs: 1106.9732. Time: 3343.3345 us. Best GFLOPs: 1479.3654
2024-04-30 12:12:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1309: GFLOPs: 1296.6159. Time: 2854.3394 us. Best GFLOPs: 1479.3654
2024-04-30 12:12:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1310: GFLOPs: 1355.3181. Time: 2730.7108 us. Best GFLOPs: 1479.3654
2024-04-30 12:12:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1311: GFLOPs: 1251.1784. Time: 2957.9968 us. Best GFLOPs: 1479.3654
2024-04-30 12:12:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1312: GFLOPs: 1322.3926. Time: 2798.7012 us. Best GFLOPs: 1479.3654
2024-04-30 12:12:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1313: GFLOPs: 1109.8234. Time: 3334.7484 us. Best GFLOPs: 1479.3654
2024-04-30 12:12:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1314: GFLOPs: 1064.6581. Time: 3476.2163 us. Best GFLOPs: 1479.3654
2024-04-30 12:12:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1315: GFLOPs: 1177.3940. Time: 3143.3672 us. Best GFLOPs: 1479.3654
2024-04-30 12:12:03 [INFO] [task_scheduler.cc:121] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1316: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(56), T.int64(56), T.int64(256)), "float32"), p1: T.Buffer((T.int64(8), T.int64(1), T.int64(3), T.int64(3), T.int64(256), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(58), T.int64(58), T.int64(256)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused in T.parallel(T.int64(224), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(16), T.int64(3), T.int64(256)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(112) * T.int64(28) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(14) // T.int64(7) * T.int64(14) + ax2)
                    v_i3 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(112) // T.int64(14) * T.int64(7) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(7) + ax3)
                    v_i4 = T.axis.spatial(T.int64(256), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(57) and T.int64(1) <= v_i3 and v_i3 < T.int64(57), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oc_block_1 in range(T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(14), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(8), oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(112) * T.int64(28) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(14) // T.int64(7) * T.int64(14) + oh_2_init * T.int64(14) + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(112) // T.int64(14) * T.int64(7) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(7) + ow_2_init + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(128), T.int64(1), T.int64(3), T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(32), T.int64(2), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(14), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(8), oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(112) * T.int64(28) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(14) // T.int64(7) * T.int64(14) + oh_2 * T.int64(14) + oh_3)
                        v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(112) // T.int64(14) * T.int64(7) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(7) + ow_2 + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(2) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)], p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)] * p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block]
                for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(8), T.int64(14)):
                    for ax3_ax4_fused in T.vectorized(T.int64(32)):
                        with T.block("T_relu"):
                            v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                            v_ax2 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(112) * T.int64(28) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(14) // T.int64(7) * T.int64(14) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(112) // T.int64(14) * T.int64(7) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(7))
                            v_ax4 = T.axis.spatial(T.int64(32), ax3_ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 8, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 2, 1, 14])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[8, 7, 1, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 32, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[128, 2])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=8)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b68)
l85 = sch.fuse(l71, l72, l73, l74, l75, l76, l77, l78, l79, preserve_unit_iters=True)
sch.parallel(loop=l85)
l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l86, preserve_unit_iters=True)
sch.parallel(loop=l104)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109, l110, l111 = sch.get_loops(block=b70)
l112 = sch.fuse(l110, l111, preserve_unit_iters=True)
sch.vectorize(loop=l112)
b113 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131 = sch.get_loops(block=b113)
b132 = sch.decompose_reduction(block=b113, loop=l116)
2024-04-30 12:12:03 [INFO] [task_scheduler.cc:121] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1317: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(56), T.int64(56), T.int64(256)), "float32"), p1: T.Buffer((T.int64(8), T.int64(1), T.int64(3), T.int64(3), T.int64(256), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(58), T.int64(58), T.int64(256)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused in T.parallel(T.int64(224), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(16), T.int64(3), T.int64(256)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(112) * T.int64(28) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(8) // T.int64(4) * T.int64(14) + ax2)
                    v_i3 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(112) // T.int64(8) * T.int64(4) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(4) + ax3)
                    v_i4 = T.axis.spatial(T.int64(256), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(57) and T.int64(1) <= v_i3 and v_i3 < T.int64(57), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oc_block_1 in range(T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(14), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(8), oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(112) * T.int64(28) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(8) // T.int64(4) * T.int64(14) + oh_2_init * T.int64(14) + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(112) // T.int64(8) * T.int64(4) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(4) + ow_2_init + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(128), T.int64(1), T.int64(3), T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(32), T.int64(2), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(14), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(8), oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(112) * T.int64(28) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(8) // T.int64(4) * T.int64(14) + oh_2 * T.int64(14) + oh_3)
                        v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(112) // T.int64(8) * T.int64(4) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(4) + ow_2 + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(2) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)], p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)] * p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block]
                for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(8), T.int64(14)):
                    for ax3_ax4_fused in T.vectorized(T.int64(32)):
                        with T.block("T_relu"):
                            v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                            v_ax2 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(112) * T.int64(28) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(8) // T.int64(4) * T.int64(14) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(112) // T.int64(8) * T.int64(4) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(4))
                            v_ax4 = T.axis.spatial(T.int64(32), ax3_ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 8, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 2, 1, 14])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[14, 4, 1, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 32, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[128, 2])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=112)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=8)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b68)
l85 = sch.fuse(l71, l72, l73, l74, l75, l76, l77, l78, l79, preserve_unit_iters=True)
sch.parallel(loop=l85)
l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l86, preserve_unit_iters=True)
sch.parallel(loop=l104)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109, l110, l111 = sch.get_loops(block=b70)
l112 = sch.fuse(l110, l111, preserve_unit_iters=True)
sch.vectorize(loop=l112)
b113 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131 = sch.get_loops(block=b113)
b132 = sch.decompose_reduction(block=b113, loop=l116)
2024-04-30 12:12:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1318: GFLOPs: 158.4637. Time: 23355.3896 us. Best GFLOPs: 1479.3654
2024-04-30 12:12:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1319: GFLOPs: 1324.6606. Time: 2793.9094 us. Best GFLOPs: 1479.3654
2024-04-30 12:12:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1320: GFLOPs: 1131.2759. Time: 3271.5111 us. Best GFLOPs: 1479.3654
2024-04-30 12:12:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1321: GFLOPs: 1056.2012. Time: 3504.0499 us. Best GFLOPs: 1479.3654
2024-04-30 12:12:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1322: GFLOPs: 1053.3167. Time: 3513.6456 us. Best GFLOPs: 1479.3654
2024-04-30 12:12:03 [INFO] [task_scheduler.cc:121] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1323: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(56), T.int64(56), T.int64(256)), "float32"), p1: T.Buffer((T.int64(8), T.int64(1), T.int64(3), T.int64(3), T.int64(256), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(58), T.int64(58), T.int64(256)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused in T.parallel(T.int64(448), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(16), T.int64(3), T.int64(256)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(16) // T.int64(4) * T.int64(14) + ax2)
                    v_i3 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(224) // T.int64(16) * T.int64(4) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(4) + ax3)
                    v_i4 = T.axis.spatial(T.int64(256), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(57) and T.int64(1) <= v_i3 and v_i3 < T.int64(57), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oc_block_1 in range(T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(14), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(8), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(224) * T.int64(4) + oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(16) // T.int64(4) * T.int64(14) + oh_2_init * T.int64(14) + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(224) // T.int64(16) * T.int64(4) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(4) + ow_2_init + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(128), T.int64(1), T.int64(3), T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(32), T.int64(2), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(14), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(8), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(224) * T.int64(4) + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(16) // T.int64(4) * T.int64(14) + oh_2 * T.int64(14) + oh_3)
                        v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(224) // T.int64(16) * T.int64(4) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(4) + ow_2 + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(2) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)], p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)] * p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block]
                for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(4), T.int64(14)):
                    for ax3_ax4_fused in T.vectorized(T.int64(32)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(8), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(224) * T.int64(4) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(16) // T.int64(4) * T.int64(14) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(224) // T.int64(16) * T.int64(4) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(4))
                            v_ax4 = T.axis.spatial(T.int64(32), ax3_ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[2, 1, 4, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 4, 1, 14])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[14, 4, 1, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 32, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[128, 2])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=112)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=8)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b68)
l85 = sch.fuse(l71, l72, l73, l74, l75, l76, l77, l78, l79, preserve_unit_iters=True)
sch.parallel(loop=l85)
l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l86, preserve_unit_iters=True)
sch.parallel(loop=l104)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109, l110, l111 = sch.get_loops(block=b70)
l112 = sch.fuse(l110, l111, preserve_unit_iters=True)
sch.vectorize(loop=l112)
b113 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131 = sch.get_loops(block=b113)
b132 = sch.decompose_reduction(block=b113, loop=l116)
2024-04-30 12:12:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1324: GFLOPs: 1175.3277. Time: 3148.8935 us. Best GFLOPs: 1479.3654
2024-04-30 12:12:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1325: GFLOPs: 1130.8929. Time: 3272.6192 us. Best GFLOPs: 1479.3654
2024-04-30 12:12:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1326: GFLOPs: 1079.7555. Time: 3427.6109 us. Best GFLOPs: 1479.3654
2024-04-30 12:12:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1327: GFLOPs: 1016.1467. Time: 3642.1727 us. Best GFLOPs: 1479.3654
2024-04-30 12:12:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1328: GFLOPs: 1126.6903. Time: 3284.8262 us. Best GFLOPs: 1479.3654
2024-04-30 12:12:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1329: GFLOPs: 1025.7341. Time: 3608.1297 us. Best GFLOPs: 1479.3654
2024-04-30 12:12:03 [INFO] [task_scheduler.cc:121] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1330: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(56), T.int64(56), T.int64(256)), "float32"), p1: T.Buffer((T.int64(8), T.int64(1), T.int64(3), T.int64(3), T.int64(256), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(58), T.int64(58), T.int64(256)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused in T.parallel(T.int64(224), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for oc_block_1 in range(T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(8), T.int64(2), T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(8), oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(56) * T.int64(14) + oh_2_init * T.int64(7) + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(56) + ow_2_init + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0 in range(T.int64(128)):
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(16), T.int64(3)):
                        for ax4_fused in T.vectorized(T.int64(2)):
                            with T.block("data_pad"):
                                v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                                v_i2 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(56) * T.int64(14) + ax2)
                                v_i3 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(56) + ax3)
                                v_i4 = T.axis.spatial(T.int64(256), ic_0 * T.int64(2) + ax4_fused)
                                T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                                T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                                data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(57) and T.int64(1) <= v_i3 and v_i3 < T.int64(57), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                    for kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(3), T.int64(3), T.int64(1), T.int64(8), T.int64(2), T.int64(1), T.int64(32), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(1)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(8), oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(56) * T.int64(14) + oh_2 * T.int64(7) + oh_3)
                            v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(56) + ow_2 + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2 + oc_block_3)
                            v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(2) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)], p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)] * p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block]
                for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(8), T.int64(14)):
                    for ax3_ax4_fused in T.vectorized(T.int64(32)):
                        with T.block("T_relu"):
                            v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                            v_ax2 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(56) * T.int64(14) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(56))
                            v_ax4 = T.axis.spatial(T.int64(32), ax3_ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 8, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 2, 2, 7])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 56, 1, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 32, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[128, 2])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=112)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=10)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86 = sch.get_loops(block=b68)
l87 = sch.fuse(l71, l72, l73, l74, l75, l76, l77, l78, l79, preserve_unit_iters=True)
sch.parallel(loop=l87)
l88 = sch.fuse(l86, preserve_unit_iters=True)
sch.vectorize(loop=l88)
l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106 = sch.get_loops(block=b69)
l107 = sch.fuse(l89, preserve_unit_iters=True)
sch.parallel(loop=l107)
sch.annotate(block_or_loop=l107, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l107, ann_key="pragma_unroll_explicit", ann_val=1)
l108, l109, l110, l111, l112, l113, l114 = sch.get_loops(block=b70)
l115 = sch.fuse(l113, l114, preserve_unit_iters=True)
sch.vectorize(loop=l115)
b116 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134 = sch.get_loops(block=b116)
b135 = sch.decompose_reduction(block=b116, loop=l119)
2024-04-30 12:12:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1331: GFLOPs: 1058.8056. Time: 3495.4308 us. Best GFLOPs: 1479.3654
2024-04-30 12:12:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1332: GFLOPs: 1174.2197. Time: 3151.8648 us. Best GFLOPs: 1479.3654
2024-04-30 12:12:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1333: GFLOPs: 1088.4588. Time: 3400.2038 us. Best GFLOPs: 1479.3654
2024-04-30 12:12:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1334: GFLOPs: 1128.3635. Time: 3279.9551 us. Best GFLOPs: 1479.3654
2024-04-30 12:12:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1335: GFLOPs: 1065.1547. Time: 3474.5956 us. Best GFLOPs: 1479.3654
2024-04-30 12:12:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1336: GFLOPs: 1020.7480. Time: 3625.7545 us. Best GFLOPs: 1479.3654
2024-04-30 12:12:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1337: GFLOPs: 1056.5199. Time: 3502.9930 us. Best GFLOPs: 1479.3654
2024-04-30 12:12:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1338: GFLOPs: 947.0684. Time: 3907.8295 us. Best GFLOPs: 1479.3654
2024-04-30 12:12:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1339: GFLOPs: 734.3309. Time: 5039.9371 us. Best GFLOPs: 1479.3654
2024-04-30 12:12:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1340: GFLOPs: 982.4256. Time: 3767.1878 us. Best GFLOPs: 1479.3654
2024-04-30 12:12:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1341: GFLOPs: 998.8400. Time: 3705.2798 us. Best GFLOPs: 1479.3654
2024-04-30 12:12:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1342: GFLOPs: 39.6875. Time: 93253.0540 us. Best GFLOPs: 1479.3654
2024-04-30 12:12:03 [INFO] [task_scheduler.cc:121] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1343: Error in running:
LocalRunner: Timeout, killed after 30 seconds

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(56), T.int64(56), T.int64(256)), "float32"), p1: T.Buffer((T.int64(8), T.int64(1), T.int64(3), T.int64(3), T.int64(256), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(58), T.int64(58), T.int64(256)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused in T.parallel(T.int64(8), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(4), T.int64(2), T.int64(1), T.int64(8), T.int64(1), T.int64(2), T.int64(28), T.int64(28), T.int64(1)):
                with T.block("conv2d_NCHWc_init"):
                    v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                    v_oc_chunk = T.axis.spatial(T.int64(8), oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                    v_oh = T.axis.spatial(T.int64(56), oh_2_init * T.int64(28) + oh_3_init)
                    v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(4) * T.int64(28) + ow_2_init * T.int64(28) + ow_3_init)
                    v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(4) * T.int64(8) + oc_block_2_init + oc_block_3_init)
                    T.reads()
                    T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                    T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                    conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
            for ic_0 in range(T.int64(16)):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(58), T.int64(30)):
                    for ax4_fused in T.vectorized(T.int64(16)):
                        with T.block("data_pad"):
                            v_i0, v_i1, v_i2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                            v_i3 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(4) * T.int64(28) + ax3)
                            v_i4 = T.axis.spatial(T.int64(256), ic_0 * T.int64(16) + ax4_fused)
                            T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                            T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                            data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(57) and T.int64(1) <= v_i3 and v_i3 < T.int64(57), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                for kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(2), T.int64(1), T.int64(8), T.int64(16), T.int64(3), T.int64(3), T.int64(1), T.int64(2), T.int64(28), T.int64(28), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(8), oc_chunk_2 * T.int64(2) + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(56), oh_2 * T.int64(28) + oh_3)
                        v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(4) * T.int64(28) + ow_2 * T.int64(28) + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(4) * T.int64(8) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(16) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)], p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)] * p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block]
        for ax0_ax1_ax2_ax3_ax4_fused_0 in T.parallel(T.int64(12544)):
            for ax0_ax1_ax2_ax3_ax4_fused_1 in T.vectorized(T.int64(64)):
                with T.block("T_relu"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(8), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) // T.int64(100352))
                    v_ax2 = T.axis.spatial(T.int64(56), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(100352) // T.int64(1792))
                    v_ax3 = T.axis.spatial(T.int64(56), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(1792) // T.int64(32))
                    v_ax4 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(32))
                    T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                    T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 4, 2])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 2, 28])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 2, 1, 28])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 4, 8, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[16, 16])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
l65 = sch.sample_compute_location(block=b0, decision=10)
sch.compute_at(block=b0, loop=l65, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b66 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.unroll_explicit")
b67, b68, b69 = sch.get_child_blocks(b66)
l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85 = sch.get_loops(block=b67)
l86 = sch.fuse(l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, preserve_unit_iters=True)
sch.parallel(loop=l86)
l87 = sch.fuse(l85, preserve_unit_iters=True)
sch.vectorize(loop=l87)
l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b68)
l105 = sch.fuse(l88, preserve_unit_iters=True)
sch.parallel(loop=l105)
sch.annotate(block_or_loop=l105, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l105, ann_key="pragma_unroll_explicit", ann_val=1)
l106, l107, l108, l109, l110 = sch.get_loops(block=b69)
l111 = sch.fuse(l106, l107, l108, l109, l110, preserve_unit_iters=True)
l112, l113 = sch.split(loop=l111, factors=[None, 64], preserve_unit_iters=True)
sch.parallel(loop=l112)
sch.vectorize(loop=l113)
b114 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131 = sch.get_loops(block=b114)
b132 = sch.decompose_reduction(block=b114, loop=l116)
2024-04-30 12:12:03 [INFO] [task_scheduler.cc:121] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1344: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(56), T.int64(56), T.int64(256)), "float32"), p1: T.Buffer((T.int64(8), T.int64(1), T.int64(3), T.int64(3), T.int64(256), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(58), T.int64(58), T.int64(256)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused in T.parallel(T.int64(8), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1, ow_1 in T.grid(T.int64(1), T.int64(4), T.int64(4), T.int64(7)):
                for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(9), T.int64(4), T.int64(256)):
                    with T.block("data_pad"):
                        v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                        v_i2 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(4) * T.int64(28) + oh_1 * T.int64(7) + ax2)
                        v_i3 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(4) * T.int64(14) + ow_1 * T.int64(2) + ax3)
                        v_i4 = T.axis.spatial(T.int64(256), ax4)
                        T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                        T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                        data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(57) and T.int64(1) <= v_i3 and v_i3 < T.int64(57), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                for oc_block_1 in range(T.int64(4)):
                    for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(2), T.int64(7), T.int64(2), T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                        for oc_block_3_fused_init in T.vectorized(T.int64(2)):
                            with T.block("conv2d_NCHWc_init"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                                v_oc_chunk = T.axis.spatial(T.int64(8), oc_chunk_1 * T.int64(2) + oc_chunk_2_init + oc_chunk_3_init)
                                v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(4) * T.int64(28) + oh_1 * T.int64(7) + oh_2_init + oh_3_init)
                                v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(4) * T.int64(14) + ow_1 * T.int64(2) + ow_2_init + ow_3_init)
                                v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(8) + oc_block_2_init * T.int64(2) + oc_block_3_fused_init)
                                T.reads()
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                    for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(4), T.int64(1), T.int64(3), T.int64(1), T.int64(2), T.int64(7), T.int64(2), T.int64(4), T.int64(64), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                        for oc_block_3_fused in T.vectorized(T.int64(2)):
                            with T.block("conv2d_NCHWc_update"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                                v_oc_chunk = T.axis.spatial(T.int64(8), oc_chunk_1 * T.int64(2) + oc_chunk_2 + oc_chunk_3)
                                v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(4) * T.int64(28) + oh_1 * T.int64(7) + oh_2 + oh_3)
                                v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(4) * T.int64(14) + ow_1 * T.int64(2) + ow_2 + ow_3)
                                v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(8) + oc_block_2 * T.int64(2) + oc_block_3_fused)
                                v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(64) + ic_1)
                                v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                                v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                                T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)], p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block])
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)] * p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(8), T.int64(28), T.int64(14)):
                for ax4_fused in T.vectorized(T.int64(32)):
                    with T.block("T_relu"):
                        v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                        v_ax2 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(4) * T.int64(28) + ax2)
                        v_ax3 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(4) * T.int64(14) + ax3)
                        v_ax4 = T.axis.spatial(T.int64(32), ax4_fused)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 4, 2, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 4, 7, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[4, 7, 2, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 4, 4, 2])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[4, 64])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=8)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b68)
l85 = sch.fuse(l71, l72, l73, l74, l75, preserve_unit_iters=True)
sch.parallel(loop=l85)
l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107 = sch.get_loops(block=b69)
l108 = sch.fuse(l86, preserve_unit_iters=True)
sch.parallel(loop=l108)
l109 = sch.fuse(l107, preserve_unit_iters=True)
sch.vectorize(loop=l109)
sch.annotate(block_or_loop=l108, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l108, ann_key="pragma_unroll_explicit", ann_val=1)
l110, l111, l112, l113, l114, l115 = sch.get_loops(block=b70)
l116 = sch.fuse(l115, preserve_unit_iters=True)
sch.vectorize(loop=l116)
b117 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139 = sch.get_loops(block=b117)
b140 = sch.decompose_reduction(block=b117, loop=l124)
2024-04-30 12:21:37 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-30 12:21:38 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-30 12:21:43 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 12:21:43 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-30 12:21:55 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 12:22:09 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 12:22:22 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 12:22:35 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 12:22:43 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.8876  0.8797  0.8661  0.8566  0.8566  0.8545  0.8513  0.8487  0.8472  0.8444  0.8436  0.8346  0.8330  0.8246  0.8242  0.8240
[17 : 32]:	0.8217  0.8171  0.8148  0.8116  0.7874  0.7740  0.7705  0.7633  0.7415  0.7407  0.7395  0.7300  0.7287  0.7271  0.7270  0.7255
[33 : 48]:	0.7238  0.7215  0.7159  0.7077  0.7052  0.7047  0.7023  0.7006  0.6943  0.6935  0.6934  0.6837  0.6805  0.6795  0.6787  0.6783
[49 : 64]:	0.6780  0.6754  0.6735  0.6712  0.6697  0.6673  0.6669  0.6646  0.6628  0.6582  0.6566  0.6558  0.6522  0.6514  0.6514  0.6484
2024-04-30 12:22:43 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-30 12:22:44 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-30 12:24:39 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1345: GFLOPs: 1272.7587. Time: 2907.8425 us. Best GFLOPs: 1479.3654
2024-04-30 12:24:39 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1346: GFLOPs: 1274.0612. Time: 2904.8696 us. Best GFLOPs: 1479.3654
2024-04-30 12:24:39 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1347: GFLOPs: 1351.4502. Time: 2738.5262 us. Best GFLOPs: 1479.3654
2024-04-30 12:24:39 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1348: GFLOPs: 1319.4369. Time: 2804.9707 us. Best GFLOPs: 1479.3654
2024-04-30 12:24:39 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1349: GFLOPs: 1419.7297. Time: 2606.8215 us. Best GFLOPs: 1479.3654
2024-04-30 12:24:39 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1350: GFLOPs: 1224.6067. Time: 3022.1799 us. Best GFLOPs: 1479.3654
2024-04-30 12:24:39 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1351: GFLOPs: 1320.4485. Time: 2802.8218 us. Best GFLOPs: 1479.3654
2024-04-30 12:24:39 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1352: GFLOPs: 1303.3050. Time: 2839.6896 us. Best GFLOPs: 1479.3654
2024-04-30 12:24:39 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1353: GFLOPs: 1383.8162. Time: 2674.4749 us. Best GFLOPs: 1479.3654
2024-04-30 12:24:39 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1354: GFLOPs: 1281.7313. Time: 2887.4865 us. Best GFLOPs: 1479.3654
2024-04-30 12:24:39 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1355: GFLOPs: 1346.0981. Time: 2749.4145 us. Best GFLOPs: 1479.3654
2024-04-30 12:24:39 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1356: GFLOPs: 1156.5582. Time: 3199.9962 us. Best GFLOPs: 1479.3654
2024-04-30 12:24:39 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1357: GFLOPs: 1261.2297. Time: 2934.4233 us. Best GFLOPs: 1479.3654
2024-04-30 12:24:39 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1358: GFLOPs: 1293.5992. Time: 2860.9957 us. Best GFLOPs: 1479.3654
2024-04-30 12:24:39 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1359: GFLOPs: 1303.0526. Time: 2840.2396 us. Best GFLOPs: 1479.3654
2024-04-30 12:24:39 [INFO] [task_scheduler.cc:121] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1360: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(56), T.int64(56), T.int64(256)), "float32"), p1: T.Buffer((T.int64(8), T.int64(1), T.int64(3), T.int64(3), T.int64(256), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(58), T.int64(58), T.int64(256)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused in T.parallel(T.int64(224), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(16), T.int64(3), T.int64(256)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(56) // T.int64(14) * T.int64(14) + ax2)
                    v_i3 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(56) * T.int64(14) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(14) + ax3)
                    v_i4 = T.axis.spatial(T.int64(256), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(57) and T.int64(1) <= v_i3 and v_i3 < T.int64(57), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oc_block_1 in range(T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(14), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(8), oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(56) // T.int64(14) * T.int64(14) + oh_2_init * T.int64(14) + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(56) * T.int64(14) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(14) + ow_2_init + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(128), T.int64(1), T.int64(3), T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(32), T.int64(2), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(14), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(8), oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(56) // T.int64(14) * T.int64(14) + oh_2 * T.int64(14) + oh_3)
                        v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(56) * T.int64(14) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(14) + ow_2 + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(2) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)], p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)] * p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block]
                for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(8), T.int64(14)):
                    for ax3_ax4_fused in T.vectorized(T.int64(32)):
                        with T.block("T_relu"):
                            v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                            v_ax2 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(56) // T.int64(14) * T.int64(14) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(56) * T.int64(14) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(14))
                            v_ax4 = T.axis.spatial(T.int64(32), ax3_ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 8, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 4, 1, 14])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[4, 14, 1, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 32, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[128, 2])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=8)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b68)
l85 = sch.fuse(l71, l72, l73, l74, l75, l76, l77, l78, l79, preserve_unit_iters=True)
sch.parallel(loop=l85)
l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l86, preserve_unit_iters=True)
sch.parallel(loop=l104)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109, l110, l111 = sch.get_loops(block=b70)
l112 = sch.fuse(l110, l111, preserve_unit_iters=True)
sch.vectorize(loop=l112)
b113 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131 = sch.get_loops(block=b113)
b132 = sch.decompose_reduction(block=b113, loop=l116)
2024-04-30 12:24:39 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1361: GFLOPs: 1279.3554. Time: 2892.8488 us. Best GFLOPs: 1479.3654
2024-04-30 12:24:39 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1362: GFLOPs: 1252.4230. Time: 2955.0572 us. Best GFLOPs: 1479.3654
2024-04-30 12:24:39 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1363: GFLOPs: 1268.2324. Time: 2918.2204 us. Best GFLOPs: 1479.3654
2024-04-30 12:24:39 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1364: GFLOPs: 1311.3490. Time: 2822.2707 us. Best GFLOPs: 1479.3654
2024-04-30 12:24:39 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1365: GFLOPs: 1312.1948. Time: 2820.4515 us. Best GFLOPs: 1479.3654
2024-04-30 12:24:39 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1366: GFLOPs: 1026.7786. Time: 3604.4594 us. Best GFLOPs: 1479.3654
2024-04-30 12:24:39 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1367: GFLOPs: 1109.1280. Time: 3336.8393 us. Best GFLOPs: 1479.3654
2024-04-30 12:24:39 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1368: GFLOPs: 1159.0799. Time: 3193.0343 us. Best GFLOPs: 1479.3654
2024-04-30 12:24:39 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1369: GFLOPs: 1088.3949. Time: 3400.4034 us. Best GFLOPs: 1479.3654
2024-04-30 12:24:39 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1370: GFLOPs: 1078.5083. Time: 3431.5746 us. Best GFLOPs: 1479.3654
2024-04-30 12:24:39 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1371: GFLOPs: 1069.4323. Time: 3460.6977 us. Best GFLOPs: 1479.3654
2024-04-30 12:24:39 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1372: GFLOPs: 1082.8370. Time: 3417.8567 us. Best GFLOPs: 1479.3654
2024-04-30 12:24:39 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1373: GFLOPs: 1190.6315. Time: 3108.4192 us. Best GFLOPs: 1479.3654
2024-04-30 12:24:39 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1374: GFLOPs: 1053.9044. Time: 3511.6866 us. Best GFLOPs: 1479.3654
2024-04-30 12:24:39 [INFO] [task_scheduler.cc:121] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1375: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(56), T.int64(56), T.int64(256)), "float32"), p1: T.Buffer((T.int64(8), T.int64(1), T.int64(3), T.int64(3), T.int64(256), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(58), T.int64(58), T.int64(256)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused in T.parallel(T.int64(448), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(16), T.int64(3), T.int64(256)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(224) // T.int64(56) * T.int64(14) + ax2)
                    v_i3 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(56) + ax3)
                    v_i4 = T.axis.spatial(T.int64(256), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(57) and T.int64(1) <= v_i3 and v_i3 < T.int64(57), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oc_block_1 in range(T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(14), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(8), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(224) * T.int64(4) + oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(224) // T.int64(56) * T.int64(14) + oh_2_init * T.int64(14) + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(56) + ow_2_init + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(128), T.int64(1), T.int64(3), T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(32), T.int64(2), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(14), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(8), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(224) * T.int64(4) + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(224) // T.int64(56) * T.int64(14) + oh_2 * T.int64(14) + oh_3)
                        v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(56) + ow_2 + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(2) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)], p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)] * p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block]
                for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(4), T.int64(14)):
                    for ax3_ax4_fused in T.vectorized(T.int64(32)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(8), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(224) * T.int64(4) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(224) // T.int64(56) * T.int64(14) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(56))
                            v_ax4 = T.axis.spatial(T.int64(32), ax3_ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 2, 4, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 4, 1, 14])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 56, 1, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 32, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[128, 2])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=8)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b68)
l85 = sch.fuse(l71, l72, l73, l74, l75, l76, l77, l78, l79, preserve_unit_iters=True)
sch.parallel(loop=l85)
l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l86, preserve_unit_iters=True)
sch.parallel(loop=l104)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109, l110, l111 = sch.get_loops(block=b70)
l112 = sch.fuse(l110, l111, preserve_unit_iters=True)
sch.vectorize(loop=l112)
b113 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131 = sch.get_loops(block=b113)
b132 = sch.decompose_reduction(block=b113, loop=l116)
2024-04-30 12:24:39 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1376: GFLOPs: 783.9949. Time: 4720.6709 us. Best GFLOPs: 1479.3654
2024-04-30 12:24:39 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1377: GFLOPs: 1169.3995. Time: 3164.8566 us. Best GFLOPs: 1479.3654
2024-04-30 12:24:39 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1378: GFLOPs: 1061.2523. Time: 3487.3723 us. Best GFLOPs: 1479.3654
2024-04-30 12:24:39 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1379: GFLOPs: 1075.6397. Time: 3440.7261 us. Best GFLOPs: 1479.3654
2024-04-30 12:24:39 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1380: GFLOPs: 982.7467. Time: 3765.9569 us. Best GFLOPs: 1479.3654
2024-04-30 12:24:39 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1381: GFLOPs: 1061.5845. Time: 3486.2809 us. Best GFLOPs: 1479.3654
2024-04-30 12:24:39 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1382: GFLOPs: 1116.8108. Time: 3313.8844 us. Best GFLOPs: 1479.3654
2024-04-30 12:24:39 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1383: GFLOPs: 1180.9623. Time: 3133.8695 us. Best GFLOPs: 1479.3654
2024-04-30 12:24:39 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1384: GFLOPs: 1034.6182. Time: 3577.1475 us. Best GFLOPs: 1479.3654
2024-04-30 12:24:39 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1385: GFLOPs: 1036.8099. Time: 3569.5857 us. Best GFLOPs: 1479.3654
2024-04-30 12:24:39 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1386: GFLOPs: 1025.8139. Time: 3607.8491 us. Best GFLOPs: 1479.3654
2024-04-30 12:24:39 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1387: GFLOPs: 1031.9378. Time: 3586.4388 us. Best GFLOPs: 1479.3654
2024-04-30 12:24:39 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1388: GFLOPs: 1063.9207. Time: 3478.6256 us. Best GFLOPs: 1479.3654
2024-04-30 12:24:39 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1389: GFLOPs: 1293.9998. Time: 2860.1100 us. Best GFLOPs: 1479.3654
2024-04-30 12:24:39 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1390: GFLOPs: 1065.7218. Time: 3472.7466 us. Best GFLOPs: 1479.3654
2024-04-30 12:24:39 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1391: GFLOPs: 1132.7644. Time: 3267.2123 us. Best GFLOPs: 1479.3654
2024-04-30 12:24:39 [INFO] [task_scheduler.cc:121] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1392: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(56), T.int64(56), T.int64(256)), "float32"), p1: T.Buffer((T.int64(8), T.int64(1), T.int64(3), T.int64(3), T.int64(256), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(58), T.int64(58), T.int64(256)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused in T.parallel(T.int64(224), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(8), T.int64(2), T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(8), oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(112) * T.int64(28) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(2) * T.int64(14) + oh_2_init * T.int64(7) + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(112) // T.int64(2) + ow_1 + ow_2_init + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0 in range(T.int64(128)):
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(16), T.int64(3)):
                        for ax4_fused in T.vectorized(T.int64(2)):
                            with T.block("data_pad"):
                                v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                                v_i2 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(112) * T.int64(28) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(2) * T.int64(14) + ax2)
                                v_i3 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(112) // T.int64(2) + ax3)
                                v_i4 = T.axis.spatial(T.int64(256), ic_0 * T.int64(2) + ax4_fused)
                                T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                                T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                                data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(57) and T.int64(1) <= v_i3 and v_i3 < T.int64(57), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                    for kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(3), T.int64(3), T.int64(1), T.int64(8), T.int64(2), T.int64(1), T.int64(32), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(1)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(8), oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(112) * T.int64(28) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(2) * T.int64(14) + oh_2 * T.int64(7) + oh_3)
                            v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(112) // T.int64(2) + ow_1 + ow_2 + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2 + oc_block_3)
                            v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(2) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)], p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)] * p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block]
                for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(8), T.int64(14)):
                    for ax3_ax4_fused in T.vectorized(T.int64(32)):
                        with T.block("T_relu"):
                            v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                            v_ax2 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(112) * T.int64(28) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(2) * T.int64(14) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(112) // T.int64(2))
                            v_ax4 = T.axis.spatial(T.int64(32), ax3_ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 8, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 2, 2, 7])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[56, 1, 1, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 32, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[128, 2])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=112)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=10)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86 = sch.get_loops(block=b68)
l87 = sch.fuse(l71, l72, l73, l74, l75, l76, l77, l78, preserve_unit_iters=True)
sch.parallel(loop=l87)
l88 = sch.fuse(l86, preserve_unit_iters=True)
sch.vectorize(loop=l88)
l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107 = sch.get_loops(block=b69)
l108 = sch.fuse(l89, preserve_unit_iters=True)
sch.parallel(loop=l108)
sch.annotate(block_or_loop=l108, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l108, ann_key="pragma_unroll_explicit", ann_val=1)
l109, l110, l111, l112, l113, l114, l115, l116 = sch.get_loops(block=b70)
l117 = sch.fuse(l115, l116, preserve_unit_iters=True)
sch.vectorize(loop=l117)
b118 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137 = sch.get_loops(block=b118)
b138 = sch.decompose_reduction(block=b118, loop=l122)
2024-04-30 12:24:39 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1393: GFLOPs: 985.5092. Time: 3755.4004 us. Best GFLOPs: 1479.3654
2024-04-30 12:24:39 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1394: GFLOPs: 1023.8330. Time: 3614.8296 us. Best GFLOPs: 1479.3654
2024-04-30 12:24:39 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1395: GFLOPs: 584.1621. Time: 6335.5391 us. Best GFLOPs: 1479.3654
2024-04-30 12:24:39 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1396: GFLOPs: 990.2963. Time: 3737.2468 us. Best GFLOPs: 1479.3654
2024-04-30 12:24:39 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1397: GFLOPs: 718.3331. Time: 5152.1805 us. Best GFLOPs: 1479.3654
2024-04-30 12:24:39 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1398: GFLOPs: 852.4194. Time: 4341.7380 us. Best GFLOPs: 1479.3654
2024-04-30 12:24:39 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1399: GFLOPs: 878.2468. Time: 4214.0566 us. Best GFLOPs: 1479.3654
2024-04-30 12:24:39 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1400: GFLOPs: 1025.5549. Time: 3608.7602 us. Best GFLOPs: 1479.3654
2024-04-30 12:24:39 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1401: GFLOPs: 453.3241. Time: 8164.0973 us. Best GFLOPs: 1479.3654
2024-04-30 12:24:39 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1402: GFLOPs: 591.7698. Time: 6254.0899 us. Best GFLOPs: 1479.3654
2024-04-30 12:24:39 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1403: GFLOPs: 930.3237. Time: 3978.1657 us. Best GFLOPs: 1479.3654
2024-04-30 12:24:39 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1404: GFLOPs: 703.5236. Time: 5260.6362 us. Best GFLOPs: 1479.3654
2024-04-30 12:24:39 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1405: GFLOPs: 597.2359. Time: 6196.8512 us. Best GFLOPs: 1479.3654
2024-04-30 12:24:39 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1406: GFLOPs: 5.5235. Time: 670039.3627 us. Best GFLOPs: 1479.3654
2024-04-30 12:24:39 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1407: GFLOPs: 89.4216. Time: 41387.9850 us. Best GFLOPs: 1479.3654
2024-04-30 12:24:39 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1408: GFLOPs: 32.2782. Time: 114658.9010 us. Best GFLOPs: 1479.3654
2024-04-30 12:34:51 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-30 12:34:52 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-30 12:34:56 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 12:34:56 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-30 12:35:09 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 12:35:23 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 12:35:36 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 12:35:49 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 12:35:57 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.8796  0.8740  0.8561  0.8508  0.8507  0.8469  0.8393  0.8340  0.8293  0.8253  0.8253  0.8219  0.8199  0.7992  0.7962  0.7962
[17 : 32]:	0.7826  0.7825  0.7747  0.7745  0.7697  0.7623  0.7557  0.7425  0.7397  0.7397  0.7376  0.7344  0.7301  0.7295  0.7269  0.7264
[33 : 48]:	0.7264  0.7257  0.7244  0.7210  0.7209  0.7199  0.7193  0.7158  0.7095  0.7080  0.7023  0.6964  0.6933  0.6872  0.6870  0.6870
[49 : 64]:	0.6840  0.6805  0.6788  0.6765  0.6749  0.6738  0.6732  0.6714  0.6714  0.6679  0.6633  0.6631  0.6625  0.6608  0.6596  0.6583
2024-04-30 12:35:57 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-30 12:35:57 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-30 12:38:32 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1409: GFLOPs: 1426.3243. Time: 2594.7687 us. Best GFLOPs: 1479.3654
2024-04-30 12:38:32 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1410: GFLOPs: 1233.2212. Time: 3001.0690 us. Best GFLOPs: 1479.3654
2024-04-30 12:38:32 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1411: GFLOPs: 1257.4793. Time: 2943.1750 us. Best GFLOPs: 1479.3654
2024-04-30 12:38:32 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1412: GFLOPs: 1230.7630. Time: 3007.0629 us. Best GFLOPs: 1479.3654
2024-04-30 12:38:32 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1413: GFLOPs: 1337.0445. Time: 2768.0319 us. Best GFLOPs: 1479.3654
2024-04-30 12:38:32 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1414: GFLOPs: 1138.2092. Time: 3251.5830 us. Best GFLOPs: 1479.3654
2024-04-30 12:38:32 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1415: GFLOPs: 1378.3721. Time: 2685.0383 us. Best GFLOPs: 1479.3654
2024-04-30 12:38:32 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1416: GFLOPs: 1142.3729. Time: 3239.7318 us. Best GFLOPs: 1479.3654
2024-04-30 12:38:32 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1417: GFLOPs: 1261.7244. Time: 2933.2728 us. Best GFLOPs: 1479.3654
2024-04-30 12:38:32 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1418: GFLOPs: 1176.2503. Time: 3146.4238 us. Best GFLOPs: 1479.3654
2024-04-30 12:38:32 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1419: GFLOPs: 1257.2027. Time: 2943.8226 us. Best GFLOPs: 1479.3654
2024-04-30 12:38:32 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1420: GFLOPs: 1291.6497. Time: 2865.3138 us. Best GFLOPs: 1479.3654
2024-04-30 12:38:32 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1421: GFLOPs: 1359.7221. Time: 2721.8662 us. Best GFLOPs: 1479.3654
2024-04-30 12:38:32 [INFO] [task_scheduler.cc:121] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1422: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(56), T.int64(56), T.int64(256)), "float32"), p1: T.Buffer((T.int64(8), T.int64(1), T.int64(3), T.int64(3), T.int64(256), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(58), T.int64(58), T.int64(256)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused in T.parallel(T.int64(896), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(16), T.int64(3), T.int64(256)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(224) // T.int64(112) * T.int64(28) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(2) * T.int64(14) + ax2)
                    v_i3 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(112) // T.int64(2) + ax3)
                    v_i4 = T.axis.spatial(T.int64(256), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(57) and T.int64(1) <= v_i3 and v_i3 < T.int64(57), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(14), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(8), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(224) * T.int64(2) + oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(224) // T.int64(112) * T.int64(28) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(2) * T.int64(14) + oh_2_init * T.int64(14) + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(112) // T.int64(2) + ow_1 + ow_2_init + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(128), T.int64(1), T.int64(3), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(32), T.int64(2), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(14), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(8), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(224) * T.int64(2) + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(224) // T.int64(112) * T.int64(28) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(2) * T.int64(14) + oh_2 * T.int64(14) + oh_3)
                        v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(112) // T.int64(2) + ow_1 + ow_2 + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(2) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)], p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)] * p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block]
                for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(2), T.int64(14)):
                    for ax3_ax4_fused in T.vectorized(T.int64(32)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(8), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(224) * T.int64(2) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(224) // T.int64(112) * T.int64(28) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(2) * T.int64(14) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(112) // T.int64(2))
                            v_ax4 = T.axis.spatial(T.int64(32), ax3_ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[4, 1, 2, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 2, 1, 14])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[56, 1, 1, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 32, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[128, 2])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=7)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83 = sch.get_loops(block=b68)
l84 = sch.fuse(l71, l72, l73, l74, l75, l76, l77, l78, preserve_unit_iters=True)
sch.parallel(loop=l84)
l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l85, preserve_unit_iters=True)
sch.parallel(loop=l104)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109, l110, l111, l112 = sch.get_loops(block=b70)
l113 = sch.fuse(l111, l112, preserve_unit_iters=True)
sch.vectorize(loop=l113)
b114 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133 = sch.get_loops(block=b114)
b134 = sch.decompose_reduction(block=b114, loop=l118)
2024-04-30 12:38:32 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1423: GFLOPs: 1151.9119. Time: 3212.9035 us. Best GFLOPs: 1479.3654
2024-04-30 12:38:32 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1424: GFLOPs: 1277.8983. Time: 2896.1472 us. Best GFLOPs: 1479.3654
2024-04-30 12:38:32 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1425: GFLOPs: 1047.6756. Time: 3532.5646 us. Best GFLOPs: 1479.3654
2024-04-30 12:38:32 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1426: GFLOPs: 1152.0541. Time: 3212.5069 us. Best GFLOPs: 1479.3654
2024-04-30 12:38:32 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1427: GFLOPs: 1113.7919. Time: 3322.8665 us. Best GFLOPs: 1479.3654
2024-04-30 12:38:32 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1428: GFLOPs: 1185.1689. Time: 3122.7463 us. Best GFLOPs: 1479.3654
2024-04-30 12:38:32 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1429: GFLOPs: 1109.9297. Time: 3334.4290 us. Best GFLOPs: 1479.3654
2024-04-30 12:38:32 [INFO] [task_scheduler.cc:121] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1430: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(56), T.int64(56), T.int64(256)), "float32"), p1: T.Buffer((T.int64(8), T.int64(1), T.int64(3), T.int64(3), T.int64(256), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(58), T.int64(58), T.int64(256)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused in T.parallel(T.int64(896), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(16), T.int64(3), T.int64(256)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(224) // T.int64(112) * T.int64(28) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(4) // T.int64(2) * T.int64(14) + ax2)
                    v_i3 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(2) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(112) // T.int64(4) * T.int64(2) + ax3)
                    v_i4 = T.axis.spatial(T.int64(256), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(57) and T.int64(1) <= v_i3 and v_i3 < T.int64(57), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oc_block_1 in range(T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(14), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(8), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(224) * T.int64(2) + oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(224) // T.int64(112) * T.int64(28) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(4) // T.int64(2) * T.int64(14) + oh_2_init * T.int64(14) + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(112) // T.int64(4) * T.int64(2) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(2) + ow_2_init + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(128), T.int64(1), T.int64(3), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(32), T.int64(2), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(14), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(8), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(224) * T.int64(2) + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(224) // T.int64(112) * T.int64(28) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(4) // T.int64(2) * T.int64(14) + oh_2 * T.int64(14) + oh_3)
                        v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(112) // T.int64(4) * T.int64(2) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(2) + ow_2 + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(2) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)], p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)] * p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block]
                for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(2), T.int64(14)):
                    for ax3_ax4_fused in T.vectorized(T.int64(32)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(8), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(224) * T.int64(2) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(224) // T.int64(112) * T.int64(28) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(4) // T.int64(2) * T.int64(14) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(112) // T.int64(4) * T.int64(2) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(2))
                            v_ax4 = T.axis.spatial(T.int64(32), ax3_ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[4, 1, 2, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 2, 1, 14])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[28, 2, 1, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 32, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[128, 2])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=8)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b68)
l85 = sch.fuse(l71, l72, l73, l74, l75, l76, l77, l78, l79, preserve_unit_iters=True)
sch.parallel(loop=l85)
l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l86, preserve_unit_iters=True)
sch.parallel(loop=l104)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109, l110, l111 = sch.get_loops(block=b70)
l112 = sch.fuse(l110, l111, preserve_unit_iters=True)
sch.vectorize(loop=l112)
b113 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131 = sch.get_loops(block=b113)
b132 = sch.decompose_reduction(block=b113, loop=l116)
2024-04-30 12:38:32 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1431: GFLOPs: 1044.1809. Time: 3544.3875 us. Best GFLOPs: 1479.3654
2024-04-30 12:38:32 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1432: GFLOPs: 1051.8574. Time: 3518.5205 us. Best GFLOPs: 1479.3654
2024-04-30 12:38:32 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1433: GFLOPs: 157.7313. Time: 23463.8400 us. Best GFLOPs: 1479.3654
2024-04-30 12:38:32 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1434: GFLOPs: 157.0398. Time: 23567.1578 us. Best GFLOPs: 1479.3654
2024-04-30 12:38:32 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1435: GFLOPs: 1075.3278. Time: 3441.7242 us. Best GFLOPs: 1479.3654
2024-04-30 12:38:32 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1436: GFLOPs: 1063.6818. Time: 3479.4067 us. Best GFLOPs: 1479.3654
2024-04-30 12:38:32 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1437: GFLOPs: 1075.7276. Time: 3440.4452 us. Best GFLOPs: 1479.3654
2024-04-30 12:38:32 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1438: GFLOPs: 1087.0487. Time: 3404.6145 us. Best GFLOPs: 1479.3654
2024-04-30 12:38:32 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1439: GFLOPs: 1034.9915. Time: 3575.8572 us. Best GFLOPs: 1479.3654
2024-04-30 12:38:32 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1440: GFLOPs: 713.1315. Time: 5189.7609 us. Best GFLOPs: 1479.3654
2024-04-30 12:38:32 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1441: GFLOPs: 573.7156. Time: 6450.9000 us. Best GFLOPs: 1479.3654
2024-04-30 12:38:32 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1442: GFLOPs: 1049.2120. Time: 3527.3917 us. Best GFLOPs: 1479.3654
2024-04-30 12:38:32 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1443: GFLOPs: 453.0380. Time: 8169.2520 us. Best GFLOPs: 1479.3654
2024-04-30 12:38:32 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1444: GFLOPs: 1023.6835. Time: 3615.3575 us. Best GFLOPs: 1479.3654
2024-04-30 12:38:32 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1445: GFLOPs: 929.6497. Time: 3981.0499 us. Best GFLOPs: 1479.3654
2024-04-30 12:38:32 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1446: GFLOPs: 954.0353. Time: 3879.2921 us. Best GFLOPs: 1479.3654
2024-04-30 12:38:32 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1447: GFLOPs: 1042.4429. Time: 3550.2968 us. Best GFLOPs: 1479.3654
2024-04-30 12:38:32 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1448: GFLOPs: 1060.3754. Time: 3490.2561 us. Best GFLOPs: 1479.3654
2024-04-30 12:38:32 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1449: GFLOPs: 1102.1791. Time: 3357.8770 us. Best GFLOPs: 1479.3654
2024-04-30 12:38:32 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1450: GFLOPs: 1044.7901. Time: 3542.3208 us. Best GFLOPs: 1479.3654
2024-04-30 12:38:32 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1451: GFLOPs: 853.7456. Time: 4334.9936 us. Best GFLOPs: 1479.3654
2024-04-30 12:38:32 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1452: GFLOPs: 810.1701. Time: 4568.1539 us. Best GFLOPs: 1479.3654
2024-04-30 12:38:32 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1453: GFLOPs: 1024.3816. Time: 3612.8938 us. Best GFLOPs: 1479.3654
2024-04-30 12:38:32 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1454: GFLOPs: 971.3737. Time: 3810.0495 us. Best GFLOPs: 1479.3654
2024-04-30 12:38:32 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1455: GFLOPs: 866.7176. Time: 4270.1127 us. Best GFLOPs: 1479.3654
2024-04-30 12:38:32 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1456: GFLOPs: 997.1473. Time: 3711.5698 us. Best GFLOPs: 1479.3654
2024-04-30 12:38:32 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1457: GFLOPs: 560.9594. Time: 6597.5927 us. Best GFLOPs: 1479.3654
2024-04-30 12:38:32 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1458: GFLOPs: 1074.4341. Time: 3444.5871 us. Best GFLOPs: 1479.3654
2024-04-30 12:38:32 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1459: GFLOPs: 1027.1333. Time: 3603.2147 us. Best GFLOPs: 1479.3654
2024-04-30 12:38:32 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1460: GFLOPs: 912.5139. Time: 4055.8084 us. Best GFLOPs: 1479.3654
2024-04-30 12:38:32 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1461: GFLOPs: 1040.9787. Time: 3555.2907 us. Best GFLOPs: 1479.3654
2024-04-30 12:38:32 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1462: GFLOPs: 1006.7303. Time: 3676.2395 us. Best GFLOPs: 1479.3654
2024-04-30 12:38:32 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1463: GFLOPs: 817.6711. Time: 4526.2477 us. Best GFLOPs: 1479.3654
2024-04-30 12:38:32 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1464: GFLOPs: 1191.0463. Time: 3107.3367 us. Best GFLOPs: 1479.3654
2024-04-30 12:38:32 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1465: GFLOPs: 940.6240. Time: 3934.6029 us. Best GFLOPs: 1479.3654
2024-04-30 12:38:32 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1466: GFLOPs: 822.3768. Time: 4500.3481 us. Best GFLOPs: 1479.3654
2024-04-30 12:38:32 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1467: GFLOPs: 900.8108. Time: 4108.5005 us. Best GFLOPs: 1479.3654
2024-04-30 12:38:32 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1468: GFLOPs: 793.8628. Time: 4661.9914 us. Best GFLOPs: 1479.3654
2024-04-30 12:38:32 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1469: GFLOPs: 944.4981. Time: 3918.4638 us. Best GFLOPs: 1479.3654
2024-04-30 12:38:32 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1470: GFLOPs: 18.3144. Time: 202080.3017 us. Best GFLOPs: 1479.3654
2024-04-30 12:38:32 [INFO] [task_scheduler.cc:121] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1471: Error in running:
LocalRunner: Timeout, killed after 30 seconds

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(56), T.int64(56), T.int64(256)), "float32"), p1: T.Buffer((T.int64(8), T.int64(1), T.int64(3), T.int64(3), T.int64(256), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(58), T.int64(58), T.int64(256)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_fused_fused_fused in T.parallel(T.int64(4)):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(58), T.int64(16), T.int64(256)):
                with T.block("data_pad"):
                    v_i0, v_i1, v_i2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                    v_i3 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_fused_fused_fused * T.int64(14) + ax3)
                    v_i4 = T.axis.spatial(T.int64(256), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(57) and T.int64(1) <= v_i3 and v_i3 < T.int64(57), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oc_block_0, n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(4), T.int64(1), T.int64(2), T.int64(1), T.int64(14), T.int64(2)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(2), T.int64(2), T.int64(1), T.int64(2), T.int64(1), T.int64(2), T.int64(28), T.int64(1)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(2)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(8), oc_chunk_1 * T.int64(4) + oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(56), oh_1 * T.int64(56) + oh_2_init * T.int64(28) + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_fused_fused_fused * T.int64(14) + ow_1 + ow_2_init + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(32), oc_block_0 * T.int64(8) + oc_block_1 * T.int64(4) + oc_block_2_init * T.int64(2) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(64), T.int64(3), T.int64(1), T.int64(1), T.int64(2), T.int64(2), T.int64(1), T.int64(2), T.int64(4), T.int64(1), T.int64(3), T.int64(1), T.int64(2), T.int64(28), T.int64(1)):
                    for oc_block_3_fused in T.vectorized(T.int64(2)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(8), oc_chunk_1 * T.int64(4) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(56), oh_1 * T.int64(56) + oh_2 * T.int64(28) + oh_3)
                            v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_fused_fused_fused * T.int64(14) + ow_1 + ow_2 + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(32), oc_block_0 * T.int64(8) + oc_block_1 * T.int64(4) + oc_block_2 * T.int64(2) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(4) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)], p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)] * p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(4), T.int64(56), T.int64(1)):
                    for ax4_fused in T.vectorized(T.int64(4)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(8), oc_chunk_1 * T.int64(4) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(56), ax2)
                            v_ax3 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_fused_fused_fused * T.int64(14) + ow_1 + ax3)
                            v_ax4 = T.axis.spatial(T.int64(32), oc_block_0 * T.int64(8) + oc_block_1 * T.int64(4) + ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 2, 2, 2])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 2, 28])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[4, 14, 1, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[4, 2, 2, 2])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[64, 4])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=3)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79 = sch.get_loops(block=b68)
l80 = sch.fuse(l71, l72, l73, l74, preserve_unit_iters=True)
sch.parallel(loop=l80)
l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l81, preserve_unit_iters=True)
sch.parallel(loop=l104)
l105 = sch.fuse(l103, preserve_unit_iters=True)
sch.vectorize(loop=l105)
l106, l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117 = sch.get_loops(block=b70)
l118 = sch.fuse(l106, preserve_unit_iters=True)
sch.parallel(loop=l118)
l119 = sch.fuse(l117, preserve_unit_iters=True)
sch.vectorize(loop=l119)
b120 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141, l142, l143 = sch.get_loops(block=b120)
b144 = sch.decompose_reduction(block=b120, loop=l128)
2024-04-30 12:38:32 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1472: GFLOPs: 4.9217. Time: 751973.8100 us. Best GFLOPs: 1479.3654
2024-04-30 12:51:14 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-30 12:51:16 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-30 12:51:20 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 12:51:20 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-30 12:51:33 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 12:51:46 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 12:52:00 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 12:52:13 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 12:52:21 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.8917  0.8857  0.8857  0.8801  0.8781  0.8647  0.8636  0.8604  0.8569  0.8547  0.8531  0.8455  0.8365  0.8344  0.8256  0.8253
[17 : 32]:	0.8133  0.8071  0.8065  0.8011  0.7996  0.7996  0.7972  0.7921  0.7761  0.7758  0.7731  0.7731  0.7690  0.7650  0.7617  0.7613
[33 : 48]:	0.7428  0.7318  0.7318  0.7284  0.7284  0.7220  0.7204  0.7185  0.7182  0.7181  0.7178  0.7178  0.7146  0.7146  0.7129  0.7124
[49 : 64]:	0.7109  0.7099  0.7077  0.7062  0.7062  0.7013  0.7013  0.7013  0.7000  0.6994  0.6994  0.6932  0.6912  0.6902  0.6893  0.6893
2024-04-30 12:52:22 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-30 12:52:22 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-30 12:54:39 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1473: GFLOPs: 1261.9261. Time: 2932.8039 us. Best GFLOPs: 1479.3654
2024-04-30 12:54:39 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1474: GFLOPs: 1348.9120. Time: 2743.6791 us. Best GFLOPs: 1479.3654
2024-04-30 12:54:39 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1475: GFLOPs: 1337.0602. Time: 2767.9992 us. Best GFLOPs: 1479.3654
2024-04-30 12:54:39 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1476: GFLOPs: 1356.4995. Time: 2728.3326 us. Best GFLOPs: 1479.3654
2024-04-30 12:54:39 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1477: GFLOPs: 1404.1383. Time: 2635.7672 us. Best GFLOPs: 1479.3654
2024-04-30 12:54:39 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1478: GFLOPs: 1244.8624. Time: 2973.0047 us. Best GFLOPs: 1479.3654
2024-04-30 12:54:39 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1479: GFLOPs: 1245.0537. Time: 2972.5478 us. Best GFLOPs: 1479.3654
2024-04-30 12:54:39 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1480: GFLOPs: 1249.2757. Time: 2962.5019 us. Best GFLOPs: 1479.3654
2024-04-30 12:54:39 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1481: GFLOPs: 1324.0470. Time: 2795.2042 us. Best GFLOPs: 1479.3654
2024-04-30 12:54:39 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1482: GFLOPs: 1223.2457. Time: 3025.5425 us. Best GFLOPs: 1479.3654
2024-04-30 12:54:39 [INFO] [task_scheduler.cc:121] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1483: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(56), T.int64(56), T.int64(256)), "float32"), p1: T.Buffer((T.int64(8), T.int64(1), T.int64(3), T.int64(3), T.int64(256), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(58), T.int64(58), T.int64(256)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused in T.parallel(T.int64(448), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(16), T.int64(3), T.int64(256)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(224) * T.int64(28) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(28) // T.int64(14) * T.int64(14) + ax2)
                    v_i3 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(224) // T.int64(56) * T.int64(14) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(14) + ax3)
                    v_i4 = T.axis.spatial(T.int64(256), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(57) and T.int64(1) <= v_i3 and v_i3 < T.int64(57), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oc_block_1 in range(T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(14), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(8), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(56) // T.int64(28) * T.int64(4) + oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(224) * T.int64(28) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(28) // T.int64(14) * T.int64(14) + oh_2_init * T.int64(14) + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(224) // T.int64(56) * T.int64(14) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(14) + ow_2_init + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(128), T.int64(1), T.int64(3), T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(32), T.int64(2), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(14), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(8), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(56) // T.int64(28) * T.int64(4) + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(224) * T.int64(28) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(28) // T.int64(14) * T.int64(14) + oh_2 * T.int64(14) + oh_3)
                        v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(224) // T.int64(56) * T.int64(14) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(14) + ow_2 + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(2) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)], p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)] * p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block]
                for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(4), T.int64(14)):
                    for ax3_ax4_fused in T.vectorized(T.int64(32)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(8), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(56) // T.int64(28) * T.int64(4) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(224) * T.int64(28) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(28) // T.int64(14) * T.int64(14) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(224) // T.int64(56) * T.int64(14) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(14))
                            v_ax4 = T.axis.spatial(T.int64(32), ax3_ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 2, 4, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 2, 1, 14])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[4, 14, 1, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 32, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[128, 2])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=8)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b68)
l85 = sch.fuse(l71, l72, l73, l74, l75, l76, l77, l78, l79, preserve_unit_iters=True)
sch.parallel(loop=l85)
l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l86, preserve_unit_iters=True)
sch.parallel(loop=l104)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109, l110, l111 = sch.get_loops(block=b70)
l112 = sch.fuse(l110, l111, preserve_unit_iters=True)
sch.vectorize(loop=l112)
b113 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131 = sch.get_loops(block=b113)
b132 = sch.decompose_reduction(block=b113, loop=l116)
2024-04-30 12:54:39 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1484: GFLOPs: 1334.4064. Time: 2773.5041 us. Best GFLOPs: 1479.3654
2024-04-30 12:54:39 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1485: GFLOPs: 1159.2009. Time: 3192.7009 us. Best GFLOPs: 1479.3654
2024-04-30 12:54:39 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1486: GFLOPs: 1292.1299. Time: 2864.2490 us. Best GFLOPs: 1479.3654
2024-04-30 12:54:39 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1487: GFLOPs: 1156.5715. Time: 3199.9594 us. Best GFLOPs: 1479.3654
2024-04-30 12:54:39 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1488: GFLOPs: 1293.1965. Time: 2861.8867 us. Best GFLOPs: 1479.3654
2024-04-30 12:54:39 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1489: GFLOPs: 1177.0316. Time: 3144.3350 us. Best GFLOPs: 1479.3654
2024-04-30 12:54:39 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1490: GFLOPs: 989.6708. Time: 3739.6091 us. Best GFLOPs: 1479.3654
2024-04-30 12:54:39 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1491: GFLOPs: 697.9854. Time: 5302.3769 us. Best GFLOPs: 1479.3654
2024-04-30 12:54:39 [INFO] [task_scheduler.cc:121] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1492: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(56), T.int64(56), T.int64(256)), "float32"), p1: T.Buffer((T.int64(8), T.int64(1), T.int64(3), T.int64(3), T.int64(256), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(58), T.int64(58), T.int64(256)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused in T.parallel(T.int64(448), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(16), T.int64(3), T.int64(256)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(112) * T.int64(14) + ax2)
                    v_i3 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(112) // T.int64(28) * T.int64(14) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(14) + ax3)
                    v_i4 = T.axis.spatial(T.int64(256), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(57) and T.int64(1) <= v_i3 and v_i3 < T.int64(57), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oc_block_1 in range(T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(14), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(8), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(28) // T.int64(14) * T.int64(4) + oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(112) * T.int64(14) + oh_2_init * T.int64(14) + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(112) // T.int64(28) * T.int64(14) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(14) + ow_2_init + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(128), T.int64(1), T.int64(3), T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(32), T.int64(2), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(14), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(8), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(28) // T.int64(14) * T.int64(4) + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(112) * T.int64(14) + oh_2 * T.int64(14) + oh_3)
                        v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(112) // T.int64(28) * T.int64(14) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(14) + ow_2 + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(2) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)], p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)] * p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block]
                for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(4), T.int64(14)):
                    for ax3_ax4_fused in T.vectorized(T.int64(32)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(8), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(28) // T.int64(14) * T.int64(4) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(112) * T.int64(14) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(112) // T.int64(28) * T.int64(14) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(14))
                            v_ax4 = T.axis.spatial(T.int64(32), ax3_ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 2, 4, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[4, 1, 1, 14])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[4, 14, 1, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 32, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[128, 2])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=8)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b68)
l85 = sch.fuse(l71, l72, l73, l74, l75, l76, l77, l78, l79, preserve_unit_iters=True)
sch.parallel(loop=l85)
l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l86, preserve_unit_iters=True)
sch.parallel(loop=l104)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109, l110, l111 = sch.get_loops(block=b70)
l112 = sch.fuse(l110, l111, preserve_unit_iters=True)
sch.vectorize(loop=l112)
b113 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131 = sch.get_loops(block=b113)
b132 = sch.decompose_reduction(block=b113, loop=l116)
2024-04-30 12:54:39 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1493: GFLOPs: 1234.2524. Time: 2998.5616 us. Best GFLOPs: 1479.3654
2024-04-30 12:54:39 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1494: GFLOPs: 1179.9377. Time: 3136.5908 us. Best GFLOPs: 1479.3654
2024-04-30 12:54:39 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1495: GFLOPs: 1276.2282. Time: 2899.9373 us. Best GFLOPs: 1479.3654
2024-04-30 12:54:39 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1496: GFLOPs: 1133.7676. Time: 3264.3213 us. Best GFLOPs: 1479.3654
2024-04-30 12:54:39 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1497: GFLOPs: 1149.0496. Time: 3220.9070 us. Best GFLOPs: 1479.3654
2024-04-30 12:54:39 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1498: GFLOPs: 878.9263. Time: 4210.7986 us. Best GFLOPs: 1479.3654
2024-04-30 12:54:39 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1499: GFLOPs: 611.0292. Time: 6056.9636 us. Best GFLOPs: 1479.3654
2024-04-30 12:54:39 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1500: GFLOPs: 1102.4309. Time: 3357.1100 us. Best GFLOPs: 1479.3654
2024-04-30 12:54:39 [INFO] [task_scheduler.cc:121] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1501: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(56), T.int64(56), T.int64(256)), "float32"), p1: T.Buffer((T.int64(8), T.int64(1), T.int64(3), T.int64(3), T.int64(256), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(58), T.int64(58), T.int64(256)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused in T.parallel(T.int64(896), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(16), T.int64(3), T.int64(256)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(56) // T.int64(14) * T.int64(14) + ax2)
                    v_i3 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(448) // T.int64(112) * T.int64(14) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(14) + ax3)
                    v_i4 = T.axis.spatial(T.int64(256), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(57) and T.int64(1) <= v_i3 and v_i3 < T.int64(57), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oc_block_1 in range(T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(14), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(8), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(448) * T.int64(4) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(112) // T.int64(56) * T.int64(2) + oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(56) // T.int64(14) * T.int64(14) + oh_2_init * T.int64(14) + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(448) // T.int64(112) * T.int64(14) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(14) + ow_2_init + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(128), T.int64(1), T.int64(3), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(32), T.int64(2), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(14), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(8), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(448) * T.int64(4) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(112) // T.int64(56) * T.int64(2) + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(56) // T.int64(14) * T.int64(14) + oh_2 * T.int64(14) + oh_3)
                        v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(448) // T.int64(112) * T.int64(14) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(14) + ow_2 + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(2) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)], p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)] * p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block]
                for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(2), T.int64(14)):
                    for ax3_ax4_fused in T.vectorized(T.int64(32)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(8), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(448) * T.int64(4) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(112) // T.int64(56) * T.int64(2) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(56) // T.int64(14) * T.int64(14) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(448) // T.int64(112) * T.int64(14) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(14))
                            v_ax4 = T.axis.spatial(T.int64(32), ax3_ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[2, 2, 2, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 4, 1, 14])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[4, 14, 1, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 32, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[128, 2])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=8)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b68)
l85 = sch.fuse(l71, l72, l73, l74, l75, l76, l77, l78, l79, preserve_unit_iters=True)
sch.parallel(loop=l85)
l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l86, preserve_unit_iters=True)
sch.parallel(loop=l104)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109, l110, l111 = sch.get_loops(block=b70)
l112 = sch.fuse(l110, l111, preserve_unit_iters=True)
sch.vectorize(loop=l112)
b113 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131 = sch.get_loops(block=b113)
b132 = sch.decompose_reduction(block=b113, loop=l116)
2024-04-30 12:54:39 [INFO] [task_scheduler.cc:121] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1502: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(56), T.int64(56), T.int64(256)), "float32"), p1: T.Buffer((T.int64(8), T.int64(1), T.int64(3), T.int64(3), T.int64(256), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(58), T.int64(58), T.int64(256)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused in T.parallel(T.int64(896), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(16), T.int64(3), T.int64(256)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(448) // T.int64(224) * T.int64(28) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(28) // T.int64(14) * T.int64(14) + ax2)
                    v_i3 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(224) // T.int64(56) * T.int64(14) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(14) + ax3)
                    v_i4 = T.axis.spatial(T.int64(256), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(57) and T.int64(1) <= v_i3 and v_i3 < T.int64(57), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oc_block_1 in range(T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(14), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(8), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(448) * T.int64(4) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(56) // T.int64(28) * T.int64(2) + oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(448) // T.int64(224) * T.int64(28) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(28) // T.int64(14) * T.int64(14) + oh_2_init * T.int64(14) + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(224) // T.int64(56) * T.int64(14) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(14) + ow_2_init + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(128), T.int64(1), T.int64(3), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(32), T.int64(2), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(14), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(8), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(448) * T.int64(4) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(56) // T.int64(28) * T.int64(2) + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(448) // T.int64(224) * T.int64(28) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(28) // T.int64(14) * T.int64(14) + oh_2 * T.int64(14) + oh_3)
                        v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(224) // T.int64(56) * T.int64(14) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(14) + ow_2 + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(2) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)], p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)] * p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block]
                for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(2), T.int64(14)):
                    for ax3_ax4_fused in T.vectorized(T.int64(32)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(8), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(448) * T.int64(4) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(56) // T.int64(28) * T.int64(2) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(448) // T.int64(224) * T.int64(28) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(28) // T.int64(14) * T.int64(14) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(224) // T.int64(56) * T.int64(14) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(14))
                            v_ax4 = T.axis.spatial(T.int64(32), ax3_ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[2, 2, 2, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 2, 1, 14])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[4, 14, 1, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 32, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[128, 2])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=8)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b68)
l85 = sch.fuse(l71, l72, l73, l74, l75, l76, l77, l78, l79, preserve_unit_iters=True)
sch.parallel(loop=l85)
l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l86, preserve_unit_iters=True)
sch.parallel(loop=l104)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109, l110, l111 = sch.get_loops(block=b70)
l112 = sch.fuse(l110, l111, preserve_unit_iters=True)
sch.vectorize(loop=l112)
b113 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131 = sch.get_loops(block=b113)
b132 = sch.decompose_reduction(block=b113, loop=l116)
2024-04-30 12:54:39 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1503: GFLOPs: 1174.5252. Time: 3151.0451 us. Best GFLOPs: 1479.3654
2024-04-30 12:54:39 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1504: GFLOPs: 1214.2965. Time: 3047.8403 us. Best GFLOPs: 1479.3654
2024-04-30 12:54:39 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1505: GFLOPs: 1027.6599. Time: 3601.3683 us. Best GFLOPs: 1479.3654
2024-04-30 12:54:39 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1506: GFLOPs: 1049.8257. Time: 3525.3296 us. Best GFLOPs: 1479.3654
2024-04-30 12:54:39 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1507: GFLOPs: 1205.8434. Time: 3069.2061 us. Best GFLOPs: 1479.3654
2024-04-30 12:54:39 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1508: GFLOPs: 970.5639. Time: 3813.2281 us. Best GFLOPs: 1479.3654
2024-04-30 12:54:39 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1509: GFLOPs: 1105.7848. Time: 3346.9275 us. Best GFLOPs: 1479.3654
2024-04-30 12:54:39 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1510: GFLOPs: 1039.1166. Time: 3561.6616 us. Best GFLOPs: 1479.3654
2024-04-30 12:54:39 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1511: GFLOPs: 1093.8482. Time: 3383.4508 us. Best GFLOPs: 1479.3654
2024-04-30 12:54:39 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1512: GFLOPs: 1032.0485. Time: 3586.0541 us. Best GFLOPs: 1479.3654
2024-04-30 12:54:39 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1513: GFLOPs: 1058.6029. Time: 3496.1001 us. Best GFLOPs: 1479.3654
2024-04-30 12:54:39 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1514: GFLOPs: 1208.6043. Time: 3062.1948 us. Best GFLOPs: 1479.3654
2024-04-30 12:54:39 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1515: GFLOPs: 1186.1390. Time: 3120.1922 us. Best GFLOPs: 1479.3654
2024-04-30 12:54:39 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1516: GFLOPs: 1099.3703. Time: 3366.4559 us. Best GFLOPs: 1479.3654
2024-04-30 12:54:39 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1517: GFLOPs: 1077.2318. Time: 3435.6411 us. Best GFLOPs: 1479.3654
2024-04-30 12:54:39 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1518: GFLOPs: 1078.5447. Time: 3431.4587 us. Best GFLOPs: 1479.3654
2024-04-30 12:54:39 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1519: GFLOPs: 996.7911. Time: 3712.8960 us. Best GFLOPs: 1479.3654
2024-04-30 12:54:39 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1520: GFLOPs: 999.8633. Time: 3701.4879 us. Best GFLOPs: 1479.3654
2024-04-30 12:54:39 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1521: GFLOPs: 1188.2548. Time: 3114.6366 us. Best GFLOPs: 1479.3654
2024-04-30 12:54:39 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1522: GFLOPs: 1037.3604. Time: 3567.6914 us. Best GFLOPs: 1479.3654
2024-04-30 12:54:39 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1523: GFLOPs: 899.5371. Time: 4114.3180 us. Best GFLOPs: 1479.3654
2024-04-30 12:54:39 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1524: GFLOPs: 877.9569. Time: 4215.4483 us. Best GFLOPs: 1479.3654
2024-04-30 12:54:39 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1525: GFLOPs: 1088.7997. Time: 3399.1391 us. Best GFLOPs: 1479.3654
2024-04-30 12:54:39 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1526: GFLOPs: 884.8565. Time: 4182.5785 us. Best GFLOPs: 1479.3654
2024-04-30 12:54:39 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1527: GFLOPs: 896.3820. Time: 4128.7998 us. Best GFLOPs: 1479.3654
2024-04-30 12:54:39 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1528: GFLOPs: 883.2657. Time: 4190.1116 us. Best GFLOPs: 1479.3654
2024-04-30 12:54:39 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1529: GFLOPs: 1012.1624. Time: 3656.5097 us. Best GFLOPs: 1479.3654
2024-04-30 12:54:39 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1530: GFLOPs: 1059.7823. Time: 3492.2093 us. Best GFLOPs: 1479.3654
2024-04-30 12:54:39 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1531: GFLOPs: 776.3121. Time: 4767.3889 us. Best GFLOPs: 1479.3654
2024-04-30 12:54:39 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1532: GFLOPs: 980.0630. Time: 3776.2694 us. Best GFLOPs: 1479.3654
2024-04-30 12:54:39 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1533: GFLOPs: 823.8807. Time: 4492.1329 us. Best GFLOPs: 1479.3654
2024-04-30 12:54:39 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1534: GFLOPs: 48.2663. Time: 76678.3337 us. Best GFLOPs: 1479.3654
2024-04-30 12:54:39 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1535: GFLOPs: 44.7556. Time: 82693.2040 us. Best GFLOPs: 1479.3654
2024-04-30 12:54:39 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1536: GFLOPs: 1.4955. Time: 2474728.1817 us. Best GFLOPs: 1479.3654
2024-04-30 13:01:16 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-30 13:01:17 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-30 13:01:22 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 13:01:22 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-30 13:01:35 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 13:01:48 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 13:02:01 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 13:02:15 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 13:02:23 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.8811  0.8632  0.8606  0.8557  0.8548  0.8546  0.8371  0.8330  0.8245  0.8234  0.8189  0.8169  0.8162  0.8158  0.8100  0.8067
[17 : 32]:	0.8034  0.8034  0.8029  0.8004  0.7762  0.7612  0.7585  0.7585  0.7544  0.7511  0.7487  0.7481  0.7479  0.7398  0.7398  0.7360
[33 : 48]:	0.7330  0.7316  0.7262  0.7260  0.7256  0.7170  0.7122  0.7122  0.7122  0.7122  0.7115  0.7089  0.7075  0.7059  0.7028  0.6989
[49 : 64]:	0.6965  0.6926  0.6906  0.6902  0.6892  0.6892  0.6834  0.6763  0.6699  0.6693  0.6693  0.6679  0.6678  0.6612  0.6602  0.6602
2024-04-30 13:02:23 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-30 13:02:23 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-30 13:04:22 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1537: GFLOPs: 1417.7310. Time: 2610.4964 us. Best GFLOPs: 1479.3654
2024-04-30 13:04:22 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1538: GFLOPs: 1251.7729. Time: 2956.5920 us. Best GFLOPs: 1479.3654
2024-04-30 13:04:22 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1539: GFLOPs: 1322.9354. Time: 2797.5528 us. Best GFLOPs: 1479.3654
2024-04-30 13:04:22 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1540: GFLOPs: 1359.7063. Time: 2721.8979 us. Best GFLOPs: 1479.3654
2024-04-30 13:04:22 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1541: GFLOPs: 1215.9377. Time: 3043.7265 us. Best GFLOPs: 1479.3654
2024-04-30 13:04:22 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1542: GFLOPs: 1356.3853. Time: 2728.5623 us. Best GFLOPs: 1479.3654
2024-04-30 13:04:22 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1543: GFLOPs: 1273.9521. Time: 2905.1185 us. Best GFLOPs: 1479.3654
2024-04-30 13:04:22 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1544: GFLOPs: 1203.1105. Time: 3076.1777 us. Best GFLOPs: 1479.3654
2024-04-30 13:04:22 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1545: GFLOPs: 1264.3707. Time: 2927.1335 us. Best GFLOPs: 1479.3654
2024-04-30 13:04:22 [INFO] [task_scheduler.cc:121] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1546: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(56), T.int64(56), T.int64(256)), "float32"), p1: T.Buffer((T.int64(8), T.int64(1), T.int64(3), T.int64(3), T.int64(256), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(58), T.int64(58), T.int64(256)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_fused_fused in T.parallel(T.int64(224), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(16), T.int64(3), T.int64(256)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(56) * T.int64(14) + ax2)
                    v_i3 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(56) + ax3)
                    v_i4 = T.axis.spatial(T.int64(256), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(57) and T.int64(1) <= v_i3 and v_i3 < T.int64(57), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oc_block_0, n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(14), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(8), oc_chunk_1 * T.int64(4) + oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(56) * T.int64(14) + oh_1 * T.int64(14) + oh_2_init * T.int64(14) + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(56) + ow_1 + ow_2_init + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_0 * T.int64(32) + oc_block_1 * T.int64(32) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(128), T.int64(1), T.int64(3), T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(32), T.int64(2), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(14), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(8), oc_chunk_1 * T.int64(4) + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(56) * T.int64(14) + oh_1 * T.int64(14) + oh_2 * T.int64(14) + oh_3)
                        v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(56) + ow_1 + ow_2 + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_0 * T.int64(32) + oc_block_1 * T.int64(32) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(2) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)], p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)] * p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block]
                for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(4), T.int64(14)):
                    for ax3_ax4_fused in T.vectorized(T.int64(32)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(8), oc_chunk_1 * T.int64(4) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(56) * T.int64(14) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(56))
                            v_ax4 = T.axis.spatial(T.int64(32), ax3_ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 2, 4, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[4, 1, 1, 14])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[56, 1, 1, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 32, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[128, 2])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=112)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=3)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79 = sch.get_loops(block=b68)
l80 = sch.fuse(l71, l72, l73, l74, preserve_unit_iters=True)
sch.parallel(loop=l80)
l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l81, preserve_unit_iters=True)
sch.parallel(loop=l104)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109, l110, l111, l112, l113, l114, l115, l116 = sch.get_loops(block=b70)
l117 = sch.fuse(l115, l116, preserve_unit_iters=True)
sch.vectorize(loop=l117)
b118 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141 = sch.get_loops(block=b118)
b142 = sch.decompose_reduction(block=b118, loop=l126)
2024-04-30 13:04:22 [INFO] [task_scheduler.cc:121] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1547: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(56), T.int64(56), T.int64(256)), "float32"), p1: T.Buffer((T.int64(8), T.int64(1), T.int64(3), T.int64(3), T.int64(256), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(58), T.int64(58), T.int64(256)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused in T.parallel(T.int64(224), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(16), T.int64(3), T.int64(256)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(112) * T.int64(28) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(16) // T.int64(8) * T.int64(14) + ax2)
                    v_i3 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(112) // T.int64(16) * T.int64(8) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(8) + ax3)
                    v_i4 = T.axis.spatial(T.int64(256), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(57) and T.int64(1) <= v_i3 and v_i3 < T.int64(57), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oc_block_1 in range(T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(14), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(8), oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(112) * T.int64(28) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(16) // T.int64(8) * T.int64(14) + oh_2_init * T.int64(14) + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(112) // T.int64(16) * T.int64(8) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(8) + ow_2_init + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(128), T.int64(1), T.int64(3), T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(32), T.int64(2), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(14), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(8), oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(112) * T.int64(28) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(16) // T.int64(8) * T.int64(14) + oh_2 * T.int64(14) + oh_3)
                        v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(112) // T.int64(16) * T.int64(8) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(8) + ow_2 + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(2) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)], p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)] * p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block]
                for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(8), T.int64(14)):
                    for ax3_ax4_fused in T.vectorized(T.int64(32)):
                        with T.block("T_relu"):
                            v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                            v_ax2 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(112) * T.int64(28) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(16) // T.int64(8) * T.int64(14) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(112) // T.int64(16) * T.int64(8) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(8))
                            v_ax4 = T.axis.spatial(T.int64(32), ax3_ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 8, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 2, 1, 14])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[7, 8, 1, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 32, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[128, 2])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=112)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=8)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b68)
l85 = sch.fuse(l71, l72, l73, l74, l75, l76, l77, l78, l79, preserve_unit_iters=True)
sch.parallel(loop=l85)
l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l86, preserve_unit_iters=True)
sch.parallel(loop=l104)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109, l110, l111 = sch.get_loops(block=b70)
l112 = sch.fuse(l110, l111, preserve_unit_iters=True)
sch.vectorize(loop=l112)
b113 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131 = sch.get_loops(block=b113)
b132 = sch.decompose_reduction(block=b113, loop=l116)
2024-04-30 13:04:22 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1548: GFLOPs: 1279.1542. Time: 2893.3038 us. Best GFLOPs: 1479.3654
2024-04-30 13:04:22 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1549: GFLOPs: 1216.5455. Time: 3042.2059 us. Best GFLOPs: 1479.3654
2024-04-30 13:04:22 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1550: GFLOPs: 1237.6737. Time: 2990.2726 us. Best GFLOPs: 1479.3654
2024-04-30 13:04:22 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1551: GFLOPs: 1207.2457. Time: 3065.6409 us. Best GFLOPs: 1479.3654
2024-04-30 13:04:22 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1552: GFLOPs: 1188.6991. Time: 3113.4723 us. Best GFLOPs: 1479.3654
2024-04-30 13:04:22 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1553: GFLOPs: 1233.5846. Time: 3000.1848 us. Best GFLOPs: 1479.3654
2024-04-30 13:04:22 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1554: GFLOPs: 1241.3757. Time: 2981.3551 us. Best GFLOPs: 1479.3654
2024-04-30 13:04:22 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1555: GFLOPs: 1261.8576. Time: 2932.9630 us. Best GFLOPs: 1479.3654
2024-04-30 13:04:22 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1556: GFLOPs: 1241.1286. Time: 2981.9486 us. Best GFLOPs: 1479.3654
2024-04-30 13:04:22 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1557: GFLOPs: 1272.9090. Time: 2907.4991 us. Best GFLOPs: 1479.3654
2024-04-30 13:04:22 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1558: GFLOPs: 1138.1342. Time: 3251.7972 us. Best GFLOPs: 1479.3654
2024-04-30 13:04:22 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1559: GFLOPs: 1180.6459. Time: 3134.7095 us. Best GFLOPs: 1479.3654
2024-04-30 13:04:22 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1560: GFLOPs: 1181.4192. Time: 3132.6576 us. Best GFLOPs: 1479.3654
2024-04-30 13:04:22 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1561: GFLOPs: 1034.0957. Time: 3578.9547 us. Best GFLOPs: 1479.3654
2024-04-30 13:04:22 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1562: GFLOPs: 1006.4007. Time: 3677.4434 us. Best GFLOPs: 1479.3654
2024-04-30 13:04:22 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1563: GFLOPs: 1094.2921. Time: 3382.0785 us. Best GFLOPs: 1479.3654
2024-04-30 13:04:22 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1564: GFLOPs: 926.2352. Time: 3995.7257 us. Best GFLOPs: 1479.3654
2024-04-30 13:04:22 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1565: GFLOPs: 1272.6587. Time: 2908.0709 us. Best GFLOPs: 1479.3654
2024-04-30 13:04:22 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1566: GFLOPs: 1069.9809. Time: 3458.9232 us. Best GFLOPs: 1479.3654
2024-04-30 13:04:22 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1567: GFLOPs: 1116.1523. Time: 3315.8393 us. Best GFLOPs: 1479.3654
2024-04-30 13:04:22 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1568: GFLOPs: 1103.0878. Time: 3355.1107 us. Best GFLOPs: 1479.3654
2024-04-30 13:04:22 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1569: GFLOPs: 1104.9366. Time: 3349.4969 us. Best GFLOPs: 1479.3654
2024-04-30 13:04:22 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1570: GFLOPs: 1114.9842. Time: 3319.3132 us. Best GFLOPs: 1479.3654
2024-04-30 13:04:22 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1571: GFLOPs: 1101.2939. Time: 3360.5761 us. Best GFLOPs: 1479.3654
2024-04-30 13:04:22 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1572: GFLOPs: 1086.5649. Time: 3406.1306 us. Best GFLOPs: 1479.3654
2024-04-30 13:04:22 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1573: GFLOPs: 1126.4001. Time: 3285.6723 us. Best GFLOPs: 1479.3654
2024-04-30 13:04:22 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1574: GFLOPs: 851.8301. Time: 4344.7415 us. Best GFLOPs: 1479.3654
2024-04-30 13:04:22 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1575: GFLOPs: 1065.9130. Time: 3472.1238 us. Best GFLOPs: 1479.3654
2024-04-30 13:04:22 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1576: GFLOPs: 1055.1957. Time: 3507.3889 us. Best GFLOPs: 1479.3654
2024-04-30 13:04:22 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1577: GFLOPs: 1066.7856. Time: 3469.2837 us. Best GFLOPs: 1479.3654
2024-04-30 13:04:22 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1578: GFLOPs: 1066.8667. Time: 3469.0200 us. Best GFLOPs: 1479.3654
2024-04-30 13:04:22 [INFO] [task_scheduler.cc:121] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1579: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(56), T.int64(56), T.int64(256)), "float32"), p1: T.Buffer((T.int64(8), T.int64(1), T.int64(3), T.int64(3), T.int64(256), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(58), T.int64(58), T.int64(256)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_fused_fused in T.parallel(T.int64(224), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(30), T.int64(3), T.int64(256)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(112) // T.int64(56) * T.int64(28) + ax2)
                    v_i3 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(56) + ax3)
                    v_i4 = T.axis.spatial(T.int64(256), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(57) and T.int64(1) <= v_i3 and v_i3 < T.int64(57), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oc_block_0, n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(14), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(8), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(112) * T.int64(4) + oc_chunk_1 * T.int64(4) + oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(112) // T.int64(56) * T.int64(28) + oh_1 * T.int64(14) + oh_2_init * T.int64(14) + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(56) + ow_1 + ow_2_init + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_0 * T.int64(32) + oc_block_1 * T.int64(32) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(128), T.int64(1), T.int64(3), T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(32), T.int64(2), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(14), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(8), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(112) * T.int64(4) + oc_chunk_1 * T.int64(4) + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(112) // T.int64(56) * T.int64(28) + oh_1 * T.int64(14) + oh_2 * T.int64(14) + oh_3)
                        v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(56) + ow_1 + ow_2 + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_0 * T.int64(32) + oc_block_1 * T.int64(32) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(2) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)], p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)] * p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block]
                for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(4), T.int64(14)):
                    for ax3_ax4_fused in T.vectorized(T.int64(32)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(8), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(112) * T.int64(4) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(112) // T.int64(56) * T.int64(28) + oh_1 * T.int64(14) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(56))
                            v_ax4 = T.axis.spatial(T.int64(32), ax3_ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[2, 1, 4, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 2, 1, 14])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[56, 1, 1, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 32, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[128, 2])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=112)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=3)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79 = sch.get_loops(block=b68)
l80 = sch.fuse(l71, l72, l73, l74, preserve_unit_iters=True)
sch.parallel(loop=l80)
l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l81, preserve_unit_iters=True)
sch.parallel(loop=l104)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109, l110, l111, l112, l113, l114, l115, l116 = sch.get_loops(block=b70)
l117 = sch.fuse(l115, l116, preserve_unit_iters=True)
sch.vectorize(loop=l117)
b118 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141 = sch.get_loops(block=b118)
b142 = sch.decompose_reduction(block=b118, loop=l126)
2024-04-30 13:04:22 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1580: GFLOPs: 1041.0069. Time: 3555.1943 us. Best GFLOPs: 1479.3654
2024-04-30 13:04:22 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1581: GFLOPs: 1000.7312. Time: 3698.2776 us. Best GFLOPs: 1479.3654
2024-04-30 13:04:22 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1582: GFLOPs: 1056.4883. Time: 3503.0978 us. Best GFLOPs: 1479.3654
2024-04-30 13:04:22 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1583: GFLOPs: 995.7968. Time: 3716.6035 us. Best GFLOPs: 1479.3654
2024-04-30 13:04:22 [INFO] [task_scheduler.cc:121] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1584: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(56), T.int64(56), T.int64(256)), "float32"), p1: T.Buffer((T.int64(8), T.int64(1), T.int64(3), T.int64(3), T.int64(256), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(58), T.int64(58), T.int64(256)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_fused_fused in T.parallel(T.int64(448), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(16), T.int64(3), T.int64(256)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(224) // T.int64(56) * T.int64(14) + ax2)
                    v_i3 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(56) + ax3)
                    v_i4 = T.axis.spatial(T.int64(256), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(57) and T.int64(1) <= v_i3 and v_i3 < T.int64(57), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oc_block_0, n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(14), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(8), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(224) * T.int64(4) + oc_chunk_1 * T.int64(4) + oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(224) // T.int64(56) * T.int64(14) + oh_1 * T.int64(14) + oh_2_init * T.int64(14) + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(56) + ow_1 + ow_2_init + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_0 * T.int64(32) + oc_block_1 * T.int64(32) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(128), T.int64(1), T.int64(3), T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(32), T.int64(2), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(14), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(8), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(224) * T.int64(4) + oc_chunk_1 * T.int64(4) + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(224) // T.int64(56) * T.int64(14) + oh_1 * T.int64(14) + oh_2 * T.int64(14) + oh_3)
                        v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(56) + ow_1 + ow_2 + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_0 * T.int64(32) + oc_block_1 * T.int64(32) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(2) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)], p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)] * p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block]
                for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(4), T.int64(14)):
                    for ax3_ax4_fused in T.vectorized(T.int64(32)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(8), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(224) * T.int64(4) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(224) // T.int64(56) * T.int64(14) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(56))
                            v_ax4 = T.axis.spatial(T.int64(32), ax3_ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[2, 1, 4, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[4, 1, 1, 14])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[56, 1, 1, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 32, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[128, 2])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=112)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=3)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79 = sch.get_loops(block=b68)
l80 = sch.fuse(l71, l72, l73, l74, preserve_unit_iters=True)
sch.parallel(loop=l80)
l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l81, preserve_unit_iters=True)
sch.parallel(loop=l104)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109, l110, l111, l112, l113, l114, l115, l116 = sch.get_loops(block=b70)
l117 = sch.fuse(l115, l116, preserve_unit_iters=True)
sch.vectorize(loop=l117)
b118 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141 = sch.get_loops(block=b118)
b142 = sch.decompose_reduction(block=b118, loop=l126)
2024-04-30 13:04:22 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1585: GFLOPs: 1104.1776. Time: 3351.7993 us. Best GFLOPs: 1479.3654
2024-04-30 13:04:22 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1586: GFLOPs: 1066.2309. Time: 3471.0886 us. Best GFLOPs: 1479.3654
2024-04-30 13:04:22 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1587: GFLOPs: 1030.9359. Time: 3589.9242 us. Best GFLOPs: 1479.3654
2024-04-30 13:04:22 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1588: GFLOPs: 1020.0648. Time: 3628.1831 us. Best GFLOPs: 1479.3654
2024-04-30 13:04:22 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1589: GFLOPs: 1066.6042. Time: 3469.8738 us. Best GFLOPs: 1479.3654
2024-04-30 13:04:22 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1590: GFLOPs: 1061.8554. Time: 3485.3916 us. Best GFLOPs: 1479.3654
2024-04-30 13:04:22 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1591: GFLOPs: 1046.7192. Time: 3535.7922 us. Best GFLOPs: 1479.3654
2024-04-30 13:04:22 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1592: GFLOPs: 1032.1949. Time: 3585.5455 us. Best GFLOPs: 1479.3654
2024-04-30 13:04:22 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1593: GFLOPs: 971.7635. Time: 3808.5211 us. Best GFLOPs: 1479.3654
2024-04-30 13:04:22 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1594: GFLOPs: 964.6305. Time: 3836.6834 us. Best GFLOPs: 1479.3654
2024-04-30 13:04:22 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1595: GFLOPs: 1067.0908. Time: 3468.2913 us. Best GFLOPs: 1479.3654
2024-04-30 13:04:22 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1596: GFLOPs: 978.9273. Time: 3780.6502 us. Best GFLOPs: 1479.3654
2024-04-30 13:04:22 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1597: GFLOPs: 976.1271. Time: 3791.4956 us. Best GFLOPs: 1479.3654
2024-04-30 13:04:22 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1598: GFLOPs: 21.7683. Time: 170016.7533 us. Best GFLOPs: 1479.3654
2024-04-30 13:04:22 [INFO] [task_scheduler.cc:121] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1599: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(56), T.int64(56), T.int64(256)), "float32"), p1: T.Buffer((T.int64(8), T.int64(1), T.int64(3), T.int64(3), T.int64(256), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(58), T.int64(58), T.int64(256)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused in T.parallel(T.int64(112), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(7), T.int64(2), T.int64(16)):
                for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(6), T.int64(6), T.int64(256)):
                    with T.block("data_pad"):
                        v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                        v_i2 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(14) // T.int64(7) * T.int64(28) + oh_1 * T.int64(4) + ax2)
                        v_i3 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(7) * T.int64(8) + ow_1 * T.int64(4) + ax3)
                        v_i4 = T.axis.spatial(T.int64(256), ax4)
                        T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                        T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                        data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(57) and T.int64(1) <= v_i3 and v_i3 < T.int64(57), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(1), T.int64(2), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(2)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(2)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(8), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(14) + oc_chunk_1 + oc_chunk_2_init + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(14) // T.int64(7) * T.int64(28) + oh_1 * T.int64(4) + oh_2_init * T.int64(2) + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(7) * T.int64(8) + ow_1 * T.int64(4) + ow_2_init * T.int64(2) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(2) + oc_block_2_init * T.int64(2) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(256), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(2), T.int64(2), T.int64(1), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(2)):
                    for oc_block_3_fused in T.vectorized(T.int64(2)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(8), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(14) + oc_chunk_1 + oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(14) // T.int64(7) * T.int64(28) + oh_1 * T.int64(4) + oh_2 * T.int64(2) + oh_3)
                            v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(7) * T.int64(8) + ow_1 * T.int64(4) + ow_2 * T.int64(2) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(2) + oc_block_2 * T.int64(2) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(256), ic_0 + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)], p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)] * p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(28), T.int64(8)):
                for ax4_fused in T.vectorized(T.int64(32)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(8), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(14) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(14) // T.int64(7) * T.int64(28) + ax2)
                        v_ax3 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(7) * T.int64(8) + ax3)
                        v_ax4 = T.axis.spatial(T.int64(32), ax4_fused)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[8, 1, 1, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 7, 2, 2])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[7, 2, 2, 2])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 16, 1, 2])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[256, 1])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=9)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85 = sch.get_loops(block=b68)
l86 = sch.fuse(l71, l72, l73, l74, l75, preserve_unit_iters=True)
sch.parallel(loop=l86)
l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107, l108 = sch.get_loops(block=b69)
l109 = sch.fuse(l87, preserve_unit_iters=True)
sch.parallel(loop=l109)
l110 = sch.fuse(l108, preserve_unit_iters=True)
sch.vectorize(loop=l110)
sch.annotate(block_or_loop=l109, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l109, ann_key="pragma_unroll_explicit", ann_val=1)
l111, l112, l113, l114, l115, l116 = sch.get_loops(block=b70)
l117 = sch.fuse(l116, preserve_unit_iters=True)
sch.vectorize(loop=l117)
b118 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140 = sch.get_loops(block=b118)
b141 = sch.decompose_reduction(block=b118, loop=l125)
2024-04-30 13:04:22 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1600: GFLOPs: 9.3683. Time: 395054.4683 us. Best GFLOPs: 1479.3654
2024-04-30 13:14:36 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-30 13:14:37 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-30 13:14:41 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 13:14:41 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-30 13:14:55 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 13:15:08 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 13:15:21 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 13:15:34 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 13:15:42 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.8943  0.8885  0.8758  0.8657  0.8650  0.8624  0.8585  0.8561  0.8558  0.8510  0.8489  0.8482  0.8482  0.8471  0.8428  0.8428
[17 : 32]:	0.8381  0.8307  0.8271  0.8206  0.8162  0.8156  0.8155  0.8155  0.8096  0.8075  0.7981  0.7937  0.7927  0.7927  0.7805  0.7785
[33 : 48]:	0.7778  0.7481  0.7481  0.7461  0.7439  0.7424  0.7329  0.7280  0.7259  0.7254  0.7225  0.7222  0.7222  0.7216  0.7188  0.7186
[49 : 64]:	0.7160  0.7109  0.7050  0.7027  0.7025  0.7001  0.7001  0.6958  0.6933  0.6927  0.6923  0.6905  0.6905  0.6874  0.6869  0.6830
2024-04-30 13:15:42 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-30 13:15:42 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-30 13:17:35 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1601: GFLOPs: 1346.9693. Time: 2747.6364 us. Best GFLOPs: 1479.3654
2024-04-30 13:17:35 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1602: GFLOPs: 1167.8695. Time: 3169.0028 us. Best GFLOPs: 1479.3654
2024-04-30 13:17:35 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1603: GFLOPs: 1278.7283. Time: 2894.2674 us. Best GFLOPs: 1479.3654
2024-04-30 13:17:35 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1604: GFLOPs: 1311.8562. Time: 2821.1796 us. Best GFLOPs: 1479.3654
2024-04-30 13:17:35 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1605: GFLOPs: 1217.0612. Time: 3040.9167 us. Best GFLOPs: 1479.3654
2024-04-30 13:17:35 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1606: GFLOPs: 1314.3464. Time: 2815.8344 us. Best GFLOPs: 1479.3654
2024-04-30 13:17:35 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1607: GFLOPs: 1260.2099. Time: 2936.7979 us. Best GFLOPs: 1479.3654
2024-04-30 13:17:35 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1608: GFLOPs: 1304.2990. Time: 2837.5257 us. Best GFLOPs: 1479.3654
2024-04-30 13:17:35 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1609: GFLOPs: 1216.2127. Time: 3043.0383 us. Best GFLOPs: 1479.3654
2024-04-30 13:17:35 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1610: GFLOPs: 1369.7220. Time: 2701.9949 us. Best GFLOPs: 1479.3654
2024-04-30 13:17:35 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1611: GFLOPs: 1212.2792. Time: 3052.9121 us. Best GFLOPs: 1479.3654
2024-04-30 13:17:35 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1612: GFLOPs: 1322.5986. Time: 2798.2652 us. Best GFLOPs: 1479.3654
2024-04-30 13:17:35 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1613: GFLOPs: 1229.6240. Time: 3009.8484 us. Best GFLOPs: 1479.3654
2024-04-30 13:17:35 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1614: GFLOPs: 1308.1377. Time: 2829.1988 us. Best GFLOPs: 1479.3654
2024-04-30 13:17:35 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1615: GFLOPs: 1210.9002. Time: 3056.3887 us. Best GFLOPs: 1479.3654
2024-04-30 13:17:35 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1616: GFLOPs: 1291.5790. Time: 2865.4706 us. Best GFLOPs: 1479.3654
2024-04-30 13:17:35 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1617: GFLOPs: 1240.3172. Time: 2983.8994 us. Best GFLOPs: 1479.3654
2024-04-30 13:17:35 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1618: GFLOPs: 1233.3334. Time: 3000.7959 us. Best GFLOPs: 1479.3654
2024-04-30 13:17:35 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1619: GFLOPs: 1180.6818. Time: 3134.6141 us. Best GFLOPs: 1479.3654
2024-04-30 13:17:35 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1620: GFLOPs: 1244.6573. Time: 2973.4946 us. Best GFLOPs: 1479.3654
2024-04-30 13:17:35 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1621: GFLOPs: 1192.7638. Time: 3102.8624 us. Best GFLOPs: 1479.3654
2024-04-30 13:17:35 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1622: GFLOPs: 1216.0524. Time: 3043.4395 us. Best GFLOPs: 1479.3654
2024-04-30 13:17:35 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1623: GFLOPs: 1197.2760. Time: 3091.1685 us. Best GFLOPs: 1479.3654
2024-04-30 13:17:35 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1624: GFLOPs: 1239.0814. Time: 2986.8754 us. Best GFLOPs: 1479.3654
2024-04-30 13:17:35 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1625: GFLOPs: 1169.0326. Time: 3165.8500 us. Best GFLOPs: 1479.3654
2024-04-30 13:17:35 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1626: GFLOPs: 1276.1499. Time: 2900.1152 us. Best GFLOPs: 1479.3654
2024-04-30 13:17:35 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1627: GFLOPs: 1100.9552. Time: 3361.6097 us. Best GFLOPs: 1479.3654
2024-04-30 13:17:35 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1628: GFLOPs: 1212.8745. Time: 3051.4136 us. Best GFLOPs: 1479.3654
2024-04-30 13:17:35 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1629: GFLOPs: 1312.8087. Time: 2819.1326 us. Best GFLOPs: 1479.3654
2024-04-30 13:17:35 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1630: GFLOPs: 1095.2852. Time: 3379.0118 us. Best GFLOPs: 1479.3654
2024-04-30 13:17:35 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1631: GFLOPs: 1046.0154. Time: 3538.1714 us. Best GFLOPs: 1479.3654
2024-04-30 13:17:35 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1632: GFLOPs: 1070.4032. Time: 3457.5587 us. Best GFLOPs: 1479.3654
2024-04-30 13:17:35 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1633: GFLOPs: 924.5316. Time: 4003.0884 us. Best GFLOPs: 1479.3654
2024-04-30 13:17:35 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1634: GFLOPs: 1054.6415. Time: 3509.2320 us. Best GFLOPs: 1479.3654
2024-04-30 13:17:35 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1635: GFLOPs: 1213.0404. Time: 3050.9963 us. Best GFLOPs: 1479.3654
2024-04-30 13:17:35 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1636: GFLOPs: 1217.5286. Time: 3039.7494 us. Best GFLOPs: 1479.3654
2024-04-30 13:17:35 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1637: GFLOPs: 1081.3240. Time: 3422.6391 us. Best GFLOPs: 1479.3654
2024-04-30 13:17:35 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1638: GFLOPs: 1086.9603. Time: 3404.8914 us. Best GFLOPs: 1479.3654
2024-04-30 13:17:35 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1639: GFLOPs: 1035.0234. Time: 3575.7469 us. Best GFLOPs: 1479.3654
2024-04-30 13:17:35 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1640: GFLOPs: 1062.0382. Time: 3484.7917 us. Best GFLOPs: 1479.3654
2024-04-30 13:17:35 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1641: GFLOPs: 1090.8676. Time: 3392.6957 us. Best GFLOPs: 1479.3654
2024-04-30 13:17:35 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1642: GFLOPs: 1366.3598. Time: 2708.6437 us. Best GFLOPs: 1479.3654
2024-04-30 13:17:35 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1643: GFLOPs: 1080.3588. Time: 3425.6969 us. Best GFLOPs: 1479.3654
2024-04-30 13:17:35 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1644: GFLOPs: 1090.8468. Time: 3392.7604 us. Best GFLOPs: 1479.3654
2024-04-30 13:17:35 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1645: GFLOPs: 1030.2978. Time: 3592.1475 us. Best GFLOPs: 1479.3654
2024-04-30 13:17:35 [INFO] [task_scheduler.cc:121] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1646: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(56), T.int64(56), T.int64(256)), "float32"), p1: T.Buffer((T.int64(8), T.int64(1), T.int64(3), T.int64(3), T.int64(256), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(58), T.int64(58), T.int64(256)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_fused_fused in T.parallel(T.int64(112), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(30), T.int64(3), T.int64(256)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(56) * T.int64(28) + ax2)
                    v_i3 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(56) + ax3)
                    v_i4 = T.axis.spatial(T.int64(256), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(57) and T.int64(1) <= v_i3 and v_i3 < T.int64(57), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oc_block_0, n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(2), T.int64(2), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(14), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(8), oc_chunk_1 * T.int64(4) + oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(56) * T.int64(28) + oh_1 * T.int64(14) + oh_2_init * T.int64(14) + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(56) + ow_1 + ow_2_init + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_0 * T.int64(32) + oc_block_1 * T.int64(32) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(128), T.int64(1), T.int64(3), T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(32), T.int64(2), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(14), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(8), oc_chunk_1 * T.int64(4) + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(56) * T.int64(28) + oh_1 * T.int64(14) + oh_2 * T.int64(14) + oh_3)
                        v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(56) + ow_1 + ow_2 + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_0 * T.int64(32) + oc_block_1 * T.int64(32) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(2) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)], p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)] * p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block]
                for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(4), T.int64(14)):
                    for ax3_ax4_fused in T.vectorized(T.int64(32)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(8), oc_chunk_1 * T.int64(4) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(56) * T.int64(28) + oh_1 * T.int64(14) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(56))
                            v_ax4 = T.axis.spatial(T.int64(32), ax3_ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 2, 4, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 2, 1, 14])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[56, 1, 1, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 32, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[128, 2])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=3)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79 = sch.get_loops(block=b68)
l80 = sch.fuse(l71, l72, l73, l74, preserve_unit_iters=True)
sch.parallel(loop=l80)
l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l81, preserve_unit_iters=True)
sch.parallel(loop=l104)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109, l110, l111, l112, l113, l114, l115, l116 = sch.get_loops(block=b70)
l117 = sch.fuse(l115, l116, preserve_unit_iters=True)
sch.vectorize(loop=l117)
b118 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141 = sch.get_loops(block=b118)
b142 = sch.decompose_reduction(block=b118, loop=l126)
2024-04-30 13:17:35 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1647: GFLOPs: 846.4523. Time: 4372.3452 us. Best GFLOPs: 1479.3654
2024-04-30 13:17:35 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1648: GFLOPs: 1076.4467. Time: 3438.1469 us. Best GFLOPs: 1479.3654
2024-04-30 13:17:35 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1649: GFLOPs: 1127.5722. Time: 3282.2571 us. Best GFLOPs: 1479.3654
2024-04-30 13:17:35 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1650: GFLOPs: 1056.8867. Time: 3501.7771 us. Best GFLOPs: 1479.3654
2024-04-30 13:17:35 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1651: GFLOPs: 1065.6516. Time: 3472.9753 us. Best GFLOPs: 1479.3654
2024-04-30 13:17:35 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1652: GFLOPs: 1026.2754. Time: 3606.2266 us. Best GFLOPs: 1479.3654
2024-04-30 13:17:35 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1653: GFLOPs: 994.2940. Time: 3722.2207 us. Best GFLOPs: 1479.3654
2024-04-30 13:17:35 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1654: GFLOPs: 1047.9128. Time: 3531.7649 us. Best GFLOPs: 1479.3654
2024-04-30 13:17:35 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1655: GFLOPs: 1068.2145. Time: 3464.6427 us. Best GFLOPs: 1479.3654
2024-04-30 13:17:35 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1656: GFLOPs: 1023.6194. Time: 3615.5840 us. Best GFLOPs: 1479.3654
2024-04-30 13:17:35 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1657: GFLOPs: 913.1035. Time: 4053.1897 us. Best GFLOPs: 1479.3654
2024-04-30 13:17:35 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1658: GFLOPs: 897.2236. Time: 4124.9270 us. Best GFLOPs: 1479.3654
2024-04-30 13:17:35 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1659: GFLOPs: 993.3331. Time: 3725.8215 us. Best GFLOPs: 1479.3654
2024-04-30 13:17:35 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1660: GFLOPs: 1041.3447. Time: 3554.0411 us. Best GFLOPs: 1479.3654
2024-04-30 13:17:35 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1661: GFLOPs: 994.5788. Time: 3721.1547 us. Best GFLOPs: 1479.3654
2024-04-30 13:17:35 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1662: GFLOPs: 73.5302. Time: 50332.8240 us. Best GFLOPs: 1479.3654
2024-04-30 13:17:35 [INFO] [task_scheduler.cc:121] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1663: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(56), T.int64(56), T.int64(256)), "float32"), p1: T.Buffer((T.int64(8), T.int64(1), T.int64(3), T.int64(3), T.int64(256), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused in T.parallel(T.int64(8), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(7), T.int64(1), T.int64(1), T.int64(2), T.int64(14), T.int64(8)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(16)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(8), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused // T.int64(4) * T.int64(4) + oc_chunk_1 * T.int64(4) + oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused % T.int64(4) // T.int64(2) * T.int64(28) + oh_1 * T.int64(14) + oh_2_init * T.int64(14) + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(56), ow_1 * T.int64(56) + ow_2_init * T.int64(8) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused % T.int64(2) * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2_init * T.int64(16) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(16), T.int64(3), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(7), T.int64(1), T.int64(16), T.int64(1), T.int64(3), T.int64(1), T.int64(2), T.int64(14), T.int64(8)):
                    for oc_block_3_fused in T.vectorized(T.int64(16)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(8), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused // T.int64(4) * T.int64(4) + oc_chunk_1 * T.int64(4) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused % T.int64(4) // T.int64(2) * T.int64(28) + oh_1 * T.int64(14) + oh_2 * T.int64(14) + oh_3)
                            v_ow = T.axis.spatial(T.int64(56), ow_1 * T.int64(56) + ow_2 * T.int64(8) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused % T.int64(2) * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2 * T.int64(16) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(16) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], p0[v_n, v_ic // T.int64(256), v_oh + v_kh - T.int64(1), v_ow + v_kw - T.int64(1), v_ic % T.int64(256)], p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + T.if_then_else(T.int64(1) <= v_oh + v_kh and v_oh + v_kh < T.int64(57) and T.int64(1) <= v_ow + v_kw and v_ow + v_kw < T.int64(57), p0[v_n, v_ic // T.int64(256), v_oh + v_kh - T.int64(1), v_ow + v_kw - T.int64(1), v_ic % T.int64(256)], T.float32(0)) * p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(4), T.int64(28), T.int64(56)):
                for ax4_fused in T.vectorized(T.int64(16)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(8), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused // T.int64(4) * T.int64(4) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused % T.int64(4) // T.int64(2) * T.int64(28) + ax2)
                        v_ax3 = T.axis.spatial(T.int64(56), ax3)
                        v_ax4 = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused % T.int64(2) * T.int64(16) + ax4_fused)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[2, 1, 2, 2])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 2, 1, 14])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 7, 8])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[2, 1, 1, 16])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[16, 16])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=-2)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69 = sch.get_child_blocks(b67)
l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95 = sch.get_loops(block=b68)
l96 = sch.fuse(l70, l71, l72, l73, l74, preserve_unit_iters=True)
sch.parallel(loop=l96)
l97 = sch.fuse(l95, preserve_unit_iters=True)
sch.vectorize(loop=l97)
sch.annotate(block_or_loop=l96, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l96, ann_key="pragma_unroll_explicit", ann_val=1)
l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l103, preserve_unit_iters=True)
sch.vectorize(loop=l104)
b105 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l106, l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127 = sch.get_loops(block=b105)
b128 = sch.decompose_reduction(block=b105, loop=l112)
2024-04-30 13:17:35 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1664: GFLOPs: 30.3589. Time: 121907.7657 us. Best GFLOPs: 1479.3654
2024-04-30 13:53:59 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-30 13:54:01 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-30 13:54:05 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 13:54:05 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-30 13:54:18 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 13:54:31 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 13:54:44 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 13:54:57 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 13:55:05 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.8838  0.8671  0.8662  0.8640  0.8581  0.8573  0.8538  0.8520  0.8461  0.8416  0.8233  0.8133  0.8085  0.7696  0.7696  0.7688
[17 : 32]:	0.7634  0.7404  0.7401  0.7397  0.7359  0.7351  0.7315  0.7308  0.7261  0.7257  0.7230  0.7221  0.7212  0.7122  0.7019  0.7019
[33 : 48]:	0.7017  0.7005  0.6950  0.6928  0.6888  0.6869  0.6847  0.6846  0.6839  0.6814  0.6808  0.6788  0.6779  0.6751  0.6751  0.6735
[49 : 64]:	0.6734  0.6732  0.6725  0.6706  0.6706  0.6704  0.6609  0.6579  0.6560  0.6545  0.6538  0.6506  0.6494  0.6494  0.6494  0.6489
2024-04-30 13:55:06 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-30 13:55:06 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-30 13:56:55 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1665: GFLOPs: 1223.9176. Time: 3023.8816 us. Best GFLOPs: 1479.3654
2024-04-30 13:56:55 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1666: GFLOPs: 1237.4502. Time: 2990.8126 us. Best GFLOPs: 1479.3654
2024-04-30 13:56:55 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1667: GFLOPs: 1305.3601. Time: 2835.2191 us. Best GFLOPs: 1479.3654
2024-04-30 13:56:55 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1668: GFLOPs: 1236.6237. Time: 2992.8115 us. Best GFLOPs: 1479.3654
2024-04-30 13:56:55 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1669: GFLOPs: 1305.1310. Time: 2835.7166 us. Best GFLOPs: 1479.3654
2024-04-30 13:56:55 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1670: GFLOPs: 1223.6946. Time: 3024.4326 us. Best GFLOPs: 1479.3654
2024-04-30 13:56:55 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1671: GFLOPs: 1302.3843. Time: 2841.6972 us. Best GFLOPs: 1479.3654
2024-04-30 13:56:55 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1672: GFLOPs: 1312.0842. Time: 2820.6893 us. Best GFLOPs: 1479.3654
2024-04-30 13:56:55 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1673: GFLOPs: 1292.5483. Time: 2863.3219 us. Best GFLOPs: 1479.3654
2024-04-30 13:56:55 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1674: GFLOPs: 1222.6037. Time: 3027.1311 us. Best GFLOPs: 1479.3654
2024-04-30 13:56:55 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1675: GFLOPs: 1230.9666. Time: 3006.5654 us. Best GFLOPs: 1479.3654
2024-04-30 13:56:55 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1676: GFLOPs: 1173.9340. Time: 3152.6320 us. Best GFLOPs: 1479.3654
2024-04-30 13:56:55 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1677: GFLOPs: 1253.8534. Time: 2951.6863 us. Best GFLOPs: 1479.3654
2024-04-30 13:56:55 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1678: GFLOPs: 1097.7859. Time: 3371.3146 us. Best GFLOPs: 1479.3654
2024-04-30 13:56:55 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1679: GFLOPs: 1157.6757. Time: 3196.9071 us. Best GFLOPs: 1479.3654
2024-04-30 13:56:55 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1680: GFLOPs: 1113.0221. Time: 3325.1648 us. Best GFLOPs: 1479.3654
2024-04-30 13:56:55 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1681: GFLOPs: 1177.7251. Time: 3142.4837 us. Best GFLOPs: 1479.3654
2024-04-30 13:56:55 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1682: GFLOPs: 1287.8966. Time: 2873.6636 us. Best GFLOPs: 1479.3654
2024-04-30 13:56:55 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1683: GFLOPs: 910.9515. Time: 4062.7650 us. Best GFLOPs: 1479.3654
2024-04-30 13:56:55 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1684: GFLOPs: 1044.1960. Time: 3544.3363 us. Best GFLOPs: 1479.3654
2024-04-30 13:56:55 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1685: GFLOPs: 1036.4687. Time: 3570.7607 us. Best GFLOPs: 1479.3654
2024-04-30 13:56:55 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1686: GFLOPs: 1078.2015. Time: 3432.5513 us. Best GFLOPs: 1479.3654
2024-04-30 13:56:55 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1687: GFLOPs: 1083.0595. Time: 3417.1547 us. Best GFLOPs: 1479.3654
2024-04-30 13:56:55 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1688: GFLOPs: 1123.2353. Time: 3294.9301 us. Best GFLOPs: 1479.3654
2024-04-30 13:56:55 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1689: GFLOPs: 1081.4742. Time: 3422.1637 us. Best GFLOPs: 1479.3654
2024-04-30 13:56:55 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1690: GFLOPs: 1037.0829. Time: 3568.6462 us. Best GFLOPs: 1479.3654
2024-04-30 13:56:55 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1691: GFLOPs: 1074.3943. Time: 3444.7148 us. Best GFLOPs: 1479.3654
2024-04-30 13:56:55 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1692: GFLOPs: 1103.2222. Time: 3354.7019 us. Best GFLOPs: 1479.3654
2024-04-30 13:56:55 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1693: GFLOPs: 559.9946. Time: 6608.9592 us. Best GFLOPs: 1479.3654
2024-04-30 13:56:55 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1694: GFLOPs: 955.2625. Time: 3874.3085 us. Best GFLOPs: 1479.3654
2024-04-30 13:56:55 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1695: GFLOPs: 918.9281. Time: 4027.4988 us. Best GFLOPs: 1479.3654
2024-04-30 13:56:55 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1696: GFLOPs: 929.9570. Time: 3979.7345 us. Best GFLOPs: 1479.3654
2024-04-30 13:56:55 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1697: GFLOPs: 495.7851. Time: 7464.8918 us. Best GFLOPs: 1479.3654
2024-04-30 13:56:55 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1698: GFLOPs: 1046.5130. Time: 3536.4890 us. Best GFLOPs: 1479.3654
2024-04-30 13:56:55 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1699: GFLOPs: 1061.8219. Time: 3485.5016 us. Best GFLOPs: 1479.3654
2024-04-30 13:56:55 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1700: GFLOPs: 1066.4454. Time: 3470.3903 us. Best GFLOPs: 1479.3654
2024-04-30 13:56:55 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1701: GFLOPs: 1029.0066. Time: 3596.6550 us. Best GFLOPs: 1479.3654
2024-04-30 13:56:55 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1702: GFLOPs: 1062.8971. Time: 3481.9757 us. Best GFLOPs: 1479.3654
2024-04-30 13:56:55 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1703: GFLOPs: 1058.6583. Time: 3495.9173 us. Best GFLOPs: 1479.3654
2024-04-30 13:56:55 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1704: GFLOPs: 1031.5562. Time: 3587.7655 us. Best GFLOPs: 1479.3654
2024-04-30 13:56:55 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1705: GFLOPs: 1008.3172. Time: 3670.4537 us. Best GFLOPs: 1479.3654
2024-04-30 13:56:55 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1706: GFLOPs: 928.8617. Time: 3984.4272 us. Best GFLOPs: 1479.3654
2024-04-30 13:56:55 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1707: GFLOPs: 1587.6337. Time: 2331.1307 us. Best GFLOPs: 1587.6337
2024-04-30 13:56:55 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1708: GFLOPs: 1053.4712. Time: 3513.1303 us. Best GFLOPs: 1587.6337
2024-04-30 13:56:55 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1709: GFLOPs: 590.8760. Time: 6263.5503 us. Best GFLOPs: 1587.6337
2024-04-30 13:56:55 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1710: GFLOPs: 1046.7559. Time: 3535.6683 us. Best GFLOPs: 1587.6337
2024-04-30 13:56:55 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1711: GFLOPs: 1011.7469. Time: 3658.0114 us. Best GFLOPs: 1587.6337
2024-04-30 13:56:55 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1712: GFLOPs: 989.0476. Time: 3741.9654 us. Best GFLOPs: 1587.6337
2024-04-30 13:56:55 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1713: GFLOPs: 483.6675. Time: 7651.9126 us. Best GFLOPs: 1587.6337
2024-04-30 13:56:55 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1714: GFLOPs: 957.5936. Time: 3864.8772 us. Best GFLOPs: 1587.6337
2024-04-30 13:56:55 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1715: GFLOPs: 961.5132. Time: 3849.1223 us. Best GFLOPs: 1587.6337
2024-04-30 13:56:55 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1716: GFLOPs: 963.5090. Time: 3841.1493 us. Best GFLOPs: 1587.6337
2024-04-30 13:56:55 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1717: GFLOPs: 967.6365. Time: 3824.7645 us. Best GFLOPs: 1587.6337
2024-04-30 13:56:55 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1718: GFLOPs: 990.9880. Time: 3734.6382 us. Best GFLOPs: 1587.6337
2024-04-30 13:56:55 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1719: GFLOPs: 204.9083. Time: 18061.6530 us. Best GFLOPs: 1587.6337
2024-04-30 13:56:55 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1720: GFLOPs: 1026.2842. Time: 3606.1959 us. Best GFLOPs: 1587.6337
2024-04-30 13:56:55 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1721: GFLOPs: 953.5647. Time: 3881.2067 us. Best GFLOPs: 1587.6337
2024-04-30 13:56:55 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1722: GFLOPs: 990.1705. Time: 3737.7216 us. Best GFLOPs: 1587.6337
2024-04-30 13:56:55 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1723: GFLOPs: 1059.7492. Time: 3492.3186 us. Best GFLOPs: 1587.6337
2024-04-30 13:56:55 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1724: GFLOPs: 978.9364. Time: 3780.6153 us. Best GFLOPs: 1587.6337
2024-04-30 13:56:55 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1725: GFLOPs: 954.2987. Time: 3878.2216 us. Best GFLOPs: 1587.6337
2024-04-30 13:56:55 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1726: GFLOPs: 59.2277. Time: 62487.3323 us. Best GFLOPs: 1587.6337
2024-04-30 13:56:55 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1727: GFLOPs: 32.6705. Time: 113281.8993 us. Best GFLOPs: 1587.6337
2024-04-30 13:56:55 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1728: GFLOPs: 110.3676. Time: 33533.2260 us. Best GFLOPs: 1587.6337
2024-04-30 13:56:55 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-30 13:56:56 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-30 13:57:01 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 13:57:01 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-30 13:57:14 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 13:57:26 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 13:57:40 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 13:57:53 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 13:58:01 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9563  0.9563  0.8653  0.8355  0.8057  0.8035  0.8026  0.7988  0.7945  0.7929  0.7929  0.7882  0.7876  0.7779  0.7673  0.7660
[17 : 32]:	0.7618  0.7618  0.7592  0.7588  0.7513  0.7496  0.7479  0.7479  0.7403  0.7358  0.7303  0.7279  0.7167  0.7148  0.7142  0.7141
[33 : 48]:	0.7129  0.7123  0.7002  0.7002  0.6998  0.6852  0.6822  0.6805  0.6764  0.6725  0.6664  0.6663  0.6663  0.6651  0.6624  0.6584
[49 : 64]:	0.6566  0.6558  0.6558  0.6507  0.6505  0.6504  0.6492  0.6476  0.6440  0.6424  0.6422  0.6391  0.6361  0.6361  0.6360  0.6343
2024-04-30 13:58:01 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-30 13:58:01 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-30 13:59:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1729: GFLOPs: 1594.6659. Time: 2320.8508 us. Best GFLOPs: 1594.6659
2024-04-30 13:59:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1730: GFLOPs: 1611.8514. Time: 2296.1061 us. Best GFLOPs: 1611.8514
2024-04-30 13:59:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1731: GFLOPs: 1588.5467. Time: 2329.7910 us. Best GFLOPs: 1611.8514
2024-04-30 13:59:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1732: GFLOPs: 1314.0883. Time: 2816.3874 us. Best GFLOPs: 1611.8514
2024-04-30 13:59:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1733: GFLOPs: 725.9811. Time: 5097.9037 us. Best GFLOPs: 1611.8514
2024-04-30 13:59:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1734: GFLOPs: 1243.1486. Time: 2977.1033 us. Best GFLOPs: 1611.8514
2024-04-30 13:59:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1735: GFLOPs: 1148.0184. Time: 3223.8000 us. Best GFLOPs: 1611.8514
2024-04-30 13:59:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1736: GFLOPs: 1286.8579. Time: 2875.9832 us. Best GFLOPs: 1611.8514
2024-04-30 13:59:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1737: GFLOPs: 1307.7213. Time: 2830.0998 us. Best GFLOPs: 1611.8514
2024-04-30 13:59:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1738: GFLOPs: 1217.2442. Time: 3040.4596 us. Best GFLOPs: 1611.8514
2024-04-30 13:59:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1739: GFLOPs: 1351.4027. Time: 2738.6225 us. Best GFLOPs: 1611.8514
2024-04-30 13:59:52 [INFO] [task_scheduler.cc:121] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1740: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(56), T.int64(56), T.int64(256)), "float32"), p1: T.Buffer((T.int64(8), T.int64(1), T.int64(3), T.int64(3), T.int64(256), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(58), T.int64(58), T.int64(256)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused in T.parallel(T.int64(448), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(16), T.int64(3), T.int64(256)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(224) * T.int64(28) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(4) // T.int64(2) * T.int64(14) + ax2)
                    v_i3 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(2) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(224) // T.int64(8) * T.int64(2) + ax3)
                    v_i4 = T.axis.spatial(T.int64(256), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(57) and T.int64(1) <= v_i3 and v_i3 < T.int64(57), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oc_block_1 in range(T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(14), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(8), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(8) // T.int64(4) * T.int64(4) + oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(224) * T.int64(28) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(4) // T.int64(2) * T.int64(14) + oh_2_init * T.int64(14) + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(224) // T.int64(8) * T.int64(2) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(2) + ow_2_init + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(128), T.int64(1), T.int64(3), T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(32), T.int64(2), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(14), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(8), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(8) // T.int64(4) * T.int64(4) + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(224) * T.int64(28) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(4) // T.int64(2) * T.int64(14) + oh_2 * T.int64(14) + oh_3)
                        v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(224) // T.int64(8) * T.int64(2) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(2) + ow_2 + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(2) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)], p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)] * p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block]
                for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(4), T.int64(14)):
                    for ax3_ax4_fused in T.vectorized(T.int64(32)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(8), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(8) // T.int64(4) * T.int64(4) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(224) * T.int64(28) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(4) // T.int64(2) * T.int64(14) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(224) // T.int64(8) * T.int64(2) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(2))
                            v_ax4 = T.axis.spatial(T.int64(32), ax3_ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 2, 4, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 2, 1, 14])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[28, 2, 1, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 32, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[128, 2])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=8)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b68)
l85 = sch.fuse(l71, l72, l73, l74, l75, l76, l77, l78, l79, preserve_unit_iters=True)
sch.parallel(loop=l85)
l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l86, preserve_unit_iters=True)
sch.parallel(loop=l104)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109, l110, l111 = sch.get_loops(block=b70)
l112 = sch.fuse(l110, l111, preserve_unit_iters=True)
sch.vectorize(loop=l112)
b113 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131 = sch.get_loops(block=b113)
b132 = sch.decompose_reduction(block=b113, loop=l116)
2024-04-30 13:59:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1741: GFLOPs: 1230.5472. Time: 3007.5903 us. Best GFLOPs: 1611.8514
2024-04-30 13:59:52 [INFO] [task_scheduler.cc:121] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1742: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(56), T.int64(56), T.int64(256)), "float32"), p1: T.Buffer((T.int64(8), T.int64(1), T.int64(3), T.int64(3), T.int64(256), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(58), T.int64(58), T.int64(256)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused in T.parallel(T.int64(448), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(16), T.int64(3), T.int64(256)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(112) * T.int64(14) + ax2)
                    v_i3 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(56) + ax3)
                    v_i4 = T.axis.spatial(T.int64(256), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(57) and T.int64(1) <= v_i3 and v_i3 < T.int64(57), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oc_block_1 in range(T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(14), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(8), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(112) // T.int64(56) * T.int64(4) + oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(112) * T.int64(14) + oh_2_init * T.int64(14) + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(56) + ow_2_init + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(128), T.int64(1), T.int64(3), T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(32), T.int64(2), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(14), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(8), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(112) // T.int64(56) * T.int64(4) + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(112) * T.int64(14) + oh_2 * T.int64(14) + oh_3)
                        v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(56) + ow_2 + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(2) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)], p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)] * p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block]
                for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(4), T.int64(14)):
                    for ax3_ax4_fused in T.vectorized(T.int64(32)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(8), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(112) // T.int64(56) * T.int64(4) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(112) * T.int64(14) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(56))
                            v_ax4 = T.axis.spatial(T.int64(32), ax3_ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 2, 4, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[4, 1, 1, 14])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 56, 1, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 32, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[128, 2])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=8)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b68)
l85 = sch.fuse(l71, l72, l73, l74, l75, l76, l77, l78, l79, preserve_unit_iters=True)
sch.parallel(loop=l85)
l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l86, preserve_unit_iters=True)
sch.parallel(loop=l104)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109, l110, l111 = sch.get_loops(block=b70)
l112 = sch.fuse(l110, l111, preserve_unit_iters=True)
sch.vectorize(loop=l112)
b113 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131 = sch.get_loops(block=b113)
b132 = sch.decompose_reduction(block=b113, loop=l116)
2024-04-30 13:59:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1743: GFLOPs: 1240.2968. Time: 2983.9484 us. Best GFLOPs: 1611.8514
2024-04-30 13:59:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1744: GFLOPs: 1198.0239. Time: 3089.2386 us. Best GFLOPs: 1611.8514
2024-04-30 13:59:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1745: GFLOPs: 747.1561. Time: 4953.4252 us. Best GFLOPs: 1611.8514
2024-04-30 13:59:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1746: GFLOPs: 758.5980. Time: 4878.7130 us. Best GFLOPs: 1611.8514
2024-04-30 13:59:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1747: GFLOPs: 1220.7638. Time: 3031.6936 us. Best GFLOPs: 1611.8514
2024-04-30 13:59:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1748: GFLOPs: 1188.0000. Time: 3115.3045 us. Best GFLOPs: 1611.8514
2024-04-30 13:59:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1749: GFLOPs: 1225.8149. Time: 3019.2012 us. Best GFLOPs: 1611.8514
2024-04-30 13:59:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1750: GFLOPs: 1019.0169. Time: 3631.9142 us. Best GFLOPs: 1611.8514
2024-04-30 13:59:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1751: GFLOPs: 758.7018. Time: 4878.0452 us. Best GFLOPs: 1611.8514
2024-04-30 13:59:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1752: GFLOPs: 757.7536. Time: 4884.1491 us. Best GFLOPs: 1611.8514
2024-04-30 13:59:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1753: GFLOPs: 1124.0290. Time: 3292.6033 us. Best GFLOPs: 1611.8514
2024-04-30 13:59:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1754: GFLOPs: 1019.0775. Time: 3631.6981 us. Best GFLOPs: 1611.8514
2024-04-30 13:59:52 [INFO] [task_scheduler.cc:121] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1755: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(56), T.int64(56), T.int64(256)), "float32"), p1: T.Buffer((T.int64(8), T.int64(1), T.int64(3), T.int64(3), T.int64(256), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(58), T.int64(58), T.int64(256)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_fused_fused in T.parallel(T.int64(224), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for oc_block_0, n_1, oc_chunk_1, oh_1 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(2)):
                for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(16), T.int64(3), T.int64(256)):
                    with T.block("data_pad"):
                        v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                        v_i2 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(112) // T.int64(56) * T.int64(28) + oh_1 * T.int64(14) + ax2)
                        v_i3 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(56) + ax3)
                        v_i4 = T.axis.spatial(T.int64(256), ax4)
                        T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                        T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                        data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(57) and T.int64(1) <= v_i3 and v_i3 < T.int64(57), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                for ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1)):
                    for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(14), T.int64(1), T.int64(1)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(8), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(112) * T.int64(4) + oc_chunk_1 * T.int64(4) + oc_chunk_2_init + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(112) // T.int64(56) * T.int64(28) + oh_1 * T.int64(14) + oh_2_init * T.int64(14) + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(56) + ow_1 + ow_2_init + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(32), oc_block_0 * T.int64(32) + oc_block_1 * T.int64(32) + oc_block_2_init + oc_block_3_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                    for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(128), T.int64(1), T.int64(3), T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(32), T.int64(2), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(14), T.int64(1), T.int64(1)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(8), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(112) * T.int64(4) + oc_chunk_1 * T.int64(4) + oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(112) // T.int64(56) * T.int64(28) + oh_1 * T.int64(14) + oh_2 * T.int64(14) + oh_3)
                            v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(56) + ow_1 + ow_2 + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(32), oc_block_0 * T.int64(32) + oc_block_1 * T.int64(32) + oc_block_2 + oc_block_3)
                            v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(2) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)], p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)] * p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block]
                    for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(4), T.int64(14)):
                        for ax3_ax4_fused in T.vectorized(T.int64(32)):
                            with T.block("T_relu"):
                                v_ax0 = T.axis.spatial(T.int64(1), ax0)
                                v_ax1 = T.axis.spatial(T.int64(8), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(112) * T.int64(4) + ax1)
                                v_ax2 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(112) // T.int64(56) * T.int64(28) + oh_1 * T.int64(14) + ax2)
                                v_ax3 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(56))
                                v_ax4 = T.axis.spatial(T.int64(32), ax3_ax4_fused)
                                T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                                T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                                T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[2, 1, 4, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 2, 1, 14])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[56, 1, 1, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 32, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[128, 2])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=4)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=7)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83 = sch.get_loops(block=b68)
l84 = sch.fuse(l71, l72, l73, l74, preserve_unit_iters=True)
sch.parallel(loop=l84)
l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107 = sch.get_loops(block=b69)
l108 = sch.fuse(l85, preserve_unit_iters=True)
sch.parallel(loop=l108)
sch.annotate(block_or_loop=l108, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l108, ann_key="pragma_unroll_explicit", ann_val=1)
l109, l110, l111, l112, l113, l114, l115, l116, l117, l118, l119, l120 = sch.get_loops(block=b70)
l121 = sch.fuse(l119, l120, preserve_unit_iters=True)
sch.vectorize(loop=l121)
b122 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141, l142, l143, l144, l145 = sch.get_loops(block=b122)
b146 = sch.decompose_reduction(block=b122, loop=l130)
2024-04-30 13:59:52 [INFO] [task_scheduler.cc:121] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1756: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(56), T.int64(56), T.int64(256)), "float32"), p1: T.Buffer((T.int64(8), T.int64(1), T.int64(3), T.int64(3), T.int64(256), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(58), T.int64(58), T.int64(256)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused in T.parallel(T.int64(448), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(16), T.int64(3), T.int64(256)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(224) * T.int64(28) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(2) * T.int64(14) + ax2)
                    v_i3 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(224) // T.int64(4) + ax3)
                    v_i4 = T.axis.spatial(T.int64(256), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(57) and T.int64(1) <= v_i3 and v_i3 < T.int64(57), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(14), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(8), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(4) // T.int64(2) * T.int64(4) + oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(224) * T.int64(28) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(2) * T.int64(14) + oh_2_init * T.int64(14) + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(224) // T.int64(4) + ow_1 + ow_2_init + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(128), T.int64(1), T.int64(3), T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(32), T.int64(2), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(14), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(8), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(4) // T.int64(2) * T.int64(4) + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(224) * T.int64(28) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(2) * T.int64(14) + oh_2 * T.int64(14) + oh_3)
                        v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(224) // T.int64(4) + ow_1 + ow_2 + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(2) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)], p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)] * p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block]
                for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(4), T.int64(14)):
                    for ax3_ax4_fused in T.vectorized(T.int64(32)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(8), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(4) // T.int64(2) * T.int64(4) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(224) * T.int64(28) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(2) * T.int64(14) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(224) // T.int64(4))
                            v_ax4 = T.axis.spatial(T.int64(32), ax3_ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 2, 4, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 2, 1, 14])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[56, 1, 1, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 32, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[128, 2])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=7)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83 = sch.get_loops(block=b68)
l84 = sch.fuse(l71, l72, l73, l74, l75, l76, l77, l78, preserve_unit_iters=True)
sch.parallel(loop=l84)
l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l85, preserve_unit_iters=True)
sch.parallel(loop=l104)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109, l110, l111, l112 = sch.get_loops(block=b70)
l113 = sch.fuse(l111, l112, preserve_unit_iters=True)
sch.vectorize(loop=l113)
b114 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133 = sch.get_loops(block=b114)
b134 = sch.decompose_reduction(block=b114, loop=l118)
2024-04-30 13:59:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1757: GFLOPs: 1170.7275. Time: 3161.2665 us. Best GFLOPs: 1611.8514
2024-04-30 13:59:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1758: GFLOPs: 1112.8339. Time: 3325.7271 us. Best GFLOPs: 1611.8514
2024-04-30 13:59:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1759: GFLOPs: 1162.3742. Time: 3183.9847 us. Best GFLOPs: 1611.8514
2024-04-30 13:59:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1760: GFLOPs: 57.1513. Time: 64757.6683 us. Best GFLOPs: 1611.8514
2024-04-30 13:59:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1761: GFLOPs: 1182.2347. Time: 3130.4966 us. Best GFLOPs: 1611.8514
2024-04-30 13:59:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1762: GFLOPs: 1111.3965. Time: 3330.0281 us. Best GFLOPs: 1611.8514
2024-04-30 13:59:52 [INFO] [task_scheduler.cc:121] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1763: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(56), T.int64(56), T.int64(256)), "float32"), p1: T.Buffer((T.int64(8), T.int64(1), T.int64(3), T.int64(3), T.int64(256), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(58), T.int64(58), T.int64(256)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)))
        for i0_i1_i2_i3_fused in T.parallel(T.int64(3364)):
            for i4 in range(T.int64(256)):
                with T.block("data_pad"):
                    v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_i1 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_i2 = T.axis.spatial(T.int64(58), i0_i1_i2_i3_fused // T.int64(58))
                    v_i3 = T.axis.spatial(T.int64(58), i0_i1_i2_i3_fused % T.int64(58))
                    v_i4 = T.axis.spatial(T.int64(256), i4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(57) and T.int64(1) <= v_i3 and v_i3 < T.int64(57), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused in T.parallel(T.int64(224), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(14), T.int64(1), T.int64(1)):
                with T.block("conv2d_NCHWc_init"):
                    v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                    v_oc_chunk = T.axis.spatial(T.int64(8), oc_chunk_2_init + oc_chunk_3_init)
                    v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused // T.int64(112) * T.int64(28) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(8) // T.int64(4) * T.int64(14) + oh_2_init * T.int64(14) + oh_3_init)
                    v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(112) // T.int64(8) * T.int64(4) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(4) + ow_2_init + ow_3_init)
                    v_oc_block = T.axis.spatial(T.int64(32), oc_block_2_init + oc_block_3_init)
                    T.reads()
                    T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                    T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                    conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
            for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(64), T.int64(1), T.int64(1), T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(32), T.int64(4), T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(14), T.int64(1), T.int64(1)):
                with T.block("conv2d_NCHWc_update"):
                    v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                    v_oc_chunk = T.axis.spatial(T.int64(8), oc_chunk_2 + oc_chunk_3)
                    v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused // T.int64(112) * T.int64(28) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(8) // T.int64(4) * T.int64(14) + oh_2 * T.int64(14) + oh_3)
                    v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(112) // T.int64(8) * T.int64(4) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(4) + ow_2 + ow_3)
                    v_oc_block = T.axis.spatial(T.int64(32), oc_block_2 + oc_block_3)
                    v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(4) + ic_1)
                    v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                    v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                    T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)], p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block])
                    T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                    T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                    conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)] * p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block]
            for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(8), T.int64(14)):
                for ax3_ax4_fused in T.vectorized(T.int64(32)):
                    with T.block("T_relu"):
                        v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                        v_ax2 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused // T.int64(112) * T.int64(28) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(8) // T.int64(4) * T.int64(14) + ax2)
                        v_ax3 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(112) // T.int64(8) * T.int64(4) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(4))
                        v_ax4 = T.axis.spatial(T.int64(32), ax3_ax4_fused)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 8, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 2, 1, 14])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[14, 4, 1, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 32, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[64, 4])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=-1)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75 = sch.get_loops(block=b68)
l76 = sch.fuse(l71, l72, l73, l74, preserve_unit_iters=True)
sch.parallel(loop=l76)
l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102 = sch.get_loops(block=b69)
l103 = sch.fuse(l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, preserve_unit_iters=True)
sch.parallel(loop=l103)
sch.annotate(block_or_loop=l103, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l103, ann_key="pragma_unroll_explicit", ann_val=1)
l104, l105, l106, l107, l108, l109 = sch.get_loops(block=b70)
l110 = sch.fuse(l108, l109, preserve_unit_iters=True)
sch.vectorize(loop=l110)
b111 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l112, l113, l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128 = sch.get_loops(block=b111)
b129 = sch.decompose_reduction(block=b111, loop=l113)
2024-04-30 13:59:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1764: GFLOPs: 145.9252. Time: 25362.1908 us. Best GFLOPs: 1611.8514
2024-04-30 13:59:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1765: GFLOPs: 705.7527. Time: 5244.0206 us. Best GFLOPs: 1611.8514
2024-04-30 13:59:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1766: GFLOPs: 1092.6751. Time: 3387.0835 us. Best GFLOPs: 1611.8514
2024-04-30 13:59:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1767: GFLOPs: 1236.1391. Time: 2993.9850 us. Best GFLOPs: 1611.8514
2024-04-30 13:59:52 [INFO] [task_scheduler.cc:121] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1768: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(56), T.int64(56), T.int64(256)), "float32"), p1: T.Buffer((T.int64(8), T.int64(1), T.int64(3), T.int64(3), T.int64(256), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(58), T.int64(58), T.int64(256)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused in T.parallel(T.int64(448), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(16), T.int64(3), T.int64(256)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(224) // T.int64(112) * T.int64(28) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(2) * T.int64(14) + ax2)
                    v_i3 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(112) // T.int64(2) + ax3)
                    v_i4 = T.axis.spatial(T.int64(256), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(57) and T.int64(1) <= v_i3 and v_i3 < T.int64(57), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(14), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(8), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(224) * T.int64(4) + oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(224) // T.int64(112) * T.int64(28) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(2) * T.int64(14) + oh_2_init * T.int64(14) + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(112) // T.int64(2) + ow_1 + ow_2_init + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(128), T.int64(1), T.int64(3), T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(32), T.int64(2), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(14), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(8), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(224) * T.int64(4) + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(224) // T.int64(112) * T.int64(28) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(2) * T.int64(14) + oh_2 * T.int64(14) + oh_3)
                        v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(112) // T.int64(2) + ow_1 + ow_2 + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(2) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)], p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)] * p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block]
                for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(4), T.int64(14)):
                    for ax3_ax4_fused in T.vectorized(T.int64(32)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(8), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(224) * T.int64(4) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(224) // T.int64(112) * T.int64(28) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(2) * T.int64(14) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(112) // T.int64(2))
                            v_ax4 = T.axis.spatial(T.int64(32), ax3_ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[2, 1, 4, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 2, 1, 14])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[56, 1, 1, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 32, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[128, 2])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=7)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83 = sch.get_loops(block=b68)
l84 = sch.fuse(l71, l72, l73, l74, l75, l76, l77, l78, preserve_unit_iters=True)
sch.parallel(loop=l84)
l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l85, preserve_unit_iters=True)
sch.parallel(loop=l104)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109, l110, l111, l112 = sch.get_loops(block=b70)
l113 = sch.fuse(l111, l112, preserve_unit_iters=True)
sch.vectorize(loop=l113)
b114 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133 = sch.get_loops(block=b114)
b134 = sch.decompose_reduction(block=b114, loop=l118)
2024-04-30 13:59:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1769: GFLOPs: 1050.0068. Time: 3524.7216 us. Best GFLOPs: 1611.8514
2024-04-30 13:59:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1770: GFLOPs: 1135.9610. Time: 3258.0182 us. Best GFLOPs: 1611.8514
2024-04-30 13:59:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1771: GFLOPs: 1087.8451. Time: 3402.1221 us. Best GFLOPs: 1611.8514
2024-04-30 13:59:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1772: GFLOPs: 1051.0682. Time: 3521.1622 us. Best GFLOPs: 1611.8514
2024-04-30 13:59:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1773: GFLOPs: 991.1275. Time: 3734.1126 us. Best GFLOPs: 1611.8514
2024-04-30 13:59:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1774: GFLOPs: 1041.6158. Time: 3553.1159 us. Best GFLOPs: 1611.8514
2024-04-30 13:59:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1775: GFLOPs: 1263.9610. Time: 2928.0823 us. Best GFLOPs: 1611.8514
2024-04-30 13:59:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1776: GFLOPs: 58.1321. Time: 63665.0663 us. Best GFLOPs: 1611.8514
2024-04-30 13:59:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1777: GFLOPs: 997.1668. Time: 3711.4973 us. Best GFLOPs: 1611.8514
2024-04-30 13:59:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1778: GFLOPs: 1059.6942. Time: 3492.4997 us. Best GFLOPs: 1611.8514
2024-04-30 13:59:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1779: GFLOPs: 1061.8551. Time: 3485.3926 us. Best GFLOPs: 1611.8514
2024-04-30 13:59:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1780: GFLOPs: 1031.7829. Time: 3586.9773 us. Best GFLOPs: 1611.8514
2024-04-30 13:59:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1781: GFLOPs: 971.2591. Time: 3810.4988 us. Best GFLOPs: 1611.8514
2024-04-30 13:59:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1782: GFLOPs: 1042.5472. Time: 3549.9417 us. Best GFLOPs: 1611.8514
2024-04-30 13:59:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1783: GFLOPs: 149.5508. Time: 24747.3160 us. Best GFLOPs: 1611.8514
2024-04-30 13:59:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1784: GFLOPs: 58.6058. Time: 63150.4740 us. Best GFLOPs: 1611.8514
2024-04-30 13:59:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1785: GFLOPs: 1036.2674. Time: 3571.4545 us. Best GFLOPs: 1611.8514
2024-04-30 13:59:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1786: GFLOPs: 1019.8614. Time: 3628.9066 us. Best GFLOPs: 1611.8514
2024-04-30 13:59:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1787: GFLOPs: 983.7861. Time: 3761.9780 us. Best GFLOPs: 1611.8514
2024-04-30 13:59:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1788: GFLOPs: 1060.0867. Time: 3491.2065 us. Best GFLOPs: 1611.8514
2024-04-30 13:59:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1789: GFLOPs: 152.0040. Time: 24347.9232 us. Best GFLOPs: 1611.8514
2024-04-30 13:59:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1790: GFLOPs: 68.8545. Time: 53750.7837 us. Best GFLOPs: 1611.8514
2024-04-30 13:59:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1791: GFLOPs: 88.9256. Time: 41618.8397 us. Best GFLOPs: 1611.8514
2024-04-30 13:59:52 [INFO] [task_scheduler.cc:121] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1792: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(56), T.int64(56), T.int64(256)), "float32"), p1: T.Buffer((T.int64(8), T.int64(1), T.int64(3), T.int64(3), T.int64(256), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(58), T.int64(58), T.int64(256)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_fused_fused in T.parallel(T.int64(8), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(58), T.int64(16), T.int64(256)):
                with T.block("data_pad"):
                    v_i0, v_i1, v_i2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                    v_i3 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(4) * T.int64(14) + ax3)
                    v_i4 = T.axis.spatial(T.int64(256), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(57) and T.int64(1) <= v_i3 and v_i3 < T.int64(57), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oc_block_0, n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(2), T.int64(2), T.int64(2), T.int64(4)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(2), T.int64(1), T.int64(2), T.int64(28), T.int64(1)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(8), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(4) * T.int64(4) + oc_chunk_1 * T.int64(2) + oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(56), oh_1 * T.int64(28) + oh_2_init * T.int64(28) + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(4) * T.int64(14) + ow_1 * T.int64(7) + ow_2_init + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(32), oc_block_0 * T.int64(32) + oc_block_1 * T.int64(8) + oc_block_2_init * T.int64(4) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(32), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(2), T.int64(8), T.int64(1), T.int64(3), T.int64(1), T.int64(2), T.int64(28), T.int64(1)):
                    for oc_block_3_fused in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(8), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(4) * T.int64(4) + oc_chunk_1 * T.int64(2) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(56), oh_1 * T.int64(28) + oh_2 * T.int64(28) + oh_3)
                            v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(4) * T.int64(14) + ow_1 * T.int64(7) + ow_2 + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(32), oc_block_0 * T.int64(32) + oc_block_1 * T.int64(8) + oc_block_2 * T.int64(4) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(8) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)], p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)] * p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block]
        for ax0_ax1_ax2_ax3_ax4_fused_0 in T.parallel(T.int64(12544)):
            for ax0_ax1_ax2_ax3_ax4_fused_1 in T.vectorized(T.int64(64)):
                with T.block("T_relu"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(8), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) // T.int64(100352))
                    v_ax2 = T.axis.spatial(T.int64(56), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(100352) // T.int64(1792))
                    v_ax3 = T.axis.spatial(T.int64(56), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(1792) // T.int64(32))
                    v_ax4 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(32))
                    T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                    T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[2, 2, 1, 2])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 2, 1, 28])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[4, 2, 7, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 4, 2, 4])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[32, 8])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
l65 = sch.sample_compute_location(block=b0, decision=3)
sch.compute_at(block=b0, loop=l65, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b66 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.unroll_explicit")
b67, b68, b69 = sch.get_child_blocks(b66)
l70, l71, l72, l73, l74, l75, l76, l77, l78 = sch.get_loops(block=b67)
l79 = sch.fuse(l70, l71, l72, l73, preserve_unit_iters=True)
sch.parallel(loop=l79)
l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102 = sch.get_loops(block=b68)
l103 = sch.fuse(l80, preserve_unit_iters=True)
sch.parallel(loop=l103)
l104 = sch.fuse(l102, preserve_unit_iters=True)
sch.vectorize(loop=l104)
sch.annotate(block_or_loop=l103, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l103, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109 = sch.get_loops(block=b69)
l110 = sch.fuse(l105, l106, l107, l108, l109, preserve_unit_iters=True)
l111, l112 = sch.split(loop=l110, factors=[None, 64], preserve_unit_iters=True)
sch.parallel(loop=l111)
sch.vectorize(loop=l112)
b113 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136 = sch.get_loops(block=b113)
b137 = sch.decompose_reduction(block=b113, loop=l121)
2024-04-30 13:59:52 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-30 13:59:54 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-30 13:59:58 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 13:59:58 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-30 14:00:11 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 14:00:24 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 14:00:37 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 14:00:50 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 14:00:58 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9263  0.9263  0.8311  0.8131  0.8081  0.8075  0.8020  0.8020  0.7774  0.7739  0.7515  0.7428  0.7370  0.7353  0.7239  0.7234
[17 : 32]:	0.7220  0.7072  0.7065  0.6946  0.6842  0.6830  0.6807  0.6793  0.6707  0.6707  0.6688  0.6659  0.6579  0.6571  0.6570  0.6544
[33 : 48]:	0.6543  0.6538  0.6517  0.6511  0.6502  0.6494  0.6490  0.6483  0.6483  0.6410  0.6364  0.6351  0.6346  0.6319  0.6296  0.6296
[49 : 64]:	0.6296  0.6296  0.6290  0.6290  0.6215  0.6212  0.6211  0.6211  0.6195  0.6184  0.6175  0.6171  0.6156  0.6113  0.6103  0.6100
2024-04-30 14:00:58 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-30 14:00:58 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-30 14:03:08 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1793: GFLOPs: 1602.2543. Time: 2309.8591 us. Best GFLOPs: 1611.8514
2024-04-30 14:03:08 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1794: GFLOPs: 1620.4045. Time: 2283.9864 us. Best GFLOPs: 1620.4045
2024-04-30 14:03:08 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1795: GFLOPs: 1614.0190. Time: 2293.0225 us. Best GFLOPs: 1620.4045
2024-04-30 14:03:08 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1796: GFLOPs: 1374.2214. Time: 2693.1481 us. Best GFLOPs: 1620.4045
2024-04-30 14:03:08 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1797: GFLOPs: 1392.7706. Time: 2657.2803 us. Best GFLOPs: 1620.4045
2024-04-30 14:03:08 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1798: GFLOPs: 1364.9557. Time: 2711.4300 us. Best GFLOPs: 1620.4045
2024-04-30 14:03:08 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1799: GFLOPs: 1229.0219. Time: 3011.3228 us. Best GFLOPs: 1620.4045
2024-04-30 14:03:08 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1800: GFLOPs: 1308.8776. Time: 2827.5996 us. Best GFLOPs: 1620.4045
2024-04-30 14:03:08 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1801: GFLOPs: 1234.0796. Time: 2998.9814 us. Best GFLOPs: 1620.4045
2024-04-30 14:03:08 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1802: GFLOPs: 1278.3418. Time: 2895.1425 us. Best GFLOPs: 1620.4045
2024-04-30 14:03:08 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1803: GFLOPs: 1165.3304. Time: 3175.9076 us. Best GFLOPs: 1620.4045
2024-04-30 14:03:08 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1804: GFLOPs: 1294.5336. Time: 2858.9307 us. Best GFLOPs: 1620.4045
2024-04-30 14:03:08 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1805: GFLOPs: 1311.2642. Time: 2822.4531 us. Best GFLOPs: 1620.4045
2024-04-30 14:03:08 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1806: GFLOPs: 1323.9039. Time: 2795.5063 us. Best GFLOPs: 1620.4045
2024-04-30 14:03:08 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1807: GFLOPs: 1091.0648. Time: 3392.0825 us. Best GFLOPs: 1620.4045
2024-04-30 14:03:08 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1808: GFLOPs: 158.5578. Time: 23341.5310 us. Best GFLOPs: 1620.4045
2024-04-30 14:03:08 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1809: GFLOPs: 999.0815. Time: 3704.3842 us. Best GFLOPs: 1620.4045
2024-04-30 14:03:08 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1810: GFLOPs: 1096.6588. Time: 3374.7795 us. Best GFLOPs: 1620.4045
2024-04-30 14:03:08 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1811: GFLOPs: 1080.0675. Time: 3426.6208 us. Best GFLOPs: 1620.4045
2024-04-30 14:03:08 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1812: GFLOPs: 791.7166. Time: 4674.6292 us. Best GFLOPs: 1620.4045
2024-04-30 14:03:08 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1813: GFLOPs: 1192.3902. Time: 3103.8344 us. Best GFLOPs: 1620.4045
2024-04-30 14:03:08 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1814: GFLOPs: 1157.8741. Time: 3196.3595 us. Best GFLOPs: 1620.4045
2024-04-30 14:03:08 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1815: GFLOPs: 842.6949. Time: 4391.8406 us. Best GFLOPs: 1620.4045
2024-04-30 14:03:08 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1816: GFLOPs: 720.5040. Time: 5136.6566 us. Best GFLOPs: 1620.4045
2024-04-30 14:03:08 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1817: GFLOPs: 1026.3587. Time: 3605.9339 us. Best GFLOPs: 1620.4045
2024-04-30 14:03:08 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1818: GFLOPs: 1002.6446. Time: 3691.2198 us. Best GFLOPs: 1620.4045
2024-04-30 14:03:08 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1819: GFLOPs: 1061.7845. Time: 3485.6242 us. Best GFLOPs: 1620.4045
2024-04-30 14:03:08 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1820: GFLOPs: 199.9853. Time: 18506.2693 us. Best GFLOPs: 1620.4045
2024-04-30 14:03:08 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1821: GFLOPs: 1196.4368. Time: 3093.3365 us. Best GFLOPs: 1620.4045
2024-04-30 14:03:08 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1822: GFLOPs: 1190.1064. Time: 3109.7906 us. Best GFLOPs: 1620.4045
2024-04-30 14:03:08 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1823: GFLOPs: 1028.9390. Time: 3596.8913 us. Best GFLOPs: 1620.4045
2024-04-30 14:03:08 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1824: GFLOPs: 1120.9093. Time: 3301.7673 us. Best GFLOPs: 1620.4045
2024-04-30 14:03:08 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1825: GFLOPs: 533.5642. Time: 6936.3384 us. Best GFLOPs: 1620.4045
2024-04-30 14:03:08 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1826: GFLOPs: 1114.2615. Time: 3321.4660 us. Best GFLOPs: 1620.4045
2024-04-30 14:03:08 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1827: GFLOPs: 1000.8561. Time: 3697.8160 us. Best GFLOPs: 1620.4045
2024-04-30 14:03:08 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1828: GFLOPs: 1005.7942. Time: 3679.6610 us. Best GFLOPs: 1620.4045
2024-04-30 14:03:08 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1829: GFLOPs: 1003.7254. Time: 3687.2454 us. Best GFLOPs: 1620.4045
2024-04-30 14:03:08 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1830: GFLOPs: 1291.0804. Time: 2866.5773 us. Best GFLOPs: 1620.4045
2024-04-30 14:03:08 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1831: GFLOPs: 1175.3353. Time: 3148.8731 us. Best GFLOPs: 1620.4045
2024-04-30 14:03:08 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1832: GFLOPs: 1095.2756. Time: 3379.0416 us. Best GFLOPs: 1620.4045
2024-04-30 14:03:08 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1833: GFLOPs: 1045.2452. Time: 3540.7786 us. Best GFLOPs: 1620.4045
2024-04-30 14:03:08 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1834: GFLOPs: 738.8334. Time: 5009.2236 us. Best GFLOPs: 1620.4045
2024-04-30 14:03:08 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1835: GFLOPs: 1059.4117. Time: 3493.4310 us. Best GFLOPs: 1620.4045
2024-04-30 14:03:08 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1836: GFLOPs: 1039.6858. Time: 3559.7118 us. Best GFLOPs: 1620.4045
2024-04-30 14:03:08 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1837: GFLOPs: 1490.4654. Time: 2483.1048 us. Best GFLOPs: 1620.4045
2024-04-30 14:03:08 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1838: GFLOPs: 996.9385. Time: 3712.3470 us. Best GFLOPs: 1620.4045
2024-04-30 14:03:08 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1839: GFLOPs: 29.4808. Time: 125538.6153 us. Best GFLOPs: 1620.4045
2024-04-30 14:03:08 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1840: GFLOPs: 29.4889. Time: 125504.1147 us. Best GFLOPs: 1620.4045
2024-04-30 14:03:08 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1841: GFLOPs: 27.1060. Time: 136537.2160 us. Best GFLOPs: 1620.4045
2024-04-30 14:03:08 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1842: GFLOPs: 20.8126. Time: 177824.2980 us. Best GFLOPs: 1620.4045
2024-04-30 14:03:08 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1843: GFLOPs: 1040.8106. Time: 3555.8648 us. Best GFLOPs: 1620.4045
2024-04-30 14:03:08 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1844: GFLOPs: 998.7874. Time: 3705.4750 us. Best GFLOPs: 1620.4045
2024-04-30 14:03:08 [INFO] [task_scheduler.cc:121] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1845: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(56), T.int64(56), T.int64(256)), "float32"), p1: T.Buffer((T.int64(8), T.int64(1), T.int64(3), T.int64(3), T.int64(256), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(58), T.int64(58), T.int64(256)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused in T.parallel(T.int64(448), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(9), T.int64(3), T.int64(256)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(32) // T.int64(4) * T.int64(7) + ax2)
                    v_i3 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(32) * T.int64(4) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(4) + ax3)
                    v_i4 = T.axis.spatial(T.int64(256), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(57) and T.int64(1) <= v_i3 and v_i3 < T.int64(57), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oc_block_1 in range(T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(8), oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(32) // T.int64(4) * T.int64(7) + oh_2_init * T.int64(7) + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(32) * T.int64(4) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(4) + ow_2_init + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(128), T.int64(1), T.int64(3), T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(32), T.int64(2), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(8), oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(32) // T.int64(4) * T.int64(7) + oh_2 * T.int64(7) + oh_3)
                        v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(32) * T.int64(4) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(4) + ow_2 + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(2) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)], p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)] * p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block]
                for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(8), T.int64(7)):
                    for ax3_ax4_fused in T.vectorized(T.int64(32)):
                        with T.block("T_relu"):
                            v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                            v_ax2 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(32) // T.int64(4) * T.int64(7) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(32) * T.int64(4) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(4))
                            v_ax4 = T.axis.spatial(T.int64(32), ax3_ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 8, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 8, 1, 7])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[14, 4, 1, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 32, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[128, 2])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=224)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=8)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b68)
l85 = sch.fuse(l71, l72, l73, l74, l75, l76, l77, l78, l79, preserve_unit_iters=True)
sch.parallel(loop=l85)
l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l86, preserve_unit_iters=True)
sch.parallel(loop=l104)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109, l110, l111 = sch.get_loops(block=b70)
l112 = sch.fuse(l110, l111, preserve_unit_iters=True)
sch.vectorize(loop=l112)
b113 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131 = sch.get_loops(block=b113)
b132 = sch.decompose_reduction(block=b113, loop=l116)
2024-04-30 14:03:08 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1846: GFLOPs: 1011.9048. Time: 3657.4406 us. Best GFLOPs: 1620.4045
2024-04-30 14:03:08 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1847: GFLOPs: 858.6131. Time: 4310.4185 us. Best GFLOPs: 1620.4045
2024-04-30 14:03:08 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1848: GFLOPs: 878.0596. Time: 4214.9552 us. Best GFLOPs: 1620.4045
2024-04-30 14:03:08 [INFO] [task_scheduler.cc:121] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1849: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(56), T.int64(56), T.int64(256)), "float32"), p1: T.Buffer((T.int64(8), T.int64(1), T.int64(3), T.int64(3), T.int64(256), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(58), T.int64(58), T.int64(256)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)))
        for i0_i1_i2_i3_fused in T.parallel(T.int64(3364)):
            for i4 in range(T.int64(256)):
                with T.block("data_pad"):
                    v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_i1 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_i2 = T.axis.spatial(T.int64(58), i0_i1_i2_i3_fused // T.int64(58))
                    v_i3 = T.axis.spatial(T.int64(58), i0_i1_i2_i3_fused % T.int64(58))
                    v_i4 = T.axis.spatial(T.int64(256), i4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(57) and T.int64(1) <= v_i3 and v_i3 < T.int64(57), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused in T.parallel(T.int64(224), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(32), T.int64(1), T.int64(8), T.int64(14), T.int64(1), T.int64(1)):
                with T.block("conv2d_NCHWc_init"):
                    v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                    v_oc_chunk = T.axis.spatial(T.int64(8), oc_chunk_2_init * T.int64(8) + oc_chunk_3_init)
                    v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused // T.int64(112) * T.int64(28) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(8) // T.int64(4) * T.int64(14) + oh_2_init * T.int64(14) + oh_3_init)
                    v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(112) // T.int64(8) * T.int64(4) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(4) + ow_2_init + ow_3_init)
                    v_oc_block = T.axis.spatial(T.int64(32), oc_block_2_init + oc_block_3_init)
                    T.reads()
                    T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                    T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                    conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
            for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(64), T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(32), T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(8), T.int64(14), T.int64(1), T.int64(1)):
                with T.block("conv2d_NCHWc_update"):
                    v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                    v_oc_chunk = T.axis.spatial(T.int64(8), oc_chunk_2 * T.int64(8) + oc_chunk_3)
                    v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused // T.int64(112) * T.int64(28) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(8) // T.int64(4) * T.int64(14) + oh_2 * T.int64(14) + oh_3)
                    v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(112) // T.int64(8) * T.int64(4) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(4) + ow_2 + ow_3)
                    v_oc_block = T.axis.spatial(T.int64(32), oc_block_2 + oc_block_3)
                    v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(4) + ic_1)
                    v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                    v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                    T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)], p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block])
                    T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                    T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                    conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)] * p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block]
            for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(8), T.int64(14)):
                for ax3_ax4_fused in T.vectorized(T.int64(32)):
                    with T.block("T_relu"):
                        v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                        v_ax2 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused // T.int64(112) * T.int64(28) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(8) // T.int64(4) * T.int64(14) + ax2)
                        v_ax3 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(112) // T.int64(8) * T.int64(4) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(4))
                        v_ax4 = T.axis.spatial(T.int64(32), ax3_ax4_fused)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 8])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 2, 1, 14])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[14, 4, 1, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 32, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[64, 4])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=-1)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75 = sch.get_loops(block=b68)
l76 = sch.fuse(l71, l72, l73, l74, preserve_unit_iters=True)
sch.parallel(loop=l76)
l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102 = sch.get_loops(block=b69)
l103 = sch.fuse(l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, preserve_unit_iters=True)
sch.parallel(loop=l103)
sch.annotate(block_or_loop=l103, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l103, ann_key="pragma_unroll_explicit", ann_val=1)
l104, l105, l106, l107, l108, l109 = sch.get_loops(block=b70)
l110 = sch.fuse(l108, l109, preserve_unit_iters=True)
sch.vectorize(loop=l110)
b111 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l112, l113, l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128 = sch.get_loops(block=b111)
b129 = sch.decompose_reduction(block=b111, loop=l113)
2024-04-30 14:03:08 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1850: GFLOPs: 1045.6020. Time: 3539.5704 us. Best GFLOPs: 1620.4045
2024-04-30 14:03:08 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1851: GFLOPs: 1067.7827. Time: 3466.0439 us. Best GFLOPs: 1620.4045
2024-04-30 14:03:08 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1852: GFLOPs: 1045.3340. Time: 3540.4777 us. Best GFLOPs: 1620.4045
2024-04-30 14:03:08 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1853: GFLOPs: 702.5350. Time: 5268.0393 us. Best GFLOPs: 1620.4045
2024-04-30 14:03:08 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1854: GFLOPs: 178.1656. Time: 20772.7086 us. Best GFLOPs: 1620.4045
2024-04-30 14:03:08 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1855: GFLOPs: 5.4703. Time: 676554.8250 us. Best GFLOPs: 1620.4045
2024-04-30 14:03:08 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1856: GFLOPs: 158.4258. Time: 23360.9822 us. Best GFLOPs: 1620.4045
2024-04-30 14:03:08 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-30 14:03:09 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-30 14:03:14 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 14:03:14 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-30 14:03:26 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 14:03:39 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 14:03:52 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 14:04:05 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 14:04:13 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9744  0.9701  0.9700  0.8443  0.8359  0.8359  0.8332  0.8138  0.7994  0.7903  0.7864  0.7862  0.7811  0.7794  0.7792  0.7790
[17 : 32]:	0.7781  0.7716  0.7710  0.7544  0.7417  0.7417  0.7414  0.7406  0.7406  0.7389  0.7313  0.7257  0.7206  0.7206  0.7071  0.7063
[33 : 48]:	0.7042  0.7016  0.6802  0.6720  0.6689  0.6634  0.6617  0.6574  0.6462  0.6455  0.6455  0.6453  0.6437  0.6427  0.6407  0.6405
[49 : 64]:	0.6395  0.6395  0.6394  0.6391  0.6313  0.6313  0.6309  0.6309  0.6309  0.6292  0.6278  0.6265  0.6223  0.6195  0.6191  0.6178
2024-04-30 14:04:13 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-30 14:04:13 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-30 14:05:59 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1857: GFLOPs: 1590.6299. Time: 2326.7398 us. Best GFLOPs: 1620.4045
2024-04-30 14:05:59 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1858: GFLOPs: 1639.7699. Time: 2257.0128 us. Best GFLOPs: 1639.7699
2024-04-30 14:05:59 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1859: GFLOPs: 1595.2603. Time: 2319.9861 us. Best GFLOPs: 1639.7699
2024-04-30 14:05:59 [INFO] [task_scheduler.cc:121] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1860: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(56), T.int64(56), T.int64(256)), "float32"), p1: T.Buffer((T.int64(8), T.int64(1), T.int64(3), T.int64(3), T.int64(256), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(58), T.int64(58), T.int64(256)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused in T.parallel(T.int64(224), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(16), T.int64(3), T.int64(256)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(16) // T.int64(4) * T.int64(14) + ax2)
                    v_i3 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(16) * T.int64(4) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(4) + ax3)
                    v_i4 = T.axis.spatial(T.int64(256), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(57) and T.int64(1) <= v_i3 and v_i3 < T.int64(57), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oc_block_1 in range(T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(14), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(8), oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(16) // T.int64(4) * T.int64(14) + oh_2_init * T.int64(14) + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(16) * T.int64(4) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(4) + ow_2_init + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(64), T.int64(1), T.int64(3), T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(32), T.int64(4), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(14), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(8), oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(16) // T.int64(4) * T.int64(14) + oh_2 * T.int64(14) + oh_3)
                        v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(16) * T.int64(4) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(4) + ow_2 + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(4) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)], p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)] * p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block]
                for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(8), T.int64(14)):
                    for ax3_ax4_fused in T.vectorized(T.int64(32)):
                        with T.block("T_relu"):
                            v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                            v_ax2 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(16) // T.int64(4) * T.int64(14) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(16) * T.int64(4) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(4))
                            v_ax4 = T.axis.spatial(T.int64(32), ax3_ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 8, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 4, 1, 14])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[14, 4, 1, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 32, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[64, 4])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=8)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b68)
l85 = sch.fuse(l71, l72, l73, l74, l75, l76, l77, l78, l79, preserve_unit_iters=True)
sch.parallel(loop=l85)
l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l86, preserve_unit_iters=True)
sch.parallel(loop=l104)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109, l110, l111 = sch.get_loops(block=b70)
l112 = sch.fuse(l110, l111, preserve_unit_iters=True)
sch.vectorize(loop=l112)
b113 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131 = sch.get_loops(block=b113)
b132 = sch.decompose_reduction(block=b113, loop=l116)
2024-04-30 14:05:59 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1861: GFLOPs: 1412.4328. Time: 2620.2888 us. Best GFLOPs: 1639.7699
2024-04-30 14:05:59 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1862: GFLOPs: 1409.7422. Time: 2625.2897 us. Best GFLOPs: 1639.7699
2024-04-30 14:05:59 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1863: GFLOPs: 1426.7723. Time: 2593.9541 us. Best GFLOPs: 1639.7699
2024-04-30 14:05:59 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1864: GFLOPs: 1255.1611. Time: 2948.6110 us. Best GFLOPs: 1639.7699
2024-04-30 14:05:59 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1865: GFLOPs: 1389.2062. Time: 2664.0982 us. Best GFLOPs: 1639.7699
2024-04-30 14:05:59 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1866: GFLOPs: 1237.8052. Time: 2989.9549 us. Best GFLOPs: 1639.7699
2024-04-30 14:05:59 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1867: GFLOPs: 1356.8666. Time: 2727.5945 us. Best GFLOPs: 1639.7699
2024-04-30 14:05:59 [INFO] [task_scheduler.cc:121] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1868: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(56), T.int64(56), T.int64(256)), "float32"), p1: T.Buffer((T.int64(8), T.int64(1), T.int64(3), T.int64(3), T.int64(256), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(58), T.int64(58), T.int64(256)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused in T.parallel(T.int64(448), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(16), T.int64(3), T.int64(256)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(4) * T.int64(14) + ax2)
                    v_i3 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(8) + ax3)
                    v_i4 = T.axis.spatial(T.int64(256), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(57) and T.int64(1) <= v_i3 and v_i3 < T.int64(57), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(14), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(8), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(8) // T.int64(4) * T.int64(4) + oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(4) * T.int64(14) + oh_2_init * T.int64(14) + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(8) + ow_1 + ow_2_init + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(128), T.int64(1), T.int64(3), T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(32), T.int64(2), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(14), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(8), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(8) // T.int64(4) * T.int64(4) + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(4) * T.int64(14) + oh_2 * T.int64(14) + oh_3)
                        v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(8) + ow_1 + ow_2 + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(2) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)], p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)] * p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block]
                for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(4), T.int64(14)):
                    for ax3_ax4_fused in T.vectorized(T.int64(32)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(8), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(8) // T.int64(4) * T.int64(4) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(4) * T.int64(14) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(8))
                            v_ax4 = T.axis.spatial(T.int64(32), ax3_ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 2, 4, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 4, 1, 14])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[56, 1, 1, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 32, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[128, 2])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=112)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=7)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83 = sch.get_loops(block=b68)
l84 = sch.fuse(l71, l72, l73, l74, l75, l76, l77, l78, preserve_unit_iters=True)
sch.parallel(loop=l84)
l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l85, preserve_unit_iters=True)
sch.parallel(loop=l104)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109, l110, l111, l112 = sch.get_loops(block=b70)
l113 = sch.fuse(l111, l112, preserve_unit_iters=True)
sch.vectorize(loop=l113)
b114 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133 = sch.get_loops(block=b114)
b134 = sch.decompose_reduction(block=b114, loop=l118)
2024-04-30 14:05:59 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1869: GFLOPs: 204.1799. Time: 18126.0803 us. Best GFLOPs: 1639.7699
2024-04-30 14:05:59 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1870: GFLOPs: 1279.2532. Time: 2893.0800 us. Best GFLOPs: 1639.7699
2024-04-30 14:05:59 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1871: GFLOPs: 1213.9675. Time: 3048.6663 us. Best GFLOPs: 1639.7699
2024-04-30 14:05:59 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1872: GFLOPs: 1320.8077. Time: 2802.0596 us. Best GFLOPs: 1639.7699
2024-04-30 14:05:59 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1873: GFLOPs: 1228.1070. Time: 3013.5661 us. Best GFLOPs: 1639.7699
2024-04-30 14:05:59 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1874: GFLOPs: 1301.5749. Time: 2843.4642 us. Best GFLOPs: 1639.7699
2024-04-30 14:05:59 [INFO] [task_scheduler.cc:121] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1875: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(56), T.int64(56), T.int64(256)), "float32"), p1: T.Buffer((T.int64(8), T.int64(1), T.int64(3), T.int64(3), T.int64(256), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(58), T.int64(58), T.int64(256)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused in T.parallel(T.int64(224), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ow_1 in range(T.int64(2)):
                for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(16), T.int64(3), T.int64(256)):
                    with T.block("data_pad"):
                        v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                        v_i2 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(112) * T.int64(28) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(2) * T.int64(14) + ax2)
                        v_i3 = T.axis.spatial(T.int64(58), ow_1 + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(112) // T.int64(4) * T.int64(2) + ax3)
                        v_i4 = T.axis.spatial(T.int64(256), ax4)
                        T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                        T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                        data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(57) and T.int64(1) <= v_i3 and v_i3 < T.int64(57), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                for oc_block_1 in range(T.int64(1)):
                    for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(14), T.int64(1), T.int64(1)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(8), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(4) // T.int64(2) * T.int64(4) + oc_chunk_2_init + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(112) * T.int64(28) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(2) * T.int64(14) + oh_2_init * T.int64(14) + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(112) // T.int64(4) * T.int64(2) + ow_1 + ow_2_init + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2_init + oc_block_3_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                    for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(128), T.int64(1), T.int64(3), T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(32), T.int64(2), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(14), T.int64(1), T.int64(1)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(8), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(4) // T.int64(2) * T.int64(4) + oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(112) * T.int64(28) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(2) * T.int64(14) + oh_2 * T.int64(14) + oh_3)
                            v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(112) // T.int64(4) * T.int64(2) + ow_1 + ow_2 + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2 + oc_block_3)
                            v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(2) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)], p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)] * p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block]
                    for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(4), T.int64(14)):
                        for ax3_ax4_fused in T.vectorized(T.int64(32)):
                            with T.block("T_relu"):
                                v_ax0 = T.axis.spatial(T.int64(1), ax0)
                                v_ax1 = T.axis.spatial(T.int64(8), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(4) // T.int64(2) * T.int64(4) + ax1)
                                v_ax2 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(112) * T.int64(28) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(2) * T.int64(14) + ax2)
                                v_ax3 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(112) // T.int64(4) * T.int64(2) + ow_1)
                                v_ax4 = T.axis.spatial(T.int64(32), ax3_ax4_fused)
                                T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                                T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                                T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 2, 4, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 2, 1, 14])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[28, 2, 1, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 32, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[128, 2])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=112)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=8)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b68)
l85 = sch.fuse(l71, l72, l73, l74, l75, l76, l77, l78, preserve_unit_iters=True)
sch.parallel(loop=l85)
l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b69)
l105 = sch.fuse(l86, preserve_unit_iters=True)
sch.parallel(loop=l105)
sch.annotate(block_or_loop=l105, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l105, ann_key="pragma_unroll_explicit", ann_val=1)
l106, l107, l108, l109, l110, l111, l112, l113 = sch.get_loops(block=b70)
l114 = sch.fuse(l112, l113, preserve_unit_iters=True)
sch.vectorize(loop=l114)
b115 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134 = sch.get_loops(block=b115)
b135 = sch.decompose_reduction(block=b115, loop=l119)
2024-04-30 14:05:59 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1876: GFLOPs: 1212.2424. Time: 3053.0046 us. Best GFLOPs: 1639.7699
2024-04-30 14:05:59 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1877: GFLOPs: 1536.5773. Time: 2408.5881 us. Best GFLOPs: 1639.7699
2024-04-30 14:05:59 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1878: GFLOPs: 1542.7050. Time: 2399.0210 us. Best GFLOPs: 1639.7699
2024-04-30 14:05:59 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1879: GFLOPs: 1213.3022. Time: 3050.3379 us. Best GFLOPs: 1639.7699
2024-04-30 14:05:59 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1880: GFLOPs: 1554.7270. Time: 2380.4705 us. Best GFLOPs: 1639.7699
2024-04-30 14:05:59 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1881: GFLOPs: 1578.1607. Time: 2345.1236 us. Best GFLOPs: 1639.7699
2024-04-30 14:05:59 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1882: GFLOPs: 1620.6364. Time: 2283.6595 us. Best GFLOPs: 1639.7699
2024-04-30 14:05:59 [INFO] [task_scheduler.cc:121] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1883: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(56), T.int64(56), T.int64(256)), "float32"), p1: T.Buffer((T.int64(8), T.int64(1), T.int64(3), T.int64(3), T.int64(256), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(58), T.int64(58), T.int64(256)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused in T.parallel(T.int64(896), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(16), T.int64(3), T.int64(256)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(448) * T.int64(28) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(28) // T.int64(14) * T.int64(14) + ax2)
                    v_i3 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(448) // T.int64(112) * T.int64(14) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(14) + ax3)
                    v_i4 = T.axis.spatial(T.int64(256), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(57) and T.int64(1) <= v_i3 and v_i3 < T.int64(57), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oc_block_1 in range(T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(14), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(8), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(112) // T.int64(28) * T.int64(2) + oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(448) * T.int64(28) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(28) // T.int64(14) * T.int64(14) + oh_2_init * T.int64(14) + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(448) // T.int64(112) * T.int64(14) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(14) + ow_2_init + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(128), T.int64(1), T.int64(3), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(32), T.int64(2), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(14), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(8), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(112) // T.int64(28) * T.int64(2) + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(448) * T.int64(28) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(28) // T.int64(14) * T.int64(14) + oh_2 * T.int64(14) + oh_3)
                        v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(448) // T.int64(112) * T.int64(14) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(14) + ow_2 + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(2) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)], p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)] * p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block]
                for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(2), T.int64(14)):
                    for ax3_ax4_fused in T.vectorized(T.int64(32)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(8), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(112) // T.int64(28) * T.int64(2) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(448) * T.int64(28) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(28) // T.int64(14) * T.int64(14) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(448) // T.int64(112) * T.int64(14) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(14))
                            v_ax4 = T.axis.spatial(T.int64(32), ax3_ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 4, 2, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 2, 1, 14])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[4, 14, 1, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 32, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[128, 2])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=8)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b68)
l85 = sch.fuse(l71, l72, l73, l74, l75, l76, l77, l78, l79, preserve_unit_iters=True)
sch.parallel(loop=l85)
l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l86, preserve_unit_iters=True)
sch.parallel(loop=l104)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109, l110, l111 = sch.get_loops(block=b70)
l112 = sch.fuse(l110, l111, preserve_unit_iters=True)
sch.vectorize(loop=l112)
b113 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131 = sch.get_loops(block=b113)
b132 = sch.decompose_reduction(block=b113, loop=l116)
2024-04-30 14:05:59 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1884: GFLOPs: 1249.6884. Time: 2961.5236 us. Best GFLOPs: 1639.7699
2024-04-30 14:05:59 [INFO] [task_scheduler.cc:121] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1885: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(56), T.int64(56), T.int64(256)), "float32"), p1: T.Buffer((T.int64(8), T.int64(1), T.int64(3), T.int64(3), T.int64(256), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(58), T.int64(58), T.int64(256)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused in T.parallel(T.int64(224), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for oh_1 in range(T.int64(2)):
                for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(16), T.int64(3), T.int64(256)):
                    with T.block("data_pad"):
                        v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                        v_i2 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(112) * T.int64(28) + oh_1 * T.int64(14) + ax2)
                        v_i3 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(112) // T.int64(2) + ax3)
                        v_i4 = T.axis.spatial(T.int64(256), ax4)
                        T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                        T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                        data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(57) and T.int64(1) <= v_i3 and v_i3 < T.int64(57), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                for ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1)):
                    for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(14), T.int64(1), T.int64(1)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(8), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(2) * T.int64(4) + oc_chunk_2_init + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(112) * T.int64(28) + oh_1 * T.int64(14) + oh_2_init * T.int64(14) + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(112) // T.int64(2) + ow_1 + ow_2_init + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2_init + oc_block_3_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                    for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(128), T.int64(1), T.int64(3), T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(32), T.int64(2), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(14), T.int64(1), T.int64(1)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(8), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(2) * T.int64(4) + oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(112) * T.int64(28) + oh_1 * T.int64(14) + oh_2 * T.int64(14) + oh_3)
                            v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(112) // T.int64(2) + ow_1 + ow_2 + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2 + oc_block_3)
                            v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(2) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)], p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)] * p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block]
                    for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(4), T.int64(14)):
                        for ax3_ax4_fused in T.vectorized(T.int64(32)):
                            with T.block("T_relu"):
                                v_ax0 = T.axis.spatial(T.int64(1), ax0)
                                v_ax1 = T.axis.spatial(T.int64(8), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(2) * T.int64(4) + ax1)
                                v_ax2 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(112) * T.int64(28) + oh_1 * T.int64(14) + ax2)
                                v_ax3 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(112) // T.int64(2))
                                v_ax4 = T.axis.spatial(T.int64(32), ax3_ax4_fused)
                                T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                                T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                                T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 2, 4, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 2, 1, 14])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[56, 1, 1, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 32, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[128, 2])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=112)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=7)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83 = sch.get_loops(block=b68)
l84 = sch.fuse(l71, l72, l73, l74, l75, l76, l77, preserve_unit_iters=True)
sch.parallel(loop=l84)
l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b69)
l105 = sch.fuse(l85, preserve_unit_iters=True)
sch.parallel(loop=l105)
sch.annotate(block_or_loop=l105, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l105, ann_key="pragma_unroll_explicit", ann_val=1)
l106, l107, l108, l109, l110, l111, l112, l113, l114 = sch.get_loops(block=b70)
l115 = sch.fuse(l113, l114, preserve_unit_iters=True)
sch.vectorize(loop=l115)
b116 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136 = sch.get_loops(block=b116)
b137 = sch.decompose_reduction(block=b116, loop=l121)
2024-04-30 14:05:59 [INFO] [task_scheduler.cc:121] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1886: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(56), T.int64(56), T.int64(256)), "float32"), p1: T.Buffer((T.int64(8), T.int64(1), T.int64(3), T.int64(3), T.int64(256), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(58), T.int64(58), T.int64(256)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused in T.parallel(T.int64(224), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for oh_1, ow_1 in T.grid(T.int64(1), T.int64(2)):
                for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(16), T.int64(3), T.int64(256)):
                    with T.block("data_pad"):
                        v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                        v_i2 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(56) * T.int64(14) + ax2)
                        v_i3 = T.axis.spatial(T.int64(58), ow_1 + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(56) // T.int64(2) * T.int64(2) + ax3)
                        v_i4 = T.axis.spatial(T.int64(256), ax4)
                        T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                        T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                        data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(57) and T.int64(1) <= v_i3 and v_i3 < T.int64(57), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                for oc_block_1 in range(T.int64(1)):
                    for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(14), T.int64(1), T.int64(1)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(8), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(2) * T.int64(4) + oc_chunk_2_init + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(56) * T.int64(14) + oh_1 * T.int64(14) + oh_2_init * T.int64(14) + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(56) // T.int64(2) * T.int64(2) + ow_1 + ow_2_init + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2_init + oc_block_3_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                    for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(128), T.int64(1), T.int64(3), T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(32), T.int64(2), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(14), T.int64(1), T.int64(1)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(8), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(2) * T.int64(4) + oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(56) * T.int64(14) + oh_1 * T.int64(14) + oh_2 * T.int64(14) + oh_3)
                            v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(56) // T.int64(2) * T.int64(2) + ow_1 + ow_2 + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2 + oc_block_3)
                            v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(2) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)], p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)] * p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block]
                    for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(4), T.int64(14)):
                        for ax3_ax4_fused in T.vectorized(T.int64(32)):
                            with T.block("T_relu"):
                                v_ax0 = T.axis.spatial(T.int64(1), ax0)
                                v_ax1 = T.axis.spatial(T.int64(8), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(2) * T.int64(4) + ax1)
                                v_ax2 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(56) * T.int64(14) + ax2)
                                v_ax3 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(56) // T.int64(2) * T.int64(2) + ow_1)
                                v_ax4 = T.axis.spatial(T.int64(32), ax3_ax4_fused)
                                T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                                T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                                T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 2, 4, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[4, 1, 1, 14])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[28, 2, 1, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 32, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[128, 2])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=112)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=8)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b68)
l85 = sch.fuse(l71, l72, l73, l74, l75, l76, l77, preserve_unit_iters=True)
sch.parallel(loop=l85)
l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105 = sch.get_loops(block=b69)
l106 = sch.fuse(l86, preserve_unit_iters=True)
sch.parallel(loop=l106)
sch.annotate(block_or_loop=l106, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l106, ann_key="pragma_unroll_explicit", ann_val=1)
l107, l108, l109, l110, l111, l112, l113, l114, l115 = sch.get_loops(block=b70)
l116 = sch.fuse(l114, l115, preserve_unit_iters=True)
sch.vectorize(loop=l116)
b117 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137 = sch.get_loops(block=b117)
b138 = sch.decompose_reduction(block=b117, loop=l122)
2024-04-30 14:05:59 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1887: GFLOPs: 1504.6892. Time: 2459.6320 us. Best GFLOPs: 1639.7699
2024-04-30 14:05:59 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1888: GFLOPs: 1198.5655. Time: 3087.8428 us. Best GFLOPs: 1639.7699
2024-04-30 14:05:59 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1889: GFLOPs: 1104.3493. Time: 3351.2783 us. Best GFLOPs: 1639.7699
2024-04-30 14:05:59 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1890: GFLOPs: 1153.7583. Time: 3207.7618 us. Best GFLOPs: 1639.7699
2024-04-30 14:05:59 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1891: GFLOPs: 1416.0107. Time: 2613.6680 us. Best GFLOPs: 1639.7699
2024-04-30 14:05:59 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1892: GFLOPs: 1347.2471. Time: 2747.0697 us. Best GFLOPs: 1639.7699
2024-04-30 14:05:59 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1893: GFLOPs: 1086.8690. Time: 3405.1775 us. Best GFLOPs: 1639.7699
2024-04-30 14:05:59 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1894: GFLOPs: 1055.1225. Time: 3507.6324 us. Best GFLOPs: 1639.7699
2024-04-30 14:05:59 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1895: GFLOPs: 1087.4145. Time: 3403.4692 us. Best GFLOPs: 1639.7699
2024-04-30 14:05:59 [INFO] [task_scheduler.cc:121] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1896: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(56), T.int64(56), T.int64(256)), "float32"), p1: T.Buffer((T.int64(8), T.int64(1), T.int64(3), T.int64(3), T.int64(256), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(58), T.int64(58), T.int64(256)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused in T.parallel(T.int64(448), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(16), T.int64(3), T.int64(256)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(4) * T.int64(14) + ax2)
                    v_i3 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(224) // T.int64(4) + ax3)
                    v_i4 = T.axis.spatial(T.int64(256), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(57) and T.int64(1) <= v_i3 and v_i3 < T.int64(57), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(14), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(8), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(224) * T.int64(4) + oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(4) * T.int64(14) + oh_2_init * T.int64(14) + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(224) // T.int64(4) + ow_1 + ow_2_init + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(128), T.int64(1), T.int64(3), T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(32), T.int64(2), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(14), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(8), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(224) * T.int64(4) + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(4) * T.int64(14) + oh_2 * T.int64(14) + oh_3)
                        v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(224) // T.int64(4) + ow_1 + ow_2 + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(2) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)], p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)] * p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block]
                for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(4), T.int64(14)):
                    for ax3_ax4_fused in T.vectorized(T.int64(32)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(8), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(224) * T.int64(4) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(4) * T.int64(14) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(224) // T.int64(4))
                            v_ax4 = T.axis.spatial(T.int64(32), ax3_ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[2, 1, 4, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 4, 1, 14])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[56, 1, 1, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 32, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[128, 2])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=112)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=7)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83 = sch.get_loops(block=b68)
l84 = sch.fuse(l71, l72, l73, l74, l75, l76, l77, l78, preserve_unit_iters=True)
sch.parallel(loop=l84)
l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l85, preserve_unit_iters=True)
sch.parallel(loop=l104)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109, l110, l111, l112 = sch.get_loops(block=b70)
l113 = sch.fuse(l111, l112, preserve_unit_iters=True)
sch.vectorize(loop=l113)
b114 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133 = sch.get_loops(block=b114)
b134 = sch.decompose_reduction(block=b114, loop=l118)
2024-04-30 14:05:59 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1897: GFLOPs: 1044.1855. Time: 3544.3720 us. Best GFLOPs: 1639.7699
2024-04-30 14:05:59 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1898: GFLOPs: 1049.9832. Time: 3524.8008 us. Best GFLOPs: 1639.7699
2024-04-30 14:05:59 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1899: GFLOPs: 1064.2716. Time: 3477.4785 us. Best GFLOPs: 1639.7699
2024-04-30 14:05:59 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1900: GFLOPs: 1070.7885. Time: 3456.3143 us. Best GFLOPs: 1639.7699
2024-04-30 14:05:59 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1901: GFLOPs: 1120.0976. Time: 3304.1601 us. Best GFLOPs: 1639.7699
2024-04-30 14:05:59 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1902: GFLOPs: 1031.7016. Time: 3587.2600 us. Best GFLOPs: 1639.7699
2024-04-30 14:05:59 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1903: GFLOPs: 1054.0893. Time: 3511.0704 us. Best GFLOPs: 1639.7699
2024-04-30 14:05:59 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1904: GFLOPs: 1051.2368. Time: 3520.5975 us. Best GFLOPs: 1639.7699
2024-04-30 14:05:59 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1905: GFLOPs: 1014.0371. Time: 3649.7500 us. Best GFLOPs: 1639.7699
2024-04-30 14:05:59 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1906: GFLOPs: 1030.0588. Time: 3592.9811 us. Best GFLOPs: 1639.7699
2024-04-30 14:05:59 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1907: GFLOPs: 1046.1904. Time: 3537.5795 us. Best GFLOPs: 1639.7699
2024-04-30 14:05:59 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1908: GFLOPs: 877.4378. Time: 4217.9422 us. Best GFLOPs: 1639.7699
2024-04-30 14:05:59 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1909: GFLOPs: 1043.4101. Time: 3547.0059 us. Best GFLOPs: 1639.7699
2024-04-30 14:05:59 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1910: GFLOPs: 1020.5009. Time: 3626.6324 us. Best GFLOPs: 1639.7699
2024-04-30 14:05:59 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1911: GFLOPs: 1053.1423. Time: 3514.2277 us. Best GFLOPs: 1639.7699
2024-04-30 14:05:59 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1912: GFLOPs: 1023.0977. Time: 3617.4276 us. Best GFLOPs: 1639.7699
2024-04-30 14:05:59 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1913: GFLOPs: 998.1798. Time: 3707.7304 us. Best GFLOPs: 1639.7699
2024-04-30 14:05:59 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1914: GFLOPs: 1022.7217. Time: 3618.7573 us. Best GFLOPs: 1639.7699
2024-04-30 14:05:59 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1915: GFLOPs: 1005.9284. Time: 3679.1701 us. Best GFLOPs: 1639.7699
2024-04-30 14:05:59 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1916: GFLOPs: 1009.4651. Time: 3666.2799 us. Best GFLOPs: 1639.7699
2024-04-30 14:05:59 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1917: GFLOPs: 956.4100. Time: 3869.6604 us. Best GFLOPs: 1639.7699
2024-04-30 14:05:59 [INFO] [task_scheduler.cc:121] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1918: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(56), T.int64(56), T.int64(256)), "float32"), p1: T.Buffer((T.int64(8), T.int64(1), T.int64(3), T.int64(3), T.int64(256), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(58), T.int64(58), T.int64(256)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused in T.parallel(T.int64(224), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(30), T.int64(256)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(56) // T.int64(2) * T.int64(2) + ax2)
                    v_i3 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(2) * T.int64(28) + ax3)
                    v_i4 = T.axis.spatial(T.int64(256), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(57) and T.int64(1) <= v_i3 and v_i3 < T.int64(57), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oc_block_1 in range(T.int64(2)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(16), T.int64(1), T.int64(2), T.int64(1), T.int64(28), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(8), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(56) * T.int64(2) + oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(56) // T.int64(2) * T.int64(2) + oh_2_init + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(2) * T.int64(28) + ow_2_init * T.int64(28) + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(16) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(4), T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(16), T.int64(64), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(28), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(8), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(56) * T.int64(2) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(56) // T.int64(2) * T.int64(2) + oh_2 + oh_3)
                        v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(2) * T.int64(28) + ow_2 * T.int64(28) + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(16) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(64) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)], p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)] * p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(2), T.int64(2), T.int64(28)):
                    for ax4_fused in T.vectorized(T.int64(16)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(8), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(56) * T.int64(2) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(56) // T.int64(2) * T.int64(2) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(2) * T.int64(28) + ax3)
                            v_ax4 = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(16) + ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[4, 1, 1, 2])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[4, 7, 2, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 2, 1, 28])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 2, 16, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[4, 64])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=8)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b68)
l85 = sch.fuse(l71, l72, l73, l74, l75, l76, l77, l78, l79, preserve_unit_iters=True)
sch.parallel(loop=l85)
l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l86, preserve_unit_iters=True)
sch.parallel(loop=l104)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109, l110, l111 = sch.get_loops(block=b70)
l112 = sch.fuse(l111, preserve_unit_iters=True)
sch.vectorize(loop=l112)
b113 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131 = sch.get_loops(block=b113)
b132 = sch.decompose_reduction(block=b113, loop=l116)
2024-04-30 14:05:59 [INFO] [task_scheduler.cc:121] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1919: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(56), T.int64(56), T.int64(256)), "float32"), p1: T.Buffer((T.int64(8), T.int64(1), T.int64(3), T.int64(3), T.int64(256), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(58), T.int64(58), T.int64(256)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused in T.parallel(T.int64(128), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(16), T.int64(30), T.int64(256)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(32) // T.int64(8) * T.int64(14) + ax2)
                    v_i3 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(8) // T.int64(4) * T.int64(28) + ax3)
                    v_i4 = T.axis.spatial(T.int64(256), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(57) and T.int64(1) <= v_i3 and v_i3 < T.int64(57), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(2), T.int64(2), T.int64(28), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1)):
                for oc_block_3_fused_init in T.vectorized(T.int64(8)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(8), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(32) * T.int64(2) + oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(32) // T.int64(8) * T.int64(14) + oh_2_init * T.int64(7) + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(8) // T.int64(4) * T.int64(28) + ow_2_init + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(4) * T.int64(8) + oc_block_2_init * T.int64(8) + oc_block_3_fused_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
            for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(128), T.int64(3), T.int64(1), T.int64(1), T.int64(2), T.int64(2), T.int64(28), T.int64(1), T.int64(2), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(7), T.int64(1)):
                for oc_block_3_fused in T.vectorized(T.int64(8)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(8), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(32) * T.int64(2) + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(32) // T.int64(8) * T.int64(14) + oh_2 * T.int64(7) + oh_3)
                        v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(8) // T.int64(4) * T.int64(28) + ow_2 + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(4) * T.int64(8) + oc_block_2 * T.int64(8) + oc_block_3_fused)
                        v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(2) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)], p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)] * p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block]
        for ax0_ax1_ax2_ax3_ax4_fused_0 in T.parallel(T.int64(12544)):
            for ax0_ax1_ax2_ax3_ax4_fused_1 in T.vectorized(T.int64(64)):
                with T.block("T_relu"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(8), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) // T.int64(100352))
                    v_ax2 = T.axis.spatial(T.int64(56), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(100352) // T.int64(1792))
                    v_ax3 = T.axis.spatial(T.int64(56), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(1792) // T.int64(32))
                    v_ax4 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(32))
                    T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                    T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[2, 2, 2, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 4, 2, 7])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 2, 28, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 4, 1, 8])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[128, 2])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
l65 = sch.sample_compute_location(block=b0, decision=9)
sch.compute_at(block=b0, loop=l65, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b66 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.unroll_explicit")
b67, b68, b69 = sch.get_child_blocks(b66)
l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b67)
l85 = sch.fuse(l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, preserve_unit_iters=True)
sch.parallel(loop=l85)
l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102 = sch.get_loops(block=b68)
l103 = sch.fuse(l86, preserve_unit_iters=True)
sch.parallel(loop=l103)
l104 = sch.fuse(l102, preserve_unit_iters=True)
sch.vectorize(loop=l104)
sch.annotate(block_or_loop=l103, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l103, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109 = sch.get_loops(block=b69)
l110 = sch.fuse(l105, l106, l107, l108, l109, preserve_unit_iters=True)
l111, l112 = sch.split(loop=l110, factors=[None, 64], preserve_unit_iters=True)
sch.parallel(loop=l111)
sch.vectorize(loop=l112)
b113 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130 = sch.get_loops(block=b113)
b131 = sch.decompose_reduction(block=b113, loop=l115)
2024-04-30 14:05:59 [INFO] [task_scheduler.cc:121] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1920: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(56), T.int64(56), T.int64(256)), "float32"), p1: T.Buffer((T.int64(8), T.int64(1), T.int64(3), T.int64(3), T.int64(256), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(58), T.int64(58), T.int64(256)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused in T.parallel(T.int64(2), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(7), T.int64(7), T.int64(2)):
                for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(10), T.int64(6), T.int64(256)):
                    with T.block("data_pad"):
                        v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                        v_i2 = T.axis.spatial(T.int64(58), oh_1 * T.int64(8) + ax2)
                        v_i3 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused * T.int64(28) + ow_1 * T.int64(4) + ax3)
                        v_i4 = T.axis.spatial(T.int64(256), ax4)
                        T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                        T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                        data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(57) and T.int64(1) <= v_i3 and v_i3 < T.int64(57), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(4), T.int64(8), T.int64(2), T.int64(8), T.int64(1), T.int64(2), T.int64(1), T.int64(2)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(2)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(8), oc_chunk_1 * T.int64(8) + oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(56), oh_1 * T.int64(8) + oh_2_init + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused * T.int64(28) + ow_1 * T.int64(4) + ow_2_init * T.int64(2) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(16) + oc_block_2_init * T.int64(2) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(128), T.int64(3), T.int64(1), T.int64(1), T.int64(4), T.int64(8), T.int64(2), T.int64(8), T.int64(2), T.int64(1), T.int64(3), T.int64(1), T.int64(2), T.int64(1), T.int64(2)):
                    for oc_block_3_fused in T.vectorized(T.int64(2)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(8), oc_chunk_1 * T.int64(8) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(56), oh_1 * T.int64(8) + oh_2 + oh_3)
                            v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused * T.int64(28) + ow_1 * T.int64(4) + ow_2 * T.int64(2) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(16) + oc_block_2 * T.int64(2) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(2) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)], p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)] * p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(8), T.int64(56), T.int64(28)):
                for ax4_fused in T.vectorized(T.int64(32)):
                    with T.block("T_relu"):
                        v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                        v_ax3 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused * T.int64(28) + ax3)
                        v_ax4 = T.axis.spatial(T.int64(32), ax4_fused)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 4, 2])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 7, 8, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[2, 7, 2, 2])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 2, 8, 2])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[128, 2])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=9)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85 = sch.get_loops(block=b68)
l86 = sch.fuse(l71, l72, l73, l74, l75, preserve_unit_iters=True)
sch.parallel(loop=l86)
l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107, l108 = sch.get_loops(block=b69)
l109 = sch.fuse(l87, preserve_unit_iters=True)
sch.parallel(loop=l109)
l110 = sch.fuse(l108, preserve_unit_iters=True)
sch.vectorize(loop=l110)
sch.annotate(block_or_loop=l109, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l109, ann_key="pragma_unroll_explicit", ann_val=1)
l111, l112, l113, l114, l115, l116 = sch.get_loops(block=b70)
l117 = sch.fuse(l116, preserve_unit_iters=True)
sch.vectorize(loop=l117)
b118 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140 = sch.get_loops(block=b118)
b141 = sch.decompose_reduction(block=b118, loop=l125)
2024-04-30 14:35:41 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-30 14:35:42 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-30 14:35:47 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 14:35:47 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-30 14:35:59 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 14:36:12 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 14:36:25 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 14:36:38 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4732c18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x337e4f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3389d58)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x33df578)]: 0 failure(s)
2024-04-30 14:36:45 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9519  0.9519  0.9509  0.9448  0.9448  0.9217  0.9217  0.9161  0.9161  0.9028  0.8739  0.8739  0.8698  0.8514  0.8499  0.8499
[17 : 32]:	0.8248  0.7980  0.7944  0.7579  0.7579  0.7579  0.7537  0.7482  0.7432  0.7396  0.7305  0.7284  0.7157  0.7156  0.7130  0.7074
[33 : 48]:	0.6946  0.6841  0.6784  0.6766  0.6737  0.6662  0.6662  0.6662  0.6505  0.6486  0.6411  0.6394  0.6394  0.6390  0.6386  0.6383
[49 : 64]:	0.6364  0.6355  0.6354  0.6332  0.6332  0.6324  0.6321  0.6302  0.6301  0.6298  0.6282  0.6276  0.6273  0.6265  0.6256  0.6256
2024-04-30 14:36:46 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-30 14:36:46 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-30 14:38:50 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1921: GFLOPs: 1617.9975. Time: 2287.3841 us. Best GFLOPs: 1639.7699
2024-04-30 14:38:50 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1922: GFLOPs: 1579.3446. Time: 2343.3656 us. Best GFLOPs: 1639.7699
2024-04-30 14:38:50 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1923: GFLOPs: 1630.1139. Time: 2270.3823 us. Best GFLOPs: 1639.7699
2024-04-30 14:38:50 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1924: GFLOPs: 1625.8045. Time: 2276.4003 us. Best GFLOPs: 1639.7699
2024-04-30 14:38:50 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1925: GFLOPs: 1636.3069. Time: 2261.7895 us. Best GFLOPs: 1639.7699
2024-04-30 14:38:50 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1926: GFLOPs: 1556.3974. Time: 2377.9157 us. Best GFLOPs: 1639.7699
2024-04-30 14:38:50 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1927: GFLOPs: 1583.8353. Time: 2336.7213 us. Best GFLOPs: 1639.7699
2024-04-30 14:38:50 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1928: GFLOPs: 1601.9157. Time: 2310.3474 us. Best GFLOPs: 1639.7699
2024-04-30 14:38:50 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1929: GFLOPs: 1582.6991. Time: 2338.3989 us. Best GFLOPs: 1639.7699
2024-04-30 14:38:50 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1930: GFLOPs: 1593.3391. Time: 2322.7835 us. Best GFLOPs: 1639.7699
2024-04-30 14:38:50 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1931: GFLOPs: 1462.8297. Time: 2530.0155 us. Best GFLOPs: 1639.7699
2024-04-30 14:38:50 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1932: GFLOPs: 1471.8106. Time: 2514.5775 us. Best GFLOPs: 1639.7699
2024-04-30 14:38:50 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1933: GFLOPs: 1461.1226. Time: 2532.9713 us. Best GFLOPs: 1639.7699
2024-04-30 14:38:50 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1934: GFLOPs: 1521.3001. Time: 2432.7756 us. Best GFLOPs: 1639.7699
2024-04-30 14:38:50 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1935: GFLOPs: 1432.8665. Time: 2582.9216 us. Best GFLOPs: 1639.7699
2024-04-30 14:38:50 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1936: GFLOPs: 1434.5666. Time: 2579.8605 us. Best GFLOPs: 1639.7699
2024-04-30 14:38:50 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1937: GFLOPs: 1191.0066. Time: 3107.4401 us. Best GFLOPs: 1639.7699
2024-04-30 14:38:50 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1938: GFLOPs: 1192.3552. Time: 3103.9255 us. Best GFLOPs: 1639.7699
2024-04-30 14:38:50 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1939: GFLOPs: 997.4380. Time: 3710.4879 us. Best GFLOPs: 1639.7699
2024-04-30 14:38:50 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1940: GFLOPs: 204.6690. Time: 18082.7642 us. Best GFLOPs: 1639.7699
2024-04-30 14:38:50 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1941: GFLOPs: 122.8895. Time: 30116.3405 us. Best GFLOPs: 1639.7699
2024-04-30 14:38:50 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1942: GFLOPs: 204.9935. Time: 18054.1432 us. Best GFLOPs: 1639.7699
2024-04-30 14:38:50 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1943: GFLOPs: 1279.2895. Time: 2892.9979 us. Best GFLOPs: 1639.7699
2024-04-30 14:38:50 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1944: GFLOPs: 1184.0791. Time: 3125.6203 us. Best GFLOPs: 1639.7699
2024-04-30 14:38:50 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1945: GFLOPs: 1282.9087. Time: 2884.8363 us. Best GFLOPs: 1639.7699
2024-04-30 14:38:50 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1946: GFLOPs: 1175.4906. Time: 3148.4571 us. Best GFLOPs: 1639.7699
2024-04-30 14:38:50 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1947: GFLOPs: 1207.6241. Time: 3064.6802 us. Best GFLOPs: 1639.7699
2024-04-30 14:38:50 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1948: GFLOPs: 1030.2112. Time: 3592.4495 us. Best GFLOPs: 1639.7699
2024-04-30 14:38:50 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1949: GFLOPs: 1151.8711. Time: 3213.0173 us. Best GFLOPs: 1639.7699
2024-04-30 14:38:50 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1950: GFLOPs: 1135.7005. Time: 3258.7656 us. Best GFLOPs: 1639.7699
2024-04-30 14:38:50 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1951: GFLOPs: 912.1449. Time: 4057.4494 us. Best GFLOPs: 1639.7699
2024-04-30 14:38:50 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1952: GFLOPs: 926.8136. Time: 3993.2320 us. Best GFLOPs: 1639.7699
2024-04-30 14:38:50 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1953: GFLOPs: 589.5857. Time: 6277.2584 us. Best GFLOPs: 1639.7699
2024-04-30 14:38:50 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1954: GFLOPs: 1097.2364. Time: 3373.0032 us. Best GFLOPs: 1639.7699
2024-04-30 14:38:50 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1955: GFLOPs: 1224.0351. Time: 3023.5913 us. Best GFLOPs: 1639.7699
2024-04-30 14:38:50 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1956: GFLOPs: 1165.5562. Time: 3175.2923 us. Best GFLOPs: 1639.7699
2024-04-30 14:38:50 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1957: GFLOPs: 1099.3185. Time: 3366.6145 us. Best GFLOPs: 1639.7699
2024-04-30 14:38:50 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1958: GFLOPs: 1109.3419. Time: 3336.1959 us. Best GFLOPs: 1639.7699
2024-04-30 14:38:50 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1959: GFLOPs: 1143.4696. Time: 3236.6245 us. Best GFLOPs: 1639.7699
2024-04-30 14:38:50 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1960: GFLOPs: 1151.1720. Time: 3214.9686 us. Best GFLOPs: 1639.7699
2024-04-30 14:38:50 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1961: GFLOPs: 40.3646. Time: 91688.9023 us. Best GFLOPs: 1639.7699
2024-04-30 14:38:50 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1962: GFLOPs: 736.2961. Time: 5026.4855 us. Best GFLOPs: 1639.7699
2024-04-30 14:38:50 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1963: GFLOPs: 1065.1030. Time: 3474.7641 us. Best GFLOPs: 1639.7699
2024-04-30 14:38:50 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1964: GFLOPs: 1081.0397. Time: 3423.5391 us. Best GFLOPs: 1639.7699
2024-04-30 14:38:50 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1965: GFLOPs: 1079.7510. Time: 3427.6252 us. Best GFLOPs: 1639.7699
2024-04-30 14:38:50 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1966: GFLOPs: 1081.2363. Time: 3422.9167 us. Best GFLOPs: 1639.7699
2024-04-30 14:38:50 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1967: GFLOPs: 1065.5173. Time: 3473.4130 us. Best GFLOPs: 1639.7699
2024-04-30 14:38:50 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1968: GFLOPs: 1053.7384. Time: 3512.2396 us. Best GFLOPs: 1639.7699
2024-04-30 14:38:50 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1969: GFLOPs: 1023.4269. Time: 3616.2638 us. Best GFLOPs: 1639.7699
2024-04-30 14:38:50 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1970: GFLOPs: 1064.5732. Time: 3476.4935 us. Best GFLOPs: 1639.7699
2024-04-30 14:38:50 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1971: GFLOPs: 1069.6773. Time: 3459.9049 us. Best GFLOPs: 1639.7699
2024-04-30 14:38:50 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1972: GFLOPs: 1076.9042. Time: 3436.6863 us. Best GFLOPs: 1639.7699
2024-04-30 14:38:50 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1973: GFLOPs: 1065.5685. Time: 3473.2461 us. Best GFLOPs: 1639.7699
2024-04-30 14:38:50 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1974: GFLOPs: 772.1169. Time: 4793.2917 us. Best GFLOPs: 1639.7699
2024-04-30 14:38:50 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1975: GFLOPs: 1052.0141. Time: 3517.9962 us. Best GFLOPs: 1639.7699
2024-04-30 14:38:50 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1976: GFLOPs: 1071.4902. Time: 3454.0510 us. Best GFLOPs: 1639.7699
2024-04-30 14:38:50 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1977: GFLOPs: 161.9700. Time: 22849.7924 us. Best GFLOPs: 1639.7699
2024-04-30 14:38:50 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1978: GFLOPs: 1080.2677. Time: 3425.9858 us. Best GFLOPs: 1639.7699
2024-04-30 14:38:50 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1979: GFLOPs: 1230.1066. Time: 3008.6675 us. Best GFLOPs: 1639.7699
2024-04-30 14:38:50 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1980: GFLOPs: 1039.9339. Time: 3558.8624 us. Best GFLOPs: 1639.7699
2024-04-30 14:38:50 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1981: GFLOPs: 1016.8948. Time: 3639.4931 us. Best GFLOPs: 1639.7699
2024-04-30 14:38:50 [INFO] [task_scheduler.cc:121] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1982: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(56), T.int64(56), T.int64(256)), "float32"), p1: T.Buffer((T.int64(8), T.int64(1), T.int64(3), T.int64(3), T.int64(256), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(58), T.int64(58), T.int64(256)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused in T.parallel(T.int64(32), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(16), T.int64(30), T.int64(256)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(4) * T.int64(14) + ax2)
                    v_i3 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(8) // T.int64(4) * T.int64(28) + ax3)
                    v_i4 = T.axis.spatial(T.int64(256), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(57) and T.int64(1) <= v_i3 and v_i3 < T.int64(57), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for ow_1, oc_block_1 in T.grid(T.int64(2), T.int64(2)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(2), T.int64(1), T.int64(2), T.int64(14), T.int64(2)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(8)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(8), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(8) * T.int64(2) + oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(4) * T.int64(14) + oh_2_init * T.int64(14) + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(8) // T.int64(4) * T.int64(28) + ow_1 * T.int64(14) + ow_2_init * T.int64(2) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(16) + oc_block_2_init * T.int64(8) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(4), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(2), T.int64(64), T.int64(3), T.int64(1), T.int64(1), T.int64(2), T.int64(14), T.int64(2)):
                    for oc_block_3_fused in T.vectorized(T.int64(8)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(8), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(8) * T.int64(2) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(4) * T.int64(14) + oh_2 * T.int64(14) + oh_3)
                            v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(8) // T.int64(4) * T.int64(28) + ow_1 * T.int64(14) + ow_2 * T.int64(2) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(16) + oc_block_2 * T.int64(8) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(64) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)], p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)] * p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block]
        for ax0_ax1_ax2_ax3_ax4_fused_0 in T.parallel(T.int64(12544)):
            for ax0_ax1_ax2_ax3_ax4_fused_1 in T.vectorized(T.int64(64)):
                with T.block("T_relu"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(8), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) // T.int64(100352))
                    v_ax2 = T.axis.spatial(T.int64(56), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(100352) // T.int64(1792))
                    v_ax3 = T.axis.spatial(T.int64(56), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(1792) // T.int64(32))
                    v_ax4 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(32))
                    T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                    T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[4, 1, 1, 2])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 4, 1, 14])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[2, 2, 7, 2])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 2, 2, 8])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[4, 64])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
l65 = sch.sample_compute_location(block=b0, decision=7)
sch.compute_at(block=b0, loop=l65, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b66 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.unroll_explicit")
b67, b68, b69 = sch.get_child_blocks(b66)
l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82 = sch.get_loops(block=b67)
l83 = sch.fuse(l70, l71, l72, l73, l74, l75, l76, l77, preserve_unit_iters=True)
sch.parallel(loop=l83)
l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102 = sch.get_loops(block=b68)
l103 = sch.fuse(l84, preserve_unit_iters=True)
sch.parallel(loop=l103)
l104 = sch.fuse(l102, preserve_unit_iters=True)
sch.vectorize(loop=l104)
sch.annotate(block_or_loop=l103, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l103, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109 = sch.get_loops(block=b69)
l110 = sch.fuse(l105, l106, l107, l108, l109, preserve_unit_iters=True)
l111, l112 = sch.split(loop=l110, factors=[None, 64], preserve_unit_iters=True)
sch.parallel(loop=l111)
sch.vectorize(loop=l112)
b113 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132 = sch.get_loops(block=b113)
b133 = sch.decompose_reduction(block=b113, loop=l117)
2024-04-30 14:38:50 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1983: GFLOPs: 42.2053. Time: 87689.9233 us. Best GFLOPs: 1639.7699
2024-04-30 14:38:50 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5] Trial #1984: GFLOPs: 44.0097. Time: 84094.6543 us. Best GFLOPs: 1639.7699
