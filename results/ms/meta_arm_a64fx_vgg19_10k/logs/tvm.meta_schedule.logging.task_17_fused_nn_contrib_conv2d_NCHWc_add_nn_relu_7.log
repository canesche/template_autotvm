2024-04-30 05:30:04 [INFO] [task_scheduler.cc:160] Initializing Task #17: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7"
2024-04-30 05:30:04 [INFO] [task_scheduler.cc:35] 
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(512)), "float32"), p1: T.Buffer((T.int64(32), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)))
        T_add = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)))
        for i0, i1, i2, i3, i4 in T.grid(T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(512)):
            with T.block("data_pad"):
                v_i0, v_i1, v_i2, v_i3, v_i4 = T.axis.remap("SSSSS", [i0, i1, i2, i3, i4])
                T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
        for n, oc_chunk, oh, ow, oc_block, ic, kh, kw in T.grid(T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16), T.int64(512), T.int64(3), T.int64(3)):
            with T.block("conv2d_NCHWc"):
                v_n, v_oc_chunk, v_oh, v_ow, v_oc_block, v_ic, v_kh, v_kw = T.axis.remap("SSSSSRRR", [n, oc_chunk, oh, ow, oc_block, ic, kh, kw])
                T.reads(data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                with T.init():
                    conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
        for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                T.writes(T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4]
        for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)):
            with T.block("T_relu"):
                v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                T.reads(T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
2024-04-30 05:30:04 [INFO] [task_scheduler.cc:164] Total 3 design space(s) generated
2024-04-30 05:30:04 [INFO] [task_scheduler.cc:170] Design space #0:
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(512)), "float32"), p1: T.Buffer((T.int64(32), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel": 768, "meta_schedule.unroll_explicit": 0, "meta_schedule.vectorize": 64})
            data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(512)))
            conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)))
            for n_0, oc_chunk_0, oh_0, ow_0, oc_block_0, n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(4), T.int64(2), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(2), T.int64(2), T.int64(4)):
                for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(9), T.int64(16), T.int64(512)):
                    with T.block("data_pad"):
                        v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                        v_i2 = T.axis.spatial(T.int64(30), oh_0 * T.int64(14) + oh_1 * T.int64(7) + ax2)
                        v_i3 = T.axis.spatial(T.int64(30), ow_1 * T.int64(14) + ax3)
                        v_i4 = T.axis.spatial(T.int64(512), ax4)
                        T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                        T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                        data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(8), T.int64(1), T.int64(3), T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(64), T.int64(3), T.int64(1), T.int64(1), T.int64(2), T.int64(7), T.int64(14), T.int64(2)):
                    with T.block("conv2d_NCHWc"):
                        v_n = T.axis.spatial(T.int64(1), n_0 + n_1 + n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(32), oc_chunk_0 * T.int64(8) + oc_chunk_1 * T.int64(8) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(28), oh_0 * T.int64(14) + oh_1 * T.int64(7) + oh_2 * T.int64(7) + oh_3)
                        v_ow = T.axis.spatial(T.int64(28), ow_0 * T.int64(28) + ow_1 * T.int64(14) + ow_2 * T.int64(14) + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(8) + oc_block_1 * T.int64(2) + oc_block_2 * T.int64(2) + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(64) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                        T.reads(data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        with T.init():
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)):
                with T.block("T_relu"):
                    v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                    T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                    T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[4, 1, 4, 2])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 2, 1, 7])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 2, 1, 14])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[2, 4, 1, 2])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[8, 64])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
l65 = sch.sample_compute_location(block=b0, decision=9)
sch.compute_at(block=b0, loop=l65, preserve_unit_loops=True, index=-1)
2024-04-30 05:30:04 [INFO] [task_scheduler.cc:170] Design space #1:
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(512)), "float32"), p1: T.Buffer((T.int64(32), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel": 768, "meta_schedule.unroll_explicit": 0, "meta_schedule.vectorize": 64})
            conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)))
            for n_0, oc_chunk_0, oh_0, ow_0, oc_block_0, n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(4), T.int64(2), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(2), T.int64(2), T.int64(4)):
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(8), T.int64(1), T.int64(3), T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(64), T.int64(3), T.int64(1), T.int64(1), T.int64(2), T.int64(7), T.int64(14), T.int64(2)):
                    with T.block("conv2d_NCHWc"):
                        v_n = T.axis.spatial(T.int64(1), n_0 + n_1 + n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(32), oc_chunk_0 * T.int64(8) + oc_chunk_1 * T.int64(8) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(28), oh_0 * T.int64(14) + oh_1 * T.int64(7) + oh_2 * T.int64(7) + oh_3)
                        v_ow = T.axis.spatial(T.int64(28), ow_0 * T.int64(28) + ow_1 * T.int64(14) + ow_2 * T.int64(14) + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(8) + oc_block_1 * T.int64(2) + oc_block_2 * T.int64(2) + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(64) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                        T.reads(p0[v_n, v_ic // T.int64(512), v_oh + v_kh - T.int64(1), v_ow + v_kw - T.int64(1), v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        with T.init():
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + T.if_then_else(T.int64(1) <= v_oh + v_kh and v_oh + v_kh < T.int64(29) and T.int64(1) <= v_ow + v_kw and v_ow + v_kw < T.int64(29), p0[v_n, v_ic // T.int64(512), v_oh + v_kh - T.int64(1), v_ow + v_kw - T.int64(1), v_ic % T.int64(512)], T.float32(0)) * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
                for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(8), T.int64(7), T.int64(14), T.int64(2)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(32), oc_chunk_0 * T.int64(8) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(28), oh_0 * T.int64(14) + oh_1 * T.int64(7) + ax2)
                        v_ax3 = T.axis.spatial(T.int64(28), ow_1 * T.int64(14) + ax3)
                        v_ax4 = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(8) + oc_block_1 * T.int64(2) + ax4)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[4, 1, 4, 2])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 2, 1, 7])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 2, 1, 14])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[2, 4, 1, 2])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[8, 64])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=-2)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
2024-04-30 05:30:04 [INFO] [task_scheduler.cc:170] Design space #2:
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(512)), "float32"), p1: T.Buffer((T.int64(32), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel": 768, "meta_schedule.unroll_explicit": 0, "meta_schedule.vectorize": 64})
            data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(512)))
            conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)))
            for n_0, oc_chunk_0, oh_0, ow_0, oc_block_0 in T.grid(T.int64(1), T.int64(4), T.int64(2), T.int64(1), T.int64(2)):
                for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1, ic_0, kh_0, kw_0 in T.grid(T.int64(1), T.int64(1), T.int64(2), T.int64(2), T.int64(4), T.int64(8), T.int64(1), T.int64(3)):
                    for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(9), T.int64(14), T.int64(64)):
                        with T.block("data_pad"):
                            v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                            v_i2 = T.axis.spatial(T.int64(30), oh_0 * T.int64(14) + oh_1 * T.int64(7) + ax2)
                            v_i3 = T.axis.spatial(T.int64(30), ow_1 * T.int64(14) + kw_0 + ax3)
                            v_i4 = T.axis.spatial(T.int64(512), ic_0 * T.int64(64) + ax4)
                            T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                            T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                            data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                    for n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(64), T.int64(3), T.int64(1), T.int64(1), T.int64(2), T.int64(7), T.int64(14), T.int64(2)):
                        with T.block("conv2d_NCHWc"):
                            v_n = T.axis.spatial(T.int64(1), n_0 + n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(32), oc_chunk_0 * T.int64(8) + oc_chunk_1 * T.int64(8) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(28), oh_0 * T.int64(14) + oh_1 * T.int64(7) + oh_2 * T.int64(7) + oh_3)
                            v_ow = T.axis.spatial(T.int64(28), ow_0 * T.int64(28) + ow_1 * T.int64(14) + ow_2 * T.int64(14) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(8) + oc_block_1 * T.int64(2) + oc_block_2 * T.int64(2) + oc_block_3)
                            v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(64) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            with T.init():
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
                for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(8), T.int64(14), T.int64(28), T.int64(8)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(32), oc_chunk_0 * T.int64(8) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(28), oh_0 * T.int64(14) + ax2)
                        v_ax3 = T.axis.spatial(T.int64(28), ax3)
                        v_ax4 = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(8) + ax4)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[4, 1, 4, 2])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 2, 1, 7])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 2, 1, 14])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[2, 4, 1, 2])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[8, 64])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=12)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
2024-04-30 06:03:34 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-30 06:03:34 [INFO] [evolutionary_search.cc:715] Picked top 0 candidate(s) from database
2024-04-30 06:03:40 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 06:03:40 [INFO] [evolutionary_search.cc:723] Sampled 512 candidate(s)
2024-04-30 06:03:46 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 06:03:52 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 06:03:58 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 06:04:04 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 06:04:05 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9993  0.9991  0.9987  0.9984  0.9984  0.9974  0.9972  0.9966  0.9959  0.9958  0.9952  0.9947  0.9935  0.9932  0.9917  0.9916
[17 : 32]:	0.9910  0.9910  0.9907  0.9893  0.9888  0.9887  0.9878  0.9875  0.9875  0.9874  0.9874  0.9863  0.9851  0.9842  0.9837  0.9836
[33 : 48]:	0.9832  0.9820  0.9816  0.9814  0.9805  0.9803  0.9799  0.9784  0.9780  0.9778  0.9766  0.9762  0.9757  0.9757  0.9749  0.9748
[49 : 64]:	0.9747  0.9745  0.9744  0.9741  0.9738  0.9735  0.9730  0.9721  0.9715  0.9714  0.9708  0.9694  0.9686  0.9669  0.9665  0.9665
2024-04-30 06:04:05 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-30 06:04:05 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-30 06:42:29 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1: GFLOPs: 82.5694. Time: 44812.9687 us. Best GFLOPs: 82.5694
2024-04-30 06:42:29 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2: GFLOPs: 63.8893. Time: 57915.4977 us. Best GFLOPs: 82.5694
2024-04-30 06:42:29 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #3: GFLOPs: 18.1951. Time: 203361.4763 us. Best GFLOPs: 82.5694
2024-04-30 06:42:29 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #4: GFLOPs: 14.1328. Time: 261814.3800 us. Best GFLOPs: 82.5694
2024-04-30 06:42:29 [INFO] [task_scheduler.cc:121] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #5: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(512)), "float32"), p1: T.Buffer((T.int64(32), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused in T.parallel(T.int64(128), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(4), T.int64(14), T.int64(14), T.int64(1)):
                with T.block("conv2d_NCHWc_init"):
                    v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                    v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(8) // T.int64(2) * T.int64(8) + oc_chunk_2_init * T.int64(4) + oc_chunk_3_init)
                    v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused // T.int64(64) * T.int64(14) + oh_2_init * T.int64(14) + oh_3_init)
                    v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(64) // T.int64(32) * T.int64(14) + ow_2_init * T.int64(14) + ow_3_init)
                    v_oc_block = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(32) // T.int64(8) * T.int64(4) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(2) * T.int64(2) + oc_block_2_init + oc_block_3_init)
                    T.reads()
                    T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                    T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                    conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
            for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(256), T.int64(3), T.int64(3), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(2), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(14), T.int64(14), T.int64(1)):
                with T.block("conv2d_NCHWc_update"):
                    v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                    v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(8) // T.int64(2) * T.int64(8) + oc_chunk_2 * T.int64(4) + oc_chunk_3)
                    v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused // T.int64(64) * T.int64(14) + oh_2 * T.int64(14) + oh_3)
                    v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(64) // T.int64(32) * T.int64(14) + ow_2 * T.int64(14) + ow_3)
                    v_oc_block = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(32) // T.int64(8) * T.int64(4) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(2) * T.int64(2) + oc_block_2 + oc_block_3)
                    v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(2) + ic_1)
                    v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                    v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                    T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], p0[v_n, v_ic // T.int64(512), v_oh + v_kh - T.int64(1), v_ow + v_kw - T.int64(1), v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                    T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                    T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                    conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + T.if_then_else(T.int64(1) <= v_oh + v_kh and v_oh + v_kh < T.int64(29) and T.int64(1) <= v_ow + v_kw and v_ow + v_kw < T.int64(29), p0[v_n, v_ic // T.int64(512), v_oh + v_kh - T.int64(1), v_ow + v_kw - T.int64(1), v_ic % T.int64(512)], T.float32(0)) * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
        for ax0_ax1_ax2_ax3_ax4_fused_0 in T.parallel(T.int64(6272)):
            for ax0_ax1_ax2_ax3_ax4_fused_1 in T.vectorized(T.int64(64)):
                with T.block("T_relu"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) // T.int64(12544))
                    v_ax2 = T.axis.spatial(T.int64(28), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(12544) // T.int64(448))
                    v_ax3 = T.axis.spatial(T.int64(28), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(448) // T.int64(16))
                    v_ax4 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(16))
                    T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                    T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 4, 2, 4])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 1, 1, 14])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[2, 1, 1, 14])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[4, 2, 2, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[256, 2])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
l65 = sch.sample_compute_location(block=b0, decision=-2)
sch.compute_at(block=b0, loop=l65, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b66 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.unroll_explicit")
b67, b68 = sch.get_child_blocks(b66)
l69, l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94 = sch.get_loops(block=b67)
l95 = sch.fuse(l69, l70, l71, l72, l73, l74, l75, l76, l77, l78, preserve_unit_iters=True)
sch.parallel(loop=l95)
sch.annotate(block_or_loop=l95, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l95, ann_key="pragma_unroll_explicit", ann_val=1)
l96, l97, l98, l99, l100 = sch.get_loops(block=b68)
l101 = sch.fuse(l96, l97, l98, l99, l100, preserve_unit_iters=True)
l102, l103 = sch.split(loop=l101, factors=[None, 64], preserve_unit_iters=True)
sch.parallel(loop=l102)
sch.vectorize(loop=l103)
b104 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l105, l106, l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117, l118, l119, l120, l121 = sch.get_loops(block=b104)
b122 = sch.decompose_reduction(block=b104, loop=l106)
2024-04-30 06:42:29 [INFO] [task_scheduler.cc:121] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #6: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(512)), "float32"), p1: T.Buffer((T.int64(32), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_fused_fused in T.parallel(T.int64(7), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(30), T.int64(6), T.int64(512)):
                with T.block("data_pad"):
                    v_i0, v_i1, v_i2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                    v_i3 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_fused_fused * T.int64(4) + ax3)
                    v_i4 = T.axis.spatial(T.int64(512), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oc_block_0, n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(8), T.int64(1), T.int64(4), T.int64(4), T.int64(4), T.int64(2)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(7), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(32), oc_chunk_1 * T.int64(8) + oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(28), oh_1 * T.int64(7) + oh_2_init * T.int64(7) + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused * T.int64(4) + ow_1 + ow_2_init + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(2) + oc_block_1 + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(512), T.int64(1), T.int64(3), T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(2), T.int64(7), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(32), oc_chunk_1 * T.int64(8) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(28), oh_1 * T.int64(7) + oh_2 * T.int64(7) + oh_3)
                        v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused * T.int64(4) + ow_1 + ow_2 + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(2) + oc_block_1 + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(512), ic_0 + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
                for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(8), T.int64(7), T.int64(1), T.int64(1)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(32), oc_chunk_1 * T.int64(8) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(28), oh_1 * T.int64(7) + ax2)
                        v_ax3 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused * T.int64(4) + ow_1 + ax3)
                        v_ax4 = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(2) + oc_block_1 + ax4)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 4, 4, 2])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 4, 1, 7])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[7, 4, 1, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[8, 2, 1, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[512, 1])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=3)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79 = sch.get_loops(block=b68)
l80 = sch.fuse(l71, l72, l73, l74, preserve_unit_iters=True)
sch.parallel(loop=l80)
l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l81, preserve_unit_iters=True)
sch.parallel(loop=l104)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109, l110, l111, l112, l113, l114, l115, l116 = sch.get_loops(block=b70)
b117 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140 = sch.get_loops(block=b117)
b141 = sch.decompose_reduction(block=b117, loop=l125)
2024-04-30 06:42:29 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #7: GFLOPs: 14.9975. Time: 246720.0400 us. Best GFLOPs: 82.5694
2024-04-30 06:42:29 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #8: GFLOPs: 8.9582. Time: 413047.1583 us. Best GFLOPs: 82.5694
2024-04-30 06:42:29 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #9: GFLOPs: 5.6618. Time: 653534.2007 us. Best GFLOPs: 82.5694
2024-04-30 06:42:29 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #10: GFLOPs: 2.7400. Time: 1350423.0350 us. Best GFLOPs: 82.5694
2024-04-30 06:42:29 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #11: GFLOPs: 10.2449. Time: 361171.5260 us. Best GFLOPs: 82.5694
2024-04-30 06:42:29 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #12: GFLOPs: 24.6593. Time: 150052.2330 us. Best GFLOPs: 82.5694
2024-04-30 06:42:29 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #13: GFLOPs: 5.5122. Time: 671265.7710 us. Best GFLOPs: 82.5694
2024-04-30 06:42:29 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #14: GFLOPs: 35.2775. Time: 104887.8533 us. Best GFLOPs: 82.5694
2024-04-30 06:42:29 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #15: GFLOPs: 30.8647. Time: 119884.0157 us. Best GFLOPs: 82.5694
2024-04-30 06:42:29 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #16: GFLOPs: 2.5614. Time: 1444582.7933 us. Best GFLOPs: 82.5694
2024-04-30 06:42:29 [INFO] [task_scheduler.cc:121] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #17: Error in running:
LocalRunner: Timeout, killed after 30 seconds

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(512)), "float32"), p1: T.Buffer((T.int64(32), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused in T.parallel(T.int64(4)):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(30), T.int64(16), T.int64(512)):
                with T.block("data_pad"):
                    v_i0, v_i1, v_i2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                    v_i3 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(2) * T.int64(14) + ax3)
                    v_i4 = T.axis.spatial(T.int64(512), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(14), T.int64(1), T.int64(1), T.int64(16), T.int64(28), T.int64(1)):
                for oc_block_3_fused_init in T.vectorized(T.int64(8)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(32), oc_chunk_2_init * T.int64(16) + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(28), oh_2_init * T.int64(28) + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(2) * T.int64(14) + ow_2_init + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(2) * T.int64(8) + oc_block_2_init * T.int64(8) + oc_block_3_fused_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
            for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(512), T.int64(3), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(14), T.int64(1), T.int64(1), T.int64(1), T.int64(3), T.int64(1), T.int64(16), T.int64(28), T.int64(1)):
                for oc_block_3_fused in T.vectorized(T.int64(8)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(32), oc_chunk_2 * T.int64(16) + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(28), oh_2 * T.int64(28) + oh_3)
                        v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(2) * T.int64(14) + ow_2 + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(2) * T.int64(8) + oc_block_2 * T.int64(8) + oc_block_3_fused)
                        v_ic = T.axis.reduce(T.int64(512), ic_0 + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
        for ax0_ax1_ax2_ax3_ax4_fused_0 in T.parallel(T.int64(6272)):
            for ax0_ax1_ax2_ax3_ax4_fused_1 in T.vectorized(T.int64(64)):
                with T.block("T_relu"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) // T.int64(12544))
                    v_ax2 = T.axis.spatial(T.int64(28), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(12544) // T.int64(448))
                    v_ax3 = T.axis.spatial(T.int64(28), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(448) // T.int64(16))
                    v_ax4 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(16))
                    T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                    T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 2, 16])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 1, 28])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[2, 1, 14, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 2, 1, 8])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[512, 1])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
l65 = sch.sample_compute_location(block=b0, decision=9)
sch.compute_at(block=b0, loop=l65, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b66 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.unroll_explicit")
b67, b68, b69 = sch.get_child_blocks(b66)
l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b67)
l85 = sch.fuse(l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, preserve_unit_iters=True)
sch.parallel(loop=l85)
l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102 = sch.get_loops(block=b68)
l103 = sch.fuse(l86, preserve_unit_iters=True)
sch.parallel(loop=l103)
l104 = sch.fuse(l102, preserve_unit_iters=True)
sch.vectorize(loop=l104)
l105, l106, l107, l108, l109 = sch.get_loops(block=b69)
l110 = sch.fuse(l105, l106, l107, l108, l109, preserve_unit_iters=True)
l111, l112 = sch.split(loop=l110, factors=[None, 64], preserve_unit_iters=True)
sch.parallel(loop=l111)
sch.vectorize(loop=l112)
b113 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130 = sch.get_loops(block=b113)
b131 = sch.decompose_reduction(block=b113, loop=l115)
2024-04-30 06:42:29 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #18: GFLOPs: 34.7232. Time: 106562.2827 us. Best GFLOPs: 82.5694
2024-04-30 06:42:29 [INFO] [task_scheduler.cc:121] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #19: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(512)), "float32"), p1: T.Buffer((T.int64(32), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)))
        for i0_i1_i2_i3_fused in T.parallel(T.int64(900)):
            for i4 in range(T.int64(512)):
                with T.block("data_pad"):
                    v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_i1 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_i2 = T.axis.spatial(T.int64(30), i0_i1_i2_i3_fused // T.int64(30))
                    v_i3 = T.axis.spatial(T.int64(30), i0_i1_i2_i3_fused % T.int64(30))
                    v_i4 = T.axis.spatial(T.int64(512), i4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused in T.parallel(T.int64(896), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(7), T.int64(2), T.int64(1), T.int64(4), T.int64(1), T.int64(2), T.int64(1)):
                with T.block("conv2d_NCHWc_init"):
                    v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                    v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused // T.int64(448) * T.int64(16) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(16) // T.int64(4) * T.int64(4) + oc_chunk_2_init * T.int64(4) + oc_chunk_3_init)
                    v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(448) // T.int64(64) * T.int64(4) + oh_2_init + oh_3_init)
                    v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(4) // T.int64(2) * T.int64(14) + ow_2_init * T.int64(2) + ow_3_init)
                    v_oc_block = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(64) // T.int64(16) * T.int64(4) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(2) * T.int64(2) + oc_block_2_init + oc_block_3_init)
                    T.reads()
                    T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                    T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                    conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
            for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(32), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(7), T.int64(2), T.int64(16), T.int64(1), T.int64(3), T.int64(1), T.int64(4), T.int64(1), T.int64(2), T.int64(1)):
                with T.block("conv2d_NCHWc_update"):
                    v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                    v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused // T.int64(448) * T.int64(16) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(16) // T.int64(4) * T.int64(4) + oc_chunk_2 * T.int64(4) + oc_chunk_3)
                    v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(448) // T.int64(64) * T.int64(4) + oh_2 + oh_3)
                    v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(4) // T.int64(2) * T.int64(14) + ow_2 * T.int64(2) + ow_3)
                    v_oc_block = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(64) // T.int64(16) * T.int64(4) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(2) * T.int64(2) + oc_block_2 + oc_block_3)
                    v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(16) + ic_1)
                    v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                    v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                    T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                    T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                    T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                    conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
        for ax0_ax1_ax2_ax3_ax4_fused_0 in T.parallel(T.int64(6272)):
            for ax0_ax1_ax2_ax3_ax4_fused_1 in T.vectorized(T.int64(64)):
                with T.block("T_relu"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) // T.int64(12544))
                    v_ax2 = T.axis.spatial(T.int64(28), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(12544) // T.int64(448))
                    v_ax3 = T.axis.spatial(T.int64(28), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(448) // T.int64(16))
                    v_ax4 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(16))
                    T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                    T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[2, 4, 1, 4])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[7, 1, 4, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 2, 7, 2])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[4, 2, 2, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[32, 16])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
l65 = sch.sample_compute_location(block=b0, decision=-1)
sch.compute_at(block=b0, loop=l65, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b66 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.unroll_explicit")
b67, b68, b69 = sch.get_child_blocks(b66)
l70, l71, l72, l73, l74 = sch.get_loops(block=b67)
l75 = sch.fuse(l70, l71, l72, l73, preserve_unit_iters=True)
sch.parallel(loop=l75)
l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101 = sch.get_loops(block=b68)
l102 = sch.fuse(l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, preserve_unit_iters=True)
sch.parallel(loop=l102)
sch.annotate(block_or_loop=l102, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l102, ann_key="pragma_unroll_explicit", ann_val=1)
l103, l104, l105, l106, l107 = sch.get_loops(block=b69)
l108 = sch.fuse(l103, l104, l105, l106, l107, preserve_unit_iters=True)
l109, l110 = sch.split(loop=l108, factors=[None, 64], preserve_unit_iters=True)
sch.parallel(loop=l109)
sch.vectorize(loop=l110)
b111 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l112, l113, l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128 = sch.get_loops(block=b111)
b129 = sch.decompose_reduction(block=b111, loop=l113)
2024-04-30 06:42:29 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #20: GFLOPs: 124.1086. Time: 29814.0488 us. Best GFLOPs: 124.1086
2024-04-30 06:42:29 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #21: GFLOPs: 2.4175. Time: 1530581.7217 us. Best GFLOPs: 124.1086
2024-04-30 06:42:29 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #22: GFLOPs: 74.9515. Time: 49367.6473 us. Best GFLOPs: 124.1086
2024-04-30 06:42:29 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #23: GFLOPs: 7.3241. Time: 505206.9167 us. Best GFLOPs: 124.1086
2024-04-30 06:42:29 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #24: GFLOPs: 28.0897. Time: 131727.1560 us. Best GFLOPs: 124.1086
2024-04-30 06:42:29 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #25: GFLOPs: 56.4912. Time: 65500.1017 us. Best GFLOPs: 124.1086
2024-04-30 06:42:29 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #26: GFLOPs: 5.9097. Time: 626117.4100 us. Best GFLOPs: 124.1086
2024-04-30 06:42:29 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #27: GFLOPs: 16.7550. Time: 220840.1213 us. Best GFLOPs: 124.1086
2024-04-30 06:42:29 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #28: GFLOPs: 6.1943. Time: 597353.5510 us. Best GFLOPs: 124.1086
2024-04-30 06:42:29 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #29: GFLOPs: 19.2522. Time: 192195.5110 us. Best GFLOPs: 124.1086
2024-04-30 06:42:29 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #30: GFLOPs: 30.7525. Time: 120321.1727 us. Best GFLOPs: 124.1086
2024-04-30 06:42:29 [INFO] [task_scheduler.cc:121] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #31: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(512)), "float32"), p1: T.Buffer((T.int64(32), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)))
        for n_0_oc_chunk_0_fused_fused in T.parallel(T.int64(2), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(512)):
                with T.block("data_pad"):
                    v_i0, v_i1, v_i2, v_i3, v_i4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oh_0, ow_0, oc_block_0, n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1), T.int64(2), T.int64(7), T.int64(1), T.int64(2)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(8), T.int64(1), T.int64(7)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_fused_fused * T.int64(16) + oc_chunk_1 * T.int64(8) + oc_chunk_2_init * T.int64(8) + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(28), oh_0 * T.int64(7) + oh_1 + oh_2_init + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(28), ow_0 * T.int64(7) + ow_1 * T.int64(7) + ow_2_init * T.int64(7) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(16) + oc_block_1 * T.int64(8) + oc_block_2_init * T.int64(4) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(8), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(64), T.int64(3), T.int64(1), T.int64(1), T.int64(8), T.int64(1), T.int64(7)):
                    for oc_block_3_fused in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_fused_fused * T.int64(16) + oc_chunk_1 * T.int64(8) + oc_chunk_2 * T.int64(8) + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(28), oh_0 * T.int64(7) + oh_1 + oh_2 + oh_3)
                            v_ow = T.axis.spatial(T.int64(28), ow_0 * T.int64(7) + ow_1 * T.int64(7) + ow_2 * T.int64(7) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(16) + oc_block_1 * T.int64(8) + oc_block_2 * T.int64(4) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(64) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
        for ax0_ax1_ax2_ax3_ax4_fused_0 in T.parallel(T.int64(6272)):
            for ax0_ax1_ax2_ax3_ax4_fused_1 in T.vectorized(T.int64(64)):
                with T.block("T_relu"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) // T.int64(12544))
                    v_ax2 = T.axis.spatial(T.int64(28), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(12544) // T.int64(448))
                    v_ax3 = T.axis.spatial(T.int64(28), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(448) // T.int64(16))
                    v_ax4 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(16))
                    T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                    T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[2, 2, 1, 8])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[4, 7, 1, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[4, 1, 1, 7])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 2, 2, 4])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[8, 64])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
l65 = sch.sample_compute_location(block=b0, decision=1)
sch.compute_at(block=b0, loop=l65, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b66 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.unroll_explicit")
b67, b68, b69 = sch.get_child_blocks(b66)
l70, l71, l72, l73, l74, l75, l76 = sch.get_loops(block=b67)
l77 = sch.fuse(l70, l71, preserve_unit_iters=True)
sch.parallel(loop=l77)
l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102 = sch.get_loops(block=b68)
l103 = sch.fuse(l78, preserve_unit_iters=True)
sch.parallel(loop=l103)
l104 = sch.fuse(l102, preserve_unit_iters=True)
sch.vectorize(loop=l104)
sch.annotate(block_or_loop=l103, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l103, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109 = sch.get_loops(block=b69)
l110 = sch.fuse(l105, l106, l107, l108, l109, preserve_unit_iters=True)
l111, l112 = sch.split(loop=l110, factors=[None, 64], preserve_unit_iters=True)
sch.parallel(loop=l111)
sch.vectorize(loop=l112)
b113 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138 = sch.get_loops(block=b113)
b139 = sch.decompose_reduction(block=b113, loop=l123)
2024-04-30 06:42:29 [INFO] [task_scheduler.cc:121] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #32: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(512)), "float32"), p1: T.Buffer((T.int64(32), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused in T.parallel(T.int64(256), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(14), T.int64(28), T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                with T.block("conv2d_NCHWc_init"):
                    v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                    v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused // T.int64(64) * T.int64(8) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(16) // T.int64(2) + oc_chunk_2_init + oc_chunk_3_init)
                    v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(64) // T.int64(32) * T.int64(14) + oh_2_init + oh_3_init)
                    v_ow = T.axis.spatial(T.int64(28), ow_2_init + ow_3_init)
                    v_oc_block = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(32) // T.int64(16) * T.int64(8) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(2) * T.int64(4) + oc_block_2_init + oc_block_3_init)
                    T.reads()
                    T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                    T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                    conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
            for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(8), T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(14), T.int64(28), T.int64(4), T.int64(64), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                with T.block("conv2d_NCHWc_update"):
                    v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                    v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused // T.int64(64) * T.int64(8) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(16) // T.int64(2) + oc_chunk_2 + oc_chunk_3)
                    v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(64) // T.int64(32) * T.int64(14) + oh_2 + oh_3)
                    v_ow = T.axis.spatial(T.int64(28), ow_2 + ow_3)
                    v_oc_block = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(32) // T.int64(16) * T.int64(8) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(2) * T.int64(4) + oc_block_2 + oc_block_3)
                    v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(64) + ic_1)
                    v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                    v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                    T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], p0[v_n, v_ic // T.int64(512), v_oh + v_kh - T.int64(1), v_ow + v_kw - T.int64(1), v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                    T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                    T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                    conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + T.if_then_else(T.int64(1) <= v_oh + v_kh and v_oh + v_kh < T.int64(29) and T.int64(1) <= v_ow + v_kw and v_ow + v_kw < T.int64(29), p0[v_n, v_ic // T.int64(512), v_oh + v_kh - T.int64(1), v_ow + v_kw - T.int64(1), v_ic % T.int64(512)], T.float32(0)) * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(14), T.int64(28)):
                for ax4_fused in T.vectorized(T.int64(4)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused // T.int64(64) * T.int64(8) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(16) // T.int64(2) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(64) // T.int64(32) * T.int64(14) + ax2)
                        v_ax3 = T.axis.spatial(T.int64(28), ax3)
                        v_ax4 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(32) // T.int64(16) * T.int64(8) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(2) * T.int64(4) + ax4_fused)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[4, 8, 1, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 1, 14, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 28, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[2, 2, 4, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[8, 64])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=-2)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69 = sch.get_child_blocks(b67)
l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95 = sch.get_loops(block=b68)
l96 = sch.fuse(l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, preserve_unit_iters=True)
sch.parallel(loop=l96)
sch.annotate(block_or_loop=l96, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l96, ann_key="pragma_unroll_explicit", ann_val=1)
l97, l98, l99, l100, l101, l102 = sch.get_loops(block=b69)
l103 = sch.fuse(l102, preserve_unit_iters=True)
sch.vectorize(loop=l103)
b104 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l105, l106, l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117, l118, l119, l120, l121 = sch.get_loops(block=b104)
b122 = sch.decompose_reduction(block=b104, loop=l106)
2024-04-30 06:42:29 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #33: GFLOPs: 22.3264. Time: 165731.1617 us. Best GFLOPs: 124.1086
2024-04-30 06:42:29 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #34: GFLOPs: 13.3563. Time: 277035.6917 us. Best GFLOPs: 124.1086
2024-04-30 06:42:29 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #35: GFLOPs: 68.2418. Time: 54221.5853 us. Best GFLOPs: 124.1086
2024-04-30 06:42:29 [INFO] [task_scheduler.cc:121] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #36: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(512)), "float32"), p1: T.Buffer((T.int64(32), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused in T.parallel(T.int64(1792), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for oh_1 in range(T.int64(2)):
                for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(3), T.int64(30), T.int64(512)):
                    with T.block("data_pad"):
                        v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                        v_i2 = T.axis.spatial(T.int64(30), oh_1 + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(896) // T.int64(64) * T.int64(2) + ax2)
                        v_i3, v_i4 = T.axis.remap("SS", [ax3, ax4])
                        T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                        T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                        data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                for ow_1, oc_block_1 in T.grid(T.int64(2), T.int64(1)):
                    for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(896) * T.int64(16) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(16) + oc_chunk_2_init + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(896) // T.int64(64) * T.int64(2) + oh_1 + oh_2_init + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(28), ow_1 * T.int64(14) + ow_2_init * T.int64(7) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(64) // T.int64(16) * T.int64(4) + oc_block_1 * T.int64(4) + oc_block_2_init + oc_block_3_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                    for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(8), T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(4), T.int64(64), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(896) * T.int64(16) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(16) + oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(896) // T.int64(64) * T.int64(2) + oh_1 + oh_2 + oh_3)
                            v_ow = T.axis.spatial(T.int64(28), ow_1 * T.int64(14) + ow_2 * T.int64(7) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(64) // T.int64(16) * T.int64(4) + oc_block_1 * T.int64(4) + oc_block_2 + oc_block_3)
                            v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(64) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(14)):
                        for ax4_fused in T.vectorized(T.int64(4)):
                            with T.block("T_relu"):
                                v_ax0 = T.axis.spatial(T.int64(1), ax0)
                                v_ax1 = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(896) * T.int64(16) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(16) + ax1)
                                v_ax2 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(896) // T.int64(64) * T.int64(2) + oh_1 + ax2)
                                v_ax3 = T.axis.spatial(T.int64(28), ow_1 * T.int64(14) + ax3)
                                v_ax4 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(64) // T.int64(16) * T.int64(4) + ax4_fused)
                                T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                                T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                                T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[2, 16, 1, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[14, 2, 1, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 2, 2, 7])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[4, 1, 4, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[8, 64])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=7)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83 = sch.get_loops(block=b68)
l84 = sch.fuse(l71, l72, l73, l74, l75, l76, l77, preserve_unit_iters=True)
sch.parallel(loop=l84)
l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b69)
l105 = sch.fuse(l85, preserve_unit_iters=True)
sch.parallel(loop=l105)
sch.annotate(block_or_loop=l105, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l105, ann_key="pragma_unroll_explicit", ann_val=1)
l106, l107, l108, l109, l110, l111, l112, l113, l114 = sch.get_loops(block=b70)
l115 = sch.fuse(l114, preserve_unit_iters=True)
sch.vectorize(loop=l115)
b116 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136 = sch.get_loops(block=b116)
b137 = sch.decompose_reduction(block=b116, loop=l121)
2024-04-30 06:42:29 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #37: GFLOPs: 29.2363. Time: 126561.1567 us. Best GFLOPs: 124.1086
2024-04-30 06:42:29 [INFO] [task_scheduler.cc:121] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #38: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(512)), "float32"), p1: T.Buffer((T.int64(32), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_fused_fused in T.parallel(T.int64(7), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(30), T.int64(6), T.int64(512)):
                with T.block("data_pad"):
                    v_i0, v_i1, v_i2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                    v_i3 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_fused_fused * T.int64(4) + ax3)
                    v_i4 = T.axis.spatial(T.int64(512), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oc_block_0, n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(8), T.int64(1), T.int64(4), T.int64(2), T.int64(4), T.int64(2)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(14), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(32), oc_chunk_1 * T.int64(8) + oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(28), oh_1 * T.int64(14) + oh_2_init * T.int64(14) + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused * T.int64(4) + ow_1 + ow_2_init + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(2) + oc_block_1 + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(512), T.int64(1), T.int64(3), T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(2), T.int64(14), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(32), oc_chunk_1 * T.int64(8) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(28), oh_1 * T.int64(14) + oh_2 * T.int64(14) + oh_3)
                        v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused * T.int64(4) + ow_1 + ow_2 + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(2) + oc_block_1 + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(512), ic_0 + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
                for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(8), T.int64(14), T.int64(1), T.int64(1)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(32), oc_chunk_1 * T.int64(8) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(28), oh_1 * T.int64(14) + ax2)
                        v_ax3 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused * T.int64(4) + ow_1 + ax3)
                        v_ax4 = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(2) + oc_block_1 + ax4)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 4, 4, 2])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 2, 1, 14])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[7, 4, 1, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[8, 2, 1, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[512, 1])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=3)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79 = sch.get_loops(block=b68)
l80 = sch.fuse(l71, l72, l73, l74, preserve_unit_iters=True)
sch.parallel(loop=l80)
l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l81, preserve_unit_iters=True)
sch.parallel(loop=l104)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109, l110, l111, l112, l113, l114, l115, l116 = sch.get_loops(block=b70)
b117 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140 = sch.get_loops(block=b117)
b141 = sch.decompose_reduction(block=b117, loop=l125)
2024-04-30 06:42:29 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #39: GFLOPs: 5.7067. Time: 648391.7983 us. Best GFLOPs: 124.1086
2024-04-30 06:42:29 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #40: GFLOPs: 30.8841. Time: 119808.5603 us. Best GFLOPs: 124.1086
2024-04-30 06:42:29 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #41: GFLOPs: 19.3038. Time: 191681.4833 us. Best GFLOPs: 124.1086
2024-04-30 06:42:29 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #42: GFLOPs: 9.8657. Time: 375055.3067 us. Best GFLOPs: 124.1086
2024-04-30 06:42:29 [INFO] [task_scheduler.cc:121] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #43: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(512)), "float32"), p1: T.Buffer((T.int64(32), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused in T.parallel(T.int64(14), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(16)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(2), T.int64(2), T.int64(1), T.int64(1), T.int64(16), T.int64(14), T.int64(2), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused // T.int64(7) * T.int64(16) + oc_chunk_1 * T.int64(16) + oc_chunk_2_init * T.int64(16) + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(28), oh_1 * T.int64(28) + oh_2_init * T.int64(14) + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused % T.int64(7) * T.int64(4) + ow_1 * T.int64(4) + ow_2_init * T.int64(2) + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(16), oc_block_1 + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(128), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(2), T.int64(1), T.int64(4), T.int64(1), T.int64(3), T.int64(1), T.int64(16), T.int64(14), T.int64(2), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused // T.int64(7) * T.int64(16) + oc_chunk_1 * T.int64(16) + oc_chunk_2 * T.int64(16) + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(28), oh_1 * T.int64(28) + oh_2 * T.int64(14) + oh_3)
                        v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused % T.int64(7) * T.int64(4) + ow_1 * T.int64(4) + ow_2 * T.int64(2) + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(16), oc_block_1 + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(4) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], p0[v_n, v_ic // T.int64(512), v_oh + v_kh - T.int64(1), v_ow + v_kw - T.int64(1), v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + T.if_then_else(T.int64(1) <= v_oh + v_kh and v_oh + v_kh < T.int64(29) and T.int64(1) <= v_ow + v_kw and v_ow + v_kw < T.int64(29), p0[v_n, v_ic // T.int64(512), v_oh + v_kh - T.int64(1), v_ow + v_kw - T.int64(1), v_ic % T.int64(512)], T.float32(0)) * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
            for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(16), T.int64(28)):
                for ax3_ax4_fused in T.vectorized(T.int64(64)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused // T.int64(7) * T.int64(16) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(28), ax2)
                        v_ax3 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused % T.int64(7) * T.int64(4) + ax3_ax4_fused // T.int64(16))
                        v_ax4 = T.axis.spatial(T.int64(16), ax3_ax4_fused % T.int64(16))
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[2, 1, 1, 16])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 2, 14])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[7, 1, 2, 2])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 16, 1, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[128, 4])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=-2)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69 = sch.get_child_blocks(b67)
l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95 = sch.get_loops(block=b68)
l96 = sch.fuse(l70, l71, l72, l73, l74, preserve_unit_iters=True)
sch.parallel(loop=l96)
sch.annotate(block_or_loop=l96, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l96, ann_key="pragma_unroll_explicit", ann_val=1)
l97, l98, l99, l100, l101, l102 = sch.get_loops(block=b69)
l103 = sch.fuse(l101, l102, preserve_unit_iters=True)
sch.vectorize(loop=l103)
b104 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l105, l106, l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126 = sch.get_loops(block=b104)
b127 = sch.decompose_reduction(block=b104, loop=l111)
2024-04-30 06:42:29 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #44: GFLOPs: 19.1068. Time: 193657.9073 us. Best GFLOPs: 124.1086
2024-04-30 06:42:29 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #45: GFLOPs: 17.9229. Time: 206449.4413 us. Best GFLOPs: 124.1086
2024-04-30 06:42:29 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #46: GFLOPs: 15.3687. Time: 240760.7633 us. Best GFLOPs: 124.1086
2024-04-30 06:42:29 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #47: GFLOPs: 35.1267. Time: 105338.1907 us. Best GFLOPs: 124.1086
2024-04-30 06:42:29 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #48: GFLOPs: 71.8820. Time: 51475.7680 us. Best GFLOPs: 124.1086
2024-04-30 06:42:29 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #49: GFLOPs: 130.1617. Time: 28427.5527 us. Best GFLOPs: 130.1617
2024-04-30 06:42:29 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #50: GFLOPs: 110.6476. Time: 33441.1145 us. Best GFLOPs: 130.1617
2024-04-30 06:42:29 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #51: GFLOPs: 44.9734. Time: 82274.8027 us. Best GFLOPs: 130.1617
2024-04-30 06:42:29 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #52: GFLOPs: 7.1222. Time: 519528.9290 us. Best GFLOPs: 130.1617
2024-04-30 06:42:29 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #53: GFLOPs: 26.4737. Time: 139767.8577 us. Best GFLOPs: 130.1617
2024-04-30 06:42:29 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #54: GFLOPs: 5.0839. Time: 727818.9853 us. Best GFLOPs: 130.1617
2024-04-30 06:42:29 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #55: GFLOPs: 90.1613. Time: 41039.5280 us. Best GFLOPs: 130.1617
2024-04-30 06:42:29 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #56: GFLOPs: 35.7090. Time: 103620.3140 us. Best GFLOPs: 130.1617
2024-04-30 06:42:29 [INFO] [task_scheduler.cc:121] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #57: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(512)), "float32"), p1: T.Buffer((T.int64(32), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)))
        for i0_i1_i2_i3_fused in T.parallel(T.int64(900)):
            for i4 in range(T.int64(512)):
                with T.block("data_pad"):
                    v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_i1 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_i2 = T.axis.spatial(T.int64(30), i0_i1_i2_i3_fused // T.int64(30))
                    v_i3 = T.axis.spatial(T.int64(30), i0_i1_i2_i3_fused % T.int64(30))
                    v_i4 = T.axis.spatial(T.int64(512), i4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused in T.parallel(T.int64(224), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(4), T.int64(4), T.int64(7), T.int64(2), T.int64(1), T.int64(4), T.int64(1), T.int64(2), T.int64(1)):
                with T.block("conv2d_NCHWc_init"):
                    v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                    v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(4) // T.int64(2) * T.int64(16) + oc_chunk_2_init * T.int64(4) + oc_chunk_3_init)
                    v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused // T.int64(32) * T.int64(4) + oh_2_init + oh_3_init)
                    v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(2) * T.int64(14) + ow_2_init * T.int64(2) + ow_3_init)
                    v_oc_block = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(32) // T.int64(4) * T.int64(2) + oc_block_2_init + oc_block_3_init)
                    T.reads()
                    T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                    T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                    conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
            for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(32), T.int64(3), T.int64(1), T.int64(1), T.int64(4), T.int64(4), T.int64(7), T.int64(2), T.int64(16), T.int64(1), T.int64(3), T.int64(1), T.int64(4), T.int64(1), T.int64(2), T.int64(1)):
                with T.block("conv2d_NCHWc_update"):
                    v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                    v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(4) // T.int64(2) * T.int64(16) + oc_chunk_2 * T.int64(4) + oc_chunk_3)
                    v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused // T.int64(32) * T.int64(4) + oh_2 + oh_3)
                    v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(2) * T.int64(14) + ow_2 * T.int64(2) + ow_3)
                    v_oc_block = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(32) // T.int64(4) * T.int64(2) + oc_block_2 + oc_block_3)
                    v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(16) + ic_1)
                    v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                    v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                    T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                    T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                    T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                    conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
        for ax0_ax1_ax2_ax3_ax4_fused_0 in T.parallel(T.int64(6272)):
            for ax0_ax1_ax2_ax3_ax4_fused_1 in T.vectorized(T.int64(64)):
                with T.block("T_relu"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) // T.int64(12544))
                    v_ax2 = T.axis.spatial(T.int64(28), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(12544) // T.int64(448))
                    v_ax3 = T.axis.spatial(T.int64(28), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(448) // T.int64(16))
                    v_ax4 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(16))
                    T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                    T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 2, 4, 4])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[7, 1, 4, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 2, 7, 2])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[8, 1, 2, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[32, 16])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
l65 = sch.sample_compute_location(block=b0, decision=-1)
sch.compute_at(block=b0, loop=l65, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b66 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.unroll_explicit")
b67, b68, b69 = sch.get_child_blocks(b66)
l70, l71, l72, l73, l74 = sch.get_loops(block=b67)
l75 = sch.fuse(l70, l71, l72, l73, preserve_unit_iters=True)
sch.parallel(loop=l75)
l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101 = sch.get_loops(block=b68)
l102 = sch.fuse(l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, preserve_unit_iters=True)
sch.parallel(loop=l102)
sch.annotate(block_or_loop=l102, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l102, ann_key="pragma_unroll_explicit", ann_val=1)
l103, l104, l105, l106, l107 = sch.get_loops(block=b69)
l108 = sch.fuse(l103, l104, l105, l106, l107, preserve_unit_iters=True)
l109, l110 = sch.split(loop=l108, factors=[None, 64], preserve_unit_iters=True)
sch.parallel(loop=l109)
sch.vectorize(loop=l110)
b111 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l112, l113, l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128 = sch.get_loops(block=b111)
b129 = sch.decompose_reduction(block=b111, loop=l113)
2024-04-30 06:42:29 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #58: GFLOPs: 3.8549. Time: 959869.5417 us. Best GFLOPs: 130.1617
2024-04-30 06:42:29 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #59: GFLOPs: 19.3944. Time: 190786.3477 us. Best GFLOPs: 130.1617
2024-04-30 06:42:29 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #60: GFLOPs: 18.2199. Time: 203084.3943 us. Best GFLOPs: 130.1617
2024-04-30 06:42:29 [INFO] [task_scheduler.cc:121] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #61: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(512)), "float32"), p1: T.Buffer((T.int64(32), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused in T.parallel(T.int64(448), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(4), T.int64(2), T.int64(14), T.int64(1), T.int64(1), T.int64(2), T.int64(2), T.int64(1)):
                for oc_block_3_fused_init in T.vectorized(T.int64(2)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(112) * T.int64(8) + oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(56) // T.int64(8) * T.int64(4) + oh_2_init * T.int64(2) + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(112) // T.int64(56) * T.int64(14) + ow_2_init + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(8) * T.int64(2) + oc_block_2_init * T.int64(2) + oc_block_3_fused_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
            for ic_0 in range(T.int64(64)):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(6), T.int64(16)):
                    for ax4_fused in T.vectorized(T.int64(8)):
                        with T.block("data_pad"):
                            v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                            v_i2 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(56) // T.int64(8) * T.int64(4) + ax2)
                            v_i3 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(112) // T.int64(56) * T.int64(14) + ax3)
                            v_i4 = T.axis.spatial(T.int64(512), ic_0 * T.int64(8) + ax4_fused)
                            T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                            T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                            data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                for kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(3), T.int64(3), T.int64(1), T.int64(4), T.int64(2), T.int64(14), T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(2), T.int64(1)):
                    for oc_block_3_fused in T.vectorized(T.int64(2)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(112) * T.int64(8) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(56) // T.int64(8) * T.int64(4) + oh_2 * T.int64(2) + oh_3)
                            v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(112) // T.int64(56) * T.int64(14) + ow_2 + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(8) * T.int64(2) + oc_block_2 * T.int64(2) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(8) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
        for ax0_ax1_ax2_ax3_ax4_fused_0 in T.parallel(T.int64(6272)):
            for ax0_ax1_ax2_ax3_ax4_fused_1 in T.vectorized(T.int64(64)):
                with T.block("T_relu"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) // T.int64(12544))
                    v_ax2 = T.axis.spatial(T.int64(28), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(12544) // T.int64(448))
                    v_ax3 = T.axis.spatial(T.int64(28), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(448) // T.int64(16))
                    v_ax4 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(16))
                    T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                    T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[4, 1, 4, 2])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 7, 2, 2])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[2, 1, 14, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 8, 1, 2])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[64, 8])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
l65 = sch.sample_compute_location(block=b0, decision=10)
sch.compute_at(block=b0, loop=l65, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b66 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.unroll_explicit")
b67, b68, b69 = sch.get_child_blocks(b66)
l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85 = sch.get_loops(block=b67)
l86 = sch.fuse(l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, preserve_unit_iters=True)
sch.parallel(loop=l86)
l87 = sch.fuse(l85, preserve_unit_iters=True)
sch.vectorize(loop=l87)
l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b68)
l105 = sch.fuse(l88, preserve_unit_iters=True)
sch.parallel(loop=l105)
l106 = sch.fuse(l104, preserve_unit_iters=True)
sch.vectorize(loop=l106)
sch.annotate(block_or_loop=l105, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l105, ann_key="pragma_unroll_explicit", ann_val=1)
l107, l108, l109, l110, l111 = sch.get_loops(block=b69)
l112 = sch.fuse(l107, l108, l109, l110, l111, preserve_unit_iters=True)
l113, l114 = sch.split(loop=l112, factors=[None, 64], preserve_unit_iters=True)
sch.parallel(loop=l113)
sch.vectorize(loop=l114)
b115 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132 = sch.get_loops(block=b115)
b133 = sch.decompose_reduction(block=b115, loop=l117)
2024-04-30 06:42:29 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #62: GFLOPs: 5.0786. Time: 728580.9583 us. Best GFLOPs: 130.1617
2024-04-30 06:42:29 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #63: GFLOPs: 103.8690. Time: 35623.5177 us. Best GFLOPs: 130.1617
2024-04-30 06:42:29 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #64: GFLOPs: 55.6132. Time: 66534.1283 us. Best GFLOPs: 130.1617
2024-04-30 06:42:56 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-30 06:42:56 [INFO] [evolutionary_search.cc:715] Picked top 53 candidate(s) from database
2024-04-30 06:43:01 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 06:43:01 [INFO] [evolutionary_search.cc:723] Sampled 459 candidate(s)
2024-04-30 06:43:14 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 06:43:26 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 06:43:39 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 06:43:52 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 06:43:59 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	1.0005  0.9933  0.9727  0.9416  0.9380  0.9377  0.9358  0.9358  0.9358  0.9358  0.9358  0.9343  0.9303  0.9246  0.9143  0.9143
[17 : 32]:	0.9127  0.8977  0.8935  0.8935  0.8918  0.8895  0.8521  0.8521  0.8521  0.8486  0.8478  0.8478  0.8478  0.8478  0.8445  0.8422
[33 : 48]:	0.8418  0.8411  0.8388  0.8385  0.8381  0.8364  0.8338  0.8289  0.8281  0.8269  0.8215  0.8201  0.8195  0.8195  0.8195  0.8183
[49 : 64]:	0.8160  0.8159  0.8151  0.8141  0.8141  0.8128  0.8122  0.8111  0.8107  0.8098  0.8087  0.8087  0.8085  0.8069  0.8040  0.8040
2024-04-30 06:44:00 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-30 06:44:00 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-30 06:46:11 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #65: GFLOPs: 150.5610. Time: 24575.9480 us. Best GFLOPs: 150.5610
2024-04-30 06:46:11 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #66: GFLOPs: 129.1941. Time: 28640.4715 us. Best GFLOPs: 150.5610
2024-04-30 06:46:11 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #67: GFLOPs: 166.9184. Time: 22167.5942 us. Best GFLOPs: 166.9184
2024-04-30 06:46:11 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #68: GFLOPs: 98.4618. Time: 37579.8583 us. Best GFLOPs: 166.9184
2024-04-30 06:46:11 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #69: GFLOPs: 78.7617. Time: 46979.3980 us. Best GFLOPs: 166.9184
2024-04-30 06:46:11 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #70: GFLOPs: 241.2934. Time: 15334.7687 us. Best GFLOPs: 241.2934
2024-04-30 06:46:11 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #71: GFLOPs: 74.1652. Time: 49891.0450 us. Best GFLOPs: 241.2934
2024-04-30 06:46:11 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #72: GFLOPs: 160.9209. Time: 22993.7746 us. Best GFLOPs: 241.2934
2024-04-30 06:46:11 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #73: GFLOPs: 83.9234. Time: 44089.9347 us. Best GFLOPs: 241.2934
2024-04-30 06:46:11 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #74: GFLOPs: 72.4934. Time: 51041.6213 us. Best GFLOPs: 241.2934
2024-04-30 06:46:11 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #75: GFLOPs: 181.1901. Time: 20421.5262 us. Best GFLOPs: 241.2934
2024-04-30 06:46:11 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #76: GFLOPs: 97.9563. Time: 37773.7780 us. Best GFLOPs: 241.2934
2024-04-30 06:46:11 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #77: GFLOPs: 136.0119. Time: 27204.8167 us. Best GFLOPs: 241.2934
2024-04-30 06:46:11 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #78: GFLOPs: 49.8425. Time: 74237.5003 us. Best GFLOPs: 241.2934
2024-04-30 06:46:11 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #79: GFLOPs: 47.0330. Time: 78671.9773 us. Best GFLOPs: 241.2934
2024-04-30 06:46:11 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #80: GFLOPs: 123.9910. Time: 29842.3298 us. Best GFLOPs: 241.2934
2024-04-30 06:46:11 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #81: GFLOPs: 172.4836. Time: 21452.3520 us. Best GFLOPs: 241.2934
2024-04-30 06:46:11 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #82: GFLOPs: 55.5330. Time: 66630.2553 us. Best GFLOPs: 241.2934
2024-04-30 06:46:11 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #83: GFLOPs: 98.7631. Time: 37465.1797 us. Best GFLOPs: 241.2934
2024-04-30 06:46:11 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #84: GFLOPs: 92.4045. Time: 40043.2677 us. Best GFLOPs: 241.2934
2024-04-30 06:46:11 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #85: GFLOPs: 66.8098. Time: 55383.7500 us. Best GFLOPs: 241.2934
2024-04-30 06:46:11 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #86: GFLOPs: 76.9900. Time: 48060.4867 us. Best GFLOPs: 241.2934
2024-04-30 06:46:11 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #87: GFLOPs: 64.7168. Time: 57174.9013 us. Best GFLOPs: 241.2934
2024-04-30 06:46:11 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #88: GFLOPs: 75.5958. Time: 48946.8633 us. Best GFLOPs: 241.2934
2024-04-30 06:46:11 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #89: GFLOPs: 79.9768. Time: 46265.6270 us. Best GFLOPs: 241.2934
2024-04-30 06:46:11 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #90: GFLOPs: 152.8024. Time: 24215.4468 us. Best GFLOPs: 241.2934
2024-04-30 06:46:11 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #91: GFLOPs: 115.1199. Time: 32141.9507 us. Best GFLOPs: 241.2934
2024-04-30 06:46:11 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #92: GFLOPs: 117.7436. Time: 31425.7260 us. Best GFLOPs: 241.2934
2024-04-30 06:46:11 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #93: GFLOPs: 114.4795. Time: 32321.7515 us. Best GFLOPs: 241.2934
2024-04-30 06:46:11 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #94: GFLOPs: 102.3957. Time: 36136.0877 us. Best GFLOPs: 241.2934
2024-04-30 06:46:11 [INFO] [task_scheduler.cc:121] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #95: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(512)), "float32"), p1: T.Buffer((T.int64(32), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_fused_fused in T.parallel(T.int64(1568), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for oc_block_0, n_1, oc_chunk_1, oh_1 in T.grid(T.int64(1), T.int64(1), T.int64(2), T.int64(2)):
                for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4), T.int64(512)):
                    with T.block("data_pad"):
                        v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                        v_i2 = T.axis.spatial(T.int64(30), oh_1 * T.int64(2) + n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(98) // T.int64(14) * T.int64(4) + ax2)
                        v_i3 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(14) * T.int64(2) + ax3)
                        v_i4 = T.axis.spatial(T.int64(512), ax4)
                        T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                        T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                        data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                for ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1)):
                    for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(2)):
                        for oc_block_3_fused_init in T.vectorized(T.int64(4)):
                            with T.block("conv2d_NCHWc_init"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                                v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(98) * T.int64(2) + oc_chunk_1 + oc_chunk_2_init + oc_chunk_3_init)
                                v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(98) // T.int64(14) * T.int64(4) + oh_1 * T.int64(2) + oh_2_init + oh_3_init)
                                v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(14) * T.int64(2) + ow_1 * T.int64(2) + ow_2_init * T.int64(2) + ow_3_init)
                                v_oc_block = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2_init * T.int64(4) + oc_block_3_fused_init)
                                T.reads()
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                    for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(512), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(4), T.int64(1), T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(2)):
                        for oc_block_3_fused in T.vectorized(T.int64(4)):
                            with T.block("conv2d_NCHWc_update"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                                v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(98) * T.int64(2) + oc_chunk_1 + oc_chunk_2 + oc_chunk_3)
                                v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(98) // T.int64(14) * T.int64(4) + oh_1 * T.int64(2) + oh_2 + oh_3)
                                v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(14) * T.int64(2) + ow_1 * T.int64(2) + ow_2 * T.int64(2) + ow_3)
                                v_oc_block = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2 * T.int64(4) + oc_block_3_fused)
                                v_ic = T.axis.reduce(T.int64(512), ic_0 + ic_1)
                                v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                                v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                                T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
                    for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(1), T.int64(2)):
                        for ax3_ax4_fused in T.vectorized(T.int64(32)):
                            with T.block("T_relu"):
                                v_ax0 = T.axis.spatial(T.int64(1), ax0)
                                v_ax1 = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(98) * T.int64(2) + oc_chunk_1 + ax1)
                                v_ax2 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(98) // T.int64(14) * T.int64(4) + oh_1 * T.int64(2) + ax2)
                                v_ax3 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(14) * T.int64(2) + ax3_ax4_fused // T.int64(16))
                                v_ax4 = T.axis.spatial(T.int64(16), ax3_ax4_fused % T.int64(16))
                                T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                                T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                                T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[16, 2, 1, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[7, 2, 2, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[14, 1, 1, 2])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 4, 4])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[512, 1])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=7)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83 = sch.get_loops(block=b68)
l84 = sch.fuse(l71, l72, l73, l74, preserve_unit_iters=True)
sch.parallel(loop=l84)
l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107 = sch.get_loops(block=b69)
l108 = sch.fuse(l85, preserve_unit_iters=True)
sch.parallel(loop=l108)
l109 = sch.fuse(l107, preserve_unit_iters=True)
sch.vectorize(loop=l109)
sch.annotate(block_or_loop=l108, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l108, ann_key="pragma_unroll_explicit", ann_val=1)
l110, l111, l112, l113, l114, l115, l116, l117, l118, l119, l120, l121 = sch.get_loops(block=b70)
l122 = sch.fuse(l120, l121, preserve_unit_iters=True)
sch.vectorize(loop=l122)
b123 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141, l142, l143, l144, l145, l146 = sch.get_loops(block=b123)
b147 = sch.decompose_reduction(block=b123, loop=l131)
2024-04-30 06:46:11 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #96: GFLOPs: 20.8785. Time: 177224.3153 us. Best GFLOPs: 241.2934
2024-04-30 06:46:11 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #97: GFLOPs: 122.9281. Time: 30100.3405 us. Best GFLOPs: 241.2934
2024-04-30 06:46:11 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #98: GFLOPs: 123.2881. Time: 30012.4515 us. Best GFLOPs: 241.2934
2024-04-30 06:46:11 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #99: GFLOPs: 22.7454. Time: 162677.7893 us. Best GFLOPs: 241.2934
2024-04-30 06:46:11 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #100: GFLOPs: 147.1760. Time: 25141.1918 us. Best GFLOPs: 241.2934
2024-04-30 06:46:11 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #101: GFLOPs: 111.8672. Time: 33076.5445 us. Best GFLOPs: 241.2934
2024-04-30 06:46:11 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #102: GFLOPs: 96.1002. Time: 38503.3353 us. Best GFLOPs: 241.2934
2024-04-30 06:46:11 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #103: GFLOPs: 134.3065. Time: 27550.2635 us. Best GFLOPs: 241.2934
2024-04-30 06:46:11 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #104: GFLOPs: 73.3370. Time: 50454.4863 us. Best GFLOPs: 241.2934
2024-04-30 06:46:11 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #105: GFLOPs: 106.8353. Time: 34634.4183 us. Best GFLOPs: 241.2934
2024-04-30 06:46:11 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #106: GFLOPs: 73.6237. Time: 50257.9630 us. Best GFLOPs: 241.2934
2024-04-30 06:46:11 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #107: GFLOPs: 116.5602. Time: 31744.7865 us. Best GFLOPs: 241.2934
2024-04-30 06:46:11 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #108: GFLOPs: 21.3151. Time: 173594.3123 us. Best GFLOPs: 241.2934
2024-04-30 06:46:11 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #109: GFLOPs: 58.1758. Time: 63603.3617 us. Best GFLOPs: 241.2934
2024-04-30 06:46:11 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #110: GFLOPs: 65.2761. Time: 56685.0147 us. Best GFLOPs: 241.2934
2024-04-30 06:46:11 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #111: GFLOPs: 63.7981. Time: 57998.2640 us. Best GFLOPs: 241.2934
2024-04-30 06:46:11 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #112: GFLOPs: 134.6095. Time: 27488.2550 us. Best GFLOPs: 241.2934
2024-04-30 06:46:11 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #113: GFLOPs: 101.2623. Time: 36540.5550 us. Best GFLOPs: 241.2934
2024-04-30 06:46:11 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #114: GFLOPs: 58.0712. Time: 63717.9903 us. Best GFLOPs: 241.2934
2024-04-30 06:46:11 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #115: GFLOPs: 115.9929. Time: 31900.0390 us. Best GFLOPs: 241.2934
2024-04-30 06:46:11 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #116: GFLOPs: 52.2737. Time: 70784.7463 us. Best GFLOPs: 241.2934
2024-04-30 06:46:11 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #117: GFLOPs: 52.3526. Time: 70678.0777 us. Best GFLOPs: 241.2934
2024-04-30 06:46:11 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #118: GFLOPs: 39.9047. Time: 92725.4743 us. Best GFLOPs: 241.2934
2024-04-30 06:46:11 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #119: GFLOPs: 121.3888. Time: 30482.0395 us. Best GFLOPs: 241.2934
2024-04-30 06:46:11 [INFO] [task_scheduler.cc:121] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #120: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(512)), "float32"), p1: T.Buffer((T.int64(32), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_fused_fused in T.parallel(T.int64(98), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(6), T.int64(4), T.int64(512)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(14) * T.int64(4) + ax2)
                    v_i3 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(14) * T.int64(2) + ax3)
                    v_i4 = T.axis.spatial(T.int64(512), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oc_block_0, n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(4), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(2), T.int64(4), T.int64(1)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(16)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(32), oc_chunk_1 * T.int64(8) + oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(14) * T.int64(4) + oh_1 * T.int64(4) + oh_2_init * T.int64(4) + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(14) * T.int64(2) + ow_1 * T.int64(2) + ow_2_init + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2_init * T.int64(16) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(64), T.int64(3), T.int64(3), T.int64(1), T.int64(4), T.int64(1), T.int64(2), T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(4), T.int64(1)):
                    for oc_block_3_fused in T.vectorized(T.int64(16)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(32), oc_chunk_1 * T.int64(8) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(14) * T.int64(4) + oh_1 * T.int64(4) + oh_2 * T.int64(4) + oh_3)
                            v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(14) * T.int64(2) + ow_1 * T.int64(2) + ow_2 + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2 * T.int64(16) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(8) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
                for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(8), T.int64(4)):
                    for ax3_ax4_fused in T.vectorized(T.int64(32)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(32), oc_chunk_1 * T.int64(8) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(14) * T.int64(4) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(14) * T.int64(2) + ax3_ax4_fused // T.int64(16))
                            v_ax4 = T.axis.spatial(T.int64(16), ax3_ax4_fused % T.int64(16))
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 4, 4, 2])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[7, 1, 1, 4])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[14, 1, 2, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 1, 16])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[64, 8])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=3)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79 = sch.get_loops(block=b68)
l80 = sch.fuse(l71, l72, l73, l74, preserve_unit_iters=True)
sch.parallel(loop=l80)
l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l81, preserve_unit_iters=True)
sch.parallel(loop=l104)
l105 = sch.fuse(l103, preserve_unit_iters=True)
sch.vectorize(loop=l105)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l106, l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117 = sch.get_loops(block=b70)
l118 = sch.fuse(l116, l117, preserve_unit_iters=True)
sch.vectorize(loop=l118)
b119 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141, l142 = sch.get_loops(block=b119)
b143 = sch.decompose_reduction(block=b119, loop=l127)
2024-04-30 06:46:11 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #121: GFLOPs: 47.7250. Time: 77531.1937 us. Best GFLOPs: 241.2934
2024-04-30 06:46:11 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #122: GFLOPs: 68.7945. Time: 53786.0043 us. Best GFLOPs: 241.2934
2024-04-30 06:46:11 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #123: GFLOPs: 139.9330. Time: 26442.5120 us. Best GFLOPs: 241.2934
2024-04-30 06:46:11 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #124: GFLOPs: 106.9563. Time: 34595.2407 us. Best GFLOPs: 241.2934
2024-04-30 06:46:11 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #125: GFLOPs: 97.2108. Time: 38063.4413 us. Best GFLOPs: 241.2934
2024-04-30 06:46:11 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #126: GFLOPs: 3.0684. Time: 1205906.5413 us. Best GFLOPs: 241.2934
2024-04-30 06:46:11 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #127: GFLOPs: 16.1495. Time: 229120.8570 us. Best GFLOPs: 241.2934
2024-04-30 06:46:11 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #128: GFLOPs: 25.7658. Time: 143608.0337 us. Best GFLOPs: 241.2934
2024-04-30 06:49:15 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-30 06:49:16 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-30 06:49:21 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 06:49:21 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-30 06:49:34 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 06:49:46 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 06:49:59 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 06:50:12 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 06:50:20 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9697  0.9610  0.9293  0.8207  0.7761  0.7225  0.7152  0.7086  0.7029  0.7006  0.6999  0.6925  0.6920  0.6918  0.6910  0.6910
[17 : 32]:	0.6892  0.6874  0.6874  0.6813  0.6812  0.6772  0.6762  0.6746  0.6624  0.6547  0.6547  0.6535  0.6535  0.6514  0.6507  0.6413
[33 : 48]:	0.6413  0.6401  0.6393  0.6388  0.6357  0.6344  0.6334  0.6263  0.6259  0.6246  0.6213  0.6211  0.6211  0.6194  0.6194  0.6193
[49 : 64]:	0.6193  0.6191  0.6186  0.6131  0.6112  0.6102  0.6092  0.6073  0.6071  0.6071  0.6034  0.6032  0.6020  0.6005  0.6001  0.6001
2024-04-30 06:50:20 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-30 06:50:20 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-30 06:52:20 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #129: GFLOPs: 246.8656. Time: 14988.6356 us. Best GFLOPs: 246.8656
2024-04-30 06:52:20 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #130: GFLOPs: 186.9480. Time: 19792.5580 us. Best GFLOPs: 246.8656
2024-04-30 06:52:20 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #131: GFLOPs: 240.2363. Time: 15402.2470 us. Best GFLOPs: 246.8656
2024-04-30 06:52:20 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #132: GFLOPs: 220.6732. Time: 16767.6857 us. Best GFLOPs: 246.8656
2024-04-30 06:52:20 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #133: GFLOPs: 169.2663. Time: 21860.1028 us. Best GFLOPs: 246.8656
2024-04-30 06:52:20 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #134: GFLOPs: 196.9182. Time: 18790.4357 us. Best GFLOPs: 246.8656
2024-04-30 06:52:20 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #135: GFLOPs: 214.6164. Time: 17240.8972 us. Best GFLOPs: 246.8656
2024-04-30 06:52:20 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #136: GFLOPs: 134.9799. Time: 27412.8077 us. Best GFLOPs: 246.8656
2024-04-30 06:52:20 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #137: GFLOPs: 209.3528. Time: 17674.3730 us. Best GFLOPs: 246.8656
2024-04-30 06:52:20 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #138: GFLOPs: 125.8827. Time: 29393.8597 us. Best GFLOPs: 246.8656
2024-04-30 06:52:20 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #139: GFLOPs: 92.9198. Time: 39821.2070 us. Best GFLOPs: 246.8656
2024-04-30 06:52:20 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #140: GFLOPs: 204.0739. Time: 18131.5625 us. Best GFLOPs: 246.8656
2024-04-30 06:52:20 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #141: GFLOPs: 131.7530. Time: 28084.2092 us. Best GFLOPs: 246.8656
2024-04-30 06:52:20 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #142: GFLOPs: 96.8613. Time: 38200.7887 us. Best GFLOPs: 246.8656
2024-04-30 06:52:20 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #143: GFLOPs: 83.4191. Time: 44356.4757 us. Best GFLOPs: 246.8656
2024-04-30 06:52:20 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #144: GFLOPs: 86.9001. Time: 42579.6680 us. Best GFLOPs: 246.8656
2024-04-30 06:52:20 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #145: GFLOPs: 153.3802. Time: 24124.2342 us. Best GFLOPs: 246.8656
2024-04-30 06:52:20 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #146: GFLOPs: 84.7717. Time: 43648.7733 us. Best GFLOPs: 246.8656
2024-04-30 06:52:20 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #147: GFLOPs: 54.6326. Time: 67728.4373 us. Best GFLOPs: 246.8656
2024-04-30 06:52:20 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #148: GFLOPs: 73.3037. Time: 50477.3517 us. Best GFLOPs: 246.8656
2024-04-30 06:52:20 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #149: GFLOPs: 97.3335. Time: 38015.4890 us. Best GFLOPs: 246.8656
2024-04-30 06:52:20 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #150: GFLOPs: 153.5944. Time: 24090.5916 us. Best GFLOPs: 246.8656
2024-04-30 06:52:20 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #151: GFLOPs: 204.6079. Time: 18084.2385 us. Best GFLOPs: 246.8656
2024-04-30 06:52:20 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #152: GFLOPs: 195.4172. Time: 18934.7698 us. Best GFLOPs: 246.8656
2024-04-30 06:52:20 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #153: GFLOPs: 74.1893. Time: 49874.8198 us. Best GFLOPs: 246.8656
2024-04-30 06:52:20 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #154: GFLOPs: 89.2721. Time: 41448.3253 us. Best GFLOPs: 246.8656
2024-04-30 06:52:21 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #155: GFLOPs: 100.3866. Time: 36859.2790 us. Best GFLOPs: 246.8656
2024-04-30 06:52:21 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #156: GFLOPs: 104.9920. Time: 35242.4743 us. Best GFLOPs: 246.8656
2024-04-30 06:52:21 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #157: GFLOPs: 103.0776. Time: 35897.0390 us. Best GFLOPs: 246.8656
2024-04-30 06:52:21 [INFO] [task_scheduler.cc:121] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #158: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(512)), "float32"), p1: T.Buffer((T.int64(32), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused in T.parallel(T.int64(112), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(4), T.int64(2), T.int64(2), T.int64(1), T.int64(1), T.int64(2), T.int64(2), T.int64(7)):
                for oc_block_3_fused_init in T.vectorized(T.int64(8)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(28) * T.int64(8) + oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(14) // T.int64(2) * T.int64(4) + oh_2_init * T.int64(2) + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(2) * T.int64(14) + ow_2_init * T.int64(7) + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(28) // T.int64(14) * T.int64(8) + oc_block_2_init * T.int64(8) + oc_block_3_fused_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
            for ic_0 in range(T.int64(128)):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(6), T.int64(16)):
                    for ax4_fused in T.vectorized(T.int64(4)):
                        with T.block("data_pad"):
                            v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                            v_i2 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(14) // T.int64(2) * T.int64(4) + ax2)
                            v_i3 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(2) * T.int64(14) + ax3)
                            v_i4 = T.axis.spatial(T.int64(512), ic_0 * T.int64(4) + ax4_fused)
                            T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                            T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                            data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                for kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(3), T.int64(3), T.int64(1), T.int64(4), T.int64(2), T.int64(2), T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(2), T.int64(7)):
                    for oc_block_3_fused in T.vectorized(T.int64(8)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(28) * T.int64(8) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(14) // T.int64(2) * T.int64(4) + oh_2 * T.int64(2) + oh_3)
                            v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(2) * T.int64(14) + ow_2 * T.int64(7) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(28) // T.int64(14) * T.int64(8) + oc_block_2 * T.int64(8) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(4) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(8), T.int64(4), T.int64(14)):
                for ax4_fused in T.vectorized(T.int64(8)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(28) * T.int64(8) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(14) // T.int64(2) * T.int64(4) + ax2)
                        v_ax3 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(2) * T.int64(14) + ax3)
                        v_ax4 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(28) // T.int64(14) * T.int64(8) + ax4_fused)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[4, 1, 4, 2])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 7, 2, 2])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 2, 2, 7])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[2, 1, 1, 8])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[128, 4])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=10)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86 = sch.get_loops(block=b68)
l87 = sch.fuse(l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, preserve_unit_iters=True)
sch.parallel(loop=l87)
l88 = sch.fuse(l86, preserve_unit_iters=True)
sch.vectorize(loop=l88)
l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105 = sch.get_loops(block=b69)
l106 = sch.fuse(l89, preserve_unit_iters=True)
sch.parallel(loop=l106)
l107 = sch.fuse(l105, preserve_unit_iters=True)
sch.vectorize(loop=l107)
sch.annotate(block_or_loop=l106, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l106, ann_key="pragma_unroll_explicit", ann_val=1)
l108, l109, l110, l111, l112, l113 = sch.get_loops(block=b70)
l114 = sch.fuse(l113, preserve_unit_iters=True)
sch.vectorize(loop=l114)
b115 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132 = sch.get_loops(block=b115)
b133 = sch.decompose_reduction(block=b115, loop=l117)
2024-04-30 06:52:21 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #159: GFLOPs: 170.1897. Time: 21741.4970 us. Best GFLOPs: 246.8656
2024-04-30 06:52:21 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #160: GFLOPs: 153.2429. Time: 24145.8406 us. Best GFLOPs: 246.8656
2024-04-30 06:52:21 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #161: GFLOPs: 113.2310. Time: 32678.1490 us. Best GFLOPs: 246.8656
2024-04-30 06:52:21 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #162: GFLOPs: 170.3522. Time: 21720.7624 us. Best GFLOPs: 246.8656
2024-04-30 06:52:21 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #163: GFLOPs: 121.8683. Time: 30362.1237 us. Best GFLOPs: 246.8656
2024-04-30 06:52:21 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #164: GFLOPs: 238.1851. Time: 15534.8907 us. Best GFLOPs: 246.8656
2024-04-30 06:52:21 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #165: GFLOPs: 107.5599. Time: 34401.0893 us. Best GFLOPs: 246.8656
2024-04-30 06:52:21 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #166: GFLOPs: 109.9396. Time: 33656.4700 us. Best GFLOPs: 246.8656
2024-04-30 06:52:21 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #167: GFLOPs: 60.4769. Time: 61183.3040 us. Best GFLOPs: 246.8656
2024-04-30 06:52:21 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #168: GFLOPs: 47.9764. Time: 77124.9433 us. Best GFLOPs: 246.8656
2024-04-30 06:52:21 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #169: GFLOPs: 155.0925. Time: 23857.8836 us. Best GFLOPs: 246.8656
2024-04-30 06:52:21 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #170: GFLOPs: 107.0370. Time: 34569.1560 us. Best GFLOPs: 246.8656
2024-04-30 06:52:21 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #171: GFLOPs: 185.8373. Time: 19910.8568 us. Best GFLOPs: 246.8656
2024-04-30 06:52:21 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #172: GFLOPs: 173.9146. Time: 21275.8328 us. Best GFLOPs: 246.8656
2024-04-30 06:52:21 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #173: GFLOPs: 188.1713. Time: 19663.8858 us. Best GFLOPs: 246.8656
2024-04-30 06:52:21 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #174: GFLOPs: 206.6867. Time: 17902.3587 us. Best GFLOPs: 246.8656
2024-04-30 06:52:21 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #175: GFLOPs: 142.7301. Time: 25924.3020 us. Best GFLOPs: 246.8656
2024-04-30 06:52:21 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #176: GFLOPs: 144.8273. Time: 25548.8978 us. Best GFLOPs: 246.8656
2024-04-30 06:52:21 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #177: GFLOPs: 116.1378. Time: 31860.2598 us. Best GFLOPs: 246.8656
2024-04-30 06:52:21 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #178: GFLOPs: 153.3724. Time: 24125.4522 us. Best GFLOPs: 246.8656
2024-04-30 06:52:21 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #179: GFLOPs: 470.8466. Time: 7858.5655 us. Best GFLOPs: 470.8466
2024-04-30 06:52:21 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #180: GFLOPs: 89.4984. Time: 41343.5197 us. Best GFLOPs: 470.8466
2024-04-30 06:52:21 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #181: GFLOPs: 68.9707. Time: 53648.5933 us. Best GFLOPs: 470.8466
2024-04-30 06:52:21 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #182: GFLOPs: 205.4292. Time: 18011.9455 us. Best GFLOPs: 470.8466
2024-04-30 06:52:21 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #183: GFLOPs: 163.7290. Time: 22599.4076 us. Best GFLOPs: 470.8466
2024-04-30 06:52:21 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #184: GFLOPs: 114.2477. Time: 32387.3387 us. Best GFLOPs: 470.8466
2024-04-30 06:52:21 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #185: GFLOPs: 108.8438. Time: 33995.3093 us. Best GFLOPs: 470.8466
2024-04-30 06:52:21 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #186: GFLOPs: 85.1739. Time: 43442.6180 us. Best GFLOPs: 470.8466
2024-04-30 06:52:21 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #187: GFLOPs: 94.3510. Time: 39217.1630 us. Best GFLOPs: 470.8466
2024-04-30 06:52:21 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #188: GFLOPs: 96.7382. Time: 38249.4163 us. Best GFLOPs: 470.8466
2024-04-30 06:52:21 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #189: GFLOPs: 102.4977. Time: 36100.1090 us. Best GFLOPs: 470.8466
2024-04-30 06:52:21 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #190: GFLOPs: 37.3820. Time: 98982.8257 us. Best GFLOPs: 470.8466
2024-04-30 06:52:21 [INFO] [task_scheduler.cc:121] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #191: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(512)), "float32"), p1: T.Buffer((T.int64(32), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused in T.parallel(T.int64(224), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(4), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(28)):
                for oc_block_3_fused_init in T.vectorized(T.int64(4)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(28) * T.int64(4) + oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(14) // T.int64(2) * T.int64(4) + oh_2_init * T.int64(2) + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(28), ow_2_init * T.int64(28) + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(28) // T.int64(14) * T.int64(8) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(2) * T.int64(4) + oc_block_2_init * T.int64(4) + oc_block_3_fused_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
            for ic_0 in range(T.int64(16)):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(6), T.int64(30)):
                    for ax4_fused in T.vectorized(T.int64(32)):
                        with T.block("data_pad"):
                            v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                            v_i2 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(14) // T.int64(2) * T.int64(4) + ax2)
                            v_i3 = T.axis.spatial(T.int64(30), ax3)
                            v_i4 = T.axis.spatial(T.int64(512), ic_0 * T.int64(32) + ax4_fused)
                            T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                            T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                            data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                for kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(2), T.int64(1), T.int64(1), T.int64(32), T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(2), T.int64(28)):
                    for oc_block_3_fused in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(28) * T.int64(4) + oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(14) // T.int64(2) * T.int64(4) + oh_2 * T.int64(2) + oh_3)
                            v_ow = T.axis.spatial(T.int64(28), ow_2 * T.int64(28) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(28) // T.int64(14) * T.int64(8) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(2) * T.int64(4) + oc_block_2 * T.int64(4) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(32) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
        for ax0_ax1_ax2_ax3_ax4_fused_0 in T.parallel(T.int64(6272)):
            for ax0_ax1_ax2_ax3_ax4_fused_1 in T.vectorized(T.int64(64)):
                with T.block("T_relu"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) // T.int64(12544))
                    v_ax2 = T.axis.spatial(T.int64(28), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(12544) // T.int64(448))
                    v_ax3 = T.axis.spatial(T.int64(28), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(448) // T.int64(16))
                    v_ax4 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(16))
                    T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                    T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[8, 1, 4, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 7, 2, 2])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 1, 28])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[2, 2, 1, 4])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[16, 32])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
l65 = sch.sample_compute_location(block=b0, decision=10)
sch.compute_at(block=b0, loop=l65, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b66 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.unroll_explicit")
b67, b68, b69 = sch.get_child_blocks(b66)
l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85 = sch.get_loops(block=b67)
l86 = sch.fuse(l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, preserve_unit_iters=True)
sch.parallel(loop=l86)
l87 = sch.fuse(l85, preserve_unit_iters=True)
sch.vectorize(loop=l87)
l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b68)
l105 = sch.fuse(l88, preserve_unit_iters=True)
sch.parallel(loop=l105)
l106 = sch.fuse(l104, preserve_unit_iters=True)
sch.vectorize(loop=l106)
sch.annotate(block_or_loop=l105, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l105, ann_key="pragma_unroll_explicit", ann_val=1)
l107, l108, l109, l110, l111 = sch.get_loops(block=b69)
l112 = sch.fuse(l107, l108, l109, l110, l111, preserve_unit_iters=True)
l113, l114 = sch.split(loop=l112, factors=[None, 64], preserve_unit_iters=True)
sch.parallel(loop=l113)
sch.vectorize(loop=l114)
b115 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132 = sch.get_loops(block=b115)
b133 = sch.decompose_reduction(block=b115, loop=l117)
2024-04-30 06:52:21 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #192: GFLOPs: 3.7212. Time: 994355.5790 us. Best GFLOPs: 470.8466
2024-04-30 07:07:41 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-30 07:07:42 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-30 07:07:47 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 07:07:47 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-30 07:07:59 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 07:08:13 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 07:08:27 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 07:08:41 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 07:08:49 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9777  0.8938  0.8845  0.8599  0.8515  0.8353  0.8345  0.8343  0.8280  0.8277  0.8059  0.8020  0.7906  0.7782  0.7782  0.7489
[17 : 32]:	0.7267  0.7219  0.7143  0.7022  0.6910  0.6910  0.6873  0.6842  0.6774  0.6696  0.6675  0.6649  0.6626  0.6476  0.6418  0.6415
[33 : 48]:	0.6362  0.6320  0.6248  0.6195  0.6082  0.6014  0.6013  0.6011  0.6003  0.5891  0.5888  0.5860  0.5860  0.5816  0.5641  0.5617
[49 : 64]:	0.5560  0.5550  0.5483  0.5458  0.5356  0.5356  0.5297  0.5183  0.5143  0.5108  0.5107  0.5100  0.5095  0.5092  0.5089  0.5061
2024-04-30 07:08:50 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-30 07:08:50 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-30 07:11:24 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #193: GFLOPs: 401.3503. Time: 9219.3248 us. Best GFLOPs: 470.8466
2024-04-30 07:11:24 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #194: GFLOPs: 336.5114. Time: 10995.7021 us. Best GFLOPs: 470.8466
2024-04-30 07:11:24 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #195: GFLOPs: 360.7208. Time: 10257.7363 us. Best GFLOPs: 470.8466
2024-04-30 07:11:24 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #196: GFLOPs: 352.8289. Time: 10487.1754 us. Best GFLOPs: 470.8466
2024-04-30 07:11:24 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #197: GFLOPs: 486.5515. Time: 7604.9071 us. Best GFLOPs: 486.5515
2024-04-30 07:11:24 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #198: GFLOPs: 337.5552. Time: 10961.7015 us. Best GFLOPs: 486.5515
2024-04-30 07:11:24 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #199: GFLOPs: 317.4084. Time: 11657.4714 us. Best GFLOPs: 486.5515
2024-04-30 07:11:24 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #200: GFLOPs: 53.1792. Time: 69579.4223 us. Best GFLOPs: 486.5515
2024-04-30 07:11:24 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #201: GFLOPs: 114.6125. Time: 32284.2480 us. Best GFLOPs: 486.5515
2024-04-30 07:11:24 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #202: GFLOPs: 80.6868. Time: 45858.5493 us. Best GFLOPs: 486.5515
2024-04-30 07:11:24 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #203: GFLOPs: 54.0801. Time: 68420.2860 us. Best GFLOPs: 486.5515
2024-04-30 07:11:24 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #204: GFLOPs: 105.4159. Time: 35100.7767 us. Best GFLOPs: 486.5515
2024-04-30 07:11:24 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #205: GFLOPs: 513.6255. Time: 7204.0409 us. Best GFLOPs: 513.6255
2024-04-30 07:11:24 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #206: GFLOPs: 103.1654. Time: 35866.4630 us. Best GFLOPs: 513.6255
2024-04-30 07:11:24 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #207: GFLOPs: 101.3772. Time: 36499.1140 us. Best GFLOPs: 513.6255
2024-04-30 07:11:24 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #208: GFLOPs: 37.6637. Time: 98242.5010 us. Best GFLOPs: 513.6255
2024-04-30 07:11:24 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #209: GFLOPs: 407.3216. Time: 9084.1712 us. Best GFLOPs: 513.6255
2024-04-30 07:11:24 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #210: GFLOPs: 192.4768. Time: 19224.0222 us. Best GFLOPs: 513.6255
2024-04-30 07:11:24 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #211: GFLOPs: 508.5275. Time: 7276.2614 us. Best GFLOPs: 513.6255
2024-04-30 07:11:24 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #212: GFLOPs: 64.6161. Time: 57263.9997 us. Best GFLOPs: 513.6255
2024-04-30 07:11:24 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #213: GFLOPs: 50.3800. Time: 73445.3793 us. Best GFLOPs: 513.6255
2024-04-30 07:11:24 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #214: GFLOPs: 49.2746. Time: 75093.0677 us. Best GFLOPs: 513.6255
2024-04-30 07:11:24 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #215: GFLOPs: 339.7412. Time: 10891.1683 us. Best GFLOPs: 513.6255
2024-04-30 07:11:24 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #216: GFLOPs: 83.8575. Time: 44124.5990 us. Best GFLOPs: 513.6255
2024-04-30 07:11:24 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #217: GFLOPs: 183.4454. Time: 20170.4606 us. Best GFLOPs: 513.6255
2024-04-30 07:11:24 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #218: GFLOPs: 10.0729. Time: 367339.3550 us. Best GFLOPs: 513.6255
2024-04-30 07:11:24 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #219: GFLOPs: 371.7252. Time: 9954.0720 us. Best GFLOPs: 513.6255
2024-04-30 07:11:24 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #220: GFLOPs: 58.6672. Time: 63070.6100 us. Best GFLOPs: 513.6255
2024-04-30 07:11:24 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #221: GFLOPs: 64.2551. Time: 57585.7583 us. Best GFLOPs: 513.6255
2024-04-30 07:11:24 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #222: GFLOPs: 353.6510. Time: 10462.7978 us. Best GFLOPs: 513.6255
2024-04-30 07:11:24 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #223: GFLOPs: 122.5659. Time: 30189.3043 us. Best GFLOPs: 513.6255
2024-04-30 07:11:24 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #224: GFLOPs: 54.0182. Time: 68498.7570 us. Best GFLOPs: 513.6255
2024-04-30 07:11:24 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #225: GFLOPs: 52.7858. Time: 70098.0480 us. Best GFLOPs: 513.6255
2024-04-30 07:11:24 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #226: GFLOPs: 75.8660. Time: 48772.5693 us. Best GFLOPs: 513.6255
2024-04-30 07:11:24 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #227: GFLOPs: 94.8185. Time: 39023.8080 us. Best GFLOPs: 513.6255
2024-04-30 07:11:24 [INFO] [task_scheduler.cc:121] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #228: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(512)), "float32"), p1: T.Buffer((T.int64(32), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_fused_fused in T.parallel(T.int64(112), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(6), T.int64(30), T.int64(512)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_fused_fused % T.int64(7) * T.int64(4) + ax2)
                    v_i3, v_i4 = T.axis.remap("SS", [ax3, ax4])
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for ow_0, oc_block_0, n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(2)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(28), T.int64(1), T.int64(1), T.int64(2), T.int64(2), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_fused_fused // T.int64(7) * T.int64(2) + oc_chunk_1 * T.int64(2) + oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_fused_fused % T.int64(7) * T.int64(4) + oh_1 * T.int64(2) + oh_2_init * T.int64(2) + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(28), ow_0 * T.int64(28) + ow_1 * T.int64(28) + ow_2_init + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(2) + oc_block_1 + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(32), T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(28), T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(2), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_fused_fused // T.int64(7) * T.int64(2) + oc_chunk_1 * T.int64(2) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_fused_fused % T.int64(7) * T.int64(4) + oh_1 * T.int64(2) + oh_2 * T.int64(2) + oh_3)
                        v_ow = T.axis.spatial(T.int64(28), ow_0 * T.int64(28) + ow_1 * T.int64(28) + ow_2 + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(2) + oc_block_1 + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(16) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
                for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(2), T.int64(2), T.int64(28), T.int64(1)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_fused_fused // T.int64(7) * T.int64(2) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_fused_fused % T.int64(7) * T.int64(4) + oh_1 * T.int64(2) + ax2)
                        v_ax3 = T.axis.spatial(T.int64(28), ax3)
                        v_ax4 = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(2) + oc_block_1 + ax4)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[16, 1, 1, 2])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[7, 2, 1, 2])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 28, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[8, 2, 1, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[32, 16])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=2)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78 = sch.get_loops(block=b68)
l79 = sch.fuse(l71, l72, l73, preserve_unit_iters=True)
sch.parallel(loop=l79)
l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l80, preserve_unit_iters=True)
sch.parallel(loop=l104)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117 = sch.get_loops(block=b70)
b118 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141, l142 = sch.get_loops(block=b118)
b143 = sch.decompose_reduction(block=b118, loop=l127)
2024-04-30 07:11:24 [INFO] [task_scheduler.cc:121] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #229: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(512)), "float32"), p1: T.Buffer((T.int64(32), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_fused_fused in T.parallel(T.int64(112), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(6), T.int64(30), T.int64(512)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_fused_fused % T.int64(7) * T.int64(4) + ax2)
                    v_i3, v_i4 = T.axis.remap("SS", [ax3, ax4])
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for ow_0, oc_block_0, n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(8)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(28), T.int64(1), T.int64(1), T.int64(2), T.int64(2), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_fused_fused // T.int64(7) * T.int64(2) + oc_chunk_1 * T.int64(2) + oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_fused_fused % T.int64(7) * T.int64(4) + oh_1 * T.int64(2) + oh_2_init * T.int64(2) + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(28), ow_0 * T.int64(28) + ow_1 * T.int64(28) + ow_2_init + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(8) + oc_block_1 + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(32), T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(28), T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(2), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_fused_fused // T.int64(7) * T.int64(2) + oc_chunk_1 * T.int64(2) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_fused_fused % T.int64(7) * T.int64(4) + oh_1 * T.int64(2) + oh_2 * T.int64(2) + oh_3)
                        v_ow = T.axis.spatial(T.int64(28), ow_0 * T.int64(28) + ow_1 * T.int64(28) + ow_2 + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(8) + oc_block_1 + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(16) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
                for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(2), T.int64(2), T.int64(28), T.int64(1)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_fused_fused // T.int64(7) * T.int64(2) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_fused_fused % T.int64(7) * T.int64(4) + oh_1 * T.int64(2) + ax2)
                        v_ax3 = T.axis.spatial(T.int64(28), ax3)
                        v_ax4 = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(8) + oc_block_1 + ax4)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[16, 1, 1, 2])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[7, 2, 1, 2])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 28, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[2, 8, 1, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[32, 16])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=2)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78 = sch.get_loops(block=b68)
l79 = sch.fuse(l71, l72, l73, preserve_unit_iters=True)
sch.parallel(loop=l79)
l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l80, preserve_unit_iters=True)
sch.parallel(loop=l104)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117 = sch.get_loops(block=b70)
b118 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141, l142 = sch.get_loops(block=b118)
b143 = sch.decompose_reduction(block=b118, loop=l127)
2024-04-30 07:11:24 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #230: GFLOPs: 91.6191. Time: 40386.5447 us. Best GFLOPs: 513.6255
2024-04-30 07:11:24 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #231: GFLOPs: 54.1932. Time: 68277.5767 us. Best GFLOPs: 513.6255
2024-04-30 07:11:24 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #232: GFLOPs: 152.8161. Time: 24213.2766 us. Best GFLOPs: 513.6255
2024-04-30 07:11:24 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #233: GFLOPs: 286.2311. Time: 12927.2434 us. Best GFLOPs: 513.6255
2024-04-30 07:11:24 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #234: GFLOPs: 64.9618. Time: 56959.3047 us. Best GFLOPs: 513.6255
2024-04-30 07:11:24 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #235: GFLOPs: 67.1304. Time: 55119.2960 us. Best GFLOPs: 513.6255
2024-04-30 07:11:24 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #236: GFLOPs: 8.4447. Time: 438167.0460 us. Best GFLOPs: 513.6255
2024-04-30 07:11:24 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #237: GFLOPs: 448.0691. Time: 8258.0543 us. Best GFLOPs: 513.6255
2024-04-30 07:11:24 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #238: GFLOPs: 522.8990. Time: 7076.2789 us. Best GFLOPs: 522.8990
2024-04-30 07:11:24 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #239: GFLOPs: 45.7875. Time: 80811.9800 us. Best GFLOPs: 522.8990
2024-04-30 07:11:24 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #240: GFLOPs: 43.4632. Time: 85133.6447 us. Best GFLOPs: 522.8990
2024-04-30 07:11:24 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #241: GFLOPs: 43.3285. Time: 85398.3127 us. Best GFLOPs: 522.8990
2024-04-30 07:11:24 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #242: GFLOPs: 98.7657. Time: 37464.2207 us. Best GFLOPs: 522.8990
2024-04-30 07:11:24 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #243: GFLOPs: 58.1134. Time: 63671.6903 us. Best GFLOPs: 522.8990
2024-04-30 07:11:24 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #244: GFLOPs: 103.0850. Time: 35894.4337 us. Best GFLOPs: 522.8990
2024-04-30 07:11:24 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #245: GFLOPs: 8.3813. Time: 441479.5800 us. Best GFLOPs: 522.8990
2024-04-30 07:11:24 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #246: GFLOPs: 43.2171. Time: 85618.3363 us. Best GFLOPs: 522.8990
2024-04-30 07:11:24 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #247: GFLOPs: 103.2087. Time: 35851.4097 us. Best GFLOPs: 522.8990
2024-04-30 07:11:24 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #248: GFLOPs: 223.5687. Time: 16550.5204 us. Best GFLOPs: 522.8990
2024-04-30 07:11:24 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #249: GFLOPs: 193.5941. Time: 19113.0787 us. Best GFLOPs: 522.8990
2024-04-30 07:11:24 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #250: GFLOPs: 206.3930. Time: 17927.8282 us. Best GFLOPs: 522.8990
2024-04-30 07:11:24 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #251: GFLOPs: 159.2284. Time: 23238.1796 us. Best GFLOPs: 522.8990
2024-04-30 07:11:24 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #252: GFLOPs: 251.7050. Time: 14700.4574 us. Best GFLOPs: 522.8990
2024-04-30 07:11:24 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #253: GFLOPs: 196.1195. Time: 18866.9610 us. Best GFLOPs: 522.8990
2024-04-30 07:11:24 [INFO] [task_scheduler.cc:121] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #254: Error in running:
LocalRunner: Timeout, killed after 30 seconds

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(512)), "float32"), p1: T.Buffer((T.int64(32), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused in T.parallel(T.int64(4), annotations={"pragma_auto_unroll_max_step": 64, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(30), T.int64(16), T.int64(512)):
                with T.block("data_pad"):
                    v_i0, v_i1, v_i2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                    v_i3 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(2) * T.int64(14) + ax3)
                    v_i4 = T.axis.spatial(T.int64(512), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(14), T.int64(14), T.int64(4), T.int64(1), T.int64(32), T.int64(2), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(32), oc_chunk_1 * T.int64(32) + oc_chunk_2_init * T.int64(32) + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(28), oh_1 * T.int64(28) + oh_2_init * T.int64(2) + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(2) * T.int64(14) + ow_1 * T.int64(14) + ow_2_init + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(2) * T.int64(8) + oc_block_1 * T.int64(4) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(8), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(14), T.int64(14), T.int64(4), T.int64(64), T.int64(1), T.int64(3), T.int64(1), T.int64(32), T.int64(2), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(32), oc_chunk_1 * T.int64(32) + oc_chunk_2 * T.int64(32) + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(28), oh_1 * T.int64(28) + oh_2 * T.int64(2) + oh_3)
                        v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(2) * T.int64(14) + ow_1 * T.int64(14) + ow_2 + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(2) * T.int64(8) + oc_block_1 * T.int64(4) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(64) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(32), T.int64(28), T.int64(14)):
                for ax4_fused in T.vectorized(T.int64(8)):
                    with T.block("T_relu"):
                        v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                        v_ax3 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(2) * T.int64(14) + ax3)
                        v_ax4 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(2) * T.int64(8) + ax4_fused)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 32])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 14, 2])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[2, 1, 14, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[2, 2, 4, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[8, 64])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=4)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80 = sch.get_loops(block=b68)
l81 = sch.fuse(l71, l72, l73, l74, l75, preserve_unit_iters=True)
sch.parallel(loop=l81)
l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l82, preserve_unit_iters=True)
sch.parallel(loop=l104)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109, l110 = sch.get_loops(block=b70)
l111 = sch.fuse(l110, preserve_unit_iters=True)
sch.vectorize(loop=l111)
b112 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l113, l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134 = sch.get_loops(block=b112)
b135 = sch.decompose_reduction(block=b112, loop=l119)
2024-04-30 07:11:24 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #255: GFLOPs: 190.1163. Time: 19462.7140 us. Best GFLOPs: 522.8990
2024-04-30 07:11:24 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #256: GFLOPs: 89.6498. Time: 41273.6950 us. Best GFLOPs: 522.8990
2024-04-30 07:11:24 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-30 07:11:25 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-30 07:11:30 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 07:11:30 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-30 07:11:43 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 07:12:01 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 07:12:15 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 07:12:30 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 07:12:39 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9903  0.9417  0.9086  0.9032  0.9032  0.8917  0.8780  0.8673  0.8646  0.8635  0.8506  0.8482  0.8442  0.8362  0.8109  0.8107
[17 : 32]:	0.8053  0.8053  0.8053  0.8053  0.8053  0.8038  0.8035  0.8028  0.7900  0.7820  0.7767  0.7741  0.7709  0.7697  0.7633  0.7586
[33 : 48]:	0.7560  0.7545  0.7444  0.7419  0.7393  0.7393  0.7389  0.7389  0.7316  0.7315  0.7297  0.7297  0.7283  0.7160  0.7131  0.7097
[49 : 64]:	0.7085  0.7048  0.7012  0.7004  0.6991  0.6980  0.6980  0.6975  0.6890  0.6883  0.6848  0.6831  0.6819  0.6819  0.6819  0.6815
2024-04-30 07:12:40 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-30 07:12:40 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-30 07:14:53 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #257: GFLOPs: 563.0711. Time: 6571.4235 us. Best GFLOPs: 563.0711
2024-04-30 07:14:53 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #258: GFLOPs: 549.0324. Time: 6739.4551 us. Best GFLOPs: 563.0711
2024-04-30 07:14:53 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #259: GFLOPs: 480.3859. Time: 7702.5138 us. Best GFLOPs: 563.0711
2024-04-30 07:14:53 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #260: GFLOPs: 492.3522. Time: 7515.3098 us. Best GFLOPs: 563.0711
2024-04-30 07:14:53 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #261: GFLOPs: 247.3277. Time: 14960.6306 us. Best GFLOPs: 563.0711
2024-04-30 07:14:53 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #262: GFLOPs: 463.4723. Time: 7983.6025 us. Best GFLOPs: 563.0711
2024-04-30 07:14:53 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #263: GFLOPs: 582.3620. Time: 6353.7435 us. Best GFLOPs: 582.3620
2024-04-30 07:14:53 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #264: GFLOPs: 86.4449. Time: 42803.9093 us. Best GFLOPs: 582.3620
2024-04-30 07:14:53 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #265: GFLOPs: 420.7255. Time: 8794.7578 us. Best GFLOPs: 582.3620
2024-04-30 07:14:53 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #266: GFLOPs: 317.8228. Time: 11642.2689 us. Best GFLOPs: 582.3620
2024-04-30 07:14:53 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #267: GFLOPs: 477.1342. Time: 7755.0063 us. Best GFLOPs: 582.3620
2024-04-30 07:14:53 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #268: GFLOPs: 537.6222. Time: 6882.4896 us. Best GFLOPs: 582.3620
2024-04-30 07:14:53 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #269: GFLOPs: 521.0657. Time: 7101.1753 us. Best GFLOPs: 582.3620
2024-04-30 07:14:53 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #270: GFLOPs: 79.9462. Time: 46283.3663 us. Best GFLOPs: 582.3620
2024-04-30 07:14:53 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #271: GFLOPs: 331.5252. Time: 11161.0773 us. Best GFLOPs: 582.3620
2024-04-30 07:14:53 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #272: GFLOPs: 431.5622. Time: 8573.9181 us. Best GFLOPs: 582.3620
2024-04-30 07:14:53 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #273: GFLOPs: 475.7780. Time: 7777.1121 us. Best GFLOPs: 582.3620
2024-04-30 07:14:53 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #274: GFLOPs: 8.4775. Time: 436472.8900 us. Best GFLOPs: 582.3620
2024-04-30 07:14:53 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #275: GFLOPs: 392.1362. Time: 9435.9530 us. Best GFLOPs: 582.3620
2024-04-30 07:14:53 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #276: GFLOPs: 8.5404. Time: 433256.8477 us. Best GFLOPs: 582.3620
2024-04-30 07:14:53 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #277: GFLOPs: 269.4355. Time: 13733.0772 us. Best GFLOPs: 582.3620
2024-04-30 07:14:53 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #278: GFLOPs: 563.8739. Time: 6562.0683 us. Best GFLOPs: 582.3620
2024-04-30 07:14:53 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #279: GFLOPs: 621.4905. Time: 5953.7176 us. Best GFLOPs: 621.4905
2024-04-30 07:14:53 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #280: GFLOPs: 124.7849. Time: 29652.4572 us. Best GFLOPs: 621.4905
2024-04-30 07:14:53 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #281: GFLOPs: 407.4095. Time: 9082.2111 us. Best GFLOPs: 621.4905
2024-04-30 07:14:53 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #282: GFLOPs: 402.0870. Time: 9202.4335 us. Best GFLOPs: 621.4905
2024-04-30 07:14:53 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #283: GFLOPs: 16.5544. Time: 223515.9677 us. Best GFLOPs: 621.4905
2024-04-30 07:14:53 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #284: GFLOPs: 336.2295. Time: 11004.9211 us. Best GFLOPs: 621.4905
2024-04-30 07:14:53 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #285: GFLOPs: 303.8478. Time: 12177.7370 us. Best GFLOPs: 621.4905
2024-04-30 07:14:53 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #286: GFLOPs: 423.2670. Time: 8741.9502 us. Best GFLOPs: 621.4905
2024-04-30 07:14:53 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #287: GFLOPs: 119.1322. Time: 31059.4490 us. Best GFLOPs: 621.4905
2024-04-30 07:14:53 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #288: GFLOPs: 55.1928. Time: 67041.0280 us. Best GFLOPs: 621.4905
2024-04-30 07:14:53 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #289: GFLOPs: 199.7870. Time: 18520.6200 us. Best GFLOPs: 621.4905
2024-04-30 07:14:53 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #290: GFLOPs: 392.4538. Time: 9428.3184 us. Best GFLOPs: 621.4905
2024-04-30 07:14:53 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #291: GFLOPs: 586.6537. Time: 6307.2627 us. Best GFLOPs: 621.4905
2024-04-30 07:14:53 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #292: GFLOPs: 465.5920. Time: 7947.2558 us. Best GFLOPs: 621.4905
2024-04-30 07:14:53 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #293: GFLOPs: 313.8267. Time: 11790.5170 us. Best GFLOPs: 621.4905
2024-04-30 07:14:53 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #294: GFLOPs: 309.3949. Time: 11959.4066 us. Best GFLOPs: 621.4905
2024-04-30 07:14:53 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #295: GFLOPs: 588.1023. Time: 6291.7269 us. Best GFLOPs: 621.4905
2024-04-30 07:14:53 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #296: GFLOPs: 597.2077. Time: 6195.7994 us. Best GFLOPs: 621.4905
2024-04-30 07:14:53 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #297: GFLOPs: 404.4640. Time: 9148.3516 us. Best GFLOPs: 621.4905
2024-04-30 07:14:53 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #298: GFLOPs: 388.3205. Time: 9528.6728 us. Best GFLOPs: 621.4905
2024-04-30 07:14:53 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #299: GFLOPs: 466.7691. Time: 7927.2155 us. Best GFLOPs: 621.4905
2024-04-30 07:14:53 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #300: GFLOPs: 8.5651. Time: 432007.4493 us. Best GFLOPs: 621.4905
2024-04-30 07:14:53 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #301: GFLOPs: 155.4380. Time: 23804.8563 us. Best GFLOPs: 621.4905
2024-04-30 07:14:53 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #302: GFLOPs: 11.6911. Time: 316494.7973 us. Best GFLOPs: 621.4905
2024-04-30 07:14:53 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #303: GFLOPs: 32.6890. Time: 113193.2953 us. Best GFLOPs: 621.4905
2024-04-30 07:14:53 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #304: GFLOPs: 258.2465. Time: 14328.0903 us. Best GFLOPs: 621.4905
2024-04-30 07:14:53 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #305: GFLOPs: 353.6404. Time: 10463.1118 us. Best GFLOPs: 621.4905
2024-04-30 07:14:53 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #306: GFLOPs: 56.3833. Time: 65625.3837 us. Best GFLOPs: 621.4905
2024-04-30 07:14:53 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #307: GFLOPs: 109.5317. Time: 33781.8203 us. Best GFLOPs: 621.4905
2024-04-30 07:14:53 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #308: GFLOPs: 310.2190. Time: 11927.6350 us. Best GFLOPs: 621.4905
2024-04-30 07:14:53 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #309: GFLOPs: 265.5777. Time: 13932.5645 us. Best GFLOPs: 621.4905
2024-04-30 07:14:53 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #310: GFLOPs: 538.7454. Time: 6868.1407 us. Best GFLOPs: 621.4905
2024-04-30 07:14:53 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #311: GFLOPs: 538.6028. Time: 6869.9587 us. Best GFLOPs: 621.4905
2024-04-30 07:14:53 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #312: GFLOPs: 514.6424. Time: 7189.8056 us. Best GFLOPs: 621.4905
2024-04-30 07:14:53 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #313: GFLOPs: 53.6980. Time: 68907.1970 us. Best GFLOPs: 621.4905
2024-04-30 07:14:53 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #314: GFLOPs: 13.2167. Time: 279962.4127 us. Best GFLOPs: 621.4905
2024-04-30 07:14:53 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #315: GFLOPs: 62.7406. Time: 58975.8290 us. Best GFLOPs: 621.4905
2024-04-30 07:14:53 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #316: GFLOPs: 74.6676. Time: 49555.3493 us. Best GFLOPs: 621.4905
2024-04-30 07:14:53 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #317: GFLOPs: 406.6914. Time: 9098.2472 us. Best GFLOPs: 621.4905
2024-04-30 07:14:53 [INFO] [task_scheduler.cc:121] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #318: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(512)), "float32"), p1: T.Buffer((T.int64(32), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused in T.parallel(T.int64(32), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(512)):
                with T.block("data_pad"):
                    v_i0, v_i1, v_i2, v_i3, v_i4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(4), T.int64(1), T.int64(14), T.int64(1), T.int64(1), T.int64(1), T.int64(28), T.int64(2)):
                for oc_block_3_fused_init in T.vectorized(T.int64(4)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(16) * T.int64(16) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(8) // T.int64(2) * T.int64(4) + oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(28), oh_2_init * T.int64(28) + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(28), ow_2_init * T.int64(2) + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(16) // T.int64(8) * T.int64(8) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(2) * T.int64(4) + oc_block_2_init * T.int64(4) + oc_block_3_fused_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
            for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(32), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(1), T.int64(14), T.int64(1), T.int64(16), T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(28), T.int64(2)):
                for oc_block_3_fused in T.vectorized(T.int64(4)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(16) * T.int64(16) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(8) // T.int64(2) * T.int64(4) + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(28), oh_2 * T.int64(28) + oh_3)
                        v_ow = T.axis.spatial(T.int64(28), ow_2 * T.int64(2) + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(16) // T.int64(8) * T.int64(8) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(2) * T.int64(4) + oc_block_2 * T.int64(4) + oc_block_3_fused)
                        v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(16) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
        for ax0_ax1_ax2_ax3_ax4_fused_0 in T.parallel(T.int64(6272)):
            for ax0_ax1_ax2_ax3_ax4_fused_1 in T.vectorized(T.int64(64)):
                with T.block("T_relu"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) // T.int64(12544))
                    v_ax2 = T.axis.spatial(T.int64(28), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(12544) // T.int64(448))
                    v_ax3 = T.axis.spatial(T.int64(28), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(448) // T.int64(16))
                    v_ax4 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(16))
                    T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                    T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[2, 4, 4, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 1, 28])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 14, 2])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[2, 2, 1, 4])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[32, 16])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
l65 = sch.sample_compute_location(block=b0, decision=9)
sch.compute_at(block=b0, loop=l65, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b66 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.unroll_explicit")
b67, b68, b69 = sch.get_child_blocks(b66)
l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b67)
l85 = sch.fuse(l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, preserve_unit_iters=True)
sch.parallel(loop=l85)
l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102 = sch.get_loops(block=b68)
l103 = sch.fuse(l86, preserve_unit_iters=True)
sch.parallel(loop=l103)
l104 = sch.fuse(l102, preserve_unit_iters=True)
sch.vectorize(loop=l104)
sch.annotate(block_or_loop=l103, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l103, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109 = sch.get_loops(block=b69)
l110 = sch.fuse(l105, l106, l107, l108, l109, preserve_unit_iters=True)
l111, l112 = sch.split(loop=l110, factors=[None, 64], preserve_unit_iters=True)
sch.parallel(loop=l111)
sch.vectorize(loop=l112)
b113 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130 = sch.get_loops(block=b113)
b131 = sch.decompose_reduction(block=b113, loop=l115)
2024-04-30 07:14:53 [INFO] [task_scheduler.cc:121] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #319: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(512)), "float32"), p1: T.Buffer((T.int64(32), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_fused_fused in T.parallel(T.int64(2), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(16), T.int64(30), T.int64(512)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_fused_fused * T.int64(14) + ax2)
                    v_i3, v_i4 = T.axis.remap("SS", [ax3, ax4])
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for ow_0, oc_block_0 in T.grid(T.int64(1), T.int64(2)):
                for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(8), T.int64(7), T.int64(4), T.int64(1)):
                    for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(2), T.int64(2), T.int64(7), T.int64(2), T.int64(1), T.int64(2), T.int64(1), T.int64(1)):
                        for oc_block_3_fused_init in T.vectorized(T.int64(4)):
                            with T.block("conv2d_NCHWc_init"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                                v_oc_chunk = T.axis.spatial(T.int64(32), oc_chunk_1 * T.int64(4) + oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                                v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_fused_fused * T.int64(14) + oh_1 * T.int64(2) + oh_2_init + oh_3_init)
                                v_ow = T.axis.spatial(T.int64(28), ow_0 * T.int64(28) + ow_1 * T.int64(7) + ow_2_init + ow_3_init)
                                v_oc_block = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(8) + oc_block_1 * T.int64(8) + oc_block_2_init * T.int64(4) + oc_block_3_fused_init)
                                T.reads()
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                    for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(128), T.int64(1), T.int64(3), T.int64(1), T.int64(2), T.int64(2), T.int64(7), T.int64(2), T.int64(4), T.int64(3), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1)):
                        for oc_block_3_fused in T.vectorized(T.int64(4)):
                            with T.block("conv2d_NCHWc_update"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                                v_oc_chunk = T.axis.spatial(T.int64(32), oc_chunk_1 * T.int64(4) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                                v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_fused_fused * T.int64(14) + oh_1 * T.int64(2) + oh_2 + oh_3)
                                v_ow = T.axis.spatial(T.int64(28), ow_0 * T.int64(28) + ow_1 * T.int64(7) + ow_2 + ow_3)
                                v_oc_block = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(8) + oc_block_1 * T.int64(8) + oc_block_2 * T.int64(4) + oc_block_3_fused)
                                v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(4) + ic_1)
                                v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                                v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                                T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(32), T.int64(14), T.int64(28)):
                    for ax4_fused in T.vectorized(T.int64(8)):
                        with T.block("T_relu"):
                            v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                            v_ax2 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_fused_fused * T.int64(14) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(28), ax3)
                            v_ax4 = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(8) + ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 8, 2, 2])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 7, 2, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 4, 7, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[2, 1, 2, 4])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[128, 4])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=2)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78 = sch.get_loops(block=b68)
l79 = sch.fuse(l71, l72, l73, preserve_unit_iters=True)
sch.parallel(loop=l79)
l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l80, preserve_unit_iters=True)
sch.parallel(loop=l104)
l105 = sch.fuse(l103, preserve_unit_iters=True)
sch.vectorize(loop=l105)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l106, l107, l108, l109, l110, l111, l112, l113 = sch.get_loops(block=b70)
l114 = sch.fuse(l113, preserve_unit_iters=True)
sch.vectorize(loop=l114)
b115 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139 = sch.get_loops(block=b115)
b140 = sch.decompose_reduction(block=b115, loop=l124)
2024-04-30 07:14:53 [INFO] [task_scheduler.cc:121] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #320: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(512)), "float32"), p1: T.Buffer((T.int64(32), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_fused_fused in T.parallel(T.int64(28), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(3), T.int64(30), T.int64(512)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_fused_fused + ax2)
                    v_i3, v_i4 = T.axis.remap("SS", [ax3, ax4])
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for ow_0, oc_block_0, n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(2), T.int64(8), T.int64(1), T.int64(4), T.int64(1), T.int64(7), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(4), T.int64(1), T.int64(1)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(2)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(32), oc_chunk_1 * T.int64(8) + oc_chunk_2_init * T.int64(4) + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_fused_fused + oh_1 + oh_2_init + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(28), ow_0 * T.int64(14) + ow_1 * T.int64(2) + ow_2_init + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(2) + oc_block_1 * T.int64(2) + oc_block_2_init * T.int64(2) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(64), T.int64(1), T.int64(3), T.int64(1), T.int64(2), T.int64(1), T.int64(2), T.int64(1), T.int64(8), T.int64(3), T.int64(1), T.int64(1), T.int64(4), T.int64(1), T.int64(1)):
                    for oc_block_3_fused in T.vectorized(T.int64(2)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(32), oc_chunk_1 * T.int64(8) + oc_chunk_2 * T.int64(4) + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_fused_fused + oh_1 + oh_2 + oh_3)
                            v_ow = T.axis.spatial(T.int64(28), ow_0 * T.int64(14) + ow_1 * T.int64(2) + ow_2 + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(2) + oc_block_1 * T.int64(2) + oc_block_2 * T.int64(2) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(8) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
        for ax0_ax1_ax2_ax3_ax4_fused_0 in T.parallel(T.int64(6272)):
            for ax0_ax1_ax2_ax3_ax4_fused_1 in T.vectorized(T.int64(64)):
                with T.block("T_relu"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) // T.int64(12544))
                    v_ax2 = T.axis.spatial(T.int64(28), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(12544) // T.int64(448))
                    v_ax3 = T.axis.spatial(T.int64(28), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(448) // T.int64(16))
                    v_ax4 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(16))
                    T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                    T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 4, 2, 4])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[28, 1, 1, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[2, 7, 2, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[8, 1, 1, 2])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[64, 8])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
l65 = sch.sample_compute_location(block=b0, decision=2)
sch.compute_at(block=b0, loop=l65, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b66 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.unroll_explicit")
b67, b68, b69 = sch.get_child_blocks(b66)
l70, l71, l72, l73, l74, l75, l76, l77 = sch.get_loops(block=b67)
l78 = sch.fuse(l70, l71, l72, preserve_unit_iters=True)
sch.parallel(loop=l78)
l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102 = sch.get_loops(block=b68)
l103 = sch.fuse(l79, preserve_unit_iters=True)
sch.parallel(loop=l103)
l104 = sch.fuse(l102, preserve_unit_iters=True)
sch.vectorize(loop=l104)
sch.annotate(block_or_loop=l103, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l103, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109 = sch.get_loops(block=b69)
l110 = sch.fuse(l105, l106, l107, l108, l109, preserve_unit_iters=True)
l111, l112 = sch.split(loop=l110, factors=[None, 64], preserve_unit_iters=True)
sch.parallel(loop=l111)
sch.vectorize(loop=l112)
b113 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137 = sch.get_loops(block=b113)
b138 = sch.decompose_reduction(block=b113, loop=l122)
2024-04-30 07:23:31 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-30 07:23:32 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-30 07:23:37 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 07:23:37 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-30 07:23:50 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 07:24:04 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 07:24:19 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 07:24:34 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 07:24:43 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.8946  0.8804  0.8784  0.8760  0.8476  0.8405  0.8389  0.8296  0.8296  0.8263  0.8221  0.8157  0.8135  0.8135  0.8051  0.7892
[17 : 32]:	0.7790  0.7666  0.7657  0.7649  0.7619  0.7600  0.7597  0.7558  0.7544  0.7533  0.7481  0.7400  0.7383  0.7306  0.7306  0.7301
[33 : 48]:	0.7293  0.7257  0.7257  0.7254  0.7254  0.7238  0.7195  0.7195  0.7168  0.7121  0.7074  0.7056  0.7007  0.7002  0.6977  0.6949
[49 : 64]:	0.6935  0.6935  0.6929  0.6928  0.6914  0.6893  0.6891  0.6888  0.6849  0.6806  0.6806  0.6759  0.6751  0.6740  0.6726  0.6704
2024-04-30 07:24:43 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-30 07:24:43 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-30 07:26:54 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #321: GFLOPs: 493.1402. Time: 7503.2997 us. Best GFLOPs: 621.4905
2024-04-30 07:26:54 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #322: GFLOPs: 450.3611. Time: 8216.0266 us. Best GFLOPs: 621.4905
2024-04-30 07:26:54 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #323: GFLOPs: 509.4392. Time: 7263.2398 us. Best GFLOPs: 621.4905
2024-04-30 07:26:54 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #324: GFLOPs: 504.0895. Time: 7340.3219 us. Best GFLOPs: 621.4905
2024-04-30 07:26:54 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #325: GFLOPs: 376.4041. Time: 9830.3358 us. Best GFLOPs: 621.4905
2024-04-30 07:26:54 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #326: GFLOPs: 578.8405. Time: 6392.3980 us. Best GFLOPs: 621.4905
2024-04-30 07:26:54 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #327: GFLOPs: 456.2196. Time: 8110.5218 us. Best GFLOPs: 621.4905
2024-04-30 07:26:54 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #328: GFLOPs: 445.9676. Time: 8296.9680 us. Best GFLOPs: 621.4905
2024-04-30 07:26:54 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #329: GFLOPs: 473.8125. Time: 7809.3735 us. Best GFLOPs: 621.4905
2024-04-30 07:26:54 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #330: GFLOPs: 467.1584. Time: 7920.6084 us. Best GFLOPs: 621.4905
2024-04-30 07:26:54 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #331: GFLOPs: 472.4997. Time: 7831.0723 us. Best GFLOPs: 621.4905
2024-04-30 07:26:54 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #332: GFLOPs: 474.6765. Time: 7795.1601 us. Best GFLOPs: 621.4905
2024-04-30 07:26:54 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #333: GFLOPs: 515.5481. Time: 7177.1748 us. Best GFLOPs: 621.4905
2024-04-30 07:26:54 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #334: GFLOPs: 521.2504. Time: 7098.6587 us. Best GFLOPs: 621.4905
2024-04-30 07:26:54 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #335: GFLOPs: 468.6761. Time: 7894.9595 us. Best GFLOPs: 621.4905
2024-04-30 07:26:54 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #336: GFLOPs: 669.6379. Time: 5525.6418 us. Best GFLOPs: 669.6379
2024-04-30 07:26:54 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #337: GFLOPs: 491.0354. Time: 7535.4624 us. Best GFLOPs: 669.6379
2024-04-30 07:26:54 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #338: GFLOPs: 616.9332. Time: 5997.6978 us. Best GFLOPs: 669.6379
2024-04-30 07:26:54 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #339: GFLOPs: 634.0890. Time: 5835.4248 us. Best GFLOPs: 669.6379
2024-04-30 07:26:54 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #340: GFLOPs: 479.0637. Time: 7723.7719 us. Best GFLOPs: 669.6379
2024-04-30 07:26:54 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #341: GFLOPs: 583.5155. Time: 6341.1834 us. Best GFLOPs: 669.6379
2024-04-30 07:26:54 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #342: GFLOPs: 85.3343. Time: 43360.9630 us. Best GFLOPs: 669.6379
2024-04-30 07:26:54 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #343: GFLOPs: 634.9697. Time: 5827.3318 us. Best GFLOPs: 669.6379
2024-04-30 07:26:54 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #344: GFLOPs: 381.0217. Time: 9711.2015 us. Best GFLOPs: 669.6379
2024-04-30 07:26:54 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #345: GFLOPs: 451.9180. Time: 8187.7215 us. Best GFLOPs: 669.6379
2024-04-30 07:26:54 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #346: GFLOPs: 434.2139. Time: 8521.5589 us. Best GFLOPs: 669.6379
2024-04-30 07:26:54 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #347: GFLOPs: 624.0923. Time: 5928.8966 us. Best GFLOPs: 669.6379
2024-04-30 07:26:54 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #348: GFLOPs: 489.9683. Time: 7551.8749 us. Best GFLOPs: 669.6379
2024-04-30 07:26:54 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #349: GFLOPs: 422.2294. Time: 8763.4323 us. Best GFLOPs: 669.6379
2024-04-30 07:26:54 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #350: GFLOPs: 482.5964. Time: 7667.2325 us. Best GFLOPs: 669.6379
2024-04-30 07:26:54 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #351: GFLOPs: 6.6118. Time: 559635.1820 us. Best GFLOPs: 669.6379
2024-04-30 07:26:54 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #352: GFLOPs: 260.6691. Time: 14194.9253 us. Best GFLOPs: 669.6379
2024-04-30 07:26:54 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #353: GFLOPs: 430.2473. Time: 8600.1203 us. Best GFLOPs: 669.6379
2024-04-30 07:26:54 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #354: GFLOPs: 423.1701. Time: 8743.9527 us. Best GFLOPs: 669.6379
2024-04-30 07:26:54 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #355: GFLOPs: 426.4868. Time: 8675.9527 us. Best GFLOPs: 669.6379
2024-04-30 07:26:54 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #356: GFLOPs: 320.7524. Time: 11535.9339 us. Best GFLOPs: 669.6379
2024-04-30 07:26:54 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #357: GFLOPs: 510.0241. Time: 7254.9106 us. Best GFLOPs: 669.6379
2024-04-30 07:26:54 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #358: GFLOPs: 394.9302. Time: 9369.1967 us. Best GFLOPs: 669.6379
2024-04-30 07:26:54 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #359: GFLOPs: 8.9421. Time: 413793.9277 us. Best GFLOPs: 669.6379
2024-04-30 07:26:54 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #360: GFLOPs: 488.9877. Time: 7567.0188 us. Best GFLOPs: 669.6379
2024-04-30 07:26:54 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #361: GFLOPs: 300.7268. Time: 12304.1230 us. Best GFLOPs: 669.6379
2024-04-30 07:26:54 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #362: GFLOPs: 351.1134. Time: 10538.4153 us. Best GFLOPs: 669.6379
2024-04-30 07:26:54 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #363: GFLOPs: 489.6433. Time: 7556.8865 us. Best GFLOPs: 669.6379
2024-04-30 07:26:54 [INFO] [task_scheduler.cc:121] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #364: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(512)), "float32"), p1: T.Buffer((T.int64(32), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused in T.parallel(T.int64(224), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(14), T.int64(2), T.int64(16), T.int64(1), T.int64(2), T.int64(2), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(14) * T.int64(2) + oc_chunk_1 * T.int64(2) + oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(28), oh_1 * T.int64(28) + oh_2_init * T.int64(2) + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(14) * T.int64(2) + ow_1 * T.int64(2) + ow_2_init + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(16), oc_block_1 * T.int64(16) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0 in T.grid(T.int64(64), T.int64(3), T.int64(3)):
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(28), T.int64(2)):
                        for ax4_fused in T.vectorized(T.int64(8)):
                            with T.block("data_pad"):
                                v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                                v_i2 = T.axis.spatial(T.int64(30), kh_0 + ax2)
                                v_i3 = T.axis.spatial(T.int64(30), kw_0 + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(14) * T.int64(2) + ax3)
                                v_i4 = T.axis.spatial(T.int64(512), ic_0 * T.int64(8) + ax4_fused)
                                T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                                T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                                data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                    for n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(1), T.int64(1), T.int64(14), T.int64(2), T.int64(16), T.int64(8), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(2), T.int64(1), T.int64(1)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(14) * T.int64(2) + oc_chunk_1 * T.int64(2) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(28), oh_1 * T.int64(28) + oh_2 * T.int64(2) + oh_3)
                            v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(14) * T.int64(2) + ow_1 * T.int64(2) + ow_2 + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_1 * T.int64(16) + oc_block_2 + oc_block_3)
                            v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(8) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
            for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(2), T.int64(28)):
                for ax3_ax4_fused in T.vectorized(T.int64(32)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(14) * T.int64(2) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(28), ax2)
                        v_ax3 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(14) * T.int64(2) + ax3_ax4_fused // T.int64(16))
                        v_ax4 = T.axis.spatial(T.int64(16), ax3_ax4_fused % T.int64(16))
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[16, 1, 1, 2])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 14, 2])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[14, 1, 2, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 16, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[64, 8])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=12)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88 = sch.get_loops(block=b68)
l89 = sch.fuse(l71, l72, l73, l74, l75, preserve_unit_iters=True)
sch.parallel(loop=l89)
l90 = sch.fuse(l88, preserve_unit_iters=True)
sch.vectorize(loop=l90)
l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107, l108, l109, l110, l111, l112 = sch.get_loops(block=b69)
l113 = sch.fuse(l91, preserve_unit_iters=True)
sch.parallel(loop=l113)
sch.annotate(block_or_loop=l113, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l113, ann_key="pragma_unroll_explicit", ann_val=1)
l114, l115, l116, l117, l118, l119 = sch.get_loops(block=b70)
l120 = sch.fuse(l118, l119, preserve_unit_iters=True)
sch.vectorize(loop=l120)
b121 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141, l142, l143 = sch.get_loops(block=b121)
b144 = sch.decompose_reduction(block=b121, loop=l128)
2024-04-30 07:26:54 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #365: GFLOPs: 281.2315. Time: 13157.0554 us. Best GFLOPs: 669.6379
2024-04-30 07:26:54 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #366: GFLOPs: 441.1896. Time: 8386.8235 us. Best GFLOPs: 669.6379
2024-04-30 07:26:54 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #367: GFLOPs: 489.0616. Time: 7565.8745 us. Best GFLOPs: 669.6379
2024-04-30 07:26:54 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #368: GFLOPs: 327.0125. Time: 11315.1002 us. Best GFLOPs: 669.6379
2024-04-30 07:26:54 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #369: GFLOPs: 479.4661. Time: 7717.2898 us. Best GFLOPs: 669.6379
2024-04-30 07:26:54 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #370: GFLOPs: 7.1238. Time: 519413.0823 us. Best GFLOPs: 669.6379
2024-04-30 07:26:54 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #371: GFLOPs: 273.8545. Time: 13511.4800 us. Best GFLOPs: 669.6379
2024-04-30 07:26:54 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #372: GFLOPs: 396.8774. Time: 9323.2295 us. Best GFLOPs: 669.6379
2024-04-30 07:26:54 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #373: GFLOPs: 400.6873. Time: 9234.5789 us. Best GFLOPs: 669.6379
2024-04-30 07:26:54 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #374: GFLOPs: 491.3875. Time: 7530.0625 us. Best GFLOPs: 669.6379
2024-04-30 07:26:54 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #375: GFLOPs: 435.1054. Time: 8504.0980 us. Best GFLOPs: 669.6379
2024-04-30 07:26:54 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #376: GFLOPs: 407.2121. Time: 9086.6132 us. Best GFLOPs: 669.6379
2024-04-30 07:26:54 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #377: GFLOPs: 415.0322. Time: 8915.4018 us. Best GFLOPs: 669.6379
2024-04-30 07:26:54 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #378: GFLOPs: 412.1933. Time: 8976.8045 us. Best GFLOPs: 669.6379
2024-04-30 07:26:54 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #379: GFLOPs: 416.6181. Time: 8881.4645 us. Best GFLOPs: 669.6379
2024-04-30 07:26:54 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #380: GFLOPs: 323.4030. Time: 11441.3880 us. Best GFLOPs: 669.6379
2024-04-30 07:26:54 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #381: GFLOPs: 520.0558. Time: 7114.9651 us. Best GFLOPs: 669.6379
2024-04-30 07:26:54 [INFO] [task_scheduler.cc:121] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #382: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(512)), "float32"), p1: T.Buffer((T.int64(32), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_fused_fused in T.parallel(T.int64(14), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(30), T.int64(6), T.int64(512)):
                with T.block("data_pad"):
                    v_i0, v_i1, v_i2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                    v_i3 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(7) * T.int64(4) + ax3)
                    v_i4 = T.axis.spatial(T.int64(512), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oc_block_0, n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(28), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(4)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(7) * T.int64(16) + oc_chunk_1 * T.int64(4) + oc_chunk_2_init + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(28), oh_1 + oh_2_init + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(7) * T.int64(4) + ow_1 * T.int64(4) + ow_2_init * T.int64(4) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2_init * T.int64(4) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(32), T.int64(3), T.int64(1), T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(4), T.int64(16), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(4)):
                    for oc_block_3_fused in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(7) * T.int64(16) + oc_chunk_1 * T.int64(4) + oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(28), oh_1 + oh_2 + oh_3)
                            v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(7) * T.int64(4) + ow_1 * T.int64(4) + ow_2 * T.int64(4) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2 * T.int64(4) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(16) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
        for ax0_ax1_ax2_ax3_ax4_fused_0 in T.parallel(T.int64(6272)):
            for ax0_ax1_ax2_ax3_ax4_fused_1 in T.vectorized(T.int64(64)):
                with T.block("T_relu"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) // T.int64(12544))
                    v_ax2 = T.axis.spatial(T.int64(28), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(12544) // T.int64(448))
                    v_ax3 = T.axis.spatial(T.int64(28), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(448) // T.int64(16))
                    v_ax4 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(16))
                    T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                    T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[2, 4, 4, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 28, 1, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[7, 1, 1, 4])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 4, 4])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[32, 16])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
l65 = sch.sample_compute_location(block=b0, decision=3)
sch.compute_at(block=b0, loop=l65, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b66 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.unroll_explicit")
b67, b68, b69 = sch.get_child_blocks(b66)
l70, l71, l72, l73, l74, l75, l76, l77, l78 = sch.get_loops(block=b67)
l79 = sch.fuse(l70, l71, l72, l73, preserve_unit_iters=True)
sch.parallel(loop=l79)
l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102 = sch.get_loops(block=b68)
l103 = sch.fuse(l80, preserve_unit_iters=True)
sch.parallel(loop=l103)
l104 = sch.fuse(l102, preserve_unit_iters=True)
sch.vectorize(loop=l104)
sch.annotate(block_or_loop=l103, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l103, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109 = sch.get_loops(block=b69)
l110 = sch.fuse(l105, l106, l107, l108, l109, preserve_unit_iters=True)
l111, l112 = sch.split(loop=l110, factors=[None, 64], preserve_unit_iters=True)
sch.parallel(loop=l111)
sch.vectorize(loop=l112)
b113 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136 = sch.get_loops(block=b113)
b137 = sch.decompose_reduction(block=b113, loop=l121)
2024-04-30 07:26:54 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #383: GFLOPs: 6.2139. Time: 595469.7520 us. Best GFLOPs: 669.6379
2024-04-30 07:26:54 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #384: GFLOPs: 63.0892. Time: 58649.9917 us. Best GFLOPs: 669.6379
2024-04-30 07:35:16 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-30 07:35:17 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-30 07:35:22 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 07:35:22 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-30 07:35:35 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 07:35:49 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 07:36:04 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 07:36:18 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 07:36:27 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9212  0.8714  0.8609  0.8478  0.8386  0.8376  0.8216  0.8193  0.8127  0.8127  0.8122  0.8122  0.8077  0.8044  0.8032  0.7970
[17 : 32]:	0.7871  0.7861  0.7739  0.7701  0.7640  0.7604  0.7579  0.7504  0.7449  0.7305  0.7278  0.7210  0.7189  0.7186  0.7171  0.7169
[33 : 48]:	0.7125  0.7123  0.7112  0.7105  0.7056  0.7000  0.6971  0.6961  0.6961  0.6912  0.6910  0.6883  0.6855  0.6846  0.6844  0.6828
[49 : 64]:	0.6806  0.6803  0.6797  0.6797  0.6780  0.6780  0.6780  0.6780  0.6780  0.6745  0.6738  0.6718  0.6707  0.6704  0.6691  0.6685
2024-04-30 07:36:28 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-30 07:36:28 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-30 07:38:23 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #385: GFLOPs: 772.3500. Time: 4790.8057 us. Best GFLOPs: 772.3500
2024-04-30 07:38:24 [INFO] [task_scheduler.cc:121] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #386: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(512)), "float32"), p1: T.Buffer((T.int64(32), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_fused_fused in T.parallel(T.int64(224), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for oc_block_0 in range(T.int64(1)):
                for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                    for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(14), T.int64(1), T.int64(16), T.int64(1), T.int64(2), T.int64(2), T.int64(2), T.int64(1)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(14) * T.int64(2) + oc_chunk_1 * T.int64(2) + oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(28), oh_1 * T.int64(28) + oh_2_init * T.int64(2) + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(14) * T.int64(2) + ow_1 * T.int64(2) + ow_2_init * T.int64(2) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2_init + oc_block_3_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                    for ic_0 in range(T.int64(128)):
                        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(30), T.int64(4)):
                            for ax4_fused in T.vectorized(T.int64(4)):
                                with T.block("data_pad"):
                                    v_i0, v_i1, v_i2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                                    v_i3 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(14) * T.int64(2) + ax3)
                                    v_i4 = T.axis.spatial(T.int64(512), ic_0 * T.int64(4) + ax4_fused)
                                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                        for kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(14), T.int64(1), T.int64(16), T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(2), T.int64(2), T.int64(1)):
                            with T.block("conv2d_NCHWc_update"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                                v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(14) * T.int64(2) + oc_chunk_1 * T.int64(2) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                                v_oh = T.axis.spatial(T.int64(28), oh_1 * T.int64(28) + oh_2 * T.int64(2) + oh_3)
                                v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(14) * T.int64(2) + ow_1 * T.int64(2) + ow_2 * T.int64(2) + ow_3)
                                v_oc_block = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2 + oc_block_3)
                                v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(4) + ic_1)
                                v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                                v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                                T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
                for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(2), T.int64(28)):
                    for ax3_ax4_fused in T.vectorized(T.int64(32)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(14) * T.int64(2) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(28), ax2)
                            v_ax3 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(14) * T.int64(2) + ax3_ax4_fused // T.int64(16))
                            v_ax4 = T.axis.spatial(T.int64(16), ax3_ax4_fused % T.int64(16))
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[16, 1, 1, 2])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 14, 2])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[14, 1, 1, 2])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 16, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[128, 4])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=32)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=10)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86 = sch.get_loops(block=b68)
l87 = sch.fuse(l71, l72, l73, l74, preserve_unit_iters=True)
sch.parallel(loop=l87)
l88 = sch.fuse(l86, preserve_unit_iters=True)
sch.vectorize(loop=l88)
l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107, l108, l109, l110, l111 = sch.get_loops(block=b69)
l112 = sch.fuse(l89, preserve_unit_iters=True)
sch.parallel(loop=l112)
sch.annotate(block_or_loop=l112, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l112, ann_key="pragma_unroll_explicit", ann_val=1)
l113, l114, l115, l116, l117, l118, l119 = sch.get_loops(block=b70)
l120 = sch.fuse(l118, l119, preserve_unit_iters=True)
sch.vectorize(loop=l120)
b121 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141, l142, l143, l144 = sch.get_loops(block=b121)
b145 = sch.decompose_reduction(block=b121, loop=l129)
2024-04-30 07:38:24 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #387: GFLOPs: 570.6038. Time: 6484.6729 us. Best GFLOPs: 772.3500
2024-04-30 07:38:24 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #388: GFLOPs: 312.3327. Time: 11846.9150 us. Best GFLOPs: 772.3500
2024-04-30 07:38:24 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #389: GFLOPs: 721.9635. Time: 5125.1609 us. Best GFLOPs: 772.3500
2024-04-30 07:38:24 [INFO] [task_scheduler.cc:121] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #390: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(512)), "float32"), p1: T.Buffer((T.int64(32), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused in T.parallel(T.int64(448), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(16), T.int64(1), T.int64(2), T.int64(2), T.int64(2), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(28) * T.int64(2) + oc_chunk_1 * T.int64(2) + oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(28) // T.int64(14) * T.int64(14) + oh_1 * T.int64(14) + oh_2_init * T.int64(2) + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(14) * T.int64(2) + ow_1 * T.int64(2) + ow_2_init * T.int64(2) + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(16), oc_block_1 * T.int64(16) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0 in range(T.int64(128)):
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(16), T.int64(4)):
                        for ax4_fused in T.vectorized(T.int64(4)):
                            with T.block("data_pad"):
                                v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                                v_i2 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(28) // T.int64(14) * T.int64(14) + ax2)
                                v_i3 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(14) * T.int64(2) + ax3)
                                v_i4 = T.axis.spatial(T.int64(512), ic_0 * T.int64(4) + ax4_fused)
                                T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                                T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                                data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                    for kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(16), T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(2), T.int64(2), T.int64(1)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(28) * T.int64(2) + oc_chunk_1 * T.int64(2) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(28) // T.int64(14) * T.int64(14) + oh_1 * T.int64(14) + oh_2 * T.int64(2) + oh_3)
                            v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(14) * T.int64(2) + ow_1 * T.int64(2) + ow_2 * T.int64(2) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_1 * T.int64(16) + oc_block_2 + oc_block_3)
                            v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(4) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
            for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(2), T.int64(14)):
                for ax3_ax4_fused in T.vectorized(T.int64(32)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(28) * T.int64(2) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(28) // T.int64(14) * T.int64(14) + ax2)
                        v_ax3 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(14) * T.int64(2) + ax3_ax4_fused // T.int64(16))
                        v_ax4 = T.axis.spatial(T.int64(16), ax3_ax4_fused % T.int64(16))
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[16, 1, 1, 2])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 1, 7, 2])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[14, 1, 1, 2])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 16, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[128, 4])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=10)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86 = sch.get_loops(block=b68)
l87 = sch.fuse(l71, l72, l73, l74, l75, preserve_unit_iters=True)
sch.parallel(loop=l87)
l88 = sch.fuse(l86, preserve_unit_iters=True)
sch.vectorize(loop=l88)
l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107, l108, l109, l110 = sch.get_loops(block=b69)
l111 = sch.fuse(l89, preserve_unit_iters=True)
sch.parallel(loop=l111)
sch.annotate(block_or_loop=l111, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l111, ann_key="pragma_unroll_explicit", ann_val=1)
l112, l113, l114, l115, l116, l117 = sch.get_loops(block=b70)
l118 = sch.fuse(l116, l117, preserve_unit_iters=True)
sch.vectorize(loop=l118)
b119 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141 = sch.get_loops(block=b119)
b142 = sch.decompose_reduction(block=b119, loop=l126)
2024-04-30 07:38:24 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #391: GFLOPs: 676.6397. Time: 5468.4631 us. Best GFLOPs: 772.3500
2024-04-30 07:38:24 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #392: GFLOPs: 580.6535. Time: 6372.4391 us. Best GFLOPs: 772.3500
2024-04-30 07:38:24 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #393: GFLOPs: 698.9557. Time: 5293.8674 us. Best GFLOPs: 772.3500
2024-04-30 07:38:24 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #394: GFLOPs: 695.6006. Time: 5319.4015 us. Best GFLOPs: 772.3500
2024-04-30 07:38:24 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #395: GFLOPs: 646.0821. Time: 5727.1030 us. Best GFLOPs: 772.3500
2024-04-30 07:38:24 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #396: GFLOPs: 599.5221. Time: 6171.8804 us. Best GFLOPs: 772.3500
2024-04-30 07:38:24 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #397: GFLOPs: 518.9202. Time: 7130.5354 us. Best GFLOPs: 772.3500
2024-04-30 07:38:24 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #398: GFLOPs: 566.7987. Time: 6528.2067 us. Best GFLOPs: 772.3500
2024-04-30 07:38:24 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #399: GFLOPs: 663.5906. Time: 5575.9965 us. Best GFLOPs: 772.3500
2024-04-30 07:38:24 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #400: GFLOPs: 650.7063. Time: 5686.4039 us. Best GFLOPs: 772.3500
2024-04-30 07:38:24 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #401: GFLOPs: 570.7193. Time: 6483.3603 us. Best GFLOPs: 772.3500
2024-04-30 07:38:24 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #402: GFLOPs: 479.7354. Time: 7712.9573 us. Best GFLOPs: 772.3500
2024-04-30 07:38:24 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #403: GFLOPs: 257.0190. Time: 14396.5191 us. Best GFLOPs: 772.3500
2024-04-30 07:38:24 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #404: GFLOPs: 585.7986. Time: 6316.4699 us. Best GFLOPs: 772.3500
2024-04-30 07:38:24 [INFO] [task_scheduler.cc:121] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #405: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(512)), "float32"), p1: T.Buffer((T.int64(32), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_fused_fused in T.parallel(T.int64(224), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for oc_block_0 in range(T.int64(1)):
                for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                    for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(14), T.int64(2), T.int64(16), T.int64(1), T.int64(2), T.int64(2), T.int64(1), T.int64(1)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(14) * T.int64(2) + oc_chunk_1 * T.int64(2) + oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(28), oh_1 * T.int64(28) + oh_2_init * T.int64(2) + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(14) * T.int64(2) + ow_1 * T.int64(2) + ow_2_init + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2_init + oc_block_3_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                    for ic_0 in range(T.int64(128)):
                        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(30), T.int64(4)):
                            for ax4_fused in T.vectorized(T.int64(4)):
                                with T.block("data_pad"):
                                    v_i0, v_i1, v_i2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                                    v_i3 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(14) * T.int64(2) + ax3)
                                    v_i4 = T.axis.spatial(T.int64(512), ic_0 * T.int64(4) + ax4_fused)
                                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                        for kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(14), T.int64(2), T.int64(16), T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(2), T.int64(1), T.int64(1)):
                            with T.block("conv2d_NCHWc_update"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                                v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(14) * T.int64(2) + oc_chunk_1 * T.int64(2) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                                v_oh = T.axis.spatial(T.int64(28), oh_1 * T.int64(28) + oh_2 * T.int64(2) + oh_3)
                                v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(14) * T.int64(2) + ow_1 * T.int64(2) + ow_2 + ow_3)
                                v_oc_block = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2 + oc_block_3)
                                v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(4) + ic_1)
                                v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                                v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                                T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
                for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(2), T.int64(28)):
                    for ax3_ax4_fused in T.vectorized(T.int64(32)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(14) * T.int64(2) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(28), ax2)
                            v_ax3 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(14) * T.int64(2) + ax3_ax4_fused // T.int64(16))
                            v_ax4 = T.axis.spatial(T.int64(16), ax3_ax4_fused % T.int64(16))
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[16, 1, 1, 2])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 14, 2])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[14, 1, 2, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 16, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[128, 4])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=32)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=10)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86 = sch.get_loops(block=b68)
l87 = sch.fuse(l71, l72, l73, l74, preserve_unit_iters=True)
sch.parallel(loop=l87)
l88 = sch.fuse(l86, preserve_unit_iters=True)
sch.vectorize(loop=l88)
l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107, l108, l109, l110, l111 = sch.get_loops(block=b69)
l112 = sch.fuse(l89, preserve_unit_iters=True)
sch.parallel(loop=l112)
sch.annotate(block_or_loop=l112, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l112, ann_key="pragma_unroll_explicit", ann_val=1)
l113, l114, l115, l116, l117, l118, l119 = sch.get_loops(block=b70)
l120 = sch.fuse(l118, l119, preserve_unit_iters=True)
sch.vectorize(loop=l120)
b121 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141, l142, l143, l144 = sch.get_loops(block=b121)
b145 = sch.decompose_reduction(block=b121, loop=l129)
2024-04-30 07:38:24 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #406: GFLOPs: 567.0165. Time: 6525.6992 us. Best GFLOPs: 772.3500
2024-04-30 07:38:24 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #407: GFLOPs: 564.5555. Time: 6554.1459 us. Best GFLOPs: 772.3500
2024-04-30 07:38:24 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #408: GFLOPs: 599.9490. Time: 6167.4896 us. Best GFLOPs: 772.3500
2024-04-30 07:38:24 [INFO] [task_scheduler.cc:121] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #409: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(512)), "float32"), p1: T.Buffer((T.int64(32), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_fused_fused in T.parallel(T.int64(224), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for oc_block_0 in range(T.int64(1)):
                for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1)):
                    for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(16), T.int64(1), T.int64(2), T.int64(2), T.int64(2), T.int64(1)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(14) * T.int64(2) + oc_chunk_1 * T.int64(2) + oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(28), oh_1 * T.int64(14) + oh_2_init * T.int64(2) + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(14) * T.int64(2) + ow_1 * T.int64(2) + ow_2_init * T.int64(2) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2_init + oc_block_3_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                    for ic_0 in range(T.int64(128)):
                        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(16), T.int64(4)):
                            for ax4_fused in T.vectorized(T.int64(4)):
                                with T.block("data_pad"):
                                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                                    v_i2 = T.axis.spatial(T.int64(30), oh_1 * T.int64(14) + ax2)
                                    v_i3 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(14) * T.int64(2) + ax3)
                                    v_i4 = T.axis.spatial(T.int64(512), ic_0 * T.int64(4) + ax4_fused)
                                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                        for kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(16), T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(2), T.int64(2), T.int64(1)):
                            with T.block("conv2d_NCHWc_update"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                                v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(14) * T.int64(2) + oc_chunk_1 * T.int64(2) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                                v_oh = T.axis.spatial(T.int64(28), oh_1 * T.int64(14) + oh_2 * T.int64(2) + oh_3)
                                v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(14) * T.int64(2) + ow_1 * T.int64(2) + ow_2 * T.int64(2) + ow_3)
                                v_oc_block = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2 + oc_block_3)
                                v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(4) + ic_1)
                                v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                                v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                                T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
                for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(2), T.int64(28)):
                    for ax3_ax4_fused in T.vectorized(T.int64(32)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(14) * T.int64(2) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(28), ax2)
                            v_ax3 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(14) * T.int64(2) + ax3_ax4_fused // T.int64(16))
                            v_ax4 = T.axis.spatial(T.int64(16), ax3_ax4_fused % T.int64(16))
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[16, 1, 1, 2])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 2, 7, 2])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[14, 1, 1, 2])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 16, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[128, 4])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=32)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=10)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86 = sch.get_loops(block=b68)
l87 = sch.fuse(l71, l72, l73, l74, preserve_unit_iters=True)
sch.parallel(loop=l87)
l88 = sch.fuse(l86, preserve_unit_iters=True)
sch.vectorize(loop=l88)
l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107, l108, l109, l110, l111 = sch.get_loops(block=b69)
l112 = sch.fuse(l89, preserve_unit_iters=True)
sch.parallel(loop=l112)
sch.annotate(block_or_loop=l112, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l112, ann_key="pragma_unroll_explicit", ann_val=1)
l113, l114, l115, l116, l117, l118, l119 = sch.get_loops(block=b70)
l120 = sch.fuse(l118, l119, preserve_unit_iters=True)
sch.vectorize(loop=l120)
b121 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141, l142, l143, l144 = sch.get_loops(block=b121)
b145 = sch.decompose_reduction(block=b121, loop=l129)
2024-04-30 07:38:24 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #410: GFLOPs: 461.1870. Time: 8023.1642 us. Best GFLOPs: 772.3500
2024-04-30 07:38:24 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #411: GFLOPs: 492.2631. Time: 7516.6701 us. Best GFLOPs: 772.3500
2024-04-30 07:38:24 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #412: GFLOPs: 108.5245. Time: 34095.3300 us. Best GFLOPs: 772.3500
2024-04-30 07:38:24 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #413: GFLOPs: 677.1173. Time: 5464.6056 us. Best GFLOPs: 772.3500
2024-04-30 07:38:24 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #414: GFLOPs: 474.9202. Time: 7791.1595 us. Best GFLOPs: 772.3500
2024-04-30 07:38:24 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #415: GFLOPs: 355.4070. Time: 10411.1042 us. Best GFLOPs: 772.3500
2024-04-30 07:38:24 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #416: GFLOPs: 343.8156. Time: 10762.1042 us. Best GFLOPs: 772.3500
2024-04-30 07:38:24 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #417: GFLOPs: 557.4886. Time: 6637.2280 us. Best GFLOPs: 772.3500
2024-04-30 07:38:24 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #418: GFLOPs: 428.9440. Time: 8626.2517 us. Best GFLOPs: 772.3500
2024-04-30 07:38:24 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #419: GFLOPs: 199.5244. Time: 18544.9958 us. Best GFLOPs: 772.3500
2024-04-30 07:38:24 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #420: GFLOPs: 424.1134. Time: 8724.5035 us. Best GFLOPs: 772.3500
2024-04-30 07:38:24 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #421: GFLOPs: 522.5005. Time: 7081.6759 us. Best GFLOPs: 772.3500
2024-04-30 07:38:24 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #422: GFLOPs: 455.0773. Time: 8130.8807 us. Best GFLOPs: 772.3500
2024-04-30 07:38:24 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #423: GFLOPs: 403.9141. Time: 9160.8066 us. Best GFLOPs: 772.3500
2024-04-30 07:38:24 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #424: GFLOPs: 423.4231. Time: 8738.7278 us. Best GFLOPs: 772.3500
2024-04-30 07:38:24 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #425: GFLOPs: 432.7444. Time: 8550.4963 us. Best GFLOPs: 772.3500
2024-04-30 07:38:24 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #426: GFLOPs: 7.8930. Time: 468793.4253 us. Best GFLOPs: 772.3500
2024-04-30 07:38:24 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #427: GFLOPs: 389.1854. Time: 9507.4973 us. Best GFLOPs: 772.3500
2024-04-30 07:38:24 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #428: GFLOPs: 498.0785. Time: 7428.9079 us. Best GFLOPs: 772.3500
2024-04-30 07:38:24 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #429: GFLOPs: 463.5172. Time: 7982.8304 us. Best GFLOPs: 772.3500
2024-04-30 07:38:24 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #430: GFLOPs: 408.3695. Time: 9060.8610 us. Best GFLOPs: 772.3500
2024-04-30 07:38:24 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #431: GFLOPs: 330.5504. Time: 11193.9948 us. Best GFLOPs: 772.3500
2024-04-30 07:38:24 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #432: GFLOPs: 612.9819. Time: 6036.3591 us. Best GFLOPs: 772.3500
2024-04-30 07:38:24 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #433: GFLOPs: 710.1105. Time: 5210.7087 us. Best GFLOPs: 772.3500
2024-04-30 07:38:24 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #434: GFLOPs: 430.5165. Time: 8594.7428 us. Best GFLOPs: 772.3500
2024-04-30 07:38:24 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #435: GFLOPs: 346.2589. Time: 10686.1629 us. Best GFLOPs: 772.3500
2024-04-30 07:38:24 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #436: GFLOPs: 491.5126. Time: 7528.1460 us. Best GFLOPs: 772.3500
2024-04-30 07:38:24 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #437: GFLOPs: 20.5669. Time: 179909.1567 us. Best GFLOPs: 772.3500
2024-04-30 07:38:24 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #438: GFLOPs: 546.1251. Time: 6775.3319 us. Best GFLOPs: 772.3500
2024-04-30 07:38:24 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #439: GFLOPs: 313.5952. Time: 11799.2219 us. Best GFLOPs: 772.3500
2024-04-30 07:38:24 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #440: GFLOPs: 16.9200. Time: 218687.0007 us. Best GFLOPs: 772.3500
2024-04-30 07:38:24 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #441: GFLOPs: 299.5050. Time: 12354.3149 us. Best GFLOPs: 772.3500
2024-04-30 07:38:24 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #442: GFLOPs: 475.2411. Time: 7785.8986 us. Best GFLOPs: 772.3500
2024-04-30 07:38:24 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #443: GFLOPs: 669.0852. Time: 5530.2062 us. Best GFLOPs: 772.3500
2024-04-30 07:38:24 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #444: GFLOPs: 492.1249. Time: 7518.7801 us. Best GFLOPs: 772.3500
2024-04-30 07:38:24 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #445: GFLOPs: 398.7737. Time: 9278.8942 us. Best GFLOPs: 772.3500
2024-04-30 07:38:24 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #446: GFLOPs: 93.7930. Time: 39450.4627 us. Best GFLOPs: 772.3500
2024-04-30 07:38:24 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #447: GFLOPs: 22.6714. Time: 163209.1907 us. Best GFLOPs: 772.3500
2024-04-30 07:38:24 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #448: GFLOPs: 180.1577. Time: 20538.5554 us. Best GFLOPs: 772.3500
2024-04-30 07:53:22 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-30 07:53:23 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-30 07:53:28 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 07:53:28 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-30 07:53:40 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 07:53:54 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 07:54:09 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 07:54:23 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 07:54:32 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9045  0.8772  0.8231  0.8102  0.7972  0.7833  0.7669  0.7640  0.7552  0.7534  0.7478  0.7400  0.7352  0.7332  0.7314  0.7305
[17 : 32]:	0.7303  0.7303  0.7220  0.7205  0.7184  0.7167  0.7129  0.7123  0.7115  0.7069  0.7069  0.7022  0.7006  0.6966  0.6964  0.6949
[33 : 48]:	0.6949  0.6945  0.6926  0.6868  0.6858  0.6858  0.6858  0.6858  0.6845  0.6844  0.6824  0.6824  0.6821  0.6821  0.6803  0.6785
[49 : 64]:	0.6768  0.6765  0.6735  0.6732  0.6732  0.6726  0.6711  0.6583  0.6553  0.6549  0.6532  0.6529  0.6518  0.6511  0.6488  0.6487
2024-04-30 07:54:33 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-30 07:54:33 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-30 07:56:33 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #449: GFLOPs: 388.4563. Time: 9525.3411 us. Best GFLOPs: 772.3500
2024-04-30 07:56:33 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #450: GFLOPs: 672.8547. Time: 5499.2245 us. Best GFLOPs: 772.3500
2024-04-30 07:56:33 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #451: GFLOPs: 625.2615. Time: 5917.8105 us. Best GFLOPs: 772.3500
2024-04-30 07:56:33 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #452: GFLOPs: 587.5814. Time: 6297.3044 us. Best GFLOPs: 772.3500
2024-04-30 07:56:33 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #453: GFLOPs: 526.8540. Time: 7023.1587 us. Best GFLOPs: 772.3500
2024-04-30 07:56:33 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #454: GFLOPs: 632.0358. Time: 5854.3823 us. Best GFLOPs: 772.3500
2024-04-30 07:56:33 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #455: GFLOPs: 526.2073. Time: 7031.7889 us. Best GFLOPs: 772.3500
2024-04-30 07:56:33 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #456: GFLOPs: 631.8419. Time: 5856.1784 us. Best GFLOPs: 772.3500
2024-04-30 07:56:33 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #457: GFLOPs: 111.2964. Time: 33246.1620 us. Best GFLOPs: 772.3500
2024-04-30 07:56:33 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #458: GFLOPs: 475.4192. Time: 7782.9815 us. Best GFLOPs: 772.3500
2024-04-30 07:56:33 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #459: GFLOPs: 585.1511. Time: 6323.4593 us. Best GFLOPs: 772.3500
2024-04-30 07:56:33 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #460: GFLOPs: 496.0185. Time: 7459.7604 us. Best GFLOPs: 772.3500
2024-04-30 07:56:33 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #461: GFLOPs: 579.8843. Time: 6380.8916 us. Best GFLOPs: 772.3500
2024-04-30 07:56:33 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #462: GFLOPs: 583.4486. Time: 6341.9102 us. Best GFLOPs: 772.3500
2024-04-30 07:56:33 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #463: GFLOPs: 414.7751. Time: 8920.9282 us. Best GFLOPs: 772.3500
2024-04-30 07:56:33 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #464: GFLOPs: 521.0961. Time: 7100.7608 us. Best GFLOPs: 772.3500
2024-04-30 07:56:33 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #465: GFLOPs: 661.0293. Time: 5597.6018 us. Best GFLOPs: 772.3500
2024-04-30 07:56:33 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #466: GFLOPs: 648.6806. Time: 5704.1614 us. Best GFLOPs: 772.3500
2024-04-30 07:56:33 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #467: GFLOPs: 532.0311. Time: 6954.8175 us. Best GFLOPs: 772.3500
2024-04-30 07:56:33 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #468: GFLOPs: 580.6806. Time: 6372.1420 us. Best GFLOPs: 772.3500
2024-04-30 07:56:33 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #469: GFLOPs: 528.3427. Time: 7003.3697 us. Best GFLOPs: 772.3500
2024-04-30 07:56:33 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #470: GFLOPs: 564.8458. Time: 6550.7770 us. Best GFLOPs: 772.3500
2024-04-30 07:56:33 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #471: GFLOPs: 137.2289. Time: 26963.5510 us. Best GFLOPs: 772.3500
2024-04-30 07:56:33 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #472: GFLOPs: 710.8146. Time: 5205.5469 us. Best GFLOPs: 772.3500
2024-04-30 07:56:33 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #473: GFLOPs: 515.3909. Time: 7179.3641 us. Best GFLOPs: 772.3500
2024-04-30 07:56:33 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #474: GFLOPs: 8.6774. Time: 426417.3307 us. Best GFLOPs: 772.3500
2024-04-30 07:56:33 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #475: GFLOPs: 483.7285. Time: 7649.2880 us. Best GFLOPs: 772.3500
2024-04-30 07:56:33 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #476: GFLOPs: 621.9437. Time: 5949.3793 us. Best GFLOPs: 772.3500
2024-04-30 07:56:33 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #477: GFLOPs: 652.9767. Time: 5666.6324 us. Best GFLOPs: 772.3500
2024-04-30 07:56:33 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #478: GFLOPs: 106.6907. Time: 34681.3627 us. Best GFLOPs: 772.3500
2024-04-30 07:56:33 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #479: GFLOPs: 328.8925. Time: 11250.4190 us. Best GFLOPs: 772.3500
2024-04-30 07:56:33 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #480: GFLOPs: 534.1250. Time: 6927.5524 us. Best GFLOPs: 772.3500
2024-04-30 07:56:33 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #481: GFLOPs: 546.7299. Time: 6767.8377 us. Best GFLOPs: 772.3500
2024-04-30 07:56:33 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #482: GFLOPs: 411.5840. Time: 8990.0945 us. Best GFLOPs: 772.3500
2024-04-30 07:56:33 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #483: GFLOPs: 470.0940. Time: 7871.1476 us. Best GFLOPs: 772.3500
2024-04-30 07:56:33 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #484: GFLOPs: 529.2121. Time: 6991.8632 us. Best GFLOPs: 772.3500
2024-04-30 07:56:33 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #485: GFLOPs: 514.2875. Time: 7194.7672 us. Best GFLOPs: 772.3500
2024-04-30 07:56:33 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #486: GFLOPs: 8.6418. Time: 428172.4410 us. Best GFLOPs: 772.3500
2024-04-30 07:56:33 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #487: GFLOPs: 419.6499. Time: 8817.2999 us. Best GFLOPs: 772.3500
2024-04-30 07:56:33 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #488: GFLOPs: 495.8995. Time: 7461.5496 us. Best GFLOPs: 772.3500
2024-04-30 07:56:33 [INFO] [task_scheduler.cc:121] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #489: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(512)), "float32"), p1: T.Buffer((T.int64(32), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused in T.parallel(T.int64(224), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(28), T.int64(1), T.int64(16), T.int64(1), T.int64(2), T.int64(1), T.int64(2), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(14) * T.int64(2) + oc_chunk_1 * T.int64(2) + oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(28), oh_1 * T.int64(28) + oh_2_init + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(14) * T.int64(2) + ow_1 * T.int64(2) + ow_2_init * T.int64(2) + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(16), oc_block_1 * T.int64(16) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0 in range(T.int64(64)):
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(30), T.int64(4)):
                        for ax4_fused in T.vectorized(T.int64(8)):
                            with T.block("data_pad"):
                                v_i0, v_i1, v_i2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                                v_i3 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(14) * T.int64(2) + ax3)
                                v_i4 = T.axis.spatial(T.int64(512), ic_0 * T.int64(8) + ax4_fused)
                                T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                                T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                                data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                    for kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(28), T.int64(1), T.int64(16), T.int64(8), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(2), T.int64(1)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(14) * T.int64(2) + oc_chunk_1 * T.int64(2) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(28), oh_1 * T.int64(28) + oh_2 + oh_3)
                            v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(14) * T.int64(2) + ow_1 * T.int64(2) + ow_2 * T.int64(2) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_1 * T.int64(16) + oc_block_2 + oc_block_3)
                            v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(8) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
            for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(2), T.int64(28)):
                for ax3_ax4_fused in T.vectorized(T.int64(32)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(14) * T.int64(2) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(28), ax2)
                        v_ax3 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(14) * T.int64(2) + ax3_ax4_fused // T.int64(16))
                        v_ax4 = T.axis.spatial(T.int64(16), ax3_ax4_fused % T.int64(16))
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[16, 1, 1, 2])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 28, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[14, 1, 1, 2])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 16, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[64, 8])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=10)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86 = sch.get_loops(block=b68)
l87 = sch.fuse(l71, l72, l73, l74, l75, preserve_unit_iters=True)
sch.parallel(loop=l87)
l88 = sch.fuse(l86, preserve_unit_iters=True)
sch.vectorize(loop=l88)
l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107, l108, l109, l110 = sch.get_loops(block=b69)
l111 = sch.fuse(l89, preserve_unit_iters=True)
sch.parallel(loop=l111)
sch.annotate(block_or_loop=l111, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l111, ann_key="pragma_unroll_explicit", ann_val=1)
l112, l113, l114, l115, l116, l117 = sch.get_loops(block=b70)
l118 = sch.fuse(l116, l117, preserve_unit_iters=True)
sch.vectorize(loop=l118)
b119 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141 = sch.get_loops(block=b119)
b142 = sch.decompose_reduction(block=b119, loop=l126)
2024-04-30 07:56:33 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #490: GFLOPs: 145.3433. Time: 25458.2025 us. Best GFLOPs: 772.3500
2024-04-30 07:56:33 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #491: GFLOPs: 539.0537. Time: 6864.2127 us. Best GFLOPs: 772.3500
2024-04-30 07:56:33 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #492: GFLOPs: 543.8853. Time: 6803.2336 us. Best GFLOPs: 772.3500
2024-04-30 07:56:33 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #493: GFLOPs: 614.3286. Time: 6023.1271 us. Best GFLOPs: 772.3500
2024-04-30 07:56:33 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #494: GFLOPs: 362.5412. Time: 10206.2310 us. Best GFLOPs: 772.3500
2024-04-30 07:56:33 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #495: GFLOPs: 421.7696. Time: 8772.9867 us. Best GFLOPs: 772.3500
2024-04-30 07:56:33 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #496: GFLOPs: 563.2653. Time: 6569.1585 us. Best GFLOPs: 772.3500
2024-04-30 07:56:33 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #497: GFLOPs: 121.3205. Time: 30499.2073 us. Best GFLOPs: 772.3500
2024-04-30 07:56:33 [INFO] [task_scheduler.cc:121] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #498: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(512)), "float32"), p1: T.Buffer((T.int64(32), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_fused_fused in T.parallel(T.int64(448), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for oc_block_0 in range(T.int64(1)):
                for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                    for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(14), T.int64(1), T.int64(16), T.int64(1), T.int64(2), T.int64(1), T.int64(2), T.int64(1)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(28) * T.int64(2) + oc_chunk_1 * T.int64(2) + oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(28) // T.int64(14) * T.int64(14) + oh_1 * T.int64(14) + oh_2_init + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(14) * T.int64(2) + ow_1 * T.int64(2) + ow_2_init * T.int64(2) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2_init + oc_block_3_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                    for ic_0 in range(T.int64(64)):
                        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(16), T.int64(4)):
                            for ax4_fused in T.vectorized(T.int64(8)):
                                with T.block("data_pad"):
                                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                                    v_i2 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(28) // T.int64(14) * T.int64(14) + ax2)
                                    v_i3 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(14) * T.int64(2) + ax3)
                                    v_i4 = T.axis.spatial(T.int64(512), ic_0 * T.int64(8) + ax4_fused)
                                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                        for kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(14), T.int64(1), T.int64(16), T.int64(8), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(2), T.int64(1)):
                            with T.block("conv2d_NCHWc_update"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                                v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(28) * T.int64(2) + oc_chunk_1 * T.int64(2) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                                v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(28) // T.int64(14) * T.int64(14) + oh_1 * T.int64(14) + oh_2 + oh_3)
                                v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(14) * T.int64(2) + ow_1 * T.int64(2) + ow_2 * T.int64(2) + ow_3)
                                v_oc_block = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2 + oc_block_3)
                                v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(8) + ic_1)
                                v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                                v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                                T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
                for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(2), T.int64(14)):
                    for ax3_ax4_fused in T.vectorized(T.int64(32)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(28) * T.int64(2) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(28) // T.int64(14) * T.int64(14) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(14) * T.int64(2) + ax3_ax4_fused // T.int64(16))
                            v_ax4 = T.axis.spatial(T.int64(16), ax3_ax4_fused % T.int64(16))
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[16, 1, 1, 2])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 1, 14, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[14, 1, 1, 2])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 16, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[64, 8])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=32)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=10)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86 = sch.get_loops(block=b68)
l87 = sch.fuse(l71, l72, l73, l74, preserve_unit_iters=True)
sch.parallel(loop=l87)
l88 = sch.fuse(l86, preserve_unit_iters=True)
sch.vectorize(loop=l88)
l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107, l108, l109, l110, l111 = sch.get_loops(block=b69)
l112 = sch.fuse(l89, preserve_unit_iters=True)
sch.parallel(loop=l112)
sch.annotate(block_or_loop=l112, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l112, ann_key="pragma_unroll_explicit", ann_val=1)
l113, l114, l115, l116, l117, l118, l119 = sch.get_loops(block=b70)
l120 = sch.fuse(l118, l119, preserve_unit_iters=True)
sch.vectorize(loop=l120)
b121 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141, l142, l143, l144 = sch.get_loops(block=b121)
b145 = sch.decompose_reduction(block=b121, loop=l129)
2024-04-30 07:56:33 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #499: GFLOPs: 566.9450. Time: 6526.5223 us. Best GFLOPs: 772.3500
2024-04-30 07:56:33 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #500: GFLOPs: 420.1829. Time: 8806.1147 us. Best GFLOPs: 772.3500
2024-04-30 07:56:33 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #501: GFLOPs: 9.0373. Time: 409432.0377 us. Best GFLOPs: 772.3500
2024-04-30 07:56:33 [INFO] [task_scheduler.cc:121] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #502: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(512)), "float32"), p1: T.Buffer((T.int64(32), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_fused_fused in T.parallel(T.int64(224), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for oc_block_0 in range(T.int64(1)):
                for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1)):
                    for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(7), T.int64(2), T.int64(16), T.int64(1), T.int64(2), T.int64(2), T.int64(1), T.int64(1)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(14) * T.int64(2) + oc_chunk_1 * T.int64(2) + oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(28), oh_1 * T.int64(14) + oh_2_init * T.int64(2) + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(14) * T.int64(2) + ow_1 * T.int64(2) + ow_2_init + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2_init + oc_block_3_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                    for ic_0, kh_0 in T.grid(T.int64(64), T.int64(3)):
                        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(14), T.int64(4)):
                            for ax4_fused in T.vectorized(T.int64(8)):
                                with T.block("data_pad"):
                                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                                    v_i2 = T.axis.spatial(T.int64(30), kh_0 + oh_1 * T.int64(14) + ax2)
                                    v_i3 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(14) * T.int64(2) + ax3)
                                    v_i4 = T.axis.spatial(T.int64(512), ic_0 * T.int64(8) + ax4_fused)
                                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                        for kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(3), T.int64(1), T.int64(1), T.int64(7), T.int64(2), T.int64(16), T.int64(8), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(2), T.int64(1), T.int64(1)):
                            with T.block("conv2d_NCHWc_update"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                                v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(14) * T.int64(2) + oc_chunk_1 * T.int64(2) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                                v_oh = T.axis.spatial(T.int64(28), oh_1 * T.int64(14) + oh_2 * T.int64(2) + oh_3)
                                v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(14) * T.int64(2) + ow_1 * T.int64(2) + ow_2 + ow_3)
                                v_oc_block = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2 + oc_block_3)
                                v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(8) + ic_1)
                                v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                                v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                                T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
                for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(2), T.int64(28)):
                    for ax3_ax4_fused in T.vectorized(T.int64(32)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(14) * T.int64(2) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(28), ax2)
                            v_ax3 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(14) * T.int64(2) + ax3_ax4_fused // T.int64(16))
                            v_ax4 = T.axis.spatial(T.int64(16), ax3_ax4_fused % T.int64(16))
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[16, 1, 1, 2])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 2, 7, 2])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[14, 1, 2, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 16, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[64, 8])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=16)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=11)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87 = sch.get_loops(block=b68)
l88 = sch.fuse(l71, l72, l73, l74, preserve_unit_iters=True)
sch.parallel(loop=l88)
l89 = sch.fuse(l87, preserve_unit_iters=True)
sch.vectorize(loop=l89)
l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107, l108, l109, l110, l111, l112 = sch.get_loops(block=b69)
l113 = sch.fuse(l90, preserve_unit_iters=True)
sch.parallel(loop=l113)
sch.annotate(block_or_loop=l113, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l113, ann_key="pragma_unroll_explicit", ann_val=1)
l114, l115, l116, l117, l118, l119, l120 = sch.get_loops(block=b70)
l121 = sch.fuse(l119, l120, preserve_unit_iters=True)
sch.vectorize(loop=l121)
b122 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141, l142, l143, l144, l145 = sch.get_loops(block=b122)
b146 = sch.decompose_reduction(block=b122, loop=l130)
2024-04-30 07:56:33 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #503: GFLOPs: 244.2907. Time: 15146.6219 us. Best GFLOPs: 772.3500
2024-04-30 07:56:33 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #504: GFLOPs: 528.1718. Time: 7005.6351 us. Best GFLOPs: 772.3500
2024-04-30 07:56:33 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #505: GFLOPs: 291.0282. Time: 12714.1610 us. Best GFLOPs: 772.3500
2024-04-30 07:56:33 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #506: GFLOPs: 510.1525. Time: 7253.0846 us. Best GFLOPs: 772.3500
2024-04-30 07:56:33 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #507: GFLOPs: 417.7697. Time: 8856.9823 us. Best GFLOPs: 772.3500
2024-04-30 07:56:33 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #508: GFLOPs: 484.3756. Time: 7639.0692 us. Best GFLOPs: 772.3500
2024-04-30 07:56:33 [INFO] [task_scheduler.cc:121] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #509: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(512)), "float32"), p1: T.Buffer((T.int64(32), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused in T.parallel(T.int64(224), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(14), T.int64(1), T.int64(16), T.int64(1), T.int64(2), T.int64(2), T.int64(2), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(14) * T.int64(2) + oc_chunk_1 * T.int64(2) + oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(28), oh_1 * T.int64(28) + oh_2_init * T.int64(2) + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(14) * T.int64(2) + ow_1 * T.int64(2) + ow_2_init * T.int64(2) + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(16), oc_block_1 * T.int64(16) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0 in T.grid(T.int64(128), T.int64(3)):
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(28), T.int64(4)):
                        for ax4_fused in T.vectorized(T.int64(4)):
                            with T.block("data_pad"):
                                v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                                v_i2 = T.axis.spatial(T.int64(30), kh_0 + ax2)
                                v_i3 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(14) * T.int64(2) + ax3)
                                v_i4 = T.axis.spatial(T.int64(512), ic_0 * T.int64(4) + ax4_fused)
                                T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                                T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                                data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                    for kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(3), T.int64(1), T.int64(1), T.int64(14), T.int64(1), T.int64(16), T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(2), T.int64(2), T.int64(1)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(14) * T.int64(2) + oc_chunk_1 * T.int64(2) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(28), oh_1 * T.int64(28) + oh_2 * T.int64(2) + oh_3)
                            v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(14) * T.int64(2) + ow_1 * T.int64(2) + ow_2 * T.int64(2) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_1 * T.int64(16) + oc_block_2 + oc_block_3)
                            v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(4) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
            for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(2), T.int64(28)):
                for ax3_ax4_fused in T.vectorized(T.int64(32)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(14) * T.int64(2) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(28), ax2)
                        v_ax3 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(14) * T.int64(2) + ax3_ax4_fused // T.int64(16))
                        v_ax4 = T.axis.spatial(T.int64(16), ax3_ax4_fused % T.int64(16))
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[16, 1, 1, 2])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 14, 2])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[14, 1, 1, 2])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 16, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[128, 4])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=11)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87 = sch.get_loops(block=b68)
l88 = sch.fuse(l71, l72, l73, l74, l75, preserve_unit_iters=True)
sch.parallel(loop=l88)
l89 = sch.fuse(l87, preserve_unit_iters=True)
sch.vectorize(loop=l89)
l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107, l108, l109, l110, l111 = sch.get_loops(block=b69)
l112 = sch.fuse(l90, preserve_unit_iters=True)
sch.parallel(loop=l112)
sch.annotate(block_or_loop=l112, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l112, ann_key="pragma_unroll_explicit", ann_val=1)
l113, l114, l115, l116, l117, l118 = sch.get_loops(block=b70)
l119 = sch.fuse(l117, l118, preserve_unit_iters=True)
sch.vectorize(loop=l119)
b120 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141, l142 = sch.get_loops(block=b120)
b143 = sch.decompose_reduction(block=b120, loop=l127)
2024-04-30 07:56:33 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #510: GFLOPs: 31.3224. Time: 118131.8920 us. Best GFLOPs: 772.3500
2024-04-30 07:56:33 [INFO] [task_scheduler.cc:121] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #511: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(512)), "float32"), p1: T.Buffer((T.int64(32), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)))
        for n_0_oc_chunk_0_fused_fused in T.parallel(T.int64(2), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(512)):
                with T.block("data_pad"):
                    v_i0, v_i1, v_i2, v_i3, v_i4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oh_0, ow_0, oc_block_0, n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(7), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(8)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(8), T.int64(14), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(2), T.int64(1)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(2)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_fused_fused * T.int64(16) + oc_chunk_1 * T.int64(16) + oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(28), oh_0 * T.int64(28) + oh_1 * T.int64(28) + oh_2_init * T.int64(2) + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(28), ow_0 * T.int64(4) + ow_1 + ow_2_init + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(16) + oc_block_1 * T.int64(2) + oc_block_2_init * T.int64(2) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(8), T.int64(3), T.int64(3), T.int64(1), T.int64(8), T.int64(14), T.int64(1), T.int64(1), T.int64(64), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(2), T.int64(1)):
                    for oc_block_3_fused in T.vectorized(T.int64(2)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_fused_fused * T.int64(16) + oc_chunk_1 * T.int64(16) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(28), oh_0 * T.int64(28) + oh_1 * T.int64(28) + oh_2 * T.int64(2) + oh_3)
                            v_ow = T.axis.spatial(T.int64(28), ow_0 * T.int64(4) + ow_1 + ow_2 + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(16) + oc_block_1 * T.int64(2) + oc_block_2 * T.int64(2) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(64) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(16), T.int64(28), T.int64(1)):
                    for ax4_fused in T.vectorized(T.int64(2)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_fused_fused * T.int64(16) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(28), ax2)
                            v_ax3 = T.axis.spatial(T.int64(28), ow_0 * T.int64(4) + ow_1 + ax3)
                            v_ax4 = T.axis.spatial(T.int64(16), oc_block_1 * T.int64(2) + ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[2, 1, 8, 2])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 14, 2])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[7, 4, 1, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 8, 1, 2])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[8, 64])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=1)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77 = sch.get_loops(block=b68)
l78 = sch.fuse(l71, l72, preserve_unit_iters=True)
sch.parallel(loop=l78)
l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l79, preserve_unit_iters=True)
sch.parallel(loop=l104)
l105 = sch.fuse(l103, preserve_unit_iters=True)
sch.vectorize(loop=l105)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l106, l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117, l118, l119 = sch.get_loops(block=b70)
l120 = sch.fuse(l119, preserve_unit_iters=True)
sch.vectorize(loop=l120)
b121 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141, l142, l143, l144, l145, l146 = sch.get_loops(block=b121)
b147 = sch.decompose_reduction(block=b121, loop=l131)
2024-04-30 07:56:33 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #512: GFLOPs: 21.3390. Time: 173400.0540 us. Best GFLOPs: 772.3500
2024-04-30 08:08:09 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-30 08:08:10 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-30 08:08:14 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 08:08:14 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-30 08:08:27 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 08:08:41 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 08:08:55 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 08:09:09 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 08:09:18 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9247  0.8827  0.8812  0.8790  0.8713  0.8713  0.8437  0.8306  0.8266  0.8092  0.8092  0.8087  0.8032  0.8020  0.7966  0.7924
[17 : 32]:	0.7733  0.7726  0.7641  0.7560  0.7473  0.7473  0.7448  0.7437  0.7350  0.7322  0.7300  0.7252  0.7243  0.7226  0.7198  0.7182
[33 : 48]:	0.7177  0.7177  0.7167  0.7166  0.7128  0.7100  0.7083  0.7076  0.7045  0.7045  0.6981  0.6967  0.6922  0.6920  0.6914  0.6911
[49 : 64]:	0.6907  0.6875  0.6855  0.6849  0.6814  0.6808  0.6786  0.6780  0.6728  0.6728  0.6682  0.6648  0.6644  0.6641  0.6584  0.6584
2024-04-30 08:09:19 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-30 08:09:19 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-30 08:11:36 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #513: GFLOPs: 775.5313. Time: 4771.1538 us. Best GFLOPs: 775.5313
2024-04-30 08:11:36 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #514: GFLOPs: 855.7932. Time: 4323.6834 us. Best GFLOPs: 855.7932
2024-04-30 08:11:36 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #515: GFLOPs: 714.1609. Time: 5181.1560 us. Best GFLOPs: 855.7932
2024-04-30 08:11:36 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #516: GFLOPs: 718.2458. Time: 5151.6889 us. Best GFLOPs: 855.7932
2024-04-30 08:11:36 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #517: GFLOPs: 700.2542. Time: 5284.0512 us. Best GFLOPs: 855.7932
2024-04-30 08:11:36 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #518: GFLOPs: 628.8798. Time: 5883.7616 us. Best GFLOPs: 855.7932
2024-04-30 08:11:36 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #519: GFLOPs: 671.0135. Time: 5514.3137 us. Best GFLOPs: 855.7932
2024-04-30 08:11:36 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #520: GFLOPs: 610.6767. Time: 6059.1452 us. Best GFLOPs: 855.7932
2024-04-30 08:11:36 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #521: GFLOPs: 671.5116. Time: 5510.2231 us. Best GFLOPs: 855.7932
2024-04-30 08:11:36 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #522: GFLOPs: 650.4844. Time: 5688.3438 us. Best GFLOPs: 855.7932
2024-04-30 08:11:36 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #523: GFLOPs: 344.4755. Time: 10741.4855 us. Best GFLOPs: 855.7932
2024-04-30 08:11:36 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #524: GFLOPs: 676.1928. Time: 5472.0766 us. Best GFLOPs: 855.7932
2024-04-30 08:11:36 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #525: GFLOPs: 611.9844. Time: 6046.1985 us. Best GFLOPs: 855.7932
2024-04-30 08:11:36 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #526: GFLOPs: 610.1438. Time: 6064.4376 us. Best GFLOPs: 855.7932
2024-04-30 08:11:36 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #527: GFLOPs: 721.7368. Time: 5126.7706 us. Best GFLOPs: 855.7932
2024-04-30 08:11:36 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #528: GFLOPs: 762.4474. Time: 4853.0286 us. Best GFLOPs: 855.7932
2024-04-30 08:11:36 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #529: GFLOPs: 622.7166. Time: 5941.9949 us. Best GFLOPs: 855.7932
2024-04-30 08:11:36 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #530: GFLOPs: 667.1511. Time: 5546.2385 us. Best GFLOPs: 855.7932
2024-04-30 08:11:36 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #531: GFLOPs: 676.0902. Time: 5472.9072 us. Best GFLOPs: 855.7932
2024-04-30 08:11:36 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #532: GFLOPs: 525.5742. Time: 7040.2595 us. Best GFLOPs: 855.7932
2024-04-30 08:11:36 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #533: GFLOPs: 689.7703. Time: 5364.3637 us. Best GFLOPs: 855.7932
2024-04-30 08:11:36 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #534: GFLOPs: 685.6391. Time: 5396.6864 us. Best GFLOPs: 855.7932
2024-04-30 08:11:36 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #535: GFLOPs: 572.0263. Time: 6468.5473 us. Best GFLOPs: 855.7932
2024-04-30 08:11:36 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #536: GFLOPs: 571.7771. Time: 6471.3661 us. Best GFLOPs: 855.7932
2024-04-30 08:11:36 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #537: GFLOPs: 81.8039. Time: 45232.2943 us. Best GFLOPs: 855.7932
2024-04-30 08:11:36 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #538: GFLOPs: 599.1510. Time: 6175.7037 us. Best GFLOPs: 855.7932
2024-04-30 08:11:36 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #539: GFLOPs: 565.0903. Time: 6547.9424 us. Best GFLOPs: 855.7932
2024-04-30 08:11:36 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #540: GFLOPs: 81.5029. Time: 45399.3337 us. Best GFLOPs: 855.7932
2024-04-30 08:11:36 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #541: GFLOPs: 528.2548. Time: 7004.5343 us. Best GFLOPs: 855.7932
2024-04-30 08:11:36 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #542: GFLOPs: 660.8077. Time: 5599.4789 us. Best GFLOPs: 855.7932
2024-04-30 08:11:36 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #543: GFLOPs: 76.0085. Time: 48681.1237 us. Best GFLOPs: 855.7932
2024-04-30 08:11:36 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #544: GFLOPs: 545.0524. Time: 6788.6666 us. Best GFLOPs: 855.7932
2024-04-30 08:11:36 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #545: GFLOPs: 76.4274. Time: 48414.2890 us. Best GFLOPs: 855.7932
2024-04-30 08:11:36 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #546: GFLOPs: 76.4431. Time: 48404.3257 us. Best GFLOPs: 855.7932
2024-04-30 08:11:36 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #547: GFLOPs: 141.0591. Time: 26231.4077 us. Best GFLOPs: 855.7932
2024-04-30 08:11:36 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #548: GFLOPs: 539.6682. Time: 6856.3957 us. Best GFLOPs: 855.7932
2024-04-30 08:11:36 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #549: GFLOPs: 585.8962. Time: 6315.4172 us. Best GFLOPs: 855.7932
2024-04-30 08:11:36 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #550: GFLOPs: 553.5251. Time: 6684.7541 us. Best GFLOPs: 855.7932
2024-04-30 08:11:36 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #551: GFLOPs: 568.5005. Time: 6508.6647 us. Best GFLOPs: 855.7932
2024-04-30 08:11:36 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #552: GFLOPs: 74.2359. Time: 49843.5073 us. Best GFLOPs: 855.7932
2024-04-30 08:11:36 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #553: GFLOPs: 138.6319. Time: 26690.6785 us. Best GFLOPs: 855.7932
2024-04-30 08:11:36 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #554: GFLOPs: 139.3365. Time: 26555.6960 us. Best GFLOPs: 855.7932
2024-04-30 08:11:36 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #555: GFLOPs: 140.0640. Time: 26417.7663 us. Best GFLOPs: 855.7932
2024-04-30 08:11:36 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #556: GFLOPs: 582.0395. Time: 6357.2642 us. Best GFLOPs: 855.7932
2024-04-30 08:11:36 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #557: GFLOPs: 74.2571. Time: 49829.3137 us. Best GFLOPs: 855.7932
2024-04-30 08:11:36 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #558: GFLOPs: 76.0530. Time: 48652.6300 us. Best GFLOPs: 855.7932
2024-04-30 08:11:36 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #559: GFLOPs: 746.0913. Time: 4959.4185 us. Best GFLOPs: 855.7932
2024-04-30 08:11:36 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #560: GFLOPs: 478.3120. Time: 7735.9112 us. Best GFLOPs: 855.7932
2024-04-30 08:11:36 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #561: GFLOPs: 75.8738. Time: 48767.5520 us. Best GFLOPs: 855.7932
2024-04-30 08:11:36 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #562: GFLOPs: 208.0795. Time: 17782.5270 us. Best GFLOPs: 855.7932
2024-04-30 08:11:36 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #563: GFLOPs: 79.9956. Time: 46254.7787 us. Best GFLOPs: 855.7932
2024-04-30 08:11:36 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #564: GFLOPs: 540.8736. Time: 6841.1161 us. Best GFLOPs: 855.7932
2024-04-30 08:11:36 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #565: GFLOPs: 520.7088. Time: 7106.0420 us. Best GFLOPs: 855.7932
2024-04-30 08:11:36 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #566: GFLOPs: 474.7976. Time: 7793.1715 us. Best GFLOPs: 855.7932
2024-04-30 08:11:36 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #567: GFLOPs: 526.2438. Time: 7031.3021 us. Best GFLOPs: 855.7932
2024-04-30 08:11:36 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #568: GFLOPs: 82.4077. Time: 44900.8820 us. Best GFLOPs: 855.7932
2024-04-30 08:11:36 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #569: GFLOPs: 660.3514. Time: 5603.3484 us. Best GFLOPs: 855.7932
2024-04-30 08:11:36 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #570: GFLOPs: 656.9818. Time: 5632.0873 us. Best GFLOPs: 855.7932
2024-04-30 08:11:36 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #571: GFLOPs: 520.2008. Time: 7112.9821 us. Best GFLOPs: 855.7932
2024-04-30 08:11:36 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #572: GFLOPs: 135.6217. Time: 27283.0910 us. Best GFLOPs: 855.7932
2024-04-30 08:11:36 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #573: GFLOPs: 104.4149. Time: 35437.2650 us. Best GFLOPs: 855.7932
2024-04-30 08:11:36 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #574: GFLOPs: 1.7202. Time: 2151070.7047 us. Best GFLOPs: 855.7932
2024-04-30 08:11:36 [INFO] [task_scheduler.cc:121] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #575: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(512)), "float32"), p1: T.Buffer((T.int64(32), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_fused_fused in T.parallel(T.int64(32), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(9), T.int64(9), T.int64(512)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(16) // T.int64(4) * T.int64(7) + ax2)
                    v_i3 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(4) * T.int64(7) + ax3)
                    v_i4 = T.axis.spatial(T.int64(512), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oc_block_0 in range(T.int64(1)):
                for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1)):
                    for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(8), T.int64(7), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                        for oc_block_3_fused_init in T.vectorized(T.int64(8)):
                            with T.block("conv2d_NCHWc_init"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                                v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(16) * T.int64(16) + oc_chunk_1 * T.int64(8) + oc_chunk_2_init + oc_chunk_3_init)
                                v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(16) // T.int64(4) * T.int64(7) + oh_1 * T.int64(7) + oh_2_init + oh_3_init)
                                v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(4) * T.int64(7) + ow_1 * T.int64(7) + ow_2_init * T.int64(7) + ow_3_init)
                                v_oc_block = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2_init * T.int64(8) + oc_block_3_fused_init)
                                T.reads()
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                    for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(8), T.int64(1), T.int64(1), T.int64(1), T.int64(8), T.int64(7), T.int64(1), T.int64(2), T.int64(64), T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                        for oc_block_3_fused in T.vectorized(T.int64(8)):
                            with T.block("conv2d_NCHWc_update"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                                v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(16) * T.int64(16) + oc_chunk_1 * T.int64(8) + oc_chunk_2 + oc_chunk_3)
                                v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(16) // T.int64(4) * T.int64(7) + oh_1 * T.int64(7) + oh_2 + oh_3)
                                v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(4) * T.int64(7) + ow_1 * T.int64(7) + ow_2 * T.int64(7) + ow_3)
                                v_oc_block = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2 * T.int64(8) + oc_block_3_fused)
                                v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(64) + ic_1)
                                v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                                v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                                T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(16), T.int64(7), T.int64(7)):
                    for ax4_fused in T.vectorized(T.int64(16)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(16) * T.int64(16) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(16) // T.int64(4) * T.int64(7) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(4) * T.int64(7) + ax3)
                            v_ax4 = T.axis.spatial(T.int64(16), ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[2, 2, 8, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[4, 1, 7, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[4, 1, 1, 7])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 2, 8])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[8, 64])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=3)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79 = sch.get_loops(block=b68)
l80 = sch.fuse(l71, l72, l73, l74, preserve_unit_iters=True)
sch.parallel(loop=l80)
l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l81, preserve_unit_iters=True)
sch.parallel(loop=l104)
l105 = sch.fuse(l103, preserve_unit_iters=True)
sch.vectorize(loop=l105)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l106, l107, l108, l109, l110, l111, l112 = sch.get_loops(block=b70)
l113 = sch.fuse(l112, preserve_unit_iters=True)
sch.vectorize(loop=l113)
b114 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137 = sch.get_loops(block=b114)
b138 = sch.decompose_reduction(block=b114, loop=l122)
2024-04-30 08:11:36 [INFO] [task_scheduler.cc:121] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #576: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(512)), "float32"), p1: T.Buffer((T.int64(32), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused in T.parallel(T.int64(64), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(30), T.int64(9), T.int64(512)):
                with T.block("data_pad"):
                    v_i0, v_i1, v_i2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                    v_i3 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(16) // T.int64(4) * T.int64(7) + ax3)
                    v_i4 = T.axis.spatial(T.int64(512), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oh_1, ow_1, oc_block_1 in T.grid(T.int64(2), T.int64(7), T.int64(4)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(2), T.int64(2), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(7), T.int64(1)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(2)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(16) * T.int64(8) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(4) * T.int64(2) + oc_chunk_2_init + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(28), oh_1 * T.int64(14) + oh_2_init * T.int64(7) + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(16) // T.int64(4) * T.int64(7) + ow_1 + ow_2_init + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_1 * T.int64(4) + oc_block_2_init * T.int64(2) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(8), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(2), T.int64(1), T.int64(2), T.int64(64), T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(7), T.int64(1)):
                    for oc_block_3_fused in T.vectorized(T.int64(2)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(16) * T.int64(8) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(4) * T.int64(2) + oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(28), oh_1 * T.int64(14) + oh_2 * T.int64(7) + oh_3)
                            v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(16) // T.int64(4) * T.int64(7) + ow_1 + ow_2 + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_1 * T.int64(4) + oc_block_2 * T.int64(2) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(64) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
        for ax0_ax1_ax2_ax3_ax4_fused_0 in T.parallel(T.int64(6272)):
            for ax0_ax1_ax2_ax3_ax4_fused_1 in T.vectorized(T.int64(64)):
                with T.block("T_relu"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) // T.int64(12544))
                    v_ax2 = T.axis.spatial(T.int64(28), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(12544) // T.int64(448))
                    v_ax3 = T.axis.spatial(T.int64(28), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(448) // T.int64(16))
                    v_ax4 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(16))
                    T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                    T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[4, 4, 2, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 2, 2, 7])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[4, 7, 1, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 4, 2, 2])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[8, 64])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
l65 = sch.sample_compute_location(block=b0, decision=6)
sch.compute_at(block=b0, loop=l65, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b66 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.unroll_explicit")
b67, b68, b69 = sch.get_child_blocks(b66)
l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81 = sch.get_loops(block=b67)
l82 = sch.fuse(l70, l71, l72, l73, l74, l75, l76, preserve_unit_iters=True)
sch.parallel(loop=l82)
l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102 = sch.get_loops(block=b68)
l103 = sch.fuse(l83, preserve_unit_iters=True)
sch.parallel(loop=l103)
l104 = sch.fuse(l102, preserve_unit_iters=True)
sch.vectorize(loop=l104)
sch.annotate(block_or_loop=l103, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l103, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109 = sch.get_loops(block=b69)
l110 = sch.fuse(l105, l106, l107, l108, l109, preserve_unit_iters=True)
l111, l112 = sch.split(loop=l110, factors=[None, 64], preserve_unit_iters=True)
sch.parallel(loop=l111)
sch.vectorize(loop=l112)
b113 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133 = sch.get_loops(block=b113)
b134 = sch.decompose_reduction(block=b113, loop=l118)
2024-04-30 08:15:04 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-30 08:15:05 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-30 08:15:10 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 08:15:10 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-30 08:15:23 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 08:15:37 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 08:15:51 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 08:16:05 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 08:16:14 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.8267  0.7871  0.7852  0.7689  0.7439  0.7234  0.7159  0.7104  0.7104  0.7015  0.7014  0.6948  0.6874  0.6840  0.6785  0.6779
[17 : 32]:	0.6739  0.6704  0.6704  0.6673  0.6586  0.6546  0.6543  0.6480  0.6401  0.6277  0.6275  0.6266  0.6233  0.6219  0.6214  0.6159
[33 : 48]:	0.6157  0.6152  0.6118  0.6023  0.6023  0.6016  0.5995  0.5961  0.5932  0.5928  0.5875  0.5873  0.5873  0.5857  0.5857  0.5852
[49 : 64]:	0.5831  0.5830  0.5826  0.5825  0.5814  0.5803  0.5803  0.5791  0.5781  0.5767  0.5767  0.5765  0.5764  0.5718  0.5703  0.5690
2024-04-30 08:16:14 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-30 08:16:15 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-30 08:18:09 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #577: GFLOPs: 907.1550. Time: 4078.8828 us. Best GFLOPs: 907.1550
2024-04-30 08:18:09 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #578: GFLOPs: 649.3715. Time: 5698.0928 us. Best GFLOPs: 907.1550
2024-04-30 08:18:09 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #579: GFLOPs: 816.0858. Time: 4534.0562 us. Best GFLOPs: 907.1550
2024-04-30 08:18:09 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #580: GFLOPs: 412.0035. Time: 8980.9406 us. Best GFLOPs: 907.1550
2024-04-30 08:18:09 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #581: GFLOPs: 625.6618. Time: 5914.0244 us. Best GFLOPs: 907.1550
2024-04-30 08:18:09 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #582: GFLOPs: 615.0943. Time: 6015.6285 us. Best GFLOPs: 907.1550
2024-04-30 08:18:09 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #583: GFLOPs: 726.6749. Time: 5091.9318 us. Best GFLOPs: 907.1550
2024-04-30 08:18:09 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #584: GFLOPs: 668.2279. Time: 5537.3008 us. Best GFLOPs: 907.1550
2024-04-30 08:18:09 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #585: GFLOPs: 714.9104. Time: 5175.7238 us. Best GFLOPs: 907.1550
2024-04-30 08:18:09 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #586: GFLOPs: 632.0308. Time: 5854.4283 us. Best GFLOPs: 907.1550
2024-04-30 08:18:09 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #587: GFLOPs: 538.8406. Time: 6866.9271 us. Best GFLOPs: 907.1550
2024-04-30 08:18:09 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #588: GFLOPs: 448.6980. Time: 8246.4792 us. Best GFLOPs: 907.1550
2024-04-30 08:18:09 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #589: GFLOPs: 656.0839. Time: 5639.7951 us. Best GFLOPs: 907.1550
2024-04-30 08:18:09 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #590: GFLOPs: 124.5778. Time: 29701.7600 us. Best GFLOPs: 907.1550
2024-04-30 08:18:09 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #591: GFLOPs: 587.7355. Time: 6295.6536 us. Best GFLOPs: 907.1550
2024-04-30 08:18:09 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #592: GFLOPs: 591.5371. Time: 6255.1938 us. Best GFLOPs: 907.1550
2024-04-30 08:18:09 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #593: GFLOPs: 572.1483. Time: 6467.1679 us. Best GFLOPs: 907.1550
2024-04-30 08:18:09 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #594: GFLOPs: 486.8881. Time: 7599.6490 us. Best GFLOPs: 907.1550
2024-04-30 08:18:09 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #595: GFLOPs: 463.2748. Time: 7987.0063 us. Best GFLOPs: 907.1550
2024-04-30 08:18:09 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #596: GFLOPs: 603.9146. Time: 6126.9904 us. Best GFLOPs: 907.1550
2024-04-30 08:18:09 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #597: GFLOPs: 799.9919. Time: 4625.2707 us. Best GFLOPs: 907.1550
2024-04-30 08:18:09 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #598: GFLOPs: 456.1599. Time: 8111.5831 us. Best GFLOPs: 907.1550
2024-04-30 08:18:09 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #599: GFLOPs: 362.1306. Time: 10217.8038 us. Best GFLOPs: 907.1550
2024-04-30 08:18:09 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #600: GFLOPs: 565.1055. Time: 6547.7667 us. Best GFLOPs: 907.1550
2024-04-30 08:18:09 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #601: GFLOPs: 403.0592. Time: 9180.2375 us. Best GFLOPs: 907.1550
2024-04-30 08:18:09 [INFO] [task_scheduler.cc:121] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #602: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(512)), "float32"), p1: T.Buffer((T.int64(32), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused in T.parallel(T.int64(224), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(7), T.int64(2), T.int64(16), T.int64(1), T.int64(2), T.int64(2), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(14) * T.int64(2) + oc_chunk_1 * T.int64(2) + oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(28), oh_1 * T.int64(14) + oh_2_init * T.int64(2) + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(14) * T.int64(2) + ow_1 * T.int64(2) + ow_2_init + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(16), oc_block_1 * T.int64(16) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0 in range(T.int64(64)):
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(16), T.int64(4)):
                        for ax4_fused in T.vectorized(T.int64(8)):
                            with T.block("data_pad"):
                                v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                                v_i2 = T.axis.spatial(T.int64(30), oh_1 * T.int64(14) + ax2)
                                v_i3 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(14) * T.int64(2) + ax3)
                                v_i4 = T.axis.spatial(T.int64(512), ic_0 * T.int64(8) + ax4_fused)
                                T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                                T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                                data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                    for kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(7), T.int64(2), T.int64(16), T.int64(8), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(2), T.int64(1), T.int64(1)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(14) * T.int64(2) + oc_chunk_1 * T.int64(2) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(28), oh_1 * T.int64(14) + oh_2 * T.int64(2) + oh_3)
                            v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(14) * T.int64(2) + ow_1 * T.int64(2) + ow_2 + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_1 * T.int64(16) + oc_block_2 + oc_block_3)
                            v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(8) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
            for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(2), T.int64(28)):
                for ax3_ax4_fused in T.vectorized(T.int64(32)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(14) * T.int64(2) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(28), ax2)
                        v_ax3 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(14) * T.int64(2) + ax3_ax4_fused // T.int64(16))
                        v_ax4 = T.axis.spatial(T.int64(16), ax3_ax4_fused % T.int64(16))
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[16, 1, 1, 2])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 2, 7, 2])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[14, 1, 2, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 16, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[64, 8])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=10)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86 = sch.get_loops(block=b68)
l87 = sch.fuse(l71, l72, l73, l74, l75, preserve_unit_iters=True)
sch.parallel(loop=l87)
l88 = sch.fuse(l86, preserve_unit_iters=True)
sch.vectorize(loop=l88)
l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107, l108, l109, l110 = sch.get_loops(block=b69)
l111 = sch.fuse(l89, preserve_unit_iters=True)
sch.parallel(loop=l111)
sch.annotate(block_or_loop=l111, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l111, ann_key="pragma_unroll_explicit", ann_val=1)
l112, l113, l114, l115, l116, l117 = sch.get_loops(block=b70)
l118 = sch.fuse(l116, l117, preserve_unit_iters=True)
sch.vectorize(loop=l118)
b119 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141 = sch.get_loops(block=b119)
b142 = sch.decompose_reduction(block=b119, loop=l126)
2024-04-30 08:18:09 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #603: GFLOPs: 646.4604. Time: 5723.7516 us. Best GFLOPs: 907.1550
2024-04-30 08:18:09 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #604: GFLOPs: 482.8607. Time: 7663.0365 us. Best GFLOPs: 907.1550
2024-04-30 08:18:09 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #605: GFLOPs: 139.3803. Time: 26547.3505 us. Best GFLOPs: 907.1550
2024-04-30 08:18:09 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #606: GFLOPs: 638.7208. Time: 5793.1088 us. Best GFLOPs: 907.1550
2024-04-30 08:18:09 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #607: GFLOPs: 485.7696. Time: 7617.1486 us. Best GFLOPs: 907.1550
2024-04-30 08:18:09 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #608: GFLOPs: 634.8955. Time: 5828.0122 us. Best GFLOPs: 907.1550
2024-04-30 08:18:09 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #609: GFLOPs: 365.7052. Time: 10117.9275 us. Best GFLOPs: 907.1550
2024-04-30 08:18:09 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #610: GFLOPs: 611.6983. Time: 6049.0256 us. Best GFLOPs: 907.1550
2024-04-30 08:18:09 [INFO] [task_scheduler.cc:121] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #611: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(512)), "float32"), p1: T.Buffer((T.int64(32), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused in T.parallel(T.int64(224), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(14), T.int64(2), T.int64(16), T.int64(1), T.int64(2), T.int64(2), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(14) * T.int64(2) + oc_chunk_1 * T.int64(2) + oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(28), oh_1 * T.int64(28) + oh_2_init * T.int64(2) + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(14) * T.int64(2) + ow_1 * T.int64(2) + ow_2_init + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(16), oc_block_1 * T.int64(16) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0 in T.grid(T.int64(64), T.int64(3)):
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(28), T.int64(4)):
                        for ax4_fused in T.vectorized(T.int64(8)):
                            with T.block("data_pad"):
                                v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                                v_i2 = T.axis.spatial(T.int64(30), kh_0 + ax2)
                                v_i3 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(14) * T.int64(2) + ax3)
                                v_i4 = T.axis.spatial(T.int64(512), ic_0 * T.int64(8) + ax4_fused)
                                T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                                T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                                data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                    for kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(3), T.int64(1), T.int64(1), T.int64(14), T.int64(2), T.int64(16), T.int64(8), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(2), T.int64(1), T.int64(1)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(14) * T.int64(2) + oc_chunk_1 * T.int64(2) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(28), oh_1 * T.int64(28) + oh_2 * T.int64(2) + oh_3)
                            v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(14) * T.int64(2) + ow_1 * T.int64(2) + ow_2 + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_1 * T.int64(16) + oc_block_2 + oc_block_3)
                            v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(8) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
            for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(2), T.int64(28)):
                for ax3_ax4_fused in T.vectorized(T.int64(32)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(14) * T.int64(2) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(28), ax2)
                        v_ax3 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(14) * T.int64(2) + ax3_ax4_fused // T.int64(16))
                        v_ax4 = T.axis.spatial(T.int64(16), ax3_ax4_fused % T.int64(16))
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[16, 1, 1, 2])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 14, 2])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[14, 1, 2, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 16, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[64, 8])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=11)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87 = sch.get_loops(block=b68)
l88 = sch.fuse(l71, l72, l73, l74, l75, preserve_unit_iters=True)
sch.parallel(loop=l88)
l89 = sch.fuse(l87, preserve_unit_iters=True)
sch.vectorize(loop=l89)
l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107, l108, l109, l110, l111 = sch.get_loops(block=b69)
l112 = sch.fuse(l90, preserve_unit_iters=True)
sch.parallel(loop=l112)
sch.annotate(block_or_loop=l112, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l112, ann_key="pragma_unroll_explicit", ann_val=1)
l113, l114, l115, l116, l117, l118 = sch.get_loops(block=b70)
l119 = sch.fuse(l117, l118, preserve_unit_iters=True)
sch.vectorize(loop=l119)
b120 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141, l142 = sch.get_loops(block=b120)
b143 = sch.decompose_reduction(block=b120, loop=l127)
2024-04-30 08:18:09 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #612: GFLOPs: 530.9161. Time: 6969.4229 us. Best GFLOPs: 907.1550
2024-04-30 08:18:09 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #613: GFLOPs: 483.4148. Time: 7654.2528 us. Best GFLOPs: 907.1550
2024-04-30 08:18:09 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #614: GFLOPs: 537.8512. Time: 6879.5593 us. Best GFLOPs: 907.1550
2024-04-30 08:18:09 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #615: GFLOPs: 516.1397. Time: 7168.9484 us. Best GFLOPs: 907.1550
2024-04-30 08:18:09 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #616: GFLOPs: 528.4254. Time: 7002.2728 us. Best GFLOPs: 907.1550
2024-04-30 08:18:09 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #617: GFLOPs: 58.0613. Time: 63728.8497 us. Best GFLOPs: 907.1550
2024-04-30 08:18:09 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #618: GFLOPs: 126.9847. Time: 29138.7777 us. Best GFLOPs: 907.1550
2024-04-30 08:18:09 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #619: GFLOPs: 386.7874. Time: 9566.4415 us. Best GFLOPs: 907.1550
2024-04-30 08:18:09 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #620: GFLOPs: 528.8117. Time: 6997.1575 us. Best GFLOPs: 907.1550
2024-04-30 08:18:09 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #621: GFLOPs: 541.2868. Time: 6835.8940 us. Best GFLOPs: 907.1550
2024-04-30 08:18:09 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #622: GFLOPs: 628.4594. Time: 5887.6981 us. Best GFLOPs: 907.1550
2024-04-30 08:18:09 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #623: GFLOPs: 642.8347. Time: 5756.0349 us. Best GFLOPs: 907.1550
2024-04-30 08:18:09 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #624: GFLOPs: 714.1011. Time: 5181.5899 us. Best GFLOPs: 907.1550
2024-04-30 08:18:09 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #625: GFLOPs: 92.2605. Time: 40105.7553 us. Best GFLOPs: 907.1550
2024-04-30 08:18:09 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #626: GFLOPs: 467.1563. Time: 7920.6444 us. Best GFLOPs: 907.1550
2024-04-30 08:18:09 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #627: GFLOPs: 103.7821. Time: 35653.3350 us. Best GFLOPs: 907.1550
2024-04-30 08:18:09 [INFO] [task_scheduler.cc:121] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #628: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(512)), "float32"), p1: T.Buffer((T.int64(32), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused in T.parallel(T.int64(224), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(7), T.int64(2), T.int64(16), T.int64(1), T.int64(2), T.int64(2), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(14) * T.int64(2) + oc_chunk_1 * T.int64(2) + oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(28), oh_1 * T.int64(14) + oh_2_init * T.int64(2) + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(14) * T.int64(2) + ow_1 * T.int64(2) + ow_2_init + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(16), oc_block_1 * T.int64(16) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0 in T.grid(T.int64(64), T.int64(3)):
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(14), T.int64(4)):
                        for ax4_fused in T.vectorized(T.int64(8)):
                            with T.block("data_pad"):
                                v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                                v_i2 = T.axis.spatial(T.int64(30), kh_0 + oh_1 * T.int64(14) + ax2)
                                v_i3 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(14) * T.int64(2) + ax3)
                                v_i4 = T.axis.spatial(T.int64(512), ic_0 * T.int64(8) + ax4_fused)
                                T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                                T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                                data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                    for kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(3), T.int64(1), T.int64(1), T.int64(7), T.int64(2), T.int64(16), T.int64(8), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(2), T.int64(1), T.int64(1)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(14) * T.int64(2) + oc_chunk_1 * T.int64(2) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(28), oh_1 * T.int64(14) + oh_2 * T.int64(2) + oh_3)
                            v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(14) * T.int64(2) + ow_1 * T.int64(2) + ow_2 + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_1 * T.int64(16) + oc_block_2 + oc_block_3)
                            v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(8) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
            for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(2), T.int64(28)):
                for ax3_ax4_fused in T.vectorized(T.int64(32)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(14) * T.int64(2) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(28), ax2)
                        v_ax3 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(14) * T.int64(2) + ax3_ax4_fused // T.int64(16))
                        v_ax4 = T.axis.spatial(T.int64(16), ax3_ax4_fused % T.int64(16))
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[16, 1, 1, 2])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 2, 7, 2])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[14, 1, 2, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 16, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[64, 8])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=11)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87 = sch.get_loops(block=b68)
l88 = sch.fuse(l71, l72, l73, l74, l75, preserve_unit_iters=True)
sch.parallel(loop=l88)
l89 = sch.fuse(l87, preserve_unit_iters=True)
sch.vectorize(loop=l89)
l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107, l108, l109, l110, l111 = sch.get_loops(block=b69)
l112 = sch.fuse(l90, preserve_unit_iters=True)
sch.parallel(loop=l112)
sch.annotate(block_or_loop=l112, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l112, ann_key="pragma_unroll_explicit", ann_val=1)
l113, l114, l115, l116, l117, l118 = sch.get_loops(block=b70)
l119 = sch.fuse(l117, l118, preserve_unit_iters=True)
sch.vectorize(loop=l119)
b120 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141, l142 = sch.get_loops(block=b120)
b143 = sch.decompose_reduction(block=b120, loop=l127)
2024-04-30 08:18:09 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #629: GFLOPs: 519.3533. Time: 7124.5891 us. Best GFLOPs: 907.1550
2024-04-30 08:18:09 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #630: GFLOPs: 582.7320. Time: 6349.7097 us. Best GFLOPs: 907.1550
2024-04-30 08:18:09 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #631: GFLOPs: 590.0907. Time: 6270.5258 us. Best GFLOPs: 907.1550
2024-04-30 08:18:09 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #632: GFLOPs: 460.2008. Time: 8040.3582 us. Best GFLOPs: 907.1550
2024-04-30 08:18:09 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #633: GFLOPs: 510.8473. Time: 7243.2194 us. Best GFLOPs: 907.1550
2024-04-30 08:18:09 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #634: GFLOPs: 22.4981. Time: 164466.0750 us. Best GFLOPs: 907.1550
2024-04-30 08:18:09 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #635: GFLOPs: 83.8722. Time: 44116.8520 us. Best GFLOPs: 907.1550
2024-04-30 08:18:09 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #636: GFLOPs: 128.6238. Time: 28767.4470 us. Best GFLOPs: 907.1550
2024-04-30 08:18:09 [INFO] [task_scheduler.cc:121] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #637: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(512)), "float32"), p1: T.Buffer((T.int64(32), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused in T.parallel(T.int64(448), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(7), T.int64(2), T.int64(16), T.int64(1), T.int64(2), T.int64(1), T.int64(2), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(28) * T.int64(2) + oc_chunk_1 * T.int64(2) + oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(28) // T.int64(7) * T.int64(7) + oh_1 * T.int64(7) + oh_2_init + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(7) * T.int64(4) + ow_1 * T.int64(4) + ow_2_init * T.int64(2) + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(16), oc_block_1 * T.int64(16) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0 in T.grid(T.int64(64), T.int64(3)):
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(7), T.int64(6)):
                        for ax4_fused in T.vectorized(T.int64(8)):
                            with T.block("data_pad"):
                                v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                                v_i2 = T.axis.spatial(T.int64(30), kh_0 + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(28) // T.int64(7) * T.int64(7) + ax2)
                                v_i3 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(7) * T.int64(4) + ax3)
                                v_i4 = T.axis.spatial(T.int64(512), ic_0 * T.int64(8) + ax4_fused)
                                T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                                T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                                data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                    for kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(3), T.int64(1), T.int64(1), T.int64(7), T.int64(2), T.int64(16), T.int64(8), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(2), T.int64(1)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(28) * T.int64(2) + oc_chunk_1 * T.int64(2) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(28) // T.int64(7) * T.int64(7) + oh_1 * T.int64(7) + oh_2 + oh_3)
                            v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(7) * T.int64(4) + ow_1 * T.int64(4) + ow_2 * T.int64(2) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_1 * T.int64(16) + oc_block_2 + oc_block_3)
                            v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(8) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
            for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(2), T.int64(7)):
                for ax3_ax4_fused in T.vectorized(T.int64(64)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(28) * T.int64(2) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(28) // T.int64(7) * T.int64(7) + ax2)
                        v_ax3 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(7) * T.int64(4) + ax3_ax4_fused // T.int64(16))
                        v_ax4 = T.axis.spatial(T.int64(16), ax3_ax4_fused % T.int64(16))
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[16, 1, 1, 2])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[4, 1, 7, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[7, 1, 2, 2])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 16, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[64, 8])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=11)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87 = sch.get_loops(block=b68)
l88 = sch.fuse(l71, l72, l73, l74, l75, preserve_unit_iters=True)
sch.parallel(loop=l88)
l89 = sch.fuse(l87, preserve_unit_iters=True)
sch.vectorize(loop=l89)
l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107, l108, l109, l110, l111 = sch.get_loops(block=b69)
l112 = sch.fuse(l90, preserve_unit_iters=True)
sch.parallel(loop=l112)
sch.annotate(block_or_loop=l112, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l112, ann_key="pragma_unroll_explicit", ann_val=1)
l113, l114, l115, l116, l117, l118 = sch.get_loops(block=b70)
l119 = sch.fuse(l117, l118, preserve_unit_iters=True)
sch.vectorize(loop=l119)
b120 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141, l142 = sch.get_loops(block=b120)
b143 = sch.decompose_reduction(block=b120, loop=l127)
2024-04-30 08:18:09 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #638: GFLOPs: 29.3324. Time: 126146.3660 us. Best GFLOPs: 907.1550
2024-04-30 08:18:09 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #639: GFLOPs: 32.0029. Time: 115620.2277 us. Best GFLOPs: 907.1550
2024-04-30 08:18:09 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #640: GFLOPs: 14.3607. Time: 257660.4983 us. Best GFLOPs: 907.1550
2024-04-30 08:27:03 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-30 08:27:04 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-30 08:27:08 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 08:27:08 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-30 08:27:22 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 08:27:35 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 08:27:50 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 08:28:04 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 08:28:13 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.8977  0.8165  0.8067  0.8067  0.7935  0.7846  0.7826  0.7816  0.7738  0.7590  0.7564  0.7480  0.7441  0.7337  0.7238  0.7213
[17 : 32]:	0.7166  0.7143  0.7131  0.7060  0.6920  0.6920  0.6839  0.6786  0.6776  0.6770  0.6720  0.6689  0.6643  0.6538  0.6501  0.6487
[33 : 48]:	0.6446  0.6408  0.6406  0.6406  0.6353  0.6306  0.6303  0.6293  0.6240  0.6239  0.6233  0.6207  0.6203  0.6160  0.6138  0.6135
[49 : 64]:	0.6104  0.6099  0.6081  0.6078  0.6074  0.6057  0.6037  0.6030  0.5964  0.5964  0.5933  0.5876  0.5871  0.5867  0.5865  0.5849
2024-04-30 08:28:13 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-30 08:28:13 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-30 08:30:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #641: GFLOPs: 970.8154. Time: 3811.4137 us. Best GFLOPs: 970.8154
2024-04-30 08:30:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #642: GFLOPs: 893.8264. Time: 4139.7063 us. Best GFLOPs: 970.8154
2024-04-30 08:30:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #643: GFLOPs: 818.2899. Time: 4521.8433 us. Best GFLOPs: 970.8154
2024-04-30 08:30:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #644: GFLOPs: 819.4487. Time: 4515.4493 us. Best GFLOPs: 970.8154
2024-04-30 08:30:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #645: GFLOPs: 776.8786. Time: 4762.8791 us. Best GFLOPs: 970.8154
2024-04-30 08:30:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #646: GFLOPs: 840.3340. Time: 4403.2243 us. Best GFLOPs: 970.8154
2024-04-30 08:30:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #647: GFLOPs: 698.6555. Time: 5296.1425 us. Best GFLOPs: 970.8154
2024-04-30 08:30:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #648: GFLOPs: 737.9405. Time: 5014.1967 us. Best GFLOPs: 970.8154
2024-04-30 08:30:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #649: GFLOPs: 720.9993. Time: 5132.0147 us. Best GFLOPs: 970.8154
2024-04-30 08:30:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #650: GFLOPs: 670.7644. Time: 5516.3616 us. Best GFLOPs: 970.8154
2024-04-30 08:30:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #651: GFLOPs: 736.9864. Time: 5020.6883 us. Best GFLOPs: 970.8154
2024-04-30 08:30:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #652: GFLOPs: 804.9126. Time: 4596.9944 us. Best GFLOPs: 970.8154
2024-04-30 08:30:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #653: GFLOPs: 777.0367. Time: 4761.9099 us. Best GFLOPs: 970.8154
2024-04-30 08:30:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #654: GFLOPs: 805.7889. Time: 4591.9952 us. Best GFLOPs: 970.8154
2024-04-30 08:30:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #655: GFLOPs: 618.3319. Time: 5984.1304 us. Best GFLOPs: 970.8154
2024-04-30 08:30:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #656: GFLOPs: 700.4121. Time: 5282.8598 us. Best GFLOPs: 970.8154
2024-04-30 08:30:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #657: GFLOPs: 606.9092. Time: 6096.7589 us. Best GFLOPs: 970.8154
2024-04-30 08:30:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #658: GFLOPs: 622.2442. Time: 5946.5056 us. Best GFLOPs: 970.8154
2024-04-30 08:30:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #659: GFLOPs: 666.4243. Time: 5552.2870 us. Best GFLOPs: 970.8154
2024-04-30 08:30:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #660: GFLOPs: 445.6898. Time: 8302.1388 us. Best GFLOPs: 970.8154
2024-04-30 08:30:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #661: GFLOPs: 638.1202. Time: 5798.5607 us. Best GFLOPs: 970.8154
2024-04-30 08:30:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #662: GFLOPs: 638.3452. Time: 5796.5173 us. Best GFLOPs: 970.8154
2024-04-30 08:30:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #663: GFLOPs: 553.5322. Time: 6684.6680 us. Best GFLOPs: 970.8154
2024-04-30 08:30:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #664: GFLOPs: 563.7104. Time: 6563.9716 us. Best GFLOPs: 970.8154
2024-04-30 08:30:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #665: GFLOPs: 633.5596. Time: 5840.3014 us. Best GFLOPs: 970.8154
2024-04-30 08:30:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #666: GFLOPs: 630.1479. Time: 5871.9214 us. Best GFLOPs: 970.8154
2024-04-30 08:30:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #667: GFLOPs: 279.3460. Time: 13245.8646 us. Best GFLOPs: 970.8154
2024-04-30 08:30:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #668: GFLOPs: 432.9465. Time: 8546.5043 us. Best GFLOPs: 970.8154
2024-04-30 08:30:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #669: GFLOPs: 395.4878. Time: 9355.9871 us. Best GFLOPs: 970.8154
2024-04-30 08:30:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #670: GFLOPs: 135.8993. Time: 27227.3505 us. Best GFLOPs: 970.8154
2024-04-30 08:30:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #671: GFLOPs: 694.6166. Time: 5326.9368 us. Best GFLOPs: 970.8154
2024-04-30 08:30:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #672: GFLOPs: 581.0702. Time: 6367.8694 us. Best GFLOPs: 970.8154
2024-04-30 08:30:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #673: GFLOPs: 527.5547. Time: 7013.8305 us. Best GFLOPs: 970.8154
2024-04-30 08:30:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #674: GFLOPs: 376.1482. Time: 9837.0245 us. Best GFLOPs: 970.8154
2024-04-30 08:30:41 [INFO] [task_scheduler.cc:121] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #675: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(512)), "float32"), p1: T.Buffer((T.int64(32), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_fused_fused in T.parallel(T.int64(224), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for oc_block_0 in range(T.int64(1)):
                for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                    for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(14), T.int64(2), T.int64(16), T.int64(1), T.int64(2), T.int64(2), T.int64(1), T.int64(1)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(14) * T.int64(2) + oc_chunk_1 * T.int64(2) + oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(28), oh_1 * T.int64(28) + oh_2_init * T.int64(2) + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(14) * T.int64(2) + ow_1 * T.int64(2) + ow_2_init + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2_init + oc_block_3_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                    for ic_0, kh_0 in T.grid(T.int64(64), T.int64(3)):
                        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(28), T.int64(4)):
                            for ax4_fused in T.vectorized(T.int64(8)):
                                with T.block("data_pad"):
                                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                                    v_i2 = T.axis.spatial(T.int64(30), kh_0 + ax2)
                                    v_i3 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(14) * T.int64(2) + ax3)
                                    v_i4 = T.axis.spatial(T.int64(512), ic_0 * T.int64(8) + ax4_fused)
                                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                        for kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(3), T.int64(1), T.int64(1), T.int64(14), T.int64(2), T.int64(16), T.int64(8), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(2), T.int64(1), T.int64(1)):
                            with T.block("conv2d_NCHWc_update"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                                v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(14) * T.int64(2) + oc_chunk_1 * T.int64(2) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                                v_oh = T.axis.spatial(T.int64(28), oh_1 * T.int64(28) + oh_2 * T.int64(2) + oh_3)
                                v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(14) * T.int64(2) + ow_1 * T.int64(2) + ow_2 + ow_3)
                                v_oc_block = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2 + oc_block_3)
                                v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(8) + ic_1)
                                v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                                v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                                T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
                for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(2), T.int64(28)):
                    for ax3_ax4_fused in T.vectorized(T.int64(32)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(14) * T.int64(2) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(28), ax2)
                            v_ax3 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(14) * T.int64(2) + ax3_ax4_fused // T.int64(16))
                            v_ax4 = T.axis.spatial(T.int64(16), ax3_ax4_fused % T.int64(16))
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[16, 1, 1, 2])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 14, 2])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[14, 1, 2, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 16, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[64, 8])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=16)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=11)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87 = sch.get_loops(block=b68)
l88 = sch.fuse(l71, l72, l73, l74, preserve_unit_iters=True)
sch.parallel(loop=l88)
l89 = sch.fuse(l87, preserve_unit_iters=True)
sch.vectorize(loop=l89)
l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107, l108, l109, l110, l111, l112 = sch.get_loops(block=b69)
l113 = sch.fuse(l90, preserve_unit_iters=True)
sch.parallel(loop=l113)
sch.annotate(block_or_loop=l113, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l113, ann_key="pragma_unroll_explicit", ann_val=1)
l114, l115, l116, l117, l118, l119, l120 = sch.get_loops(block=b70)
l121 = sch.fuse(l119, l120, preserve_unit_iters=True)
sch.vectorize(loop=l121)
b122 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141, l142, l143, l144, l145 = sch.get_loops(block=b122)
b146 = sch.decompose_reduction(block=b122, loop=l130)
2024-04-30 08:30:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #676: GFLOPs: 77.8575. Time: 47525.0347 us. Best GFLOPs: 970.8154
2024-04-30 08:30:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #677: GFLOPs: 650.0547. Time: 5692.1039 us. Best GFLOPs: 970.8154
2024-04-30 08:30:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #678: GFLOPs: 555.2371. Time: 6664.1422 us. Best GFLOPs: 970.8154
2024-04-30 08:30:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #679: GFLOPs: 509.7297. Time: 7259.0997 us. Best GFLOPs: 970.8154
2024-04-30 08:30:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #680: GFLOPs: 612.6413. Time: 6039.7155 us. Best GFLOPs: 970.8154
2024-04-30 08:30:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #681: GFLOPs: 560.1651. Time: 6605.5154 us. Best GFLOPs: 970.8154
2024-04-30 08:30:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #682: GFLOPs: 524.2469. Time: 7058.0846 us. Best GFLOPs: 970.8154
2024-04-30 08:30:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #683: GFLOPs: 591.7851. Time: 6252.5724 us. Best GFLOPs: 970.8154
2024-04-30 08:30:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #684: GFLOPs: 675.1441. Time: 5480.5763 us. Best GFLOPs: 970.8154
2024-04-30 08:30:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #685: GFLOPs: 527.9029. Time: 7009.2037 us. Best GFLOPs: 970.8154
2024-04-30 08:30:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #686: GFLOPs: 490.9780. Time: 7536.3438 us. Best GFLOPs: 970.8154
2024-04-30 08:30:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #687: GFLOPs: 673.2667. Time: 5495.8592 us. Best GFLOPs: 970.8154
2024-04-30 08:30:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #688: GFLOPs: 512.6394. Time: 7217.8976 us. Best GFLOPs: 970.8154
2024-04-30 08:30:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #689: GFLOPs: 527.5297. Time: 7014.1619 us. Best GFLOPs: 970.8154
2024-04-30 08:30:41 [INFO] [task_scheduler.cc:121] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #690: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(512)), "float32"), p1: T.Buffer((T.int64(32), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_fused_fused in T.parallel(T.int64(224), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for oc_block_0 in range(T.int64(1)):
                for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                    for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(2), T.int64(14), T.int64(1), T.int64(16), T.int64(1), T.int64(2), T.int64(1), T.int64(2), T.int64(1)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(28) * T.int64(4) + oc_chunk_1 * T.int64(4) + oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(28) // T.int64(14) * T.int64(14) + oh_1 * T.int64(14) + oh_2_init + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(14) * T.int64(2) + ow_1 * T.int64(2) + ow_2_init * T.int64(2) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2_init + oc_block_3_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                    for ic_0, kh_0 in T.grid(T.int64(64), T.int64(3)):
                        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(14), T.int64(4)):
                            for ax4_fused in T.vectorized(T.int64(8)):
                                with T.block("data_pad"):
                                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                                    v_i2 = T.axis.spatial(T.int64(30), kh_0 + n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(28) // T.int64(14) * T.int64(14) + ax2)
                                    v_i3 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(14) * T.int64(2) + ax3)
                                    v_i4 = T.axis.spatial(T.int64(512), ic_0 * T.int64(8) + ax4_fused)
                                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                        for kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(3), T.int64(1), T.int64(2), T.int64(14), T.int64(1), T.int64(16), T.int64(8), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(2), T.int64(1)):
                            with T.block("conv2d_NCHWc_update"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                                v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(28) * T.int64(4) + oc_chunk_1 * T.int64(4) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                                v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(28) // T.int64(14) * T.int64(14) + oh_1 * T.int64(14) + oh_2 + oh_3)
                                v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(14) * T.int64(2) + ow_1 * T.int64(2) + ow_2 * T.int64(2) + ow_3)
                                v_oc_block = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2 + oc_block_3)
                                v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(8) + ic_1)
                                v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                                v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                                T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
                for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(4), T.int64(14)):
                    for ax3_ax4_fused in T.vectorized(T.int64(32)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(28) * T.int64(4) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(28) // T.int64(14) * T.int64(14) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(14) * T.int64(2) + ax3_ax4_fused // T.int64(16))
                            v_ax4 = T.axis.spatial(T.int64(16), ax3_ax4_fused % T.int64(16))
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[8, 1, 2, 2])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 1, 14, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[14, 1, 1, 2])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 16, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[64, 8])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=16)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=11)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87 = sch.get_loops(block=b68)
l88 = sch.fuse(l71, l72, l73, l74, preserve_unit_iters=True)
sch.parallel(loop=l88)
l89 = sch.fuse(l87, preserve_unit_iters=True)
sch.vectorize(loop=l89)
l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107, l108, l109, l110, l111, l112 = sch.get_loops(block=b69)
l113 = sch.fuse(l90, preserve_unit_iters=True)
sch.parallel(loop=l113)
sch.annotate(block_or_loop=l113, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l113, ann_key="pragma_unroll_explicit", ann_val=1)
l114, l115, l116, l117, l118, l119, l120 = sch.get_loops(block=b70)
l121 = sch.fuse(l119, l120, preserve_unit_iters=True)
sch.vectorize(loop=l121)
b122 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141, l142, l143, l144, l145 = sch.get_loops(block=b122)
b146 = sch.decompose_reduction(block=b122, loop=l130)
2024-04-30 08:30:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #691: GFLOPs: 311.9646. Time: 11860.8938 us. Best GFLOPs: 970.8154
2024-04-30 08:30:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #692: GFLOPs: 462.7193. Time: 7996.5944 us. Best GFLOPs: 970.8154
2024-04-30 08:30:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #693: GFLOPs: 523.8083. Time: 7063.9947 us. Best GFLOPs: 970.8154
2024-04-30 08:30:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #694: GFLOPs: 468.8364. Time: 7892.2602 us. Best GFLOPs: 970.8154
2024-04-30 08:30:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #695: GFLOPs: 424.6306. Time: 8713.8781 us. Best GFLOPs: 970.8154
2024-04-30 08:30:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #696: GFLOPs: 558.3770. Time: 6626.6682 us. Best GFLOPs: 970.8154
2024-04-30 08:30:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #697: GFLOPs: 130.7087. Time: 28308.5918 us. Best GFLOPs: 970.8154
2024-04-30 08:30:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #698: GFLOPs: 533.4952. Time: 6935.7311 us. Best GFLOPs: 970.8154
2024-04-30 08:30:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #699: GFLOPs: 589.6989. Time: 6274.6916 us. Best GFLOPs: 970.8154
2024-04-30 08:30:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #700: GFLOPs: 502.2733. Time: 7366.8630 us. Best GFLOPs: 970.8154
2024-04-30 08:30:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #701: GFLOPs: 570.9304. Time: 6480.9632 us. Best GFLOPs: 970.8154
2024-04-30 08:30:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #702: GFLOPs: 81.7279. Time: 45274.3890 us. Best GFLOPs: 970.8154
2024-04-30 08:30:42 [INFO] [task_scheduler.cc:121] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #703: Error in running:
LocalRunner: Timeout, killed after 30 seconds

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(512)), "float32"), p1: T.Buffer((T.int64(32), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)))
        for n_0 in T.serial(T.int64(1), annotations={"pragma_auto_unroll_max_step": 16, "pragma_unroll_explicit": 1}):
            for oc_chunk_0, oh_0, ow_0, oc_block_0 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(2), T.int64(28), T.int64(1), T.int64(8)):
                    for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(3), T.int64(30), T.int64(512)):
                        with T.block("data_pad"):
                            v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                            v_i2 = T.axis.spatial(T.int64(30), oh_1 + ax2)
                            v_i3, v_i4 = T.axis.remap("SS", [ax3, ax4])
                            T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                            T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                            data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                    for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(4), T.int64(1), T.int64(28), T.int64(1)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_0 + n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(32), oc_chunk_0 * T.int64(32) + oc_chunk_1 * T.int64(16) + oc_chunk_2_init * T.int64(4) + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(28), oh_0 * T.int64(28) + oh_1 + oh_2_init + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(28), ow_0 * T.int64(28) + ow_1 * T.int64(28) + ow_2_init * T.int64(28) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(16) + oc_block_1 * T.int64(2) + oc_block_2_init + oc_block_3_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                    for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(256), T.int64(3), T.int64(3), T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(2), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(1), T.int64(28), T.int64(1)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_0 + n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(32), oc_chunk_0 * T.int64(32) + oc_chunk_1 * T.int64(16) + oc_chunk_2 * T.int64(4) + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(28), oh_0 * T.int64(28) + oh_1 + oh_2 + oh_3)
                            v_ow = T.axis.spatial(T.int64(28), ow_0 * T.int64(28) + ow_1 * T.int64(28) + ow_2 * T.int64(28) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(16) + oc_block_1 * T.int64(2) + oc_block_2 + oc_block_3)
                            v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(2) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(32), T.int64(28), T.int64(28)):
                    for ax4_fused in T.vectorized(T.int64(16)):
                        with T.block("T_relu"):
                            v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4_fused])
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 2, 4, 4])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 28, 1, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 1, 28])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 8, 2, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[256, 2])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=9)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85 = sch.get_loops(block=b68)
l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107, l108, l109, l110, l111 = sch.get_loops(block=b69)
sch.annotate(block_or_loop=l86, ann_key="pragma_auto_unroll_max_step", ann_val=16)
sch.annotate(block_or_loop=l86, ann_key="pragma_unroll_explicit", ann_val=1)
l112, l113, l114, l115, l116, l117, l118, l119, l120, l121 = sch.get_loops(block=b70)
l122 = sch.fuse(l121, preserve_unit_iters=True)
sch.vectorize(loop=l122)
b123 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141, l142, l143, l144, l145, l146, l147, l148, l149 = sch.get_loops(block=b123)
b150 = sch.decompose_reduction(block=b123, loop=l134)
2024-04-30 08:30:42 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #704: GFLOPs: 25.7447. Time: 143725.9937 us. Best GFLOPs: 970.8154
2024-04-30 08:33:57 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-30 08:33:58 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-30 08:34:02 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 08:34:02 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-30 08:34:15 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 08:34:29 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 08:34:43 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 08:34:57 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 08:35:06 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.8349  0.8197  0.8166  0.8088  0.8038  0.7970  0.7894  0.7660  0.7518  0.7481  0.7467  0.7357  0.7340  0.7231  0.7207  0.7207
[17 : 32]:	0.7207  0.7190  0.7187  0.7047  0.7022  0.7007  0.6988  0.6987  0.6898  0.6795  0.6795  0.6774  0.6759  0.6718  0.6715  0.6684
[33 : 48]:	0.6653  0.6653  0.6653  0.6653  0.6653  0.6624  0.6616  0.6559  0.6551  0.6548  0.6498  0.6483  0.6449  0.6445  0.6393  0.6355
[49 : 64]:	0.6300  0.6300  0.6276  0.6276  0.6276  0.6225  0.6225  0.6225  0.6222  0.6197  0.6189  0.6177  0.6148  0.6123  0.6110  0.6086
2024-04-30 08:35:06 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-30 08:35:06 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-30 08:37:58 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #705: GFLOPs: 842.4692. Time: 4392.0646 us. Best GFLOPs: 970.8154
2024-04-30 08:37:58 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #706: GFLOPs: 876.2872. Time: 4222.5643 us. Best GFLOPs: 970.8154
2024-04-30 08:37:58 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #707: GFLOPs: 782.7888. Time: 4726.9185 us. Best GFLOPs: 970.8154
2024-04-30 08:37:58 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #708: GFLOPs: 806.7266. Time: 4586.6579 us. Best GFLOPs: 970.8154
2024-04-30 08:37:58 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #709: GFLOPs: 813.3462. Time: 4549.3282 us. Best GFLOPs: 970.8154
2024-04-30 08:37:58 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #710: GFLOPs: 833.7816. Time: 4437.8276 us. Best GFLOPs: 970.8154
2024-04-30 08:37:58 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #711: GFLOPs: 782.8291. Time: 4726.6753 us. Best GFLOPs: 970.8154
2024-04-30 08:37:58 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #712: GFLOPs: 672.7240. Time: 5500.2924 us. Best GFLOPs: 970.8154
2024-04-30 08:37:58 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #713: GFLOPs: 605.6823. Time: 6109.1085 us. Best GFLOPs: 970.8154
2024-04-30 08:37:58 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #714: GFLOPs: 728.1901. Time: 5081.3369 us. Best GFLOPs: 970.8154
2024-04-30 08:37:58 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #715: GFLOPs: 772.1026. Time: 4792.3410 us. Best GFLOPs: 970.8154
2024-04-30 08:37:58 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #716: GFLOPs: 819.1992. Time: 4516.8242 us. Best GFLOPs: 970.8154
2024-04-30 08:37:58 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #717: GFLOPs: 6.4701. Time: 571886.8160 us. Best GFLOPs: 970.8154
2024-04-30 08:37:58 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #718: GFLOPs: 679.9279. Time: 5442.0167 us. Best GFLOPs: 970.8154
2024-04-30 08:37:58 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #719: GFLOPs: 6.5307. Time: 566583.8407 us. Best GFLOPs: 970.8154
2024-04-30 08:37:58 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #720: GFLOPs: 13.1166. Time: 282099.1567 us. Best GFLOPs: 970.8154
2024-04-30 08:37:58 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #721: GFLOPs: 10.7510. Time: 344170.1760 us. Best GFLOPs: 970.8154
2024-04-30 08:37:58 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #722: GFLOPs: 423.5233. Time: 8736.6595 us. Best GFLOPs: 970.8154
2024-04-30 08:37:58 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #723: GFLOPs: 750.8799. Time: 4927.7904 us. Best GFLOPs: 970.8154
2024-04-30 08:37:58 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #724: GFLOPs: 431.0434. Time: 8584.2378 us. Best GFLOPs: 970.8154
2024-04-30 08:37:58 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #725: GFLOPs: 693.2358. Time: 5337.5475 us. Best GFLOPs: 970.8154
2024-04-30 08:37:58 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #726: GFLOPs: 807.6736. Time: 4581.2801 us. Best GFLOPs: 970.8154
2024-04-30 08:37:58 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #727: GFLOPs: 626.6072. Time: 5905.1015 us. Best GFLOPs: 970.8154
2024-04-30 08:37:58 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #728: GFLOPs: 682.6320. Time: 5420.4595 us. Best GFLOPs: 970.8154
2024-04-30 08:37:58 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #729: GFLOPs: 682.2187. Time: 5423.7427 us. Best GFLOPs: 970.8154
2024-04-30 08:37:58 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #730: GFLOPs: 6.5022. Time: 569067.6173 us. Best GFLOPs: 970.8154
2024-04-30 08:37:58 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #731: GFLOPs: 288.7912. Time: 12812.6449 us. Best GFLOPs: 970.8154
2024-04-30 08:37:58 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #732: GFLOPs: 704.8499. Time: 5249.5982 us. Best GFLOPs: 970.8154
2024-04-30 08:37:58 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #733: GFLOPs: 621.8228. Time: 5950.5358 us. Best GFLOPs: 970.8154
2024-04-30 08:37:58 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #734: GFLOPs: 682.6471. Time: 5420.3390 us. Best GFLOPs: 970.8154
2024-04-30 08:37:58 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #735: GFLOPs: 716.9448. Time: 5161.0377 us. Best GFLOPs: 970.8154
2024-04-30 08:37:58 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #736: GFLOPs: 563.7228. Time: 6563.8266 us. Best GFLOPs: 970.8154
2024-04-30 08:37:58 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #737: GFLOPs: 11.6152. Time: 318564.4537 us. Best GFLOPs: 970.8154
2024-04-30 08:37:58 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #738: GFLOPs: 6.2498. Time: 592049.8843 us. Best GFLOPs: 970.8154
2024-04-30 08:37:58 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #739: GFLOPs: 5.7871. Time: 639378.8123 us. Best GFLOPs: 970.8154
2024-04-30 08:37:58 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #740: GFLOPs: 9.4804. Time: 390298.4567 us. Best GFLOPs: 970.8154
2024-04-30 08:37:58 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #741: GFLOPs: 11.9115. Time: 310640.0400 us. Best GFLOPs: 970.8154
2024-04-30 08:37:58 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #742: GFLOPs: 648.5549. Time: 5705.2675 us. Best GFLOPs: 970.8154
2024-04-30 08:37:58 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #743: GFLOPs: 618.4463. Time: 5983.0240 us. Best GFLOPs: 970.8154
2024-04-30 08:37:58 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #744: GFLOPs: 404.6901. Time: 9143.2407 us. Best GFLOPs: 970.8154
2024-04-30 08:37:58 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #745: GFLOPs: 604.6792. Time: 6119.2434 us. Best GFLOPs: 970.8154
2024-04-30 08:37:58 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #746: GFLOPs: 567.1616. Time: 6524.0291 us. Best GFLOPs: 970.8154
2024-04-30 08:37:58 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #747: GFLOPs: 633.1774. Time: 5843.8266 us. Best GFLOPs: 970.8154
2024-04-30 08:37:58 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #748: GFLOPs: 11.2609. Time: 328585.0137 us. Best GFLOPs: 970.8154
2024-04-30 08:37:58 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #749: GFLOPs: 356.4748. Time: 10379.9163 us. Best GFLOPs: 970.8154
2024-04-30 08:37:58 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #750: GFLOPs: 292.5706. Time: 12647.1311 us. Best GFLOPs: 970.8154
2024-04-30 08:37:58 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #751: GFLOPs: 613.4332. Time: 6031.9184 us. Best GFLOPs: 970.8154
2024-04-30 08:37:58 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #752: GFLOPs: 543.2592. Time: 6811.0744 us. Best GFLOPs: 970.8154
2024-04-30 08:37:58 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #753: GFLOPs: 21.4923. Time: 172163.1127 us. Best GFLOPs: 970.8154
2024-04-30 08:37:58 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #754: GFLOPs: 19.1234. Time: 193489.6483 us. Best GFLOPs: 970.8154
2024-04-30 08:37:58 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #755: GFLOPs: 11.6382. Time: 317933.7127 us. Best GFLOPs: 970.8154
2024-04-30 08:37:58 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #756: GFLOPs: 9.4629. Time: 391017.6760 us. Best GFLOPs: 970.8154
2024-04-30 08:37:58 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #757: GFLOPs: 12.6579. Time: 292322.1567 us. Best GFLOPs: 970.8154
2024-04-30 08:37:58 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #758: GFLOPs: 25.8779. Time: 142985.9083 us. Best GFLOPs: 970.8154
2024-04-30 08:37:58 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #759: GFLOPs: 12.7069. Time: 291194.3573 us. Best GFLOPs: 970.8154
2024-04-30 08:37:58 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #760: GFLOPs: 6.5134. Time: 568090.4837 us. Best GFLOPs: 970.8154
2024-04-30 08:37:58 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #761: GFLOPs: 645.5030. Time: 5732.2415 us. Best GFLOPs: 970.8154
2024-04-30 08:37:58 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #762: GFLOPs: 588.8101. Time: 6284.1636 us. Best GFLOPs: 970.8154
2024-04-30 08:37:58 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #763: GFLOPs: 406.1077. Time: 9111.3239 us. Best GFLOPs: 970.8154
2024-04-30 08:37:58 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #764: GFLOPs: 603.4174. Time: 6132.0384 us. Best GFLOPs: 970.8154
2024-04-30 08:37:58 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #765: GFLOPs: 699.2346. Time: 5291.7562 us. Best GFLOPs: 970.8154
2024-04-30 08:37:58 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #766: GFLOPs: 7.2884. Time: 507681.2660 us. Best GFLOPs: 970.8154
2024-04-30 08:37:58 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #767: GFLOPs: 58.3531. Time: 63410.1060 us. Best GFLOPs: 970.8154
2024-04-30 08:37:58 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #768: GFLOPs: 104.6824. Time: 35346.7043 us. Best GFLOPs: 970.8154
2024-04-30 09:06:25 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-30 09:06:26 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-30 09:06:31 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 09:06:31 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-30 09:06:44 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 09:06:57 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 09:07:11 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 09:07:25 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 09:07:34 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9091  0.8525  0.8112  0.8107  0.8083  0.8009  0.7672  0.7649  0.7617  0.7608  0.7563  0.7533  0.7439  0.7305  0.7182  0.7133
[17 : 32]:	0.6866  0.6847  0.6830  0.6819  0.6813  0.6807  0.6715  0.6701  0.6692  0.6692  0.6681  0.6681  0.6659  0.6624  0.6605  0.6580
[33 : 48]:	0.6559  0.6558  0.6424  0.6359  0.6359  0.6354  0.6350  0.6345  0.6271  0.6258  0.6229  0.6201  0.6201  0.6201  0.6187  0.6148
[49 : 64]:	0.6119  0.6118  0.6060  0.6015  0.5999  0.5982  0.5981  0.5981  0.5967  0.5942  0.5942  0.5920  0.5919  0.5912  0.5899  0.5895
2024-04-30 09:07:34 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-30 09:07:34 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-30 09:09:55 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #769: GFLOPs: 929.2063. Time: 3982.0857 us. Best GFLOPs: 970.8154
2024-04-30 09:09:55 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #770: GFLOPs: 864.5338. Time: 4279.9702 us. Best GFLOPs: 970.8154
2024-04-30 09:09:55 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #771: GFLOPs: 685.7578. Time: 5395.7519 us. Best GFLOPs: 970.8154
2024-04-30 09:09:55 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #772: GFLOPs: 822.7596. Time: 4497.2781 us. Best GFLOPs: 970.8154
2024-04-30 09:09:55 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #773: GFLOPs: 812.7320. Time: 4552.7664 us. Best GFLOPs: 970.8154
2024-04-30 09:09:55 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #774: GFLOPs: 642.3642. Time: 5760.2506 us. Best GFLOPs: 970.8154
2024-04-30 09:09:55 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #775: GFLOPs: 777.7276. Time: 4757.6797 us. Best GFLOPs: 970.8154
2024-04-30 09:09:55 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #776: GFLOPs: 881.8625. Time: 4195.8683 us. Best GFLOPs: 970.8154
2024-04-30 09:09:55 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #777: GFLOPs: 768.4291. Time: 4815.2508 us. Best GFLOPs: 970.8154
2024-04-30 09:09:55 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #778: GFLOPs: 722.6114. Time: 5120.5655 us. Best GFLOPs: 970.8154
2024-04-30 09:09:55 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #779: GFLOPs: 802.3110. Time: 4611.9010 us. Best GFLOPs: 970.8154
2024-04-30 09:09:55 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #780: GFLOPs: 87.7030. Time: 42189.8950 us. Best GFLOPs: 970.8154
2024-04-30 09:09:55 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #781: GFLOPs: 126.9162. Time: 29154.4985 us. Best GFLOPs: 970.8154
2024-04-30 09:09:55 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #782: GFLOPs: 827.6706. Time: 4470.5937 us. Best GFLOPs: 970.8154
2024-04-30 09:09:55 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #783: GFLOPs: 846.4266. Time: 4371.5298 us. Best GFLOPs: 970.8154
2024-04-30 09:09:55 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #784: GFLOPs: 732.9704. Time: 5048.1972 us. Best GFLOPs: 970.8154
2024-04-30 09:09:55 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #785: GFLOPs: 111.7841. Time: 33101.1165 us. Best GFLOPs: 970.8154
2024-04-30 09:09:55 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #786: GFLOPs: 815.0813. Time: 4539.6440 us. Best GFLOPs: 970.8154
2024-04-30 09:09:55 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #787: GFLOPs: 708.8309. Time: 5220.1151 us. Best GFLOPs: 970.8154
2024-04-30 09:09:55 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #788: GFLOPs: 788.2721. Time: 4694.0379 us. Best GFLOPs: 970.8154
2024-04-30 09:09:55 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #789: GFLOPs: 769.9779. Time: 4805.5654 us. Best GFLOPs: 970.8154
2024-04-30 09:09:55 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #790: GFLOPs: 349.2551. Time: 10594.4875 us. Best GFLOPs: 970.8154
2024-04-30 09:09:55 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #791: GFLOPs: 646.6033. Time: 5722.4866 us. Best GFLOPs: 970.8154
2024-04-30 09:09:55 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #792: GFLOPs: 638.4198. Time: 5795.8396 us. Best GFLOPs: 970.8154
2024-04-30 09:09:55 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #793: GFLOPs: 699.9076. Time: 5286.6676 us. Best GFLOPs: 970.8154
2024-04-30 09:09:55 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #794: GFLOPs: 765.7427. Time: 4832.1440 us. Best GFLOPs: 970.8154
2024-04-30 09:09:55 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #795: GFLOPs: 646.2057. Time: 5726.0083 us. Best GFLOPs: 970.8154
2024-04-30 09:09:55 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #796: GFLOPs: 653.3900. Time: 5663.0484 us. Best GFLOPs: 970.8154
2024-04-30 09:09:55 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #797: GFLOPs: 642.5379. Time: 5758.6939 us. Best GFLOPs: 970.8154
2024-04-30 09:09:55 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #798: GFLOPs: 800.8790. Time: 4620.1470 us. Best GFLOPs: 970.8154
2024-04-30 09:09:55 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #799: GFLOPs: 724.7587. Time: 5105.3941 us. Best GFLOPs: 970.8154
2024-04-30 09:09:55 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #800: GFLOPs: 492.1206. Time: 7518.8462 us. Best GFLOPs: 970.8154
2024-04-30 09:09:55 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #801: GFLOPs: 671.9950. Time: 5506.2598 us. Best GFLOPs: 970.8154
2024-04-30 09:09:55 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #802: GFLOPs: 764.5864. Time: 4839.4517 us. Best GFLOPs: 970.8154
2024-04-30 09:09:55 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #803: GFLOPs: 728.3731. Time: 5080.0597 us. Best GFLOPs: 970.8154
2024-04-30 09:09:55 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #804: GFLOPs: 798.0469. Time: 4636.5432 us. Best GFLOPs: 970.8154
2024-04-30 09:09:55 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #805: GFLOPs: 808.8201. Time: 4574.7858 us. Best GFLOPs: 970.8154
2024-04-30 09:09:55 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #806: GFLOPs: 648.8344. Time: 5702.8096 us. Best GFLOPs: 970.8154
2024-04-30 09:09:55 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #807: GFLOPs: 644.5696. Time: 5740.5425 us. Best GFLOPs: 970.8154
2024-04-30 09:09:55 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #808: GFLOPs: 602.4120. Time: 6142.2731 us. Best GFLOPs: 970.8154
2024-04-30 09:09:55 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #809: GFLOPs: 129.1043. Time: 28660.3923 us. Best GFLOPs: 970.8154
2024-04-30 09:09:55 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #810: GFLOPs: 659.1715. Time: 5613.3786 us. Best GFLOPs: 970.8154
2024-04-30 09:09:55 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #811: GFLOPs: 601.9831. Time: 6146.6496 us. Best GFLOPs: 970.8154
2024-04-30 09:09:55 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #812: GFLOPs: 557.0891. Time: 6641.9872 us. Best GFLOPs: 970.8154
2024-04-30 09:09:55 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #813: GFLOPs: 568.7237. Time: 6506.1098 us. Best GFLOPs: 970.8154
2024-04-30 09:09:55 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #814: GFLOPs: 604.7290. Time: 6118.7392 us. Best GFLOPs: 970.8154
2024-04-30 09:09:55 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #815: GFLOPs: 683.6561. Time: 5412.3393 us. Best GFLOPs: 970.8154
2024-04-30 09:09:55 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #816: GFLOPs: 659.0295. Time: 5614.5875 us. Best GFLOPs: 970.8154
2024-04-30 09:09:55 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #817: GFLOPs: 582.7160. Time: 6349.8834 us. Best GFLOPs: 970.8154
2024-04-30 09:09:55 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #818: GFLOPs: 480.0258. Time: 7708.2913 us. Best GFLOPs: 970.8154
2024-04-30 09:09:55 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #819: GFLOPs: 728.3519. Time: 5080.2078 us. Best GFLOPs: 970.8154
2024-04-30 09:09:55 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #820: GFLOPs: 644.7425. Time: 5739.0030 us. Best GFLOPs: 970.8154
2024-04-30 09:09:55 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #821: GFLOPs: 582.0635. Time: 6357.0022 us. Best GFLOPs: 970.8154
2024-04-30 09:09:55 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #822: GFLOPs: 614.3377. Time: 6023.0369 us. Best GFLOPs: 970.8154
2024-04-30 09:09:55 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #823: GFLOPs: 759.5830. Time: 4871.3294 us. Best GFLOPs: 970.8154
2024-04-30 09:09:55 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #824: GFLOPs: 736.6694. Time: 5022.8488 us. Best GFLOPs: 970.8154
2024-04-30 09:09:55 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #825: GFLOPs: 141.6353. Time: 26124.6912 us. Best GFLOPs: 970.8154
2024-04-30 09:09:55 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #826: GFLOPs: 709.7424. Time: 5213.4111 us. Best GFLOPs: 970.8154
2024-04-30 09:09:55 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #827: GFLOPs: 773.5153. Time: 4783.5888 us. Best GFLOPs: 970.8154
2024-04-30 09:09:55 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #828: GFLOPs: 525.6957. Time: 7038.6320 us. Best GFLOPs: 970.8154
2024-04-30 09:09:55 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #829: GFLOPs: 581.4793. Time: 6363.3895 us. Best GFLOPs: 970.8154
2024-04-30 09:09:55 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #830: GFLOPs: 66.7374. Time: 55443.8373 us. Best GFLOPs: 970.8154
2024-04-30 09:09:55 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #831: GFLOPs: 2.1035. Time: 1759083.8090 us. Best GFLOPs: 970.8154
2024-04-30 09:09:55 [INFO] [task_scheduler.cc:121] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #832: Error in running:
LocalRunner: Timeout, killed after 30 seconds

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(512)), "float32"), p1: T.Buffer((T.int64(32), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_fused_fused in T.parallel(T.int64(7), annotations={"pragma_auto_unroll_max_step": 64, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(6), T.int64(30), T.int64(512)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_fused_fused * T.int64(4) + ax2)
                    v_i3, v_i4 = T.axis.remap("SS", [ax3, ax4])
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for ow_0, oc_block_0, n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(7), T.int64(1), T.int64(1), T.int64(8), T.int64(4), T.int64(4), T.int64(2)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(8), T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(32), oc_chunk_1 * T.int64(4) + oc_chunk_2_init * T.int64(4) + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_fused_fused * T.int64(4) + oh_1 + oh_2_init + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(28), ow_0 * T.int64(4) + ow_1 + ow_2_init + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(16) + oc_block_1 * T.int64(8) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(64), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(8), T.int64(8), T.int64(3), T.int64(3), T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(32), oc_chunk_1 * T.int64(4) + oc_chunk_2 * T.int64(4) + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_fused_fused * T.int64(4) + oh_1 + oh_2 + oh_3)
                        v_ow = T.axis.spatial(T.int64(28), ow_0 * T.int64(4) + ow_1 + ow_2 + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(16) + oc_block_1 * T.int64(8) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(8) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(4), T.int64(1), T.int64(1)):
                    for ax4_fused in T.vectorized(T.int64(8)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(32), oc_chunk_1 * T.int64(4) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_fused_fused * T.int64(4) + oh_1 + ax2)
                            v_ax3 = T.axis.spatial(T.int64(28), ow_0 * T.int64(4) + ow_1 + ax3)
                            v_ax4 = T.axis.spatial(T.int64(16), oc_block_1 * T.int64(8) + ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 8, 1, 4])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[7, 4, 1, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[7, 4, 1, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 2, 8, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[64, 8])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=2)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78 = sch.get_loops(block=b68)
l79 = sch.fuse(l71, l72, l73, preserve_unit_iters=True)
sch.parallel(loop=l79)
l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l80, preserve_unit_iters=True)
sch.parallel(loop=l104)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117 = sch.get_loops(block=b70)
l118 = sch.fuse(l117, preserve_unit_iters=True)
sch.vectorize(loop=l118)
b119 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141, l142, l143 = sch.get_loops(block=b119)
b144 = sch.decompose_reduction(block=b119, loop=l128)
2024-04-30 09:13:16 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-30 09:13:17 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-30 09:13:22 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 09:13:22 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-30 09:13:34 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 09:13:48 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 09:14:02 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 09:14:16 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 09:14:25 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9174  0.8558  0.8083  0.8058  0.7739  0.7670  0.7634  0.7614  0.7607  0.7601  0.7473  0.7450  0.7423  0.7419  0.7343  0.7297
[17 : 32]:	0.7290  0.7139  0.7119  0.7084  0.7081  0.7057  0.7048  0.7048  0.7042  0.7040  0.7023  0.7000  0.6943  0.6828  0.6805  0.6768
[33 : 48]:	0.6740  0.6708  0.6648  0.6619  0.6604  0.6589  0.6577  0.6556  0.6518  0.6473  0.6453  0.6441  0.6439  0.6424  0.6398  0.6395
[49 : 64]:	0.6338  0.6321  0.6288  0.6280  0.6274  0.6241  0.6229  0.6229  0.6213  0.6208  0.6178  0.6155  0.6106  0.6100  0.6018  0.5970
2024-04-30 09:14:25 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-30 09:14:26 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-30 09:16:31 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #833: GFLOPs: 517.4627. Time: 7150.6202 us. Best GFLOPs: 970.8154
2024-04-30 09:16:31 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #834: GFLOPs: 944.3922. Time: 3918.0535 us. Best GFLOPs: 970.8154
2024-04-30 09:16:31 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #835: GFLOPs: 788.4218. Time: 4693.1465 us. Best GFLOPs: 970.8154
2024-04-30 09:16:31 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #836: GFLOPs: 799.4131. Time: 4628.6195 us. Best GFLOPs: 970.8154
2024-04-30 09:16:31 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #837: GFLOPs: 771.7949. Time: 4794.2514 us. Best GFLOPs: 970.8154
2024-04-30 09:16:31 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #838: GFLOPs: 697.9545. Time: 5301.4616 us. Best GFLOPs: 970.8154
2024-04-30 09:16:31 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #839: GFLOPs: 731.0889. Time: 5061.1885 us. Best GFLOPs: 970.8154
2024-04-30 09:16:31 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #840: GFLOPs: 790.3674. Time: 4681.5936 us. Best GFLOPs: 970.8154
2024-04-30 09:16:31 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #841: GFLOPs: 109.6437. Time: 33747.2867 us. Best GFLOPs: 970.8154
2024-04-30 09:16:31 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #842: GFLOPs: 812.9057. Time: 4551.7934 us. Best GFLOPs: 970.8154
2024-04-30 09:16:31 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #843: GFLOPs: 109.2076. Time: 33882.0787 us. Best GFLOPs: 970.8154
2024-04-30 09:16:31 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #844: GFLOPs: 674.8538. Time: 5482.9342 us. Best GFLOPs: 970.8154
2024-04-30 09:16:31 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #845: GFLOPs: 447.0107. Time: 8277.6076 us. Best GFLOPs: 970.8154
2024-04-30 09:16:31 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #846: GFLOPs: 789.9332. Time: 4684.1668 us. Best GFLOPs: 970.8154
2024-04-30 09:16:31 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #847: GFLOPs: 772.7335. Time: 4788.4284 us. Best GFLOPs: 970.8154
2024-04-30 09:16:31 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #848: GFLOPs: 326.5305. Time: 11331.8002 us. Best GFLOPs: 970.8154
2024-04-30 09:16:31 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #849: GFLOPs: 836.4426. Time: 4423.7095 us. Best GFLOPs: 970.8154
2024-04-30 09:16:31 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #850: GFLOPs: 630.1734. Time: 5871.6840 us. Best GFLOPs: 970.8154
2024-04-30 09:16:31 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #851: GFLOPs: 775.4139. Time: 4771.8758 us. Best GFLOPs: 970.8154
2024-04-30 09:16:31 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #852: GFLOPs: 705.4635. Time: 5245.0326 us. Best GFLOPs: 970.8154
2024-04-30 09:16:31 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #853: GFLOPs: 128.7015. Time: 28750.0792 us. Best GFLOPs: 970.8154
2024-04-30 09:16:31 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #854: GFLOPs: 650.8797. Time: 5684.8893 us. Best GFLOPs: 970.8154
2024-04-30 09:16:31 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #855: GFLOPs: 651.2728. Time: 5681.4582 us. Best GFLOPs: 970.8154
2024-04-30 09:16:31 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #856: GFLOPs: 706.7223. Time: 5235.6900 us. Best GFLOPs: 970.8154
2024-04-30 09:16:31 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #857: GFLOPs: 674.3799. Time: 5486.7869 us. Best GFLOPs: 970.8154
2024-04-30 09:16:31 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #858: GFLOPs: 573.1961. Time: 6455.3459 us. Best GFLOPs: 970.8154
2024-04-30 09:16:31 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #859: GFLOPs: 713.9310. Time: 5182.8246 us. Best GFLOPs: 970.8154
2024-04-30 09:16:31 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #860: GFLOPs: 560.7756. Time: 6598.3240 us. Best GFLOPs: 970.8154
2024-04-30 09:16:31 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #861: GFLOPs: 759.9093. Time: 4869.2375 us. Best GFLOPs: 970.8154
2024-04-30 09:16:31 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #862: GFLOPs: 534.2364. Time: 6926.1077 us. Best GFLOPs: 970.8154
2024-04-30 09:16:31 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #863: GFLOPs: 630.6900. Time: 5866.8741 us. Best GFLOPs: 970.8154
2024-04-30 09:16:31 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #864: GFLOPs: 561.2979. Time: 6592.1839 us. Best GFLOPs: 970.8154
2024-04-30 09:16:31 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #865: GFLOPs: 604.9243. Time: 6116.7631 us. Best GFLOPs: 970.8154
2024-04-30 09:16:31 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #866: GFLOPs: 298.7852. Time: 12384.0784 us. Best GFLOPs: 970.8154
2024-04-30 09:16:31 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #867: GFLOPs: 678.0511. Time: 5457.0801 us. Best GFLOPs: 970.8154
2024-04-30 09:16:31 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #868: GFLOPs: 469.4238. Time: 7882.3839 us. Best GFLOPs: 970.8154
2024-04-30 09:16:31 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #869: GFLOPs: 386.6500. Time: 9569.8411 us. Best GFLOPs: 970.8154
2024-04-30 09:16:31 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #870: GFLOPs: 678.3612. Time: 5454.5853 us. Best GFLOPs: 970.8154
2024-04-30 09:16:31 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #871: GFLOPs: 625.2753. Time: 5917.6793 us. Best GFLOPs: 970.8154
2024-04-30 09:16:31 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #872: GFLOPs: 591.3863. Time: 6256.7881 us. Best GFLOPs: 970.8154
2024-04-30 09:16:31 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #873: GFLOPs: 650.8921. Time: 5684.7810 us. Best GFLOPs: 970.8154
2024-04-30 09:16:31 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #874: GFLOPs: 650.9203. Time: 5684.5343 us. Best GFLOPs: 970.8154
2024-04-30 09:16:31 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #875: GFLOPs: 380.9342. Time: 9713.4325 us. Best GFLOPs: 970.8154
2024-04-30 09:16:31 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #876: GFLOPs: 107.3694. Time: 34462.1487 us. Best GFLOPs: 970.8154
2024-04-30 09:16:31 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #877: GFLOPs: 119.2419. Time: 31030.8512 us. Best GFLOPs: 970.8154
2024-04-30 09:16:31 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #878: GFLOPs: 512.9151. Time: 7214.0182 us. Best GFLOPs: 970.8154
2024-04-30 09:16:31 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #879: GFLOPs: 468.9547. Time: 7890.2702 us. Best GFLOPs: 970.8154
2024-04-30 09:16:31 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #880: GFLOPs: 108.9237. Time: 33970.3737 us. Best GFLOPs: 970.8154
2024-04-30 09:16:31 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #881: GFLOPs: 555.0545. Time: 6666.3339 us. Best GFLOPs: 970.8154
2024-04-30 09:16:31 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #882: GFLOPs: 720.5079. Time: 5135.5147 us. Best GFLOPs: 970.8154
2024-04-30 09:16:31 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #883: GFLOPs: 726.5793. Time: 5092.6015 us. Best GFLOPs: 970.8154
2024-04-30 09:16:31 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #884: GFLOPs: 55.2847. Time: 66929.4863 us. Best GFLOPs: 970.8154
2024-04-30 09:16:31 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #885: GFLOPs: 620.3578. Time: 5964.5884 us. Best GFLOPs: 970.8154
2024-04-30 09:16:31 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #886: GFLOPs: 591.4810. Time: 6255.7868 us. Best GFLOPs: 970.8154
2024-04-30 09:16:31 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #887: GFLOPs: 513.3057. Time: 7208.5281 us. Best GFLOPs: 970.8154
2024-04-30 09:16:31 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #888: GFLOPs: 354.8089. Time: 10428.6538 us. Best GFLOPs: 970.8154
2024-04-30 09:16:31 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #889: GFLOPs: 593.6019. Time: 6233.4354 us. Best GFLOPs: 970.8154
2024-04-30 09:16:31 [INFO] [task_scheduler.cc:121] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #890: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(512)), "float32"), p1: T.Buffer((T.int64(32), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused in T.parallel(T.int64(224), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(14), T.int64(1), T.int64(16), T.int64(1), T.int64(4), T.int64(2), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(28) * T.int64(4) + oc_chunk_1 * T.int64(4) + oc_chunk_2_init * T.int64(4) + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(28), oh_1 * T.int64(28) + oh_2_init * T.int64(2) + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(28) + ow_1 + ow_2_init + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(16), oc_block_1 * T.int64(16) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0 in range(T.int64(128)):
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(30), T.int64(3)):
                        for ax4_fused in T.vectorized(T.int64(4)):
                            with T.block("data_pad"):
                                v_i0, v_i1, v_i2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                                v_i3 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(28) + ax3)
                                v_i4 = T.axis.spatial(T.int64(512), ic_0 * T.int64(4) + ax4_fused)
                                T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                                T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                                data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                    for kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(14), T.int64(1), T.int64(16), T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(2), T.int64(1), T.int64(1)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(28) * T.int64(4) + oc_chunk_1 * T.int64(4) + oc_chunk_2 * T.int64(4) + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(28), oh_1 * T.int64(28) + oh_2 * T.int64(2) + oh_3)
                            v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(28) + ow_1 + ow_2 + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_1 * T.int64(16) + oc_block_2 + oc_block_3)
                            v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(4) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
            for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(4), T.int64(28)):
                for ax3_ax4_fused in T.vectorized(T.int64(16)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(28) * T.int64(4) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(28), ax2)
                        v_ax3 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(28))
                        v_ax4 = T.axis.spatial(T.int64(16), ax3_ax4_fused)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[8, 1, 1, 4])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 14, 2])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[28, 1, 1, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 16, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[128, 4])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=10)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86 = sch.get_loops(block=b68)
l87 = sch.fuse(l71, l72, l73, l74, l75, preserve_unit_iters=True)
sch.parallel(loop=l87)
l88 = sch.fuse(l86, preserve_unit_iters=True)
sch.vectorize(loop=l88)
l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107, l108, l109, l110 = sch.get_loops(block=b69)
l111 = sch.fuse(l89, preserve_unit_iters=True)
sch.parallel(loop=l111)
sch.annotate(block_or_loop=l111, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l111, ann_key="pragma_unroll_explicit", ann_val=1)
l112, l113, l114, l115, l116, l117 = sch.get_loops(block=b70)
l118 = sch.fuse(l116, l117, preserve_unit_iters=True)
sch.vectorize(loop=l118)
b119 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141 = sch.get_loops(block=b119)
b142 = sch.decompose_reduction(block=b119, loop=l126)
2024-04-30 09:16:31 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #891: GFLOPs: 629.3337. Time: 5879.5182 us. Best GFLOPs: 970.8154
2024-04-30 09:16:31 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #892: GFLOPs: 518.9864. Time: 7129.6259 us. Best GFLOPs: 970.8154
2024-04-30 09:16:31 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #893: GFLOPs: 696.3703. Time: 5313.5218 us. Best GFLOPs: 970.8154
2024-04-30 09:16:31 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #894: GFLOPs: 39.4388. Time: 93820.6777 us. Best GFLOPs: 970.8154
2024-04-30 09:16:31 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #895: GFLOPs: 10.4142. Time: 355300.5357 us. Best GFLOPs: 970.8154
2024-04-30 09:16:31 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #896: GFLOPs: 8.5895. Time: 430781.5330 us. Best GFLOPs: 970.8154
2024-04-30 09:33:22 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-30 09:33:24 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-30 09:33:28 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 09:33:28 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-30 09:33:41 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 09:33:55 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 09:34:09 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 09:34:23 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 09:34:32 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.8513  0.8461  0.8128  0.8056  0.7779  0.7702  0.7659  0.7600  0.7508  0.7342  0.7285  0.7192  0.7107  0.7084  0.6989  0.6969
[17 : 32]:	0.6936  0.6840  0.6820  0.6802  0.6790  0.6786  0.6784  0.6783  0.6717  0.6703  0.6646  0.6646  0.6638  0.6632  0.6526  0.6516
[33 : 48]:	0.6457  0.6442  0.6402  0.6397  0.6361  0.6340  0.6333  0.6303  0.6245  0.6222  0.6222  0.6206  0.6200  0.6129  0.6127  0.6111
[49 : 64]:	0.6105  0.6101  0.6008  0.5975  0.5964  0.5931  0.5901  0.5849  0.5848  0.5822  0.5813  0.5791  0.5791  0.5780  0.5773  0.5757
2024-04-30 09:34:33 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-30 09:34:33 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-30 09:36:42 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #897: GFLOPs: 852.8078. Time: 4338.8191 us. Best GFLOPs: 970.8154
2024-04-30 09:36:42 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #898: GFLOPs: 795.1709. Time: 4653.3131 us. Best GFLOPs: 970.8154
2024-04-30 09:36:42 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #899: GFLOPs: 845.1608. Time: 4378.0769 us. Best GFLOPs: 970.8154
2024-04-30 09:36:42 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #900: GFLOPs: 737.5599. Time: 5016.7843 us. Best GFLOPs: 970.8154
2024-04-30 09:36:42 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #901: GFLOPs: 709.7792. Time: 5213.1411 us. Best GFLOPs: 970.8154
2024-04-30 09:36:42 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #902: GFLOPs: 868.2288. Time: 4261.7557 us. Best GFLOPs: 970.8154
2024-04-30 09:36:42 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #903: GFLOPs: 752.6250. Time: 4916.3649 us. Best GFLOPs: 970.8154
2024-04-30 09:36:42 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #904: GFLOPs: 720.2714. Time: 5137.2007 us. Best GFLOPs: 970.8154
2024-04-30 09:36:42 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #905: GFLOPs: 755.2617. Time: 4899.2008 us. Best GFLOPs: 970.8154
2024-04-30 09:36:42 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #906: GFLOPs: 737.1814. Time: 5019.3603 us. Best GFLOPs: 970.8154
2024-04-30 09:36:42 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #907: GFLOPs: 657.7830. Time: 5625.2272 us. Best GFLOPs: 970.8154
2024-04-30 09:36:42 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #908: GFLOPs: 550.1598. Time: 6725.6440 us. Best GFLOPs: 970.8154
2024-04-30 09:36:42 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #909: GFLOPs: 656.5370. Time: 5635.9034 us. Best GFLOPs: 970.8154
2024-04-30 09:36:42 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #910: GFLOPs: 571.6194. Time: 6473.1518 us. Best GFLOPs: 970.8154
2024-04-30 09:36:42 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #911: GFLOPs: 610.0995. Time: 6064.8783 us. Best GFLOPs: 970.8154
2024-04-30 09:36:42 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #912: GFLOPs: 587.7489. Time: 6295.5094 us. Best GFLOPs: 970.8154
2024-04-30 09:36:42 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #913: GFLOPs: 670.3788. Time: 5519.5343 us. Best GFLOPs: 970.8154
2024-04-30 09:36:42 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #914: GFLOPs: 683.5772. Time: 5412.9641 us. Best GFLOPs: 970.8154
2024-04-30 09:36:42 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #915: GFLOPs: 628.0860. Time: 5891.1982 us. Best GFLOPs: 970.8154
2024-04-30 09:36:42 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #916: GFLOPs: 580.6873. Time: 6372.0682 us. Best GFLOPs: 970.8154
2024-04-30 09:36:42 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #917: GFLOPs: 513.7656. Time: 7202.0766 us. Best GFLOPs: 970.8154
2024-04-30 09:36:42 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #918: GFLOPs: 655.9334. Time: 5641.0893 us. Best GFLOPs: 970.8154
2024-04-30 09:36:42 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #919: GFLOPs: 544.6237. Time: 6794.0100 us. Best GFLOPs: 970.8154
2024-04-30 09:36:42 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #920: GFLOPs: 594.1919. Time: 6227.2458 us. Best GFLOPs: 970.8154
2024-04-30 09:36:42 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #921: GFLOPs: 505.2436. Time: 7323.5536 us. Best GFLOPs: 970.8154
2024-04-30 09:36:42 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #922: GFLOPs: 621.2563. Time: 5955.9617 us. Best GFLOPs: 970.8154
2024-04-30 09:36:42 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #923: GFLOPs: 538.0387. Time: 6877.1614 us. Best GFLOPs: 970.8154
2024-04-30 09:36:42 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #924: GFLOPs: 541.8877. Time: 6828.3126 us. Best GFLOPs: 970.8154
2024-04-30 09:36:42 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #925: GFLOPs: 676.0963. Time: 5472.8582 us. Best GFLOPs: 970.8154
2024-04-30 09:36:42 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #926: GFLOPs: 534.7078. Time: 6920.0021 us. Best GFLOPs: 970.8154
2024-04-30 09:36:42 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #927: GFLOPs: 619.3795. Time: 5974.0091 us. Best GFLOPs: 970.8154
2024-04-30 09:36:42 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #928: GFLOPs: 525.6054. Time: 7039.8416 us. Best GFLOPs: 970.8154
2024-04-30 09:36:42 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #929: GFLOPs: 645.1612. Time: 5735.2785 us. Best GFLOPs: 970.8154
2024-04-30 09:36:42 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #930: GFLOPs: 700.9795. Time: 5278.5835 us. Best GFLOPs: 970.8154
2024-04-30 09:36:42 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #931: GFLOPs: 547.7270. Time: 6755.5173 us. Best GFLOPs: 970.8154
2024-04-30 09:36:42 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #932: GFLOPs: 526.4983. Time: 7027.9034 us. Best GFLOPs: 970.8154
2024-04-30 09:36:42 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #933: GFLOPs: 601.5861. Time: 6150.7051 us. Best GFLOPs: 970.8154
2024-04-30 09:36:42 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #934: GFLOPs: 734.4644. Time: 5037.9285 us. Best GFLOPs: 970.8154
2024-04-30 09:36:42 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #935: GFLOPs: 705.4536. Time: 5245.1061 us. Best GFLOPs: 970.8154
2024-04-30 09:36:42 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #936: GFLOPs: 509.8552. Time: 7257.3132 us. Best GFLOPs: 970.8154
2024-04-30 09:36:42 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #937: GFLOPs: 43.1247. Time: 85801.7787 us. Best GFLOPs: 970.8154
2024-04-30 09:36:42 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #938: GFLOPs: 663.9342. Time: 5573.1113 us. Best GFLOPs: 970.8154
2024-04-30 09:36:42 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #939: GFLOPs: 566.5278. Time: 6531.3284 us. Best GFLOPs: 970.8154
2024-04-30 09:36:42 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #940: GFLOPs: 608.5347. Time: 6080.4732 us. Best GFLOPs: 970.8154
2024-04-30 09:36:42 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #941: GFLOPs: 605.7637. Time: 6108.2879 us. Best GFLOPs: 970.8154
2024-04-30 09:36:42 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #942: GFLOPs: 274.0283. Time: 13502.9070 us. Best GFLOPs: 970.8154
2024-04-30 09:36:42 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #943: GFLOPs: 499.7543. Time: 7403.9957 us. Best GFLOPs: 970.8154
2024-04-30 09:36:42 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #944: GFLOPs: 525.8217. Time: 7036.9455 us. Best GFLOPs: 970.8154
2024-04-30 09:36:42 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #945: GFLOPs: 671.5227. Time: 5510.1321 us. Best GFLOPs: 970.8154
2024-04-30 09:36:42 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #946: GFLOPs: 439.6932. Time: 8415.3653 us. Best GFLOPs: 970.8154
2024-04-30 09:36:42 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #947: GFLOPs: 452.0476. Time: 8185.3752 us. Best GFLOPs: 970.8154
2024-04-30 09:36:42 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #948: GFLOPs: 619.3523. Time: 5974.2720 us. Best GFLOPs: 970.8154
2024-04-30 09:36:42 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #949: GFLOPs: 552.3373. Time: 6699.1290 us. Best GFLOPs: 970.8154
2024-04-30 09:36:42 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #950: GFLOPs: 687.1435. Time: 5384.8709 us. Best GFLOPs: 970.8154
2024-04-30 09:36:42 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #951: GFLOPs: 530.5541. Time: 6974.1778 us. Best GFLOPs: 970.8154
2024-04-30 09:36:42 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #952: GFLOPs: 561.0319. Time: 6595.3096 us. Best GFLOPs: 970.8154
2024-04-30 09:36:42 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #953: GFLOPs: 497.6543. Time: 7435.2391 us. Best GFLOPs: 970.8154
2024-04-30 09:36:42 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #954: GFLOPs: 592.2649. Time: 6247.5068 us. Best GFLOPs: 970.8154
2024-04-30 09:36:42 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #955: GFLOPs: 607.7319. Time: 6088.5058 us. Best GFLOPs: 970.8154
2024-04-30 09:36:42 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #956: GFLOPs: 133.5386. Time: 27708.6910 us. Best GFLOPs: 970.8154
2024-04-30 09:36:42 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #957: GFLOPs: 354.1929. Time: 10446.7894 us. Best GFLOPs: 970.8154
2024-04-30 09:36:42 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #958: GFLOPs: 21.0139. Time: 176082.7247 us. Best GFLOPs: 970.8154
2024-04-30 09:36:42 [INFO] [task_scheduler.cc:121] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #959: Error in running:
LocalRunner: Timeout, killed after 30 seconds

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(512)), "float32"), p1: T.Buffer((T.int64(32), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused_fused in T.parallel(T.int64(8)):
            for n_1, oc_chunk_1 in T.grid(T.int64(1), T.int64(4)):
                for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(512)):
                    with T.block("data_pad"):
                        v_i0, v_i1, v_i2, v_i3, v_i4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                        T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                        T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                        data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                for oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(7), T.int64(2)):
                    for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(4), T.int64(1), T.int64(2), T.int64(28), T.int64(2), T.int64(1)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused_fused // T.int64(2) * T.int64(8) + oc_chunk_1 * T.int64(2) + oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(28), oh_1 * T.int64(28) + oh_2_init * T.int64(28) + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(28), ow_1 * T.int64(4) + ow_2_init * T.int64(2) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused_fused % T.int64(2) * T.int64(8) + oc_block_1 * T.int64(4) + oc_block_2_init + oc_block_3_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                    for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(32), T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(4), T.int64(16), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(28), T.int64(2), T.int64(1)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused_fused // T.int64(2) * T.int64(8) + oc_chunk_1 * T.int64(2) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(28), oh_1 * T.int64(28) + oh_2 * T.int64(28) + oh_3)
                            v_ow = T.axis.spatial(T.int64(28), ow_1 * T.int64(4) + ow_2 * T.int64(2) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused_fused % T.int64(2) * T.int64(8) + oc_block_1 * T.int64(4) + oc_block_2 + oc_block_3)
                            v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(16) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(8), T.int64(28), T.int64(28)):
                for ax4_fused in T.vectorized(T.int64(8)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused_fused // T.int64(2) * T.int64(8) + ax1)
                        v_ax2, v_ax3 = T.axis.remap("SS", [ax2, ax3])
                        v_ax4 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused_fused % T.int64(2) * T.int64(8) + ax4_fused)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[4, 4, 1, 2])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 1, 28])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 7, 2, 2])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[2, 2, 4, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[32, 16])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=6)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82 = sch.get_loops(block=b68)
l83 = sch.fuse(l71, l72, l73, l74, l75, preserve_unit_iters=True)
sch.parallel(loop=l83)
l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105 = sch.get_loops(block=b69)
l106 = sch.fuse(l84, preserve_unit_iters=True)
sch.parallel(loop=l106)
l107, l108, l109, l110, l111, l112 = sch.get_loops(block=b70)
l113 = sch.fuse(l107, preserve_unit_iters=True)
sch.parallel(loop=l113)
l114 = sch.fuse(l112, preserve_unit_iters=True)
sch.vectorize(loop=l114)
b115 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137 = sch.get_loops(block=b115)
b138 = sch.decompose_reduction(block=b115, loop=l122)
2024-04-30 09:36:42 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #960: GFLOPs: 14.9013. Time: 248312.6890 us. Best GFLOPs: 970.8154
2024-04-30 09:39:55 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-30 09:39:57 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-30 09:40:01 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 09:40:01 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-30 09:40:14 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 09:40:28 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 09:40:42 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 09:40:56 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 09:41:05 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.8679  0.8506  0.8335  0.8335  0.8105  0.8059  0.7868  0.7720  0.7664  0.7441  0.7169  0.7150  0.7113  0.6973  0.6956  0.6950
[17 : 32]:	0.6898  0.6774  0.6754  0.6700  0.6678  0.6532  0.6492  0.6483  0.6480  0.6478  0.6469  0.6432  0.6384  0.6326  0.6322  0.6308
[33 : 48]:	0.6293  0.6208  0.6186  0.6186  0.6159  0.6159  0.6105  0.6084  0.6084  0.6077  0.6065  0.6062  0.5996  0.5960  0.5958  0.5946
[49 : 64]:	0.5887  0.5867  0.5867  0.5867  0.5867  0.5867  0.5867  0.5848  0.5846  0.5827  0.5825  0.5824  0.5812  0.5801  0.5782  0.5769
2024-04-30 09:41:05 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-30 09:41:05 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-30 09:43:36 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #961: GFLOPs: 925.3300. Time: 3998.7668 us. Best GFLOPs: 970.8154
2024-04-30 09:43:36 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #962: GFLOPs: 920.4247. Time: 4020.0778 us. Best GFLOPs: 970.8154
2024-04-30 09:43:36 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #963: GFLOPs: 811.3983. Time: 4560.2497 us. Best GFLOPs: 970.8154
2024-04-30 09:43:36 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #964: GFLOPs: 817.8272. Time: 4524.4020 us. Best GFLOPs: 970.8154
2024-04-30 09:43:36 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #965: GFLOPs: 832.2165. Time: 4446.1733 us. Best GFLOPs: 970.8154
2024-04-30 09:43:36 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #966: GFLOPs: 770.3094. Time: 4803.4968 us. Best GFLOPs: 970.8154
2024-04-30 09:43:36 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #967: GFLOPs: 760.3173. Time: 4866.6245 us. Best GFLOPs: 970.8154
2024-04-30 09:43:36 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #968: GFLOPs: 758.7430. Time: 4876.7224 us. Best GFLOPs: 970.8154
2024-04-30 09:43:36 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #969: GFLOPs: 804.5186. Time: 4599.2463 us. Best GFLOPs: 970.8154
2024-04-30 09:43:36 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #970: GFLOPs: 787.0855. Time: 4701.1144 us. Best GFLOPs: 970.8154
2024-04-30 09:43:36 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #971: GFLOPs: 730.6269. Time: 5064.3890 us. Best GFLOPs: 970.8154
2024-04-30 09:43:36 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #972: GFLOPs: 92.4762. Time: 40012.2213 us. Best GFLOPs: 970.8154
2024-04-30 09:43:36 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #973: GFLOPs: 669.4572. Time: 5527.1331 us. Best GFLOPs: 970.8154
2024-04-30 09:43:36 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #974: GFLOPs: 826.0564. Time: 4479.3296 us. Best GFLOPs: 970.8154
2024-04-30 09:43:36 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #975: GFLOPs: 680.4523. Time: 5437.8229 us. Best GFLOPs: 970.8154
2024-04-30 09:43:36 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #976: GFLOPs: 587.6365. Time: 6296.7137 us. Best GFLOPs: 970.8154
2024-04-30 09:43:36 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #977: GFLOPs: 698.1999. Time: 5299.5978 us. Best GFLOPs: 970.8154
2024-04-30 09:43:36 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #978: GFLOPs: 662.1640. Time: 5588.0098 us. Best GFLOPs: 970.8154
2024-04-30 09:43:36 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #979: GFLOPs: 614.9475. Time: 6017.0645 us. Best GFLOPs: 970.8154
2024-04-30 09:43:36 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #980: GFLOPs: 324.1198. Time: 11416.0850 us. Best GFLOPs: 970.8154
2024-04-30 09:43:36 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #981: GFLOPs: 834.3194. Time: 4434.9670 us. Best GFLOPs: 970.8154
2024-04-30 09:43:36 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #982: GFLOPs: 634.0892. Time: 5835.4236 us. Best GFLOPs: 970.8154
2024-04-30 09:43:36 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #983: GFLOPs: 766.2231. Time: 4829.1143 us. Best GFLOPs: 970.8154
2024-04-30 09:43:36 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #984: GFLOPs: 287.2309. Time: 12882.2464 us. Best GFLOPs: 970.8154
2024-04-30 09:43:36 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #985: GFLOPs: 593.4522. Time: 6235.0071 us. Best GFLOPs: 970.8154
2024-04-30 09:43:36 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #986: GFLOPs: 665.3354. Time: 5561.3740 us. Best GFLOPs: 970.8154
2024-04-30 09:43:36 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #987: GFLOPs: 605.1008. Time: 6114.9798 us. Best GFLOPs: 970.8154
2024-04-30 09:43:36 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #988: GFLOPs: 655.7397. Time: 5642.7558 us. Best GFLOPs: 970.8154
2024-04-30 09:43:36 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #989: GFLOPs: 297.5475. Time: 12435.5927 us. Best GFLOPs: 970.8154
2024-04-30 09:43:36 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #990: GFLOPs: 626.6124. Time: 5905.0526 us. Best GFLOPs: 970.8154
2024-04-30 09:43:36 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #991: GFLOPs: 563.8895. Time: 6561.8871 us. Best GFLOPs: 970.8154
2024-04-30 09:43:36 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #992: GFLOPs: 627.7652. Time: 5894.2089 us. Best GFLOPs: 970.8154
2024-04-30 09:43:36 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #993: GFLOPs: 474.1481. Time: 7803.8462 us. Best GFLOPs: 970.8154
2024-04-30 09:43:36 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #994: GFLOPs: 716.4098. Time: 5164.8917 us. Best GFLOPs: 970.8154
2024-04-30 09:43:36 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #995: GFLOPs: 688.8485. Time: 5371.5428 us. Best GFLOPs: 970.8154
2024-04-30 09:43:36 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #996: GFLOPs: 748.2258. Time: 4945.2707 us. Best GFLOPs: 970.8154
2024-04-30 09:43:36 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #997: GFLOPs: 763.0883. Time: 4848.9528 us. Best GFLOPs: 970.8154
2024-04-30 09:43:36 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #998: GFLOPs: 81.0322. Time: 45663.0887 us. Best GFLOPs: 970.8154
2024-04-30 09:43:36 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #999: GFLOPs: 551.3823. Time: 6710.7326 us. Best GFLOPs: 970.8154
2024-04-30 09:43:36 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1000: GFLOPs: 611.0400. Time: 6055.5428 us. Best GFLOPs: 970.8154
2024-04-30 09:43:36 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1001: GFLOPs: 564.3102. Time: 6556.9951 us. Best GFLOPs: 970.8154
2024-04-30 09:43:36 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1002: GFLOPs: 553.0199. Time: 6690.8603 us. Best GFLOPs: 970.8154
2024-04-30 09:43:36 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1003: GFLOPs: 553.6328. Time: 6683.4528 us. Best GFLOPs: 970.8154
2024-04-30 09:43:36 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1004: GFLOPs: 111.6197. Time: 33149.8603 us. Best GFLOPs: 970.8154
2024-04-30 09:43:36 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1005: GFLOPs: 678.4935. Time: 5453.5216 us. Best GFLOPs: 970.8154
2024-04-30 09:43:36 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1006: GFLOPs: 472.5705. Time: 7829.8983 us. Best GFLOPs: 970.8154
2024-04-30 09:43:36 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1007: GFLOPs: 273.4563. Time: 13531.1513 us. Best GFLOPs: 970.8154
2024-04-30 09:43:36 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1008: GFLOPs: 576.2109. Time: 6421.5703 us. Best GFLOPs: 970.8154
2024-04-30 09:43:36 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1009: GFLOPs: 343.9670. Time: 10757.3668 us. Best GFLOPs: 970.8154
2024-04-30 09:43:36 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1010: GFLOPs: 10.6675. Time: 346866.1717 us. Best GFLOPs: 970.8154
2024-04-30 09:43:36 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1011: GFLOPs: 10.7630. Time: 343787.0987 us. Best GFLOPs: 970.8154
2024-04-30 09:43:36 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1012: GFLOPs: 5.3898. Time: 686514.4490 us. Best GFLOPs: 970.8154
2024-04-30 09:43:36 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1013: GFLOPs: 5.3910. Time: 686365.3530 us. Best GFLOPs: 970.8154
2024-04-30 09:43:36 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1014: GFLOPs: 9.6574. Time: 383142.5017 us. Best GFLOPs: 970.8154
2024-04-30 09:43:36 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1015: GFLOPs: 9.6905. Time: 381835.8657 us. Best GFLOPs: 970.8154
2024-04-30 09:43:36 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1016: GFLOPs: 330.8133. Time: 11185.0966 us. Best GFLOPs: 970.8154
2024-04-30 09:43:36 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1017: GFLOPs: 17.5905. Time: 210350.8870 us. Best GFLOPs: 970.8154
2024-04-30 09:43:36 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1018: GFLOPs: 338.4797. Time: 10931.7608 us. Best GFLOPs: 970.8154
2024-04-30 09:43:36 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1019: GFLOPs: 558.0203. Time: 6630.9037 us. Best GFLOPs: 970.8154
2024-04-30 09:43:36 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1020: GFLOPs: 538.2519. Time: 6874.4374 us. Best GFLOPs: 970.8154
2024-04-30 09:43:36 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1021: GFLOPs: 577.1417. Time: 6411.2145 us. Best GFLOPs: 970.8154
2024-04-30 09:43:36 [INFO] [task_scheduler.cc:121] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1022: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(512)), "float32"), p1: T.Buffer((T.int64(32), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_fused_fused in T.parallel(T.int64(56), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(9), T.int64(4), T.int64(512)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(14) * T.int64(7) + ax2)
                    v_i3 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(14) * T.int64(2) + ax3)
                    v_i4 = T.axis.spatial(T.int64(512), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oc_block_0, n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(32), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(2)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(32), oc_chunk_1 * T.int64(32) + oc_chunk_2_init + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(14) * T.int64(7) + oh_1 * T.int64(7) + oh_2_init * T.int64(7) + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(14) * T.int64(2) + ow_1 * T.int64(2) + ow_2_init + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(4) + oc_block_1 * T.int64(2) + oc_block_2_init * T.int64(2) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(8), T.int64(3), T.int64(3), T.int64(1), T.int64(32), T.int64(1), T.int64(2), T.int64(1), T.int64(64), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1)):
                    for oc_block_3_fused in T.vectorized(T.int64(2)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(32), oc_chunk_1 * T.int64(32) + oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(14) * T.int64(7) + oh_1 * T.int64(7) + oh_2 * T.int64(7) + oh_3)
                            v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(14) * T.int64(2) + ow_1 * T.int64(2) + ow_2 + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(4) + oc_block_1 * T.int64(2) + oc_block_2 * T.int64(2) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(64) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(32), T.int64(7), T.int64(2)):
                    for ax4_fused in T.vectorized(T.int64(2)):
                        with T.block("T_relu"):
                            v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                            v_ax2 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(14) * T.int64(7) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(14) * T.int64(2) + ax3)
                            v_ax4 = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(4) + oc_block_1 * T.int64(2) + ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 32, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[4, 1, 1, 7])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[14, 1, 2, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[4, 2, 1, 2])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[8, 64])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=3)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79 = sch.get_loops(block=b68)
l80 = sch.fuse(l71, l72, l73, l74, preserve_unit_iters=True)
sch.parallel(loop=l80)
l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l81, preserve_unit_iters=True)
sch.parallel(loop=l104)
l105 = sch.fuse(l103, preserve_unit_iters=True)
sch.vectorize(loop=l105)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l106, l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117 = sch.get_loops(block=b70)
l118 = sch.fuse(l117, preserve_unit_iters=True)
sch.vectorize(loop=l118)
b119 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141, l142 = sch.get_loops(block=b119)
b143 = sch.decompose_reduction(block=b119, loop=l127)
2024-04-30 09:43:36 [INFO] [task_scheduler.cc:121] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1023: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(512)), "float32"), p1: T.Buffer((T.int64(32), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused in T.parallel(T.int64(2), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1 in T.grid(T.int64(1), T.int64(1), T.int64(4)):
                for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(9), T.int64(30), T.int64(512)):
                    with T.block("data_pad"):
                        v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                        v_i2 = T.axis.spatial(T.int64(30), oh_1 * T.int64(7) + ax2)
                        v_i3, v_i4 = T.axis.remap("SS", [ax3, ax4])
                        T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                        T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                        data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                for ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(8)):
                    for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(16), T.int64(1), T.int64(4), T.int64(2), T.int64(1), T.int64(1), T.int64(7), T.int64(7), T.int64(1)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused * T.int64(16) + oc_chunk_1 * T.int64(16) + oc_chunk_2_init + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(28), oh_1 * T.int64(7) + oh_2_init * T.int64(7) + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(28), ow_1 * T.int64(28) + ow_2_init * T.int64(7) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_1 * T.int64(2) + oc_block_2_init + oc_block_3_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                    for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(16), T.int64(1), T.int64(1), T.int64(1), T.int64(16), T.int64(1), T.int64(4), T.int64(2), T.int64(32), T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(7), T.int64(7), T.int64(1)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused * T.int64(16) + oc_chunk_1 * T.int64(16) + oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(28), oh_1 * T.int64(7) + oh_2 * T.int64(7) + oh_3)
                            v_ow = T.axis.spatial(T.int64(28), ow_1 * T.int64(28) + ow_2 * T.int64(7) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_1 * T.int64(2) + oc_block_2 + oc_block_3)
                            v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(32) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(16), T.int64(28), T.int64(28)):
                for ax4_fused in T.vectorized(T.int64(16)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused * T.int64(16) + ax1)
                        v_ax2, v_ax3, v_ax4 = T.axis.remap("SSS", [ax2, ax3, ax4_fused])
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[2, 1, 16, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 4, 1, 7])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 4, 7])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 8, 2, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[16, 32])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=7)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83 = sch.get_loops(block=b68)
l84 = sch.fuse(l71, l72, l73, l74, l75, preserve_unit_iters=True)
sch.parallel(loop=l84)
l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106 = sch.get_loops(block=b69)
l107 = sch.fuse(l85, preserve_unit_iters=True)
sch.parallel(loop=l107)
sch.annotate(block_or_loop=l107, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l107, ann_key="pragma_unroll_explicit", ann_val=1)
l108, l109, l110, l111, l112, l113 = sch.get_loops(block=b70)
l114 = sch.fuse(l113, preserve_unit_iters=True)
sch.vectorize(loop=l114)
b115 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137 = sch.get_loops(block=b115)
b138 = sch.decompose_reduction(block=b115, loop=l122)
2024-04-30 09:43:36 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1024: GFLOPs: 8.3774. Time: 441688.1767 us. Best GFLOPs: 970.8154
2024-04-30 09:46:35 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-30 09:46:36 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-30 09:46:40 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 09:46:40 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-30 09:46:53 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 09:47:07 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 09:47:21 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 09:47:36 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 09:47:45 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.8910  0.8339  0.8239  0.7474  0.7325  0.7094  0.7021  0.6972  0.6824  0.6768  0.6720  0.6654  0.6618  0.6617  0.6599  0.6578
[17 : 32]:	0.6562  0.6543  0.6522  0.6522  0.6519  0.6515  0.6506  0.6442  0.6433  0.6429  0.6367  0.6367  0.6363  0.6345  0.6341  0.6341
[33 : 48]:	0.6328  0.6328  0.6219  0.6174  0.6168  0.6116  0.6077  0.6073  0.6061  0.6045  0.5944  0.5913  0.5902  0.5897  0.5882  0.5882
[49 : 64]:	0.5879  0.5879  0.5866  0.5852  0.5840  0.5832  0.5820  0.5807  0.5803  0.5746  0.5736  0.5683  0.5680  0.5675  0.5659  0.5658
2024-04-30 09:47:45 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-30 09:47:45 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-30 09:49:56 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1025: GFLOPs: 931.2512. Time: 3973.3413 us. Best GFLOPs: 970.8154
2024-04-30 09:49:56 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1026: GFLOPs: 809.2873. Time: 4572.1453 us. Best GFLOPs: 970.8154
2024-04-30 09:49:56 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1027: GFLOPs: 839.9210. Time: 4405.3891 us. Best GFLOPs: 970.8154
2024-04-30 09:49:56 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1028: GFLOPs: 877.6474. Time: 4216.0199 us. Best GFLOPs: 970.8154
2024-04-30 09:49:56 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1029: GFLOPs: 763.5363. Time: 4846.1075 us. Best GFLOPs: 970.8154
2024-04-30 09:49:56 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1030: GFLOPs: 678.4939. Time: 5453.5183 us. Best GFLOPs: 970.8154
2024-04-30 09:49:56 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1031: GFLOPs: 379.9104. Time: 9739.6107 us. Best GFLOPs: 970.8154
2024-04-30 09:49:56 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1032: GFLOPs: 832.5863. Time: 4444.1988 us. Best GFLOPs: 970.8154
2024-04-30 09:49:56 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1033: GFLOPs: 732.8332. Time: 5049.1421 us. Best GFLOPs: 970.8154
2024-04-30 09:49:56 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1034: GFLOPs: 518.0083. Time: 7143.0883 us. Best GFLOPs: 970.8154
2024-04-30 09:49:56 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1035: GFLOPs: 669.3070. Time: 5528.3733 us. Best GFLOPs: 970.8154
2024-04-30 09:49:56 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1036: GFLOPs: 675.5265. Time: 5477.4740 us. Best GFLOPs: 970.8154
2024-04-30 09:49:56 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1037: GFLOPs: 540.7767. Time: 6842.3419 us. Best GFLOPs: 970.8154
2024-04-30 09:49:56 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1038: GFLOPs: 620.0873. Time: 5967.1900 us. Best GFLOPs: 970.8154
2024-04-30 09:49:56 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1039: GFLOPs: 616.9318. Time: 5997.7112 us. Best GFLOPs: 970.8154
2024-04-30 09:49:56 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1040: GFLOPs: 559.7302. Time: 6610.6478 us. Best GFLOPs: 970.8154
2024-04-30 09:49:56 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1041: GFLOPs: 640.6119. Time: 5776.0069 us. Best GFLOPs: 970.8154
2024-04-30 09:49:56 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1042: GFLOPs: 123.5767. Time: 29942.3567 us. Best GFLOPs: 970.8154
2024-04-30 09:49:56 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1043: GFLOPs: 682.9026. Time: 5418.3114 us. Best GFLOPs: 970.8154
2024-04-30 09:49:56 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1044: GFLOPs: 632.9612. Time: 5845.8226 us. Best GFLOPs: 970.8154
2024-04-30 09:49:56 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1045: GFLOPs: 583.2918. Time: 6343.6157 us. Best GFLOPs: 970.8154
2024-04-30 09:49:56 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1046: GFLOPs: 598.9785. Time: 6177.4825 us. Best GFLOPs: 970.8154
2024-04-30 09:49:56 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1047: GFLOPs: 559.4947. Time: 6613.4298 us. Best GFLOPs: 970.8154
2024-04-30 09:49:56 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1048: GFLOPs: 567.1136. Time: 6524.5813 us. Best GFLOPs: 970.8154
2024-04-30 09:49:56 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1049: GFLOPs: 556.1224. Time: 6653.5336 us. Best GFLOPs: 970.8154
2024-04-30 09:49:56 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1050: GFLOPs: 584.3926. Time: 6331.6668 us. Best GFLOPs: 970.8154
2024-04-30 09:49:56 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1051: GFLOPs: 769.1495. Time: 4810.7411 us. Best GFLOPs: 970.8154
2024-04-30 09:49:56 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1052: GFLOPs: 758.6555. Time: 4877.2847 us. Best GFLOPs: 970.8154
2024-04-30 09:49:56 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1053: GFLOPs: 613.7335. Time: 6028.9670 us. Best GFLOPs: 970.8154
2024-04-30 09:49:56 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1054: GFLOPs: 490.2650. Time: 7547.3046 us. Best GFLOPs: 970.8154
2024-04-30 09:49:56 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1055: GFLOPs: 652.9355. Time: 5666.9900 us. Best GFLOPs: 970.8154
2024-04-30 09:49:56 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1056: GFLOPs: 655.9349. Time: 5641.0762 us. Best GFLOPs: 970.8154
2024-04-30 09:49:56 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1057: GFLOPs: 762.1729. Time: 4854.7766 us. Best GFLOPs: 970.8154
2024-04-30 09:49:56 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1058: GFLOPs: 767.6903. Time: 4819.8850 us. Best GFLOPs: 970.8154
2024-04-30 09:49:56 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1059: GFLOPs: 631.7154. Time: 5857.3516 us. Best GFLOPs: 970.8154
2024-04-30 09:49:56 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1060: GFLOPs: 583.0309. Time: 6346.4545 us. Best GFLOPs: 970.8154
2024-04-30 09:49:56 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1061: GFLOPs: 517.0976. Time: 7155.6678 us. Best GFLOPs: 970.8154
2024-04-30 09:49:56 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1062: GFLOPs: 625.5751. Time: 5914.8438 us. Best GFLOPs: 970.8154
2024-04-30 09:49:56 [INFO] [task_scheduler.cc:121] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1063: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(512)), "float32"), p1: T.Buffer((T.int64(32), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_fused_fused in T.parallel(T.int64(224), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for oc_block_0 in range(T.int64(1)):
                for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                    for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(14), T.int64(2), T.int64(16), T.int64(1), T.int64(2), T.int64(2), T.int64(1), T.int64(1)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(14) * T.int64(2) + oc_chunk_1 * T.int64(2) + oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(28), oh_1 * T.int64(28) + oh_2_init * T.int64(2) + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(14) * T.int64(2) + ow_1 * T.int64(2) + ow_2_init + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2_init + oc_block_3_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                    for ic_0 in range(T.int64(64)):
                        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(30), T.int64(4)):
                            for ax4_fused in T.vectorized(T.int64(8)):
                                with T.block("data_pad"):
                                    v_i0, v_i1, v_i2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                                    v_i3 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(14) * T.int64(2) + ax3)
                                    v_i4 = T.axis.spatial(T.int64(512), ic_0 * T.int64(8) + ax4_fused)
                                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                        for kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(14), T.int64(2), T.int64(16), T.int64(8), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(2), T.int64(1), T.int64(1)):
                            with T.block("conv2d_NCHWc_update"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                                v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(14) * T.int64(2) + oc_chunk_1 * T.int64(2) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                                v_oh = T.axis.spatial(T.int64(28), oh_1 * T.int64(28) + oh_2 * T.int64(2) + oh_3)
                                v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(14) * T.int64(2) + ow_1 * T.int64(2) + ow_2 + ow_3)
                                v_oc_block = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2 + oc_block_3)
                                v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(8) + ic_1)
                                v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                                v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                                T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
                for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(2), T.int64(28)):
                    for ax3_ax4_fused in T.vectorized(T.int64(32)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(14) * T.int64(2) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(28), ax2)
                            v_ax3 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(14) * T.int64(2) + ax3_ax4_fused // T.int64(16))
                            v_ax4 = T.axis.spatial(T.int64(16), ax3_ax4_fused % T.int64(16))
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[16, 1, 1, 2])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 14, 2])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[14, 1, 2, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 16, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[64, 8])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=32)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=10)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86 = sch.get_loops(block=b68)
l87 = sch.fuse(l71, l72, l73, l74, preserve_unit_iters=True)
sch.parallel(loop=l87)
l88 = sch.fuse(l86, preserve_unit_iters=True)
sch.vectorize(loop=l88)
l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107, l108, l109, l110, l111 = sch.get_loops(block=b69)
l112 = sch.fuse(l89, preserve_unit_iters=True)
sch.parallel(loop=l112)
sch.annotate(block_or_loop=l112, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l112, ann_key="pragma_unroll_explicit", ann_val=1)
l113, l114, l115, l116, l117, l118, l119 = sch.get_loops(block=b70)
l120 = sch.fuse(l118, l119, preserve_unit_iters=True)
sch.vectorize(loop=l120)
b121 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141, l142, l143, l144 = sch.get_loops(block=b121)
b145 = sch.decompose_reduction(block=b121, loop=l129)
2024-04-30 09:49:56 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1064: GFLOPs: 701.7867. Time: 5272.5125 us. Best GFLOPs: 970.8154
2024-04-30 09:49:56 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1065: GFLOPs: 403.7551. Time: 9164.4145 us. Best GFLOPs: 970.8154
2024-04-30 09:49:56 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1066: GFLOPs: 608.4543. Time: 6081.2767 us. Best GFLOPs: 970.8154
2024-04-30 09:49:56 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1067: GFLOPs: 312.1578. Time: 11853.5546 us. Best GFLOPs: 970.8154
2024-04-30 09:49:56 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1068: GFLOPs: 116.7093. Time: 31704.2295 us. Best GFLOPs: 970.8154
2024-04-30 09:49:56 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1069: GFLOPs: 563.3021. Time: 6568.7290 us. Best GFLOPs: 970.8154
2024-04-30 09:49:56 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1070: GFLOPs: 676.7363. Time: 5467.6817 us. Best GFLOPs: 970.8154
2024-04-30 09:49:56 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1071: GFLOPs: 684.4022. Time: 5406.4396 us. Best GFLOPs: 970.8154
2024-04-30 09:49:56 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1072: GFLOPs: 516.1467. Time: 7168.8510 us. Best GFLOPs: 970.8154
2024-04-30 09:49:56 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1073: GFLOPs: 105.8463. Time: 34958.0367 us. Best GFLOPs: 970.8154
2024-04-30 09:49:56 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1074: GFLOPs: 106.3690. Time: 34786.2470 us. Best GFLOPs: 970.8154
2024-04-30 09:49:56 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1075: GFLOPs: 583.8359. Time: 6337.7037 us. Best GFLOPs: 970.8154
2024-04-30 09:49:56 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1076: GFLOPs: 510.9323. Time: 7242.0136 us. Best GFLOPs: 970.8154
2024-04-30 09:49:56 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1077: GFLOPs: 477.5723. Time: 7747.8922 us. Best GFLOPs: 970.8154
2024-04-30 09:49:56 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1078: GFLOPs: 608.6180. Time: 6079.6414 us. Best GFLOPs: 970.8154
2024-04-30 09:49:56 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1079: GFLOPs: 662.5696. Time: 5584.5892 us. Best GFLOPs: 970.8154
2024-04-30 09:49:56 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1080: GFLOPs: 571.7689. Time: 6471.4592 us. Best GFLOPs: 970.8154
2024-04-30 09:49:56 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1081: GFLOPs: 539.2968. Time: 6861.1184 us. Best GFLOPs: 970.8154
2024-04-30 09:49:56 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1082: GFLOPs: 581.5644. Time: 6362.4573 us. Best GFLOPs: 970.8154
2024-04-30 09:49:56 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1083: GFLOPs: 372.0542. Time: 9945.2688 us. Best GFLOPs: 970.8154
2024-04-30 09:49:56 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1084: GFLOPs: 111.1098. Time: 33302.0020 us. Best GFLOPs: 970.8154
2024-04-30 09:49:56 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1085: GFLOPs: 124.7889. Time: 29651.4990 us. Best GFLOPs: 970.8154
2024-04-30 09:49:56 [INFO] [task_scheduler.cc:121] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1086: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(512)), "float32"), p1: T.Buffer((T.int64(32), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused in T.parallel(T.int64(1792), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(6), T.int64(30), T.int64(512)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(7) * T.int64(4) + ax2)
                    v_i3, v_i4 = T.axis.remap("SS", [ax3, ax4])
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(2)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(7), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(56) + oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(7) * T.int64(4) + oh_2_init * T.int64(4) + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(28), ow_1 * T.int64(28) + ow_2_init * T.int64(7) + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(56) // T.int64(7) * T.int64(2) + oc_block_1 + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(64), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(1), T.int64(8), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(7), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(56) + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(7) * T.int64(4) + oh_2 * T.int64(4) + oh_3)
                        v_ow = T.axis.spatial(T.int64(28), ow_1 * T.int64(28) + ow_2 * T.int64(7) + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(56) // T.int64(7) * T.int64(2) + oc_block_1 + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(8) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
                for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(28), T.int64(1)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(56) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(7) * T.int64(4) + ax2)
                        v_ax3 = T.axis.spatial(T.int64(28), ax3)
                        v_ax4 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(56) // T.int64(7) * T.int64(2) + oc_block_1 + ax4)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[32, 1, 1, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 7, 1, 4])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 4, 7])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[8, 2, 1, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[64, 8])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=7)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83 = sch.get_loops(block=b68)
l84 = sch.fuse(l71, l72, l73, l74, l75, l76, l77, l78, preserve_unit_iters=True)
sch.parallel(loop=l84)
l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l85, preserve_unit_iters=True)
sch.parallel(loop=l104)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109, l110, l111, l112 = sch.get_loops(block=b70)
b113 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132 = sch.get_loops(block=b113)
b133 = sch.decompose_reduction(block=b113, loop=l117)
2024-04-30 09:49:56 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1087: GFLOPs: 60.7265. Time: 60931.9113 us. Best GFLOPs: 970.8154
2024-04-30 09:49:56 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1088: GFLOPs: 2.2107. Time: 1673788.0703 us. Best GFLOPs: 970.8154
2024-04-30 09:53:07 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-30 09:53:09 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-30 09:53:13 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 09:53:13 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-30 09:53:26 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 09:53:40 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 09:53:54 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 09:54:07 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 09:54:16 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.8504  0.8485  0.8370  0.8276  0.8171  0.8037  0.7951  0.7923  0.7840  0.7764  0.7676  0.7559  0.7559  0.7518  0.7488  0.7307
[17 : 32]:	0.7274  0.7274  0.7243  0.7194  0.7184  0.7161  0.7139  0.7139  0.7139  0.7134  0.7027  0.7023  0.7003  0.6798  0.6786  0.6764
[33 : 48]:	0.6713  0.6676  0.6660  0.6644  0.6617  0.6579  0.6551  0.6533  0.6526  0.6521  0.6521  0.6489  0.6419  0.6406  0.6397  0.6385
[49 : 64]:	0.6373  0.6360  0.6334  0.6327  0.6302  0.6297  0.6262  0.6250  0.6250  0.6250  0.6236  0.6205  0.6205  0.6205  0.6205  0.6205
2024-04-30 09:54:16 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-30 09:54:16 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-30 09:57:13 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1089: GFLOPs: 479.8591. Time: 7710.9691 us. Best GFLOPs: 970.8154
2024-04-30 09:57:13 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1090: GFLOPs: 798.4108. Time: 4634.4300 us. Best GFLOPs: 970.8154
2024-04-30 09:57:13 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1091: GFLOPs: 780.0324. Time: 4743.6219 us. Best GFLOPs: 970.8154
2024-04-30 09:57:13 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1092: GFLOPs: 829.4648. Time: 4460.9235 us. Best GFLOPs: 970.8154
2024-04-30 09:57:13 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1093: GFLOPs: 855.7339. Time: 4323.9834 us. Best GFLOPs: 970.8154
2024-04-30 09:57:13 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1094: GFLOPs: 840.1448. Time: 4404.2156 us. Best GFLOPs: 970.8154
2024-04-30 09:57:13 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1095: GFLOPs: 78.2171. Time: 47306.5097 us. Best GFLOPs: 970.8154
2024-04-30 09:57:13 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1096: GFLOPs: 728.9928. Time: 5075.7416 us. Best GFLOPs: 970.8154
2024-04-30 09:57:13 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1097: GFLOPs: 725.7816. Time: 5098.1989 us. Best GFLOPs: 970.8154
2024-04-30 09:57:13 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1098: GFLOPs: 293.3480. Time: 12613.6151 us. Best GFLOPs: 970.8154
2024-04-30 09:57:13 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1099: GFLOPs: 762.1513. Time: 4854.9138 us. Best GFLOPs: 970.8154
2024-04-30 09:57:13 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1100: GFLOPs: 20.2569. Time: 182662.4623 us. Best GFLOPs: 970.8154
2024-04-30 09:57:13 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1101: GFLOPs: 20.1478. Time: 183651.9490 us. Best GFLOPs: 970.8154
2024-04-30 09:57:13 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1102: GFLOPs: 485.5713. Time: 7620.2588 us. Best GFLOPs: 970.8154
2024-04-30 09:57:13 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1103: GFLOPs: 934.9603. Time: 3957.5787 us. Best GFLOPs: 970.8154
2024-04-30 09:57:13 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1104: GFLOPs: 382.1072. Time: 9683.6144 us. Best GFLOPs: 970.8154
2024-04-30 09:57:13 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1105: GFLOPs: 466.0428. Time: 7939.5687 us. Best GFLOPs: 970.8154
2024-04-30 09:57:13 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1106: GFLOPs: 597.1844. Time: 6196.0410 us. Best GFLOPs: 970.8154
2024-04-30 09:57:13 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1107: GFLOPs: 696.9183. Time: 5309.3443 us. Best GFLOPs: 970.8154
2024-04-30 09:57:13 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1108: GFLOPs: 716.8467. Time: 5161.7436 us. Best GFLOPs: 970.8154
2024-04-30 09:57:13 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1109: GFLOPs: 691.0614. Time: 5354.3418 us. Best GFLOPs: 970.8154
2024-04-30 09:57:13 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1110: GFLOPs: 666.4387. Time: 5552.1674 us. Best GFLOPs: 970.8154
2024-04-30 09:57:13 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1111: GFLOPs: 13.2060. Time: 280188.9017 us. Best GFLOPs: 970.8154
2024-04-30 09:57:13 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1112: GFLOPs: 7.2936. Time: 507319.5147 us. Best GFLOPs: 970.8154
2024-04-30 09:57:13 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1113: GFLOPs: 13.0452. Time: 283642.2747 us. Best GFLOPs: 970.8154
2024-04-30 09:57:13 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1114: GFLOPs: 6.3742. Time: 580491.0407 us. Best GFLOPs: 970.8154
2024-04-30 09:57:13 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1115: GFLOPs: 731.0583. Time: 5061.4004 us. Best GFLOPs: 970.8154
2024-04-30 09:57:13 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1116: GFLOPs: 751.1659. Time: 4925.9146 us. Best GFLOPs: 970.8154
2024-04-30 09:57:13 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1117: GFLOPs: 57.9360. Time: 63866.6887 us. Best GFLOPs: 970.8154
2024-04-30 09:57:13 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1118: GFLOPs: 817.3267. Time: 4527.1725 us. Best GFLOPs: 970.8154
2024-04-30 09:57:13 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1119: GFLOPs: 660.1221. Time: 5605.2945 us. Best GFLOPs: 970.8154
2024-04-30 09:57:13 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1120: GFLOPs: 602.2316. Time: 6144.1125 us. Best GFLOPs: 970.8154
2024-04-30 09:57:13 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1121: GFLOPs: 564.5438. Time: 6554.2812 us. Best GFLOPs: 970.8154
2024-04-30 09:57:13 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1122: GFLOPs: 521.7995. Time: 7091.1897 us. Best GFLOPs: 970.8154
2024-04-30 09:57:13 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1123: GFLOPs: 682.7987. Time: 5419.1361 us. Best GFLOPs: 970.8154
2024-04-30 09:57:13 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1124: GFLOPs: 558.6987. Time: 6622.8518 us. Best GFLOPs: 970.8154
2024-04-30 09:57:13 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1125: GFLOPs: 671.9870. Time: 5506.3251 us. Best GFLOPs: 970.8154
2024-04-30 09:57:13 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1126: GFLOPs: 122.6639. Time: 30165.1905 us. Best GFLOPs: 970.8154
2024-04-30 09:57:13 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1127: GFLOPs: 672.2214. Time: 5504.4055 us. Best GFLOPs: 970.8154
2024-04-30 09:57:13 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1128: GFLOPs: 721.9090. Time: 5125.5474 us. Best GFLOPs: 970.8154
2024-04-30 09:57:13 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1129: GFLOPs: 428.7015. Time: 8631.1314 us. Best GFLOPs: 970.8154
2024-04-30 09:57:13 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1130: GFLOPs: 150.4496. Time: 24594.1424 us. Best GFLOPs: 970.8154
2024-04-30 09:57:13 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1131: GFLOPs: 158.7197. Time: 23312.6624 us. Best GFLOPs: 970.8154
2024-04-30 09:57:13 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1132: GFLOPs: 551.8676. Time: 6704.8304 us. Best GFLOPs: 970.8154
2024-04-30 09:57:13 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1133: GFLOPs: 681.4460. Time: 5429.8932 us. Best GFLOPs: 970.8154
2024-04-30 09:57:13 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1134: GFLOPs: 623.0610. Time: 5938.7107 us. Best GFLOPs: 970.8154
2024-04-30 09:57:13 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1135: GFLOPs: 16.4993. Time: 224263.3533 us. Best GFLOPs: 970.8154
2024-04-30 09:57:13 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1136: GFLOPs: 565.8286. Time: 6539.3985 us. Best GFLOPs: 970.8154
2024-04-30 09:57:13 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1137: GFLOPs: 11.9848. Time: 308738.3677 us. Best GFLOPs: 970.8154
2024-04-30 09:57:13 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1138: GFLOPs: 157.4709. Time: 23497.5434 us. Best GFLOPs: 970.8154
2024-04-30 09:57:13 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1139: GFLOPs: 608.2058. Time: 6083.7615 us. Best GFLOPs: 970.8154
2024-04-30 09:57:13 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1140: GFLOPs: 545.7900. Time: 6779.4917 us. Best GFLOPs: 970.8154
2024-04-30 09:57:13 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1141: GFLOPs: 609.0800. Time: 6075.0295 us. Best GFLOPs: 970.8154
2024-04-30 09:57:13 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1142: GFLOPs: 562.4790. Time: 6578.3410 us. Best GFLOPs: 970.8154
2024-04-30 09:57:13 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1143: GFLOPs: 662.7478. Time: 5583.0874 us. Best GFLOPs: 970.8154
2024-04-30 09:57:13 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1144: GFLOPs: 672.2205. Time: 5504.4128 us. Best GFLOPs: 970.8154
2024-04-30 09:57:13 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1145: GFLOPs: 409.0689. Time: 9045.3686 us. Best GFLOPs: 970.8154
2024-04-30 09:57:13 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1146: GFLOPs: 749.1694. Time: 4939.0419 us. Best GFLOPs: 970.8154
2024-04-30 09:57:13 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1147: GFLOPs: 764.0060. Time: 4843.1283 us. Best GFLOPs: 970.8154
2024-04-30 09:57:13 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1148: GFLOPs: 6.4469. Time: 573948.2510 us. Best GFLOPs: 970.8154
2024-04-30 09:57:13 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1149: GFLOPs: 164.9814. Time: 22427.8510 us. Best GFLOPs: 970.8154
2024-04-30 09:57:13 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1150: GFLOPs: 36.0245. Time: 102712.8623 us. Best GFLOPs: 970.8154
2024-04-30 09:57:13 [INFO] [task_scheduler.cc:121] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1151: Error in running:
LocalRunner: Timeout, killed after 30 seconds

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(512)), "float32"), p1: T.Buffer((T.int64(32), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_fused_fused in T.parallel(T.int64(2)):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(16), T.int64(30), T.int64(512)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_fused_fused * T.int64(14) + ax2)
                    v_i3, v_i4 = T.axis.remap("SS", [ax3, ax4])
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for ow_0, oc_block_0, n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(32), T.int64(1), T.int64(4), T.int64(2)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(14), T.int64(7)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(2)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(32), oc_chunk_1 + oc_chunk_2_init + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_fused_fused * T.int64(14) + oh_1 * T.int64(14) + oh_2_init * T.int64(14) + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(28), ow_0 * T.int64(28) + ow_1 * T.int64(7) + ow_2_init * T.int64(7) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(16) + oc_block_1 * T.int64(8) + oc_block_2_init * T.int64(2) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(32), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(16), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(14), T.int64(7)):
                    for oc_block_3_fused in T.vectorized(T.int64(2)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(32), oc_chunk_1 + oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_fused_fused * T.int64(14) + oh_1 * T.int64(14) + oh_2 * T.int64(14) + oh_3)
                            v_ow = T.axis.spatial(T.int64(28), ow_0 * T.int64(28) + ow_1 * T.int64(7) + ow_2 * T.int64(7) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(16) + oc_block_1 * T.int64(8) + oc_block_2 * T.int64(2) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(16) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
        for ax0_ax1_ax2_ax3_ax4_fused_0 in T.parallel(T.int64(6272)):
            for ax0_ax1_ax2_ax3_ax4_fused_1 in T.vectorized(T.int64(64)):
                with T.block("T_relu"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) // T.int64(12544))
                    v_ax2 = T.axis.spatial(T.int64(28), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(12544) // T.int64(448))
                    v_ax3 = T.axis.spatial(T.int64(28), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(448) // T.int64(16))
                    v_ax4 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(16))
                    T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                    T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 32, 1, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 1, 1, 14])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 4, 1, 7])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 2, 4, 2])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[32, 16])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
l65 = sch.sample_compute_location(block=b0, decision=2)
sch.compute_at(block=b0, loop=l65, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b66 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.unroll_explicit")
b67, b68, b69 = sch.get_child_blocks(b66)
l70, l71, l72, l73, l74, l75, l76, l77 = sch.get_loops(block=b67)
l78 = sch.fuse(l70, l71, l72, preserve_unit_iters=True)
sch.parallel(loop=l78)
l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102 = sch.get_loops(block=b68)
l103 = sch.fuse(l79, preserve_unit_iters=True)
sch.parallel(loop=l103)
l104 = sch.fuse(l102, preserve_unit_iters=True)
sch.vectorize(loop=l104)
l105, l106, l107, l108, l109 = sch.get_loops(block=b69)
l110 = sch.fuse(l105, l106, l107, l108, l109, preserve_unit_iters=True)
l111, l112 = sch.split(loop=l110, factors=[None, 64], preserve_unit_iters=True)
sch.parallel(loop=l111)
sch.vectorize(loop=l112)
b113 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137 = sch.get_loops(block=b113)
b138 = sch.decompose_reduction(block=b113, loop=l122)
2024-04-30 09:57:13 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1152: GFLOPs: 353.4230. Time: 10469.5476 us. Best GFLOPs: 970.8154
2024-04-30 10:00:03 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-30 10:00:04 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-30 10:00:09 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 10:00:09 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-30 10:00:22 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 10:00:35 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 10:00:50 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 10:01:04 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 10:01:12 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9137  0.8365  0.7892  0.7754  0.7738  0.7711  0.7700  0.7657  0.7577  0.7433  0.7398  0.7314  0.7291  0.7242  0.7218  0.7142
[17 : 32]:	0.7131  0.7038  0.7037  0.6851  0.6835  0.6835  0.6831  0.6759  0.6652  0.6614  0.6588  0.6463  0.6443  0.6432  0.6409  0.6397
[33 : 48]:	0.6393  0.6373  0.6336  0.6328  0.6287  0.6263  0.6237  0.6234  0.6171  0.6121  0.6098  0.6062  0.6058  0.6044  0.6036  0.6034
[49 : 64]:	0.5992  0.5945  0.5929  0.5924  0.5905  0.5856  0.5821  0.5791  0.5787  0.5774  0.5759  0.5706  0.5694  0.5690  0.5589  0.5588
2024-04-30 10:01:13 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-30 10:01:13 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-30 10:03:25 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1153: GFLOPs: 503.3405. Time: 7351.2439 us. Best GFLOPs: 970.8154
2024-04-30 10:03:25 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1154: GFLOPs: 696.6016. Time: 5311.7578 us. Best GFLOPs: 970.8154
2024-04-30 10:03:25 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1155: GFLOPs: 697.4394. Time: 5305.3767 us. Best GFLOPs: 970.8154
2024-04-30 10:03:25 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1156: GFLOPs: 745.0673. Time: 4966.2346 us. Best GFLOPs: 970.8154
2024-04-30 10:03:25 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1157: GFLOPs: 698.4296. Time: 5297.8550 us. Best GFLOPs: 970.8154
2024-04-30 10:03:25 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1158: GFLOPs: 714.9775. Time: 5175.2382 us. Best GFLOPs: 970.8154
2024-04-30 10:03:25 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1159: GFLOPs: 791.7560. Time: 4673.3828 us. Best GFLOPs: 970.8154
2024-04-30 10:03:25 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1160: GFLOPs: 610.3850. Time: 6062.0415 us. Best GFLOPs: 970.8154
2024-04-30 10:03:25 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1161: GFLOPs: 574.7861. Time: 6437.4884 us. Best GFLOPs: 970.8154
2024-04-30 10:03:25 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1162: GFLOPs: 601.1228. Time: 6155.4455 us. Best GFLOPs: 970.8154
2024-04-30 10:03:25 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1163: GFLOPs: 685.2825. Time: 5399.4941 us. Best GFLOPs: 970.8154
2024-04-30 10:03:25 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1164: GFLOPs: 133.2865. Time: 27761.1035 us. Best GFLOPs: 970.8154
2024-04-30 10:03:25 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1165: GFLOPs: 514.1671. Time: 7196.4518 us. Best GFLOPs: 970.8154
2024-04-30 10:03:25 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1166: GFLOPs: 393.3427. Time: 9407.0109 us. Best GFLOPs: 970.8154
2024-04-30 10:03:25 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1167: GFLOPs: 720.3728. Time: 5136.4775 us. Best GFLOPs: 970.8154
2024-04-30 10:03:25 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1168: GFLOPs: 587.7407. Time: 6295.5979 us. Best GFLOPs: 970.8154
2024-04-30 10:03:25 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1169: GFLOPs: 750.1620. Time: 4932.5062 us. Best GFLOPs: 970.8154
2024-04-30 10:03:25 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1170: GFLOPs: 377.7718. Time: 9794.7456 us. Best GFLOPs: 970.8154
2024-04-30 10:03:25 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1171: GFLOPs: 387.0001. Time: 9561.1830 us. Best GFLOPs: 970.8154
2024-04-30 10:03:25 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1172: GFLOPs: 124.7222. Time: 29667.3692 us. Best GFLOPs: 970.8154
2024-04-30 10:03:25 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1173: GFLOPs: 658.2762. Time: 5621.0127 us. Best GFLOPs: 970.8154
2024-04-30 10:03:25 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1174: GFLOPs: 652.3264. Time: 5672.2812 us. Best GFLOPs: 970.8154
2024-04-30 10:03:25 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1175: GFLOPs: 633.0104. Time: 5845.3680 us. Best GFLOPs: 970.8154
2024-04-30 10:03:25 [INFO] [task_scheduler.cc:121] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1176: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(512)), "float32"), p1: T.Buffer((T.int64(32), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_fused_fused in T.parallel(T.int64(448), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(9), T.int64(4), T.int64(512)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(56) // T.int64(14) * T.int64(7) + ax2)
                    v_i3 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(14) * T.int64(2) + ax3)
                    v_i4 = T.axis.spatial(T.int64(512), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oc_block_0 in range(T.int64(1)):
                for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                    for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(16), T.int64(1), T.int64(4), T.int64(1), T.int64(2), T.int64(1)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(56) * T.int64(4) + oc_chunk_1 * T.int64(4) + oc_chunk_2_init * T.int64(4) + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(56) // T.int64(14) * T.int64(7) + oh_1 * T.int64(7) + oh_2_init + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(14) * T.int64(2) + ow_1 * T.int64(2) + ow_2_init * T.int64(2) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2_init + oc_block_3_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                    for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(64), T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(16), T.int64(8), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(1), T.int64(2), T.int64(1)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(56) * T.int64(4) + oc_chunk_1 * T.int64(4) + oc_chunk_2 * T.int64(4) + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(56) // T.int64(14) * T.int64(7) + oh_1 * T.int64(7) + oh_2 + oh_3)
                            v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(14) * T.int64(2) + ow_1 * T.int64(2) + ow_2 * T.int64(2) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2 + oc_block_3)
                            v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(8) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
                for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(4), T.int64(7)):
                    for ax3_ax4_fused in T.vectorized(T.int64(32)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(56) * T.int64(4) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(56) // T.int64(14) * T.int64(7) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(14) * T.int64(2) + ax3_ax4_fused // T.int64(16))
                            v_ax4 = T.axis.spatial(T.int64(16), ax3_ax4_fused % T.int64(16))
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[8, 1, 1, 4])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[4, 1, 7, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[14, 1, 1, 2])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 16, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[64, 8])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=3)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79 = sch.get_loops(block=b68)
l80 = sch.fuse(l71, l72, l73, l74, preserve_unit_iters=True)
sch.parallel(loop=l80)
l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l81, preserve_unit_iters=True)
sch.parallel(loop=l104)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109, l110, l111 = sch.get_loops(block=b70)
l112 = sch.fuse(l110, l111, preserve_unit_iters=True)
sch.vectorize(loop=l112)
b113 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136 = sch.get_loops(block=b113)
b137 = sch.decompose_reduction(block=b113, loop=l121)
2024-04-30 10:03:25 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1177: GFLOPs: 655.1380. Time: 5647.9379 us. Best GFLOPs: 970.8154
2024-04-30 10:03:25 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1178: GFLOPs: 579.5148. Time: 6384.9607 us. Best GFLOPs: 970.8154
2024-04-30 10:03:25 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1179: GFLOPs: 760.9879. Time: 4862.3362 us. Best GFLOPs: 970.8154
2024-04-30 10:03:25 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1180: GFLOPs: 466.0682. Time: 7939.1368 us. Best GFLOPs: 970.8154
2024-04-30 10:03:25 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1181: GFLOPs: 542.7385. Time: 6817.6094 us. Best GFLOPs: 970.8154
2024-04-30 10:03:25 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1182: GFLOPs: 645.8966. Time: 5728.7482 us. Best GFLOPs: 970.8154
2024-04-30 10:03:25 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1183: GFLOPs: 600.3387. Time: 6163.4856 us. Best GFLOPs: 970.8154
2024-04-30 10:03:25 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1184: GFLOPs: 672.2929. Time: 5503.8196 us. Best GFLOPs: 970.8154
2024-04-30 10:03:25 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1185: GFLOPs: 759.4638. Time: 4872.0940 us. Best GFLOPs: 970.8154
2024-04-30 10:03:25 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1186: GFLOPs: 614.5406. Time: 6021.0485 us. Best GFLOPs: 970.8154
2024-04-30 10:03:25 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1187: GFLOPs: 709.1397. Time: 5217.8419 us. Best GFLOPs: 970.8154
2024-04-30 10:03:25 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1188: GFLOPs: 621.0366. Time: 5958.0692 us. Best GFLOPs: 970.8154
2024-04-30 10:03:25 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1189: GFLOPs: 590.9017. Time: 6261.9192 us. Best GFLOPs: 970.8154
2024-04-30 10:03:25 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1190: GFLOPs: 658.1921. Time: 5621.7313 us. Best GFLOPs: 970.8154
2024-04-30 10:03:25 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1191: GFLOPs: 479.9029. Time: 7710.2665 us. Best GFLOPs: 970.8154
2024-04-30 10:03:25 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1192: GFLOPs: 545.2371. Time: 6786.3666 us. Best GFLOPs: 970.8154
2024-04-30 10:03:25 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1193: GFLOPs: 724.9095. Time: 5104.3320 us. Best GFLOPs: 970.8154
2024-04-30 10:03:25 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1194: GFLOPs: 728.0893. Time: 5082.0401 us. Best GFLOPs: 970.8154
2024-04-30 10:03:25 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1195: GFLOPs: 648.3942. Time: 5706.6811 us. Best GFLOPs: 970.8154
2024-04-30 10:03:25 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1196: GFLOPs: 620.7413. Time: 5960.9033 us. Best GFLOPs: 970.8154
2024-04-30 10:03:25 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1197: GFLOPs: 444.8508. Time: 8317.7973 us. Best GFLOPs: 970.8154
2024-04-30 10:03:25 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1198: GFLOPs: 578.2276. Time: 6399.1735 us. Best GFLOPs: 970.8154
2024-04-30 10:03:25 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1199: GFLOPs: 505.6581. Time: 7317.5511 us. Best GFLOPs: 970.8154
2024-04-30 10:03:25 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1200: GFLOPs: 104.6460. Time: 35359.0030 us. Best GFLOPs: 970.8154
2024-04-30 10:03:25 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1201: GFLOPs: 481.2216. Time: 7689.1380 us. Best GFLOPs: 970.8154
2024-04-30 10:03:25 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1202: GFLOPs: 426.1363. Time: 8683.0872 us. Best GFLOPs: 970.8154
2024-04-30 10:03:25 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1203: GFLOPs: 10.9754. Time: 337134.5270 us. Best GFLOPs: 970.8154
2024-04-30 10:03:25 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1204: GFLOPs: 778.2711. Time: 4754.3574 us. Best GFLOPs: 970.8154
2024-04-30 10:03:25 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1205: GFLOPs: 466.1507. Time: 7937.7307 us. Best GFLOPs: 970.8154
2024-04-30 10:03:25 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1206: GFLOPs: 591.6619. Time: 6253.8741 us. Best GFLOPs: 970.8154
2024-04-30 10:03:25 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1207: GFLOPs: 609.6402. Time: 6069.4475 us. Best GFLOPs: 970.8154
2024-04-30 10:03:25 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1208: GFLOPs: 504.9556. Time: 7327.7313 us. Best GFLOPs: 970.8154
2024-04-30 10:03:25 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1209: GFLOPs: 581.9785. Time: 6357.9302 us. Best GFLOPs: 970.8154
2024-04-30 10:03:25 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1210: GFLOPs: 11.9050. Time: 310808.6340 us. Best GFLOPs: 970.8154
2024-04-30 10:03:25 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1211: GFLOPs: 433.2731. Time: 8540.0622 us. Best GFLOPs: 970.8154
2024-04-30 10:03:25 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1212: GFLOPs: 487.1209. Time: 7596.0174 us. Best GFLOPs: 970.8154
2024-04-30 10:03:25 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1213: GFLOPs: 542.6280. Time: 6818.9975 us. Best GFLOPs: 970.8154
2024-04-30 10:03:25 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1214: GFLOPs: 8.9676. Time: 412614.8083 us. Best GFLOPs: 970.8154
2024-04-30 10:03:25 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1215: GFLOPs: 17.9047. Time: 206659.5820 us. Best GFLOPs: 970.8154
2024-04-30 10:03:25 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1216: GFLOPs: 7.9131. Time: 467602.2417 us. Best GFLOPs: 970.8154
2024-04-30 10:06:48 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-30 10:06:49 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-30 10:06:54 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 10:06:54 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-30 10:07:07 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 10:07:20 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 10:07:34 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 10:07:48 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 10:07:57 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9159  0.8953  0.8889  0.8682  0.8633  0.8240  0.8239  0.8053  0.7890  0.7837  0.7767  0.7681  0.7638  0.7492  0.7483  0.7470
[17 : 32]:	0.7463  0.7404  0.7404  0.7377  0.7359  0.7346  0.7177  0.7170  0.7152  0.7150  0.7130  0.7110  0.7103  0.7091  0.7029  0.7022
[33 : 48]:	0.6989  0.6895  0.6845  0.6844  0.6823  0.6795  0.6734  0.6700  0.6625  0.6573  0.6557  0.6543  0.6526  0.6502  0.6479  0.6429
[49 : 64]:	0.6407  0.6345  0.6303  0.6300  0.6300  0.6266  0.6253  0.6252  0.6237  0.6200  0.6127  0.6090  0.6007  0.5982  0.5952  0.5951
2024-04-30 10:07:57 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-30 10:07:57 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-30 10:09:43 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1217: GFLOPs: 819.7328. Time: 4513.8840 us. Best GFLOPs: 970.8154
2024-04-30 10:09:43 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1218: GFLOPs: 774.5237. Time: 4777.3606 us. Best GFLOPs: 970.8154
2024-04-30 10:09:43 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1219: GFLOPs: 949.0144. Time: 3898.9704 us. Best GFLOPs: 970.8154
2024-04-30 10:09:43 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1220: GFLOPs: 784.0479. Time: 4719.3279 us. Best GFLOPs: 970.8154
2024-04-30 10:09:43 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1221: GFLOPs: 821.4735. Time: 4504.3195 us. Best GFLOPs: 970.8154
2024-04-30 10:09:43 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1222: GFLOPs: 500.1965. Time: 7397.4507 us. Best GFLOPs: 970.8154
2024-04-30 10:09:43 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1223: GFLOPs: 436.8646. Time: 8469.8525 us. Best GFLOPs: 970.8154
2024-04-30 10:09:43 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1224: GFLOPs: 439.9159. Time: 8411.1061 us. Best GFLOPs: 970.8154
2024-04-30 10:09:43 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1225: GFLOPs: 810.4600. Time: 4565.5293 us. Best GFLOPs: 970.8154
2024-04-30 10:09:43 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1226: GFLOPs: 666.0108. Time: 5555.7344 us. Best GFLOPs: 970.8154
2024-04-30 10:09:43 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1227: GFLOPs: 820.4166. Time: 4510.1222 us. Best GFLOPs: 970.8154
2024-04-30 10:09:43 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1228: GFLOPs: 755.9448. Time: 4894.7740 us. Best GFLOPs: 970.8154
2024-04-30 10:09:43 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1229: GFLOPs: 707.4748. Time: 5230.1213 us. Best GFLOPs: 970.8154
2024-04-30 10:09:43 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1230: GFLOPs: 666.8100. Time: 5549.0753 us. Best GFLOPs: 970.8154
2024-04-30 10:09:43 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1231: GFLOPs: 709.7245. Time: 5213.5426 us. Best GFLOPs: 970.8154
2024-04-30 10:09:43 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1232: GFLOPs: 611.2708. Time: 6053.2565 us. Best GFLOPs: 970.8154
2024-04-30 10:09:43 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1233: GFLOPs: 94.8602. Time: 39006.6507 us. Best GFLOPs: 970.8154
2024-04-30 10:09:43 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1234: GFLOPs: 666.5020. Time: 5551.6401 us. Best GFLOPs: 970.8154
2024-04-30 10:09:43 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1235: GFLOPs: 661.1834. Time: 5596.2972 us. Best GFLOPs: 970.8154
2024-04-30 10:09:43 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1236: GFLOPs: 757.3139. Time: 4885.9248 us. Best GFLOPs: 970.8154
2024-04-30 10:09:43 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1237: GFLOPs: 455.2264. Time: 8128.2175 us. Best GFLOPs: 970.8154
2024-04-30 10:09:43 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1238: GFLOPs: 521.0422. Time: 7101.4961 us. Best GFLOPs: 970.8154
2024-04-30 10:09:43 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1239: GFLOPs: 562.6930. Time: 6575.8398 us. Best GFLOPs: 970.8154
2024-04-30 10:09:43 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1240: GFLOPs: 665.4240. Time: 5560.6338 us. Best GFLOPs: 970.8154
2024-04-30 10:09:43 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1241: GFLOPs: 597.8073. Time: 6189.5851 us. Best GFLOPs: 970.8154
2024-04-30 10:09:43 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1242: GFLOPs: 766.1986. Time: 4829.2686 us. Best GFLOPs: 970.8154
2024-04-30 10:09:43 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1243: GFLOPs: 682.1424. Time: 5424.3494 us. Best GFLOPs: 970.8154
2024-04-30 10:09:43 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1244: GFLOPs: 471.1383. Time: 7853.7002 us. Best GFLOPs: 970.8154
2024-04-30 10:09:43 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1245: GFLOPs: 437.3615. Time: 8460.2303 us. Best GFLOPs: 970.8154
2024-04-30 10:09:43 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1246: GFLOPs: 649.0152. Time: 5701.2205 us. Best GFLOPs: 970.8154
2024-04-30 10:09:43 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1247: GFLOPs: 586.9459. Time: 6304.1224 us. Best GFLOPs: 970.8154
2024-04-30 10:09:43 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1248: GFLOPs: 774.7296. Time: 4776.0910 us. Best GFLOPs: 970.8154
2024-04-30 10:09:43 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1249: GFLOPs: 651.6388. Time: 5678.2669 us. Best GFLOPs: 970.8154
2024-04-30 10:09:43 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1250: GFLOPs: 695.7317. Time: 5318.3990 us. Best GFLOPs: 970.8154
2024-04-30 10:09:43 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1251: GFLOPs: 725.1890. Time: 5102.3651 us. Best GFLOPs: 970.8154
2024-04-30 10:09:43 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1252: GFLOPs: 671.8836. Time: 5507.1725 us. Best GFLOPs: 970.8154
2024-04-30 10:09:43 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1253: GFLOPs: 707.9471. Time: 5226.6318 us. Best GFLOPs: 970.8154
2024-04-30 10:09:43 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1254: GFLOPs: 676.1392. Time: 5472.5108 us. Best GFLOPs: 970.8154
2024-04-30 10:09:43 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1255: GFLOPs: 641.1284. Time: 5771.3541 us. Best GFLOPs: 970.8154
2024-04-30 10:09:43 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1256: GFLOPs: 582.1957. Time: 6355.5591 us. Best GFLOPs: 970.8154
2024-04-30 10:09:43 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1257: GFLOPs: 538.4558. Time: 6871.8338 us. Best GFLOPs: 970.8154
2024-04-30 10:09:43 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1258: GFLOPs: 118.8422. Time: 31135.2155 us. Best GFLOPs: 970.8154
2024-04-30 10:09:43 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1259: GFLOPs: 683.1090. Time: 5416.6746 us. Best GFLOPs: 970.8154
2024-04-30 10:09:43 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1260: GFLOPs: 595.9840. Time: 6208.5208 us. Best GFLOPs: 970.8154
2024-04-30 10:09:43 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1261: GFLOPs: 656.0367. Time: 5640.2007 us. Best GFLOPs: 970.8154
2024-04-30 10:09:43 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1262: GFLOPs: 574.5369. Time: 6440.2812 us. Best GFLOPs: 970.8154
2024-04-30 10:09:43 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1263: GFLOPs: 477.7425. Time: 7745.1322 us. Best GFLOPs: 970.8154
2024-04-30 10:09:43 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1264: GFLOPs: 633.2082. Time: 5843.5421 us. Best GFLOPs: 970.8154
2024-04-30 10:09:43 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1265: GFLOPs: 359.2389. Time: 10300.0498 us. Best GFLOPs: 970.8154
2024-04-30 10:09:43 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1266: GFLOPs: 617.6007. Time: 5991.2152 us. Best GFLOPs: 970.8154
2024-04-30 10:09:43 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1267: GFLOPs: 628.4641. Time: 5887.6534 us. Best GFLOPs: 970.8154
2024-04-30 10:09:43 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1268: GFLOPs: 531.1726. Time: 6966.0576 us. Best GFLOPs: 970.8154
2024-04-30 10:09:43 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1269: GFLOPs: 75.6849. Time: 48889.2457 us. Best GFLOPs: 970.8154
2024-04-30 10:09:43 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1270: GFLOPs: 630.5506. Time: 5868.1711 us. Best GFLOPs: 970.8154
2024-04-30 10:09:43 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1271: GFLOPs: 606.2988. Time: 6102.8966 us. Best GFLOPs: 970.8154
2024-04-30 10:09:43 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1272: GFLOPs: 564.5280. Time: 6554.4651 us. Best GFLOPs: 970.8154
2024-04-30 10:09:43 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1273: GFLOPs: 624.2995. Time: 5926.9294 us. Best GFLOPs: 970.8154
2024-04-30 10:09:43 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1274: GFLOPs: 633.7351. Time: 5838.6842 us. Best GFLOPs: 970.8154
2024-04-30 10:09:43 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1275: GFLOPs: 741.2501. Time: 4991.8090 us. Best GFLOPs: 970.8154
2024-04-30 10:09:43 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1276: GFLOPs: 125.5917. Time: 29461.9715 us. Best GFLOPs: 970.8154
2024-04-30 10:09:43 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1277: GFLOPs: 610.9017. Time: 6056.9140 us. Best GFLOPs: 970.8154
2024-04-30 10:09:43 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1278: GFLOPs: 96.0120. Time: 38538.7157 us. Best GFLOPs: 970.8154
2024-04-30 10:09:43 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1279: GFLOPs: 58.6780. Time: 63059.0717 us. Best GFLOPs: 970.8154
2024-04-30 10:09:43 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1280: GFLOPs: 16.4189. Time: 225361.0697 us. Best GFLOPs: 970.8154
2024-04-30 10:13:18 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-30 10:13:19 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-30 10:13:23 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 10:13:23 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-30 10:13:36 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 10:13:50 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 10:14:05 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 10:14:18 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 10:14:27 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.8537  0.8236  0.8117  0.8097  0.8088  0.7842  0.7798  0.7444  0.7411  0.7394  0.7383  0.7350  0.7261  0.7153  0.7091  0.6977
[17 : 32]:	0.6972  0.6966  0.6940  0.6929  0.6916  0.6895  0.6861  0.6822  0.6721  0.6587  0.6587  0.6562  0.6545  0.6469  0.6450  0.6401
[33 : 48]:	0.6270  0.6220  0.6216  0.6158  0.6158  0.6133  0.6103  0.6073  0.6049  0.5976  0.5961  0.5925  0.5872  0.5842  0.5841  0.5841
[49 : 64]:	0.5839  0.5836  0.5797  0.5796  0.5759  0.5746  0.5746  0.5724  0.5716  0.5693  0.5669  0.5650  0.5627  0.5622  0.5571  0.5479
2024-04-30 10:14:28 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-30 10:14:28 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-30 10:16:30 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1281: GFLOPs: 879.4746. Time: 4207.2609 us. Best GFLOPs: 970.8154
2024-04-30 10:16:30 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1282: GFLOPs: 766.8037. Time: 4825.4578 us. Best GFLOPs: 970.8154
2024-04-30 10:16:30 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1283: GFLOPs: 791.9340. Time: 4672.3324 us. Best GFLOPs: 970.8154
2024-04-30 10:16:30 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1284: GFLOPs: 799.9638. Time: 4625.4329 us. Best GFLOPs: 970.8154
2024-04-30 10:16:30 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1285: GFLOPs: 876.3692. Time: 4222.1690 us. Best GFLOPs: 970.8154
2024-04-30 10:16:30 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1286: GFLOPs: 848.7214. Time: 4359.7100 us. Best GFLOPs: 970.8154
2024-04-30 10:16:30 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1287: GFLOPs: 773.6260. Time: 4782.9042 us. Best GFLOPs: 970.8154
2024-04-30 10:16:30 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1288: GFLOPs: 132.4057. Time: 27945.7670 us. Best GFLOPs: 970.8154
2024-04-30 10:16:30 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1289: GFLOPs: 767.7279. Time: 4819.6488 us. Best GFLOPs: 970.8154
2024-04-30 10:16:30 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1290: GFLOPs: 534.4723. Time: 6923.0515 us. Best GFLOPs: 970.8154
2024-04-30 10:16:30 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1291: GFLOPs: 729.8535. Time: 5069.7559 us. Best GFLOPs: 970.8154
2024-04-30 10:16:30 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1292: GFLOPs: 99.1903. Time: 37303.8337 us. Best GFLOPs: 970.8154
2024-04-30 10:16:30 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1293: GFLOPs: 773.0392. Time: 4786.5349 us. Best GFLOPs: 970.8154
2024-04-30 10:16:30 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1294: GFLOPs: 638.8141. Time: 5792.2621 us. Best GFLOPs: 970.8154
2024-04-30 10:16:30 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1295: GFLOPs: 637.2693. Time: 5806.3034 us. Best GFLOPs: 970.8154
2024-04-30 10:16:30 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1296: GFLOPs: 677.9647. Time: 5457.7752 us. Best GFLOPs: 970.8154
2024-04-30 10:16:30 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1297: GFLOPs: 694.5185. Time: 5327.6898 us. Best GFLOPs: 970.8154
2024-04-30 10:16:30 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1298: GFLOPs: 642.6440. Time: 5757.7426 us. Best GFLOPs: 970.8154
2024-04-30 10:16:30 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1299: GFLOPs: 632.6476. Time: 5848.7203 us. Best GFLOPs: 970.8154
2024-04-30 10:16:30 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1300: GFLOPs: 607.8315. Time: 6087.5073 us. Best GFLOPs: 970.8154
2024-04-30 10:16:30 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1301: GFLOPs: 668.0304. Time: 5538.9382 us. Best GFLOPs: 970.8154
2024-04-30 10:16:30 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1302: GFLOPs: 657.1542. Time: 5630.6099 us. Best GFLOPs: 970.8154
2024-04-30 10:16:30 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1303: GFLOPs: 680.0756. Time: 5440.8344 us. Best GFLOPs: 970.8154
2024-04-30 10:16:30 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1304: GFLOPs: 670.8179. Time: 5515.9220 us. Best GFLOPs: 970.8154
2024-04-30 10:16:30 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1305: GFLOPs: 703.4460. Time: 5260.0755 us. Best GFLOPs: 970.8154
2024-04-30 10:16:30 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1306: GFLOPs: 92.1864. Time: 40137.9960 us. Best GFLOPs: 970.8154
2024-04-30 10:16:30 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1307: GFLOPs: 125.6372. Time: 29451.2908 us. Best GFLOPs: 970.8154
2024-04-30 10:16:30 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1308: GFLOPs: 658.6220. Time: 5618.0613 us. Best GFLOPs: 970.8154
2024-04-30 10:16:30 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1309: GFLOPs: 358.1457. Time: 10331.4917 us. Best GFLOPs: 970.8154
2024-04-30 10:16:30 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1310: GFLOPs: 556.6671. Time: 6647.0228 us. Best GFLOPs: 970.8154
2024-04-30 10:16:30 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1311: GFLOPs: 576.1522. Time: 6422.2251 us. Best GFLOPs: 970.8154
2024-04-30 10:16:30 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1312: GFLOPs: 643.5587. Time: 5749.5592 us. Best GFLOPs: 970.8154
2024-04-30 10:16:30 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1313: GFLOPs: 620.6603. Time: 5961.6816 us. Best GFLOPs: 970.8154
2024-04-30 10:16:30 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1314: GFLOPs: 658.8092. Time: 5616.4652 us. Best GFLOPs: 970.8154
2024-04-30 10:16:30 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1315: GFLOPs: 621.1633. Time: 5956.8538 us. Best GFLOPs: 970.8154
2024-04-30 10:16:30 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1316: GFLOPs: 560.7714. Time: 6598.3732 us. Best GFLOPs: 970.8154
2024-04-30 10:16:30 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1317: GFLOPs: 555.6458. Time: 6659.2404 us. Best GFLOPs: 970.8154
2024-04-30 10:16:30 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1318: GFLOPs: 558.0496. Time: 6630.5556 us. Best GFLOPs: 970.8154
2024-04-30 10:16:30 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1319: GFLOPs: 634.0813. Time: 5835.4962 us. Best GFLOPs: 970.8154
2024-04-30 10:16:30 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1320: GFLOPs: 595.1470. Time: 6217.2522 us. Best GFLOPs: 970.8154
2024-04-30 10:16:30 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1321: GFLOPs: 587.2548. Time: 6300.8068 us. Best GFLOPs: 970.8154
2024-04-30 10:16:30 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1322: GFLOPs: 503.4271. Time: 7349.9803 us. Best GFLOPs: 970.8154
2024-04-30 10:16:30 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1323: GFLOPs: 609.4954. Time: 6070.8888 us. Best GFLOPs: 970.8154
2024-04-30 10:16:30 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1324: GFLOPs: 670.0262. Time: 5522.4395 us. Best GFLOPs: 970.8154
2024-04-30 10:16:30 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1325: GFLOPs: 607.1306. Time: 6094.5356 us. Best GFLOPs: 970.8154
2024-04-30 10:16:30 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1326: GFLOPs: 538.9164. Time: 6865.9604 us. Best GFLOPs: 970.8154
2024-04-30 10:16:30 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1327: GFLOPs: 23.9595. Time: 154434.8317 us. Best GFLOPs: 970.8154
2024-04-30 10:16:30 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1328: GFLOPs: 25.1502. Time: 147123.2247 us. Best GFLOPs: 970.8154
2024-04-30 10:16:30 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1329: GFLOPs: 609.8707. Time: 6067.1534 us. Best GFLOPs: 970.8154
2024-04-30 10:16:30 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1330: GFLOPs: 546.2128. Time: 6774.2448 us. Best GFLOPs: 970.8154
2024-04-30 10:16:30 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1331: GFLOPs: 601.5001. Time: 6151.5849 us. Best GFLOPs: 970.8154
2024-04-30 10:16:30 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1332: GFLOPs: 595.9692. Time: 6208.6748 us. Best GFLOPs: 970.8154
2024-04-30 10:16:30 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1333: GFLOPs: 21.7009. Time: 170508.3470 us. Best GFLOPs: 970.8154
2024-04-30 10:16:30 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1334: GFLOPs: 595.2669. Time: 6216.0001 us. Best GFLOPs: 970.8154
2024-04-30 10:16:30 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1335: GFLOPs: 565.1131. Time: 6547.6791 us. Best GFLOPs: 970.8154
2024-04-30 10:16:30 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1336: GFLOPs: 537.3713. Time: 6885.7027 us. Best GFLOPs: 970.8154
2024-04-30 10:16:30 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1337: GFLOPs: 652.5866. Time: 5670.0200 us. Best GFLOPs: 970.8154
2024-04-30 10:16:30 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1338: GFLOPs: 175.7778. Time: 21050.3230 us. Best GFLOPs: 970.8154
2024-04-30 10:16:30 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1339: GFLOPs: 536.5391. Time: 6896.3823 us. Best GFLOPs: 970.8154
2024-04-30 10:16:30 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1340: GFLOPs: 295.4313. Time: 12524.6694 us. Best GFLOPs: 970.8154
2024-04-30 10:16:30 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1341: GFLOPs: 405.7566. Time: 9119.2073 us. Best GFLOPs: 970.8154
2024-04-30 10:16:31 [INFO] [task_scheduler.cc:121] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1342: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(512)), "float32"), p1: T.Buffer((T.int64(32), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused in T.parallel(T.int64(256), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(9), T.int64(16), T.int64(512)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(8) // T.int64(2) * T.int64(7) + ax2)
                    v_i3 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(128) * T.int64(14) + ax3)
                    v_i4 = T.axis.spatial(T.int64(512), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(1), T.int64(1), T.int64(8), T.int64(1), T.int64(14)):
                for oc_block_3_fused_init in T.vectorized(T.int64(2)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(32) // T.int64(8) * T.int64(8) + oc_chunk_2_init * T.int64(8) + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(8) // T.int64(2) * T.int64(7) + oh_2_init + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(128) * T.int64(14) + ow_2_init * T.int64(14) + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(128) // T.int64(32) * T.int64(4) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(2) * T.int64(2) + oc_block_2_init * T.int64(2) + oc_block_3_fused_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
            for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(128), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(1), T.int64(4), T.int64(3), T.int64(1), T.int64(1), T.int64(8), T.int64(1), T.int64(14)):
                for oc_block_3_fused in T.vectorized(T.int64(2)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(32) // T.int64(8) * T.int64(8) + oc_chunk_2 * T.int64(8) + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(8) // T.int64(2) * T.int64(7) + oh_2 + oh_3)
                        v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(128) * T.int64(14) + ow_2 * T.int64(14) + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(128) // T.int64(32) * T.int64(4) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(2) * T.int64(2) + oc_block_2 * T.int64(2) + oc_block_3_fused)
                        v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(4) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
        for ax0_ax1_ax2_ax3_ax4_fused_0 in T.parallel(T.int64(6272)):
            for ax0_ax1_ax2_ax3_ax4_fused_1 in T.vectorized(T.int64(64)):
                with T.block("T_relu"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) // T.int64(12544))
                    v_ax2 = T.axis.spatial(T.int64(28), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(12544) // T.int64(448))
                    v_ax3 = T.axis.spatial(T.int64(28), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(448) // T.int64(16))
                    v_ax4 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(16))
                    T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                    T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 4, 1, 8])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 4, 7, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[2, 1, 1, 14])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[4, 2, 1, 2])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[128, 4])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
l65 = sch.sample_compute_location(block=b0, decision=9)
sch.compute_at(block=b0, loop=l65, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b66 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.unroll_explicit")
b67, b68, b69 = sch.get_child_blocks(b66)
l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b67)
l85 = sch.fuse(l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, preserve_unit_iters=True)
sch.parallel(loop=l85)
l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102 = sch.get_loops(block=b68)
l103 = sch.fuse(l86, preserve_unit_iters=True)
sch.parallel(loop=l103)
l104 = sch.fuse(l102, preserve_unit_iters=True)
sch.vectorize(loop=l104)
sch.annotate(block_or_loop=l103, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l103, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109 = sch.get_loops(block=b69)
l110 = sch.fuse(l105, l106, l107, l108, l109, preserve_unit_iters=True)
l111, l112 = sch.split(loop=l110, factors=[None, 64], preserve_unit_iters=True)
sch.parallel(loop=l111)
sch.vectorize(loop=l112)
b113 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130 = sch.get_loops(block=b113)
b131 = sch.decompose_reduction(block=b113, loop=l115)
2024-04-30 10:16:31 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1343: GFLOPs: 15.3461. Time: 241115.8510 us. Best GFLOPs: 970.8154
2024-04-30 10:16:31 [INFO] [task_scheduler.cc:121] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1344: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(512)), "float32"), p1: T.Buffer((T.int64(32), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_fused_fused in T.parallel(T.int64(896), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for oc_block_0 in range(T.int64(4)):
                for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(9), T.int64(512)):
                    with T.block("data_pad"):
                        v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                        v_i2 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(56) // T.int64(4) * T.int64(2) + ax2)
                        v_i3 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(4) * T.int64(7) + ax3)
                        v_i4 = T.axis.spatial(T.int64(512), ax4)
                        T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                        T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                        data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(7), T.int64(2)):
                    for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                        for oc_block_3_fused_init in T.vectorized(T.int64(2)):
                            with T.block("conv2d_NCHWc_init"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                                v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(56) * T.int64(2) + oc_chunk_1 + oc_chunk_2_init + oc_chunk_3_init)
                                v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(56) // T.int64(4) * T.int64(2) + oh_1 * T.int64(2) + oh_2_init + oh_3_init)
                                v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(4) * T.int64(7) + ow_1 + ow_2_init + ow_3_init)
                                v_oc_block = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(4) + oc_block_1 * T.int64(2) + oc_block_2_init * T.int64(2) + oc_block_3_fused_init)
                                T.reads()
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                    for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(8), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(64), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                        for oc_block_3_fused in T.vectorized(T.int64(2)):
                            with T.block("conv2d_NCHWc_update"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                                v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(56) * T.int64(2) + oc_chunk_1 + oc_chunk_2 + oc_chunk_3)
                                v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(56) // T.int64(4) * T.int64(2) + oh_1 * T.int64(2) + oh_2 + oh_3)
                                v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(4) * T.int64(7) + ow_1 + ow_2 + ow_3)
                                v_oc_block = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(4) + oc_block_1 * T.int64(2) + oc_block_2 * T.int64(2) + oc_block_3_fused)
                                v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(64) + ic_1)
                                v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                                v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                                T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(2), T.int64(1)):
                        for ax4_fused in T.vectorized(T.int64(2)):
                            with T.block("T_relu"):
                                v_ax0 = T.axis.spatial(T.int64(1), ax0)
                                v_ax1 = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(56) * T.int64(2) + oc_chunk_1 + ax1)
                                v_ax2 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(56) // T.int64(4) * T.int64(2) + ax2)
                                v_ax3 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(4) * T.int64(7) + ow_1 + ax3)
                                v_ax4 = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(4) + oc_block_1 * T.int64(2) + ax4_fused)
                                T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                                T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                                T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[16, 2, 1, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[14, 1, 2, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[4, 7, 1, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[4, 2, 1, 2])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[8, 64])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=4)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80 = sch.get_loops(block=b68)
l81 = sch.fuse(l71, l72, l73, l74, preserve_unit_iters=True)
sch.parallel(loop=l81)
l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b69)
l105 = sch.fuse(l82, preserve_unit_iters=True)
sch.parallel(loop=l105)
l106 = sch.fuse(l104, preserve_unit_iters=True)
sch.vectorize(loop=l106)
sch.annotate(block_or_loop=l105, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l105, ann_key="pragma_unroll_explicit", ann_val=1)
l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117, l118 = sch.get_loops(block=b70)
l119 = sch.fuse(l118, preserve_unit_iters=True)
sch.vectorize(loop=l119)
b120 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141, l142, l143 = sch.get_loops(block=b120)
b144 = sch.decompose_reduction(block=b120, loop=l128)
2024-04-30 10:28:10 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-30 10:28:11 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-30 10:28:15 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 10:28:15 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-30 10:28:28 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 10:28:42 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 10:28:56 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 10:29:10 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 10:29:19 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9685  0.8752  0.8268  0.8194  0.8169  0.7432  0.7390  0.7342  0.7327  0.7267  0.7102  0.7084  0.7072  0.6931  0.6931  0.6812
[17 : 32]:	0.6780  0.6639  0.6592  0.6484  0.6470  0.6466  0.6432  0.6372  0.6292  0.6271  0.6271  0.6239  0.6233  0.6227  0.6227  0.6222
[33 : 48]:	0.6219  0.6204  0.6193  0.6131  0.6121  0.6106  0.6035  0.5998  0.5987  0.5973  0.5947  0.5947  0.5905  0.5838  0.5813  0.5780
[49 : 64]:	0.5731  0.5731  0.5727  0.5698  0.5664  0.5643  0.5617  0.5600  0.5568  0.5548  0.5532  0.5522  0.5517  0.5501  0.5497  0.5477
2024-04-30 10:29:20 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-30 10:29:20 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-30 10:31:53 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1345: GFLOPs: 942.3463. Time: 3926.5596 us. Best GFLOPs: 970.8154
2024-04-30 10:31:53 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1346: GFLOPs: 932.1418. Time: 3969.5453 us. Best GFLOPs: 970.8154
2024-04-30 10:31:53 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1347: GFLOPs: 821.7007. Time: 4503.0740 us. Best GFLOPs: 970.8154
2024-04-30 10:31:53 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1348: GFLOPs: 449.4223. Time: 8233.1899 us. Best GFLOPs: 970.8154
2024-04-30 10:31:53 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1349: GFLOPs: 816.7164. Time: 4530.5554 us. Best GFLOPs: 970.8154
2024-04-30 10:31:53 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1350: GFLOPs: 398.3893. Time: 9287.8463 us. Best GFLOPs: 970.8154
2024-04-30 10:31:53 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1351: GFLOPs: 591.3481. Time: 6257.1926 us. Best GFLOPs: 970.8154
2024-04-30 10:31:53 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1352: GFLOPs: 404.6357. Time: 9144.4689 us. Best GFLOPs: 970.8154
2024-04-30 10:31:53 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1353: GFLOPs: 729.1185. Time: 5074.8664 us. Best GFLOPs: 970.8154
2024-04-30 10:31:53 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1354: GFLOPs: 689.2171. Time: 5368.6698 us. Best GFLOPs: 970.8154
2024-04-30 10:31:53 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1355: GFLOPs: 762.1577. Time: 4854.8731 us. Best GFLOPs: 970.8154
2024-04-30 10:31:53 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1356: GFLOPs: 789.2880. Time: 4687.9957 us. Best GFLOPs: 970.8154
2024-04-30 10:31:53 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1357: GFLOPs: 707.5473. Time: 5229.5850 us. Best GFLOPs: 970.8154
2024-04-30 10:31:53 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1358: GFLOPs: 665.4781. Time: 5560.1813 us. Best GFLOPs: 970.8154
2024-04-30 10:31:53 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1359: GFLOPs: 123.7497. Time: 29900.5105 us. Best GFLOPs: 970.8154
2024-04-30 10:31:53 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1360: GFLOPs: 738.4007. Time: 5011.0718 us. Best GFLOPs: 970.8154
2024-04-30 10:31:53 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1361: GFLOPs: 716.8836. Time: 5161.4779 us. Best GFLOPs: 970.8154
2024-04-30 10:31:53 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1362: GFLOPs: 107.6325. Time: 34377.9120 us. Best GFLOPs: 970.8154
2024-04-30 10:31:53 [INFO] [task_scheduler.cc:121] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1363: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(512)), "float32"), p1: T.Buffer((T.int64(32), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused in T.parallel(T.int64(224), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(2), T.int64(14), T.int64(16), T.int64(1), T.int64(2), T.int64(2), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(14) * T.int64(2) + oc_chunk_1 * T.int64(2) + oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(14) // T.int64(2) * T.int64(4) + oh_1 * T.int64(4) + oh_2_init * T.int64(2) + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(2) * T.int64(14) + ow_1 * T.int64(14) + ow_2_init + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(16), oc_block_1 * T.int64(16) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0 in range(T.int64(64)):
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(6), T.int64(16)):
                        for ax4_fused in T.vectorized(T.int64(8)):
                            with T.block("data_pad"):
                                v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                                v_i2 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(14) // T.int64(2) * T.int64(4) + ax2)
                                v_i3 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(2) * T.int64(14) + ax3)
                                v_i4 = T.axis.spatial(T.int64(512), ic_0 * T.int64(8) + ax4_fused)
                                T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                                T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                                data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                    for kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(2), T.int64(14), T.int64(16), T.int64(8), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(2), T.int64(1), T.int64(1)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(14) * T.int64(2) + oc_chunk_1 * T.int64(2) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(14) // T.int64(2) * T.int64(4) + oh_1 * T.int64(4) + oh_2 * T.int64(2) + oh_3)
                            v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(2) * T.int64(14) + ow_1 * T.int64(14) + ow_2 + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_1 * T.int64(16) + oc_block_2 + oc_block_3)
                            v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(8) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(2), T.int64(4), T.int64(14)):
                for ax4_fused in T.vectorized(T.int64(16)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(14) * T.int64(2) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(14) // T.int64(2) * T.int64(4) + ax2)
                        v_ax3 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(2) * T.int64(14) + ax3)
                        v_ax4 = T.axis.spatial(T.int64(16), ax4_fused)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[16, 1, 1, 2])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[7, 1, 2, 2])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[2, 1, 14, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 16, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[64, 8])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=10)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86 = sch.get_loops(block=b68)
l87 = sch.fuse(l71, l72, l73, l74, l75, preserve_unit_iters=True)
sch.parallel(loop=l87)
l88 = sch.fuse(l86, preserve_unit_iters=True)
sch.vectorize(loop=l88)
l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107, l108, l109, l110 = sch.get_loops(block=b69)
l111 = sch.fuse(l89, preserve_unit_iters=True)
sch.parallel(loop=l111)
sch.annotate(block_or_loop=l111, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l111, ann_key="pragma_unroll_explicit", ann_val=1)
l112, l113, l114, l115, l116, l117 = sch.get_loops(block=b70)
l118 = sch.fuse(l117, preserve_unit_iters=True)
sch.vectorize(loop=l118)
b119 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141 = sch.get_loops(block=b119)
b142 = sch.decompose_reduction(block=b119, loop=l126)
2024-04-30 10:31:53 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1364: GFLOPs: 653.3406. Time: 5663.4764 us. Best GFLOPs: 970.8154
2024-04-30 10:31:53 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1365: GFLOPs: 677.8450. Time: 5458.7393 us. Best GFLOPs: 970.8154
2024-04-30 10:31:53 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1366: GFLOPs: 631.1311. Time: 5862.7737 us. Best GFLOPs: 970.8154
2024-04-30 10:31:53 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1367: GFLOPs: 636.3491. Time: 5814.6998 us. Best GFLOPs: 970.8154
2024-04-30 10:31:53 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1368: GFLOPs: 669.5789. Time: 5526.1283 us. Best GFLOPs: 970.8154
2024-04-30 10:31:53 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1369: GFLOPs: 109.1689. Time: 33894.0703 us. Best GFLOPs: 970.8154
2024-04-30 10:31:53 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1370: GFLOPs: 629.0506. Time: 5882.1641 us. Best GFLOPs: 970.8154
2024-04-30 10:31:53 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1371: GFLOPs: 585.7850. Time: 6316.6163 us. Best GFLOPs: 970.8154
2024-04-30 10:31:53 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1372: GFLOPs: 368.4116. Time: 10043.6003 us. Best GFLOPs: 970.8154
2024-04-30 10:31:53 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1373: GFLOPs: 780.2788. Time: 4742.1240 us. Best GFLOPs: 970.8154
2024-04-30 10:31:53 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1374: GFLOPs: 12.2761. Time: 301412.9100 us. Best GFLOPs: 970.8154
2024-04-30 10:31:53 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1375: GFLOPs: 11.8964. Time: 311033.3100 us. Best GFLOPs: 970.8154
2024-04-30 10:31:53 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1376: GFLOPs: 590.5737. Time: 6265.3979 us. Best GFLOPs: 970.8154
2024-04-30 10:31:53 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1377: GFLOPs: 687.1942. Time: 5384.4738 us. Best GFLOPs: 970.8154
2024-04-30 10:31:53 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1378: GFLOPs: 618.1567. Time: 5985.8272 us. Best GFLOPs: 970.8154
2024-04-30 10:31:53 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1379: GFLOPs: 659.9573. Time: 5606.6943 us. Best GFLOPs: 970.8154
2024-04-30 10:31:53 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1380: GFLOPs: 701.2294. Time: 5276.7024 us. Best GFLOPs: 970.8154
2024-04-30 10:31:53 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1381: GFLOPs: 523.9405. Time: 7062.2116 us. Best GFLOPs: 970.8154
2024-04-30 10:31:53 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1382: GFLOPs: 594.2223. Time: 6226.9273 us. Best GFLOPs: 970.8154
2024-04-30 10:31:53 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1383: GFLOPs: 597.6793. Time: 6190.9102 us. Best GFLOPs: 970.8154
2024-04-30 10:31:53 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1384: GFLOPs: 543.0320. Time: 6813.9247 us. Best GFLOPs: 970.8154
2024-04-30 10:31:53 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1385: GFLOPs: 80.9748. Time: 45695.4513 us. Best GFLOPs: 970.8154
2024-04-30 10:31:53 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1386: GFLOPs: 539.4228. Time: 6859.5148 us. Best GFLOPs: 970.8154
2024-04-30 10:31:53 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1387: GFLOPs: 26.1363. Time: 141572.5883 us. Best GFLOPs: 970.8154
2024-04-30 10:31:53 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1388: GFLOPs: 6.6127. Time: 559559.7737 us. Best GFLOPs: 970.8154
2024-04-30 10:31:53 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1389: GFLOPs: 326.0880. Time: 11347.1794 us. Best GFLOPs: 970.8154
2024-04-30 10:31:53 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1390: GFLOPs: 726.8223. Time: 5090.8987 us. Best GFLOPs: 970.8154
2024-04-30 10:31:53 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1391: GFLOPs: 499.0421. Time: 7414.5627 us. Best GFLOPs: 970.8154
2024-04-30 10:31:53 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1392: GFLOPs: 708.5940. Time: 5221.8604 us. Best GFLOPs: 970.8154
2024-04-30 10:31:53 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1393: GFLOPs: 503.7950. Time: 7344.6129 us. Best GFLOPs: 970.8154
2024-04-30 10:31:53 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1394: GFLOPs: 824.5769. Time: 4487.3668 us. Best GFLOPs: 970.8154
2024-04-30 10:31:53 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1395: GFLOPs: 610.0947. Time: 6064.9256 us. Best GFLOPs: 970.8154
2024-04-30 10:31:53 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1396: GFLOPs: 814.4292. Time: 4543.2791 us. Best GFLOPs: 970.8154
2024-04-30 10:31:53 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1397: GFLOPs: 538.2650. Time: 6874.2704 us. Best GFLOPs: 970.8154
2024-04-30 10:31:53 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1398: GFLOPs: 89.0009. Time: 41574.6167 us. Best GFLOPs: 970.8154
2024-04-30 10:31:53 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1399: GFLOPs: 591.3587. Time: 6257.0802 us. Best GFLOPs: 970.8154
2024-04-30 10:31:53 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1400: GFLOPs: 268.9085. Time: 13759.9946 us. Best GFLOPs: 970.8154
2024-04-30 10:31:53 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1401: GFLOPs: 506.0199. Time: 7312.3188 us. Best GFLOPs: 970.8154
2024-04-30 10:31:53 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1402: GFLOPs: 569.9100. Time: 6492.5674 us. Best GFLOPs: 970.8154
2024-04-30 10:31:53 [INFO] [task_scheduler.cc:121] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1403: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(512)), "float32"), p1: T.Buffer((T.int64(32), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused in T.parallel(T.int64(224), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(14), T.int64(1), T.int64(16), T.int64(1), T.int64(4), T.int64(1), T.int64(2), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(28) * T.int64(4) + oc_chunk_1 * T.int64(4) + oc_chunk_2_init * T.int64(4) + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(28) // T.int64(14) * T.int64(14) + oh_1 * T.int64(14) + oh_2_init + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(14) * T.int64(2) + ow_1 * T.int64(2) + ow_2_init * T.int64(2) + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(16), oc_block_1 * T.int64(16) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0 in range(T.int64(128)):
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(16), T.int64(4)):
                        for ax4_fused in T.vectorized(T.int64(4)):
                            with T.block("data_pad"):
                                v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                                v_i2 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(28) // T.int64(14) * T.int64(14) + ax2)
                                v_i3 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(14) * T.int64(2) + ax3)
                                v_i4 = T.axis.spatial(T.int64(512), ic_0 * T.int64(4) + ax4_fused)
                                T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                                T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                                data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                    for kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(14), T.int64(1), T.int64(16), T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(1), T.int64(2), T.int64(1)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(28) * T.int64(4) + oc_chunk_1 * T.int64(4) + oc_chunk_2 * T.int64(4) + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(28) // T.int64(14) * T.int64(14) + oh_1 * T.int64(14) + oh_2 + oh_3)
                            v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(14) * T.int64(2) + ow_1 * T.int64(2) + ow_2 * T.int64(2) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_1 * T.int64(16) + oc_block_2 + oc_block_3)
                            v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(4) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
            for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(4), T.int64(14)):
                for ax3_ax4_fused in T.vectorized(T.int64(32)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(28) * T.int64(4) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(28) // T.int64(14) * T.int64(14) + ax2)
                        v_ax3 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(14) * T.int64(2) + ax3_ax4_fused // T.int64(16))
                        v_ax4 = T.axis.spatial(T.int64(16), ax3_ax4_fused % T.int64(16))
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[8, 1, 1, 4])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 1, 14, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[14, 1, 1, 2])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 16, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[128, 4])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=10)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86 = sch.get_loops(block=b68)
l87 = sch.fuse(l71, l72, l73, l74, l75, preserve_unit_iters=True)
sch.parallel(loop=l87)
l88 = sch.fuse(l86, preserve_unit_iters=True)
sch.vectorize(loop=l88)
l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107, l108, l109, l110 = sch.get_loops(block=b69)
l111 = sch.fuse(l89, preserve_unit_iters=True)
sch.parallel(loop=l111)
sch.annotate(block_or_loop=l111, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l111, ann_key="pragma_unroll_explicit", ann_val=1)
l112, l113, l114, l115, l116, l117 = sch.get_loops(block=b70)
l118 = sch.fuse(l116, l117, preserve_unit_iters=True)
sch.vectorize(loop=l118)
b119 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141 = sch.get_loops(block=b119)
b142 = sch.decompose_reduction(block=b119, loop=l126)
2024-04-30 10:31:53 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1404: GFLOPs: 565.7140. Time: 6540.7239 us. Best GFLOPs: 970.8154
2024-04-30 10:31:53 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1405: GFLOPs: 514.6249. Time: 7190.0509 us. Best GFLOPs: 970.8154
2024-04-30 10:31:53 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1406: GFLOPs: 61.7805. Time: 59892.3537 us. Best GFLOPs: 970.8154
2024-04-30 10:31:53 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1407: GFLOPs: 5.5185. Time: 670507.2723 us. Best GFLOPs: 970.8154
2024-04-30 10:31:53 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1408: GFLOPs: 2.3790. Time: 1555353.2437 us. Best GFLOPs: 970.8154
2024-04-30 10:35:30 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-30 10:35:32 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-30 10:35:36 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 10:35:36 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-30 10:35:49 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 10:36:03 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 10:36:17 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 10:36:31 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 10:36:40 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9288  0.8330  0.8008  0.7913  0.7753  0.7562  0.7381  0.7129  0.7054  0.7053  0.7032  0.6978  0.6948  0.6898  0.6885  0.6881
[17 : 32]:	0.6851  0.6849  0.6788  0.6717  0.6537  0.6494  0.6486  0.6485  0.6429  0.6429  0.6429  0.6429  0.6428  0.6386  0.6301  0.6293
[33 : 48]:	0.6281  0.6255  0.6203  0.6185  0.6154  0.6107  0.6101  0.6093  0.6064  0.6061  0.6041  0.6041  0.6019  0.5951  0.5939  0.5931
[49 : 64]:	0.5930  0.5915  0.5905  0.5905  0.5901  0.5878  0.5826  0.5810  0.5764  0.5755  0.5753  0.5737  0.5735  0.5703  0.5690  0.5688
2024-04-30 10:36:41 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-30 10:36:41 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-30 10:38:38 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1409: GFLOPs: 977.5728. Time: 3785.0674 us. Best GFLOPs: 977.5728
2024-04-30 10:38:38 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1410: GFLOPs: 725.5094. Time: 5100.1119 us. Best GFLOPs: 977.5728
2024-04-30 10:38:38 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1411: GFLOPs: 812.8078. Time: 4552.3415 us. Best GFLOPs: 977.5728
2024-04-30 10:38:38 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1412: GFLOPs: 826.7826. Time: 4475.3953 us. Best GFLOPs: 977.5728
2024-04-30 10:38:38 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1413: GFLOPs: 129.5749. Time: 28556.2920 us. Best GFLOPs: 977.5728
2024-04-30 10:38:38 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1414: GFLOPs: 783.1269. Time: 4724.8778 us. Best GFLOPs: 977.5728
2024-04-30 10:38:38 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1415: GFLOPs: 671.0947. Time: 5513.6466 us. Best GFLOPs: 977.5728
2024-04-30 10:38:38 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1416: GFLOPs: 696.9056. Time: 5309.4404 us. Best GFLOPs: 977.5728
2024-04-30 10:38:38 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1417: GFLOPs: 681.9831. Time: 5425.6166 us. Best GFLOPs: 977.5728
2024-04-30 10:38:38 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1418: GFLOPs: 698.1075. Time: 5300.2999 us. Best GFLOPs: 977.5728
2024-04-30 10:38:38 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1419: GFLOPs: 799.8788. Time: 4625.9247 us. Best GFLOPs: 977.5728
2024-04-30 10:38:38 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1420: GFLOPs: 474.6275. Time: 7795.9635 us. Best GFLOPs: 977.5728
2024-04-30 10:38:38 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1421: GFLOPs: 652.4728. Time: 5671.0088 us. Best GFLOPs: 977.5728
2024-04-30 10:38:38 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1422: GFLOPs: 680.7699. Time: 5435.2857 us. Best GFLOPs: 977.5728
2024-04-30 10:38:38 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1423: GFLOPs: 653.6466. Time: 5660.8247 us. Best GFLOPs: 977.5728
2024-04-30 10:38:38 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1424: GFLOPs: 657.1728. Time: 5630.4509 us. Best GFLOPs: 977.5728
2024-04-30 10:38:38 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1425: GFLOPs: 745.8870. Time: 4960.7769 us. Best GFLOPs: 977.5728
2024-04-30 10:38:38 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1426: GFLOPs: 603.8380. Time: 6127.7674 us. Best GFLOPs: 977.5728
2024-04-30 10:38:38 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1427: GFLOPs: 685.9668. Time: 5394.1077 us. Best GFLOPs: 977.5728
2024-04-30 10:38:38 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1428: GFLOPs: 646.5406. Time: 5723.0419 us. Best GFLOPs: 977.5728
2024-04-30 10:38:38 [INFO] [task_scheduler.cc:121] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1429: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(512)), "float32"), p1: T.Buffer((T.int64(32), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_fused_fused in T.parallel(T.int64(112), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for oc_block_0 in range(T.int64(1)):
                for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                    for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(14), T.int64(1), T.int64(16), T.int64(1), T.int64(4), T.int64(1), T.int64(4), T.int64(1)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(14) * T.int64(4) + oc_chunk_1 * T.int64(4) + oc_chunk_2_init * T.int64(4) + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(14) // T.int64(7) * T.int64(14) + oh_1 * T.int64(14) + oh_2_init + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(7) * T.int64(4) + ow_1 * T.int64(4) + ow_2_init * T.int64(4) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2_init + oc_block_3_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                    for ic_0 in range(T.int64(64)):
                        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(16), T.int64(6)):
                            for ax4_fused in T.vectorized(T.int64(8)):
                                with T.block("data_pad"):
                                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                                    v_i2 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(14) // T.int64(7) * T.int64(14) + ax2)
                                    v_i3 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(7) * T.int64(4) + ax3)
                                    v_i4 = T.axis.spatial(T.int64(512), ic_0 * T.int64(8) + ax4_fused)
                                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                        for kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(14), T.int64(1), T.int64(16), T.int64(8), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(1), T.int64(4), T.int64(1)):
                            with T.block("conv2d_NCHWc_update"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                                v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(14) * T.int64(4) + oc_chunk_1 * T.int64(4) + oc_chunk_2 * T.int64(4) + oc_chunk_3)
                                v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(14) // T.int64(7) * T.int64(14) + oh_1 * T.int64(14) + oh_2 + oh_3)
                                v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(7) * T.int64(4) + ow_1 * T.int64(4) + ow_2 * T.int64(4) + ow_3)
                                v_oc_block = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2 + oc_block_3)
                                v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(8) + ic_1)
                                v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                                v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                                T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
                for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(4), T.int64(14)):
                    for ax3_ax4_fused in T.vectorized(T.int64(64)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(14) * T.int64(4) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(14) // T.int64(7) * T.int64(14) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(7) * T.int64(4) + ax3_ax4_fused // T.int64(16))
                            v_ax4 = T.axis.spatial(T.int64(16), ax3_ax4_fused % T.int64(16))
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[8, 1, 1, 4])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 1, 14, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[7, 1, 1, 4])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 16, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[64, 8])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=32)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=10)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86 = sch.get_loops(block=b68)
l87 = sch.fuse(l71, l72, l73, l74, preserve_unit_iters=True)
sch.parallel(loop=l87)
l88 = sch.fuse(l86, preserve_unit_iters=True)
sch.vectorize(loop=l88)
l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107, l108, l109, l110, l111 = sch.get_loops(block=b69)
l112 = sch.fuse(l89, preserve_unit_iters=True)
sch.parallel(loop=l112)
sch.annotate(block_or_loop=l112, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l112, ann_key="pragma_unroll_explicit", ann_val=1)
l113, l114, l115, l116, l117, l118, l119 = sch.get_loops(block=b70)
l120 = sch.fuse(l118, l119, preserve_unit_iters=True)
sch.vectorize(loop=l120)
b121 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141, l142, l143, l144 = sch.get_loops(block=b121)
b145 = sch.decompose_reduction(block=b121, loop=l129)
2024-04-30 10:38:38 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1430: GFLOPs: 686.7653. Time: 5387.8359 us. Best GFLOPs: 977.5728
2024-04-30 10:38:38 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1431: GFLOPs: 625.9520. Time: 5911.2824 us. Best GFLOPs: 977.5728
2024-04-30 10:38:38 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1432: GFLOPs: 364.3549. Time: 10155.4239 us. Best GFLOPs: 977.5728
2024-04-30 10:38:38 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1433: GFLOPs: 619.0425. Time: 5977.2618 us. Best GFLOPs: 977.5728
2024-04-30 10:38:38 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1434: GFLOPs: 273.3790. Time: 13534.9770 us. Best GFLOPs: 977.5728
2024-04-30 10:38:38 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1435: GFLOPs: 628.2030. Time: 5890.1009 us. Best GFLOPs: 977.5728
2024-04-30 10:38:38 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1436: GFLOPs: 631.6853. Time: 5857.6304 us. Best GFLOPs: 977.5728
2024-04-30 10:38:38 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1437: GFLOPs: 714.2556. Time: 5180.4687 us. Best GFLOPs: 977.5728
2024-04-30 10:38:38 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1438: GFLOPs: 580.8778. Time: 6369.9784 us. Best GFLOPs: 977.5728
2024-04-30 10:38:38 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1439: GFLOPs: 574.2671. Time: 6443.3066 us. Best GFLOPs: 977.5728
2024-04-30 10:38:38 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1440: GFLOPs: 468.7853. Time: 7893.1198 us. Best GFLOPs: 977.5728
2024-04-30 10:38:38 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1441: GFLOPs: 365.3890. Time: 10126.6844 us. Best GFLOPs: 977.5728
2024-04-30 10:38:38 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1442: GFLOPs: 680.4675. Time: 5437.7016 us. Best GFLOPs: 977.5728
2024-04-30 10:38:38 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1443: GFLOPs: 158.6054. Time: 23329.4582 us. Best GFLOPs: 977.5728
2024-04-30 10:38:38 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1444: GFLOPs: 350.0663. Time: 10569.9391 us. Best GFLOPs: 977.5728
2024-04-30 10:38:38 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1445: GFLOPs: 584.6915. Time: 6328.4290 us. Best GFLOPs: 977.5728
2024-04-30 10:38:38 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1446: GFLOPs: 523.4765. Time: 7068.4718 us. Best GFLOPs: 977.5728
2024-04-30 10:38:38 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1447: GFLOPs: 616.1309. Time: 6005.5075 us. Best GFLOPs: 977.5728
2024-04-30 10:38:38 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1448: GFLOPs: 867.9819. Time: 4262.9679 us. Best GFLOPs: 977.5728
2024-04-30 10:38:38 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1449: GFLOPs: 582.4140. Time: 6353.1769 us. Best GFLOPs: 977.5728
2024-04-30 10:38:38 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1450: GFLOPs: 552.0618. Time: 6702.4721 us. Best GFLOPs: 977.5728
2024-04-30 10:38:38 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1451: GFLOPs: 696.8225. Time: 5310.0741 us. Best GFLOPs: 977.5728
2024-04-30 10:38:38 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1452: GFLOPs: 684.6093. Time: 5404.8042 us. Best GFLOPs: 977.5728
2024-04-30 10:38:38 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1453: GFLOPs: 411.0687. Time: 9001.3639 us. Best GFLOPs: 977.5728
2024-04-30 10:38:38 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1454: GFLOPs: 870.0978. Time: 4252.6012 us. Best GFLOPs: 977.5728
2024-04-30 10:38:38 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1455: GFLOPs: 565.0864. Time: 6547.9884 us. Best GFLOPs: 977.5728
2024-04-30 10:38:38 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1456: GFLOPs: 673.4792. Time: 5494.1252 us. Best GFLOPs: 977.5728
2024-04-30 10:38:38 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1457: GFLOPs: 466.1116. Time: 7938.3975 us. Best GFLOPs: 977.5728
2024-04-30 10:38:38 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1458: GFLOPs: 498.2593. Time: 7426.2108 us. Best GFLOPs: 977.5728
2024-04-30 10:38:38 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1459: GFLOPs: 573.0598. Time: 6456.8814 us. Best GFLOPs: 977.5728
2024-04-30 10:38:38 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1460: GFLOPs: 593.6407. Time: 6233.0274 us. Best GFLOPs: 977.5728
2024-04-30 10:38:38 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1461: GFLOPs: 445.1176. Time: 8312.8117 us. Best GFLOPs: 977.5728
2024-04-30 10:38:38 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1462: GFLOPs: 584.6961. Time: 6328.3796 us. Best GFLOPs: 977.5728
2024-04-30 10:38:38 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1463: GFLOPs: 687.7517. Time: 5380.1090 us. Best GFLOPs: 977.5728
2024-04-30 10:38:38 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1464: GFLOPs: 129.3825. Time: 28598.7578 us. Best GFLOPs: 977.5728
2024-04-30 10:38:38 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1465: GFLOPs: 543.6956. Time: 6805.6079 us. Best GFLOPs: 977.5728
2024-04-30 10:38:38 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1466: GFLOPs: 568.1484. Time: 6512.6985 us. Best GFLOPs: 977.5728
2024-04-30 10:38:38 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1467: GFLOPs: 581.7268. Time: 6360.6814 us. Best GFLOPs: 977.5728
2024-04-30 10:38:38 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1468: GFLOPs: 132.6850. Time: 27886.9505 us. Best GFLOPs: 977.5728
2024-04-30 10:38:38 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1469: GFLOPs: 359.4104. Time: 10295.1353 us. Best GFLOPs: 977.5728
2024-04-30 10:38:38 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1470: GFLOPs: 68.6273. Time: 53917.0207 us. Best GFLOPs: 977.5728
2024-04-30 10:38:38 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1471: GFLOPs: 8.8955. Time: 415960.1090 us. Best GFLOPs: 977.5728
2024-04-30 10:38:38 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1472: GFLOPs: 49.1064. Time: 75350.2520 us. Best GFLOPs: 977.5728
2024-04-30 10:38:38 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-30 10:38:40 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-30 10:38:44 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 10:38:44 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-30 10:38:57 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 10:39:11 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 10:39:25 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 10:39:39 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 10:39:48 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.8853  0.8252  0.7937  0.7899  0.7410  0.7256  0.7241  0.7181  0.7124  0.7098  0.6999  0.6936  0.6892  0.6817  0.6801  0.6765
[17 : 32]:	0.6699  0.6698  0.6614  0.6596  0.6568  0.6560  0.6547  0.6539  0.6539  0.6503  0.6490  0.6445  0.6212  0.6138  0.6082  0.6066
[33 : 48]:	0.6064  0.6001  0.5973  0.5838  0.5830  0.5829  0.5795  0.5781  0.5728  0.5722  0.5705  0.5693  0.5672  0.5662  0.5662  0.5647
[49 : 64]:	0.5628  0.5574  0.5491  0.5438  0.5435  0.5423  0.5360  0.5354  0.5353  0.5308  0.5304  0.5289  0.5285  0.5272  0.5262  0.5257
2024-04-30 10:39:48 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-30 10:39:49 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-30 10:41:52 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1473: GFLOPs: 835.3538. Time: 4429.4753 us. Best GFLOPs: 977.5728
2024-04-30 10:41:52 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1474: GFLOPs: 809.0130. Time: 4573.6955 us. Best GFLOPs: 977.5728
2024-04-30 10:41:52 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1475: GFLOPs: 820.0300. Time: 4512.2480 us. Best GFLOPs: 977.5728
2024-04-30 10:41:52 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1476: GFLOPs: 790.6654. Time: 4679.8291 us. Best GFLOPs: 977.5728
2024-04-30 10:41:52 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1477: GFLOPs: 768.8490. Time: 4812.6213 us. Best GFLOPs: 977.5728
2024-04-30 10:41:52 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1478: GFLOPs: 747.4772. Time: 4950.2232 us. Best GFLOPs: 977.5728
2024-04-30 10:41:52 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1479: GFLOPs: 688.6573. Time: 5373.0340 us. Best GFLOPs: 977.5728
2024-04-30 10:41:52 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1480: GFLOPs: 759.7378. Time: 4870.3366 us. Best GFLOPs: 977.5728
2024-04-30 10:41:52 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1481: GFLOPs: 680.2213. Time: 5439.6694 us. Best GFLOPs: 977.5728
2024-04-30 10:41:52 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1482: GFLOPs: 703.8305. Time: 5257.2019 us. Best GFLOPs: 977.5728
2024-04-30 10:41:52 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1483: GFLOPs: 590.6520. Time: 6264.5673 us. Best GFLOPs: 977.5728
2024-04-30 10:41:52 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1484: GFLOPs: 688.3636. Time: 5375.3266 us. Best GFLOPs: 977.5728
2024-04-30 10:41:52 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1485: GFLOPs: 680.1127. Time: 5440.5383 us. Best GFLOPs: 977.5728
2024-04-30 10:41:52 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1486: GFLOPs: 631.0586. Time: 5863.4470 us. Best GFLOPs: 977.5728
2024-04-30 10:41:52 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1487: GFLOPs: 772.0425. Time: 4792.7139 us. Best GFLOPs: 977.5728
2024-04-30 10:41:52 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1488: GFLOPs: 657.8712. Time: 5624.4728 us. Best GFLOPs: 977.5728
2024-04-30 10:41:52 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1489: GFLOPs: 755.3420. Time: 4898.6805 us. Best GFLOPs: 977.5728
2024-04-30 10:41:52 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1490: GFLOPs: 817.0771. Time: 4528.5557 us. Best GFLOPs: 977.5728
2024-04-30 10:41:52 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1491: GFLOPs: 685.1076. Time: 5400.8724 us. Best GFLOPs: 977.5728
2024-04-30 10:41:52 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1492: GFLOPs: 633.1663. Time: 5843.9288 us. Best GFLOPs: 977.5728
2024-04-30 10:41:52 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1493: GFLOPs: 524.6051. Time: 7053.2651 us. Best GFLOPs: 977.5728
2024-04-30 10:41:52 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1494: GFLOPs: 588.5883. Time: 6286.5312 us. Best GFLOPs: 977.5728
2024-04-30 10:41:52 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1495: GFLOPs: 658.7224. Time: 5617.2055 us. Best GFLOPs: 977.5728
2024-04-30 10:41:52 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1496: GFLOPs: 685.4510. Time: 5398.1671 us. Best GFLOPs: 977.5728
2024-04-30 10:41:52 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1497: GFLOPs: 692.5617. Time: 5342.7429 us. Best GFLOPs: 977.5728
2024-04-30 10:41:52 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1498: GFLOPs: 658.0316. Time: 5623.1022 us. Best GFLOPs: 977.5728
2024-04-30 10:41:52 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1499: GFLOPs: 734.7112. Time: 5036.2356 us. Best GFLOPs: 977.5728
2024-04-30 10:41:52 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1500: GFLOPs: 785.3878. Time: 4711.2765 us. Best GFLOPs: 977.5728
2024-04-30 10:41:52 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1501: GFLOPs: 591.6913. Time: 6253.5635 us. Best GFLOPs: 977.5728
2024-04-30 10:41:52 [INFO] [task_scheduler.cc:121] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1502: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(512)), "float32"), p1: T.Buffer((T.int64(32), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_fused_fused in T.parallel(T.int64(224), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for oc_block_0 in range(T.int64(1)):
                for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                    for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(14), T.int64(1), T.int64(16), T.int64(1), T.int64(4), T.int64(1), T.int64(2), T.int64(1)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(28) * T.int64(4) + oc_chunk_1 * T.int64(4) + oc_chunk_2_init * T.int64(4) + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(28) // T.int64(14) * T.int64(14) + oh_1 * T.int64(14) + oh_2_init + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(14) * T.int64(2) + ow_1 * T.int64(2) + ow_2_init * T.int64(2) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2_init + oc_block_3_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                    for ic_0 in range(T.int64(128)):
                        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(16), T.int64(4)):
                            for ax4_fused in T.vectorized(T.int64(4)):
                                with T.block("data_pad"):
                                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                                    v_i2 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(28) // T.int64(14) * T.int64(14) + ax2)
                                    v_i3 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(14) * T.int64(2) + ax3)
                                    v_i4 = T.axis.spatial(T.int64(512), ic_0 * T.int64(4) + ax4_fused)
                                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                        for kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(14), T.int64(1), T.int64(16), T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(1), T.int64(2), T.int64(1)):
                            with T.block("conv2d_NCHWc_update"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                                v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(28) * T.int64(4) + oc_chunk_1 * T.int64(4) + oc_chunk_2 * T.int64(4) + oc_chunk_3)
                                v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(28) // T.int64(14) * T.int64(14) + oh_1 * T.int64(14) + oh_2 + oh_3)
                                v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(14) * T.int64(2) + ow_1 * T.int64(2) + ow_2 * T.int64(2) + ow_3)
                                v_oc_block = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2 + oc_block_3)
                                v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(4) + ic_1)
                                v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                                v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                                T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
                for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(4), T.int64(14)):
                    for ax3_ax4_fused in T.vectorized(T.int64(32)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(28) * T.int64(4) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(28) // T.int64(14) * T.int64(14) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(14) * T.int64(2) + ax3_ax4_fused // T.int64(16))
                            v_ax4 = T.axis.spatial(T.int64(16), ax3_ax4_fused % T.int64(16))
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[8, 1, 1, 4])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 1, 14, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[14, 1, 1, 2])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 16, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[128, 4])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=32)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=10)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86 = sch.get_loops(block=b68)
l87 = sch.fuse(l71, l72, l73, l74, preserve_unit_iters=True)
sch.parallel(loop=l87)
l88 = sch.fuse(l86, preserve_unit_iters=True)
sch.vectorize(loop=l88)
l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107, l108, l109, l110, l111 = sch.get_loops(block=b69)
l112 = sch.fuse(l89, preserve_unit_iters=True)
sch.parallel(loop=l112)
sch.annotate(block_or_loop=l112, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l112, ann_key="pragma_unroll_explicit", ann_val=1)
l113, l114, l115, l116, l117, l118, l119 = sch.get_loops(block=b70)
l120 = sch.fuse(l118, l119, preserve_unit_iters=True)
sch.vectorize(loop=l120)
b121 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141, l142, l143, l144 = sch.get_loops(block=b121)
b145 = sch.decompose_reduction(block=b121, loop=l129)
2024-04-30 10:41:52 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1503: GFLOPs: 600.6646. Time: 6160.1412 us. Best GFLOPs: 977.5728
2024-04-30 10:41:52 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1504: GFLOPs: 601.0444. Time: 6156.2488 us. Best GFLOPs: 977.5728
2024-04-30 10:41:52 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1505: GFLOPs: 111.9060. Time: 33065.0595 us. Best GFLOPs: 977.5728
2024-04-30 10:41:52 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1506: GFLOPs: 476.5425. Time: 7764.6350 us. Best GFLOPs: 977.5728
2024-04-30 10:41:52 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1507: GFLOPs: 531.0196. Time: 6968.0645 us. Best GFLOPs: 977.5728
2024-04-30 10:41:52 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1508: GFLOPs: 531.9603. Time: 6955.7423 us. Best GFLOPs: 977.5728
2024-04-30 10:41:52 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1509: GFLOPs: 602.3175. Time: 6143.2363 us. Best GFLOPs: 977.5728
2024-04-30 10:41:52 [INFO] [task_scheduler.cc:121] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1510: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(512)), "float32"), p1: T.Buffer((T.int64(32), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_fused_fused in T.parallel(T.int64(224), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for oc_block_0 in range(T.int64(1)):
                for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                    for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(7), T.int64(2), T.int64(16), T.int64(1), T.int64(4), T.int64(2), T.int64(1), T.int64(1)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(28) * T.int64(4) + oc_chunk_1 * T.int64(4) + oc_chunk_2_init * T.int64(4) + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(28) // T.int64(14) * T.int64(14) + oh_1 * T.int64(14) + oh_2_init * T.int64(2) + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(14) * T.int64(2) + ow_1 * T.int64(2) + ow_2_init + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2_init + oc_block_3_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                    for ic_0 in range(T.int64(128)):
                        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(16), T.int64(4)):
                            for ax4_fused in T.vectorized(T.int64(4)):
                                with T.block("data_pad"):
                                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                                    v_i2 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(28) // T.int64(14) * T.int64(14) + ax2)
                                    v_i3 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(14) * T.int64(2) + ax3)
                                    v_i4 = T.axis.spatial(T.int64(512), ic_0 * T.int64(4) + ax4_fused)
                                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                        for kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(7), T.int64(2), T.int64(16), T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(2), T.int64(1), T.int64(1)):
                            with T.block("conv2d_NCHWc_update"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                                v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(28) * T.int64(4) + oc_chunk_1 * T.int64(4) + oc_chunk_2 * T.int64(4) + oc_chunk_3)
                                v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(28) // T.int64(14) * T.int64(14) + oh_1 * T.int64(14) + oh_2 * T.int64(2) + oh_3)
                                v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(14) * T.int64(2) + ow_1 * T.int64(2) + ow_2 + ow_3)
                                v_oc_block = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2 + oc_block_3)
                                v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(4) + ic_1)
                                v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                                v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                                T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
                for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(4), T.int64(14)):
                    for ax3_ax4_fused in T.vectorized(T.int64(32)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(28) * T.int64(4) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(28) // T.int64(14) * T.int64(14) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(14) * T.int64(2) + ax3_ax4_fused // T.int64(16))
                            v_ax4 = T.axis.spatial(T.int64(16), ax3_ax4_fused % T.int64(16))
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[8, 1, 1, 4])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 1, 7, 2])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[14, 1, 2, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 16, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[128, 4])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=32)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=10)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86 = sch.get_loops(block=b68)
l87 = sch.fuse(l71, l72, l73, l74, preserve_unit_iters=True)
sch.parallel(loop=l87)
l88 = sch.fuse(l86, preserve_unit_iters=True)
sch.vectorize(loop=l88)
l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107, l108, l109, l110, l111 = sch.get_loops(block=b69)
l112 = sch.fuse(l89, preserve_unit_iters=True)
sch.parallel(loop=l112)
sch.annotate(block_or_loop=l112, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l112, ann_key="pragma_unroll_explicit", ann_val=1)
l113, l114, l115, l116, l117, l118, l119 = sch.get_loops(block=b70)
l120 = sch.fuse(l118, l119, preserve_unit_iters=True)
sch.vectorize(loop=l120)
b121 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141, l142, l143, l144 = sch.get_loops(block=b121)
b145 = sch.decompose_reduction(block=b121, loop=l129)
2024-04-30 10:41:52 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1511: GFLOPs: 49.3255. Time: 75015.5940 us. Best GFLOPs: 977.5728
2024-04-30 10:41:52 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1512: GFLOPs: 755.4653. Time: 4897.8804 us. Best GFLOPs: 977.5728
2024-04-30 10:41:52 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1513: GFLOPs: 520.7381. Time: 7105.6429 us. Best GFLOPs: 977.5728
2024-04-30 10:41:52 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1514: GFLOPs: 555.9839. Time: 6655.1904 us. Best GFLOPs: 977.5728
2024-04-30 10:41:52 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1515: GFLOPs: 650.2185. Time: 5690.6701 us. Best GFLOPs: 977.5728
2024-04-30 10:41:52 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1516: GFLOPs: 160.0477. Time: 23119.2258 us. Best GFLOPs: 977.5728
2024-04-30 10:41:52 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1517: GFLOPs: 633.9812. Time: 5836.4173 us. Best GFLOPs: 977.5728
2024-04-30 10:41:52 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1518: GFLOPs: 61.6995. Time: 59970.9303 us. Best GFLOPs: 977.5728
2024-04-30 10:41:52 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1519: GFLOPs: 564.9711. Time: 6549.3239 us. Best GFLOPs: 977.5728
2024-04-30 10:41:52 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1520: GFLOPs: 513.3512. Time: 7207.8896 us. Best GFLOPs: 977.5728
2024-04-30 10:41:52 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1521: GFLOPs: 624.1115. Time: 5928.7149 us. Best GFLOPs: 977.5728
2024-04-30 10:41:52 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1522: GFLOPs: 125.9210. Time: 29384.9158 us. Best GFLOPs: 977.5728
2024-04-30 10:41:52 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1523: GFLOPs: 559.9570. Time: 6607.9693 us. Best GFLOPs: 977.5728
2024-04-30 10:41:52 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1524: GFLOPs: 533.1791. Time: 6939.8420 us. Best GFLOPs: 977.5728
2024-04-30 10:41:52 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1525: GFLOPs: 697.3475. Time: 5306.0765 us. Best GFLOPs: 977.5728
2024-04-30 10:41:52 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1526: GFLOPs: 512.0795. Time: 7225.7899 us. Best GFLOPs: 977.5728
2024-04-30 10:41:52 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1527: GFLOPs: 47.6923. Time: 77584.3487 us. Best GFLOPs: 977.5728
2024-04-30 10:41:52 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1528: GFLOPs: 131.0281. Time: 28239.5860 us. Best GFLOPs: 977.5728
2024-04-30 10:41:52 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1529: GFLOPs: 126.0187. Time: 29362.1427 us. Best GFLOPs: 977.5728
2024-04-30 10:41:52 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1530: GFLOPs: 417.3172. Time: 8866.5858 us. Best GFLOPs: 977.5728
2024-04-30 10:41:52 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1531: GFLOPs: 526.1899. Time: 7032.0217 us. Best GFLOPs: 977.5728
2024-04-30 10:41:52 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1532: GFLOPs: 387.1458. Time: 9557.5853 us. Best GFLOPs: 977.5728
2024-04-30 10:41:52 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1533: GFLOPs: 562.6384. Time: 6576.4781 us. Best GFLOPs: 977.5728
2024-04-30 10:41:52 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1534: GFLOPs: 40.5305. Time: 91293.6123 us. Best GFLOPs: 977.5728
2024-04-30 10:41:52 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1535: GFLOPs: 29.3133. Time: 126228.6667 us. Best GFLOPs: 977.5728
2024-04-30 10:41:52 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1536: GFLOPs: 10.1051. Time: 366170.0030 us. Best GFLOPs: 977.5728
2024-04-30 11:13:43 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-30 11:13:45 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-30 11:13:49 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 11:13:49 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-30 11:14:02 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 11:14:16 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 11:14:30 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 11:14:44 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 11:14:52 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.8732  0.8592  0.8545  0.8201  0.8191  0.7965  0.7879  0.7739  0.7611  0.7554  0.7553  0.7473  0.7473  0.7325  0.7270  0.7247
[17 : 32]:	0.7244  0.7037  0.6886  0.6819  0.6776  0.6758  0.6715  0.6514  0.6471  0.6457  0.6440  0.6421  0.6359  0.6208  0.6203  0.6142
[33 : 48]:	0.6127  0.6077  0.6055  0.6034  0.6003  0.5991  0.5968  0.5965  0.5952  0.5916  0.5895  0.5821  0.5816  0.5802  0.5744  0.5696
[49 : 64]:	0.5659  0.5627  0.5626  0.5621  0.5617  0.5600  0.5566  0.5549  0.5547  0.5538  0.5512  0.5509  0.5451  0.5447  0.5433  0.5433
2024-04-30 11:14:53 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-30 11:14:53 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-30 11:17:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1537: GFLOPs: 895.8465. Time: 4130.3714 us. Best GFLOPs: 977.5728
2024-04-30 11:17:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1538: GFLOPs: 838.0759. Time: 4415.0881 us. Best GFLOPs: 977.5728
2024-04-30 11:17:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1539: GFLOPs: 772.5048. Time: 4789.8461 us. Best GFLOPs: 977.5728
2024-04-30 11:17:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1540: GFLOPs: 802.1204. Time: 4612.9970 us. Best GFLOPs: 977.5728
2024-04-30 11:17:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1541: GFLOPs: 778.8620. Time: 4750.7503 us. Best GFLOPs: 977.5728
2024-04-30 11:17:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1542: GFLOPs: 795.7317. Time: 4650.0336 us. Best GFLOPs: 977.5728
2024-04-30 11:17:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1543: GFLOPs: 782.9719. Time: 4725.8130 us. Best GFLOPs: 977.5728
2024-04-30 11:17:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1544: GFLOPs: 802.8607. Time: 4608.7433 us. Best GFLOPs: 977.5728
2024-04-30 11:17:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1545: GFLOPs: 659.7948. Time: 5608.0753 us. Best GFLOPs: 977.5728
2024-04-30 11:17:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1546: GFLOPs: 754.7521. Time: 4902.5090 us. Best GFLOPs: 977.5728
2024-04-30 11:17:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1547: GFLOPs: 657.7785. Time: 5625.2656 us. Best GFLOPs: 977.5728
2024-04-30 11:17:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1548: GFLOPs: 777.6496. Time: 4758.1568 us. Best GFLOPs: 977.5728
2024-04-30 11:17:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1549: GFLOPs: 313.1476. Time: 11816.0854 us. Best GFLOPs: 977.5728
2024-04-30 11:17:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1550: GFLOPs: 750.2265. Time: 4932.0824 us. Best GFLOPs: 977.5728
2024-04-30 11:17:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1551: GFLOPs: 735.0859. Time: 5033.6690 us. Best GFLOPs: 977.5728
2024-04-30 11:17:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1552: GFLOPs: 682.0616. Time: 5424.9922 us. Best GFLOPs: 977.5728
2024-04-30 11:17:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1553: GFLOPs: 602.3541. Time: 6142.8632 us. Best GFLOPs: 977.5728
2024-04-30 11:17:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1554: GFLOPs: 664.6444. Time: 5567.1562 us. Best GFLOPs: 977.5728
2024-04-30 11:17:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1555: GFLOPs: 666.7711. Time: 5549.3991 us. Best GFLOPs: 977.5728
2024-04-30 11:17:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1556: GFLOPs: 651.0125. Time: 5683.7293 us. Best GFLOPs: 977.5728
2024-04-30 11:17:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1557: GFLOPs: 598.0565. Time: 6187.0052 us. Best GFLOPs: 977.5728
2024-04-30 11:17:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1558: GFLOPs: 697.1528. Time: 5307.5581 us. Best GFLOPs: 977.5728
2024-04-30 11:17:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1559: GFLOPs: 706.2482. Time: 5239.2050 us. Best GFLOPs: 977.5728
2024-04-30 11:17:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1560: GFLOPs: 716.1460. Time: 5166.7944 us. Best GFLOPs: 977.5728
2024-04-30 11:17:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1561: GFLOPs: 607.5154. Time: 6090.6747 us. Best GFLOPs: 977.5728
2024-04-30 11:17:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1562: GFLOPs: 604.6243. Time: 6119.7988 us. Best GFLOPs: 977.5728
2024-04-30 11:17:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1563: GFLOPs: 340.2377. Time: 10875.2770 us. Best GFLOPs: 977.5728
2024-04-30 11:17:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1564: GFLOPs: 634.2010. Time: 5834.3948 us. Best GFLOPs: 977.5728
2024-04-30 11:17:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1565: GFLOPs: 726.2676. Time: 5094.7876 us. Best GFLOPs: 977.5728
2024-04-30 11:17:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1566: GFLOPs: 601.1060. Time: 6155.6176 us. Best GFLOPs: 977.5728
2024-04-30 11:17:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1567: GFLOPs: 356.4123. Time: 10381.7389 us. Best GFLOPs: 977.5728
2024-04-30 11:17:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1568: GFLOPs: 121.0037. Time: 30579.0510 us. Best GFLOPs: 977.5728
2024-04-30 11:17:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1569: GFLOPs: 107.1552. Time: 34531.0237 us. Best GFLOPs: 977.5728
2024-04-30 11:17:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1570: GFLOPs: 565.8556. Time: 6539.0868 us. Best GFLOPs: 977.5728
2024-04-30 11:17:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1571: GFLOPs: 692.5059. Time: 5343.1734 us. Best GFLOPs: 977.5728
2024-04-30 11:17:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1572: GFLOPs: 346.6251. Time: 10674.8735 us. Best GFLOPs: 977.5728
2024-04-30 11:17:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1573: GFLOPs: 671.8687. Time: 5507.2947 us. Best GFLOPs: 977.5728
2024-04-30 11:17:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1574: GFLOPs: 346.8004. Time: 10669.4765 us. Best GFLOPs: 977.5728
2024-04-30 11:17:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1575: GFLOPs: 585.5616. Time: 6319.0255 us. Best GFLOPs: 977.5728
2024-04-30 11:17:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1576: GFLOPs: 402.0257. Time: 9203.8365 us. Best GFLOPs: 977.5728
2024-04-30 11:17:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1577: GFLOPs: 586.6427. Time: 6307.3809 us. Best GFLOPs: 977.5728
2024-04-30 11:17:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1578: GFLOPs: 529.5052. Time: 6987.9941 us. Best GFLOPs: 977.5728
2024-04-30 11:17:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1579: GFLOPs: 447.7127. Time: 8264.6275 us. Best GFLOPs: 977.5728
2024-04-30 11:17:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1580: GFLOPs: 631.7173. Time: 5857.3335 us. Best GFLOPs: 977.5728
2024-04-30 11:17:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1581: GFLOPs: 126.4733. Time: 29256.6060 us. Best GFLOPs: 977.5728
2024-04-30 11:17:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1582: GFLOPs: 121.5766. Time: 30434.9688 us. Best GFLOPs: 977.5728
2024-04-30 11:17:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1583: GFLOPs: 500.5550. Time: 7392.1528 us. Best GFLOPs: 977.5728
2024-04-30 11:17:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1584: GFLOPs: 555.3745. Time: 6662.4932 us. Best GFLOPs: 977.5728
2024-04-30 11:17:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1585: GFLOPs: 586.3425. Time: 6310.6104 us. Best GFLOPs: 977.5728
2024-04-30 11:17:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1586: GFLOPs: 690.8591. Time: 5355.9098 us. Best GFLOPs: 977.5728
2024-04-30 11:17:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1587: GFLOPs: 11.8936. Time: 311106.7883 us. Best GFLOPs: 977.5728
2024-04-30 11:17:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1588: GFLOPs: 114.2144. Time: 32396.7875 us. Best GFLOPs: 977.5728
2024-04-30 11:17:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1589: GFLOPs: 105.2543. Time: 35154.6677 us. Best GFLOPs: 977.5728
2024-04-30 11:17:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1590: GFLOPs: 508.3884. Time: 7278.2522 us. Best GFLOPs: 977.5728
2024-04-30 11:17:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1591: GFLOPs: 261.4565. Time: 14152.1761 us. Best GFLOPs: 977.5728
2024-04-30 11:17:00 [INFO] [task_scheduler.cc:121] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1592: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(512)), "float32"), p1: T.Buffer((T.int64(32), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_fused_fused in T.parallel(T.int64(224), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ow_0, oc_block_0 in T.grid(T.int64(1), T.int64(1)):
                for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                    for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(28), T.int64(16), T.int64(1), T.int64(2), T.int64(2), T.int64(1), T.int64(1)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_fused_fused // T.int64(14) * T.int64(2) + oc_chunk_1 * T.int64(2) + oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_fused_fused % T.int64(14) * T.int64(2) + oh_1 * T.int64(2) + oh_2_init * T.int64(2) + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(28), ow_0 * T.int64(28) + ow_1 * T.int64(28) + ow_2_init + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2_init + oc_block_3_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                    for ic_0 in range(T.int64(64)):
                        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(30)):
                            for ax4_fused in T.vectorized(T.int64(8)):
                                with T.block("data_pad"):
                                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                                    v_i2 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_fused_fused % T.int64(14) * T.int64(2) + ax2)
                                    v_i3 = T.axis.spatial(T.int64(30), ax3)
                                    v_i4 = T.axis.spatial(T.int64(512), ic_0 * T.int64(8) + ax4_fused)
                                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                        for kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(28), T.int64(16), T.int64(8), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(2), T.int64(1), T.int64(1)):
                            with T.block("conv2d_NCHWc_update"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                                v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_fused_fused // T.int64(14) * T.int64(2) + oc_chunk_1 * T.int64(2) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                                v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_fused_fused % T.int64(14) * T.int64(2) + oh_1 * T.int64(2) + oh_2 * T.int64(2) + oh_3)
                                v_ow = T.axis.spatial(T.int64(28), ow_0 * T.int64(28) + ow_1 * T.int64(28) + ow_2 + ow_3)
                                v_oc_block = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2 + oc_block_3)
                                v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(8) + ic_1)
                                v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                                v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                                T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(2), T.int64(2), T.int64(28)):
                    for ax4_fused in T.vectorized(T.int64(16)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_fused_fused // T.int64(14) * T.int64(2) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_fused_fused % T.int64(14) * T.int64(2) + ax2)
                            v_ax3, v_ax4 = T.axis.remap("SS", [ax3, ax4_fused])
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[16, 1, 1, 2])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[14, 1, 1, 2])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 28, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 16, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[64, 8])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=16)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=10)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86 = sch.get_loops(block=b68)
l87 = sch.fuse(l71, l72, l73, preserve_unit_iters=True)
sch.parallel(loop=l87)
l88 = sch.fuse(l86, preserve_unit_iters=True)
sch.vectorize(loop=l88)
l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107, l108, l109, l110, l111, l112 = sch.get_loops(block=b69)
l113 = sch.fuse(l89, preserve_unit_iters=True)
sch.parallel(loop=l113)
sch.annotate(block_or_loop=l113, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l113, ann_key="pragma_unroll_explicit", ann_val=1)
l114, l115, l116, l117, l118, l119, l120, l121 = sch.get_loops(block=b70)
l122 = sch.fuse(l121, preserve_unit_iters=True)
sch.vectorize(loop=l122)
b123 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141, l142, l143, l144, l145, l146, l147 = sch.get_loops(block=b123)
b148 = sch.decompose_reduction(block=b123, loop=l132)
2024-04-30 11:17:00 [INFO] [task_scheduler.cc:121] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1593: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(512)), "float32"), p1: T.Buffer((T.int64(32), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_fused_fused in T.parallel(T.int64(224), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for oc_block_0 in range(T.int64(1)):
                for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                    for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(7), T.int64(4), T.int64(16), T.int64(1), T.int64(2), T.int64(2), T.int64(1), T.int64(1)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(14) * T.int64(2) + oc_chunk_1 * T.int64(2) + oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(14) // T.int64(7) * T.int64(14) + oh_1 * T.int64(14) + oh_2_init * T.int64(2) + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(7) * T.int64(4) + ow_1 * T.int64(4) + ow_2_init + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2_init + oc_block_3_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                    for ic_0 in range(T.int64(64)):
                        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(16), T.int64(6)):
                            for ax4_fused in T.vectorized(T.int64(8)):
                                with T.block("data_pad"):
                                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                                    v_i2 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(14) // T.int64(7) * T.int64(14) + ax2)
                                    v_i3 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(7) * T.int64(4) + ax3)
                                    v_i4 = T.axis.spatial(T.int64(512), ic_0 * T.int64(8) + ax4_fused)
                                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                        for kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(7), T.int64(4), T.int64(16), T.int64(8), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(2), T.int64(1), T.int64(1)):
                            with T.block("conv2d_NCHWc_update"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                                v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(14) * T.int64(2) + oc_chunk_1 * T.int64(2) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                                v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(14) // T.int64(7) * T.int64(14) + oh_1 * T.int64(14) + oh_2 * T.int64(2) + oh_3)
                                v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(7) * T.int64(4) + ow_1 * T.int64(4) + ow_2 + ow_3)
                                v_oc_block = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2 + oc_block_3)
                                v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(8) + ic_1)
                                v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                                v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                                T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
                for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(2), T.int64(14)):
                    for ax3_ax4_fused in T.vectorized(T.int64(64)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(14) * T.int64(2) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(14) // T.int64(7) * T.int64(14) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(7) * T.int64(4) + ax3_ax4_fused // T.int64(16))
                            v_ax4 = T.axis.spatial(T.int64(16), ax3_ax4_fused % T.int64(16))
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[16, 1, 1, 2])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 1, 7, 2])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[7, 1, 4, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 16, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[64, 8])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=32)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=10)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86 = sch.get_loops(block=b68)
l87 = sch.fuse(l71, l72, l73, l74, preserve_unit_iters=True)
sch.parallel(loop=l87)
l88 = sch.fuse(l86, preserve_unit_iters=True)
sch.vectorize(loop=l88)
l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107, l108, l109, l110, l111 = sch.get_loops(block=b69)
l112 = sch.fuse(l89, preserve_unit_iters=True)
sch.parallel(loop=l112)
sch.annotate(block_or_loop=l112, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l112, ann_key="pragma_unroll_explicit", ann_val=1)
l113, l114, l115, l116, l117, l118, l119 = sch.get_loops(block=b70)
l120 = sch.fuse(l118, l119, preserve_unit_iters=True)
sch.vectorize(loop=l120)
b121 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141, l142, l143, l144 = sch.get_loops(block=b121)
b145 = sch.decompose_reduction(block=b121, loop=l129)
2024-04-30 11:17:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1594: GFLOPs: 598.3076. Time: 6184.4087 us. Best GFLOPs: 977.5728
2024-04-30 11:17:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1595: GFLOPs: 437.4153. Time: 8459.1896 us. Best GFLOPs: 977.5728
2024-04-30 11:17:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1596: GFLOPs: 135.7867. Time: 27249.9312 us. Best GFLOPs: 977.5728
2024-04-30 11:17:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1597: GFLOPs: 90.4944. Time: 40888.4903 us. Best GFLOPs: 977.5728
2024-04-30 11:17:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1598: GFLOPs: 234.6311. Time: 15770.1970 us. Best GFLOPs: 977.5728
2024-04-30 11:17:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1599: GFLOPs: 36.4950. Time: 101388.5993 us. Best GFLOPs: 977.5728
2024-04-30 11:17:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1600: GFLOPs: 41.8940. Time: 88322.4437 us. Best GFLOPs: 977.5728
2024-04-30 11:23:23 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-30 11:23:25 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-30 11:23:29 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 11:23:29 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-30 11:23:42 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 11:23:56 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 11:24:10 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 11:24:23 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 11:24:32 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.8056  0.7999  0.7889  0.7691  0.7516  0.7283  0.7276  0.7162  0.7162  0.7119  0.7010  0.6996  0.6967  0.6967  0.6962  0.6846
[17 : 32]:	0.6818  0.6787  0.6762  0.6747  0.6649  0.6605  0.6580  0.6514  0.6506  0.6497  0.6490  0.6487  0.6458  0.6420  0.6400  0.6391
[33 : 48]:	0.6307  0.6307  0.6278  0.6274  0.6210  0.6181  0.6181  0.6162  0.6161  0.6057  0.6057  0.6040  0.5949  0.5942  0.5941  0.5940
[49 : 64]:	0.5821  0.5819  0.5804  0.5770  0.5744  0.5703  0.5675  0.5622  0.5603  0.5593  0.5576  0.5555  0.5489  0.5487  0.5456  0.5456
2024-04-30 11:24:32 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-30 11:24:32 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-30 11:26:51 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1601: GFLOPs: 965.9522. Time: 3830.6025 us. Best GFLOPs: 977.5728
2024-04-30 11:26:51 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1602: GFLOPs: 829.2686. Time: 4461.9789 us. Best GFLOPs: 977.5728
2024-04-30 11:26:51 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1603: GFLOPs: 796.9519. Time: 4642.9137 us. Best GFLOPs: 977.5728
2024-04-30 11:26:51 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1604: GFLOPs: 825.4641. Time: 4482.5438 us. Best GFLOPs: 977.5728
2024-04-30 11:26:51 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1605: GFLOPs: 728.9426. Time: 5076.0913 us. Best GFLOPs: 977.5728
2024-04-30 11:26:51 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1606: GFLOPs: 807.3979. Time: 4582.8442 us. Best GFLOPs: 977.5728
2024-04-30 11:26:51 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1607: GFLOPs: 778.3735. Time: 4753.7322 us. Best GFLOPs: 977.5728
2024-04-30 11:26:51 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1608: GFLOPs: 648.9692. Time: 5701.6247 us. Best GFLOPs: 977.5728
2024-04-30 11:26:51 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1609: GFLOPs: 673.4888. Time: 5494.0471 us. Best GFLOPs: 977.5728
2024-04-30 11:26:51 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1610: GFLOPs: 716.9577. Time: 5160.9443 us. Best GFLOPs: 977.5728
2024-04-30 11:26:51 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1611: GFLOPs: 697.5375. Time: 5304.6312 us. Best GFLOPs: 977.5728
2024-04-30 11:26:51 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1612: GFLOPs: 709.7136. Time: 5213.6226 us. Best GFLOPs: 977.5728
2024-04-30 11:26:51 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1613: GFLOPs: 676.1016. Time: 5472.8151 us. Best GFLOPs: 977.5728
2024-04-30 11:26:51 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1614: GFLOPs: 660.2777. Time: 5603.9741 us. Best GFLOPs: 977.5728
2024-04-30 11:26:51 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1615: GFLOPs: 746.7695. Time: 4954.9142 us. Best GFLOPs: 977.5728
2024-04-30 11:26:51 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1616: GFLOPs: 576.4702. Time: 6418.6816 us. Best GFLOPs: 977.5728
2024-04-30 11:26:51 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1617: GFLOPs: 668.9777. Time: 5531.0949 us. Best GFLOPs: 977.5728
2024-04-30 11:26:51 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1618: GFLOPs: 846.0910. Time: 4373.2634 us. Best GFLOPs: 977.5728
2024-04-30 11:26:51 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1619: GFLOPs: 543.5128. Time: 6807.8971 us. Best GFLOPs: 977.5728
2024-04-30 11:26:51 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1620: GFLOPs: 85.0684. Time: 43496.4953 us. Best GFLOPs: 977.5728
2024-04-30 11:26:51 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1621: GFLOPs: 582.2844. Time: 6354.5905 us. Best GFLOPs: 977.5728
2024-04-30 11:26:51 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1622: GFLOPs: 639.2047. Time: 5788.7234 us. Best GFLOPs: 977.5728
2024-04-30 11:26:51 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1623: GFLOPs: 80.8470. Time: 45767.6943 us. Best GFLOPs: 977.5728
2024-04-30 11:26:51 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1624: GFLOPs: 70.1101. Time: 52776.6657 us. Best GFLOPs: 977.5728
2024-04-30 11:26:51 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1625: GFLOPs: 728.6106. Time: 5078.4037 us. Best GFLOPs: 977.5728
2024-04-30 11:26:51 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1626: GFLOPs: 600.4691. Time: 6162.1471 us. Best GFLOPs: 977.5728
2024-04-30 11:26:51 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1627: GFLOPs: 496.7851. Time: 7448.2488 us. Best GFLOPs: 977.5728
2024-04-30 11:26:51 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1628: GFLOPs: 646.9555. Time: 5719.3716 us. Best GFLOPs: 977.5728
2024-04-30 11:26:51 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1629: GFLOPs: 763.6286. Time: 4845.5219 us. Best GFLOPs: 977.5728
2024-04-30 11:26:51 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1630: GFLOPs: 684.6459. Time: 5404.5145 us. Best GFLOPs: 977.5728
2024-04-30 11:26:51 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1631: GFLOPs: 448.6294. Time: 8247.7403 us. Best GFLOPs: 977.5728
2024-04-30 11:26:51 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1632: GFLOPs: 593.9327. Time: 6229.9636 us. Best GFLOPs: 977.5728
2024-04-30 11:26:51 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1633: GFLOPs: 316.7606. Time: 11681.3097 us. Best GFLOPs: 977.5728
2024-04-30 11:26:51 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1634: GFLOPs: 785.0327. Time: 4713.4074 us. Best GFLOPs: 977.5728
2024-04-30 11:26:51 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1635: GFLOPs: 582.2602. Time: 6354.8549 us. Best GFLOPs: 977.5728
2024-04-30 11:26:51 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1636: GFLOPs: 633.2981. Time: 5842.7132 us. Best GFLOPs: 977.5728
2024-04-30 11:26:51 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1637: GFLOPs: 568.6046. Time: 6507.4725 us. Best GFLOPs: 977.5728
2024-04-30 11:26:51 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1638: GFLOPs: 280.4515. Time: 13193.6481 us. Best GFLOPs: 977.5728
2024-04-30 11:26:51 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1639: GFLOPs: 399.1906. Time: 9269.2047 us. Best GFLOPs: 977.5728
2024-04-30 11:26:51 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1640: GFLOPs: 647.4018. Time: 5715.4288 us. Best GFLOPs: 977.5728
2024-04-30 11:26:51 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1641: GFLOPs: 679.7865. Time: 5443.1488 us. Best GFLOPs: 977.5728
2024-04-30 11:26:51 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1642: GFLOPs: 552.3047. Time: 6699.5245 us. Best GFLOPs: 977.5728
2024-04-30 11:26:51 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1643: GFLOPs: 565.2841. Time: 6545.6982 us. Best GFLOPs: 977.5728
2024-04-30 11:26:51 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1644: GFLOPs: 622.2182. Time: 5946.7545 us. Best GFLOPs: 977.5728
2024-04-30 11:26:51 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1645: GFLOPs: 593.5465. Time: 6234.0166 us. Best GFLOPs: 977.5728
2024-04-30 11:26:51 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1646: GFLOPs: 549.5397. Time: 6733.2331 us. Best GFLOPs: 977.5728
2024-04-30 11:26:51 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1647: GFLOPs: 527.8766. Time: 7009.5525 us. Best GFLOPs: 977.5728
2024-04-30 11:26:51 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1648: GFLOPs: 588.2332. Time: 6290.3269 us. Best GFLOPs: 977.5728
2024-04-30 11:26:51 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1649: GFLOPs: 518.5629. Time: 7135.4487 us. Best GFLOPs: 977.5728
2024-04-30 11:26:51 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1650: GFLOPs: 574.6752. Time: 6438.7313 us. Best GFLOPs: 977.5728
2024-04-30 11:26:51 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1651: GFLOPs: 625.4002. Time: 5916.4976 us. Best GFLOPs: 977.5728
2024-04-30 11:26:51 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1652: GFLOPs: 430.9689. Time: 8585.7217 us. Best GFLOPs: 977.5728
2024-04-30 11:26:51 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1653: GFLOPs: 376.5396. Time: 9826.7999 us. Best GFLOPs: 977.5728
2024-04-30 11:26:51 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1654: GFLOPs: 648.1380. Time: 5708.9371 us. Best GFLOPs: 977.5728
2024-04-30 11:26:51 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1655: GFLOPs: 597.0533. Time: 6197.4019 us. Best GFLOPs: 977.5728
2024-04-30 11:26:51 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1656: GFLOPs: 569.1489. Time: 6501.2499 us. Best GFLOPs: 977.5728
2024-04-30 11:26:51 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1657: GFLOPs: 369.2501. Time: 10020.7926 us. Best GFLOPs: 977.5728
2024-04-30 11:26:51 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1658: GFLOPs: 554.7636. Time: 6669.8306 us. Best GFLOPs: 977.5728
2024-04-30 11:26:51 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1659: GFLOPs: 373.2398. Time: 9913.6786 us. Best GFLOPs: 977.5728
2024-04-30 11:26:51 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1660: GFLOPs: 344.1706. Time: 10751.0019 us. Best GFLOPs: 977.5728
2024-04-30 11:26:51 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1661: GFLOPs: 275.2168. Time: 13444.5949 us. Best GFLOPs: 977.5728
2024-04-30 11:26:51 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1662: GFLOPs: 48.4092. Time: 76435.4513 us. Best GFLOPs: 977.5728
2024-04-30 11:26:51 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1663: GFLOPs: 16.2376. Time: 227876.8130 us. Best GFLOPs: 977.5728
2024-04-30 11:26:51 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1664: GFLOPs: 1.6590. Time: 2230322.4173 us. Best GFLOPs: 977.5728
2024-04-30 11:39:32 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-30 11:39:33 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-30 11:39:38 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 11:39:38 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-30 11:39:51 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 11:40:05 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 11:40:20 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 11:40:34 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 11:40:42 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9081  0.9005  0.8777  0.8757  0.8294  0.8247  0.8242  0.8201  0.8201  0.8173  0.8122  0.8096  0.7728  0.7694  0.7566  0.7450
[17 : 32]:	0.7417  0.7394  0.7233  0.7090  0.7009  0.6960  0.6882  0.6853  0.6849  0.6714  0.6669  0.6613  0.6550  0.6547  0.6510  0.6493
[33 : 48]:	0.6490  0.6386  0.6369  0.6284  0.6159  0.6155  0.6155  0.6083  0.6001  0.5999  0.5942  0.5933  0.5857  0.5829  0.5803  0.5803
[49 : 64]:	0.5787  0.5773  0.5726  0.5724  0.5710  0.5658  0.5627  0.5624  0.5615  0.5609  0.5606  0.5554  0.5542  0.5534  0.5526  0.5508
2024-04-30 11:40:43 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-30 11:40:43 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-30 11:42:40 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1665: GFLOPs: 955.6949. Time: 3871.7158 us. Best GFLOPs: 977.5728
2024-04-30 11:42:40 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1666: GFLOPs: 888.0901. Time: 4166.4452 us. Best GFLOPs: 977.5728
2024-04-30 11:42:40 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1667: GFLOPs: 835.0906. Time: 4430.8714 us. Best GFLOPs: 977.5728
2024-04-30 11:42:40 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1668: GFLOPs: 790.5744. Time: 4680.3678 us. Best GFLOPs: 977.5728
2024-04-30 11:42:40 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1669: GFLOPs: 713.7573. Time: 5184.0857 us. Best GFLOPs: 977.5728
2024-04-30 11:42:40 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1670: GFLOPs: 816.9461. Time: 4529.2818 us. Best GFLOPs: 977.5728
2024-04-30 11:42:40 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1671: GFLOPs: 961.5182. Time: 3848.2673 us. Best GFLOPs: 977.5728
2024-04-30 11:42:40 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1672: GFLOPs: 272.4829. Time: 13579.4911 us. Best GFLOPs: 977.5728
2024-04-30 11:42:40 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1673: GFLOPs: 98.7846. Time: 37457.0580 us. Best GFLOPs: 977.5728
2024-04-30 11:42:40 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1674: GFLOPs: 754.7059. Time: 4902.8091 us. Best GFLOPs: 977.5728
2024-04-30 11:42:40 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1675: GFLOPs: 780.2987. Time: 4742.0030 us. Best GFLOPs: 977.5728
2024-04-30 11:42:40 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1676: GFLOPs: 915.8091. Time: 4040.3387 us. Best GFLOPs: 977.5728
2024-04-30 11:42:40 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1677: GFLOPs: 410.2657. Time: 9018.9819 us. Best GFLOPs: 977.5728
2024-04-30 11:42:40 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1678: GFLOPs: 790.1928. Time: 4682.6283 us. Best GFLOPs: 977.5728
2024-04-30 11:42:40 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1679: GFLOPs: 743.8102. Time: 4974.6280 us. Best GFLOPs: 977.5728
2024-04-30 11:42:40 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1680: GFLOPs: 736.6546. Time: 5022.9499 us. Best GFLOPs: 977.5728
2024-04-30 11:42:40 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1681: GFLOPs: 846.8797. Time: 4369.1908 us. Best GFLOPs: 977.5728
2024-04-30 11:42:40 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1682: GFLOPs: 711.5643. Time: 5200.0629 us. Best GFLOPs: 977.5728
2024-04-30 11:42:40 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1683: GFLOPs: 711.1835. Time: 5202.8471 us. Best GFLOPs: 977.5728
2024-04-30 11:42:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1684: GFLOPs: 784.6959. Time: 4715.4302 us. Best GFLOPs: 977.5728
2024-04-30 11:42:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1685: GFLOPs: 754.2115. Time: 4906.0230 us. Best GFLOPs: 977.5728
2024-04-30 11:42:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1686: GFLOPs: 724.4135. Time: 5107.8273 us. Best GFLOPs: 977.5728
2024-04-30 11:42:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1687: GFLOPs: 664.0431. Time: 5572.1969 us. Best GFLOPs: 977.5728
2024-04-30 11:42:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1688: GFLOPs: 616.1569. Time: 6005.2545 us. Best GFLOPs: 977.5728
2024-04-30 11:42:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1689: GFLOPs: 661.1704. Time: 5596.4074 us. Best GFLOPs: 977.5728
2024-04-30 11:42:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1690: GFLOPs: 634.5429. Time: 5831.2508 us. Best GFLOPs: 977.5728
2024-04-30 11:42:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1691: GFLOPs: 152.2008. Time: 24311.1606 us. Best GFLOPs: 977.5728
2024-04-30 11:42:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1692: GFLOPs: 551.7188. Time: 6706.6393 us. Best GFLOPs: 977.5728
2024-04-30 11:42:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1693: GFLOPs: 104.0049. Time: 35576.9590 us. Best GFLOPs: 977.5728
2024-04-30 11:42:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1694: GFLOPs: 649.0272. Time: 5701.1153 us. Best GFLOPs: 977.5728
2024-04-30 11:42:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1695: GFLOPs: 585.7988. Time: 6316.4674 us. Best GFLOPs: 977.5728
2024-04-30 11:42:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1696: GFLOPs: 589.0763. Time: 6281.3239 us. Best GFLOPs: 977.5728
2024-04-30 11:42:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1697: GFLOPs: 566.0345. Time: 6537.0206 us. Best GFLOPs: 977.5728
2024-04-30 11:42:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1698: GFLOPs: 632.9383. Time: 5846.0343 us. Best GFLOPs: 977.5728
2024-04-30 11:42:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1699: GFLOPs: 668.8717. Time: 5531.9709 us. Best GFLOPs: 977.5728
2024-04-30 11:42:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1700: GFLOPs: 627.3731. Time: 5897.8920 us. Best GFLOPs: 977.5728
2024-04-30 11:42:41 [INFO] [task_scheduler.cc:121] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1701: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(512)), "float32"), p1: T.Buffer((T.int64(32), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused in T.parallel(T.int64(112), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(7), T.int64(4), T.int64(16), T.int64(1), T.int64(4), T.int64(2), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(14) * T.int64(4) + oc_chunk_1 * T.int64(4) + oc_chunk_2_init * T.int64(4) + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(14) // T.int64(7) * T.int64(14) + oh_1 * T.int64(14) + oh_2_init * T.int64(2) + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(7) * T.int64(4) + ow_1 * T.int64(4) + ow_2_init + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(16), oc_block_1 * T.int64(16) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0 in range(T.int64(64)):
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(16), T.int64(6)):
                        for ax4_fused in T.vectorized(T.int64(8)):
                            with T.block("data_pad"):
                                v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                                v_i2 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(14) // T.int64(7) * T.int64(14) + ax2)
                                v_i3 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(7) * T.int64(4) + ax3)
                                v_i4 = T.axis.spatial(T.int64(512), ic_0 * T.int64(8) + ax4_fused)
                                T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                                T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                                data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                    for kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(7), T.int64(4), T.int64(16), T.int64(8), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(2), T.int64(1), T.int64(1)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(14) * T.int64(4) + oc_chunk_1 * T.int64(4) + oc_chunk_2 * T.int64(4) + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(14) // T.int64(7) * T.int64(14) + oh_1 * T.int64(14) + oh_2 * T.int64(2) + oh_3)
                            v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(7) * T.int64(4) + ow_1 * T.int64(4) + ow_2 + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_1 * T.int64(16) + oc_block_2 + oc_block_3)
                            v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(8) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
            for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(4), T.int64(14)):
                for ax3_ax4_fused in T.vectorized(T.int64(64)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(14) * T.int64(4) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(14) // T.int64(7) * T.int64(14) + ax2)
                        v_ax3 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(7) * T.int64(4) + ax3_ax4_fused // T.int64(16))
                        v_ax4 = T.axis.spatial(T.int64(16), ax3_ax4_fused % T.int64(16))
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[8, 1, 1, 4])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 1, 7, 2])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[7, 1, 4, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 16, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[64, 8])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=10)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86 = sch.get_loops(block=b68)
l87 = sch.fuse(l71, l72, l73, l74, l75, preserve_unit_iters=True)
sch.parallel(loop=l87)
l88 = sch.fuse(l86, preserve_unit_iters=True)
sch.vectorize(loop=l88)
l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107, l108, l109, l110 = sch.get_loops(block=b69)
l111 = sch.fuse(l89, preserve_unit_iters=True)
sch.parallel(loop=l111)
sch.annotate(block_or_loop=l111, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l111, ann_key="pragma_unroll_explicit", ann_val=1)
l112, l113, l114, l115, l116, l117 = sch.get_loops(block=b70)
l118 = sch.fuse(l116, l117, preserve_unit_iters=True)
sch.vectorize(loop=l118)
b119 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141 = sch.get_loops(block=b119)
b142 = sch.decompose_reduction(block=b119, loop=l126)
2024-04-30 11:42:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1702: GFLOPs: 415.8760. Time: 8897.3131 us. Best GFLOPs: 977.5728
2024-04-30 11:42:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1703: GFLOPs: 623.0945. Time: 5938.3910 us. Best GFLOPs: 977.5728
2024-04-30 11:42:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1704: GFLOPs: 536.7115. Time: 6894.1679 us. Best GFLOPs: 977.5728
2024-04-30 11:42:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1705: GFLOPs: 561.5056. Time: 6589.7449 us. Best GFLOPs: 977.5728
2024-04-30 11:42:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1706: GFLOPs: 638.3685. Time: 5796.3053 us. Best GFLOPs: 977.5728
2024-04-30 11:42:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1707: GFLOPs: 541.9571. Time: 6827.4388 us. Best GFLOPs: 977.5728
2024-04-30 11:42:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1708: GFLOPs: 620.2099. Time: 5966.0103 us. Best GFLOPs: 977.5728
2024-04-30 11:42:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1709: GFLOPs: 113.5437. Time: 32588.1413 us. Best GFLOPs: 977.5728
2024-04-30 11:42:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1710: GFLOPs: 674.8126. Time: 5483.2691 us. Best GFLOPs: 977.5728
2024-04-30 11:42:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1711: GFLOPs: 126.4513. Time: 29261.6838 us. Best GFLOPs: 977.5728
2024-04-30 11:42:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1712: GFLOPs: 112.6371. Time: 32850.4383 us. Best GFLOPs: 977.5728
2024-04-30 11:42:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1713: GFLOPs: 771.9293. Time: 4793.4170 us. Best GFLOPs: 977.5728
2024-04-30 11:42:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1714: GFLOPs: 78.4183. Time: 47185.1630 us. Best GFLOPs: 977.5728
2024-04-30 11:42:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1715: GFLOPs: 475.7085. Time: 7778.2492 us. Best GFLOPs: 977.5728
2024-04-30 11:42:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1716: GFLOPs: 578.4503. Time: 6396.7106 us. Best GFLOPs: 977.5728
2024-04-30 11:42:41 [INFO] [task_scheduler.cc:121] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1717: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(512)), "float32"), p1: T.Buffer((T.int64(32), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused in T.parallel(T.int64(224), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(2), T.int64(7), T.int64(1), T.int64(16), T.int64(1), T.int64(4), T.int64(1), T.int64(2), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(56) * T.int64(8) + oc_chunk_1 * T.int64(8) + oc_chunk_2_init * T.int64(4) + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(56) // T.int64(14) * T.int64(7) + oh_1 * T.int64(7) + oh_2_init + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(14) * T.int64(2) + ow_1 * T.int64(2) + ow_2_init * T.int64(2) + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(16), oc_block_1 * T.int64(16) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0 in T.grid(T.int64(128), T.int64(3)):
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(7), T.int64(4)):
                        for ax4_fused in T.vectorized(T.int64(4)):
                            with T.block("data_pad"):
                                v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                                v_i2 = T.axis.spatial(T.int64(30), kh_0 + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(56) // T.int64(14) * T.int64(7) + ax2)
                                v_i3 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(14) * T.int64(2) + ax3)
                                v_i4 = T.axis.spatial(T.int64(512), ic_0 * T.int64(4) + ax4_fused)
                                T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                                T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                                data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                    for kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(3), T.int64(1), T.int64(2), T.int64(7), T.int64(1), T.int64(16), T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(1), T.int64(2), T.int64(1)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(56) * T.int64(8) + oc_chunk_1 * T.int64(8) + oc_chunk_2 * T.int64(4) + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(56) // T.int64(14) * T.int64(7) + oh_1 * T.int64(7) + oh_2 + oh_3)
                            v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(14) * T.int64(2) + ow_1 * T.int64(2) + ow_2 * T.int64(2) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_1 * T.int64(16) + oc_block_2 + oc_block_3)
                            v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(4) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
            for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(8), T.int64(7)):
                for ax3_ax4_fused in T.vectorized(T.int64(32)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(56) * T.int64(8) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(56) // T.int64(14) * T.int64(7) + ax2)
                        v_ax3 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(14) * T.int64(2) + ax3_ax4_fused // T.int64(16))
                        v_ax4 = T.axis.spatial(T.int64(16), ax3_ax4_fused % T.int64(16))
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[4, 1, 2, 4])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[4, 1, 7, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[14, 1, 1, 2])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 16, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[128, 4])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=11)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87 = sch.get_loops(block=b68)
l88 = sch.fuse(l71, l72, l73, l74, l75, preserve_unit_iters=True)
sch.parallel(loop=l88)
l89 = sch.fuse(l87, preserve_unit_iters=True)
sch.vectorize(loop=l89)
l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107, l108, l109, l110, l111 = sch.get_loops(block=b69)
l112 = sch.fuse(l90, preserve_unit_iters=True)
sch.parallel(loop=l112)
sch.annotate(block_or_loop=l112, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l112, ann_key="pragma_unroll_explicit", ann_val=1)
l113, l114, l115, l116, l117, l118 = sch.get_loops(block=b70)
l119 = sch.fuse(l117, l118, preserve_unit_iters=True)
sch.vectorize(loop=l119)
b120 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141, l142 = sch.get_loops(block=b120)
b143 = sch.decompose_reduction(block=b120, loop=l127)
2024-04-30 11:42:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1718: GFLOPs: 487.6155. Time: 7588.3127 us. Best GFLOPs: 977.5728
2024-04-30 11:42:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1719: GFLOPs: 533.2739. Time: 6938.6087 us. Best GFLOPs: 977.5728
2024-04-30 11:42:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1720: GFLOPs: 523.3629. Time: 7070.0063 us. Best GFLOPs: 977.5728
2024-04-30 11:42:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1721: GFLOPs: 501.9587. Time: 7371.4811 us. Best GFLOPs: 977.5728
2024-04-30 11:42:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1722: GFLOPs: 497.3358. Time: 7440.0016 us. Best GFLOPs: 977.5728
2024-04-30 11:42:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1723: GFLOPs: 166.2084. Time: 22262.2852 us. Best GFLOPs: 977.5728
2024-04-30 11:42:41 [INFO] [task_scheduler.cc:121] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1724: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(512)), "float32"), p1: T.Buffer((T.int64(32), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused in T.parallel(T.int64(112), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(7), T.int64(4), T.int64(16), T.int64(1), T.int64(4), T.int64(2), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(14) * T.int64(4) + oc_chunk_1 * T.int64(4) + oc_chunk_2_init * T.int64(4) + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(14) // T.int64(7) * T.int64(14) + oh_1 * T.int64(14) + oh_2_init * T.int64(2) + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(7) * T.int64(4) + ow_1 * T.int64(4) + ow_2_init + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(16), oc_block_1 * T.int64(16) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0 in range(T.int64(128)):
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(16), T.int64(6)):
                        for ax4_fused in T.vectorized(T.int64(4)):
                            with T.block("data_pad"):
                                v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                                v_i2 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(14) // T.int64(7) * T.int64(14) + ax2)
                                v_i3 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(7) * T.int64(4) + ax3)
                                v_i4 = T.axis.spatial(T.int64(512), ic_0 * T.int64(4) + ax4_fused)
                                T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                                T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                                data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                    for kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(7), T.int64(4), T.int64(16), T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(2), T.int64(1), T.int64(1)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(14) * T.int64(4) + oc_chunk_1 * T.int64(4) + oc_chunk_2 * T.int64(4) + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(14) // T.int64(7) * T.int64(14) + oh_1 * T.int64(14) + oh_2 * T.int64(2) + oh_3)
                            v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(7) * T.int64(4) + ow_1 * T.int64(4) + ow_2 + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_1 * T.int64(16) + oc_block_2 + oc_block_3)
                            v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(4) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
            for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(4), T.int64(14)):
                for ax3_ax4_fused in T.vectorized(T.int64(64)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(14) * T.int64(4) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(14) // T.int64(7) * T.int64(14) + ax2)
                        v_ax3 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(7) * T.int64(4) + ax3_ax4_fused // T.int64(16))
                        v_ax4 = T.axis.spatial(T.int64(16), ax3_ax4_fused % T.int64(16))
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[8, 1, 1, 4])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 1, 7, 2])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[7, 1, 4, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 16, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[128, 4])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=10)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86 = sch.get_loops(block=b68)
l87 = sch.fuse(l71, l72, l73, l74, l75, preserve_unit_iters=True)
sch.parallel(loop=l87)
l88 = sch.fuse(l86, preserve_unit_iters=True)
sch.vectorize(loop=l88)
l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107, l108, l109, l110 = sch.get_loops(block=b69)
l111 = sch.fuse(l89, preserve_unit_iters=True)
sch.parallel(loop=l111)
sch.annotate(block_or_loop=l111, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l111, ann_key="pragma_unroll_explicit", ann_val=1)
l112, l113, l114, l115, l116, l117 = sch.get_loops(block=b70)
l118 = sch.fuse(l116, l117, preserve_unit_iters=True)
sch.vectorize(loop=l118)
b119 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141 = sch.get_loops(block=b119)
b142 = sch.decompose_reduction(block=b119, loop=l126)
2024-04-30 11:42:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1725: GFLOPs: 177.9958. Time: 20788.0136 us. Best GFLOPs: 977.5728
2024-04-30 11:42:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1726: GFLOPs: 39.7372. Time: 93116.3273 us. Best GFLOPs: 977.5728
2024-04-30 11:42:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1727: GFLOPs: 94.7271. Time: 39061.4523 us. Best GFLOPs: 977.5728
2024-04-30 11:42:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1728: GFLOPs: 27.5052. Time: 134526.4107 us. Best GFLOPs: 977.5728
2024-04-30 11:42:41 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-30 11:42:42 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-30 11:42:46 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 11:42:46 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-30 11:42:59 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 11:43:14 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 11:43:28 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 11:43:42 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 11:43:51 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.8620  0.8481  0.8372  0.8065  0.8016  0.7983  0.7942  0.7936  0.7718  0.7684  0.7676  0.7536  0.7519  0.7472  0.7415  0.7413
[17 : 32]:	0.7328  0.7237  0.7206  0.7154  0.7079  0.7056  0.6935  0.6909  0.6886  0.6828  0.6817  0.6811  0.6715  0.6515  0.6496  0.6470
[33 : 48]:	0.6430  0.6419  0.6419  0.6402  0.6383  0.6344  0.6341  0.6318  0.6296  0.6271  0.6271  0.6269  0.6249  0.6208  0.6188  0.6056
[49 : 64]:	0.6039  0.6033  0.6024  0.5972  0.5902  0.5892  0.5890  0.5888  0.5825  0.5825  0.5817  0.5787  0.5785  0.5762  0.5731  0.5721
2024-04-30 11:43:51 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-30 11:43:51 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-30 11:46:11 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1729: GFLOPs: 711.4164. Time: 5201.1438 us. Best GFLOPs: 977.5728
2024-04-30 11:46:11 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1730: GFLOPs: 972.7765. Time: 3803.7299 us. Best GFLOPs: 977.5728
2024-04-30 11:46:11 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1731: GFLOPs: 905.0198. Time: 4088.5059 us. Best GFLOPs: 977.5728
2024-04-30 11:46:11 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1732: GFLOPs: 526.6452. Time: 7025.9423 us. Best GFLOPs: 977.5728
2024-04-30 11:46:11 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1733: GFLOPs: 777.6528. Time: 4758.1377 us. Best GFLOPs: 977.5728
2024-04-30 11:46:11 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1734: GFLOPs: 895.7864. Time: 4130.6486 us. Best GFLOPs: 977.5728
2024-04-30 11:46:11 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1735: GFLOPs: 362.2040. Time: 10215.7312 us. Best GFLOPs: 977.5728
2024-04-30 11:46:11 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1736: GFLOPs: 724.4860. Time: 5107.3163 us. Best GFLOPs: 977.5728
2024-04-30 11:46:11 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1737: GFLOPs: 670.2185. Time: 5520.8549 us. Best GFLOPs: 977.5728
2024-04-30 11:46:11 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1738: GFLOPs: 848.7054. Time: 4359.7917 us. Best GFLOPs: 977.5728
2024-04-30 11:46:11 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1739: GFLOPs: 800.5350. Time: 4622.1326 us. Best GFLOPs: 977.5728
2024-04-30 11:46:11 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1740: GFLOPs: 517.8947. Time: 7144.6554 us. Best GFLOPs: 977.5728
2024-04-30 11:46:11 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1741: GFLOPs: 580.6527. Time: 6372.4477 us. Best GFLOPs: 977.5728
2024-04-30 11:46:11 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1742: GFLOPs: 882.5241. Time: 4192.7229 us. Best GFLOPs: 977.5728
2024-04-30 11:46:11 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1743: GFLOPs: 322.0891. Time: 11488.0609 us. Best GFLOPs: 977.5728
2024-04-30 11:46:11 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1744: GFLOPs: 702.9982. Time: 5263.4257 us. Best GFLOPs: 977.5728
2024-04-30 11:46:11 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1745: GFLOPs: 752.8091. Time: 4915.1621 us. Best GFLOPs: 977.5728
2024-04-30 11:46:11 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1746: GFLOPs: 596.2513. Time: 6205.7373 us. Best GFLOPs: 977.5728
2024-04-30 11:46:11 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1747: GFLOPs: 668.8085. Time: 5532.4935 us. Best GFLOPs: 977.5728
2024-04-30 11:46:11 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1748: GFLOPs: 806.9863. Time: 4585.1820 us. Best GFLOPs: 977.5728
2024-04-30 11:46:11 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1749: GFLOPs: 652.4704. Time: 5671.0292 us. Best GFLOPs: 977.5728
2024-04-30 11:46:11 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1750: GFLOPs: 679.3880. Time: 5446.3416 us. Best GFLOPs: 977.5728
2024-04-30 11:46:11 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1751: GFLOPs: 825.7923. Time: 4480.7623 us. Best GFLOPs: 977.5728
2024-04-30 11:46:11 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1752: GFLOPs: 704.0319. Time: 5255.6978 us. Best GFLOPs: 977.5728
2024-04-30 11:46:11 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1753: GFLOPs: 722.4649. Time: 5121.6040 us. Best GFLOPs: 977.5728
2024-04-30 11:46:11 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1754: GFLOPs: 676.7980. Time: 5467.1835 us. Best GFLOPs: 977.5728
2024-04-30 11:46:11 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1755: GFLOPs: 553.6593. Time: 6683.1335 us. Best GFLOPs: 977.5728
2024-04-30 11:46:11 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1756: GFLOPs: 738.2241. Time: 5012.2704 us. Best GFLOPs: 977.5728
2024-04-30 11:46:11 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1757: GFLOPs: 672.5591. Time: 5501.6414 us. Best GFLOPs: 977.5728
2024-04-30 11:46:11 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1758: GFLOPs: 610.4011. Time: 6061.8807 us. Best GFLOPs: 977.5728
2024-04-30 11:46:11 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1759: GFLOPs: 702.1031. Time: 5270.1364 us. Best GFLOPs: 977.5728
2024-04-30 11:46:11 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1760: GFLOPs: 584.4395. Time: 6331.1582 us. Best GFLOPs: 977.5728
2024-04-30 11:46:11 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1761: GFLOPs: 333.8794. Time: 11082.3801 us. Best GFLOPs: 977.5728
2024-04-30 11:46:11 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1762: GFLOPs: 707.9926. Time: 5226.2959 us. Best GFLOPs: 977.5728
2024-04-30 11:46:11 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1763: GFLOPs: 698.1296. Time: 5300.1322 us. Best GFLOPs: 977.5728
2024-04-30 11:46:11 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1764: GFLOPs: 508.4394. Time: 7277.5223 us. Best GFLOPs: 977.5728
2024-04-30 11:46:11 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1765: GFLOPs: 620.0428. Time: 5967.6185 us. Best GFLOPs: 977.5728
2024-04-30 11:46:11 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1766: GFLOPs: 593.0196. Time: 6239.5561 us. Best GFLOPs: 977.5728
2024-04-30 11:46:11 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1767: GFLOPs: 674.7626. Time: 5483.6748 us. Best GFLOPs: 977.5728
2024-04-30 11:46:11 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1768: GFLOPs: 27.7358. Time: 133408.2303 us. Best GFLOPs: 977.5728
2024-04-30 11:46:11 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1769: GFLOPs: 740.0183. Time: 5000.1180 us. Best GFLOPs: 977.5728
2024-04-30 11:46:11 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1770: GFLOPs: 89.5359. Time: 41326.2180 us. Best GFLOPs: 977.5728
2024-04-30 11:46:11 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1771: GFLOPs: 488.5017. Time: 7574.5467 us. Best GFLOPs: 977.5728
2024-04-30 11:46:11 [INFO] [task_scheduler.cc:121] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1772: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(512)), "float32"), p1: T.Buffer((T.int64(32), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused in T.parallel(T.int64(448), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(16), T.int64(1), T.int64(4), T.int64(2), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(56) * T.int64(4) + oc_chunk_1 * T.int64(4) + oc_chunk_2_init * T.int64(4) + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(56) // T.int64(4) * T.int64(2) + oh_1 * T.int64(2) + oh_2_init * T.int64(2) + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(4) * T.int64(7) + ow_1 * T.int64(7) + ow_2_init + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(16), oc_block_1 * T.int64(16) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0 in range(T.int64(128)):
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(9)):
                        for ax4_fused in T.vectorized(T.int64(4)):
                            with T.block("data_pad"):
                                v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                                v_i2 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(56) // T.int64(4) * T.int64(2) + ax2)
                                v_i3 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(4) * T.int64(7) + ax3)
                                v_i4 = T.axis.spatial(T.int64(512), ic_0 * T.int64(4) + ax4_fused)
                                T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                                T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                                data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                    for kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(16), T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(2), T.int64(1), T.int64(1)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(56) * T.int64(4) + oc_chunk_1 * T.int64(4) + oc_chunk_2 * T.int64(4) + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(56) // T.int64(4) * T.int64(2) + oh_1 * T.int64(2) + oh_2 * T.int64(2) + oh_3)
                            v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(4) * T.int64(7) + ow_1 * T.int64(7) + ow_2 + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_1 * T.int64(16) + oc_block_2 + oc_block_3)
                            v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(4) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(4), T.int64(2), T.int64(7)):
                for ax4_fused in T.vectorized(T.int64(16)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(56) * T.int64(4) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(56) // T.int64(4) * T.int64(2) + ax2)
                        v_ax3 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(4) * T.int64(7) + ax3)
                        v_ax4 = T.axis.spatial(T.int64(16), ax4_fused)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[8, 1, 1, 4])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[14, 1, 1, 2])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[4, 1, 7, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 16, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[128, 4])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=10)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86 = sch.get_loops(block=b68)
l87 = sch.fuse(l71, l72, l73, l74, l75, preserve_unit_iters=True)
sch.parallel(loop=l87)
l88 = sch.fuse(l86, preserve_unit_iters=True)
sch.vectorize(loop=l88)
l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107, l108, l109, l110 = sch.get_loops(block=b69)
l111 = sch.fuse(l89, preserve_unit_iters=True)
sch.parallel(loop=l111)
sch.annotate(block_or_loop=l111, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l111, ann_key="pragma_unroll_explicit", ann_val=1)
l112, l113, l114, l115, l116, l117 = sch.get_loops(block=b70)
l118 = sch.fuse(l117, preserve_unit_iters=True)
sch.vectorize(loop=l118)
b119 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141 = sch.get_loops(block=b119)
b142 = sch.decompose_reduction(block=b119, loop=l126)
2024-04-30 11:46:11 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1773: GFLOPs: 595.9939. Time: 6208.4174 us. Best GFLOPs: 977.5728
2024-04-30 11:46:11 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1774: GFLOPs: 552.9896. Time: 6691.2264 us. Best GFLOPs: 977.5728
2024-04-30 11:46:11 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1775: GFLOPs: 390.4775. Time: 9476.0366 us. Best GFLOPs: 977.5728
2024-04-30 11:46:11 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1776: GFLOPs: 626.0278. Time: 5910.5669 us. Best GFLOPs: 977.5728
2024-04-30 11:46:11 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1777: GFLOPs: 635.1667. Time: 5825.5241 us. Best GFLOPs: 977.5728
2024-04-30 11:46:11 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1778: GFLOPs: 657.4578. Time: 5628.0101 us. Best GFLOPs: 977.5728
2024-04-30 11:46:11 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1779: GFLOPs: 626.2232. Time: 5908.7222 us. Best GFLOPs: 977.5728
2024-04-30 11:46:11 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1780: GFLOPs: 10.7866. Time: 343034.9417 us. Best GFLOPs: 977.5728
2024-04-30 11:46:11 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1781: GFLOPs: 574.9468. Time: 6435.6894 us. Best GFLOPs: 977.5728
2024-04-30 11:46:11 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1782: GFLOPs: 437.5631. Time: 8456.3328 us. Best GFLOPs: 977.5728
2024-04-30 11:46:11 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1783: GFLOPs: 567.4419. Time: 6520.8066 us. Best GFLOPs: 977.5728
2024-04-30 11:46:11 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1784: GFLOPs: 628.2660. Time: 5889.5101 us. Best GFLOPs: 977.5728
2024-04-30 11:46:11 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1785: GFLOPs: 24.1651. Time: 153121.0010 us. Best GFLOPs: 977.5728
2024-04-30 11:46:11 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1786: GFLOPs: 25.3326. Time: 146063.7827 us. Best GFLOPs: 977.5728
2024-04-30 11:46:11 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1787: GFLOPs: 609.8868. Time: 6066.9925 us. Best GFLOPs: 977.5728
2024-04-30 11:46:11 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1788: GFLOPs: 408.3021. Time: 9062.3567 us. Best GFLOPs: 977.5728
2024-04-30 11:46:11 [INFO] [task_scheduler.cc:121] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1789: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(512)), "float32"), p1: T.Buffer((T.int64(32), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused in T.parallel(T.int64(224), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(7), T.int64(2), T.int64(16), T.int64(1), T.int64(4), T.int64(2), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(28) * T.int64(4) + oc_chunk_1 * T.int64(4) + oc_chunk_2_init * T.int64(4) + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(28) // T.int64(14) * T.int64(14) + oh_1 * T.int64(14) + oh_2_init * T.int64(2) + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(14) * T.int64(2) + ow_1 * T.int64(2) + ow_2_init + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(16), oc_block_1 * T.int64(16) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0 in range(T.int64(128)):
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(16), T.int64(4)):
                        for ax4_fused in T.vectorized(T.int64(4)):
                            with T.block("data_pad"):
                                v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                                v_i2 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(28) // T.int64(14) * T.int64(14) + ax2)
                                v_i3 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(14) * T.int64(2) + ax3)
                                v_i4 = T.axis.spatial(T.int64(512), ic_0 * T.int64(4) + ax4_fused)
                                T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                                T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                                data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                    for kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(7), T.int64(2), T.int64(16), T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(2), T.int64(1), T.int64(1)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(28) * T.int64(4) + oc_chunk_1 * T.int64(4) + oc_chunk_2 * T.int64(4) + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(28) // T.int64(14) * T.int64(14) + oh_1 * T.int64(14) + oh_2 * T.int64(2) + oh_3)
                            v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(14) * T.int64(2) + ow_1 * T.int64(2) + ow_2 + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_1 * T.int64(16) + oc_block_2 + oc_block_3)
                            v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(4) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
            for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(4), T.int64(14)):
                for ax3_ax4_fused in T.vectorized(T.int64(32)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(28) * T.int64(4) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(28) // T.int64(14) * T.int64(14) + ax2)
                        v_ax3 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(14) * T.int64(2) + ax3_ax4_fused // T.int64(16))
                        v_ax4 = T.axis.spatial(T.int64(16), ax3_ax4_fused % T.int64(16))
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[8, 1, 1, 4])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 1, 7, 2])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[14, 1, 2, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 16, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[128, 4])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=10)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86 = sch.get_loops(block=b68)
l87 = sch.fuse(l71, l72, l73, l74, l75, preserve_unit_iters=True)
sch.parallel(loop=l87)
l88 = sch.fuse(l86, preserve_unit_iters=True)
sch.vectorize(loop=l88)
l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107, l108, l109, l110 = sch.get_loops(block=b69)
l111 = sch.fuse(l89, preserve_unit_iters=True)
sch.parallel(loop=l111)
sch.annotate(block_or_loop=l111, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l111, ann_key="pragma_unroll_explicit", ann_val=1)
l112, l113, l114, l115, l116, l117 = sch.get_loops(block=b70)
l118 = sch.fuse(l116, l117, preserve_unit_iters=True)
sch.vectorize(loop=l118)
b119 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141 = sch.get_loops(block=b119)
b142 = sch.decompose_reduction(block=b119, loop=l126)
2024-04-30 11:46:11 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1790: GFLOPs: 4.4643. Time: 828846.5393 us. Best GFLOPs: 977.5728
2024-04-30 11:46:11 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1791: GFLOPs: 68.1163. Time: 54321.5027 us. Best GFLOPs: 977.5728
2024-04-30 11:46:11 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1792: GFLOPs: 61.7905. Time: 59882.6387 us. Best GFLOPs: 977.5728
2024-04-30 11:52:10 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-30 11:52:11 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-30 11:52:16 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 11:52:16 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-30 11:52:29 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 11:52:43 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 11:52:57 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 11:53:12 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 11:53:20 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9465  0.9069  0.8155  0.7679  0.7550  0.7485  0.7406  0.7316  0.7215  0.7212  0.7176  0.7154  0.7123  0.7059  0.7032  0.7026
[17 : 32]:	0.7003  0.6934  0.6925  0.6859  0.6833  0.6831  0.6613  0.6585  0.6569  0.6547  0.6539  0.6479  0.6458  0.6395  0.6379  0.6364
[33 : 48]:	0.6268  0.6248  0.6238  0.6209  0.6197  0.6196  0.6166  0.6140  0.6133  0.6131  0.6114  0.6098  0.5972  0.5891  0.5881  0.5871
[49 : 64]:	0.5868  0.5852  0.5802  0.5786  0.5747  0.5690  0.5679  0.5666  0.5628  0.5605  0.5587  0.5543  0.5542  0.5528  0.5513  0.5485
2024-04-30 11:53:21 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-30 11:53:21 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-30 11:55:27 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1793: GFLOPs: 960.5059. Time: 3852.3232 us. Best GFLOPs: 977.5728
2024-04-30 11:55:27 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1794: GFLOPs: 951.2334. Time: 3889.8748 us. Best GFLOPs: 977.5728
2024-04-30 11:55:27 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1795: GFLOPs: 496.5937. Time: 7451.1199 us. Best GFLOPs: 977.5728
2024-04-30 11:55:27 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1796: GFLOPs: 835.0665. Time: 4430.9991 us. Best GFLOPs: 977.5728
2024-04-30 11:55:27 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1797: GFLOPs: 808.1323. Time: 4578.6795 us. Best GFLOPs: 977.5728
2024-04-30 11:55:27 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1798: GFLOPs: 801.6281. Time: 4615.8297 us. Best GFLOPs: 977.5728
2024-04-30 11:55:27 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1799: GFLOPs: 359.1682. Time: 10302.0793 us. Best GFLOPs: 977.5728
2024-04-30 11:55:27 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1800: GFLOPs: 793.3372. Time: 4664.0682 us. Best GFLOPs: 977.5728
2024-04-30 11:55:27 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1801: GFLOPs: 681.8990. Time: 5426.2857 us. Best GFLOPs: 977.5728
2024-04-30 11:55:27 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1802: GFLOPs: 724.5025. Time: 5107.1997 us. Best GFLOPs: 977.5728
2024-04-30 11:55:27 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1803: GFLOPs: 726.8282. Time: 5090.8579 us. Best GFLOPs: 977.5728
2024-04-30 11:55:27 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1804: GFLOPs: 695.4583. Time: 5320.4897 us. Best GFLOPs: 977.5728
2024-04-30 11:55:27 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1805: GFLOPs: 793.3025. Time: 4664.2723 us. Best GFLOPs: 977.5728
2024-04-30 11:55:27 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1806: GFLOPs: 336.5122. Time: 10995.6739 us. Best GFLOPs: 977.5728
2024-04-30 11:55:27 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1807: GFLOPs: 701.2960. Time: 5276.2016 us. Best GFLOPs: 977.5728
2024-04-30 11:55:27 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1808: GFLOPs: 841.9308. Time: 4394.8728 us. Best GFLOPs: 977.5728
2024-04-30 11:55:27 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1809: GFLOPs: 657.3967. Time: 5628.5329 us. Best GFLOPs: 977.5728
2024-04-30 11:55:27 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1810: GFLOPs: 653.2469. Time: 5664.2889 us. Best GFLOPs: 977.5728
2024-04-30 11:55:27 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1811: GFLOPs: 608.1392. Time: 6084.4279 us. Best GFLOPs: 977.5728
2024-04-30 11:55:27 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1812: GFLOPs: 654.4484. Time: 5653.8898 us. Best GFLOPs: 977.5728
2024-04-30 11:55:27 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1813: GFLOPs: 651.7074. Time: 5677.6691 us. Best GFLOPs: 977.5728
2024-04-30 11:55:27 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1814: GFLOPs: 621.7826. Time: 5950.9209 us. Best GFLOPs: 977.5728
2024-04-30 11:55:27 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1815: GFLOPs: 730.9372. Time: 5062.2394 us. Best GFLOPs: 977.5728
2024-04-30 11:55:27 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1816: GFLOPs: 646.5078. Time: 5723.3321 us. Best GFLOPs: 977.5728
2024-04-30 11:55:27 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1817: GFLOPs: 681.4879. Time: 5429.5589 us. Best GFLOPs: 977.5728
2024-04-30 11:55:27 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1818: GFLOPs: 572.3520. Time: 6464.8660 us. Best GFLOPs: 977.5728
2024-04-30 11:55:27 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1819: GFLOPs: 670.9751. Time: 5514.6289 us. Best GFLOPs: 977.5728
2024-04-30 11:55:27 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1820: GFLOPs: 712.4621. Time: 5193.5102 us. Best GFLOPs: 977.5728
2024-04-30 11:55:27 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1821: GFLOPs: 630.6138. Time: 5867.5829 us. Best GFLOPs: 977.5728
2024-04-30 11:55:27 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1822: GFLOPs: 575.2075. Time: 6432.7723 us. Best GFLOPs: 977.5728
2024-04-30 11:55:27 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1823: GFLOPs: 656.3911. Time: 5637.1556 us. Best GFLOPs: 977.5728
2024-04-30 11:55:27 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1824: GFLOPs: 726.4799. Time: 5093.2984 us. Best GFLOPs: 977.5728
2024-04-30 11:55:27 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1825: GFLOPs: 556.7078. Time: 6646.5366 us. Best GFLOPs: 977.5728
2024-04-30 11:55:27 [INFO] [task_scheduler.cc:121] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1826: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(512)), "float32"), p1: T.Buffer((T.int64(32), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused in T.parallel(T.int64(224), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(2), T.int64(14), T.int64(1), T.int64(16), T.int64(1), T.int64(2), T.int64(1), T.int64(2), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(28) * T.int64(4) + oc_chunk_1 * T.int64(4) + oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(28) // T.int64(14) * T.int64(14) + oh_1 * T.int64(14) + oh_2_init + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(14) * T.int64(2) + ow_1 * T.int64(2) + ow_2_init * T.int64(2) + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(16), oc_block_1 * T.int64(16) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0 in range(T.int64(64)):
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(16), T.int64(4)):
                        for ax4_fused in T.vectorized(T.int64(8)):
                            with T.block("data_pad"):
                                v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                                v_i2 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(28) // T.int64(14) * T.int64(14) + ax2)
                                v_i3 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(14) * T.int64(2) + ax3)
                                v_i4 = T.axis.spatial(T.int64(512), ic_0 * T.int64(8) + ax4_fused)
                                T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                                T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                                data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                    for kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(3), T.int64(3), T.int64(1), T.int64(2), T.int64(14), T.int64(1), T.int64(16), T.int64(8), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(2), T.int64(1)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(28) * T.int64(4) + oc_chunk_1 * T.int64(4) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(28) // T.int64(14) * T.int64(14) + oh_1 * T.int64(14) + oh_2 + oh_3)
                            v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(14) * T.int64(2) + ow_1 * T.int64(2) + ow_2 * T.int64(2) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_1 * T.int64(16) + oc_block_2 + oc_block_3)
                            v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(8) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
            for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(4), T.int64(14)):
                for ax3_ax4_fused in T.vectorized(T.int64(32)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(28) * T.int64(4) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(28) // T.int64(14) * T.int64(14) + ax2)
                        v_ax3 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(14) * T.int64(2) + ax3_ax4_fused // T.int64(16))
                        v_ax4 = T.axis.spatial(T.int64(16), ax3_ax4_fused % T.int64(16))
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[8, 1, 2, 2])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 1, 14, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[14, 1, 1, 2])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 16, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[64, 8])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=10)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86 = sch.get_loops(block=b68)
l87 = sch.fuse(l71, l72, l73, l74, l75, preserve_unit_iters=True)
sch.parallel(loop=l87)
l88 = sch.fuse(l86, preserve_unit_iters=True)
sch.vectorize(loop=l88)
l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107, l108, l109, l110 = sch.get_loops(block=b69)
l111 = sch.fuse(l89, preserve_unit_iters=True)
sch.parallel(loop=l111)
sch.annotate(block_or_loop=l111, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l111, ann_key="pragma_unroll_explicit", ann_val=1)
l112, l113, l114, l115, l116, l117 = sch.get_loops(block=b70)
l118 = sch.fuse(l116, l117, preserve_unit_iters=True)
sch.vectorize(loop=l118)
b119 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141 = sch.get_loops(block=b119)
b142 = sch.decompose_reduction(block=b119, loop=l126)
2024-04-30 11:55:27 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1827: GFLOPs: 643.9849. Time: 5745.7542 us. Best GFLOPs: 977.5728
2024-04-30 11:55:27 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1828: GFLOPs: 398.8530. Time: 9277.0489 us. Best GFLOPs: 977.5728
2024-04-30 11:55:27 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1829: GFLOPs: 589.7318. Time: 6274.3421 us. Best GFLOPs: 977.5728
2024-04-30 11:55:27 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1830: GFLOPs: 568.2480. Time: 6511.5561 us. Best GFLOPs: 977.5728
2024-04-30 11:55:27 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1831: GFLOPs: 560.3144. Time: 6603.7546 us. Best GFLOPs: 977.5728
2024-04-30 11:55:27 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1832: GFLOPs: 624.0627. Time: 5929.1782 us. Best GFLOPs: 977.5728
2024-04-30 11:55:27 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1833: GFLOPs: 664.1635. Time: 5571.1867 us. Best GFLOPs: 977.5728
2024-04-30 11:55:27 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1834: GFLOPs: 590.3440. Time: 6267.8351 us. Best GFLOPs: 977.5728
2024-04-30 11:55:27 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1835: GFLOPs: 657.9949. Time: 5623.4154 us. Best GFLOPs: 977.5728
2024-04-30 11:55:27 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1836: GFLOPs: 705.9771. Time: 5241.2170 us. Best GFLOPs: 977.5728
2024-04-30 11:55:27 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1837: GFLOPs: 570.0948. Time: 6490.4620 us. Best GFLOPs: 977.5728
2024-04-30 11:55:27 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1838: GFLOPs: 538.0713. Time: 6876.7447 us. Best GFLOPs: 977.5728
2024-04-30 11:55:27 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1839: GFLOPs: 548.3289. Time: 6748.1019 us. Best GFLOPs: 977.5728
2024-04-30 11:55:27 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1840: GFLOPs: 552.9023. Time: 6692.2836 us. Best GFLOPs: 977.5728
2024-04-30 11:55:27 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1841: GFLOPs: 569.0542. Time: 6502.3310 us. Best GFLOPs: 977.5728
2024-04-30 11:55:27 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1842: GFLOPs: 551.2415. Time: 6712.4465 us. Best GFLOPs: 977.5728
2024-04-30 11:55:27 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1843: GFLOPs: 673.0849. Time: 5497.3433 us. Best GFLOPs: 977.5728
2024-04-30 11:55:27 [INFO] [task_scheduler.cc:121] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1844: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(512)), "float32"), p1: T.Buffer((T.int64(32), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_fused_fused in T.parallel(T.int64(224), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for oc_block_0 in range(T.int64(1)):
                for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                    for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(2), T.int64(7), T.int64(1), T.int64(16), T.int64(1), T.int64(4), T.int64(1), T.int64(2), T.int64(1)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(56) * T.int64(8) + oc_chunk_1 * T.int64(8) + oc_chunk_2_init * T.int64(4) + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(56) // T.int64(14) * T.int64(7) + oh_1 * T.int64(7) + oh_2_init + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(14) * T.int64(2) + ow_1 * T.int64(2) + ow_2_init * T.int64(2) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2_init + oc_block_3_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                    for ic_0 in range(T.int64(128)):
                        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(9), T.int64(4)):
                            for ax4_fused in T.vectorized(T.int64(4)):
                                with T.block("data_pad"):
                                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                                    v_i2 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(56) // T.int64(14) * T.int64(7) + ax2)
                                    v_i3 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(14) * T.int64(2) + ax3)
                                    v_i4 = T.axis.spatial(T.int64(512), ic_0 * T.int64(4) + ax4_fused)
                                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                        for kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(3), T.int64(3), T.int64(1), T.int64(2), T.int64(7), T.int64(1), T.int64(16), T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(1), T.int64(2), T.int64(1)):
                            with T.block("conv2d_NCHWc_update"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                                v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(56) * T.int64(8) + oc_chunk_1 * T.int64(8) + oc_chunk_2 * T.int64(4) + oc_chunk_3)
                                v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(56) // T.int64(14) * T.int64(7) + oh_1 * T.int64(7) + oh_2 + oh_3)
                                v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(14) * T.int64(2) + ow_1 * T.int64(2) + ow_2 * T.int64(2) + ow_3)
                                v_oc_block = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2 + oc_block_3)
                                v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(4) + ic_1)
                                v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                                v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                                T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
                for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(8), T.int64(7)):
                    for ax3_ax4_fused in T.vectorized(T.int64(32)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(56) * T.int64(8) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(56) // T.int64(14) * T.int64(7) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(14) * T.int64(2) + ax3_ax4_fused // T.int64(16))
                            v_ax4 = T.axis.spatial(T.int64(16), ax3_ax4_fused % T.int64(16))
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[4, 1, 2, 4])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[4, 1, 7, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[14, 1, 1, 2])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 16, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[128, 4])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=32)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=10)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86 = sch.get_loops(block=b68)
l87 = sch.fuse(l71, l72, l73, l74, preserve_unit_iters=True)
sch.parallel(loop=l87)
l88 = sch.fuse(l86, preserve_unit_iters=True)
sch.vectorize(loop=l88)
l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107, l108, l109, l110, l111 = sch.get_loops(block=b69)
l112 = sch.fuse(l89, preserve_unit_iters=True)
sch.parallel(loop=l112)
sch.annotate(block_or_loop=l112, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l112, ann_key="pragma_unroll_explicit", ann_val=1)
l113, l114, l115, l116, l117, l118, l119 = sch.get_loops(block=b70)
l120 = sch.fuse(l118, l119, preserve_unit_iters=True)
sch.vectorize(loop=l120)
b121 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141, l142, l143, l144 = sch.get_loops(block=b121)
b145 = sch.decompose_reduction(block=b121, loop=l129)
2024-04-30 11:55:27 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1845: GFLOPs: 21.7156. Time: 170392.2813 us. Best GFLOPs: 977.5728
2024-04-30 11:55:27 [INFO] [task_scheduler.cc:121] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1846: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(512)), "float32"), p1: T.Buffer((T.int64(32), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_fused_fused in T.parallel(T.int64(224), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for oc_block_0 in range(T.int64(1)):
                for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1)):
                    for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(16), T.int64(1), T.int64(4), T.int64(1), T.int64(2), T.int64(1)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(56) * T.int64(8) + oc_chunk_1 * T.int64(4) + oc_chunk_2_init * T.int64(4) + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(56) // T.int64(14) * T.int64(7) + oh_1 * T.int64(7) + oh_2_init + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(14) * T.int64(2) + ow_1 * T.int64(2) + ow_2_init * T.int64(2) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2_init + oc_block_3_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                    for ic_0 in range(T.int64(128)):
                        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(9), T.int64(4)):
                            for ax4_fused in T.vectorized(T.int64(4)):
                                with T.block("data_pad"):
                                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                                    v_i2 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(56) // T.int64(14) * T.int64(7) + ax2)
                                    v_i3 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(14) * T.int64(2) + ax3)
                                    v_i4 = T.axis.spatial(T.int64(512), ic_0 * T.int64(4) + ax4_fused)
                                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                        for kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(16), T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(1), T.int64(2), T.int64(1)):
                            with T.block("conv2d_NCHWc_update"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                                v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(56) * T.int64(8) + oc_chunk_1 * T.int64(4) + oc_chunk_2 * T.int64(4) + oc_chunk_3)
                                v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(56) // T.int64(14) * T.int64(7) + oh_1 * T.int64(7) + oh_2 + oh_3)
                                v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(14) * T.int64(2) + ow_1 * T.int64(2) + ow_2 * T.int64(2) + ow_3)
                                v_oc_block = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2 + oc_block_3)
                                v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(4) + ic_1)
                                v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                                v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                                T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
                for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(8), T.int64(7)):
                    for ax3_ax4_fused in T.vectorized(T.int64(32)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(56) * T.int64(8) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(56) // T.int64(14) * T.int64(7) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(14) * T.int64(2) + ax3_ax4_fused // T.int64(16))
                            v_ax4 = T.axis.spatial(T.int64(16), ax3_ax4_fused % T.int64(16))
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[4, 2, 1, 4])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[4, 1, 7, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[14, 1, 1, 2])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 16, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[128, 4])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=32)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=10)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86 = sch.get_loops(block=b68)
l87 = sch.fuse(l71, l72, l73, l74, preserve_unit_iters=True)
sch.parallel(loop=l87)
l88 = sch.fuse(l86, preserve_unit_iters=True)
sch.vectorize(loop=l88)
l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107, l108, l109, l110, l111 = sch.get_loops(block=b69)
l112 = sch.fuse(l89, preserve_unit_iters=True)
sch.parallel(loop=l112)
sch.annotate(block_or_loop=l112, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l112, ann_key="pragma_unroll_explicit", ann_val=1)
l113, l114, l115, l116, l117, l118, l119 = sch.get_loops(block=b70)
l120 = sch.fuse(l118, l119, preserve_unit_iters=True)
sch.vectorize(loop=l120)
b121 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141, l142, l143, l144 = sch.get_loops(block=b121)
b145 = sch.decompose_reduction(block=b121, loop=l129)
2024-04-30 11:55:27 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1847: GFLOPs: 493.8015. Time: 7493.2522 us. Best GFLOPs: 977.5728
2024-04-30 11:55:27 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1848: GFLOPs: 489.8575. Time: 7553.5819 us. Best GFLOPs: 977.5728
2024-04-30 11:55:27 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1849: GFLOPs: 671.7839. Time: 5507.9903 us. Best GFLOPs: 977.5728
2024-04-30 11:55:27 [INFO] [task_scheduler.cc:121] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1850: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(512)), "float32"), p1: T.Buffer((T.int64(32), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_fused_fused in T.parallel(T.int64(224), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(16), T.int64(512)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(28) // T.int64(2) * T.int64(2) + ax2)
                    v_i3 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(2) * T.int64(14) + ax3)
                    v_i4 = T.axis.spatial(T.int64(512), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oc_block_0 in range(T.int64(1)):
                for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                    for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(14), T.int64(16), T.int64(1), T.int64(4), T.int64(2), T.int64(1), T.int64(1)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(28) * T.int64(4) + oc_chunk_1 * T.int64(4) + oc_chunk_2_init * T.int64(4) + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(28) // T.int64(2) * T.int64(2) + oh_1 * T.int64(2) + oh_2_init * T.int64(2) + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(2) * T.int64(14) + ow_1 * T.int64(14) + ow_2_init + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2_init + oc_block_3_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                    for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(128), T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(14), T.int64(16), T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(2), T.int64(1), T.int64(1)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(28) * T.int64(4) + oc_chunk_1 * T.int64(4) + oc_chunk_2 * T.int64(4) + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(28) // T.int64(2) * T.int64(2) + oh_1 * T.int64(2) + oh_2 * T.int64(2) + oh_3)
                            v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(2) * T.int64(14) + ow_1 * T.int64(14) + ow_2 + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2 + oc_block_3)
                            v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(4) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(4), T.int64(2), T.int64(14)):
                    for ax4_fused in T.vectorized(T.int64(16)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(28) * T.int64(4) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(28) // T.int64(2) * T.int64(2) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(2) * T.int64(14) + ax3)
                            v_ax4 = T.axis.spatial(T.int64(16), ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[8, 1, 1, 4])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[14, 1, 1, 2])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[2, 1, 14, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 16, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[128, 4])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=3)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79 = sch.get_loops(block=b68)
l80 = sch.fuse(l71, l72, l73, l74, preserve_unit_iters=True)
sch.parallel(loop=l80)
l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l81, preserve_unit_iters=True)
sch.parallel(loop=l104)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109, l110, l111 = sch.get_loops(block=b70)
l112 = sch.fuse(l111, preserve_unit_iters=True)
sch.vectorize(loop=l112)
b113 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136 = sch.get_loops(block=b113)
b137 = sch.decompose_reduction(block=b113, loop=l121)
2024-04-30 11:55:27 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1851: GFLOPs: 486.5480. Time: 7604.9613 us. Best GFLOPs: 977.5728
2024-04-30 11:55:27 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1852: GFLOPs: 644.2161. Time: 5743.6925 us. Best GFLOPs: 977.5728
2024-04-30 11:55:27 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1853: GFLOPs: 568.5799. Time: 6507.7554 us. Best GFLOPs: 977.5728
2024-04-30 11:55:27 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1854: GFLOPs: 156.3898. Time: 23659.9704 us. Best GFLOPs: 977.5728
2024-04-30 11:55:27 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1855: GFLOPs: 32.9220. Time: 112392.4270 us. Best GFLOPs: 977.5728
2024-04-30 11:55:27 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1856: GFLOPs: 95.5473. Time: 38726.1317 us. Best GFLOPs: 977.5728
2024-04-30 11:58:29 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-30 11:58:31 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-30 11:58:35 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 11:58:35 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-30 11:58:48 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 11:59:03 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 11:59:17 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 11:59:31 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 11:59:39 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.8562  0.8539  0.8427  0.8419  0.8308  0.8291  0.8246  0.8178  0.8160  0.8055  0.7930  0.7901  0.7881  0.7873  0.7614  0.7588
[17 : 32]:	0.7557  0.7548  0.7548  0.7454  0.7147  0.7126  0.7122  0.7079  0.6994  0.6984  0.6965  0.6960  0.6943  0.6880  0.6863  0.6859
[33 : 48]:	0.6828  0.6828  0.6780  0.6775  0.6775  0.6707  0.6609  0.6570  0.6570  0.6565  0.6518  0.6511  0.6494  0.6421  0.6361  0.6318
[49 : 64]:	0.6168  0.6140  0.6107  0.6096  0.6084  0.6075  0.6051  0.5993  0.5990  0.5988  0.5988  0.5985  0.5905  0.5813  0.5795  0.5753
2024-04-30 11:59:40 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-30 11:59:40 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-30 12:01:47 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1857: GFLOPs: 461.3141. Time: 8020.9532 us. Best GFLOPs: 977.5728
2024-04-30 12:01:47 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1858: GFLOPs: 749.4769. Time: 4937.0152 us. Best GFLOPs: 977.5728
2024-04-30 12:01:47 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1859: GFLOPs: 849.8401. Time: 4353.9708 us. Best GFLOPs: 977.5728
2024-04-30 12:01:47 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1860: GFLOPs: 831.2011. Time: 4451.6051 us. Best GFLOPs: 977.5728
2024-04-30 12:01:47 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1861: GFLOPs: 784.2662. Time: 4718.0142 us. Best GFLOPs: 977.5728
2024-04-30 12:01:47 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1862: GFLOPs: 839.5658. Time: 4407.2530 us. Best GFLOPs: 977.5728
2024-04-30 12:01:47 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1863: GFLOPs: 92.3671. Time: 40059.4880 us. Best GFLOPs: 977.5728
2024-04-30 12:01:47 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1864: GFLOPs: 830.4257. Time: 4455.7616 us. Best GFLOPs: 977.5728
2024-04-30 12:01:47 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1865: GFLOPs: 850.8898. Time: 4348.5997 us. Best GFLOPs: 977.5728
2024-04-30 12:01:47 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1866: GFLOPs: 109.2105. Time: 33881.1517 us. Best GFLOPs: 977.5728
2024-04-30 12:01:47 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1867: GFLOPs: 785.0652. Time: 4713.2123 us. Best GFLOPs: 977.5728
2024-04-30 12:01:47 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1868: GFLOPs: 883.9931. Time: 4185.7556 us. Best GFLOPs: 977.5728
2024-04-30 12:01:47 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1869: GFLOPs: 927.2387. Time: 3990.5354 us. Best GFLOPs: 977.5728
2024-04-30 12:01:47 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1870: GFLOPs: 750.6208. Time: 4929.4918 us. Best GFLOPs: 977.5728
2024-04-30 12:01:47 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1871: GFLOPs: 129.4264. Time: 28589.0560 us. Best GFLOPs: 977.5728
2024-04-30 12:01:47 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1872: GFLOPs: 823.2977. Time: 4494.3389 us. Best GFLOPs: 977.5728
2024-04-30 12:01:47 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1873: GFLOPs: 774.6337. Time: 4776.6820 us. Best GFLOPs: 977.5728
2024-04-30 12:01:47 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1874: GFLOPs: 801.6834. Time: 4615.5115 us. Best GFLOPs: 977.5728
2024-04-30 12:01:47 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1875: GFLOPs: 696.2779. Time: 5314.2270 us. Best GFLOPs: 977.5728
2024-04-30 12:01:47 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1876: GFLOPs: 599.8395. Time: 6168.6147 us. Best GFLOPs: 977.5728
2024-04-30 12:01:47 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1877: GFLOPs: 777.8709. Time: 4756.8035 us. Best GFLOPs: 977.5728
2024-04-30 12:01:47 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1878: GFLOPs: 711.2657. Time: 5202.2458 us. Best GFLOPs: 977.5728
2024-04-30 12:01:47 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1879: GFLOPs: 770.3716. Time: 4803.1091 us. Best GFLOPs: 977.5728
2024-04-30 12:01:47 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1880: GFLOPs: 670.4585. Time: 5518.8784 us. Best GFLOPs: 977.5728
2024-04-30 12:01:47 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1881: GFLOPs: 686.2429. Time: 5391.9373 us. Best GFLOPs: 977.5728
2024-04-30 12:01:47 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1882: GFLOPs: 765.5022. Time: 4833.6621 us. Best GFLOPs: 977.5728
2024-04-30 12:01:47 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1883: GFLOPs: 740.8677. Time: 4994.3852 us. Best GFLOPs: 977.5728
2024-04-30 12:01:47 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1884: GFLOPs: 650.3804. Time: 5689.2538 us. Best GFLOPs: 977.5728
2024-04-30 12:01:47 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1885: GFLOPs: 610.6883. Time: 6059.0299 us. Best GFLOPs: 977.5728
2024-04-30 12:01:47 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1886: GFLOPs: 811.1294. Time: 4561.7615 us. Best GFLOPs: 977.5728
2024-04-30 12:01:47 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1887: GFLOPs: 604.0388. Time: 6125.7304 us. Best GFLOPs: 977.5728
2024-04-30 12:01:47 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1888: GFLOPs: 667.9296. Time: 5539.7735 us. Best GFLOPs: 977.5728
2024-04-30 12:01:47 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1889: GFLOPs: 382.3276. Time: 9678.0327 us. Best GFLOPs: 977.5728
2024-04-30 12:01:47 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1890: GFLOPs: 676.2989. Time: 5471.2187 us. Best GFLOPs: 977.5728
2024-04-30 12:01:47 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1891: GFLOPs: 760.9052. Time: 4862.8644 us. Best GFLOPs: 977.5728
2024-04-30 12:01:47 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1892: GFLOPs: 775.1192. Time: 4773.6901 us. Best GFLOPs: 977.5728
2024-04-30 12:01:47 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1893: GFLOPs: 771.9136. Time: 4793.5141 us. Best GFLOPs: 977.5728
2024-04-30 12:01:47 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1894: GFLOPs: 648.7649. Time: 5703.4201 us. Best GFLOPs: 977.5728
2024-04-30 12:01:47 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1895: GFLOPs: 673.9109. Time: 5490.6058 us. Best GFLOPs: 977.5728
2024-04-30 12:01:47 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1896: GFLOPs: 635.5391. Time: 5822.1111 us. Best GFLOPs: 977.5728
2024-04-30 12:01:47 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1897: GFLOPs: 625.2654. Time: 5917.7733 us. Best GFLOPs: 977.5728
2024-04-30 12:01:47 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1898: GFLOPs: 385.0214. Time: 9610.3195 us. Best GFLOPs: 977.5728
2024-04-30 12:01:47 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1899: GFLOPs: 348.4637. Time: 10618.5503 us. Best GFLOPs: 977.5728
2024-04-30 12:01:47 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1900: GFLOPs: 657.7986. Time: 5625.0938 us. Best GFLOPs: 977.5728
2024-04-30 12:01:47 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1901: GFLOPs: 658.5432. Time: 5618.7337 us. Best GFLOPs: 977.5728
2024-04-30 12:01:47 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1902: GFLOPs: 529.6728. Time: 6985.7826 us. Best GFLOPs: 977.5728
2024-04-30 12:01:47 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1903: GFLOPs: 603.8693. Time: 6127.4505 us. Best GFLOPs: 977.5728
2024-04-30 12:01:47 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1904: GFLOPs: 663.8596. Time: 5573.7373 us. Best GFLOPs: 977.5728
2024-04-30 12:01:47 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1905: GFLOPs: 626.9496. Time: 5901.8765 us. Best GFLOPs: 977.5728
2024-04-30 12:01:47 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1906: GFLOPs: 636.9744. Time: 5808.9914 us. Best GFLOPs: 977.5728
2024-04-30 12:01:47 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1907: GFLOPs: 452.5104. Time: 8177.0035 us. Best GFLOPs: 977.5728
2024-04-30 12:01:47 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1908: GFLOPs: 606.6970. Time: 6098.8912 us. Best GFLOPs: 977.5728
2024-04-30 12:01:47 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1909: GFLOPs: 615.6898. Time: 6009.8108 us. Best GFLOPs: 977.5728
2024-04-30 12:01:47 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1910: GFLOPs: 528.2699. Time: 7004.3343 us. Best GFLOPs: 977.5728
2024-04-30 12:01:47 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1911: GFLOPs: 41.8319. Time: 88453.5637 us. Best GFLOPs: 977.5728
2024-04-30 12:01:47 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1912: GFLOPs: 78.7877. Time: 46963.9440 us. Best GFLOPs: 977.5728
2024-04-30 12:01:47 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1913: GFLOPs: 578.2290. Time: 6399.1586 us. Best GFLOPs: 977.5728
2024-04-30 12:01:47 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1914: GFLOPs: 742.1657. Time: 4985.6508 us. Best GFLOPs: 977.5728
2024-04-30 12:01:47 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1915: GFLOPs: 716.4995. Time: 5164.2451 us. Best GFLOPs: 977.5728
2024-04-30 12:01:47 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1916: GFLOPs: 466.5344. Time: 7931.2028 us. Best GFLOPs: 977.5728
2024-04-30 12:01:47 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1917: GFLOPs: 541.5291. Time: 6832.8346 us. Best GFLOPs: 977.5728
2024-04-30 12:01:47 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1918: GFLOPs: 12.6189. Time: 293225.3650 us. Best GFLOPs: 977.5728
2024-04-30 12:01:47 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1919: GFLOPs: 62.1678. Time: 59519.2003 us. Best GFLOPs: 977.5728
2024-04-30 12:01:47 [INFO] [task_scheduler.cc:121] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1920: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(512)), "float32"), p1: T.Buffer((T.int64(32), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused in T.parallel(T.int64(4), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(30), T.int64(16), T.int64(512)):
                with T.block("data_pad"):
                    v_i0, v_i1, v_i2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                    v_i3 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(2) * T.int64(14) + ax3)
                    v_i4 = T.axis.spatial(T.int64(512), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(2), T.int64(7), T.int64(2), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(2), T.int64(4), T.int64(7), T.int64(2), T.int64(1), T.int64(8), T.int64(1), T.int64(1)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(32), oc_chunk_1 * T.int64(16) + oc_chunk_2_init * T.int64(8) + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(28), oh_1 * T.int64(4) + oh_2_init + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(2) * T.int64(14) + ow_1 * T.int64(7) + ow_2_init + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(2) * T.int64(8) + oc_block_1 * T.int64(8) + oc_block_2_init * T.int64(4) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(256), T.int64(3), T.int64(1), T.int64(1), T.int64(2), T.int64(4), T.int64(7), T.int64(2), T.int64(2), T.int64(1), T.int64(3), T.int64(1), T.int64(8), T.int64(1), T.int64(1)):
                    for oc_block_3_fused in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(32), oc_chunk_1 * T.int64(16) + oc_chunk_2 * T.int64(8) + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(28), oh_1 * T.int64(4) + oh_2 + oh_3)
                            v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(2) * T.int64(14) + ow_1 * T.int64(7) + ow_2 + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(2) * T.int64(8) + oc_block_1 * T.int64(8) + oc_block_2 * T.int64(4) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(2) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(16), T.int64(4), T.int64(7)):
                    for ax4_fused in T.vectorized(T.int64(8)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(32), oc_chunk_1 * T.int64(16) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(28), oh_1 * T.int64(4) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(2) * T.int64(14) + ow_1 * T.int64(7) + ax3)
                            v_ax4 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(2) * T.int64(8) + ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 2, 2, 8])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 7, 4, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[2, 2, 7, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[2, 1, 2, 4])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[256, 2])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=4)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80 = sch.get_loops(block=b68)
l81 = sch.fuse(l71, l72, l73, l74, l75, preserve_unit_iters=True)
sch.parallel(loop=l81)
l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l82, preserve_unit_iters=True)
sch.parallel(loop=l104)
l105 = sch.fuse(l103, preserve_unit_iters=True)
sch.vectorize(loop=l105)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l106, l107, l108, l109, l110, l111, l112, l113, l114, l115, l116 = sch.get_loops(block=b70)
l117 = sch.fuse(l116, preserve_unit_iters=True)
sch.vectorize(loop=l117)
b118 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140 = sch.get_loops(block=b118)
b141 = sch.decompose_reduction(block=b118, loop=l125)
2024-04-30 12:05:05 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-30 12:05:07 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-30 12:05:11 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 12:05:11 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-30 12:05:24 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 12:05:38 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 12:05:52 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 12:06:06 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 12:06:14 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.8556  0.8555  0.8408  0.8255  0.8123  0.7994  0.7989  0.7986  0.7944  0.7912  0.7839  0.7625  0.7580  0.7578  0.7578  0.7578
[17 : 32]:	0.7578  0.7566  0.7519  0.7455  0.7383  0.7315  0.7311  0.7295  0.7182  0.7181  0.7172  0.7131  0.7106  0.7074  0.7030  0.6993
[33 : 48]:	0.6945  0.6929  0.6909  0.6905  0.6854  0.6844  0.6824  0.6771  0.6748  0.6711  0.6681  0.6659  0.6635  0.6611  0.6608  0.6603
[49 : 64]:	0.6603  0.6583  0.6549  0.6545  0.6422  0.6362  0.6362  0.6356  0.6311  0.6287  0.6265  0.6209  0.6207  0.6186  0.6176  0.6170
2024-04-30 12:06:15 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-30 12:06:15 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-30 12:08:37 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1921: GFLOPs: 801.7778. Time: 4614.9682 us. Best GFLOPs: 977.5728
2024-04-30 12:08:37 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1922: GFLOPs: 987.5055. Time: 3746.9957 us. Best GFLOPs: 987.5055
2024-04-30 12:08:37 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1923: GFLOPs: 826.7798. Time: 4475.4106 us. Best GFLOPs: 987.5055
2024-04-30 12:08:37 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1924: GFLOPs: 836.1239. Time: 4425.3954 us. Best GFLOPs: 987.5055
2024-04-30 12:08:37 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1925: GFLOPs: 814.7355. Time: 4541.5708 us. Best GFLOPs: 987.5055
2024-04-30 12:08:37 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1926: GFLOPs: 813.3848. Time: 4549.1126 us. Best GFLOPs: 987.5055
2024-04-30 12:08:37 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1927: GFLOPs: 400.4558. Time: 9239.9193 us. Best GFLOPs: 987.5055
2024-04-30 12:08:37 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1928: GFLOPs: 833.5992. Time: 4438.7983 us. Best GFLOPs: 987.5055
2024-04-30 12:08:37 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1929: GFLOPs: 517.8582. Time: 7145.1579 us. Best GFLOPs: 987.5055
2024-04-30 12:08:37 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1930: GFLOPs: 639.3896. Time: 5787.0487 us. Best GFLOPs: 987.5055
2024-04-30 12:08:37 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1931: GFLOPs: 773.9260. Time: 4781.0501 us. Best GFLOPs: 987.5055
2024-04-30 12:08:37 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1932: GFLOPs: 688.8856. Time: 5371.2531 us. Best GFLOPs: 987.5055
2024-04-30 12:08:37 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1933: GFLOPs: 856.6863. Time: 4319.1760 us. Best GFLOPs: 987.5055
2024-04-30 12:08:37 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1934: GFLOPs: 111.0927. Time: 33307.1250 us. Best GFLOPs: 987.5055
2024-04-30 12:08:37 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1935: GFLOPs: 98.2115. Time: 37675.6017 us. Best GFLOPs: 987.5055
2024-04-30 12:08:37 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1936: GFLOPs: 127.7183. Time: 28971.4178 us. Best GFLOPs: 987.5055
2024-04-30 12:08:37 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1937: GFLOPs: 486.7239. Time: 7602.2135 us. Best GFLOPs: 987.5055
2024-04-30 12:08:37 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1938: GFLOPs: 725.5005. Time: 5100.1744 us. Best GFLOPs: 987.5055
2024-04-30 12:08:37 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1939: GFLOPs: 721.1033. Time: 5131.2746 us. Best GFLOPs: 987.5055
2024-04-30 12:08:37 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1940: GFLOPs: 692.7246. Time: 5341.4863 us. Best GFLOPs: 987.5055
2024-04-30 12:08:37 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1941: GFLOPs: 660.1608. Time: 5604.9661 us. Best GFLOPs: 987.5055
2024-04-30 12:08:37 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1942: GFLOPs: 820.7233. Time: 4508.4363 us. Best GFLOPs: 987.5055
2024-04-30 12:08:37 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1943: GFLOPs: 696.2092. Time: 5314.7517 us. Best GFLOPs: 987.5055
2024-04-30 12:08:37 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1944: GFLOPs: 78.8983. Time: 46898.0530 us. Best GFLOPs: 987.5055
2024-04-30 12:08:37 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1945: GFLOPs: 88.2198. Time: 41942.7103 us. Best GFLOPs: 987.5055
2024-04-30 12:08:37 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1946: GFLOPs: 659.4899. Time: 5610.6680 us. Best GFLOPs: 987.5055
2024-04-30 12:08:37 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1947: GFLOPs: 738.8590. Time: 5007.9634 us. Best GFLOPs: 987.5055
2024-04-30 12:08:37 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1948: GFLOPs: 691.1495. Time: 5353.6591 us. Best GFLOPs: 987.5055
2024-04-30 12:08:37 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1949: GFLOPs: 796.2063. Time: 4647.2615 us. Best GFLOPs: 987.5055
2024-04-30 12:08:37 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1950: GFLOPs: 627.1870. Time: 5899.6418 us. Best GFLOPs: 987.5055
2024-04-30 12:08:37 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1951: GFLOPs: 652.6898. Time: 5669.1233 us. Best GFLOPs: 987.5055
2024-04-30 12:08:37 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1952: GFLOPs: 670.3742. Time: 5519.5723 us. Best GFLOPs: 987.5055
2024-04-30 12:08:37 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1953: GFLOPs: 60.2810. Time: 61382.1890 us. Best GFLOPs: 987.5055
2024-04-30 12:08:37 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1954: GFLOPs: 681.0676. Time: 5432.9099 us. Best GFLOPs: 987.5055
2024-04-30 12:08:37 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1955: GFLOPs: 561.1857. Time: 6593.5021 us. Best GFLOPs: 987.5055
2024-04-30 12:08:37 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1956: GFLOPs: 724.9169. Time: 5104.2800 us. Best GFLOPs: 987.5055
2024-04-30 12:08:37 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1957: GFLOPs: 543.6779. Time: 6805.8298 us. Best GFLOPs: 987.5055
2024-04-30 12:08:37 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1958: GFLOPs: 713.7903. Time: 5183.8458 us. Best GFLOPs: 987.5055
2024-04-30 12:08:37 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1959: GFLOPs: 126.8718. Time: 29164.7132 us. Best GFLOPs: 987.5055
2024-04-30 12:08:37 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1960: GFLOPs: 134.0424. Time: 27604.5390 us. Best GFLOPs: 987.5055
2024-04-30 12:08:37 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1961: GFLOPs: 197.2676. Time: 18757.1587 us. Best GFLOPs: 987.5055
2024-04-30 12:08:37 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1962: GFLOPs: 755.6846. Time: 4896.4593 us. Best GFLOPs: 987.5055
2024-04-30 12:08:37 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1963: GFLOPs: 132.0049. Time: 28030.6288 us. Best GFLOPs: 987.5055
2024-04-30 12:08:37 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1964: GFLOPs: 653.5283. Time: 5661.8499 us. Best GFLOPs: 987.5055
2024-04-30 12:08:37 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1965: GFLOPs: 660.6502. Time: 5600.8139 us. Best GFLOPs: 987.5055
2024-04-30 12:08:37 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1966: GFLOPs: 675.9909. Time: 5473.7113 us. Best GFLOPs: 987.5055
2024-04-30 12:08:37 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1967: GFLOPs: 699.8931. Time: 5286.7775 us. Best GFLOPs: 987.5055
2024-04-30 12:08:37 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1968: GFLOPs: 783.3624. Time: 4723.4574 us. Best GFLOPs: 987.5055
2024-04-30 12:08:37 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1969: GFLOPs: 343.8948. Time: 10759.6237 us. Best GFLOPs: 987.5055
2024-04-30 12:08:37 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1970: GFLOPs: 604.6469. Time: 6119.5697 us. Best GFLOPs: 987.5055
2024-04-30 12:08:37 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1971: GFLOPs: 631.4506. Time: 5859.8078 us. Best GFLOPs: 987.5055
2024-04-30 12:08:37 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1972: GFLOPs: 778.7223. Time: 4751.6024 us. Best GFLOPs: 987.5055
2024-04-30 12:08:37 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1973: GFLOPs: 674.1557. Time: 5488.6115 us. Best GFLOPs: 987.5055
2024-04-30 12:08:37 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1974: GFLOPs: 937.1300. Time: 3948.4158 us. Best GFLOPs: 987.5055
2024-04-30 12:08:37 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1975: GFLOPs: 677.0731. Time: 5464.9622 us. Best GFLOPs: 987.5055
2024-04-30 12:08:37 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1976: GFLOPs: 478.8837. Time: 7726.6762 us. Best GFLOPs: 987.5055
2024-04-30 12:08:37 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1977: GFLOPs: 621.8961. Time: 5949.8350 us. Best GFLOPs: 987.5055
2024-04-30 12:08:37 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1978: GFLOPs: 577.9172. Time: 6402.6111 us. Best GFLOPs: 987.5055
2024-04-30 12:08:37 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1979: GFLOPs: 609.3074. Time: 6072.7618 us. Best GFLOPs: 987.5055
2024-04-30 12:08:37 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1980: GFLOPs: 552.3126. Time: 6699.4289 us. Best GFLOPs: 987.5055
2024-04-30 12:08:37 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1981: GFLOPs: 465.5239. Time: 7948.4195 us. Best GFLOPs: 987.5055
2024-04-30 12:08:37 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1982: GFLOPs: 3.6915. Time: 1002351.4247 us. Best GFLOPs: 987.5055
2024-04-30 12:08:37 [INFO] [task_scheduler.cc:121] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1983: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(512)), "float32"), p1: T.Buffer((T.int64(32), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_fused in T.parallel(T.int64(1568), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for oc_block_0 in range(T.int64(1)):
                for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(1)):
                    for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(8), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                        for oc_block_3_fused_init in T.vectorized(T.int64(2)):
                            with T.block("conv2d_NCHWc_init"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                                v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_fused // T.int64(392) * T.int64(8) + oc_chunk_1 + oc_chunk_2_init + oc_chunk_3_init)
                                v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused % T.int64(392) // T.int64(14) + oh_1 + oh_2_init + oh_3_init)
                                v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused % T.int64(14) * T.int64(2) + ow_1 * T.int64(2) + ow_2_init + ow_3_init)
                                v_oc_block = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2_init * T.int64(2) + oc_block_3_fused_init)
                                T.reads()
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                    for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(64), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(8), T.int64(8), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                        for oc_block_3_fused in T.vectorized(T.int64(2)):
                            with T.block("conv2d_NCHWc_update"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                                v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_fused // T.int64(392) * T.int64(8) + oc_chunk_1 + oc_chunk_2 + oc_chunk_3)
                                v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused % T.int64(392) // T.int64(14) + oh_1 + oh_2 + oh_3)
                                v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused % T.int64(14) * T.int64(2) + ow_1 * T.int64(2) + ow_2 + ow_3)
                                v_oc_block = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2 * T.int64(2) + oc_block_3_fused)
                                v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(8) + ic_1)
                                v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                                v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                                T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], p0[v_n, v_ic // T.int64(512), v_oh + v_kh - T.int64(1), v_ow + v_kw - T.int64(1), v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + T.if_then_else(T.int64(1) <= v_oh + v_kh and v_oh + v_kh < T.int64(29) and T.int64(1) <= v_ow + v_kw and v_ow + v_kw < T.int64(29), p0[v_n, v_ic // T.int64(512), v_oh + v_kh - T.int64(1), v_ow + v_kw - T.int64(1), v_ic % T.int64(512)], T.float32(0)) * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
                for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(8), T.int64(1)):
                    for ax3_ax4_fused in T.vectorized(T.int64(32)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_fused // T.int64(392) * T.int64(8) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused % T.int64(392) // T.int64(14) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused % T.int64(14) * T.int64(2) + ax3_ax4_fused // T.int64(16))
                            v_ax4 = T.axis.spatial(T.int64(16), ax3_ax4_fused % T.int64(16))
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[4, 8, 1, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[28, 1, 1, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[14, 1, 2, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 8, 2])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[64, 8])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=-2)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69 = sch.get_child_blocks(b67)
l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95 = sch.get_loops(block=b68)
l96 = sch.fuse(l70, l71, l72, l73, preserve_unit_iters=True)
sch.parallel(loop=l96)
l97 = sch.fuse(l95, preserve_unit_iters=True)
sch.vectorize(loop=l97)
sch.annotate(block_or_loop=l96, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l96, ann_key="pragma_unroll_explicit", ann_val=1)
l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b69)
l105 = sch.fuse(l103, l104, preserve_unit_iters=True)
sch.vectorize(loop=l105)
b106 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129 = sch.get_loops(block=b106)
b130 = sch.decompose_reduction(block=b106, loop=l114)
2024-04-30 12:08:37 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1984: GFLOPs: 3.4372. Time: 1076524.5747 us. Best GFLOPs: 987.5055
2024-04-30 12:15:19 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-30 12:15:21 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-30 12:15:25 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 12:15:25 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-30 12:15:38 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 12:15:52 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 12:16:07 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 12:16:21 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 12:16:30 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.8436  0.8404  0.8319  0.8275  0.8119  0.8001  0.7765  0.7707  0.7508  0.7508  0.7508  0.7483  0.7325  0.7205  0.7176  0.7151
[17 : 32]:	0.7038  0.6976  0.6776  0.6714  0.6699  0.6687  0.6623  0.6615  0.6584  0.6560  0.6537  0.6430  0.6413  0.6382  0.6321  0.6313
[33 : 48]:	0.6265  0.6262  0.6202  0.6119  0.6086  0.5999  0.5954  0.5954  0.5920  0.5909  0.5894  0.5889  0.5889  0.5880  0.5838  0.5765
[49 : 64]:	0.5759  0.5748  0.5735  0.5629  0.5565  0.5526  0.5525  0.5512  0.5391  0.5371  0.5371  0.5366  0.5366  0.5353  0.5328  0.5328
2024-04-30 12:16:31 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-30 12:16:31 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-30 12:18:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1985: GFLOPs: 839.8829. Time: 4405.5891 us. Best GFLOPs: 987.5055
2024-04-30 12:18:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1986: GFLOPs: 97.0277. Time: 38135.2683 us. Best GFLOPs: 987.5055
2024-04-30 12:18:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1987: GFLOPs: 792.3965. Time: 4669.6056 us. Best GFLOPs: 987.5055
2024-04-30 12:18:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1988: GFLOPs: 830.0589. Time: 4457.7304 us. Best GFLOPs: 987.5055
2024-04-30 12:18:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1989: GFLOPs: 778.0986. Time: 4755.4112 us. Best GFLOPs: 987.5055
2024-04-30 12:18:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1990: GFLOPs: 768.1193. Time: 4817.1931 us. Best GFLOPs: 987.5055
2024-04-30 12:18:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1991: GFLOPs: 96.0412. Time: 38526.9780 us. Best GFLOPs: 987.5055
2024-04-30 12:18:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1992: GFLOPs: 805.9555. Time: 4591.0461 us. Best GFLOPs: 987.5055
2024-04-30 12:18:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1993: GFLOPs: 363.7728. Time: 10171.6766 us. Best GFLOPs: 987.5055
2024-04-30 12:18:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1994: GFLOPs: 802.6810. Time: 4609.7755 us. Best GFLOPs: 987.5055
2024-04-30 12:18:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1995: GFLOPs: 730.7035. Time: 5063.8584 us. Best GFLOPs: 987.5055
2024-04-30 12:18:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1996: GFLOPs: 843.7542. Time: 4385.3757 us. Best GFLOPs: 987.5055
2024-04-30 12:18:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1997: GFLOPs: 735.6817. Time: 5029.5923 us. Best GFLOPs: 987.5055
2024-04-30 12:18:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1998: GFLOPs: 730.1750. Time: 5067.5234 us. Best GFLOPs: 987.5055
2024-04-30 12:18:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1999: GFLOPs: 737.7163. Time: 5015.7209 us. Best GFLOPs: 987.5055
2024-04-30 12:18:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2000: GFLOPs: 654.5032. Time: 5653.4163 us. Best GFLOPs: 987.5055
2024-04-30 12:18:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2001: GFLOPs: 691.4041. Time: 5351.6879 us. Best GFLOPs: 987.5055
2024-04-30 12:18:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2002: GFLOPs: 679.0785. Time: 5448.8235 us. Best GFLOPs: 987.5055
2024-04-30 12:18:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2003: GFLOPs: 759.1640. Time: 4874.0179 us. Best GFLOPs: 987.5055
2024-04-30 12:18:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2004: GFLOPs: 722.0015. Time: 5124.8909 us. Best GFLOPs: 987.5055
2024-04-30 12:18:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2005: GFLOPs: 706.8114. Time: 5235.0298 us. Best GFLOPs: 987.5055
2024-04-30 12:18:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2006: GFLOPs: 774.4787. Time: 4777.6382 us. Best GFLOPs: 987.5055
2024-04-30 12:18:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2007: GFLOPs: 594.2629. Time: 6226.5018 us. Best GFLOPs: 987.5055
2024-04-30 12:18:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2008: GFLOPs: 699.5909. Time: 5289.0608 us. Best GFLOPs: 987.5055
2024-04-30 12:18:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2009: GFLOPs: 630.4414. Time: 5869.1876 us. Best GFLOPs: 987.5055
2024-04-30 12:18:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2010: GFLOPs: 659.6959. Time: 5608.9157 us. Best GFLOPs: 987.5055
2024-04-30 12:18:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2011: GFLOPs: 497.3780. Time: 7439.3696 us. Best GFLOPs: 987.5055
2024-04-30 12:18:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2012: GFLOPs: 643.5957. Time: 5749.2292 us. Best GFLOPs: 987.5055
2024-04-30 12:18:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2013: GFLOPs: 807.5052. Time: 4582.2354 us. Best GFLOPs: 987.5055
2024-04-30 12:18:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2014: GFLOPs: 716.0766. Time: 5167.2947 us. Best GFLOPs: 987.5055
2024-04-30 12:18:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2015: GFLOPs: 294.3599. Time: 12570.2532 us. Best GFLOPs: 987.5055
2024-04-30 12:18:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2016: GFLOPs: 706.7561. Time: 5235.4394 us. Best GFLOPs: 987.5055
2024-04-30 12:18:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2017: GFLOPs: 605.3943. Time: 6112.0144 us. Best GFLOPs: 987.5055
2024-04-30 12:18:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2018: GFLOPs: 615.0048. Time: 6016.5044 us. Best GFLOPs: 987.5055
2024-04-30 12:18:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2019: GFLOPs: 684.3671. Time: 5406.7169 us. Best GFLOPs: 987.5055
2024-04-30 12:18:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2020: GFLOPs: 590.2235. Time: 6269.1144 us. Best GFLOPs: 987.5055
2024-04-30 12:18:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2021: GFLOPs: 677.2197. Time: 5463.7790 us. Best GFLOPs: 987.5055
2024-04-30 12:18:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2022: GFLOPs: 595.9628. Time: 6208.7419 us. Best GFLOPs: 987.5055
2024-04-30 12:18:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2023: GFLOPs: 769.2258. Time: 4810.2635 us. Best GFLOPs: 987.5055
2024-04-30 12:18:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2024: GFLOPs: 769.8663. Time: 4806.2615 us. Best GFLOPs: 987.5055
2024-04-30 12:18:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2025: GFLOPs: 552.5580. Time: 6696.4535 us. Best GFLOPs: 987.5055
2024-04-30 12:18:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2026: GFLOPs: 599.0843. Time: 6176.3907 us. Best GFLOPs: 987.5055
2024-04-30 12:18:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2027: GFLOPs: 675.4172. Time: 5478.3608 us. Best GFLOPs: 987.5055
2024-04-30 12:18:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2028: GFLOPs: 105.4844. Time: 35077.9620 us. Best GFLOPs: 987.5055
2024-04-30 12:18:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2029: GFLOPs: 673.2090. Time: 5496.3301 us. Best GFLOPs: 987.5055
2024-04-30 12:18:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2030: GFLOPs: 490.5740. Time: 7542.5502 us. Best GFLOPs: 987.5055
2024-04-30 12:18:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2031: GFLOPs: 658.7406. Time: 5617.0502 us. Best GFLOPs: 987.5055
2024-04-30 12:18:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2032: GFLOPs: 277.4746. Time: 13335.1975 us. Best GFLOPs: 987.5055
2024-04-30 12:18:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2033: GFLOPs: 574.5202. Time: 6440.4680 us. Best GFLOPs: 987.5055
2024-04-30 12:18:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2034: GFLOPs: 570.8511. Time: 6481.8637 us. Best GFLOPs: 987.5055
2024-04-30 12:18:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2035: GFLOPs: 605.6686. Time: 6109.2466 us. Best GFLOPs: 987.5055
2024-04-30 12:18:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2036: GFLOPs: 533.3035. Time: 6938.2238 us. Best GFLOPs: 987.5055
2024-04-30 12:18:41 [INFO] [task_scheduler.cc:121] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2037: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(512)), "float32"), p1: T.Buffer((T.int64(32), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_fused_fused in T.parallel(T.int64(224), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(3), T.int64(30), T.int64(512)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_fused_fused % T.int64(28) + ax2)
                    v_i3, v_i4 = T.axis.remap("SS", [ax3, ax4])
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for ow_0, oc_block_0 in T.grid(T.int64(1), T.int64(1)):
                for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(16)):
                    for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(14), T.int64(1), T.int64(1), T.int64(4), T.int64(1), T.int64(2), T.int64(1)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_fused_fused // T.int64(28) * T.int64(4) + oc_chunk_1 * T.int64(4) + oc_chunk_2_init * T.int64(4) + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_fused_fused % T.int64(28) + oh_1 + oh_2_init + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(28), ow_0 * T.int64(28) + ow_1 * T.int64(28) + ow_2_init * T.int64(2) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(16) + oc_block_1 + oc_block_2_init + oc_block_3_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                    for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(64), T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(14), T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(1), T.int64(2), T.int64(1)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_fused_fused // T.int64(28) * T.int64(4) + oc_chunk_1 * T.int64(4) + oc_chunk_2 * T.int64(4) + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_fused_fused % T.int64(28) + oh_1 + oh_2 + oh_3)
                            v_ow = T.axis.spatial(T.int64(28), ow_0 * T.int64(28) + ow_1 * T.int64(28) + ow_2 * T.int64(2) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(16) + oc_block_1 + oc_block_2 + oc_block_3)
                            v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(8) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(4), T.int64(1), T.int64(28)):
                    for ax4_fused in T.vectorized(T.int64(16)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_fused_fused // T.int64(28) * T.int64(4) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_fused_fused % T.int64(28) + ax2)
                            v_ax3, v_ax4 = T.axis.remap("SS", [ax3, ax4_fused])
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[8, 1, 1, 4])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[28, 1, 1, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 14, 2])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 16, 1, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[64, 8])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=2)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78 = sch.get_loops(block=b68)
l79 = sch.fuse(l71, l72, l73, preserve_unit_iters=True)
sch.parallel(loop=l79)
l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l80, preserve_unit_iters=True)
sch.parallel(loop=l104)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109, l110, l111, l112 = sch.get_loops(block=b70)
l113 = sch.fuse(l112, preserve_unit_iters=True)
sch.vectorize(loop=l113)
b114 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138 = sch.get_loops(block=b114)
b139 = sch.decompose_reduction(block=b114, loop=l123)
2024-04-30 12:18:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2038: GFLOPs: 114.3957. Time: 32345.4358 us. Best GFLOPs: 987.5055
2024-04-30 12:18:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2039: GFLOPs: 549.0014. Time: 6739.8350 us. Best GFLOPs: 987.5055
2024-04-30 12:18:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2040: GFLOPs: 67.3542. Time: 54936.0917 us. Best GFLOPs: 987.5055
2024-04-30 12:18:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2041: GFLOPs: 493.0266. Time: 7505.0288 us. Best GFLOPs: 987.5055
2024-04-30 12:18:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2042: GFLOPs: 583.1687. Time: 6344.9545 us. Best GFLOPs: 987.5055
2024-04-30 12:18:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2043: GFLOPs: 462.8848. Time: 7993.7356 us. Best GFLOPs: 987.5055
2024-04-30 12:18:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2044: GFLOPs: 593.9888. Time: 6229.3746 us. Best GFLOPs: 987.5055
2024-04-30 12:18:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2045: GFLOPs: 592.8728. Time: 6241.1013 us. Best GFLOPs: 987.5055
2024-04-30 12:18:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2046: GFLOPs: 9.5604. Time: 387033.0327 us. Best GFLOPs: 987.5055
2024-04-30 12:18:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2047: GFLOPs: 88.6320. Time: 41747.6637 us. Best GFLOPs: 987.5055
2024-04-30 12:18:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2048: GFLOPs: 41.7087. Time: 88714.7977 us. Best GFLOPs: 987.5055
2024-04-30 12:18:41 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-30 12:18:42 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-30 12:18:46 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 12:18:46 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-30 12:18:59 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 12:19:13 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 12:19:27 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 12:19:42 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 12:19:50 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.8120  0.8069  0.7918  0.7691  0.7671  0.7395  0.7299  0.7171  0.7121  0.7121  0.7121  0.7112  0.7027  0.7020  0.7015  0.7006
[17 : 32]:	0.6923  0.6865  0.6840  0.6822  0.6821  0.6723  0.6681  0.6649  0.6636  0.6623  0.6612  0.6589  0.6489  0.6440  0.6402  0.6400
[33 : 48]:	0.6387  0.6354  0.6300  0.6281  0.6250  0.6208  0.6208  0.6171  0.6147  0.6117  0.6073  0.6007  0.5972  0.5909  0.5866  0.5837
[49 : 64]:	0.5818  0.5812  0.5809  0.5809  0.5796  0.5787  0.5674  0.5672  0.5651  0.5646  0.5646  0.5629  0.5625  0.5620  0.5601  0.5598
2024-04-30 12:19:51 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-30 12:19:51 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-30 12:21:37 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2049: GFLOPs: 475.8774. Time: 7775.4879 us. Best GFLOPs: 987.5055
2024-04-30 12:21:37 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2050: GFLOPs: 458.4724. Time: 8070.6684 us. Best GFLOPs: 987.5055
2024-04-30 12:21:37 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2051: GFLOPs: 831.3832. Time: 4450.6298 us. Best GFLOPs: 987.5055
2024-04-30 12:21:37 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2052: GFLOPs: 785.0452. Time: 4713.3322 us. Best GFLOPs: 987.5055
2024-04-30 12:21:37 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2053: GFLOPs: 693.7421. Time: 5333.6520 us. Best GFLOPs: 987.5055
2024-04-30 12:21:37 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2054: GFLOPs: 787.4515. Time: 4698.9292 us. Best GFLOPs: 987.5055
2024-04-30 12:21:37 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2055: GFLOPs: 695.1793. Time: 5322.6255 us. Best GFLOPs: 987.5055
2024-04-30 12:21:37 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2056: GFLOPs: 706.3259. Time: 5238.6283 us. Best GFLOPs: 987.5055
2024-04-30 12:21:37 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2057: GFLOPs: 761.0704. Time: 4861.8091 us. Best GFLOPs: 987.5055
2024-04-30 12:21:37 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2058: GFLOPs: 329.3033. Time: 11236.3850 us. Best GFLOPs: 987.5055
2024-04-30 12:21:37 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2059: GFLOPs: 457.8843. Time: 8081.0348 us. Best GFLOPs: 987.5055
2024-04-30 12:21:37 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2060: GFLOPs: 675.8957. Time: 5474.4823 us. Best GFLOPs: 987.5055
2024-04-30 12:21:37 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2061: GFLOPs: 682.2233. Time: 5423.7062 us. Best GFLOPs: 987.5055
2024-04-30 12:21:37 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2062: GFLOPs: 840.6534. Time: 4401.5511 us. Best GFLOPs: 987.5055
2024-04-30 12:21:37 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2063: GFLOPs: 767.7291. Time: 4819.6412 us. Best GFLOPs: 987.5055
2024-04-30 12:21:37 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2064: GFLOPs: 635.4236. Time: 5823.1687 us. Best GFLOPs: 987.5055
2024-04-30 12:21:37 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2065: GFLOPs: 623.6849. Time: 5932.7694 us. Best GFLOPs: 987.5055
2024-04-30 12:21:37 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2066: GFLOPs: 643.2585. Time: 5752.2425 us. Best GFLOPs: 987.5055
2024-04-30 12:21:37 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2067: GFLOPs: 674.9576. Time: 5482.0908 us. Best GFLOPs: 987.5055
2024-04-30 12:21:37 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2068: GFLOPs: 678.4185. Time: 5454.1246 us. Best GFLOPs: 987.5055
2024-04-30 12:21:37 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2069: GFLOPs: 861.2512. Time: 4296.2828 us. Best GFLOPs: 987.5055
2024-04-30 12:21:37 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2070: GFLOPs: 715.2753. Time: 5173.0837 us. Best GFLOPs: 987.5055
2024-04-30 12:21:37 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2071: GFLOPs: 759.2246. Time: 4873.6288 us. Best GFLOPs: 987.5055
2024-04-30 12:21:37 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2072: GFLOPs: 613.2014. Time: 6034.1988 us. Best GFLOPs: 987.5055
2024-04-30 12:21:37 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2073: GFLOPs: 812.3832. Time: 4554.7211 us. Best GFLOPs: 987.5055
2024-04-30 12:21:37 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2074: GFLOPs: 816.8778. Time: 4529.6603 us. Best GFLOPs: 987.5055
2024-04-30 12:21:37 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2075: GFLOPs: 821.2077. Time: 4505.7773 us. Best GFLOPs: 987.5055
2024-04-30 12:21:37 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2076: GFLOPs: 703.7382. Time: 5257.8912 us. Best GFLOPs: 987.5055
2024-04-30 12:21:37 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2077: GFLOPs: 642.0150. Time: 5763.3836 us. Best GFLOPs: 987.5055
2024-04-30 12:21:37 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2078: GFLOPs: 652.9706. Time: 5666.6850 us. Best GFLOPs: 987.5055
2024-04-30 12:21:37 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2079: GFLOPs: 705.1268. Time: 5247.5370 us. Best GFLOPs: 987.5055
2024-04-30 12:21:37 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2080: GFLOPs: 650.4198. Time: 5688.9087 us. Best GFLOPs: 987.5055
2024-04-30 12:21:37 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2081: GFLOPs: 600.9486. Time: 6157.2303 us. Best GFLOPs: 987.5055
2024-04-30 12:21:37 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2082: GFLOPs: 595.9311. Time: 6209.0718 us. Best GFLOPs: 987.5055
2024-04-30 12:21:37 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2083: GFLOPs: 625.0368. Time: 5919.9374 us. Best GFLOPs: 987.5055
2024-04-30 12:21:37 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2084: GFLOPs: 123.0503. Time: 30070.4655 us. Best GFLOPs: 987.5055
2024-04-30 12:21:37 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2085: GFLOPs: 589.5071. Time: 6276.7333 us. Best GFLOPs: 987.5055
2024-04-30 12:21:37 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2086: GFLOPs: 572.4368. Time: 6463.9084 us. Best GFLOPs: 987.5055
2024-04-30 12:21:37 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2087: GFLOPs: 588.9178. Time: 6283.0146 us. Best GFLOPs: 987.5055
2024-04-30 12:21:37 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2088: GFLOPs: 690.2754. Time: 5360.4387 us. Best GFLOPs: 987.5055
2024-04-30 12:21:37 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2089: GFLOPs: 606.8066. Time: 6097.7893 us. Best GFLOPs: 987.5055
2024-04-30 12:21:37 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2090: GFLOPs: 630.2064. Time: 5871.3762 us. Best GFLOPs: 987.5055
2024-04-30 12:21:37 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2091: GFLOPs: 590.9497. Time: 6261.4109 us. Best GFLOPs: 987.5055
2024-04-30 12:21:37 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2092: GFLOPs: 573.5953. Time: 6450.8531 us. Best GFLOPs: 987.5055
2024-04-30 12:21:37 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2093: GFLOPs: 605.0595. Time: 6115.3972 us. Best GFLOPs: 987.5055
2024-04-30 12:21:37 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2094: GFLOPs: 565.0522. Time: 6548.3842 us. Best GFLOPs: 987.5055
2024-04-30 12:21:37 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2095: GFLOPs: 579.3763. Time: 6386.4870 us. Best GFLOPs: 987.5055
2024-04-30 12:21:37 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2096: GFLOPs: 526.9584. Time: 7021.7671 us. Best GFLOPs: 987.5055
2024-04-30 12:21:37 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2097: GFLOPs: 617.5068. Time: 5992.1269 us. Best GFLOPs: 987.5055
2024-04-30 12:21:37 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2098: GFLOPs: 567.3670. Time: 6521.6674 us. Best GFLOPs: 987.5055
2024-04-30 12:21:37 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2099: GFLOPs: 721.7374. Time: 5126.7659 us. Best GFLOPs: 987.5055
2024-04-30 12:21:37 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2100: GFLOPs: 284.6895. Time: 12997.2429 us. Best GFLOPs: 987.5055
2024-04-30 12:21:37 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2101: GFLOPs: 632.7253. Time: 5848.0025 us. Best GFLOPs: 987.5055
2024-04-30 12:21:37 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2102: GFLOPs: 752.8570. Time: 4914.8496 us. Best GFLOPs: 987.5055
2024-04-30 12:21:37 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2103: GFLOPs: 583.7742. Time: 6338.3731 us. Best GFLOPs: 987.5055
2024-04-30 12:21:37 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2104: GFLOPs: 644.5976. Time: 5740.2923 us. Best GFLOPs: 987.5055
2024-04-30 12:21:37 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2105: GFLOPs: 573.8755. Time: 6447.7031 us. Best GFLOPs: 987.5055
2024-04-30 12:21:37 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2106: GFLOPs: 599.2793. Time: 6174.3812 us. Best GFLOPs: 987.5055
2024-04-30 12:21:37 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2107: GFLOPs: 594.9372. Time: 6219.4449 us. Best GFLOPs: 987.5055
2024-04-30 12:21:37 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2108: GFLOPs: 107.3721. Time: 34461.2673 us. Best GFLOPs: 987.5055
2024-04-30 12:21:37 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2109: GFLOPs: 621.6577. Time: 5952.1168 us. Best GFLOPs: 987.5055
2024-04-30 12:21:37 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2110: GFLOPs: 49.4816. Time: 74778.8623 us. Best GFLOPs: 987.5055
2024-04-30 12:21:37 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2111: GFLOPs: 77.9959. Time: 47440.6600 us. Best GFLOPs: 987.5055
2024-04-30 12:21:37 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2112: GFLOPs: 87.8661. Time: 42111.5490 us. Best GFLOPs: 987.5055
2024-04-30 12:27:22 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-30 12:27:23 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-30 12:27:28 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 12:27:28 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-30 12:27:40 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 12:27:54 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 12:28:08 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 12:28:22 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 12:28:31 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.8320  0.8248  0.8131  0.8029  0.8029  0.7775  0.7607  0.7435  0.7397  0.7397  0.7362  0.7346  0.7168  0.7168  0.7078  0.7068
[17 : 32]:	0.7033  0.6955  0.6844  0.6778  0.6754  0.6749  0.6679  0.6676  0.6669  0.6667  0.6627  0.6614  0.6608  0.6512  0.6425  0.6330
[33 : 48]:	0.6263  0.6139  0.6065  0.5986  0.5944  0.5940  0.5927  0.5902  0.5891  0.5884  0.5780  0.5722  0.5721  0.5649  0.5610  0.5528
[49 : 64]:	0.5528  0.5528  0.5465  0.5456  0.5446  0.5428  0.5397  0.5361  0.5343  0.5323  0.5304  0.5298  0.5270  0.5258  0.5257  0.5235
2024-04-30 12:28:31 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-30 12:28:31 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-30 12:31:20 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2113: GFLOPs: 798.9517. Time: 4631.2926 us. Best GFLOPs: 987.5055
2024-04-30 12:31:20 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2114: GFLOPs: 839.9312. Time: 4405.3360 us. Best GFLOPs: 987.5055
2024-04-30 12:31:20 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2115: GFLOPs: 843.8137. Time: 4385.0661 us. Best GFLOPs: 987.5055
2024-04-30 12:31:20 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2116: GFLOPs: 820.9471. Time: 4507.2078 us. Best GFLOPs: 987.5055
2024-04-30 12:31:20 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2117: GFLOPs: 821.0233. Time: 4506.7889 us. Best GFLOPs: 987.5055
2024-04-30 12:31:20 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2118: GFLOPs: 797.8452. Time: 4637.7155 us. Best GFLOPs: 987.5055
2024-04-30 12:31:20 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2119: GFLOPs: 788.2130. Time: 4694.3897 us. Best GFLOPs: 987.5055
2024-04-30 12:31:20 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2120: GFLOPs: 684.2487. Time: 5407.6523 us. Best GFLOPs: 987.5055
2024-04-30 12:31:20 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2121: GFLOPs: 781.2300. Time: 4736.3501 us. Best GFLOPs: 987.5055
2024-04-30 12:31:20 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2122: GFLOPs: 840.2981. Time: 4403.4125 us. Best GFLOPs: 987.5055
2024-04-30 12:31:20 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2123: GFLOPs: 705.1441. Time: 5247.4081 us. Best GFLOPs: 987.5055
2024-04-30 12:31:20 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2124: GFLOPs: 670.4205. Time: 5519.1911 us. Best GFLOPs: 987.5055
2024-04-30 12:31:20 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2125: GFLOPs: 624.5472. Time: 5924.5784 us. Best GFLOPs: 987.5055
2024-04-30 12:31:20 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2126: GFLOPs: 619.0272. Time: 5977.4090 us. Best GFLOPs: 987.5055
2024-04-30 12:31:20 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2127: GFLOPs: 773.2893. Time: 4784.9863 us. Best GFLOPs: 987.5055
2024-04-30 12:31:20 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2128: GFLOPs: 400.3616. Time: 9242.0924 us. Best GFLOPs: 987.5055
2024-04-30 12:31:20 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2129: GFLOPs: 782.7474. Time: 4727.1684 us. Best GFLOPs: 987.5055
2024-04-30 12:31:20 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2130: GFLOPs: 755.6261. Time: 4896.8388 us. Best GFLOPs: 987.5055
2024-04-30 12:31:20 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2131: GFLOPs: 676.9983. Time: 5465.5659 us. Best GFLOPs: 987.5055
2024-04-30 12:31:20 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2132: GFLOPs: 657.0608. Time: 5631.4099 us. Best GFLOPs: 987.5055
2024-04-30 12:31:20 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2133: GFLOPs: 679.7516. Time: 5443.4280 us. Best GFLOPs: 987.5055
2024-04-30 12:31:20 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2134: GFLOPs: 679.4021. Time: 5446.2281 us. Best GFLOPs: 987.5055
2024-04-30 12:31:20 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2135: GFLOPs: 655.8856. Time: 5641.5005 us. Best GFLOPs: 987.5055
2024-04-30 12:31:20 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2136: GFLOPs: 651.5080. Time: 5679.4067 us. Best GFLOPs: 987.5055
2024-04-30 12:31:20 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2137: GFLOPs: 703.8104. Time: 5257.3521 us. Best GFLOPs: 987.5055
2024-04-30 12:31:20 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2138: GFLOPs: 661.6970. Time: 5591.9536 us. Best GFLOPs: 987.5055
2024-04-30 12:31:20 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2139: GFLOPs: 672.1717. Time: 5504.8122 us. Best GFLOPs: 987.5055
2024-04-30 12:31:20 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2140: GFLOPs: 662.6195. Time: 5584.1684 us. Best GFLOPs: 987.5055
2024-04-30 12:31:20 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2141: GFLOPs: 715.5468. Time: 5171.1211 us. Best GFLOPs: 987.5055
2024-04-30 12:31:20 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2142: GFLOPs: 670.3093. Time: 5520.1067 us. Best GFLOPs: 987.5055
2024-04-30 12:31:20 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2143: GFLOPs: 761.8911. Time: 4856.5717 us. Best GFLOPs: 987.5055
2024-04-30 12:31:20 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2144: GFLOPs: 597.9519. Time: 6188.0884 us. Best GFLOPs: 987.5055
2024-04-30 12:31:20 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2145: GFLOPs: 593.2038. Time: 6237.6187 us. Best GFLOPs: 987.5055
2024-04-30 12:31:20 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2146: GFLOPs: 589.4876. Time: 6276.9406 us. Best GFLOPs: 987.5055
2024-04-30 12:31:20 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2147: GFLOPs: 585.0519. Time: 6324.5308 us. Best GFLOPs: 987.5055
2024-04-30 12:31:20 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2148: GFLOPs: 738.5160. Time: 5010.2897 us. Best GFLOPs: 987.5055
2024-04-30 12:31:20 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2149: GFLOPs: 590.5169. Time: 6265.9998 us. Best GFLOPs: 987.5055
2024-04-30 12:31:20 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2150: GFLOPs: 366.9433. Time: 10083.7896 us. Best GFLOPs: 987.5055
2024-04-30 12:31:20 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2151: GFLOPs: 511.5400. Time: 7233.4110 us. Best GFLOPs: 987.5055
2024-04-30 12:31:20 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2152: GFLOPs: 544.5834. Time: 6794.5124 us. Best GFLOPs: 987.5055
2024-04-30 12:31:20 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2153: GFLOPs: 603.5124. Time: 6131.0733 us. Best GFLOPs: 987.5055
2024-04-30 12:31:20 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2154: GFLOPs: 731.7616. Time: 5056.5361 us. Best GFLOPs: 987.5055
2024-04-30 12:31:20 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2155: GFLOPs: 548.6630. Time: 6743.9922 us. Best GFLOPs: 987.5055
2024-04-30 12:31:20 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2156: GFLOPs: 601.7096. Time: 6149.4430 us. Best GFLOPs: 987.5055
2024-04-30 12:31:20 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2157: GFLOPs: 536.0483. Time: 6902.6975 us. Best GFLOPs: 987.5055
2024-04-30 12:31:20 [INFO] [task_scheduler.cc:121] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2158: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(512)), "float32"), p1: T.Buffer((T.int64(32), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused in T.parallel(T.int64(112), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(14), T.int64(2), T.int64(16), T.int64(1), T.int64(4), T.int64(1), T.int64(2), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(14) * T.int64(4) + oc_chunk_1 * T.int64(4) + oc_chunk_2_init * T.int64(4) + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(14) // T.int64(7) * T.int64(14) + oh_1 * T.int64(14) + oh_2_init + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(7) * T.int64(4) + ow_1 * T.int64(4) + ow_2_init * T.int64(2) + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(16), oc_block_1 * T.int64(16) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0 in range(T.int64(64)):
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(16), T.int64(6)):
                        for ax4_fused in T.vectorized(T.int64(8)):
                            with T.block("data_pad"):
                                v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                                v_i2 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(14) // T.int64(7) * T.int64(14) + ax2)
                                v_i3 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(7) * T.int64(4) + ax3)
                                v_i4 = T.axis.spatial(T.int64(512), ic_0 * T.int64(8) + ax4_fused)
                                T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                                T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                                data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                    for kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(14), T.int64(2), T.int64(16), T.int64(8), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(1), T.int64(2), T.int64(1)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(14) * T.int64(4) + oc_chunk_1 * T.int64(4) + oc_chunk_2 * T.int64(4) + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(14) // T.int64(7) * T.int64(14) + oh_1 * T.int64(14) + oh_2 + oh_3)
                            v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(7) * T.int64(4) + ow_1 * T.int64(4) + ow_2 * T.int64(2) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_1 * T.int64(16) + oc_block_2 + oc_block_3)
                            v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(8) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
            for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(4), T.int64(14)):
                for ax3_ax4_fused in T.vectorized(T.int64(64)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(14) * T.int64(4) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(14) // T.int64(7) * T.int64(14) + ax2)
                        v_ax3 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(7) * T.int64(4) + ax3_ax4_fused // T.int64(16))
                        v_ax4 = T.axis.spatial(T.int64(16), ax3_ax4_fused % T.int64(16))
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[8, 1, 1, 4])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 1, 14, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[7, 1, 2, 2])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 16, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[64, 8])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=10)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86 = sch.get_loops(block=b68)
l87 = sch.fuse(l71, l72, l73, l74, l75, preserve_unit_iters=True)
sch.parallel(loop=l87)
l88 = sch.fuse(l86, preserve_unit_iters=True)
sch.vectorize(loop=l88)
l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107, l108, l109, l110 = sch.get_loops(block=b69)
l111 = sch.fuse(l89, preserve_unit_iters=True)
sch.parallel(loop=l111)
sch.annotate(block_or_loop=l111, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l111, ann_key="pragma_unroll_explicit", ann_val=1)
l112, l113, l114, l115, l116, l117 = sch.get_loops(block=b70)
l118 = sch.fuse(l116, l117, preserve_unit_iters=True)
sch.vectorize(loop=l118)
b119 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141 = sch.get_loops(block=b119)
b142 = sch.decompose_reduction(block=b119, loop=l126)
2024-04-30 12:31:20 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2159: GFLOPs: 697.4266. Time: 5305.4740 us. Best GFLOPs: 987.5055
2024-04-30 12:31:20 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2160: GFLOPs: 151.5342. Time: 24418.1178 us. Best GFLOPs: 987.5055
2024-04-30 12:31:20 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2161: GFLOPs: 20.2588. Time: 182645.8563 us. Best GFLOPs: 987.5055
2024-04-30 12:31:20 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2162: GFLOPs: 11.1526. Time: 331775.8090 us. Best GFLOPs: 987.5055
2024-04-30 12:31:20 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2163: GFLOPs: 252.7384. Time: 14640.3493 us. Best GFLOPs: 987.5055
2024-04-30 12:31:20 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2164: GFLOPs: 376.7618. Time: 9821.0032 us. Best GFLOPs: 987.5055
2024-04-30 12:31:20 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2165: GFLOPs: 539.7591. Time: 6855.2415 us. Best GFLOPs: 987.5055
2024-04-30 12:31:20 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2166: GFLOPs: 537.9038. Time: 6878.8859 us. Best GFLOPs: 987.5055
2024-04-30 12:31:20 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2167: GFLOPs: 531.9164. Time: 6956.3172 us. Best GFLOPs: 987.5055
2024-04-30 12:31:20 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2168: GFLOPs: 469.0793. Time: 7888.1744 us. Best GFLOPs: 987.5055
2024-04-30 12:31:20 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2169: GFLOPs: 628.6214. Time: 5886.1808 us. Best GFLOPs: 987.5055
2024-04-30 12:31:20 [INFO] [task_scheduler.cc:121] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2170: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(512)), "float32"), p1: T.Buffer((T.int64(32), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused in T.parallel(T.int64(224), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(2), T.int64(7), T.int64(16), T.int64(1), T.int64(4), T.int64(1), T.int64(2), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(28) * T.int64(4) + oc_chunk_1 * T.int64(4) + oc_chunk_2_init * T.int64(4) + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(28) // T.int64(2) * T.int64(2) + oh_1 * T.int64(2) + oh_2_init + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(2) * T.int64(14) + ow_1 * T.int64(14) + ow_2_init * T.int64(2) + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(16), oc_block_1 * T.int64(16) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0 in T.grid(T.int64(128), T.int64(3)):
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(2), T.int64(16)):
                        for ax4_fused in T.vectorized(T.int64(4)):
                            with T.block("data_pad"):
                                v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                                v_i2 = T.axis.spatial(T.int64(30), kh_0 + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(28) // T.int64(2) * T.int64(2) + ax2)
                                v_i3 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(2) * T.int64(14) + ax3)
                                v_i4 = T.axis.spatial(T.int64(512), ic_0 * T.int64(4) + ax4_fused)
                                T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                                T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                                data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                    for kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(3), T.int64(1), T.int64(1), T.int64(2), T.int64(7), T.int64(16), T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(1), T.int64(2), T.int64(1)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(28) * T.int64(4) + oc_chunk_1 * T.int64(4) + oc_chunk_2 * T.int64(4) + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(28) // T.int64(2) * T.int64(2) + oh_1 * T.int64(2) + oh_2 + oh_3)
                            v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(2) * T.int64(14) + ow_1 * T.int64(14) + ow_2 * T.int64(2) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_1 * T.int64(16) + oc_block_2 + oc_block_3)
                            v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(4) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(4), T.int64(2), T.int64(14)):
                for ax4_fused in T.vectorized(T.int64(16)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(28) * T.int64(4) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(28) // T.int64(2) * T.int64(2) + ax2)
                        v_ax3 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(2) * T.int64(14) + ax3)
                        v_ax4 = T.axis.spatial(T.int64(16), ax4_fused)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[8, 1, 1, 4])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[14, 1, 2, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[2, 1, 7, 2])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 16, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[128, 4])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=11)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87 = sch.get_loops(block=b68)
l88 = sch.fuse(l71, l72, l73, l74, l75, preserve_unit_iters=True)
sch.parallel(loop=l88)
l89 = sch.fuse(l87, preserve_unit_iters=True)
sch.vectorize(loop=l89)
l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107, l108, l109, l110, l111 = sch.get_loops(block=b69)
l112 = sch.fuse(l90, preserve_unit_iters=True)
sch.parallel(loop=l112)
sch.annotate(block_or_loop=l112, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l112, ann_key="pragma_unroll_explicit", ann_val=1)
l113, l114, l115, l116, l117, l118 = sch.get_loops(block=b70)
l119 = sch.fuse(l118, preserve_unit_iters=True)
sch.vectorize(loop=l119)
b120 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141, l142 = sch.get_loops(block=b120)
b143 = sch.decompose_reduction(block=b120, loop=l127)
2024-04-30 12:31:20 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2171: GFLOPs: 477.0091. Time: 7757.0413 us. Best GFLOPs: 987.5055
2024-04-30 12:31:20 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2172: GFLOPs: 23.9102. Time: 154753.1113 us. Best GFLOPs: 987.5055
2024-04-30 12:31:20 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2173: GFLOPs: 549.2397. Time: 6736.9114 us. Best GFLOPs: 987.5055
2024-04-30 12:31:20 [INFO] [task_scheduler.cc:121] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2174: Error in running:
LocalRunner: Timeout, killed after 30 seconds

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(512)), "float32"), p1: T.Buffer((T.int64(32), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused in T.parallel(T.int64(2), annotations={"pragma_auto_unroll_max_step": 16, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(2), T.int64(2), T.int64(14), T.int64(2)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(1), T.int64(7), T.int64(2), T.int64(2), T.int64(1), T.int64(16), T.int64(1), T.int64(1)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(32), oc_chunk_1 * T.int64(16) + oc_chunk_2_init * T.int64(16) + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused * T.int64(14) + oh_1 * T.int64(7) + oh_2_init + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(28), ow_1 * T.int64(2) + ow_2_init + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_1 * T.int64(8) + oc_block_2_init * T.int64(4) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0 in T.grid(T.int64(128), T.int64(3), T.int64(3)):
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(7), T.int64(2)):
                        for ax4_fused in T.vectorized(T.int64(4)):
                            with T.block("data_pad"):
                                v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                                v_i2 = T.axis.spatial(T.int64(30), kh_0 + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused * T.int64(14) + oh_1 * T.int64(7) + ax2)
                                v_i3 = T.axis.spatial(T.int64(30), kw_0 + ow_1 * T.int64(2) + ax3)
                                v_i4 = T.axis.spatial(T.int64(512), ic_0 * T.int64(4) + ax4_fused)
                                T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                                T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                                data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                    for n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(1), T.int64(1), T.int64(7), T.int64(2), T.int64(2), T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(16), T.int64(1), T.int64(1)):
                        for oc_block_3_fused in T.vectorized(T.int64(4)):
                            with T.block("conv2d_NCHWc_update"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                                v_oc_chunk = T.axis.spatial(T.int64(32), oc_chunk_1 * T.int64(16) + oc_chunk_2 * T.int64(16) + oc_chunk_3)
                                v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused * T.int64(14) + oh_1 * T.int64(7) + oh_2 + oh_3)
                                v_ow = T.axis.spatial(T.int64(28), ow_1 * T.int64(2) + ow_2 + ow_3)
                                v_oc_block = T.axis.spatial(T.int64(16), oc_block_1 * T.int64(8) + oc_block_2 * T.int64(4) + oc_block_3_fused)
                                v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(4) + ic_1)
                                v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                                v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                                T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(32), T.int64(14), T.int64(28)):
                for ax4_fused in T.vectorized(T.int64(16)):
                    with T.block("T_relu"):
                        v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                        v_ax2 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused * T.int64(14) + ax2)
                        v_ax3, v_ax4 = T.axis.remap("SS", [ax3, ax4_fused])
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 2, 1, 16])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 2, 7, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 14, 2, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 2, 2, 4])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[128, 4])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=12)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88 = sch.get_loops(block=b68)
l89 = sch.fuse(l71, l72, l73, l74, l75, preserve_unit_iters=True)
sch.parallel(loop=l89)
l90 = sch.fuse(l88, preserve_unit_iters=True)
sch.vectorize(loop=l90)
l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107, l108, l109, l110, l111, l112 = sch.get_loops(block=b69)
l113 = sch.fuse(l91, preserve_unit_iters=True)
sch.parallel(loop=l113)
l114 = sch.fuse(l112, preserve_unit_iters=True)
sch.vectorize(loop=l114)
sch.annotate(block_or_loop=l113, ann_key="pragma_auto_unroll_max_step", ann_val=16)
sch.annotate(block_or_loop=l113, ann_key="pragma_unroll_explicit", ann_val=1)
l115, l116, l117, l118, l119, l120 = sch.get_loops(block=b70)
l121 = sch.fuse(l120, preserve_unit_iters=True)
sch.vectorize(loop=l121)
b122 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141, l142, l143, l144 = sch.get_loops(block=b122)
b145 = sch.decompose_reduction(block=b122, loop=l129)
2024-04-30 12:31:20 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2175: GFLOPs: 11.2988. Time: 327484.2857 us. Best GFLOPs: 987.5055
2024-04-30 12:31:20 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2176: GFLOPs: 6.1971. Time: 597086.8550 us. Best GFLOPs: 987.5055
2024-04-30 12:44:42 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-30 12:44:43 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-30 12:44:47 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 12:44:47 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-30 12:45:00 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 12:45:14 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 12:45:28 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 12:45:42 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 12:45:51 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9487  0.8814  0.8768  0.8587  0.8407  0.8077  0.8024  0.7942  0.7871  0.7855  0.7669  0.7657  0.7514  0.7409  0.7309  0.7225
[17 : 32]:	0.7127  0.7108  0.6812  0.6808  0.6734  0.6721  0.6675  0.6647  0.6641  0.6641  0.6632  0.6623  0.6558  0.6549  0.6461  0.6461
[33 : 48]:	0.6421  0.6410  0.6401  0.6387  0.6385  0.6378  0.6356  0.6350  0.6337  0.6279  0.6276  0.6241  0.6199  0.6151  0.6125  0.6108
[49 : 64]:	0.6003  0.5982  0.5967  0.5955  0.5955  0.5917  0.5869  0.5845  0.5803  0.5729  0.5721  0.5654  0.5643  0.5641  0.5583  0.5578
2024-04-30 12:45:52 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-30 12:45:52 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-30 12:48:06 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2177: GFLOPs: 980.5102. Time: 3773.7283 us. Best GFLOPs: 987.5055
2024-04-30 12:48:06 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2178: GFLOPs: 949.4736. Time: 3897.0844 us. Best GFLOPs: 987.5055
2024-04-30 12:48:06 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2179: GFLOPs: 950.7725. Time: 3891.7605 us. Best GFLOPs: 987.5055
2024-04-30 12:48:06 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2180: GFLOPs: 971.0984. Time: 3810.3027 us. Best GFLOPs: 987.5055
2024-04-30 12:48:06 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2181: GFLOPs: 874.5926. Time: 4230.7458 us. Best GFLOPs: 987.5055
2024-04-30 12:48:06 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2182: GFLOPs: 861.1171. Time: 4296.9520 us. Best GFLOPs: 987.5055
2024-04-30 12:48:06 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2183: GFLOPs: 866.1968. Time: 4271.7532 us. Best GFLOPs: 987.5055
2024-04-30 12:48:06 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2184: GFLOPs: 892.5297. Time: 4145.7208 us. Best GFLOPs: 987.5055
2024-04-30 12:48:06 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2185: GFLOPs: 805.2217. Time: 4595.2301 us. Best GFLOPs: 987.5055
2024-04-30 12:48:06 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2186: GFLOPs: 856.6800. Time: 4319.2078 us. Best GFLOPs: 987.5055
2024-04-30 12:48:06 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2187: GFLOPs: 785.8838. Time: 4708.3030 us. Best GFLOPs: 987.5055
2024-04-30 12:48:06 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2188: GFLOPs: 437.8990. Time: 8449.8464 us. Best GFLOPs: 987.5055
2024-04-30 12:48:06 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2189: GFLOPs: 814.7017. Time: 4541.7592 us. Best GFLOPs: 987.5055
2024-04-30 12:48:06 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2190: GFLOPs: 702.2979. Time: 5268.6744 us. Best GFLOPs: 987.5055
2024-04-30 12:48:06 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2191: GFLOPs: 738.0408. Time: 5013.5153 us. Best GFLOPs: 987.5055
2024-04-30 12:48:06 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2192: GFLOPs: 755.6507. Time: 4896.6789 us. Best GFLOPs: 987.5055
2024-04-30 12:48:06 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2193: GFLOPs: 612.5382. Time: 6040.7313 us. Best GFLOPs: 987.5055
2024-04-30 12:48:06 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2194: GFLOPs: 695.7915. Time: 5317.9418 us. Best GFLOPs: 987.5055
2024-04-30 12:48:06 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2195: GFLOPs: 695.2506. Time: 5322.0793 us. Best GFLOPs: 987.5055
2024-04-30 12:48:06 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2196: GFLOPs: 394.8463. Time: 9371.1892 us. Best GFLOPs: 987.5055
2024-04-30 12:48:06 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2197: GFLOPs: 703.8835. Time: 5256.8056 us. Best GFLOPs: 987.5055
2024-04-30 12:48:06 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2198: GFLOPs: 761.4277. Time: 4859.5278 us. Best GFLOPs: 987.5055
2024-04-30 12:48:06 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2199: GFLOPs: 698.7700. Time: 5295.2746 us. Best GFLOPs: 987.5055
2024-04-30 12:48:06 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2200: GFLOPs: 716.1906. Time: 5166.4722 us. Best GFLOPs: 987.5055
2024-04-30 12:48:06 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2201: GFLOPs: 699.5841. Time: 5289.1124 us. Best GFLOPs: 987.5055
2024-04-30 12:48:06 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2202: GFLOPs: 699.0620. Time: 5293.0625 us. Best GFLOPs: 987.5055
2024-04-30 12:48:06 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2203: GFLOPs: 671.7143. Time: 5508.5609 us. Best GFLOPs: 987.5055
2024-04-30 12:48:06 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2204: GFLOPs: 678.8706. Time: 5450.4925 us. Best GFLOPs: 987.5055
2024-04-30 12:48:06 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2205: GFLOPs: 616.4701. Time: 6002.2036 us. Best GFLOPs: 987.5055
2024-04-30 12:48:06 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2206: GFLOPs: 696.0752. Time: 5315.7750 us. Best GFLOPs: 987.5055
2024-04-30 12:48:06 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2207: GFLOPs: 884.9243. Time: 4181.3510 us. Best GFLOPs: 987.5055
2024-04-30 12:48:06 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2208: GFLOPs: 884.9542. Time: 4181.2098 us. Best GFLOPs: 987.5055
2024-04-30 12:48:06 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2209: GFLOPs: 735.3476. Time: 5031.8774 us. Best GFLOPs: 987.5055
2024-04-30 12:48:06 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2210: GFLOPs: 634.2490. Time: 5833.9536 us. Best GFLOPs: 987.5055
2024-04-30 12:48:06 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2211: GFLOPs: 600.5015. Time: 6161.8146 us. Best GFLOPs: 987.5055
2024-04-30 12:48:06 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2212: GFLOPs: 417.5709. Time: 8861.1983 us. Best GFLOPs: 987.5055
2024-04-30 12:48:06 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2213: GFLOPs: 701.3179. Time: 5276.0369 us. Best GFLOPs: 987.5055
2024-04-30 12:48:06 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2214: GFLOPs: 615.5878. Time: 6010.8062 us. Best GFLOPs: 987.5055
2024-04-30 12:48:06 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2215: GFLOPs: 725.8060. Time: 5098.0276 us. Best GFLOPs: 987.5055
2024-04-30 12:48:06 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2216: GFLOPs: 724.0782. Time: 5110.1923 us. Best GFLOPs: 987.5055
2024-04-30 12:48:06 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2217: GFLOPs: 610.5674. Time: 6060.2299 us. Best GFLOPs: 987.5055
2024-04-30 12:48:06 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2218: GFLOPs: 663.9769. Time: 5572.7524 us. Best GFLOPs: 987.5055
2024-04-30 12:48:06 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2219: GFLOPs: 627.0044. Time: 5901.3602 us. Best GFLOPs: 987.5055
2024-04-30 12:48:06 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2220: GFLOPs: 105.7576. Time: 34987.3643 us. Best GFLOPs: 987.5055
2024-04-30 12:48:06 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2221: GFLOPs: 601.2525. Time: 6154.1181 us. Best GFLOPs: 987.5055
2024-04-30 12:48:06 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2222: GFLOPs: 607.9047. Time: 6086.7750 us. Best GFLOPs: 987.5055
2024-04-30 12:48:06 [INFO] [task_scheduler.cc:121] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2223: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(512)), "float32"), p1: T.Buffer((T.int64(32), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_fused_fused in T.parallel(T.int64(224), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for oc_block_0 in range(T.int64(1)):
                for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                    for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(2), T.int64(7), T.int64(16), T.int64(1), T.int64(4), T.int64(1), T.int64(2), T.int64(1)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(28) * T.int64(4) + oc_chunk_1 * T.int64(4) + oc_chunk_2_init * T.int64(4) + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(28) // T.int64(2) * T.int64(2) + oh_1 * T.int64(2) + oh_2_init + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(2) * T.int64(14) + ow_1 * T.int64(14) + ow_2_init * T.int64(2) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2_init + oc_block_3_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                    for ic_0 in range(T.int64(128)):
                        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(16)):
                            for ax4_fused in T.vectorized(T.int64(4)):
                                with T.block("data_pad"):
                                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                                    v_i2 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(28) // T.int64(2) * T.int64(2) + ax2)
                                    v_i3 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(2) * T.int64(14) + ax3)
                                    v_i4 = T.axis.spatial(T.int64(512), ic_0 * T.int64(4) + ax4_fused)
                                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                        for kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(2), T.int64(7), T.int64(16), T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(1), T.int64(2), T.int64(1)):
                            with T.block("conv2d_NCHWc_update"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                                v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(28) * T.int64(4) + oc_chunk_1 * T.int64(4) + oc_chunk_2 * T.int64(4) + oc_chunk_3)
                                v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(28) // T.int64(2) * T.int64(2) + oh_1 * T.int64(2) + oh_2 + oh_3)
                                v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(2) * T.int64(14) + ow_1 * T.int64(14) + ow_2 * T.int64(2) + ow_3)
                                v_oc_block = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2 + oc_block_3)
                                v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(4) + ic_1)
                                v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                                v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                                T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(4), T.int64(2), T.int64(14)):
                    for ax4_fused in T.vectorized(T.int64(16)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(28) * T.int64(4) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(28) // T.int64(2) * T.int64(2) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(2) * T.int64(14) + ax3)
                            v_ax4 = T.axis.spatial(T.int64(16), ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[8, 1, 1, 4])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[14, 1, 2, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[2, 1, 7, 2])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 16, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[128, 4])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=112)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=10)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86 = sch.get_loops(block=b68)
l87 = sch.fuse(l71, l72, l73, l74, preserve_unit_iters=True)
sch.parallel(loop=l87)
l88 = sch.fuse(l86, preserve_unit_iters=True)
sch.vectorize(loop=l88)
l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107, l108, l109, l110, l111 = sch.get_loops(block=b69)
l112 = sch.fuse(l89, preserve_unit_iters=True)
sch.parallel(loop=l112)
sch.annotate(block_or_loop=l112, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l112, ann_key="pragma_unroll_explicit", ann_val=1)
l113, l114, l115, l116, l117, l118, l119 = sch.get_loops(block=b70)
l120 = sch.fuse(l119, preserve_unit_iters=True)
sch.vectorize(loop=l120)
b121 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141, l142, l143, l144 = sch.get_loops(block=b121)
b145 = sch.decompose_reduction(block=b121, loop=l129)
2024-04-30 12:48:06 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2224: GFLOPs: 652.8303. Time: 5667.9029 us. Best GFLOPs: 987.5055
2024-04-30 12:48:06 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2225: GFLOPs: 614.1784. Time: 6024.5994 us. Best GFLOPs: 987.5055
2024-04-30 12:48:06 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2226: GFLOPs: 669.0973. Time: 5530.1055 us. Best GFLOPs: 987.5055
2024-04-30 12:48:06 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2227: GFLOPs: 131.3671. Time: 28166.7015 us. Best GFLOPs: 987.5055
2024-04-30 12:48:06 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2228: GFLOPs: 645.0762. Time: 5736.0335 us. Best GFLOPs: 987.5055
2024-04-30 12:48:06 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2229: GFLOPs: 568.6259. Time: 6507.2293 us. Best GFLOPs: 987.5055
2024-04-30 12:48:06 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2230: GFLOPs: 602.7677. Time: 6138.6484 us. Best GFLOPs: 987.5055
2024-04-30 12:48:06 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2231: GFLOPs: 676.1325. Time: 5472.5651 us. Best GFLOPs: 987.5055
2024-04-30 12:48:06 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2232: GFLOPs: 538.1302. Time: 6875.9921 us. Best GFLOPs: 987.5055
2024-04-30 12:48:06 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2233: GFLOPs: 600.8142. Time: 6158.6075 us. Best GFLOPs: 987.5055
2024-04-30 12:48:06 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2234: GFLOPs: 545.1057. Time: 6788.0033 us. Best GFLOPs: 987.5055
2024-04-30 12:48:06 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2235: GFLOPs: 623.4513. Time: 5934.9925 us. Best GFLOPs: 987.5055
2024-04-30 12:48:06 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2236: GFLOPs: 626.4062. Time: 5906.9956 us. Best GFLOPs: 987.5055
2024-04-30 12:48:06 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2237: GFLOPs: 582.7010. Time: 6350.0472 us. Best GFLOPs: 987.5055
2024-04-30 12:48:06 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2238: GFLOPs: 45.6993. Time: 80967.9873 us. Best GFLOPs: 987.5055
2024-04-30 12:48:06 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2239: GFLOPs: 197.9098. Time: 18696.2878 us. Best GFLOPs: 987.5055
2024-04-30 12:48:06 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2240: GFLOPs: 4.2303. Time: 874681.8540 us. Best GFLOPs: 987.5055
2024-04-30 12:54:39 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-30 12:54:40 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-30 12:54:45 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 12:54:45 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-30 12:54:58 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 12:55:12 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 12:55:26 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 12:55:40 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 12:55:49 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.8442  0.8394  0.8154  0.8040  0.7938  0.7928  0.7744  0.7737  0.7674  0.7421  0.7324  0.7280  0.7267  0.7219  0.7093  0.7088
[17 : 32]:	0.7011  0.7008  0.6991  0.6975  0.6769  0.6673  0.6660  0.6639  0.6614  0.6542  0.6497  0.6465  0.6388  0.6354  0.6346  0.6340
[33 : 48]:	0.6338  0.6256  0.6160  0.6157  0.6143  0.6114  0.6093  0.6086  0.6045  0.6044  0.5979  0.5877  0.5851  0.5851  0.5851  0.5839
[49 : 64]:	0.5827  0.5822  0.5814  0.5784  0.5769  0.5755  0.5657  0.5657  0.5654  0.5643  0.5574  0.5567  0.5525  0.5485  0.5461  0.5452
2024-04-30 12:55:49 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-30 12:55:50 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-30 12:57:39 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2241: GFLOPs: 921.4135. Time: 4015.7637 us. Best GFLOPs: 987.5055
2024-04-30 12:57:39 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2242: GFLOPs: 821.7966. Time: 4502.5486 us. Best GFLOPs: 987.5055
2024-04-30 12:57:39 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2243: GFLOPs: 811.2577. Time: 4561.0401 us. Best GFLOPs: 987.5055
2024-04-30 12:57:39 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2244: GFLOPs: 834.3715. Time: 4434.6900 us. Best GFLOPs: 987.5055
2024-04-30 12:57:39 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2245: GFLOPs: 722.6319. Time: 5120.4203 us. Best GFLOPs: 987.5055
2024-04-30 12:57:39 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2246: GFLOPs: 835.2446. Time: 4430.0543 us. Best GFLOPs: 987.5055
2024-04-30 12:57:39 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2247: GFLOPs: 802.9505. Time: 4608.2277 us. Best GFLOPs: 987.5055
2024-04-30 12:57:39 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2248: GFLOPs: 815.6442. Time: 4536.5110 us. Best GFLOPs: 987.5055
2024-04-30 12:57:39 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2249: GFLOPs: 774.0709. Time: 4780.1550 us. Best GFLOPs: 987.5055
2024-04-30 12:57:39 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2250: GFLOPs: 762.1939. Time: 4854.6424 us. Best GFLOPs: 987.5055
2024-04-30 12:57:39 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2251: GFLOPs: 731.9984. Time: 5054.9003 us. Best GFLOPs: 987.5055
2024-04-30 12:57:39 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2252: GFLOPs: 467.5224. Time: 7914.4428 us. Best GFLOPs: 987.5055
2024-04-30 12:57:39 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2253: GFLOPs: 105.6512. Time: 35022.5780 us. Best GFLOPs: 987.5055
2024-04-30 12:57:39 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2254: GFLOPs: 726.1105. Time: 5095.8895 us. Best GFLOPs: 987.5055
2024-04-30 12:57:39 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2255: GFLOPs: 800.4339. Time: 4622.7162 us. Best GFLOPs: 987.5055
2024-04-30 12:57:39 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2256: GFLOPs: 678.4328. Time: 5454.0092 us. Best GFLOPs: 987.5055
2024-04-30 12:57:39 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2257: GFLOPs: 665.2616. Time: 5561.9908 us. Best GFLOPs: 987.5055
2024-04-30 12:57:39 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2258: GFLOPs: 778.7790. Time: 4751.2568 us. Best GFLOPs: 987.5055
2024-04-30 12:57:39 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2259: GFLOPs: 703.9701. Time: 5256.1595 us. Best GFLOPs: 987.5055
2024-04-30 12:57:39 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2260: GFLOPs: 763.5114. Time: 4846.2654 us. Best GFLOPs: 987.5055
2024-04-30 12:57:39 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2261: GFLOPs: 678.3911. Time: 5454.3444 us. Best GFLOPs: 987.5055
2024-04-30 12:57:39 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2262: GFLOPs: 856.8468. Time: 4318.3669 us. Best GFLOPs: 987.5055
2024-04-30 12:57:39 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2263: GFLOPs: 643.1775. Time: 5752.9674 us. Best GFLOPs: 987.5055
2024-04-30 12:57:39 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2264: GFLOPs: 673.7423. Time: 5491.9793 us. Best GFLOPs: 987.5055
2024-04-30 12:57:39 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2265: GFLOPs: 776.1699. Time: 4767.2278 us. Best GFLOPs: 987.5055
2024-04-30 12:57:39 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2266: GFLOPs: 652.9622. Time: 5666.7586 us. Best GFLOPs: 987.5055
2024-04-30 12:57:39 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2267: GFLOPs: 674.7268. Time: 5483.9665 us. Best GFLOPs: 987.5055
2024-04-30 12:57:39 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2268: GFLOPs: 679.2086. Time: 5447.7801 us. Best GFLOPs: 987.5055
2024-04-30 12:57:39 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2269: GFLOPs: 571.1574. Time: 6478.3872 us. Best GFLOPs: 987.5055
2024-04-30 12:57:39 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2270: GFLOPs: 754.0431. Time: 4907.1183 us. Best GFLOPs: 987.5055
2024-04-30 12:57:39 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2271: GFLOPs: 645.9813. Time: 5727.9970 us. Best GFLOPs: 987.5055
2024-04-30 12:57:39 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2272: GFLOPs: 594.4330. Time: 6224.7195 us. Best GFLOPs: 987.5055
2024-04-30 12:57:39 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2273: GFLOPs: 633.3147. Time: 5842.5594 us. Best GFLOPs: 987.5055
2024-04-30 12:57:39 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2274: GFLOPs: 645.5747. Time: 5731.6043 us. Best GFLOPs: 987.5055
2024-04-30 12:57:39 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2275: GFLOPs: 642.8901. Time: 5755.5386 us. Best GFLOPs: 987.5055
2024-04-30 12:57:39 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2276: GFLOPs: 559.2704. Time: 6616.0820 us. Best GFLOPs: 987.5055
2024-04-30 12:57:39 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2277: GFLOPs: 612.8174. Time: 6037.9799 us. Best GFLOPs: 987.5055
2024-04-30 12:57:39 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2278: GFLOPs: 83.2455. Time: 44448.9983 us. Best GFLOPs: 987.5055
2024-04-30 12:57:39 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2279: GFLOPs: 497.3155. Time: 7440.3053 us. Best GFLOPs: 987.5055
2024-04-30 12:57:39 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2280: GFLOPs: 497.0809. Time: 7443.8160 us. Best GFLOPs: 987.5055
2024-04-30 12:57:39 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2281: GFLOPs: 673.1925. Time: 5496.4646 us. Best GFLOPs: 987.5055
2024-04-30 12:57:39 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2282: GFLOPs: 549.7527. Time: 6730.6239 us. Best GFLOPs: 987.5055
2024-04-30 12:57:39 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2283: GFLOPs: 586.4871. Time: 6309.0543 us. Best GFLOPs: 987.5055
2024-04-30 12:57:39 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2284: GFLOPs: 598.7515. Time: 6179.8246 us. Best GFLOPs: 987.5055
2024-04-30 12:57:39 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2285: GFLOPs: 615.6260. Time: 6010.4335 us. Best GFLOPs: 987.5055
2024-04-30 12:57:39 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2286: GFLOPs: 393.0944. Time: 9412.9530 us. Best GFLOPs: 987.5055
2024-04-30 12:57:39 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2287: GFLOPs: 594.9150. Time: 6219.6771 us. Best GFLOPs: 987.5055
2024-04-30 12:57:39 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2288: GFLOPs: 850.4849. Time: 4350.6697 us. Best GFLOPs: 987.5055
2024-04-30 12:57:39 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2289: GFLOPs: 516.5193. Time: 7163.6806 us. Best GFLOPs: 987.5055
2024-04-30 12:57:39 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2290: GFLOPs: 92.9991. Time: 39787.2363 us. Best GFLOPs: 987.5055
2024-04-30 12:57:39 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2291: GFLOPs: 436.0589. Time: 8485.5028 us. Best GFLOPs: 987.5055
2024-04-30 12:57:39 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2292: GFLOPs: 657.8743. Time: 5624.4463 us. Best GFLOPs: 987.5055
2024-04-30 12:57:39 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2293: GFLOPs: 571.2803. Time: 6476.9934 us. Best GFLOPs: 987.5055
2024-04-30 12:57:39 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2294: GFLOPs: 624.2642. Time: 5927.2645 us. Best GFLOPs: 987.5055
2024-04-30 12:57:39 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2295: GFLOPs: 11.7287. Time: 315480.9170 us. Best GFLOPs: 987.5055
2024-04-30 12:57:39 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2296: GFLOPs: 11.7576. Time: 314705.6440 us. Best GFLOPs: 987.5055
2024-04-30 12:57:39 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2297: GFLOPs: 629.9873. Time: 5873.4183 us. Best GFLOPs: 987.5055
2024-04-30 12:57:39 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2298: GFLOPs: 303.8779. Time: 12176.5338 us. Best GFLOPs: 987.5055
2024-04-30 12:57:39 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2299: GFLOPs: 287.3206. Time: 12878.2230 us. Best GFLOPs: 987.5055
2024-04-30 12:57:39 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2300: GFLOPs: 490.4731. Time: 7544.1020 us. Best GFLOPs: 987.5055
2024-04-30 12:57:39 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2301: GFLOPs: 522.1938. Time: 7085.8347 us. Best GFLOPs: 987.5055
2024-04-30 12:57:39 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2302: GFLOPs: 35.1043. Time: 105405.2310 us. Best GFLOPs: 987.5055
2024-04-30 12:57:39 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2303: GFLOPs: 19.7220. Time: 187616.7580 us. Best GFLOPs: 987.5055
2024-04-30 12:57:39 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2304: GFLOPs: 71.6039. Time: 51675.6467 us. Best GFLOPs: 987.5055
2024-04-30 13:04:22 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-30 13:04:23 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-30 13:04:28 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 13:04:28 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-30 13:04:40 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 13:04:54 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 13:05:08 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 13:05:22 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 13:05:31 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.8499  0.8140  0.8015  0.7878  0.7446  0.7328  0.7066  0.7041  0.7031  0.6917  0.6872  0.6797  0.6725  0.6656  0.6608  0.6549
[17 : 32]:	0.6494  0.6447  0.6433  0.6430  0.6385  0.6364  0.6231  0.6179  0.6142  0.6127  0.6090  0.6079  0.6076  0.6052  0.5983  0.5962
[33 : 48]:	0.5943  0.5918  0.5857  0.5857  0.5848  0.5834  0.5793  0.5761  0.5733  0.5711  0.5668  0.5660  0.5599  0.5576  0.5562  0.5558
[49 : 64]:	0.5442  0.5439  0.5426  0.5411  0.5385  0.5329  0.5240  0.5224  0.5154  0.5130  0.5091  0.5091  0.5086  0.5076  0.5076  0.5071
2024-04-30 13:05:32 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-30 13:05:32 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-30 13:08:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2305: GFLOPs: 395.1026. Time: 9365.1095 us. Best GFLOPs: 987.5055
2024-04-30 13:08:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2306: GFLOPs: 788.6844. Time: 4691.5835 us. Best GFLOPs: 987.5055
2024-04-30 13:08:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2307: GFLOPs: 815.9852. Time: 4534.6150 us. Best GFLOPs: 987.5055
2024-04-30 13:08:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2308: GFLOPs: 128.7551. Time: 28738.1175 us. Best GFLOPs: 987.5055
2024-04-30 13:08:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2309: GFLOPs: 721.7031. Time: 5127.0102 us. Best GFLOPs: 987.5055
2024-04-30 13:08:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2310: GFLOPs: 715.6387. Time: 5170.4570 us. Best GFLOPs: 987.5055
2024-04-30 13:08:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2311: GFLOPs: 762.3785. Time: 4853.4674 us. Best GFLOPs: 987.5055
2024-04-30 13:08:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2312: GFLOPs: 750.2866. Time: 4931.6873 us. Best GFLOPs: 987.5055
2024-04-30 13:08:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2313: GFLOPs: 672.7600. Time: 5499.9984 us. Best GFLOPs: 987.5055
2024-04-30 13:08:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2314: GFLOPs: 702.8640. Time: 5264.4306 us. Best GFLOPs: 987.5055
2024-04-30 13:08:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2315: GFLOPs: 675.7205. Time: 5475.9017 us. Best GFLOPs: 987.5055
2024-04-30 13:08:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2316: GFLOPs: 303.5583. Time: 12189.3510 us. Best GFLOPs: 987.5055
2024-04-30 13:08:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2317: GFLOPs: 739.4739. Time: 5003.7991 us. Best GFLOPs: 987.5055
2024-04-30 13:08:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2318: GFLOPs: 697.3416. Time: 5306.1208 us. Best GFLOPs: 987.5055
2024-04-30 13:08:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2319: GFLOPs: 672.3229. Time: 5503.5743 us. Best GFLOPs: 987.5055
2024-04-30 13:08:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2320: GFLOPs: 739.1187. Time: 5006.2036 us. Best GFLOPs: 987.5055
2024-04-30 13:08:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2321: GFLOPs: 587.5308. Time: 6297.8472 us. Best GFLOPs: 987.5055
2024-04-30 13:08:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2322: GFLOPs: 692.6777. Time: 5341.8477 us. Best GFLOPs: 987.5055
2024-04-30 13:08:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2323: GFLOPs: 739.5804. Time: 5003.0787 us. Best GFLOPs: 987.5055
2024-04-30 13:08:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2324: GFLOPs: 530.0622. Time: 6980.6509 us. Best GFLOPs: 987.5055
2024-04-30 13:08:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2325: GFLOPs: 662.6118. Time: 5584.2333 us. Best GFLOPs: 987.5055
2024-04-30 13:08:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2326: GFLOPs: 659.8590. Time: 5607.5299 us. Best GFLOPs: 987.5055
2024-04-30 13:08:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2327: GFLOPs: 626.2151. Time: 5908.7982 us. Best GFLOPs: 987.5055
2024-04-30 13:08:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2328: GFLOPs: 668.0286. Time: 5538.9527 us. Best GFLOPs: 987.5055
2024-04-30 13:08:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2329: GFLOPs: 266.7973. Time: 13868.8755 us. Best GFLOPs: 987.5055
2024-04-30 13:08:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2330: GFLOPs: 680.6473. Time: 5436.2652 us. Best GFLOPs: 987.5055
2024-04-30 13:08:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2331: GFLOPs: 350.5086. Time: 10556.6003 us. Best GFLOPs: 987.5055
2024-04-30 13:08:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2332: GFLOPs: 102.3632. Time: 36147.5360 us. Best GFLOPs: 987.5055
2024-04-30 13:08:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2333: GFLOPs: 589.7545. Time: 6274.1005 us. Best GFLOPs: 987.5055
2024-04-30 13:08:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2334: GFLOPs: 670.8526. Time: 5515.6365 us. Best GFLOPs: 987.5055
2024-04-30 13:08:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2335: GFLOPs: 594.6846. Time: 6222.0859 us. Best GFLOPs: 987.5055
2024-04-30 13:08:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2336: GFLOPs: 573.6719. Time: 6449.9917 us. Best GFLOPs: 987.5055
2024-04-30 13:08:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2337: GFLOPs: 623.3616. Time: 5935.8464 us. Best GFLOPs: 987.5055
2024-04-30 13:08:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2338: GFLOPs: 571.9456. Time: 6469.4595 us. Best GFLOPs: 987.5055
2024-04-30 13:08:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2339: GFLOPs: 531.5093. Time: 6961.6446 us. Best GFLOPs: 987.5055
2024-04-30 13:08:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2340: GFLOPs: 632.5502. Time: 5849.6206 us. Best GFLOPs: 987.5055
2024-04-30 13:08:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2341: GFLOPs: 580.2435. Time: 6376.9416 us. Best GFLOPs: 987.5055
2024-04-30 13:08:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2342: GFLOPs: 563.8114. Time: 6562.7961 us. Best GFLOPs: 987.5055
2024-04-30 13:08:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2343: GFLOPs: 625.3036. Time: 5917.4119 us. Best GFLOPs: 987.5055
2024-04-30 13:08:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2344: GFLOPs: 648.6539. Time: 5704.3967 us. Best GFLOPs: 987.5055
2024-04-30 13:08:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2345: GFLOPs: 530.6735. Time: 6972.6089 us. Best GFLOPs: 987.5055
2024-04-30 13:08:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2346: GFLOPs: 633.2025. Time: 5843.5951 us. Best GFLOPs: 987.5055
2024-04-30 13:08:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2347: GFLOPs: 105.0416. Time: 35225.8533 us. Best GFLOPs: 987.5055
2024-04-30 13:08:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2348: GFLOPs: 514.7088. Time: 7188.8788 us. Best GFLOPs: 987.5055
2024-04-30 13:08:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2349: GFLOPs: 628.9311. Time: 5883.2819 us. Best GFLOPs: 987.5055
2024-04-30 13:08:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2350: GFLOPs: 600.2908. Time: 6163.9779 us. Best GFLOPs: 987.5055
2024-04-30 13:08:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2351: GFLOPs: 495.2429. Time: 7471.4422 us. Best GFLOPs: 987.5055
2024-04-30 13:08:00 [INFO] [task_scheduler.cc:121] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2352: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(512)), "float32"), p1: T.Buffer((T.int64(32), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_fused_fused in T.parallel(T.int64(224), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for oc_block_0 in range(T.int64(1)):
                for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1)):
                    for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(16), T.int64(1), T.int64(4), T.int64(2), T.int64(1), T.int64(1)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(28) * T.int64(4) + oc_chunk_1 * T.int64(4) + oc_chunk_2_init * T.int64(4) + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(28) // T.int64(4) * T.int64(4) + oh_1 * T.int64(2) + oh_2_init * T.int64(2) + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(4) * T.int64(7) + ow_1 * T.int64(7) + ow_2_init + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2_init + oc_block_3_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                    for ic_0, kh_0 in T.grid(T.int64(128), T.int64(3)):
                        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(2), T.int64(9)):
                            for ax4_fused in T.vectorized(T.int64(4)):
                                with T.block("data_pad"):
                                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                                    v_i2 = T.axis.spatial(T.int64(30), kh_0 + n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(28) // T.int64(4) * T.int64(4) + oh_1 * T.int64(2) + ax2)
                                    v_i3 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(4) * T.int64(7) + ax3)
                                    v_i4 = T.axis.spatial(T.int64(512), ic_0 * T.int64(4) + ax4_fused)
                                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                        for kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(16), T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(2), T.int64(1), T.int64(1)):
                            with T.block("conv2d_NCHWc_update"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                                v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(28) * T.int64(4) + oc_chunk_1 * T.int64(4) + oc_chunk_2 * T.int64(4) + oc_chunk_3)
                                v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(28) // T.int64(4) * T.int64(4) + oh_1 * T.int64(2) + oh_2 * T.int64(2) + oh_3)
                                v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(4) * T.int64(7) + ow_1 * T.int64(7) + ow_2 + ow_3)
                                v_oc_block = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2 + oc_block_3)
                                v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(4) + ic_1)
                                v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                                v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                                T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(4), T.int64(4), T.int64(7)):
                    for ax4_fused in T.vectorized(T.int64(16)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(28) * T.int64(4) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(28) // T.int64(4) * T.int64(4) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(4) * T.int64(7) + ax3)
                            v_ax4 = T.axis.spatial(T.int64(16), ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[8, 1, 1, 4])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[7, 2, 1, 2])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[4, 1, 7, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 16, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[128, 4])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=56)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=11)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87 = sch.get_loops(block=b68)
l88 = sch.fuse(l71, l72, l73, l74, preserve_unit_iters=True)
sch.parallel(loop=l88)
l89 = sch.fuse(l87, preserve_unit_iters=True)
sch.vectorize(loop=l89)
l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107, l108, l109, l110, l111, l112 = sch.get_loops(block=b69)
l113 = sch.fuse(l90, preserve_unit_iters=True)
sch.parallel(loop=l113)
sch.annotate(block_or_loop=l113, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l113, ann_key="pragma_unroll_explicit", ann_val=1)
l114, l115, l116, l117, l118, l119, l120 = sch.get_loops(block=b70)
l121 = sch.fuse(l120, preserve_unit_iters=True)
sch.vectorize(loop=l121)
b122 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141, l142, l143, l144, l145 = sch.get_loops(block=b122)
b146 = sch.decompose_reduction(block=b122, loop=l130)
2024-04-30 13:08:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2353: GFLOPs: 705.6632. Time: 5243.5483 us. Best GFLOPs: 987.5055
2024-04-30 13:08:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2354: GFLOPs: 49.3539. Time: 74972.4013 us. Best GFLOPs: 987.5055
2024-04-30 13:08:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2355: GFLOPs: 528.1855. Time: 7005.4533 us. Best GFLOPs: 987.5055
2024-04-30 13:08:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2356: GFLOPs: 436.5304. Time: 8476.3376 us. Best GFLOPs: 987.5055
2024-04-30 13:08:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2357: GFLOPs: 606.7149. Time: 6098.7109 us. Best GFLOPs: 987.5055
2024-04-30 13:08:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2358: GFLOPs: 631.9014. Time: 5855.6275 us. Best GFLOPs: 987.5055
2024-04-30 13:08:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2359: GFLOPs: 679.3767. Time: 5446.4317 us. Best GFLOPs: 987.5055
2024-04-30 13:08:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2360: GFLOPs: 583.6745. Time: 6339.4560 us. Best GFLOPs: 987.5055
2024-04-30 13:08:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2361: GFLOPs: 585.7229. Time: 6317.2863 us. Best GFLOPs: 987.5055
2024-04-30 13:08:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2362: GFLOPs: 538.9212. Time: 6865.8995 us. Best GFLOPs: 987.5055
2024-04-30 13:08:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2363: GFLOPs: 203.8989. Time: 18147.1248 us. Best GFLOPs: 987.5055
2024-04-30 13:08:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2364: GFLOPs: 203.9094. Time: 18146.1913 us. Best GFLOPs: 987.5055
2024-04-30 13:08:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2365: GFLOPs: 154.8274. Time: 23898.7316 us. Best GFLOPs: 987.5055
2024-04-30 13:08:00 [INFO] [task_scheduler.cc:121] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2366: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(512)), "float32"), p1: T.Buffer((T.int64(32), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused in T.parallel(T.int64(896), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(3), T.int64(16), T.int64(512)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(448) // T.int64(16) + ax2)
                    v_i3 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(16) // T.int64(8) * T.int64(14) + ax3)
                    v_i4 = T.axis.spatial(T.int64(512), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(2), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(4), T.int64(1), T.int64(2), T.int64(1), T.int64(7)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(2)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(448) * T.int64(16) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(4) * T.int64(4) + oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(448) // T.int64(16) + oh_1 + oh_2_init + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(16) // T.int64(8) * T.int64(14) + ow_1 * T.int64(7) + ow_2_init * T.int64(7) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(8) // T.int64(4) * T.int64(8) + oc_block_1 * T.int64(8) + oc_block_2_init * T.int64(2) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(64), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(4), T.int64(8), T.int64(3), T.int64(3), T.int64(1), T.int64(2), T.int64(1), T.int64(7)):
                    for oc_block_3_fused in T.vectorized(T.int64(2)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(448) * T.int64(16) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(4) * T.int64(4) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(448) // T.int64(16) + oh_1 + oh_2 + oh_3)
                            v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(16) // T.int64(8) * T.int64(14) + ow_1 * T.int64(7) + ow_2 * T.int64(7) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(8) // T.int64(4) * T.int64(8) + oc_block_1 * T.int64(8) + oc_block_2 * T.int64(2) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(8) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
        for ax0_ax1_ax2_ax3_ax4_fused_0 in T.parallel(T.int64(6272)):
            for ax0_ax1_ax2_ax3_ax4_fused_1 in T.vectorized(T.int64(64)):
                with T.block("T_relu"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) // T.int64(12544))
                    v_ax2 = T.axis.spatial(T.int64(28), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(12544) // T.int64(448))
                    v_ax3 = T.axis.spatial(T.int64(28), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(448) // T.int64(16))
                    v_ax4 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(16))
                    T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                    T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[2, 4, 2, 2])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[28, 1, 1, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[2, 2, 1, 7])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[2, 1, 4, 2])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[64, 8])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
l65 = sch.sample_compute_location(block=b0, decision=6)
sch.compute_at(block=b0, loop=l65, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b66 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.unroll_explicit")
b67, b68, b69 = sch.get_child_blocks(b66)
l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81 = sch.get_loops(block=b67)
l82 = sch.fuse(l70, l71, l72, l73, l74, l75, l76, preserve_unit_iters=True)
sch.parallel(loop=l82)
l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102 = sch.get_loops(block=b68)
l103 = sch.fuse(l83, preserve_unit_iters=True)
sch.parallel(loop=l103)
l104 = sch.fuse(l102, preserve_unit_iters=True)
sch.vectorize(loop=l104)
sch.annotate(block_or_loop=l103, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l103, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109 = sch.get_loops(block=b69)
l110 = sch.fuse(l105, l106, l107, l108, l109, preserve_unit_iters=True)
l111, l112 = sch.split(loop=l110, factors=[None, 64], preserve_unit_iters=True)
sch.parallel(loop=l111)
sch.vectorize(loop=l112)
b113 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133 = sch.get_loops(block=b113)
b134 = sch.decompose_reduction(block=b113, loop=l118)
2024-04-30 13:08:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2367: GFLOPs: 2.0876. Time: 1772434.9717 us. Best GFLOPs: 987.5055
2024-04-30 13:08:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2368: GFLOPs: 5.5236. Time: 669889.0657 us. Best GFLOPs: 987.5055
2024-04-30 13:08:00 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-30 13:08:02 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-30 13:08:06 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 13:08:06 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-30 13:08:19 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 13:08:33 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 13:08:47 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 13:09:01 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 13:09:10 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9162  0.8274  0.8131  0.7951  0.7832  0.7802  0.7734  0.7678  0.7660  0.7555  0.7555  0.7331  0.7290  0.7177  0.7177  0.7117
[17 : 32]:	0.7116  0.7010  0.7004  0.6867  0.6863  0.6841  0.6745  0.6618  0.6488  0.6488  0.6411  0.6382  0.6371  0.6305  0.6277  0.6265
[33 : 48]:	0.6238  0.6235  0.6160  0.6151  0.6138  0.6068  0.6058  0.6044  0.5984  0.5959  0.5950  0.5900  0.5880  0.5876  0.5866  0.5852
[49 : 64]:	0.5792  0.5768  0.5677  0.5664  0.5613  0.5609  0.5608  0.5598  0.5584  0.5557  0.5552  0.5532  0.5486  0.5440  0.5420  0.5351
2024-04-30 13:09:10 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-30 13:09:11 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-30 13:11:03 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2369: GFLOPs: 1005.7953. Time: 3678.8588 us. Best GFLOPs: 1005.7953
2024-04-30 13:11:03 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2370: GFLOPs: 841.6464. Time: 4396.3580 us. Best GFLOPs: 1005.7953
2024-04-30 13:11:03 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2371: GFLOPs: 823.1574. Time: 4495.1049 us. Best GFLOPs: 1005.7953
2024-04-30 13:11:03 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2372: GFLOPs: 798.8865. Time: 4631.6703 us. Best GFLOPs: 1005.7953
2024-04-30 13:11:03 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2373: GFLOPs: 808.0912. Time: 4578.9126 us. Best GFLOPs: 1005.7953
2024-04-30 13:11:03 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2374: GFLOPs: 795.4082. Time: 4651.9243 us. Best GFLOPs: 1005.7953
2024-04-30 13:11:03 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2375: GFLOPs: 826.0008. Time: 4479.6312 us. Best GFLOPs: 1005.7953
2024-04-30 13:11:03 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2376: GFLOPs: 796.9276. Time: 4643.0555 us. Best GFLOPs: 1005.7953
2024-04-30 13:11:03 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2377: GFLOPs: 874.7566. Time: 4229.9525 us. Best GFLOPs: 1005.7953
2024-04-30 13:11:03 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2378: GFLOPs: 859.0394. Time: 4307.3451 us. Best GFLOPs: 1005.7953
2024-04-30 13:11:03 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2379: GFLOPs: 864.8269. Time: 4278.5196 us. Best GFLOPs: 1005.7953
2024-04-30 13:11:03 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2380: GFLOPs: 716.6239. Time: 5163.3485 us. Best GFLOPs: 1005.7953
2024-04-30 13:11:03 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2381: GFLOPs: 772.5167. Time: 4789.7721 us. Best GFLOPs: 1005.7953
2024-04-30 13:11:03 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2382: GFLOPs: 796.9668. Time: 4642.8269 us. Best GFLOPs: 1005.7953
2024-04-30 13:11:03 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2383: GFLOPs: 727.5807. Time: 5085.5922 us. Best GFLOPs: 1005.7953
2024-04-30 13:11:03 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2384: GFLOPs: 767.7691. Time: 4819.3902 us. Best GFLOPs: 1005.7953
2024-04-30 13:11:03 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2385: GFLOPs: 732.6582. Time: 5050.3481 us. Best GFLOPs: 1005.7953
2024-04-30 13:11:03 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2386: GFLOPs: 818.9162. Time: 4518.3853 us. Best GFLOPs: 1005.7953
2024-04-30 13:11:03 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2387: GFLOPs: 693.4592. Time: 5335.8278 us. Best GFLOPs: 1005.7953
2024-04-30 13:11:03 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2388: GFLOPs: 830.9426. Time: 4452.9898 us. Best GFLOPs: 1005.7953
2024-04-30 13:11:03 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2389: GFLOPs: 694.7887. Time: 5325.6176 us. Best GFLOPs: 1005.7953
2024-04-30 13:11:03 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2390: GFLOPs: 651.2762. Time: 5681.4279 us. Best GFLOPs: 1005.7953
2024-04-30 13:11:03 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2391: GFLOPs: 831.2092. Time: 4451.5616 us. Best GFLOPs: 1005.7953
2024-04-30 13:11:03 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2392: GFLOPs: 701.7002. Time: 5273.1625 us. Best GFLOPs: 1005.7953
2024-04-30 13:11:03 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2393: GFLOPs: 541.4563. Time: 6833.7539 us. Best GFLOPs: 1005.7953
2024-04-30 13:11:03 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2394: GFLOPs: 844.1144. Time: 4383.5042 us. Best GFLOPs: 1005.7953
2024-04-30 13:11:03 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2395: GFLOPs: 688.5881. Time: 5373.5737 us. Best GFLOPs: 1005.7953
2024-04-30 13:11:03 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2396: GFLOPs: 689.5109. Time: 5366.3820 us. Best GFLOPs: 1005.7953
2024-04-30 13:11:03 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2397: GFLOPs: 670.2335. Time: 5520.7315 us. Best GFLOPs: 1005.7953
2024-04-30 13:11:03 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2398: GFLOPs: 755.4408. Time: 4898.0397 us. Best GFLOPs: 1005.7953
2024-04-30 13:11:03 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2399: GFLOPs: 686.2692. Time: 5391.7308 us. Best GFLOPs: 1005.7953
2024-04-30 13:11:03 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2400: GFLOPs: 733.6155. Time: 5043.7580 us. Best GFLOPs: 1005.7953
2024-04-30 13:11:03 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2401: GFLOPs: 704.6390. Time: 5251.1696 us. Best GFLOPs: 1005.7953
2024-04-30 13:11:03 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2402: GFLOPs: 666.6605. Time: 5550.3197 us. Best GFLOPs: 1005.7953
2024-04-30 13:11:03 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2403: GFLOPs: 348.7070. Time: 10611.1403 us. Best GFLOPs: 1005.7953
2024-04-30 13:11:03 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2404: GFLOPs: 504.6658. Time: 7331.9386 us. Best GFLOPs: 1005.7953
2024-04-30 13:11:03 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2405: GFLOPs: 695.3407. Time: 5321.3897 us. Best GFLOPs: 1005.7953
2024-04-30 13:11:03 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2406: GFLOPs: 632.8147. Time: 5847.1764 us. Best GFLOPs: 1005.7953
2024-04-30 13:11:03 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2407: GFLOPs: 779.8852. Time: 4744.5173 us. Best GFLOPs: 1005.7953
2024-04-30 13:11:03 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2408: GFLOPs: 629.3615. Time: 5879.2587 us. Best GFLOPs: 1005.7953
2024-04-30 13:11:03 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2409: GFLOPs: 684.5604. Time: 5405.1895 us. Best GFLOPs: 1005.7953
2024-04-30 13:11:03 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2410: GFLOPs: 576.7633. Time: 6415.4206 us. Best GFLOPs: 1005.7953
2024-04-30 13:11:03 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2411: GFLOPs: 644.9002. Time: 5737.5995 us. Best GFLOPs: 1005.7953
2024-04-30 13:11:03 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2412: GFLOPs: 616.6666. Time: 6000.2905 us. Best GFLOPs: 1005.7953
2024-04-30 13:11:03 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2413: GFLOPs: 604.3619. Time: 6122.4562 us. Best GFLOPs: 1005.7953
2024-04-30 13:11:03 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2414: GFLOPs: 596.6258. Time: 6201.8416 us. Best GFLOPs: 1005.7953
2024-04-30 13:11:03 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2415: GFLOPs: 726.6020. Time: 5092.4424 us. Best GFLOPs: 1005.7953
2024-04-30 13:11:03 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2416: GFLOPs: 632.4201. Time: 5850.8248 us. Best GFLOPs: 1005.7953
2024-04-30 13:11:03 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2417: GFLOPs: 637.7917. Time: 5801.5473 us. Best GFLOPs: 1005.7953
2024-04-30 13:11:03 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2418: GFLOPs: 583.2226. Time: 6344.3681 us. Best GFLOPs: 1005.7953
2024-04-30 13:11:03 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2419: GFLOPs: 626.1820. Time: 5909.1107 us. Best GFLOPs: 1005.7953
2024-04-30 13:11:03 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2420: GFLOPs: 381.0943. Time: 9709.3517 us. Best GFLOPs: 1005.7953
2024-04-30 13:11:03 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2421: GFLOPs: 697.2617. Time: 5306.7288 us. Best GFLOPs: 1005.7953
2024-04-30 13:11:03 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2422: GFLOPs: 324.1302. Time: 11415.7191 us. Best GFLOPs: 1005.7953
2024-04-30 13:11:03 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2423: GFLOPs: 551.9025. Time: 6704.4069 us. Best GFLOPs: 1005.7953
2024-04-30 13:11:03 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2424: GFLOPs: 112.4047. Time: 32918.3715 us. Best GFLOPs: 1005.7953
2024-04-30 13:11:03 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2425: GFLOPs: 290.9744. Time: 12716.5092 us. Best GFLOPs: 1005.7953
2024-04-30 13:11:03 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2426: GFLOPs: 554.2159. Time: 6676.4218 us. Best GFLOPs: 1005.7953
2024-04-30 13:11:03 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2427: GFLOPs: 284.2030. Time: 13019.4920 us. Best GFLOPs: 1005.7953
2024-04-30 13:11:03 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2428: GFLOPs: 492.9380. Time: 7506.3773 us. Best GFLOPs: 1005.7953
2024-04-30 13:11:03 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2429: GFLOPs: 619.0966. Time: 5976.7389 us. Best GFLOPs: 1005.7953
2024-04-30 13:11:03 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2430: GFLOPs: 40.8113. Time: 90665.5040 us. Best GFLOPs: 1005.7953
2024-04-30 13:11:03 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2431: GFLOPs: 4.9529. Time: 747066.6390 us. Best GFLOPs: 1005.7953
2024-04-30 13:11:03 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2432: GFLOPs: 27.6768. Time: 133692.4443 us. Best GFLOPs: 1005.7953
2024-04-30 13:11:03 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-30 13:11:04 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-30 13:11:09 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 13:11:09 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-30 13:11:22 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 13:11:36 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 13:11:50 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 13:12:03 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 13:12:12 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.8191  0.8175  0.7756  0.7555  0.7549  0.7519  0.7482  0.7265  0.7261  0.7088  0.7077  0.6924  0.6887  0.6804  0.6731  0.6722
[17 : 32]:	0.6631  0.6621  0.6576  0.6527  0.6523  0.6472  0.6438  0.6411  0.6398  0.6381  0.6293  0.6289  0.6131  0.6131  0.6116  0.6064
[33 : 48]:	0.5971  0.5942  0.5923  0.5919  0.5918  0.5839  0.5831  0.5811  0.5802  0.5765  0.5762  0.5710  0.5673  0.5606  0.5595  0.5586
[49 : 64]:	0.5510  0.5510  0.5485  0.5310  0.5277  0.5275  0.5240  0.5215  0.5201  0.5194  0.5192  0.5169  0.5161  0.5161  0.5147  0.5115
2024-04-30 13:12:12 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-30 13:12:12 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-30 13:14:35 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2433: GFLOPs: 830.3006. Time: 4456.4331 us. Best GFLOPs: 1005.7953
2024-04-30 13:14:35 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2434: GFLOPs: 834.3883. Time: 4434.6006 us. Best GFLOPs: 1005.7953
2024-04-30 13:14:35 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2435: GFLOPs: 853.8475. Time: 4333.5362 us. Best GFLOPs: 1005.7953
2024-04-30 13:14:35 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2436: GFLOPs: 820.5243. Time: 4509.5301 us. Best GFLOPs: 1005.7953
2024-04-30 13:14:35 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2437: GFLOPs: 377.0965. Time: 9812.2868 us. Best GFLOPs: 1005.7953
2024-04-30 13:14:35 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2438: GFLOPs: 127.7504. Time: 28964.1308 us. Best GFLOPs: 1005.7953
2024-04-30 13:14:35 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2439: GFLOPs: 438.0476. Time: 8446.9792 us. Best GFLOPs: 1005.7953
2024-04-30 13:14:35 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2440: GFLOPs: 712.3069. Time: 5194.6413 us. Best GFLOPs: 1005.7953
2024-04-30 13:14:35 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2441: GFLOPs: 798.7290. Time: 4632.5837 us. Best GFLOPs: 1005.7953
2024-04-30 13:14:35 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2442: GFLOPs: 736.5449. Time: 5023.6978 us. Best GFLOPs: 1005.7953
2024-04-30 13:14:35 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2443: GFLOPs: 493.8374. Time: 7492.7074 us. Best GFLOPs: 1005.7953
2024-04-30 13:14:35 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2444: GFLOPs: 827.6575. Time: 4470.6642 us. Best GFLOPs: 1005.7953
2024-04-30 13:14:35 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2445: GFLOPs: 737.2591. Time: 5018.8315 us. Best GFLOPs: 1005.7953
2024-04-30 13:14:35 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2446: GFLOPs: 811.4236. Time: 4560.1079 us. Best GFLOPs: 1005.7953
2024-04-30 13:14:35 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2447: GFLOPs: 738.7977. Time: 5008.3790 us. Best GFLOPs: 1005.7953
2024-04-30 13:14:35 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2448: GFLOPs: 697.3107. Time: 5306.3560 us. Best GFLOPs: 1005.7953
2024-04-30 13:14:35 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2449: GFLOPs: 672.0454. Time: 5505.8467 us. Best GFLOPs: 1005.7953
2024-04-30 13:14:35 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2450: GFLOPs: 522.4108. Time: 7082.8917 us. Best GFLOPs: 1005.7953
2024-04-30 13:14:35 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2451: GFLOPs: 602.3726. Time: 6142.6744 us. Best GFLOPs: 1005.7953
2024-04-30 13:14:35 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2452: GFLOPs: 685.0498. Time: 5401.3281 us. Best GFLOPs: 1005.7953
2024-04-30 13:14:35 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2453: GFLOPs: 714.9571. Time: 5175.3859 us. Best GFLOPs: 1005.7953
2024-04-30 13:14:35 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2454: GFLOPs: 658.3503. Time: 5620.3804 us. Best GFLOPs: 1005.7953
2024-04-30 13:14:35 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2455: GFLOPs: 631.4131. Time: 5860.1557 us. Best GFLOPs: 1005.7953
2024-04-30 13:14:35 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2456: GFLOPs: 652.6137. Time: 5669.7847 us. Best GFLOPs: 1005.7953
2024-04-30 13:14:35 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2457: GFLOPs: 685.5516. Time: 5397.3748 us. Best GFLOPs: 1005.7953
2024-04-30 13:14:35 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2458: GFLOPs: 615.9847. Time: 6006.9332 us. Best GFLOPs: 1005.7953
2024-04-30 13:14:35 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2459: GFLOPs: 682.2477. Time: 5423.5127 us. Best GFLOPs: 1005.7953
2024-04-30 13:14:35 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2460: GFLOPs: 626.3718. Time: 5907.3209 us. Best GFLOPs: 1005.7953
2024-04-30 13:14:35 [INFO] [task_scheduler.cc:121] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2461: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(512)), "float32"), p1: T.Buffer((T.int64(32), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused in T.parallel(T.int64(224), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(7), T.int64(2), T.int64(16), T.int64(1), T.int64(4), T.int64(1), T.int64(2), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(28) * T.int64(4) + oc_chunk_1 * T.int64(4) + oc_chunk_2_init * T.int64(4) + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(28) // T.int64(7) * T.int64(7) + oh_1 * T.int64(7) + oh_2_init + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(7) * T.int64(4) + ow_1 * T.int64(4) + ow_2_init * T.int64(2) + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(16), oc_block_1 * T.int64(16) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0 in range(T.int64(128)):
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(9), T.int64(6)):
                        for ax4_fused in T.vectorized(T.int64(4)):
                            with T.block("data_pad"):
                                v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                                v_i2 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(28) // T.int64(7) * T.int64(7) + ax2)
                                v_i3 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(7) * T.int64(4) + ax3)
                                v_i4 = T.axis.spatial(T.int64(512), ic_0 * T.int64(4) + ax4_fused)
                                T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                                T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                                data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                    for kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(7), T.int64(2), T.int64(16), T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(1), T.int64(2), T.int64(1)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(28) * T.int64(4) + oc_chunk_1 * T.int64(4) + oc_chunk_2 * T.int64(4) + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(28) // T.int64(7) * T.int64(7) + oh_1 * T.int64(7) + oh_2 + oh_3)
                            v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(7) * T.int64(4) + ow_1 * T.int64(4) + ow_2 * T.int64(2) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_1 * T.int64(16) + oc_block_2 + oc_block_3)
                            v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(4) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
            for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(4), T.int64(7)):
                for ax3_ax4_fused in T.vectorized(T.int64(64)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(28) * T.int64(4) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(28) // T.int64(7) * T.int64(7) + ax2)
                        v_ax3 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(7) * T.int64(4) + ax3_ax4_fused // T.int64(16))
                        v_ax4 = T.axis.spatial(T.int64(16), ax3_ax4_fused % T.int64(16))
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[8, 1, 1, 4])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[4, 1, 7, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[7, 1, 2, 2])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 16, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[128, 4])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=10)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86 = sch.get_loops(block=b68)
l87 = sch.fuse(l71, l72, l73, l74, l75, preserve_unit_iters=True)
sch.parallel(loop=l87)
l88 = sch.fuse(l86, preserve_unit_iters=True)
sch.vectorize(loop=l88)
l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107, l108, l109, l110 = sch.get_loops(block=b69)
l111 = sch.fuse(l89, preserve_unit_iters=True)
sch.parallel(loop=l111)
sch.annotate(block_or_loop=l111, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l111, ann_key="pragma_unroll_explicit", ann_val=1)
l112, l113, l114, l115, l116, l117 = sch.get_loops(block=b70)
l118 = sch.fuse(l116, l117, preserve_unit_iters=True)
sch.vectorize(loop=l118)
b119 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141 = sch.get_loops(block=b119)
b142 = sch.decompose_reduction(block=b119, loop=l126)
2024-04-30 13:14:35 [INFO] [task_scheduler.cc:121] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2462: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(512)), "float32"), p1: T.Buffer((T.int64(32), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_fused_fused in T.parallel(T.int64(224), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for oc_block_0 in range(T.int64(1)):
                for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                    for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(7), T.int64(2), T.int64(16), T.int64(1), T.int64(4), T.int64(1), T.int64(2), T.int64(1)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(28) * T.int64(4) + oc_chunk_1 * T.int64(4) + oc_chunk_2_init * T.int64(4) + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(28) // T.int64(7) * T.int64(7) + oh_1 * T.int64(7) + oh_2_init + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(7) * T.int64(4) + ow_1 * T.int64(4) + ow_2_init * T.int64(2) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2_init + oc_block_3_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                    for ic_0 in range(T.int64(128)):
                        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(9), T.int64(6)):
                            for ax4_fused in T.vectorized(T.int64(4)):
                                with T.block("data_pad"):
                                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                                    v_i2 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(28) // T.int64(7) * T.int64(7) + ax2)
                                    v_i3 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(7) * T.int64(4) + ax3)
                                    v_i4 = T.axis.spatial(T.int64(512), ic_0 * T.int64(4) + ax4_fused)
                                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                        for kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(7), T.int64(2), T.int64(16), T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(1), T.int64(2), T.int64(1)):
                            with T.block("conv2d_NCHWc_update"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                                v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(28) * T.int64(4) + oc_chunk_1 * T.int64(4) + oc_chunk_2 * T.int64(4) + oc_chunk_3)
                                v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(28) // T.int64(7) * T.int64(7) + oh_1 * T.int64(7) + oh_2 + oh_3)
                                v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(7) * T.int64(4) + ow_1 * T.int64(4) + ow_2 * T.int64(2) + ow_3)
                                v_oc_block = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2 + oc_block_3)
                                v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(4) + ic_1)
                                v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                                v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                                T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
                for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(4), T.int64(7)):
                    for ax3_ax4_fused in T.vectorized(T.int64(64)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(28) * T.int64(4) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(28) // T.int64(7) * T.int64(7) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(7) * T.int64(4) + ax3_ax4_fused // T.int64(16))
                            v_ax4 = T.axis.spatial(T.int64(16), ax3_ax4_fused % T.int64(16))
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[8, 1, 1, 4])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[4, 1, 7, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[7, 1, 2, 2])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 16, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[128, 4])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=32)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=10)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86 = sch.get_loops(block=b68)
l87 = sch.fuse(l71, l72, l73, l74, preserve_unit_iters=True)
sch.parallel(loop=l87)
l88 = sch.fuse(l86, preserve_unit_iters=True)
sch.vectorize(loop=l88)
l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107, l108, l109, l110, l111 = sch.get_loops(block=b69)
l112 = sch.fuse(l89, preserve_unit_iters=True)
sch.parallel(loop=l112)
sch.annotate(block_or_loop=l112, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l112, ann_key="pragma_unroll_explicit", ann_val=1)
l113, l114, l115, l116, l117, l118, l119 = sch.get_loops(block=b70)
l120 = sch.fuse(l118, l119, preserve_unit_iters=True)
sch.vectorize(loop=l120)
b121 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141, l142, l143, l144 = sch.get_loops(block=b121)
b145 = sch.decompose_reduction(block=b121, loop=l129)
2024-04-30 13:14:35 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2463: GFLOPs: 639.9659. Time: 5781.8377 us. Best GFLOPs: 1005.7953
2024-04-30 13:14:35 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2464: GFLOPs: 634.2422. Time: 5834.0153 us. Best GFLOPs: 1005.7953
2024-04-30 13:14:35 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2465: GFLOPs: 589.7181. Time: 6274.4872 us. Best GFLOPs: 1005.7953
2024-04-30 13:14:35 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2466: GFLOPs: 631.0731. Time: 5863.3124 us. Best GFLOPs: 1005.7953
2024-04-30 13:14:35 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2467: GFLOPs: 513.4313. Time: 7206.7659 us. Best GFLOPs: 1005.7953
2024-04-30 13:14:35 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2468: GFLOPs: 760.2495. Time: 4867.0589 us. Best GFLOPs: 1005.7953
2024-04-30 13:14:35 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2469: GFLOPs: 706.2717. Time: 5239.0305 us. Best GFLOPs: 1005.7953
2024-04-30 13:14:35 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2470: GFLOPs: 605.9998. Time: 6105.9079 us. Best GFLOPs: 1005.7953
2024-04-30 13:14:35 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2471: GFLOPs: 110.7442. Time: 33411.9340 us. Best GFLOPs: 1005.7953
2024-04-30 13:14:35 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2472: GFLOPs: 630.4144. Time: 5869.4387 us. Best GFLOPs: 1005.7953
2024-04-30 13:14:35 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2473: GFLOPs: 617.9956. Time: 5987.3876 us. Best GFLOPs: 1005.7953
2024-04-30 13:14:35 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2474: GFLOPs: 597.7120. Time: 6190.5711 us. Best GFLOPs: 1005.7953
2024-04-30 13:14:35 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2475: GFLOPs: 632.8315. Time: 5847.0211 us. Best GFLOPs: 1005.7953
2024-04-30 13:14:35 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2476: GFLOPs: 380.1020. Time: 9734.7001 us. Best GFLOPs: 1005.7953
2024-04-30 13:14:35 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2477: GFLOPs: 625.0825. Time: 5919.5046 us. Best GFLOPs: 1005.7953
2024-04-30 13:14:35 [INFO] [task_scheduler.cc:121] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2478: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(512)), "float32"), p1: T.Buffer((T.int64(32), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_fused_fused in T.parallel(T.int64(224), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for oc_block_0 in range(T.int64(1)):
                for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                    for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(2), T.int64(7), T.int64(16), T.int64(1), T.int64(4), T.int64(2), T.int64(1), T.int64(1)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(28) * T.int64(4) + oc_chunk_1 * T.int64(4) + oc_chunk_2_init * T.int64(4) + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(28) // T.int64(4) * T.int64(4) + oh_1 * T.int64(4) + oh_2_init * T.int64(2) + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(4) * T.int64(7) + ow_1 * T.int64(7) + ow_2_init + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2_init + oc_block_3_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                    for ic_0, kh_0 in T.grid(T.int64(128), T.int64(3)):
                        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(9)):
                            for ax4_fused in T.vectorized(T.int64(4)):
                                with T.block("data_pad"):
                                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                                    v_i2 = T.axis.spatial(T.int64(30), kh_0 + n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(28) // T.int64(4) * T.int64(4) + ax2)
                                    v_i3 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(4) * T.int64(7) + ax3)
                                    v_i4 = T.axis.spatial(T.int64(512), ic_0 * T.int64(4) + ax4_fused)
                                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                        for kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(3), T.int64(1), T.int64(1), T.int64(2), T.int64(7), T.int64(16), T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(2), T.int64(1), T.int64(1)):
                            with T.block("conv2d_NCHWc_update"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                                v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(28) * T.int64(4) + oc_chunk_1 * T.int64(4) + oc_chunk_2 * T.int64(4) + oc_chunk_3)
                                v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(28) // T.int64(4) * T.int64(4) + oh_1 * T.int64(4) + oh_2 * T.int64(2) + oh_3)
                                v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(4) * T.int64(7) + ow_1 * T.int64(7) + ow_2 + ow_3)
                                v_oc_block = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2 + oc_block_3)
                                v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(4) + ic_1)
                                v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                                v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                                T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(4), T.int64(4), T.int64(7)):
                    for ax4_fused in T.vectorized(T.int64(16)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(28) * T.int64(4) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(28) // T.int64(4) * T.int64(4) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(4) * T.int64(7) + ax3)
                            v_ax4 = T.axis.spatial(T.int64(16), ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[8, 1, 1, 4])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[7, 1, 2, 2])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[4, 1, 7, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 16, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[128, 4])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=112)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=11)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87 = sch.get_loops(block=b68)
l88 = sch.fuse(l71, l72, l73, l74, preserve_unit_iters=True)
sch.parallel(loop=l88)
l89 = sch.fuse(l87, preserve_unit_iters=True)
sch.vectorize(loop=l89)
l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107, l108, l109, l110, l111, l112 = sch.get_loops(block=b69)
l113 = sch.fuse(l90, preserve_unit_iters=True)
sch.parallel(loop=l113)
sch.annotate(block_or_loop=l113, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l113, ann_key="pragma_unroll_explicit", ann_val=1)
l114, l115, l116, l117, l118, l119, l120 = sch.get_loops(block=b70)
l121 = sch.fuse(l120, preserve_unit_iters=True)
sch.vectorize(loop=l121)
b122 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141, l142, l143, l144, l145 = sch.get_loops(block=b122)
b146 = sch.decompose_reduction(block=b122, loop=l130)
2024-04-30 13:14:35 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2479: GFLOPs: 508.9262. Time: 7270.5606 us. Best GFLOPs: 1005.7953
2024-04-30 13:14:35 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2480: GFLOPs: 348.1472. Time: 10628.2028 us. Best GFLOPs: 1005.7953
2024-04-30 13:14:35 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2481: GFLOPs: 534.0156. Time: 6928.9718 us. Best GFLOPs: 1005.7953
2024-04-30 13:14:36 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2482: GFLOPs: 531.6474. Time: 6959.8370 us. Best GFLOPs: 1005.7953
2024-04-30 13:14:36 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2483: GFLOPs: 612.3925. Time: 6042.1692 us. Best GFLOPs: 1005.7953
2024-04-30 13:14:36 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2484: GFLOPs: 701.4978. Time: 5274.6835 us. Best GFLOPs: 1005.7953
2024-04-30 13:14:36 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2485: GFLOPs: 527.8351. Time: 7010.1035 us. Best GFLOPs: 1005.7953
2024-04-30 13:14:36 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2486: GFLOPs: 809.2365. Time: 4572.4320 us. Best GFLOPs: 1005.7953
2024-04-30 13:14:36 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2487: GFLOPs: 101.3795. Time: 36498.3123 us. Best GFLOPs: 1005.7953
2024-04-30 13:14:36 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2488: GFLOPs: 685.1433. Time: 5400.5909 us. Best GFLOPs: 1005.7953
2024-04-30 13:14:36 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2489: GFLOPs: 582.4760. Time: 6352.5001 us. Best GFLOPs: 1005.7953
2024-04-30 13:14:36 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2490: GFLOPs: 449.6558. Time: 8228.9149 us. Best GFLOPs: 1005.7953
2024-04-30 13:14:36 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2491: GFLOPs: 594.0126. Time: 6229.1250 us. Best GFLOPs: 1005.7953
2024-04-30 13:14:36 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2492: GFLOPs: 501.2766. Time: 7381.5107 us. Best GFLOPs: 1005.7953
2024-04-30 13:14:36 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2493: GFLOPs: 125.5435. Time: 29473.2710 us. Best GFLOPs: 1005.7953
2024-04-30 13:14:36 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2494: GFLOPs: 2.4507. Time: 1509818.9193 us. Best GFLOPs: 1005.7953
2024-04-30 13:14:36 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2495: GFLOPs: 4.7474. Time: 779411.0783 us. Best GFLOPs: 1005.7953
2024-04-30 13:14:36 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2496: GFLOPs: 75.2614. Time: 49164.3900 us. Best GFLOPs: 1005.7953
2024-04-30 13:17:35 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-30 13:17:37 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-30 13:17:41 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 13:17:41 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-30 13:17:54 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 13:18:08 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 13:18:22 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 13:18:36 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 13:18:45 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.8138  0.7954  0.7859  0.7693  0.7412  0.7318  0.7187  0.7127  0.7045  0.6992  0.6952  0.6743  0.6741  0.6732  0.6722  0.6678
[17 : 32]:	0.6568  0.6529  0.6524  0.6523  0.6452  0.6420  0.6406  0.6404  0.6402  0.6399  0.6347  0.6335  0.6333  0.6330  0.6268  0.6175
[33 : 48]:	0.6151  0.6134  0.6127  0.6115  0.6097  0.6054  0.6041  0.6029  0.5962  0.5953  0.5907  0.5873  0.5860  0.5852  0.5845  0.5822
[49 : 64]:	0.5815  0.5777  0.5652  0.5607  0.5606  0.5570  0.5563  0.5534  0.5526  0.5525  0.5525  0.5524  0.5418  0.5252  0.5240  0.5237
2024-04-30 13:18:45 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-30 13:18:45 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-30 13:21:23 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2497: GFLOPs: 465.2756. Time: 7952.6612 us. Best GFLOPs: 1005.7953
2024-04-30 13:21:23 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2498: GFLOPs: 803.5654. Time: 4604.7018 us. Best GFLOPs: 1005.7953
2024-04-30 13:21:23 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2499: GFLOPs: 775.1399. Time: 4773.5625 us. Best GFLOPs: 1005.7953
2024-04-30 13:21:23 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2500: GFLOPs: 95.6371. Time: 38689.7820 us. Best GFLOPs: 1005.7953
2024-04-30 13:21:23 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2501: GFLOPs: 807.8057. Time: 4580.5309 us. Best GFLOPs: 1005.7953
2024-04-30 13:21:23 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2502: GFLOPs: 764.8560. Time: 4837.7460 us. Best GFLOPs: 1005.7953
2024-04-30 13:21:23 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2503: GFLOPs: 79.2210. Time: 46707.0547 us. Best GFLOPs: 1005.7953
2024-04-30 13:21:23 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2504: GFLOPs: 375.2982. Time: 9859.3040 us. Best GFLOPs: 1005.7953
2024-04-30 13:21:23 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2505: GFLOPs: 677.9797. Time: 5457.6543 us. Best GFLOPs: 1005.7953
2024-04-30 13:21:23 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2506: GFLOPs: 678.0068. Time: 5457.4364 us. Best GFLOPs: 1005.7953
2024-04-30 13:21:23 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2507: GFLOPs: 711.1440. Time: 5203.1364 us. Best GFLOPs: 1005.7953
2024-04-30 13:21:23 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2508: GFLOPs: 705.8412. Time: 5242.2257 us. Best GFLOPs: 1005.7953
2024-04-30 13:21:23 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2509: GFLOPs: 589.5336. Time: 6276.4514 us. Best GFLOPs: 1005.7953
2024-04-30 13:21:23 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2510: GFLOPs: 695.9809. Time: 5316.4949 us. Best GFLOPs: 1005.7953
2024-04-30 13:21:23 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2511: GFLOPs: 636.4049. Time: 5814.1899 us. Best GFLOPs: 1005.7953
2024-04-30 13:21:23 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2512: GFLOPs: 91.6605. Time: 40368.2913 us. Best GFLOPs: 1005.7953
2024-04-30 13:21:23 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2513: GFLOPs: 693.1960. Time: 5337.8537 us. Best GFLOPs: 1005.7953
2024-04-30 13:21:23 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2514: GFLOPs: 696.5510. Time: 5312.1438 us. Best GFLOPs: 1005.7953
2024-04-30 13:21:23 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2515: GFLOPs: 633.7500. Time: 5838.5470 us. Best GFLOPs: 1005.7953
2024-04-30 13:21:23 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2516: GFLOPs: 687.7255. Time: 5380.3135 us. Best GFLOPs: 1005.7953
2024-04-30 13:21:23 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2517: GFLOPs: 709.5364. Time: 5214.9246 us. Best GFLOPs: 1005.7953
2024-04-30 13:21:23 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2518: GFLOPs: 682.0001. Time: 5425.4816 us. Best GFLOPs: 1005.7953
2024-04-30 13:21:23 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2519: GFLOPs: 710.5039. Time: 5207.8234 us. Best GFLOPs: 1005.7953
2024-04-30 13:21:23 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2520: GFLOPs: 598.7645. Time: 6179.6903 us. Best GFLOPs: 1005.7953
2024-04-30 13:21:23 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2521: GFLOPs: 619.3642. Time: 5974.1567 us. Best GFLOPs: 1005.7953
2024-04-30 13:21:23 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2522: GFLOPs: 627.3006. Time: 5898.5741 us. Best GFLOPs: 1005.7953
2024-04-30 13:21:23 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2523: GFLOPs: 600.9411. Time: 6157.3069 us. Best GFLOPs: 1005.7953
2024-04-30 13:21:23 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2524: GFLOPs: 737.3937. Time: 5017.9152 us. Best GFLOPs: 1005.7953
2024-04-30 13:21:23 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2525: GFLOPs: 94.4448. Time: 39178.2107 us. Best GFLOPs: 1005.7953
2024-04-30 13:21:23 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2526: GFLOPs: 664.8431. Time: 5565.4917 us. Best GFLOPs: 1005.7953
2024-04-30 13:21:23 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2527: GFLOPs: 697.7130. Time: 5303.2963 us. Best GFLOPs: 1005.7953
2024-04-30 13:21:23 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2528: GFLOPs: 558.7705. Time: 6622.0017 us. Best GFLOPs: 1005.7953
2024-04-30 13:21:23 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2529: GFLOPs: 386.3908. Time: 9576.2593 us. Best GFLOPs: 1005.7953
2024-04-30 13:21:23 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2530: GFLOPs: 504.0197. Time: 7341.3375 us. Best GFLOPs: 1005.7953
2024-04-30 13:21:23 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2531: GFLOPs: 494.4900. Time: 7482.8193 us. Best GFLOPs: 1005.7953
2024-04-30 13:21:23 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2532: GFLOPs: 599.0811. Time: 6176.4244 us. Best GFLOPs: 1005.7953
2024-04-30 13:21:23 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2533: GFLOPs: 636.2860. Time: 5815.2766 us. Best GFLOPs: 1005.7953
2024-04-30 13:21:23 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2534: GFLOPs: 338.9825. Time: 10915.5446 us. Best GFLOPs: 1005.7953
2024-04-30 13:21:23 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2535: GFLOPs: 622.7897. Time: 5941.2979 us. Best GFLOPs: 1005.7953
2024-04-30 13:21:23 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2536: GFLOPs: 597.6951. Time: 6190.7464 us. Best GFLOPs: 1005.7953
2024-04-30 13:21:23 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2537: GFLOPs: 593.2658. Time: 6236.9665 us. Best GFLOPs: 1005.7953
2024-04-30 13:21:23 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2538: GFLOPs: 568.3987. Time: 6509.8304 us. Best GFLOPs: 1005.7953
2024-04-30 13:21:23 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2539: GFLOPs: 470.5158. Time: 7864.0908 us. Best GFLOPs: 1005.7953
2024-04-30 13:21:23 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2540: GFLOPs: 347.3865. Time: 10651.4755 us. Best GFLOPs: 1005.7953
2024-04-30 13:21:23 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2541: GFLOPs: 620.9838. Time: 5958.5757 us. Best GFLOPs: 1005.7953
2024-04-30 13:21:23 [INFO] [task_scheduler.cc:121] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2542: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(512)), "float32"), p1: T.Buffer((T.int64(32), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)))
        for i0_i1_i2_i3_fused in T.parallel(T.int64(900)):
            for i4 in range(T.int64(512)):
                with T.block("data_pad"):
                    v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_i1 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_i2 = T.axis.spatial(T.int64(30), i0_i1_i2_i3_fused // T.int64(30))
                    v_i3 = T.axis.spatial(T.int64(30), i0_i1_i2_i3_fused % T.int64(30))
                    v_i4 = T.axis.spatial(T.int64(512), i4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
        for n_0_oc_chunk_0_oh_0_ow_0_fused in T.parallel(T.int64(224), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for oc_block_0 in range(T.int64(1)):
                for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                    for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(2), T.int64(7), T.int64(16), T.int64(1), T.int64(4), T.int64(1), T.int64(2), T.int64(1)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_fused // T.int64(28) * T.int64(4) + oc_chunk_1 * T.int64(4) + oc_chunk_2_init * T.int64(4) + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused % T.int64(28) // T.int64(2) * T.int64(2) + oh_1 * T.int64(2) + oh_2_init + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused % T.int64(2) * T.int64(14) + ow_1 * T.int64(14) + ow_2_init * T.int64(2) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2_init + oc_block_3_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                    for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(128), T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(2), T.int64(7), T.int64(16), T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(1), T.int64(2), T.int64(1)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_fused // T.int64(28) * T.int64(4) + oc_chunk_1 * T.int64(4) + oc_chunk_2 * T.int64(4) + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused % T.int64(28) // T.int64(2) * T.int64(2) + oh_1 * T.int64(2) + oh_2 + oh_3)
                            v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused % T.int64(2) * T.int64(14) + ow_1 * T.int64(14) + ow_2 * T.int64(2) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2 + oc_block_3)
                            v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(4) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(4), T.int64(2), T.int64(14)):
                    for ax4_fused in T.vectorized(T.int64(16)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_fused // T.int64(28) * T.int64(4) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused % T.int64(28) // T.int64(2) * T.int64(2) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused % T.int64(2) * T.int64(14) + ax3)
                            v_ax4 = T.axis.spatial(T.int64(16), ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[8, 1, 1, 4])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[14, 1, 2, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[2, 1, 7, 2])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 16, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[128, 4])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=112)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=-1)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75 = sch.get_loops(block=b68)
l76 = sch.fuse(l71, l72, l73, l74, preserve_unit_iters=True)
sch.parallel(loop=l76)
l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102 = sch.get_loops(block=b69)
l103 = sch.fuse(l77, l78, l79, l80, preserve_unit_iters=True)
sch.parallel(loop=l103)
sch.annotate(block_or_loop=l103, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l103, ann_key="pragma_unroll_explicit", ann_val=1)
l104, l105, l106, l107, l108, l109, l110 = sch.get_loops(block=b70)
l111 = sch.fuse(l110, preserve_unit_iters=True)
sch.vectorize(loop=l111)
b112 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l113, l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135 = sch.get_loops(block=b112)
b136 = sch.decompose_reduction(block=b112, loop=l120)
2024-04-30 13:21:23 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2543: GFLOPs: 504.9560. Time: 7327.7249 us. Best GFLOPs: 1005.7953
2024-04-30 13:21:23 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2544: GFLOPs: 589.2036. Time: 6279.9664 us. Best GFLOPs: 1005.7953
2024-04-30 13:21:23 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2545: GFLOPs: 610.9778. Time: 6056.1597 us. Best GFLOPs: 1005.7953
2024-04-30 13:21:23 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2546: GFLOPs: 622.1125. Time: 5947.7649 us. Best GFLOPs: 1005.7953
2024-04-30 13:21:23 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2547: GFLOPs: 124.9306. Time: 29617.8685 us. Best GFLOPs: 1005.7953
2024-04-30 13:21:23 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2548: GFLOPs: 654.1550. Time: 5656.4253 us. Best GFLOPs: 1005.7953
2024-04-30 13:21:23 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2549: GFLOPs: 566.2228. Time: 6534.8464 us. Best GFLOPs: 1005.7953
2024-04-30 13:21:23 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2550: GFLOPs: 605.3793. Time: 6112.1666 us. Best GFLOPs: 1005.7953
2024-04-30 13:21:23 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2551: GFLOPs: 638.1928. Time: 5797.9016 us. Best GFLOPs: 1005.7953
2024-04-30 13:21:23 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2552: GFLOPs: 605.8111. Time: 6107.8094 us. Best GFLOPs: 1005.7953
2024-04-30 13:21:23 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2553: GFLOPs: 583.0548. Time: 6346.1944 us. Best GFLOPs: 1005.7953
2024-04-30 13:21:23 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2554: GFLOPs: 119.6027. Time: 30937.2415 us. Best GFLOPs: 1005.7953
2024-04-30 13:21:23 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2555: GFLOPs: 126.5107. Time: 29247.9470 us. Best GFLOPs: 1005.7953
2024-04-30 13:21:23 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2556: GFLOPs: 727.5928. Time: 5085.5077 us. Best GFLOPs: 1005.7953
2024-04-30 13:21:23 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2557: GFLOPs: 449.6525. Time: 8228.9744 us. Best GFLOPs: 1005.7953
2024-04-30 13:21:23 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2558: GFLOPs: 42.3671. Time: 87336.2010 us. Best GFLOPs: 1005.7953
2024-04-30 13:21:23 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2559: GFLOPs: 3.5784. Time: 1034019.8120 us. Best GFLOPs: 1005.7953
2024-04-30 13:21:23 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2560: GFLOPs: 1.5860. Time: 2333074.1660 us. Best GFLOPs: 1005.7953
2024-04-30 13:40:33 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-30 13:40:34 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-30 13:40:39 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 13:40:39 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-30 13:40:52 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 13:41:05 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 13:41:20 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 13:41:34 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 13:41:44 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.8080  0.7846  0.7813  0.7572  0.7572  0.7443  0.7329  0.7235  0.7121  0.7027  0.6815  0.6730  0.6661  0.6558  0.6544  0.6535
[17 : 32]:	0.6492  0.6488  0.6477  0.6287  0.6286  0.6235  0.6223  0.6223  0.6186  0.6058  0.5925  0.5925  0.5846  0.5839  0.5774  0.5699
[33 : 48]:	0.5672  0.5619  0.5609  0.5594  0.5591  0.5490  0.5489  0.5461  0.5441  0.5398  0.5361  0.5332  0.5305  0.5277  0.5274  0.5270
[49 : 64]:	0.5174  0.5118  0.5093  0.5077  0.5063  0.5056  0.5048  0.5048  0.5036  0.5029  0.4980  0.4953  0.4921  0.4915  0.4902  0.4889
2024-04-30 13:41:44 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-30 13:41:44 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-30 13:44:18 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2561: GFLOPs: 813.0186. Time: 4551.1616 us. Best GFLOPs: 1005.7953
2024-04-30 13:44:18 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2562: GFLOPs: 787.4498. Time: 4698.9397 us. Best GFLOPs: 1005.7953
2024-04-30 13:44:18 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2563: GFLOPs: 806.8543. Time: 4585.9318 us. Best GFLOPs: 1005.7953
2024-04-30 13:44:18 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2564: GFLOPs: 77.4690. Time: 47763.3763 us. Best GFLOPs: 1005.7953
2024-04-30 13:44:18 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2565: GFLOPs: 759.0887. Time: 4874.5012 us. Best GFLOPs: 1005.7953
2024-04-30 13:44:18 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2566: GFLOPs: 814.7412. Time: 4541.5387 us. Best GFLOPs: 1005.7953
2024-04-30 13:44:18 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2567: GFLOPs: 701.7979. Time: 5272.4283 us. Best GFLOPs: 1005.7953
2024-04-30 13:44:18 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2568: GFLOPs: 725.0151. Time: 5103.5885 us. Best GFLOPs: 1005.7953
2024-04-30 13:44:18 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2569: GFLOPs: 698.4106. Time: 5297.9992 us. Best GFLOPs: 1005.7953
2024-04-30 13:44:18 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2570: GFLOPs: 774.8280. Time: 4775.4842 us. Best GFLOPs: 1005.7953
2024-04-30 13:44:18 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2571: GFLOPs: 637.9255. Time: 5800.3306 us. Best GFLOPs: 1005.7953
2024-04-30 13:44:18 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2572: GFLOPs: 439.7331. Time: 8414.6015 us. Best GFLOPs: 1005.7953
2024-04-30 13:44:18 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2573: GFLOPs: 667.0007. Time: 5547.4888 us. Best GFLOPs: 1005.7953
2024-04-30 13:44:18 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2574: GFLOPs: 678.4036. Time: 5454.2446 us. Best GFLOPs: 1005.7953
2024-04-30 13:44:18 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2575: GFLOPs: 694.0322. Time: 5331.4229 us. Best GFLOPs: 1005.7953
2024-04-30 13:44:18 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2576: GFLOPs: 706.0931. Time: 5240.3558 us. Best GFLOPs: 1005.7953
2024-04-30 13:44:18 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2577: GFLOPs: 709.7975. Time: 5213.0064 us. Best GFLOPs: 1005.7953
2024-04-30 13:44:18 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2578: GFLOPs: 664.5677. Time: 5567.7981 us. Best GFLOPs: 1005.7953
2024-04-30 13:44:18 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2579: GFLOPs: 743.8928. Time: 4974.0758 us. Best GFLOPs: 1005.7953
2024-04-30 13:44:18 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2580: GFLOPs: 556.5232. Time: 6648.7416 us. Best GFLOPs: 1005.7953
2024-04-30 13:44:18 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2581: GFLOPs: 590.5896. Time: 6265.2286 us. Best GFLOPs: 1005.7953
2024-04-30 13:44:18 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2582: GFLOPs: 618.8403. Time: 5979.2141 us. Best GFLOPs: 1005.7953
2024-04-30 13:44:18 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2583: GFLOPs: 583.6709. Time: 6339.4954 us. Best GFLOPs: 1005.7953
2024-04-30 13:44:18 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2584: GFLOPs: 585.3701. Time: 6321.0932 us. Best GFLOPs: 1005.7953
2024-04-30 13:44:18 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2585: GFLOPs: 687.8355. Time: 5379.4532 us. Best GFLOPs: 1005.7953
2024-04-30 13:44:18 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2586: GFLOPs: 634.1704. Time: 5834.6761 us. Best GFLOPs: 1005.7953
2024-04-30 13:44:18 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2587: GFLOPs: 602.6044. Time: 6140.3122 us. Best GFLOPs: 1005.7953
2024-04-30 13:44:18 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2588: GFLOPs: 573.4220. Time: 6452.8030 us. Best GFLOPs: 1005.7953
2024-04-30 13:44:18 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2589: GFLOPs: 583.7330. Time: 6338.8204 us. Best GFLOPs: 1005.7953
2024-04-30 13:44:18 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2590: GFLOPs: 628.7013. Time: 5885.4325 us. Best GFLOPs: 1005.7953
2024-04-30 13:44:18 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2591: GFLOPs: 624.3887. Time: 5926.0821 us. Best GFLOPs: 1005.7953
2024-04-30 13:44:18 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2592: GFLOPs: 557.9492. Time: 6631.7486 us. Best GFLOPs: 1005.7953
2024-04-30 13:44:18 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2593: GFLOPs: 558.8819. Time: 6620.6816 us. Best GFLOPs: 1005.7953
2024-04-30 13:44:18 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2594: GFLOPs: 675.3032. Time: 5479.2854 us. Best GFLOPs: 1005.7953
2024-04-30 13:44:18 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2595: GFLOPs: 571.6336. Time: 6472.9902 us. Best GFLOPs: 1005.7953
2024-04-30 13:44:18 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2596: GFLOPs: 101.8629. Time: 36325.0790 us. Best GFLOPs: 1005.7953
2024-04-30 13:44:18 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2597: GFLOPs: 586.7761. Time: 6305.9473 us. Best GFLOPs: 1005.7953
2024-04-30 13:44:18 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2598: GFLOPs: 565.1231. Time: 6547.5622 us. Best GFLOPs: 1005.7953
2024-04-30 13:44:18 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2599: GFLOPs: 581.0686. Time: 6367.8865 us. Best GFLOPs: 1005.7953
2024-04-30 13:44:18 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2600: GFLOPs: 591.0508. Time: 6260.3402 us. Best GFLOPs: 1005.7953
2024-04-30 13:44:18 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2601: GFLOPs: 753.6752. Time: 4909.5140 us. Best GFLOPs: 1005.7953
2024-04-30 13:44:18 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2602: GFLOPs: 67.2679. Time: 55006.6077 us. Best GFLOPs: 1005.7953
2024-04-30 13:44:18 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2603: GFLOPs: 572.3569. Time: 6464.8101 us. Best GFLOPs: 1005.7953
2024-04-30 13:44:18 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2604: GFLOPs: 108.0907. Time: 34232.1593 us. Best GFLOPs: 1005.7953
2024-04-30 13:44:18 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2605: GFLOPs: 691.6079. Time: 5350.1106 us. Best GFLOPs: 1005.7953
2024-04-30 13:44:18 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2606: GFLOPs: 541.0854. Time: 6838.4378 us. Best GFLOPs: 1005.7953
2024-04-30 13:44:18 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2607: GFLOPs: 596.1443. Time: 6206.8510 us. Best GFLOPs: 1005.7953
2024-04-30 13:44:18 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2608: GFLOPs: 40.1290. Time: 92207.2057 us. Best GFLOPs: 1005.7953
2024-04-30 13:44:18 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2609: GFLOPs: 526.7968. Time: 7023.9203 us. Best GFLOPs: 1005.7953
2024-04-30 13:44:18 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2610: GFLOPs: 550.5295. Time: 6721.1270 us. Best GFLOPs: 1005.7953
2024-04-30 13:44:18 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2611: GFLOPs: 309.4652. Time: 11956.6870 us. Best GFLOPs: 1005.7953
2024-04-30 13:44:18 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2612: GFLOPs: 461.8447. Time: 8011.7380 us. Best GFLOPs: 1005.7953
2024-04-30 13:44:18 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2613: GFLOPs: 690.0803. Time: 5361.9539 us. Best GFLOPs: 1005.7953
2024-04-30 13:44:18 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2614: GFLOPs: 423.9527. Time: 8727.8112 us. Best GFLOPs: 1005.7953
2024-04-30 13:44:18 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2615: GFLOPs: 78.7936. Time: 46960.3880 us. Best GFLOPs: 1005.7953
2024-04-30 13:44:18 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2616: GFLOPs: 448.6613. Time: 8247.1552 us. Best GFLOPs: 1005.7953
2024-04-30 13:44:18 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2617: GFLOPs: 502.1519. Time: 7368.6447 us. Best GFLOPs: 1005.7953
2024-04-30 13:44:18 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2618: GFLOPs: 772.5409. Time: 4789.6220 us. Best GFLOPs: 1005.7953
2024-04-30 13:44:18 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2619: GFLOPs: 443.3976. Time: 8345.0592 us. Best GFLOPs: 1005.7953
2024-04-30 13:44:18 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2620: GFLOPs: 615.1221. Time: 6015.3564 us. Best GFLOPs: 1005.7953
2024-04-30 13:44:18 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2621: GFLOPs: 382.9505. Time: 9662.2910 us. Best GFLOPs: 1005.7953
2024-04-30 13:44:18 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2622: GFLOPs: 3.6769. Time: 1006343.6040 us. Best GFLOPs: 1005.7953
2024-04-30 13:44:18 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2623: GFLOPs: 2.7713. Time: 1335157.4097 us. Best GFLOPs: 1005.7953
2024-04-30 13:44:18 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2624: GFLOPs: 31.9271. Time: 115894.6583 us. Best GFLOPs: 1005.7953
2024-04-30 14:09:05 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-30 14:09:07 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-30 14:09:11 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 14:09:11 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-30 14:09:24 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 14:09:38 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 14:09:52 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 14:10:06 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 14:10:15 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.8355  0.8115  0.7841  0.7709  0.7610  0.7610  0.7492  0.7305  0.7004  0.6967  0.6905  0.6863  0.6667  0.6554  0.6517  0.6483
[17 : 32]:	0.6471  0.6446  0.6418  0.6416  0.6392  0.6374  0.6352  0.6344  0.6319  0.6313  0.6282  0.6242  0.6239  0.6218  0.6174  0.6142
[33 : 48]:	0.6125  0.6068  0.6068  0.6051  0.6042  0.6011  0.5985  0.5968  0.5908  0.5903  0.5903  0.5893  0.5887  0.5885  0.5860  0.5834
[49 : 64]:	0.5834  0.5780  0.5764  0.5745  0.5738  0.5711  0.5673  0.5652  0.5578  0.5565  0.5565  0.5547  0.5505  0.5486  0.5473  0.5459
2024-04-30 14:10:15 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-30 14:10:15 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-30 14:12:03 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2625: GFLOPs: 838.7486. Time: 4411.5469 us. Best GFLOPs: 1005.7953
2024-04-30 14:12:03 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2626: GFLOPs: 888.8318. Time: 4162.9688 us. Best GFLOPs: 1005.7953
2024-04-30 14:12:03 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2627: GFLOPs: 742.5195. Time: 4983.2753 us. Best GFLOPs: 1005.7953
2024-04-30 14:12:03 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2628: GFLOPs: 797.1302. Time: 4641.8755 us. Best GFLOPs: 1005.7953
2024-04-30 14:12:03 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2629: GFLOPs: 799.1083. Time: 4630.3848 us. Best GFLOPs: 1005.7953
2024-04-30 14:12:03 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2630: GFLOPs: 432.5941. Time: 8553.4657 us. Best GFLOPs: 1005.7953
2024-04-30 14:12:03 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2631: GFLOPs: 770.1441. Time: 4804.5280 us. Best GFLOPs: 1005.7953
2024-04-30 14:12:03 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2632: GFLOPs: 739.6268. Time: 5002.7648 us. Best GFLOPs: 1005.7953
2024-04-30 14:12:03 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2633: GFLOPs: 702.4292. Time: 5267.6892 us. Best GFLOPs: 1005.7953
2024-04-30 14:12:03 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2634: GFLOPs: 790.1729. Time: 4682.7461 us. Best GFLOPs: 1005.7953
2024-04-30 14:12:03 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2635: GFLOPs: 646.0943. Time: 5726.9953 us. Best GFLOPs: 1005.7953
2024-04-30 14:12:03 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2636: GFLOPs: 744.4116. Time: 4970.6090 us. Best GFLOPs: 1005.7953
2024-04-30 14:12:03 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2637: GFLOPs: 575.0005. Time: 6435.0884 us. Best GFLOPs: 1005.7953
2024-04-30 14:12:03 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2638: GFLOPs: 93.2494. Time: 39680.4627 us. Best GFLOPs: 1005.7953
2024-04-30 14:12:03 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2639: GFLOPs: 659.8918. Time: 5607.2508 us. Best GFLOPs: 1005.7953
2024-04-30 14:12:03 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2640: GFLOPs: 715.1914. Time: 5173.6908 us. Best GFLOPs: 1005.7953
2024-04-30 14:12:03 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2641: GFLOPs: 692.5331. Time: 5342.9636 us. Best GFLOPs: 1005.7953
2024-04-30 14:12:03 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2642: GFLOPs: 715.1620. Time: 5173.9033 us. Best GFLOPs: 1005.7953
2024-04-30 14:12:03 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2643: GFLOPs: 707.4173. Time: 5230.5462 us. Best GFLOPs: 1005.7953
2024-04-30 14:12:03 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2644: GFLOPs: 757.7950. Time: 4882.8234 us. Best GFLOPs: 1005.7953
2024-04-30 14:12:03 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2645: GFLOPs: 648.7621. Time: 5703.4452 us. Best GFLOPs: 1005.7953
2024-04-30 14:12:03 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2646: GFLOPs: 663.4590. Time: 5577.1026 us. Best GFLOPs: 1005.7953
2024-04-30 14:12:03 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2647: GFLOPs: 830.4353. Time: 4455.7100 us. Best GFLOPs: 1005.7953
2024-04-30 14:12:03 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2648: GFLOPs: 725.0342. Time: 5103.4547 us. Best GFLOPs: 1005.7953
2024-04-30 14:12:03 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2649: GFLOPs: 795.0229. Time: 4654.1790 us. Best GFLOPs: 1005.7953
2024-04-30 14:12:03 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2650: GFLOPs: 683.2190. Time: 5415.8019 us. Best GFLOPs: 1005.7953
2024-04-30 14:12:03 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2651: GFLOPs: 669.8011. Time: 5524.2948 us. Best GFLOPs: 1005.7953
2024-04-30 14:12:03 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2652: GFLOPs: 566.9544. Time: 6526.4132 us. Best GFLOPs: 1005.7953
2024-04-30 14:12:03 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2653: GFLOPs: 726.6764. Time: 5091.9210 us. Best GFLOPs: 1005.7953
2024-04-30 14:12:03 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2654: GFLOPs: 444.0342. Time: 8333.0943 us. Best GFLOPs: 1005.7953
2024-04-30 14:12:03 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2655: GFLOPs: 703.9944. Time: 5255.9777 us. Best GFLOPs: 1005.7953
2024-04-30 14:12:03 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2656: GFLOPs: 662.2181. Time: 5587.5533 us. Best GFLOPs: 1005.7953
2024-04-30 14:12:03 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2657: GFLOPs: 576.8392. Time: 6414.5764 us. Best GFLOPs: 1005.7953
2024-04-30 14:12:03 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2658: GFLOPs: 700.3171. Time: 5283.5766 us. Best GFLOPs: 1005.7953
2024-04-30 14:12:03 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2659: GFLOPs: 603.8458. Time: 6127.6881 us. Best GFLOPs: 1005.7953
2024-04-30 14:12:03 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2660: GFLOPs: 698.5333. Time: 5297.0689 us. Best GFLOPs: 1005.7953
2024-04-30 14:12:03 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2661: GFLOPs: 688.4181. Time: 5374.9007 us. Best GFLOPs: 1005.7953
2024-04-30 14:12:03 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2662: GFLOPs: 742.3806. Time: 4984.2074 us. Best GFLOPs: 1005.7953
2024-04-30 14:12:03 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2663: GFLOPs: 826.3740. Time: 4477.6082 us. Best GFLOPs: 1005.7953
2024-04-30 14:12:03 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2664: GFLOPs: 464.3571. Time: 7968.3907 us. Best GFLOPs: 1005.7953
2024-04-30 14:12:03 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2665: GFLOPs: 525.8785. Time: 7036.1854 us. Best GFLOPs: 1005.7953
2024-04-30 14:12:03 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2666: GFLOPs: 737.7615. Time: 5015.4137 us. Best GFLOPs: 1005.7953
2024-04-30 14:12:03 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2667: GFLOPs: 783.9309. Time: 4720.0318 us. Best GFLOPs: 1005.7953
2024-04-30 14:12:03 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2668: GFLOPs: 507.4923. Time: 7291.1031 us. Best GFLOPs: 1005.7953
2024-04-30 14:12:03 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2669: GFLOPs: 665.7111. Time: 5558.2356 us. Best GFLOPs: 1005.7953
2024-04-30 14:12:03 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2670: GFLOPs: 585.2188. Time: 6322.7269 us. Best GFLOPs: 1005.7953
2024-04-30 14:12:03 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2671: GFLOPs: 597.3929. Time: 6193.8786 us. Best GFLOPs: 1005.7953
2024-04-30 14:12:03 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2672: GFLOPs: 590.3750. Time: 6267.5059 us. Best GFLOPs: 1005.7953
2024-04-30 14:12:03 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2673: GFLOPs: 560.3341. Time: 6603.5233 us. Best GFLOPs: 1005.7953
2024-04-30 14:12:03 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2674: GFLOPs: 670.5306. Time: 5518.2852 us. Best GFLOPs: 1005.7953
2024-04-30 14:12:03 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2675: GFLOPs: 346.1032. Time: 10690.9693 us. Best GFLOPs: 1005.7953
2024-04-30 14:12:03 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2676: GFLOPs: 647.2365. Time: 5716.8882 us. Best GFLOPs: 1005.7953
2024-04-30 14:12:03 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2677: GFLOPs: 586.3362. Time: 6310.6785 us. Best GFLOPs: 1005.7953
2024-04-30 14:12:03 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2678: GFLOPs: 664.7566. Time: 5566.2160 us. Best GFLOPs: 1005.7953
2024-04-30 14:12:03 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2679: GFLOPs: 552.3824. Time: 6698.5825 us. Best GFLOPs: 1005.7953
2024-04-30 14:12:03 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2680: GFLOPs: 512.2186. Time: 7223.8278 us. Best GFLOPs: 1005.7953
2024-04-30 14:12:03 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2681: GFLOPs: 396.0471. Time: 9342.7741 us. Best GFLOPs: 1005.7953
2024-04-30 14:12:03 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2682: GFLOPs: 654.2260. Time: 5655.8117 us. Best GFLOPs: 1005.7953
2024-04-30 14:12:03 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2683: GFLOPs: 716.0259. Time: 5167.6605 us. Best GFLOPs: 1005.7953
2024-04-30 14:12:03 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2684: GFLOPs: 436.7481. Time: 8472.1131 us. Best GFLOPs: 1005.7953
2024-04-30 14:12:03 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2685: GFLOPs: 730.3214. Time: 5066.5076 us. Best GFLOPs: 1005.7953
2024-04-30 14:12:03 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2686: GFLOPs: 18.0759. Time: 204702.5400 us. Best GFLOPs: 1005.7953
2024-04-30 14:12:03 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2687: GFLOPs: 25.3156. Time: 146162.2217 us. Best GFLOPs: 1005.7953
2024-04-30 14:12:03 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2688: GFLOPs: 11.3173. Time: 326949.7910 us. Best GFLOPs: 1005.7953
2024-04-30 14:12:03 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-30 14:12:04 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-30 14:12:09 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 14:12:09 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-30 14:12:22 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 14:12:36 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 14:12:50 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 14:13:04 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 14:13:12 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.8195  0.8139  0.7895  0.7879  0.7879  0.7713  0.7643  0.7499  0.7492  0.7451  0.7437  0.7369  0.7360  0.7348  0.7348  0.7343
[17 : 32]:	0.7305  0.7291  0.7242  0.7227  0.7132  0.7042  0.7007  0.6967  0.6951  0.6895  0.6858  0.6840  0.6800  0.6798  0.6746  0.6636
[33 : 48]:	0.6633  0.6633  0.6561  0.6484  0.6455  0.6455  0.6454  0.6447  0.6399  0.6368  0.6319  0.6188  0.6141  0.6140  0.6131  0.6112
[49 : 64]:	0.6112  0.6084  0.6084  0.6052  0.6011  0.6004  0.5964  0.5907  0.5823  0.5806  0.5722  0.5692  0.5652  0.5562  0.5523  0.5514
2024-04-30 14:13:13 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-30 14:13:13 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-30 14:15:34 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2689: GFLOPs: 440.5012. Time: 8399.9292 us. Best GFLOPs: 1005.7953
2024-04-30 14:15:34 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2690: GFLOPs: 428.6773. Time: 8631.6183 us. Best GFLOPs: 1005.7953
2024-04-30 14:15:34 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2691: GFLOPs: 424.7445. Time: 8711.5396 us. Best GFLOPs: 1005.7953
2024-04-30 14:15:34 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2692: GFLOPs: 764.0156. Time: 4843.0670 us. Best GFLOPs: 1005.7953
2024-04-30 14:15:34 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2693: GFLOPs: 453.2185. Time: 8164.2279 us. Best GFLOPs: 1005.7953
2024-04-30 14:15:34 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2694: GFLOPs: 743.9840. Time: 4973.4659 us. Best GFLOPs: 1005.7953
2024-04-30 14:15:34 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2695: GFLOPs: 796.8764. Time: 4643.3538 us. Best GFLOPs: 1005.7953
2024-04-30 14:15:34 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2696: GFLOPs: 698.4042. Time: 5298.0483 us. Best GFLOPs: 1005.7953
2024-04-30 14:15:34 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2697: GFLOPs: 776.4819. Time: 4765.3123 us. Best GFLOPs: 1005.7953
2024-04-30 14:15:34 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2698: GFLOPs: 279.0276. Time: 13260.9764 us. Best GFLOPs: 1005.7953
2024-04-30 14:15:34 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2699: GFLOPs: 127.5195. Time: 29016.5755 us. Best GFLOPs: 1005.7953
2024-04-30 14:15:34 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2700: GFLOPs: 669.0155. Time: 5530.7823 us. Best GFLOPs: 1005.7953
2024-04-30 14:15:34 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2701: GFLOPs: 785.3523. Time: 4711.4891 us. Best GFLOPs: 1005.7953
2024-04-30 14:15:34 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2702: GFLOPs: 87.4146. Time: 42329.0627 us. Best GFLOPs: 1005.7953
2024-04-30 14:15:34 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2703: GFLOPs: 741.3002. Time: 4991.4715 us. Best GFLOPs: 1005.7953
2024-04-30 14:15:34 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2704: GFLOPs: 640.7862. Time: 5774.4358 us. Best GFLOPs: 1005.7953
2024-04-30 14:15:34 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2705: GFLOPs: 699.9880. Time: 5286.0603 us. Best GFLOPs: 1005.7953
2024-04-30 14:15:34 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2706: GFLOPs: 710.2865. Time: 5209.4174 us. Best GFLOPs: 1005.7953
2024-04-30 14:15:34 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2707: GFLOPs: 723.6703. Time: 5113.0728 us. Best GFLOPs: 1005.7953
2024-04-30 14:15:34 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2708: GFLOPs: 761.7911. Time: 4857.2096 us. Best GFLOPs: 1005.7953
2024-04-30 14:15:34 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2709: GFLOPs: 702.2942. Time: 5268.7023 us. Best GFLOPs: 1005.7953
2024-04-30 14:15:34 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2710: GFLOPs: 684.6224. Time: 5404.7007 us. Best GFLOPs: 1005.7953
2024-04-30 14:15:34 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2711: GFLOPs: 509.0359. Time: 7268.9946 us. Best GFLOPs: 1005.7953
2024-04-30 14:15:34 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2712: GFLOPs: 384.3898. Time: 9626.1112 us. Best GFLOPs: 1005.7953
2024-04-30 14:15:34 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2713: GFLOPs: 793.4181. Time: 4663.5930 us. Best GFLOPs: 1005.7953
2024-04-30 14:15:34 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2714: GFLOPs: 673.6657. Time: 5492.6043 us. Best GFLOPs: 1005.7953
2024-04-30 14:15:34 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2715: GFLOPs: 77.3783. Time: 47819.3100 us. Best GFLOPs: 1005.7953
2024-04-30 14:15:34 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2716: GFLOPs: 647.6188. Time: 5713.5137 us. Best GFLOPs: 1005.7953
2024-04-30 14:15:34 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2717: GFLOPs: 696.6069. Time: 5311.7170 us. Best GFLOPs: 1005.7953
2024-04-30 14:15:34 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2718: GFLOPs: 619.1549. Time: 5976.1768 us. Best GFLOPs: 1005.7953
2024-04-30 14:15:34 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2719: GFLOPs: 462.6838. Time: 7997.2089 us. Best GFLOPs: 1005.7953
2024-04-30 14:15:34 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2720: GFLOPs: 740.5607. Time: 4996.4558 us. Best GFLOPs: 1005.7953
2024-04-30 14:15:34 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2721: GFLOPs: 631.8513. Time: 5856.0917 us. Best GFLOPs: 1005.7953
2024-04-30 14:15:34 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2722: GFLOPs: 628.3753. Time: 5888.4859 us. Best GFLOPs: 1005.7953
2024-04-30 14:15:34 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2723: GFLOPs: 573.6502. Time: 6450.2357 us. Best GFLOPs: 1005.7953
2024-04-30 14:15:34 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2724: GFLOPs: 572.8461. Time: 6459.2897 us. Best GFLOPs: 1005.7953
2024-04-30 14:15:34 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2725: GFLOPs: 73.8861. Time: 50079.5120 us. Best GFLOPs: 1005.7953
2024-04-30 14:15:34 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2726: GFLOPs: 92.2183. Time: 40124.1353 us. Best GFLOPs: 1005.7953
2024-04-30 14:15:34 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2727: GFLOPs: 576.1593. Time: 6422.1461 us. Best GFLOPs: 1005.7953
2024-04-30 14:15:34 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2728: GFLOPs: 637.1615. Time: 5807.2858 us. Best GFLOPs: 1005.7953
2024-04-30 14:15:34 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2729: GFLOPs: 692.5172. Time: 5343.0860 us. Best GFLOPs: 1005.7953
2024-04-30 14:15:34 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2730: GFLOPs: 661.2533. Time: 5595.7061 us. Best GFLOPs: 1005.7953
2024-04-30 14:15:34 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2731: GFLOPs: 586.3092. Time: 6310.9684 us. Best GFLOPs: 1005.7953
2024-04-30 14:15:34 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2732: GFLOPs: 555.0710. Time: 6666.1363 us. Best GFLOPs: 1005.7953
2024-04-30 14:15:34 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2733: GFLOPs: 741.1366. Time: 4992.5737 us. Best GFLOPs: 1005.7953
2024-04-30 14:15:34 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2734: GFLOPs: 368.0221. Time: 10054.2297 us. Best GFLOPs: 1005.7953
2024-04-30 14:15:34 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2735: GFLOPs: 649.6282. Time: 5695.8409 us. Best GFLOPs: 1005.7953
2024-04-30 14:15:34 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2736: GFLOPs: 498.5183. Time: 7422.3539 us. Best GFLOPs: 1005.7953
2024-04-30 14:15:34 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2737: GFLOPs: 499.2409. Time: 7411.6109 us. Best GFLOPs: 1005.7953
2024-04-30 14:15:34 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2738: GFLOPs: 550.1204. Time: 6726.1255 us. Best GFLOPs: 1005.7953
2024-04-30 14:15:34 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2739: GFLOPs: 552.7444. Time: 6694.1950 us. Best GFLOPs: 1005.7953
2024-04-30 14:15:34 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2740: GFLOPs: 101.9524. Time: 36293.1833 us. Best GFLOPs: 1005.7953
2024-04-30 14:15:34 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2741: GFLOPs: 551.5912. Time: 6708.1908 us. Best GFLOPs: 1005.7953
2024-04-30 14:15:34 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2742: GFLOPs: 509.9350. Time: 7256.1775 us. Best GFLOPs: 1005.7953
2024-04-30 14:15:34 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2743: GFLOPs: 617.1546. Time: 5995.5465 us. Best GFLOPs: 1005.7953
2024-04-30 14:15:34 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2744: GFLOPs: 584.2556. Time: 6333.1506 us. Best GFLOPs: 1005.7953
2024-04-30 14:15:34 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2745: GFLOPs: 299.3891. Time: 12359.0989 us. Best GFLOPs: 1005.7953
2024-04-30 14:15:34 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2746: GFLOPs: 596.2459. Time: 6205.7931 us. Best GFLOPs: 1005.7953
2024-04-30 14:15:34 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2747: GFLOPs: 564.6990. Time: 6552.4801 us. Best GFLOPs: 1005.7953
2024-04-30 14:15:34 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2748: GFLOPs: 632.5976. Time: 5849.1827 us. Best GFLOPs: 1005.7953
2024-04-30 14:15:34 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2749: GFLOPs: 591.0658. Time: 6260.1807 us. Best GFLOPs: 1005.7953
2024-04-30 14:15:34 [INFO] [task_scheduler.cc:121] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2750: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(512)), "float32"), p1: T.Buffer((T.int64(32), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused in T.parallel(T.int64(16), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(30), T.int64(9), T.int64(512)):
                with T.block("data_pad"):
                    v_i0, v_i1, v_i2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                    v_i3 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(4) * T.int64(7) + ax3)
                    v_i4 = T.axis.spatial(T.int64(512), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(2)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(8), T.int64(7), T.int64(7), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(1)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(8)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(4) * T.int64(8) + oc_chunk_2_init + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(28), oh_1 * T.int64(28) + oh_2_init * T.int64(4) + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(4) * T.int64(7) + ow_1 * T.int64(7) + ow_2_init + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_1 * T.int64(8) + oc_block_2_init * T.int64(8) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(512), T.int64(1), T.int64(1), T.int64(1), T.int64(8), T.int64(7), T.int64(7), T.int64(1), T.int64(1), T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(4), T.int64(1)):
                    for oc_block_3_fused in T.vectorized(T.int64(8)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(4) * T.int64(8) + oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(28), oh_1 * T.int64(28) + oh_2 * T.int64(4) + oh_3)
                            v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(4) * T.int64(7) + ow_1 * T.int64(7) + ow_2 + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_1 * T.int64(8) + oc_block_2 * T.int64(8) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(512), ic_0 + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
        for ax0_ax1_ax2_ax3_ax4_fused_0 in T.parallel(T.int64(6272)):
            for ax0_ax1_ax2_ax3_ax4_fused_1 in T.vectorized(T.int64(64)):
                with T.block("T_relu"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) // T.int64(12544))
                    v_ax2 = T.axis.spatial(T.int64(28), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(12544) // T.int64(448))
                    v_ax3 = T.axis.spatial(T.int64(28), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(448) // T.int64(16))
                    v_ax4 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(16))
                    T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                    T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 4, 8, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 7, 4])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[4, 1, 7, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 2, 1, 8])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[512, 1])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
l65 = sch.sample_compute_location(block=b0, decision=6)
sch.compute_at(block=b0, loop=l65, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b66 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.unroll_explicit")
b67, b68, b69 = sch.get_child_blocks(b66)
l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81 = sch.get_loops(block=b67)
l82 = sch.fuse(l70, l71, l72, l73, l74, l75, l76, preserve_unit_iters=True)
sch.parallel(loop=l82)
l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102 = sch.get_loops(block=b68)
l103 = sch.fuse(l83, preserve_unit_iters=True)
sch.parallel(loop=l103)
l104 = sch.fuse(l102, preserve_unit_iters=True)
sch.vectorize(loop=l104)
sch.annotate(block_or_loop=l103, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l103, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109 = sch.get_loops(block=b69)
l110 = sch.fuse(l105, l106, l107, l108, l109, preserve_unit_iters=True)
l111, l112 = sch.split(loop=l110, factors=[None, 64], preserve_unit_iters=True)
sch.parallel(loop=l111)
sch.vectorize(loop=l112)
b113 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133 = sch.get_loops(block=b113)
b134 = sch.decompose_reduction(block=b113, loop=l118)
2024-04-30 14:15:34 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2751: GFLOPs: 19.2037. Time: 192680.3503 us. Best GFLOPs: 1005.7953
2024-04-30 14:15:34 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2752: GFLOPs: 2.7201. Time: 1360309.3233 us. Best GFLOPs: 1005.7953
2024-04-30 14:22:16 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-30 14:22:17 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-30 14:22:21 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 14:22:21 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-30 14:22:34 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 14:22:48 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 14:23:02 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 14:23:16 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 14:23:25 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.7895  0.7818  0.7690  0.7654  0.7619  0.7600  0.7515  0.7396  0.7309  0.7280  0.7134  0.7130  0.7128  0.7112  0.7085  0.7035
[17 : 32]:	0.7028  0.6969  0.6913  0.6913  0.6890  0.6885  0.6862  0.6822  0.6784  0.6784  0.6774  0.6763  0.6751  0.6738  0.6726  0.6715
[33 : 48]:	0.6707  0.6669  0.6649  0.6632  0.6607  0.6576  0.6575  0.6573  0.6548  0.6532  0.6524  0.6523  0.6490  0.6446  0.6401  0.6395
[49 : 64]:	0.6371  0.6351  0.6307  0.6296  0.6295  0.6289  0.6250  0.6176  0.6161  0.6123  0.6110  0.6094  0.6092  0.6030  0.5977  0.5956
2024-04-30 14:23:25 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-30 14:23:25 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-30 14:25:33 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2753: GFLOPs: 789.2084. Time: 4688.4689 us. Best GFLOPs: 1005.7953
2024-04-30 14:25:33 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2754: GFLOPs: 835.2198. Time: 4430.1857 us. Best GFLOPs: 1005.7953
2024-04-30 14:25:33 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2755: GFLOPs: 388.6681. Time: 9520.1502 us. Best GFLOPs: 1005.7953
2024-04-30 14:25:33 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2756: GFLOPs: 412.5089. Time: 8969.9377 us. Best GFLOPs: 1005.7953
2024-04-30 14:25:33 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2757: GFLOPs: 427.4585. Time: 8656.2298 us. Best GFLOPs: 1005.7953
2024-04-30 14:25:33 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2758: GFLOPs: 793.8107. Time: 4661.2865 us. Best GFLOPs: 1005.7953
2024-04-30 14:25:33 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2759: GFLOPs: 104.1192. Time: 35537.8980 us. Best GFLOPs: 1005.7953
2024-04-30 14:25:33 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2760: GFLOPs: 764.8119. Time: 4838.0246 us. Best GFLOPs: 1005.7953
2024-04-30 14:25:33 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2761: GFLOPs: 184.8607. Time: 20016.0383 us. Best GFLOPs: 1005.7953
2024-04-30 14:25:33 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2762: GFLOPs: 705.6604. Time: 5243.5688 us. Best GFLOPs: 1005.7953
2024-04-30 14:25:33 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2763: GFLOPs: 794.1646. Time: 4659.2092 us. Best GFLOPs: 1005.7953
2024-04-30 14:25:33 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2764: GFLOPs: 449.9676. Time: 8223.2121 us. Best GFLOPs: 1005.7953
2024-04-30 14:25:33 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2765: GFLOPs: 708.0528. Time: 5225.8519 us. Best GFLOPs: 1005.7953
2024-04-30 14:25:33 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2766: GFLOPs: 722.9914. Time: 5117.8741 us. Best GFLOPs: 1005.7953
2024-04-30 14:25:33 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2767: GFLOPs: 720.6792. Time: 5134.2938 us. Best GFLOPs: 1005.7953
2024-04-30 14:25:33 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2768: GFLOPs: 739.7211. Time: 5002.1270 us. Best GFLOPs: 1005.7953
2024-04-30 14:25:33 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2769: GFLOPs: 102.1146. Time: 36235.5403 us. Best GFLOPs: 1005.7953
2024-04-30 14:25:33 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2770: GFLOPs: 699.5542. Time: 5289.3383 us. Best GFLOPs: 1005.7953
2024-04-30 14:25:33 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2771: GFLOPs: 681.4697. Time: 5429.7045 us. Best GFLOPs: 1005.7953
2024-04-30 14:25:33 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2772: GFLOPs: 673.3575. Time: 5495.1182 us. Best GFLOPs: 1005.7953
2024-04-30 14:25:33 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2773: GFLOPs: 717.4876. Time: 5157.1332 us. Best GFLOPs: 1005.7953
2024-04-30 14:25:33 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2774: GFLOPs: 688.1966. Time: 5376.6309 us. Best GFLOPs: 1005.7953
2024-04-30 14:25:33 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2775: GFLOPs: 709.5904. Time: 5214.5282 us. Best GFLOPs: 1005.7953
2024-04-30 14:25:33 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2776: GFLOPs: 679.5922. Time: 5444.7047 us. Best GFLOPs: 1005.7953
2024-04-30 14:25:33 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2777: GFLOPs: 651.0297. Time: 5683.5794 us. Best GFLOPs: 1005.7953
2024-04-30 14:25:33 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2778: GFLOPs: 707.8717. Time: 5227.1884 us. Best GFLOPs: 1005.7953
2024-04-30 14:25:33 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2779: GFLOPs: 557.5837. Time: 6636.0954 us. Best GFLOPs: 1005.7953
2024-04-30 14:25:33 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2780: GFLOPs: 694.7144. Time: 5326.1874 us. Best GFLOPs: 1005.7953
2024-04-30 14:25:33 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2781: GFLOPs: 495.4555. Time: 7468.2360 us. Best GFLOPs: 1005.7953
2024-04-30 14:25:33 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2782: GFLOPs: 669.5949. Time: 5525.9964 us. Best GFLOPs: 1005.7953
2024-04-30 14:25:33 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2783: GFLOPs: 406.8747. Time: 9094.1487 us. Best GFLOPs: 1005.7953
2024-04-30 14:25:33 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2784: GFLOPs: 436.5699. Time: 8475.5699 us. Best GFLOPs: 1005.7953
2024-04-30 14:25:33 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2785: GFLOPs: 671.2051. Time: 5512.7396 us. Best GFLOPs: 1005.7953
2024-04-30 14:25:33 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2786: GFLOPs: 683.9524. Time: 5409.9947 us. Best GFLOPs: 1005.7953
2024-04-30 14:25:33 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2787: GFLOPs: 690.8956. Time: 5355.6268 us. Best GFLOPs: 1005.7953
2024-04-30 14:25:33 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2788: GFLOPs: 549.2145. Time: 6737.2199 us. Best GFLOPs: 1005.7953
2024-04-30 14:25:33 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2789: GFLOPs: 491.2699. Time: 7531.8653 us. Best GFLOPs: 1005.7953
2024-04-30 14:25:33 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2790: GFLOPs: 107.2399. Time: 34503.7570 us. Best GFLOPs: 1005.7953
2024-04-30 14:25:33 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2791: GFLOPs: 673.1248. Time: 5497.0177 us. Best GFLOPs: 1005.7953
2024-04-30 14:25:33 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2792: GFLOPs: 643.3655. Time: 5751.2856 us. Best GFLOPs: 1005.7953
2024-04-30 14:25:33 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2793: GFLOPs: 396.0613. Time: 9342.4389 us. Best GFLOPs: 1005.7953
2024-04-30 14:25:33 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2794: GFLOPs: 742.4568. Time: 4983.6958 us. Best GFLOPs: 1005.7953
2024-04-30 14:25:33 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2795: GFLOPs: 591.7473. Time: 6252.9713 us. Best GFLOPs: 1005.7953
2024-04-30 14:25:33 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2796: GFLOPs: 682.8106. Time: 5419.0411 us. Best GFLOPs: 1005.7953
2024-04-30 14:25:33 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2797: GFLOPs: 663.1528. Time: 5579.6777 us. Best GFLOPs: 1005.7953
2024-04-30 14:25:33 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2798: GFLOPs: 578.0133. Time: 6401.5464 us. Best GFLOPs: 1005.7953
2024-04-30 14:25:33 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2799: GFLOPs: 636.4262. Time: 5813.9956 us. Best GFLOPs: 1005.7953
2024-04-30 14:25:33 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2800: GFLOPs: 703.4288. Time: 5260.2037 us. Best GFLOPs: 1005.7953
2024-04-30 14:25:33 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2801: GFLOPs: 587.9671. Time: 6293.1739 us. Best GFLOPs: 1005.7953
2024-04-30 14:25:33 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2802: GFLOPs: 641.5209. Time: 5767.8226 us. Best GFLOPs: 1005.7953
2024-04-30 14:25:33 [INFO] [task_scheduler.cc:121] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2803: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(512)), "float32"), p1: T.Buffer((T.int64(32), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_fused_fused in T.parallel(T.int64(224), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for oc_block_0 in range(T.int64(1)):
                for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                    for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(2), T.int64(7), T.int64(16), T.int64(1), T.int64(4), T.int64(2), T.int64(1), T.int64(1)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(28) * T.int64(4) + oc_chunk_1 * T.int64(4) + oc_chunk_2_init * T.int64(4) + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(28) // T.int64(4) * T.int64(4) + oh_1 * T.int64(4) + oh_2_init * T.int64(2) + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(4) * T.int64(7) + ow_1 * T.int64(7) + ow_2_init + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2_init + oc_block_3_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                    for ic_0 in range(T.int64(128)):
                        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(6), T.int64(9)):
                            for ax4_fused in T.vectorized(T.int64(4)):
                                with T.block("data_pad"):
                                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                                    v_i2 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(28) // T.int64(4) * T.int64(4) + ax2)
                                    v_i3 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(4) * T.int64(7) + ax3)
                                    v_i4 = T.axis.spatial(T.int64(512), ic_0 * T.int64(4) + ax4_fused)
                                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                        for kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(2), T.int64(7), T.int64(16), T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(2), T.int64(1), T.int64(1)):
                            with T.block("conv2d_NCHWc_update"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                                v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(28) * T.int64(4) + oc_chunk_1 * T.int64(4) + oc_chunk_2 * T.int64(4) + oc_chunk_3)
                                v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(28) // T.int64(4) * T.int64(4) + oh_1 * T.int64(4) + oh_2 * T.int64(2) + oh_3)
                                v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(4) * T.int64(7) + ow_1 * T.int64(7) + ow_2 + ow_3)
                                v_oc_block = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2 + oc_block_3)
                                v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(4) + ic_1)
                                v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                                v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                                T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(4), T.int64(4), T.int64(7)):
                    for ax4_fused in T.vectorized(T.int64(16)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(28) * T.int64(4) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(28) // T.int64(4) * T.int64(4) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(4) * T.int64(7) + ax3)
                            v_ax4 = T.axis.spatial(T.int64(16), ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[8, 1, 1, 4])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[7, 1, 2, 2])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[4, 1, 7, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 16, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[128, 4])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=112)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=10)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86 = sch.get_loops(block=b68)
l87 = sch.fuse(l71, l72, l73, l74, preserve_unit_iters=True)
sch.parallel(loop=l87)
l88 = sch.fuse(l86, preserve_unit_iters=True)
sch.vectorize(loop=l88)
l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107, l108, l109, l110, l111 = sch.get_loops(block=b69)
l112 = sch.fuse(l89, preserve_unit_iters=True)
sch.parallel(loop=l112)
sch.annotate(block_or_loop=l112, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l112, ann_key="pragma_unroll_explicit", ann_val=1)
l113, l114, l115, l116, l117, l118, l119 = sch.get_loops(block=b70)
l120 = sch.fuse(l119, preserve_unit_iters=True)
sch.vectorize(loop=l120)
b121 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141, l142, l143, l144 = sch.get_loops(block=b121)
b145 = sch.decompose_reduction(block=b121, loop=l129)
2024-04-30 14:25:33 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2804: GFLOPs: 664.0776. Time: 5571.9076 us. Best GFLOPs: 1005.7953
2024-04-30 14:25:33 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2805: GFLOPs: 612.2791. Time: 6043.2875 us. Best GFLOPs: 1005.7953
2024-04-30 14:25:33 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2806: GFLOPs: 640.1393. Time: 5780.2717 us. Best GFLOPs: 1005.7953
2024-04-30 14:25:33 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2807: GFLOPs: 617.7005. Time: 5990.2472 us. Best GFLOPs: 1005.7953
2024-04-30 14:25:33 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2808: GFLOPs: 675.5497. Time: 5477.2864 us. Best GFLOPs: 1005.7953
2024-04-30 14:25:33 [INFO] [task_scheduler.cc:121] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2809: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(512)), "float32"), p1: T.Buffer((T.int64(32), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_fused_fused in T.parallel(T.int64(224), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for oc_block_0 in range(T.int64(1)):
                for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                    for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(2), T.int64(2), T.int64(7), T.int64(16), T.int64(1), T.int64(2), T.int64(2), T.int64(1), T.int64(1)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(28) * T.int64(4) + oc_chunk_1 * T.int64(4) + oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(28) // T.int64(4) * T.int64(4) + oh_1 * T.int64(4) + oh_2_init * T.int64(2) + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(4) * T.int64(7) + ow_1 * T.int64(7) + ow_2_init + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2_init + oc_block_3_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                    for ic_0 in range(T.int64(64)):
                        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(6), T.int64(9)):
                            for ax4_fused in T.vectorized(T.int64(8)):
                                with T.block("data_pad"):
                                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                                    v_i2 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(28) // T.int64(4) * T.int64(4) + ax2)
                                    v_i3 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(4) * T.int64(7) + ax3)
                                    v_i4 = T.axis.spatial(T.int64(512), ic_0 * T.int64(8) + ax4_fused)
                                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                        for kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(3), T.int64(3), T.int64(1), T.int64(2), T.int64(2), T.int64(7), T.int64(16), T.int64(8), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(2), T.int64(1), T.int64(1)):
                            with T.block("conv2d_NCHWc_update"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                                v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(28) * T.int64(4) + oc_chunk_1 * T.int64(4) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                                v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(28) // T.int64(4) * T.int64(4) + oh_1 * T.int64(4) + oh_2 * T.int64(2) + oh_3)
                                v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(4) * T.int64(7) + ow_1 * T.int64(7) + ow_2 + ow_3)
                                v_oc_block = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2 + oc_block_3)
                                v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(8) + ic_1)
                                v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                                v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                                T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(4), T.int64(4), T.int64(7)):
                    for ax4_fused in T.vectorized(T.int64(16)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(28) * T.int64(4) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(28) // T.int64(4) * T.int64(4) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(4) * T.int64(7) + ax3)
                            v_ax4 = T.axis.spatial(T.int64(16), ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[8, 1, 2, 2])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[7, 1, 2, 2])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[4, 1, 7, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 16, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[64, 8])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=112)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=10)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86 = sch.get_loops(block=b68)
l87 = sch.fuse(l71, l72, l73, l74, preserve_unit_iters=True)
sch.parallel(loop=l87)
l88 = sch.fuse(l86, preserve_unit_iters=True)
sch.vectorize(loop=l88)
l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107, l108, l109, l110, l111 = sch.get_loops(block=b69)
l112 = sch.fuse(l89, preserve_unit_iters=True)
sch.parallel(loop=l112)
sch.annotate(block_or_loop=l112, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l112, ann_key="pragma_unroll_explicit", ann_val=1)
l113, l114, l115, l116, l117, l118, l119 = sch.get_loops(block=b70)
l120 = sch.fuse(l119, preserve_unit_iters=True)
sch.vectorize(loop=l120)
b121 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141, l142, l143, l144 = sch.get_loops(block=b121)
b145 = sch.decompose_reduction(block=b121, loop=l129)
2024-04-30 14:25:33 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2810: GFLOPs: 716.7648. Time: 5162.3338 us. Best GFLOPs: 1005.7953
2024-04-30 14:25:33 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2811: GFLOPs: 675.4564. Time: 5478.0427 us. Best GFLOPs: 1005.7953
2024-04-30 14:25:33 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2812: GFLOPs: 567.2028. Time: 6523.5554 us. Best GFLOPs: 1005.7953
2024-04-30 14:25:33 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2813: GFLOPs: 671.1874. Time: 5512.8849 us. Best GFLOPs: 1005.7953
2024-04-30 14:25:33 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2814: GFLOPs: 39.5691. Time: 93511.8647 us. Best GFLOPs: 1005.7953
2024-04-30 14:25:33 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2815: GFLOPs: 19.5981. Time: 188802.5537 us. Best GFLOPs: 1005.7953
2024-04-30 14:25:33 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2816: GFLOPs: 23.5852. Time: 156885.6947 us. Best GFLOPs: 1005.7953
2024-04-30 14:28:39 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-30 14:28:40 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-30 14:28:45 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 14:28:45 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-30 14:28:58 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 14:29:12 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 14:29:26 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 14:29:44 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 14:29:52 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.7700  0.7491  0.7190  0.7162  0.7025  0.7025  0.7009  0.6989  0.6901  0.6883  0.6881  0.6794  0.6779  0.6779  0.6779  0.6770
[17 : 32]:	0.6767  0.6711  0.6711  0.6708  0.6585  0.6528  0.6393  0.6340  0.6321  0.6160  0.6143  0.6121  0.6111  0.6043  0.6043  0.6018
[33 : 48]:	0.5985  0.5980  0.5976  0.5964  0.5956  0.5934  0.5919  0.5915  0.5870  0.5856  0.5847  0.5835  0.5832  0.5823  0.5823  0.5810
[49 : 64]:	0.5789  0.5767  0.5764  0.5754  0.5735  0.5729  0.5620  0.5603  0.5587  0.5524  0.5488  0.5482  0.5468  0.5468  0.5445  0.5442
2024-04-30 14:29:53 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-30 14:29:53 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-30 14:32:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2817: GFLOPs: 800.3083. Time: 4623.4416 us. Best GFLOPs: 1005.7953
2024-04-30 14:32:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2818: GFLOPs: 798.5391. Time: 4633.6854 us. Best GFLOPs: 1005.7953
2024-04-30 14:32:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2819: GFLOPs: 90.4005. Time: 40930.9600 us. Best GFLOPs: 1005.7953
2024-04-30 14:32:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2820: GFLOPs: 722.9277. Time: 5118.3253 us. Best GFLOPs: 1005.7953
2024-04-30 14:32:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2821: GFLOPs: 813.9308. Time: 4546.0606 us. Best GFLOPs: 1005.7953
2024-04-30 14:32:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2822: GFLOPs: 815.4639. Time: 4537.5143 us. Best GFLOPs: 1005.7953
2024-04-30 14:32:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2823: GFLOPs: 462.7190. Time: 7996.6011 us. Best GFLOPs: 1005.7953
2024-04-30 14:32:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2824: GFLOPs: 713.7768. Time: 5183.9440 us. Best GFLOPs: 1005.7953
2024-04-30 14:32:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2825: GFLOPs: 672.3991. Time: 5502.9502 us. Best GFLOPs: 1005.7953
2024-04-30 14:32:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2826: GFLOPs: 738.9617. Time: 5007.2673 us. Best GFLOPs: 1005.7953
2024-04-30 14:32:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2827: GFLOPs: 737.2853. Time: 5018.6527 us. Best GFLOPs: 1005.7953
2024-04-30 14:32:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2828: GFLOPs: 649.6070. Time: 5696.0272 us. Best GFLOPs: 1005.7953
2024-04-30 14:32:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2829: GFLOPs: 93.4623. Time: 39590.0870 us. Best GFLOPs: 1005.7953
2024-04-30 14:32:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2830: GFLOPs: 113.3788. Time: 32635.5422 us. Best GFLOPs: 1005.7953
2024-04-30 14:32:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2831: GFLOPs: 68.8240. Time: 53762.9350 us. Best GFLOPs: 1005.7953
2024-04-30 14:32:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2832: GFLOPs: 705.1881. Time: 5247.0810 us. Best GFLOPs: 1005.7953
2024-04-30 14:32:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2833: GFLOPs: 680.6946. Time: 5435.8870 us. Best GFLOPs: 1005.7953
2024-04-30 14:32:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2834: GFLOPs: 722.6914. Time: 5119.9989 us. Best GFLOPs: 1005.7953
2024-04-30 14:32:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2835: GFLOPs: 418.1579. Time: 8848.7609 us. Best GFLOPs: 1005.7953
2024-04-30 14:32:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2836: GFLOPs: 579.2354. Time: 6388.0403 us. Best GFLOPs: 1005.7953
2024-04-30 14:32:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2837: GFLOPs: 590.4954. Time: 6266.2282 us. Best GFLOPs: 1005.7953
2024-04-30 14:32:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2838: GFLOPs: 620.6513. Time: 5961.7682 us. Best GFLOPs: 1005.7953
2024-04-30 14:32:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2839: GFLOPs: 559.6046. Time: 6612.1309 us. Best GFLOPs: 1005.7953
2024-04-30 14:32:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2840: GFLOPs: 669.6346. Time: 5525.6684 us. Best GFLOPs: 1005.7953
2024-04-30 14:32:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2841: GFLOPs: 674.3463. Time: 5487.0605 us. Best GFLOPs: 1005.7953
2024-04-30 14:32:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2842: GFLOPs: 582.4646. Time: 6352.6241 us. Best GFLOPs: 1005.7953
2024-04-30 14:32:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2843: GFLOPs: 710.7946. Time: 5205.6933 us. Best GFLOPs: 1005.7953
2024-04-30 14:32:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2844: GFLOPs: 695.9335. Time: 5316.8571 us. Best GFLOPs: 1005.7953
2024-04-30 14:32:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2845: GFLOPs: 646.3632. Time: 5724.6127 us. Best GFLOPs: 1005.7953
2024-04-30 14:32:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2846: GFLOPs: 550.7169. Time: 6718.8400 us. Best GFLOPs: 1005.7953
2024-04-30 14:32:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2847: GFLOPs: 551.2550. Time: 6712.2819 us. Best GFLOPs: 1005.7953
2024-04-30 14:32:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2848: GFLOPs: 597.5286. Time: 6192.4721 us. Best GFLOPs: 1005.7953
2024-04-30 14:32:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2849: GFLOPs: 402.1159. Time: 9201.7725 us. Best GFLOPs: 1005.7953
2024-04-30 14:32:00 [INFO] [task_scheduler.cc:121] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2850: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(512)), "float32"), p1: T.Buffer((T.int64(32), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused in T.parallel(T.int64(224), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(28), T.int64(16), T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(28) * T.int64(4) + oc_chunk_1 * T.int64(4) + oc_chunk_2_init * T.int64(4) + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(28) + oh_1 + oh_2_init + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(28), ow_1 * T.int64(28) + ow_2_init + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(16), oc_block_1 * T.int64(16) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0 in T.grid(T.int64(64), T.int64(3)):
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(30)):
                        for ax4_fused in T.vectorized(T.int64(8)):
                            with T.block("data_pad"):
                                v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                                v_i2 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(28) + kh_0 + ax2)
                                v_i3 = T.axis.spatial(T.int64(30), ax3)
                                v_i4 = T.axis.spatial(T.int64(512), ic_0 * T.int64(8) + ax4_fused)
                                T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                                T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                                data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                    for kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(28), T.int64(16), T.int64(8), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(1)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(28) * T.int64(4) + oc_chunk_1 * T.int64(4) + oc_chunk_2 * T.int64(4) + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(28) + oh_1 + oh_2 + oh_3)
                            v_ow = T.axis.spatial(T.int64(28), ow_1 * T.int64(28) + ow_2 + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_1 * T.int64(16) + oc_block_2 + oc_block_3)
                            v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(8) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(4), T.int64(1), T.int64(28)):
                for ax4_fused in T.vectorized(T.int64(16)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(28) * T.int64(4) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(28) + ax2)
                        v_ax3, v_ax4 = T.axis.remap("SS", [ax3, ax4_fused])
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[8, 1, 1, 4])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[28, 1, 1, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 28, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 16, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[64, 8])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=11)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87 = sch.get_loops(block=b68)
l88 = sch.fuse(l71, l72, l73, l74, l75, preserve_unit_iters=True)
sch.parallel(loop=l88)
l89 = sch.fuse(l87, preserve_unit_iters=True)
sch.vectorize(loop=l89)
l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107, l108, l109, l110, l111 = sch.get_loops(block=b69)
l112 = sch.fuse(l90, preserve_unit_iters=True)
sch.parallel(loop=l112)
sch.annotate(block_or_loop=l112, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l112, ann_key="pragma_unroll_explicit", ann_val=1)
l113, l114, l115, l116, l117, l118 = sch.get_loops(block=b70)
l119 = sch.fuse(l118, preserve_unit_iters=True)
sch.vectorize(loop=l119)
b120 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141, l142 = sch.get_loops(block=b120)
b143 = sch.decompose_reduction(block=b120, loop=l127)
2024-04-30 14:32:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2851: GFLOPs: 659.5175. Time: 5610.4330 us. Best GFLOPs: 1005.7953
2024-04-30 14:32:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2852: GFLOPs: 589.0933. Time: 6281.1428 us. Best GFLOPs: 1005.7953
2024-04-30 14:32:00 [INFO] [task_scheduler.cc:121] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2853: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(512)), "float32"), p1: T.Buffer((T.int64(32), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused in T.parallel(T.int64(224), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(2), T.int64(14), T.int64(16), T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(28) * T.int64(4) + oc_chunk_1 * T.int64(4) + oc_chunk_2_init * T.int64(4) + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(28) // T.int64(2) * T.int64(2) + oh_1 * T.int64(2) + oh_2_init + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(2) * T.int64(14) + ow_1 * T.int64(14) + ow_2_init + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(16), oc_block_1 * T.int64(16) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0 in range(T.int64(64)):
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(16)):
                        for ax4_fused in T.vectorized(T.int64(8)):
                            with T.block("data_pad"):
                                v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                                v_i2 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(28) // T.int64(2) * T.int64(2) + ax2)
                                v_i3 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(2) * T.int64(14) + ax3)
                                v_i4 = T.axis.spatial(T.int64(512), ic_0 * T.int64(8) + ax4_fused)
                                T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                                T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                                data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                    for kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(2), T.int64(14), T.int64(16), T.int64(8), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(1)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(28) * T.int64(4) + oc_chunk_1 * T.int64(4) + oc_chunk_2 * T.int64(4) + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(28) // T.int64(2) * T.int64(2) + oh_1 * T.int64(2) + oh_2 + oh_3)
                            v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(2) * T.int64(14) + ow_1 * T.int64(14) + ow_2 + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_1 * T.int64(16) + oc_block_2 + oc_block_3)
                            v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(8) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(4), T.int64(2), T.int64(14)):
                for ax4_fused in T.vectorized(T.int64(16)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(28) * T.int64(4) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(28) // T.int64(2) * T.int64(2) + ax2)
                        v_ax3 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(2) * T.int64(14) + ax3)
                        v_ax4 = T.axis.spatial(T.int64(16), ax4_fused)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[8, 1, 1, 4])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[14, 1, 2, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[2, 1, 14, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 16, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[64, 8])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=10)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86 = sch.get_loops(block=b68)
l87 = sch.fuse(l71, l72, l73, l74, l75, preserve_unit_iters=True)
sch.parallel(loop=l87)
l88 = sch.fuse(l86, preserve_unit_iters=True)
sch.vectorize(loop=l88)
l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107, l108, l109, l110 = sch.get_loops(block=b69)
l111 = sch.fuse(l89, preserve_unit_iters=True)
sch.parallel(loop=l111)
sch.annotate(block_or_loop=l111, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l111, ann_key="pragma_unroll_explicit", ann_val=1)
l112, l113, l114, l115, l116, l117 = sch.get_loops(block=b70)
l118 = sch.fuse(l117, preserve_unit_iters=True)
sch.vectorize(loop=l118)
b119 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141 = sch.get_loops(block=b119)
b142 = sch.decompose_reduction(block=b119, loop=l126)
2024-04-30 14:32:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2854: GFLOPs: 486.0176. Time: 7613.2619 us. Best GFLOPs: 1005.7953
2024-04-30 14:32:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2855: GFLOPs: 92.4325. Time: 40031.1617 us. Best GFLOPs: 1005.7953
2024-04-30 14:32:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2856: GFLOPs: 537.1358. Time: 6888.7215 us. Best GFLOPs: 1005.7953
2024-04-30 14:32:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2857: GFLOPs: 577.5224. Time: 6406.9881 us. Best GFLOPs: 1005.7953
2024-04-30 14:32:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2858: GFLOPs: 364.8067. Time: 10142.8471 us. Best GFLOPs: 1005.7953
2024-04-30 14:32:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2859: GFLOPs: 555.8077. Time: 6657.3004 us. Best GFLOPs: 1005.7953
2024-04-30 14:32:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2860: GFLOPs: 578.4952. Time: 6396.2141 us. Best GFLOPs: 1005.7953
2024-04-30 14:32:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2861: GFLOPs: 683.8910. Time: 5410.4802 us. Best GFLOPs: 1005.7953
2024-04-30 14:32:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2862: GFLOPs: 722.8698. Time: 5118.7348 us. Best GFLOPs: 1005.7953
2024-04-30 14:32:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2863: GFLOPs: 458.0654. Time: 8077.8398 us. Best GFLOPs: 1005.7953
2024-04-30 14:32:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2864: GFLOPs: 562.4147. Time: 6579.0934 us. Best GFLOPs: 1005.7953
2024-04-30 14:32:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2865: GFLOPs: 624.1195. Time: 5928.6387 us. Best GFLOPs: 1005.7953
2024-04-30 14:32:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2866: GFLOPs: 689.2298. Time: 5368.5709 us. Best GFLOPs: 1005.7953
2024-04-30 14:32:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2867: GFLOPs: 537.1697. Time: 6888.2867 us. Best GFLOPs: 1005.7953
2024-04-30 14:32:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2868: GFLOPs: 579.0964. Time: 6389.5732 us. Best GFLOPs: 1005.7953
2024-04-30 14:32:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2869: GFLOPs: 565.2783. Time: 6545.7647 us. Best GFLOPs: 1005.7953
2024-04-30 14:32:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2870: GFLOPs: 726.1368. Time: 5095.7054 us. Best GFLOPs: 1005.7953
2024-04-30 14:32:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2871: GFLOPs: 737.2709. Time: 5018.7511 us. Best GFLOPs: 1005.7953
2024-04-30 14:32:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2872: GFLOPs: 101.9103. Time: 36308.1823 us. Best GFLOPs: 1005.7953
2024-04-30 14:32:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2873: GFLOPs: 638.8039. Time: 5792.3550 us. Best GFLOPs: 1005.7953
2024-04-30 14:32:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2874: GFLOPs: 549.4916. Time: 6733.8228 us. Best GFLOPs: 1005.7953
2024-04-30 14:32:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2875: GFLOPs: 417.5226. Time: 8862.2236 us. Best GFLOPs: 1005.7953
2024-04-30 14:32:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2876: GFLOPs: 399.8430. Time: 9254.0795 us. Best GFLOPs: 1005.7953
2024-04-30 14:32:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2877: GFLOPs: 440.8643. Time: 8393.0114 us. Best GFLOPs: 1005.7953
2024-04-30 14:32:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2878: GFLOPs: 51.2849. Time: 72149.4567 us. Best GFLOPs: 1005.7953
2024-04-30 14:32:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2879: GFLOPs: 82.0033. Time: 45122.3027 us. Best GFLOPs: 1005.7953
2024-04-30 14:32:00 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2880: GFLOPs: 22.6773. Time: 163166.9617 us. Best GFLOPs: 1005.7953
2024-04-30 14:32:00 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-30 14:32:02 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-30 14:32:06 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 14:32:06 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-30 14:32:19 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 14:32:33 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 14:32:47 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 14:33:01 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 14:33:10 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.7816  0.7742  0.7510  0.7503  0.7374  0.7203  0.7183  0.7154  0.7014  0.6832  0.6799  0.6793  0.6793  0.6790  0.6777  0.6737
[17 : 32]:	0.6638  0.6557  0.6502  0.6502  0.6492  0.6437  0.6345  0.6341  0.6301  0.6282  0.6221  0.6216  0.6199  0.6162  0.6108  0.6092
[33 : 48]:	0.6043  0.6031  0.5944  0.5931  0.5895  0.5882  0.5786  0.5732  0.5692  0.5659  0.5647  0.5603  0.5603  0.5526  0.5490  0.5446
[49 : 64]:	0.5445  0.5379  0.5379  0.5363  0.5349  0.5326  0.5292  0.5270  0.5259  0.5259  0.5192  0.5169  0.5100  0.5058  0.5043  0.5043
2024-04-30 14:33:10 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-30 14:33:10 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-30 14:35:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2881: GFLOPs: 792.4658. Time: 4669.1968 us. Best GFLOPs: 1005.7953
2024-04-30 14:35:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2882: GFLOPs: 774.4191. Time: 4778.0056 us. Best GFLOPs: 1005.7953
2024-04-30 14:35:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2883: GFLOPs: 372.6881. Time: 9928.3525 us. Best GFLOPs: 1005.7953
2024-04-30 14:35:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2884: GFLOPs: 765.3075. Time: 4834.8916 us. Best GFLOPs: 1005.7953
2024-04-30 14:35:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2885: GFLOPs: 767.0726. Time: 4823.7664 us. Best GFLOPs: 1005.7953
2024-04-30 14:35:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2886: GFLOPs: 79.8374. Time: 46346.4303 us. Best GFLOPs: 1005.7953
2024-04-30 14:35:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2887: GFLOPs: 671.8308. Time: 5507.6050 us. Best GFLOPs: 1005.7953
2024-04-30 14:35:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2888: GFLOPs: 741.5471. Time: 4989.8101 us. Best GFLOPs: 1005.7953
2024-04-30 14:35:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2889: GFLOPs: 701.4255. Time: 5275.2272 us. Best GFLOPs: 1005.7953
2024-04-30 14:35:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2890: GFLOPs: 664.7068. Time: 5566.6336 us. Best GFLOPs: 1005.7953
2024-04-30 14:35:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2891: GFLOPs: 721.5895. Time: 5127.8168 us. Best GFLOPs: 1005.7953
2024-04-30 14:35:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2892: GFLOPs: 689.7901. Time: 5364.2103 us. Best GFLOPs: 1005.7953
2024-04-30 14:35:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2893: GFLOPs: 697.0445. Time: 5308.3830 us. Best GFLOPs: 1005.7953
2024-04-30 14:35:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2894: GFLOPs: 383.2027. Time: 9655.9317 us. Best GFLOPs: 1005.7953
2024-04-30 14:35:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2895: GFLOPs: 609.1470. Time: 6074.3616 us. Best GFLOPs: 1005.7953
2024-04-30 14:35:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2896: GFLOPs: 738.8877. Time: 5007.7692 us. Best GFLOPs: 1005.7953
2024-04-30 14:35:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2897: GFLOPs: 498.7697. Time: 7418.6123 us. Best GFLOPs: 1005.7953
2024-04-30 14:35:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2898: GFLOPs: 656.3451. Time: 5637.5510 us. Best GFLOPs: 1005.7953
2024-04-30 14:35:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2899: GFLOPs: 741.5058. Time: 4990.0875 us. Best GFLOPs: 1005.7953
2024-04-30 14:35:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2900: GFLOPs: 683.0227. Time: 5417.3586 us. Best GFLOPs: 1005.7953
2024-04-30 14:35:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2901: GFLOPs: 644.2766. Time: 5743.1523 us. Best GFLOPs: 1005.7953
2024-04-30 14:35:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2902: GFLOPs: 762.9142. Time: 4850.0588 us. Best GFLOPs: 1005.7953
2024-04-30 14:35:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2903: GFLOPs: 656.3103. Time: 5637.8499 us. Best GFLOPs: 1005.7953
2024-04-30 14:35:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2904: GFLOPs: 672.4826. Time: 5502.2670 us. Best GFLOPs: 1005.7953
2024-04-30 14:35:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2905: GFLOPs: 628.7652. Time: 5884.8338 us. Best GFLOPs: 1005.7953
2024-04-30 14:35:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2906: GFLOPs: 441.9567. Time: 8372.2661 us. Best GFLOPs: 1005.7953
2024-04-30 14:35:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2907: GFLOPs: 686.4053. Time: 5390.6620 us. Best GFLOPs: 1005.7953
2024-04-30 14:35:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2908: GFLOPs: 687.4092. Time: 5382.7896 us. Best GFLOPs: 1005.7953
2024-04-30 14:35:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2909: GFLOPs: 841.5590. Time: 4396.8149 us. Best GFLOPs: 1005.7953
2024-04-30 14:35:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2910: GFLOPs: 553.0575. Time: 6690.4052 us. Best GFLOPs: 1005.7953
2024-04-30 14:35:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2911: GFLOPs: 640.0096. Time: 5781.4430 us. Best GFLOPs: 1005.7953
2024-04-30 14:35:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2912: GFLOPs: 632.7352. Time: 5847.9103 us. Best GFLOPs: 1005.7953
2024-04-30 14:35:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2913: GFLOPs: 708.9889. Time: 5218.9520 us. Best GFLOPs: 1005.7953
2024-04-30 14:35:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2914: GFLOPs: 631.4652. Time: 5859.6722 us. Best GFLOPs: 1005.7953
2024-04-30 14:35:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2915: GFLOPs: 663.0123. Time: 5580.8606 us. Best GFLOPs: 1005.7953
2024-04-30 14:35:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2916: GFLOPs: 666.8908. Time: 5548.4026 us. Best GFLOPs: 1005.7953
2024-04-30 14:35:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2917: GFLOPs: 598.5093. Time: 6182.3253 us. Best GFLOPs: 1005.7953
2024-04-30 14:35:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2918: GFLOPs: 354.3744. Time: 10441.4409 us. Best GFLOPs: 1005.7953
2024-04-30 14:35:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2919: GFLOPs: 601.0342. Time: 6156.3539 us. Best GFLOPs: 1005.7953
2024-04-30 14:35:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2920: GFLOPs: 550.0505. Time: 6726.9807 us. Best GFLOPs: 1005.7953
2024-04-30 14:35:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2921: GFLOPs: 601.2929. Time: 6153.7044 us. Best GFLOPs: 1005.7953
2024-04-30 14:35:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2922: GFLOPs: 596.5064. Time: 6203.0829 us. Best GFLOPs: 1005.7953
2024-04-30 14:35:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2923: GFLOPs: 675.7150. Time: 5475.9461 us. Best GFLOPs: 1005.7953
2024-04-30 14:35:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2924: GFLOPs: 588.2912. Time: 6289.7067 us. Best GFLOPs: 1005.7953
2024-04-30 14:35:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2925: GFLOPs: 585.6608. Time: 6317.9552 us. Best GFLOPs: 1005.7953
2024-04-30 14:35:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2926: GFLOPs: 492.9083. Time: 7506.8310 us. Best GFLOPs: 1005.7953
2024-04-30 14:35:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2927: GFLOPs: 469.7906. Time: 7876.2305 us. Best GFLOPs: 1005.7953
2024-04-30 14:35:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2928: GFLOPs: 613.0127. Time: 6036.0559 us. Best GFLOPs: 1005.7953
2024-04-30 14:35:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2929: GFLOPs: 551.2531. Time: 6712.3051 us. Best GFLOPs: 1005.7953
2024-04-30 14:35:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2930: GFLOPs: 521.4680. Time: 7095.6965 us. Best GFLOPs: 1005.7953
2024-04-30 14:35:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2931: GFLOPs: 660.0029. Time: 5606.3068 us. Best GFLOPs: 1005.7953
2024-04-30 14:35:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2932: GFLOPs: 649.1057. Time: 5700.4256 us. Best GFLOPs: 1005.7953
2024-04-30 14:35:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2933: GFLOPs: 398.6388. Time: 9282.0338 us. Best GFLOPs: 1005.7953
2024-04-30 14:35:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2934: GFLOPs: 642.0442. Time: 5763.1217 us. Best GFLOPs: 1005.7953
2024-04-30 14:35:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2935: GFLOPs: 590.5216. Time: 6265.9501 us. Best GFLOPs: 1005.7953
2024-04-30 14:35:41 [INFO] [task_scheduler.cc:121] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2936: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(512)), "float32"), p1: T.Buffer((T.int64(32), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_fused_fused in T.parallel(T.int64(224), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(6), T.int64(9), T.int64(512)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(28) // T.int64(4) * T.int64(4) + ax2)
                    v_i3 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(4) * T.int64(7) + ax3)
                    v_i4 = T.axis.spatial(T.int64(512), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oc_block_0 in range(T.int64(1)):
                for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(16)):
                    for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(1), T.int64(4), T.int64(2), T.int64(1), T.int64(1)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(28) * T.int64(4) + oc_chunk_1 * T.int64(4) + oc_chunk_2_init * T.int64(4) + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(28) // T.int64(4) * T.int64(4) + oh_1 * T.int64(2) + oh_2_init * T.int64(2) + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(4) * T.int64(7) + ow_1 * T.int64(7) + ow_2_init + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(16) + oc_block_1 + oc_block_2_init + oc_block_3_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                    for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(64), T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(2), T.int64(1), T.int64(1)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(28) * T.int64(4) + oc_chunk_1 * T.int64(4) + oc_chunk_2 * T.int64(4) + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(28) // T.int64(4) * T.int64(4) + oh_1 * T.int64(2) + oh_2 * T.int64(2) + oh_3)
                            v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(4) * T.int64(7) + ow_1 * T.int64(7) + ow_2 + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(16) + oc_block_1 + oc_block_2 + oc_block_3)
                            v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(8) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(4), T.int64(4), T.int64(7)):
                    for ax4_fused in T.vectorized(T.int64(16)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(28) * T.int64(4) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(28) // T.int64(4) * T.int64(4) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(4) * T.int64(7) + ax3)
                            v_ax4 = T.axis.spatial(T.int64(16), ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[8, 1, 1, 4])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[7, 2, 1, 2])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[4, 1, 7, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 16, 1, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[64, 8])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=112)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=3)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79 = sch.get_loops(block=b68)
l80 = sch.fuse(l71, l72, l73, l74, preserve_unit_iters=True)
sch.parallel(loop=l80)
l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l81, preserve_unit_iters=True)
sch.parallel(loop=l104)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109, l110, l111 = sch.get_loops(block=b70)
l112 = sch.fuse(l111, preserve_unit_iters=True)
sch.vectorize(loop=l112)
b113 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136 = sch.get_loops(block=b113)
b137 = sch.decompose_reduction(block=b113, loop=l121)
2024-04-30 14:35:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2937: GFLOPs: 591.3420. Time: 6257.2574 us. Best GFLOPs: 1005.7953
2024-04-30 14:35:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2938: GFLOPs: 592.4402. Time: 6245.6578 us. Best GFLOPs: 1005.7953
2024-04-30 14:35:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2939: GFLOPs: 498.9838. Time: 7415.4294 us. Best GFLOPs: 1005.7953
2024-04-30 14:35:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2940: GFLOPs: 98.7785. Time: 37459.3630 us. Best GFLOPs: 1005.7953
2024-04-30 14:35:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2941: GFLOPs: 508.6804. Time: 7274.0741 us. Best GFLOPs: 1005.7953
2024-04-30 14:35:41 [INFO] [task_scheduler.cc:121] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2942: Error in running:
LocalRunner: Timeout, killed after 30 seconds

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(512)), "float32"), p1: T.Buffer((T.int64(32), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)))
        for n_0 in T.serial(T.int64(1), annotations={"pragma_auto_unroll_max_step": 64, "pragma_unroll_explicit": 1}):
            for oc_chunk_0, oh_0, ow_0, oc_block_0 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                for n_1, oc_chunk_1, oh_1 in T.grid(T.int64(1), T.int64(2), T.int64(2)):
                    for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(16), T.int64(30), T.int64(512)):
                        with T.block("data_pad"):
                            v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                            v_i2 = T.axis.spatial(T.int64(30), oh_1 * T.int64(14) + ax2)
                            v_i3, v_i4 = T.axis.remap("SS", [ax3, ax4])
                            T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                            T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                            data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                    for ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(8)):
                        for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(2), T.int64(1), T.int64(1), T.int64(2), T.int64(4), T.int64(1)):
                            with T.block("conv2d_NCHWc_init"):
                                v_n = T.axis.spatial(T.int64(1), n_0 + n_1 + n_2_init + n_3_init)
                                v_oc_chunk = T.axis.spatial(T.int64(32), oc_chunk_0 * T.int64(32) + oc_chunk_1 * T.int64(16) + oc_chunk_2_init + oc_chunk_3_init)
                                v_oh = T.axis.spatial(T.int64(28), oh_0 * T.int64(28) + oh_1 * T.int64(14) + oh_2_init * T.int64(2) + oh_3_init)
                                v_ow = T.axis.spatial(T.int64(28), ow_0 * T.int64(28) + ow_1 * T.int64(28) + ow_2_init * T.int64(4) + ow_3_init)
                                v_oc_block = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(16) + oc_block_1 * T.int64(2) + oc_block_2_init + oc_block_3_init)
                                T.reads()
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                        for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(8), T.int64(3), T.int64(3), T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(2), T.int64(64), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(4), T.int64(1)):
                            with T.block("conv2d_NCHWc_update"):
                                v_n = T.axis.spatial(T.int64(1), n_0 + n_1 + n_2 + n_3)
                                v_oc_chunk = T.axis.spatial(T.int64(32), oc_chunk_0 * T.int64(32) + oc_chunk_1 * T.int64(16) + oc_chunk_2 + oc_chunk_3)
                                v_oh = T.axis.spatial(T.int64(28), oh_0 * T.int64(28) + oh_1 * T.int64(14) + oh_2 * T.int64(2) + oh_3)
                                v_ow = T.axis.spatial(T.int64(28), ow_0 * T.int64(28) + ow_1 * T.int64(28) + ow_2 * T.int64(4) + ow_3)
                                v_oc_block = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(16) + oc_block_1 * T.int64(2) + oc_block_2 + oc_block_3)
                                v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(64) + ic_1)
                                v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                                v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                                T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(32), T.int64(28), T.int64(28)):
                    for ax4_fused in T.vectorized(T.int64(16)):
                        with T.block("T_relu"):
                            v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4_fused])
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 2, 16, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 2, 7, 2])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 7, 4])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 8, 2, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[8, 64])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=7)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83 = sch.get_loops(block=b68)
l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107, l108, l109 = sch.get_loops(block=b69)
sch.annotate(block_or_loop=l84, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l84, ann_key="pragma_unroll_explicit", ann_val=1)
l110, l111, l112, l113, l114, l115, l116, l117, l118, l119 = sch.get_loops(block=b70)
l120 = sch.fuse(l119, preserve_unit_iters=True)
sch.vectorize(loop=l120)
b121 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141, l142, l143, l144, l145, l146, l147 = sch.get_loops(block=b121)
b148 = sch.decompose_reduction(block=b121, loop=l132)
2024-04-30 14:35:41 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2943: GFLOPs: 21.3963. Time: 172935.2577 us. Best GFLOPs: 1005.7953
2024-04-30 14:35:41 [INFO] [task_scheduler.cc:121] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2944: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(512)), "float32"), p1: T.Buffer((T.int64(32), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused in T.parallel(T.int64(128), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(2), T.int64(28), T.int64(7), T.int64(2), T.int64(1), T.int64(2), T.int64(1), T.int64(1)):
                for oc_block_3_fused_init in T.vectorized(T.int64(2)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(8) * T.int64(4) + oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(28), oh_2_init + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused // T.int64(32) * T.int64(7) + ow_2_init + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(32) // T.int64(8) * T.int64(4) + oc_block_2_init * T.int64(2) + oc_block_3_fused_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
            for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(8), T.int64(3), T.int64(3), T.int64(1), T.int64(2), T.int64(28), T.int64(7), T.int64(2), T.int64(64), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1)):
                for oc_block_3_fused in T.vectorized(T.int64(2)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(8) * T.int64(4) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(28), oh_2 + oh_3)
                        v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused // T.int64(32) * T.int64(7) + ow_2 + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(32) // T.int64(8) * T.int64(4) + oc_block_2 * T.int64(2) + oc_block_3_fused)
                        v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(64) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], p0[v_n, v_ic // T.int64(512), v_oh + v_kh - T.int64(1), v_ow + v_kw - T.int64(1), v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + T.if_then_else(T.int64(1) <= v_oh + v_kh and v_oh + v_kh < T.int64(29) and T.int64(1) <= v_ow + v_kw and v_ow + v_kw < T.int64(29), p0[v_n, v_ic // T.int64(512), v_oh + v_kh - T.int64(1), v_ow + v_kw - T.int64(1), v_ic % T.int64(512)], T.float32(0)) * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(4), T.int64(28), T.int64(7)):
                for ax4_fused in T.vectorized(T.int64(4)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(8) * T.int64(4) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(28), ax2)
                        v_ax3 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused // T.int64(32) * T.int64(7) + ax3)
                        v_ax4 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(32) // T.int64(8) * T.int64(4) + ax4_fused)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 8, 2, 2])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 28, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[4, 1, 7, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[4, 1, 2, 2])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[8, 64])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=-2)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69 = sch.get_child_blocks(b67)
l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95 = sch.get_loops(block=b68)
l96 = sch.fuse(l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, preserve_unit_iters=True)
sch.parallel(loop=l96)
l97 = sch.fuse(l95, preserve_unit_iters=True)
sch.vectorize(loop=l97)
sch.annotate(block_or_loop=l96, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l96, ann_key="pragma_unroll_explicit", ann_val=1)
l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l103, preserve_unit_iters=True)
sch.vectorize(loop=l104)
b105 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l106, l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117, l118, l119, l120, l121, l122 = sch.get_loops(block=b105)
b123 = sch.decompose_reduction(block=b105, loop=l107)
2024-04-30 14:44:53 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-30 14:44:55 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-30 14:44:59 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 14:44:59 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-30 14:45:12 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 14:45:26 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 14:45:41 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 14:45:55 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x54bf4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x36471c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x309bbe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x54ad6d8)]: 0 failure(s)
2024-04-30 14:46:04 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.8343  0.8232  0.8038  0.7829  0.7437  0.7211  0.7149  0.7071  0.7054  0.7020  0.6958  0.6876  0.6723  0.6703  0.6672  0.6662
[17 : 32]:	0.6646  0.6622  0.6539  0.6506  0.6460  0.6451  0.6417  0.6400  0.6382  0.6374  0.6230  0.6204  0.6127  0.6104  0.6097  0.6095
[33 : 48]:	0.6005  0.5996  0.5979  0.5933  0.5894  0.5859  0.5772  0.5742  0.5720  0.5640  0.5600  0.5524  0.5510  0.5455  0.5447  0.5440
[49 : 64]:	0.5421  0.5365  0.5363  0.5361  0.5352  0.5320  0.5286  0.5257  0.5247  0.5217  0.5188  0.5179  0.5159  0.5139  0.5057  0.5042
2024-04-30 14:46:04 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-30 14:46:04 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-30 14:49:01 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2945: GFLOPs: 837.3646. Time: 4418.8384 us. Best GFLOPs: 1005.7953
2024-04-30 14:49:01 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2946: GFLOPs: 837.5054. Time: 4418.0958 us. Best GFLOPs: 1005.7953
2024-04-30 14:49:01 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2947: GFLOPs: 829.4370. Time: 4461.0731 us. Best GFLOPs: 1005.7953
2024-04-30 14:49:01 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2948: GFLOPs: 765.9539. Time: 4830.8119 us. Best GFLOPs: 1005.7953
2024-04-30 14:49:01 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2949: GFLOPs: 675.1298. Time: 5480.6929 us. Best GFLOPs: 1005.7953
2024-04-30 14:49:01 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2950: GFLOPs: 676.6081. Time: 5468.7180 us. Best GFLOPs: 1005.7953
2024-04-30 14:49:01 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2951: GFLOPs: 743.9835. Time: 4973.4693 us. Best GFLOPs: 1005.7953
2024-04-30 14:49:01 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2952: GFLOPs: 665.7452. Time: 5557.9503 us. Best GFLOPs: 1005.7953
2024-04-30 14:49:01 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2953: GFLOPs: 703.1452. Time: 5262.3258 us. Best GFLOPs: 1005.7953
2024-04-30 14:49:01 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2954: GFLOPs: 746.7661. Time: 4954.9369 us. Best GFLOPs: 1005.7953
2024-04-30 14:49:01 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2955: GFLOPs: 759.0502. Time: 4874.7484 us. Best GFLOPs: 1005.7953
2024-04-30 14:49:01 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2956: GFLOPs: 687.4745. Time: 5382.2781 us. Best GFLOPs: 1005.7953
2024-04-30 14:49:01 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2957: GFLOPs: 357.4949. Time: 10350.2985 us. Best GFLOPs: 1005.7953
2024-04-30 14:49:01 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2958: GFLOPs: 666.9617. Time: 5547.8136 us. Best GFLOPs: 1005.7953
2024-04-30 14:49:01 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2959: GFLOPs: 764.1045. Time: 4842.5040 us. Best GFLOPs: 1005.7953
2024-04-30 14:49:01 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2960: GFLOPs: 656.0262. Time: 5640.2918 us. Best GFLOPs: 1005.7953
2024-04-30 14:49:01 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2961: GFLOPs: 733.1386. Time: 5047.0386 us. Best GFLOPs: 1005.7953
2024-04-30 14:49:01 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2962: GFLOPs: 694.0330. Time: 5331.4167 us. Best GFLOPs: 1005.7953
2024-04-30 14:49:01 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2963: GFLOPs: 671.9446. Time: 5506.6729 us. Best GFLOPs: 1005.7953
2024-04-30 14:49:01 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2964: GFLOPs: 625.1861. Time: 5918.5239 us. Best GFLOPs: 1005.7953
2024-04-30 14:49:01 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2965: GFLOPs: 744.9686. Time: 4966.8923 us. Best GFLOPs: 1005.7953
2024-04-30 14:49:01 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2966: GFLOPs: 615.6115. Time: 6010.5743 us. Best GFLOPs: 1005.7953
2024-04-30 14:49:01 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2967: GFLOPs: 644.8591. Time: 5737.9646 us. Best GFLOPs: 1005.7953
2024-04-30 14:49:01 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2968: GFLOPs: 668.0409. Time: 5538.8508 us. Best GFLOPs: 1005.7953
2024-04-30 14:49:01 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2969: GFLOPs: 679.2758. Time: 5447.2408 us. Best GFLOPs: 1005.7953
2024-04-30 14:49:01 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2970: GFLOPs: 704.2440. Time: 5254.1147 us. Best GFLOPs: 1005.7953
2024-04-30 14:49:01 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2971: GFLOPs: 634.5209. Time: 5831.4534 us. Best GFLOPs: 1005.7953
2024-04-30 14:49:01 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2972: GFLOPs: 634.6274. Time: 5830.4751 us. Best GFLOPs: 1005.7953
2024-04-30 14:49:01 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2973: GFLOPs: 574.6508. Time: 6439.0042 us. Best GFLOPs: 1005.7953
2024-04-30 14:49:01 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2974: GFLOPs: 571.2560. Time: 6477.2693 us. Best GFLOPs: 1005.7953
2024-04-30 14:49:01 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2975: GFLOPs: 616.6167. Time: 6000.7765 us. Best GFLOPs: 1005.7953
2024-04-30 14:49:01 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2976: GFLOPs: 733.3858. Time: 5045.3376 us. Best GFLOPs: 1005.7953
2024-04-30 14:49:01 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2977: GFLOPs: 594.1088. Time: 6228.1163 us. Best GFLOPs: 1005.7953
2024-04-30 14:49:01 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2978: GFLOPs: 646.7670. Time: 5721.0382 us. Best GFLOPs: 1005.7953
2024-04-30 14:49:01 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2979: GFLOPs: 654.4724. Time: 5653.6820 us. Best GFLOPs: 1005.7953
2024-04-30 14:49:01 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2980: GFLOPs: 631.1863. Time: 5862.2615 us. Best GFLOPs: 1005.7953
2024-04-30 14:49:01 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2981: GFLOPs: 577.7451. Time: 6404.5180 us. Best GFLOPs: 1005.7953
2024-04-30 14:49:01 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2982: GFLOPs: 523.2699. Time: 7071.2633 us. Best GFLOPs: 1005.7953
2024-04-30 14:49:01 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2983: GFLOPs: 581.3020. Time: 6365.3298 us. Best GFLOPs: 1005.7953
2024-04-30 14:49:01 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2984: GFLOPs: 515.8055. Time: 7173.5938 us. Best GFLOPs: 1005.7953
2024-04-30 14:49:01 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2985: GFLOPs: 636.1429. Time: 5816.5842 us. Best GFLOPs: 1005.7953
2024-04-30 14:49:01 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2986: GFLOPs: 645.7125. Time: 5730.3817 us. Best GFLOPs: 1005.7953
2024-04-30 14:49:01 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2987: GFLOPs: 627.9814. Time: 5892.1794 us. Best GFLOPs: 1005.7953
2024-04-30 14:49:01 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2988: GFLOPs: 589.0161. Time: 6281.9654 us. Best GFLOPs: 1005.7953
2024-04-30 14:49:01 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2989: GFLOPs: 581.6596. Time: 6361.4160 us. Best GFLOPs: 1005.7953
2024-04-30 14:49:01 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2990: GFLOPs: 522.8234. Time: 7077.3014 us. Best GFLOPs: 1005.7953
2024-04-30 14:49:01 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2991: GFLOPs: 608.2813. Time: 6083.0067 us. Best GFLOPs: 1005.7953
2024-04-30 14:49:01 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2992: GFLOPs: 538.1972. Time: 6875.1366 us. Best GFLOPs: 1005.7953
2024-04-30 14:49:01 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2993: GFLOPs: 657.1125. Time: 5630.9672 us. Best GFLOPs: 1005.7953
2024-04-30 14:49:01 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2994: GFLOPs: 666.8669. Time: 5548.6021 us. Best GFLOPs: 1005.7953
2024-04-30 14:49:01 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2995: GFLOPs: 508.3135. Time: 7279.3249 us. Best GFLOPs: 1005.7953
2024-04-30 14:49:01 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2996: GFLOPs: 635.9136. Time: 5818.6816 us. Best GFLOPs: 1005.7953
2024-04-30 14:49:01 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2997: GFLOPs: 567.7992. Time: 6516.7032 us. Best GFLOPs: 1005.7953
2024-04-30 14:49:01 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2998: GFLOPs: 509.8385. Time: 7257.5504 us. Best GFLOPs: 1005.7953
2024-04-30 14:49:01 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2999: GFLOPs: 122.2403. Time: 30269.7130 us. Best GFLOPs: 1005.7953
2024-04-30 14:49:01 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #3000: GFLOPs: 530.7344. Time: 6971.8098 us. Best GFLOPs: 1005.7953
2024-04-30 14:49:01 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #3001: GFLOPs: 93.7945. Time: 39449.8383 us. Best GFLOPs: 1005.7953
2024-04-30 14:49:01 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #3002: GFLOPs: 595.7446. Time: 6211.0155 us. Best GFLOPs: 1005.7953
2024-04-30 14:49:01 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #3003: GFLOPs: 413.7900. Time: 8942.1669 us. Best GFLOPs: 1005.7953
2024-04-30 14:49:01 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #3004: GFLOPs: 561.1251. Time: 6594.2139 us. Best GFLOPs: 1005.7953
2024-04-30 14:49:01 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #3005: GFLOPs: 104.4219. Time: 35434.8957 us. Best GFLOPs: 1005.7953
2024-04-30 14:49:01 [INFO] [task_scheduler.cc:121] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #3006: Error in running:
LocalRunner: Timeout, killed after 30 seconds

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(512)), "float32"), p1: T.Buffer((T.int64(32), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)))
        for n_0 in T.serial(T.int64(1), annotations={"pragma_auto_unroll_max_step": 16, "pragma_unroll_explicit": 1}):
            for oc_chunk_0, oh_0, ow_0, oc_block_0 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                for n_1, oc_chunk_1 in T.grid(T.int64(1), T.int64(2)):
                    for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(512)):
                        with T.block("data_pad"):
                            v_i0, v_i1, v_i2, v_i3, v_i4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                            T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                            T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                            data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                    for oh_1, ow_1, oc_block_1 in T.grid(T.int64(14), T.int64(2), T.int64(2)):
                        for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(8), T.int64(1), T.int64(2), T.int64(8), T.int64(1), T.int64(2), T.int64(2), T.int64(7), T.int64(1)):
                            with T.block("conv2d_NCHWc_init"):
                                v_n = T.axis.spatial(T.int64(1), n_0 + n_1 + n_2_init + n_3_init)
                                v_oc_chunk = T.axis.spatial(T.int64(32), oc_chunk_0 * T.int64(32) + oc_chunk_1 * T.int64(16) + oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                                v_oh = T.axis.spatial(T.int64(28), oh_0 * T.int64(28) + oh_1 * T.int64(2) + oh_2_init * T.int64(2) + oh_3_init)
                                v_ow = T.axis.spatial(T.int64(28), ow_0 * T.int64(28) + ow_1 * T.int64(14) + ow_2_init * T.int64(7) + ow_3_init)
                                v_oc_block = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(16) + oc_block_1 * T.int64(8) + oc_block_2_init + oc_block_3_init)
                                T.reads()
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                        for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(64), T.int64(1), T.int64(1), T.int64(1), T.int64(8), T.int64(1), T.int64(2), T.int64(8), T.int64(8), T.int64(3), T.int64(3), T.int64(1), T.int64(2), T.int64(2), T.int64(7), T.int64(1)):
                            with T.block("conv2d_NCHWc_update"):
                                v_n = T.axis.spatial(T.int64(1), n_0 + n_1 + n_2 + n_3)
                                v_oc_chunk = T.axis.spatial(T.int64(32), oc_chunk_0 * T.int64(32) + oc_chunk_1 * T.int64(16) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                                v_oh = T.axis.spatial(T.int64(28), oh_0 * T.int64(28) + oh_1 * T.int64(2) + oh_2 * T.int64(2) + oh_3)
                                v_ow = T.axis.spatial(T.int64(28), ow_0 * T.int64(28) + ow_1 * T.int64(14) + ow_2 * T.int64(7) + ow_3)
                                v_oc_block = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(16) + oc_block_1 * T.int64(8) + oc_block_2 + oc_block_3)
                                v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(8) + ic_1)
                                v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                                v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                                T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(32), T.int64(28), T.int64(28)):
                    for ax4_fused in T.vectorized(T.int64(16)):
                        with T.block("T_relu"):
                            v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4_fused])
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 2, 8, 2])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 14, 1, 2])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 2, 2, 7])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 2, 8, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[64, 8])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=6)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82 = sch.get_loops(block=b68)
l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107, l108 = sch.get_loops(block=b69)
sch.annotate(block_or_loop=l83, ann_key="pragma_auto_unroll_max_step", ann_val=16)
sch.annotate(block_or_loop=l83, ann_key="pragma_unroll_explicit", ann_val=1)
l109, l110, l111, l112, l113, l114, l115, l116, l117, l118 = sch.get_loops(block=b70)
l119 = sch.fuse(l118, preserve_unit_iters=True)
sch.vectorize(loop=l119)
b120 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141, l142, l143, l144, l145, l146 = sch.get_loops(block=b120)
b147 = sch.decompose_reduction(block=b120, loop=l131)
2024-04-30 14:49:01 [INFO] [task_scheduler.cc:131] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #3007: GFLOPs: 8.9170. Time: 414956.1687 us. Best GFLOPs: 1005.7953
2024-04-30 14:49:01 [INFO] [task_scheduler.cc:121] [Task #17: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #3008: Error in running:
LocalRunner: Timeout, killed after 30 seconds

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(512)), "float32"), p1: T.Buffer((T.int64(32), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(28), T.int64(28), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused in T.parallel(T.int64(2), annotations={"pragma_auto_unroll_max_step": 16, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1 in T.grid(T.int64(1), T.int64(8)):
                for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(30), T.int64(16), T.int64(512)):
                    with T.block("data_pad"):
                        v_i0, v_i1, v_i2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                        v_i3 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused * T.int64(14) + ax3)
                        v_i4 = T.axis.spatial(T.int64(512), ax4)
                        T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                        T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                        data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                for oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(16)):
                    for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(2), T.int64(4), T.int64(7), T.int64(1), T.int64(1), T.int64(2), T.int64(7), T.int64(2), T.int64(1)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(32), oc_chunk_1 * T.int64(4) + oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(28), oh_1 * T.int64(28) + oh_2_init * T.int64(7) + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused * T.int64(14) + ow_1 * T.int64(14) + ow_2_init * T.int64(2) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_1 + oc_block_2_init + oc_block_3_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                    for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(16), T.int64(3), T.int64(3), T.int64(1), T.int64(2), T.int64(4), T.int64(7), T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(7), T.int64(2), T.int64(1)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(32), oc_chunk_1 * T.int64(4) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(28), oh_1 * T.int64(28) + oh_2 * T.int64(7) + oh_3)
                            v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused * T.int64(14) + ow_1 * T.int64(14) + ow_2 * T.int64(2) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_1 + oc_block_2 + oc_block_3)
                            v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(32) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(32), T.int64(28), T.int64(14)):
                for ax4_fused in T.vectorized(T.int64(16)):
                    with T.block("T_relu"):
                        v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                        v_ax3 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused * T.int64(14) + ax3)
                        v_ax4 = T.axis.spatial(T.int64(16), ax4_fused)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 8, 2, 2])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 4, 7])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[2, 1, 7, 2])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 16, 1, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[16, 32])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=6)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82 = sch.get_loops(block=b68)
l83 = sch.fuse(l71, l72, l73, l74, l75, preserve_unit_iters=True)
sch.parallel(loop=l83)
l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105 = sch.get_loops(block=b69)
l106 = sch.fuse(l84, preserve_unit_iters=True)
sch.parallel(loop=l106)
sch.annotate(block_or_loop=l106, ann_key="pragma_auto_unroll_max_step", ann_val=16)
sch.annotate(block_or_loop=l106, ann_key="pragma_unroll_explicit", ann_val=1)
l107, l108, l109, l110, l111, l112 = sch.get_loops(block=b70)
l113 = sch.fuse(l112, preserve_unit_iters=True)
sch.vectorize(loop=l113)
b114 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136 = sch.get_loops(block=b114)
b137 = sch.decompose_reduction(block=b114, loop=l121)
