2024-04-30 05:29:32 [INFO] [task_scheduler.cc:160] Initializing Task #6: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3"
2024-04-30 05:29:32 [INFO] [task_scheduler.cc:35] 
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(112), T.int64(112), T.int64(64)), "float32"), p1: T.Buffer((T.int64(2), T.int64(2), T.int64(3), T.int64(3), T.int64(64), T.int64(64)), "float32"), p2: T.Buffer((T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(64)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(2), T.int64(112), T.int64(112), T.int64(64)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(114), T.int64(114), T.int64(64)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(112), T.int64(112), T.int64(64)))
        T_add = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(112), T.int64(112), T.int64(64)))
        for i0, i1, i2, i3, i4 in T.grid(T.int64(1), T.int64(2), T.int64(114), T.int64(114), T.int64(64)):
            with T.block("data_pad"):
                v_i0, v_i1, v_i2, v_i3, v_i4 = T.axis.remap("SSSSS", [i0, i1, i2, i3, i4])
                T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(113) and T.int64(1) <= v_i3 and v_i3 < T.int64(113), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
        for n, oc_chunk, oh, ow, oc_block, ic, kh, kw in T.grid(T.int64(1), T.int64(2), T.int64(112), T.int64(112), T.int64(64), T.int64(128), T.int64(3), T.int64(3)):
            with T.block("conv2d_NCHWc"):
                v_n, v_oc_chunk, v_oh, v_ow, v_oc_block, v_ic, v_kh, v_kw = T.axis.remap("SSSSSRRR", [n, oc_chunk, oh, ow, oc_block, ic, kh, kw])
                T.reads(data_pad[v_n, v_ic // T.int64(64), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(64)], p1[v_oc_chunk, v_ic // T.int64(64), v_kh, v_kw, v_ic % T.int64(64), v_oc_block])
                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                with T.init():
                    conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(64), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(64)] * p1[v_oc_chunk, v_ic // T.int64(64), v_kh, v_kw, v_ic % T.int64(64), v_oc_block]
        for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(2), T.int64(112), T.int64(112), T.int64(64)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                T.writes(T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4]
        for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(2), T.int64(112), T.int64(112), T.int64(64)):
            with T.block("T_relu"):
                v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                T.reads(T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
2024-04-30 05:29:32 [INFO] [task_scheduler.cc:164] Total 3 design space(s) generated
2024-04-30 05:29:32 [INFO] [task_scheduler.cc:170] Design space #0:
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(112), T.int64(112), T.int64(64)), "float32"), p1: T.Buffer((T.int64(2), T.int64(2), T.int64(3), T.int64(3), T.int64(64), T.int64(64)), "float32"), p2: T.Buffer((T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(64)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(2), T.int64(112), T.int64(112), T.int64(64)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel": 768, "meta_schedule.unroll_explicit": 64, "meta_schedule.vectorize": 64})
            data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(114), T.int64(114), T.int64(64)))
            conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(112), T.int64(112), T.int64(64)))
            for n_0, oc_chunk_0, oh_0, ow_0 in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(56)):
                for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(2), T.int64(114), T.int64(4), T.int64(64)):
                    with T.block("data_pad"):
                        v_i0, v_i1, v_i2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                        v_i3 = T.axis.spatial(T.int64(114), ow_0 * T.int64(2) + ax3)
                        v_i4 = T.axis.spatial(T.int64(64), ax4)
                        T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                        T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                        data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(113) and T.int64(1) <= v_i3 and v_i3 < T.int64(113), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                for oc_block_0, n_1, oc_chunk_1, oh_1, ow_1, oc_block_1, ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(16), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(2), T.int64(2), T.int64(64), T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(8), T.int64(1), T.int64(2)):
                    with T.block("conv2d_NCHWc"):
                        v_n = T.axis.spatial(T.int64(1), n_0 + n_1 + n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(2), oc_chunk_0 + oc_chunk_1 + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(112), oh_0 * T.int64(112) + oh_1 * T.int64(56) + oh_2 * T.int64(8) + oh_3)
                        v_ow = T.axis.spatial(T.int64(112), ow_0 * T.int64(2) + ow_1 * T.int64(2) + ow_2 + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(64), oc_block_0 * T.int64(64) + oc_block_1 * T.int64(4) + oc_block_2 * T.int64(2) + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(128), ic_0 * T.int64(64) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                        T.reads(data_pad[v_n, v_ic // T.int64(64), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(64)], p1[v_oc_chunk, v_ic // T.int64(64), v_kh, v_kw, v_ic % T.int64(64), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        with T.init():
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(64), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(64)] * p1[v_oc_chunk, v_ic // T.int64(64), v_kh, v_kw, v_ic % T.int64(64), v_oc_block]
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(2), T.int64(112), T.int64(112), T.int64(64)):
                with T.block("T_relu"):
                    v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                    T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                    T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[2, 1, 1, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 2, 7, 8])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[56, 1, 2, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 16, 2, 2])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[2, 64])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
l65 = sch.sample_compute_location(block=b0, decision=3)
sch.compute_at(block=b0, loop=l65, preserve_unit_loops=True, index=-1)
2024-04-30 05:29:32 [INFO] [task_scheduler.cc:170] Design space #1:
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(112), T.int64(112), T.int64(64)), "float32"), p1: T.Buffer((T.int64(2), T.int64(2), T.int64(3), T.int64(3), T.int64(64), T.int64(64)), "float32"), p2: T.Buffer((T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(64)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(2), T.int64(112), T.int64(112), T.int64(64)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel": 768, "meta_schedule.unroll_explicit": 0, "meta_schedule.vectorize": 64})
            data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(114), T.int64(114), T.int64(64)))
            conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(112), T.int64(112), T.int64(64)))
            for n_0, oc_chunk_0, oh_0, ow_0 in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(56)):
                for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(2), T.int64(114), T.int64(4), T.int64(64)):
                    with T.block("data_pad"):
                        v_i0, v_i1, v_i2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                        v_i3 = T.axis.spatial(T.int64(114), ow_0 * T.int64(2) + ax3)
                        v_i4 = T.axis.spatial(T.int64(64), ax4)
                        T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                        T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                        data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(113) and T.int64(1) <= v_i3 and v_i3 < T.int64(113), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                for oc_block_0, n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(16)):
                    for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(2), T.int64(2), T.int64(64), T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(8), T.int64(1), T.int64(2)):
                        with T.block("conv2d_NCHWc"):
                            v_n = T.axis.spatial(T.int64(1), n_0 + n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(2), oc_chunk_0 + oc_chunk_1 + oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(112), oh_0 * T.int64(112) + oh_1 * T.int64(56) + oh_2 * T.int64(8) + oh_3)
                            v_ow = T.axis.spatial(T.int64(112), ow_0 * T.int64(2) + ow_1 * T.int64(2) + ow_2 + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(64), oc_block_0 * T.int64(64) + oc_block_1 * T.int64(4) + oc_block_2 * T.int64(2) + oc_block_3)
                            v_ic = T.axis.reduce(T.int64(128), ic_0 * T.int64(64) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                            T.reads(data_pad[v_n, v_ic // T.int64(64), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(64)], p1[v_oc_chunk, v_ic // T.int64(64), v_kh, v_kw, v_ic % T.int64(64), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            with T.init():
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(64), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(64)] * p1[v_oc_chunk, v_ic // T.int64(64), v_kh, v_kw, v_ic % T.int64(64), v_oc_block]
                    for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(56), T.int64(2), T.int64(4)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(2), oc_chunk_0 + ax1)
                            v_ax2 = T.axis.spatial(T.int64(112), oh_1 * T.int64(56) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(112), ow_0 * T.int64(2) + ax3)
                            v_ax4 = T.axis.spatial(T.int64(64), oc_block_1 * T.int64(4) + ax4)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[2, 1, 1, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 2, 7, 8])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[56, 1, 2, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 16, 2, 2])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[2, 64])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=3)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
2024-04-30 05:29:32 [INFO] [task_scheduler.cc:170] Design space #2:
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(112), T.int64(112), T.int64(64)), "float32"), p1: T.Buffer((T.int64(2), T.int64(2), T.int64(3), T.int64(3), T.int64(64), T.int64(64)), "float32"), p2: T.Buffer((T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(64)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(2), T.int64(112), T.int64(112), T.int64(64)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel": 768, "meta_schedule.unroll_explicit": 0, "meta_schedule.vectorize": 64})
            data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(114), T.int64(114), T.int64(64)))
            conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(112), T.int64(112), T.int64(64)))
            for n_0, oc_chunk_0, oh_0, ow_0, oc_block_0 in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(56), T.int64(1)):
                for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(16)):
                    for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(2), T.int64(58), T.int64(4), T.int64(64)):
                        with T.block("data_pad"):
                            v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                            v_i2 = T.axis.spatial(T.int64(114), oh_1 * T.int64(56) + ax2)
                            v_i3 = T.axis.spatial(T.int64(114), ow_0 * T.int64(2) + ax3)
                            v_i4 = T.axis.spatial(T.int64(64), ax4)
                            T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                            T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                            data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(113) and T.int64(1) <= v_i3 and v_i3 < T.int64(113), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                    for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(2), T.int64(2), T.int64(64), T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(8), T.int64(1), T.int64(2)):
                        with T.block("conv2d_NCHWc"):
                            v_n = T.axis.spatial(T.int64(1), n_0 + n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(2), oc_chunk_0 + oc_chunk_1 + oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(112), oh_0 * T.int64(112) + oh_1 * T.int64(56) + oh_2 * T.int64(8) + oh_3)
                            v_ow = T.axis.spatial(T.int64(112), ow_0 * T.int64(2) + ow_1 * T.int64(2) + ow_2 + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(64), oc_block_0 * T.int64(64) + oc_block_1 * T.int64(4) + oc_block_2 * T.int64(2) + oc_block_3)
                            v_ic = T.axis.reduce(T.int64(128), ic_0 * T.int64(64) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                            T.reads(data_pad[v_n, v_ic // T.int64(64), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(64)], p1[v_oc_chunk, v_ic // T.int64(64), v_kh, v_kw, v_ic % T.int64(64), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            with T.init():
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(64), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(64)] * p1[v_oc_chunk, v_ic // T.int64(64), v_kh, v_kw, v_ic % T.int64(64), v_oc_block]
                for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(112), T.int64(2), T.int64(64)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(2), oc_chunk_0 + ax1)
                        v_ax2 = T.axis.spatial(T.int64(112), ax2)
                        v_ax3 = T.axis.spatial(T.int64(112), ow_0 * T.int64(2) + ax3)
                        v_ax4 = T.axis.spatial(T.int64(64), ax4)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[2, 1, 1, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 2, 7, 8])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[56, 1, 2, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 16, 2, 2])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[2, 64])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=9)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
2024-04-30 05:43:16 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-30 05:43:16 [INFO] [evolutionary_search.cc:715] Picked top 0 candidate(s) from database
2024-04-30 05:43:22 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x315e438)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x371f878)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3352b68)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x36bf9a8)]: 0 failure(s)
2024-04-30 05:43:22 [INFO] [evolutionary_search.cc:723] Sampled 512 candidate(s)
2024-04-30 05:43:28 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x315e438)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x371f878)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3352b68)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x36bf9a8)]: 0 failure(s)
2024-04-30 05:43:35 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x315e438)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x371f878)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3352b68)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x36bf9a8)]: 0 failure(s)
2024-04-30 05:43:41 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x315e438)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x371f878)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3352b68)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x36bf9a8)]: 0 failure(s)
2024-04-30 05:43:48 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x315e438)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x371f878)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3352b68)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x36bf9a8)]: 0 failure(s)
2024-04-30 05:43:49 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9990  0.9979  0.9977  0.9969  0.9969  0.9967  0.9959  0.9953  0.9945  0.9944  0.9942  0.9941  0.9914  0.9913  0.9911  0.9910
[17 : 32]:	0.9908  0.9886  0.9883  0.9882  0.9878  0.9876  0.9874  0.9867  0.9853  0.9852  0.9851  0.9847  0.9845  0.9844  0.9838  0.9836
[33 : 48]:	0.9829  0.9827  0.9823  0.9821  0.9806  0.9804  0.9799  0.9797  0.9795  0.9788  0.9785  0.9785  0.9782  0.9782  0.9777  0.9776
[49 : 64]:	0.9765  0.9759  0.9758  0.9752  0.9752  0.9751  0.9750  0.9749  0.9748  0.9724  0.9722  0.9715  0.9710  0.9701  0.9699  0.9694
2024-04-30 05:43:49 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-30 05:43:49 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-30 06:42:05 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #1: GFLOPs: 7.8755. Time: 470141.2367 us. Best GFLOPs: 7.8755
2024-04-30 06:42:05 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #2: GFLOPs: 6.3356. Time: 584406.7657 us. Best GFLOPs: 7.8755
2024-04-30 06:42:05 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #3: GFLOPs: 17.2272. Time: 214926.3020 us. Best GFLOPs: 17.2272
2024-04-30 06:42:05 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #4: GFLOPs: 39.1896. Time: 94478.8327 us. Best GFLOPs: 39.1896
2024-04-30 06:42:05 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #5: GFLOPs: 91.0443. Time: 40667.9680 us. Best GFLOPs: 91.0443
2024-04-30 06:42:05 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #6: GFLOPs: 20.8820. Time: 177310.0643 us. Best GFLOPs: 91.0443
2024-04-30 06:42:05 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #7: GFLOPs: 3.6807. Time: 1005942.3487 us. Best GFLOPs: 91.0443
2024-04-30 06:42:05 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #8: GFLOPs: 198.4729. Time: 18655.3765 us. Best GFLOPs: 198.4729
2024-04-30 06:42:05 [INFO] [task_scheduler.cc:121] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #9: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(112), T.int64(112), T.int64(64)), "float32"), p1: T.Buffer((T.int64(2), T.int64(2), T.int64(3), T.int64(3), T.int64(64), T.int64(64)), "float32"), p2: T.Buffer((T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(64)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(2), T.int64(112), T.int64(112), T.int64(64)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(114), T.int64(114), T.int64(64)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(112), T.int64(112), T.int64(64)))
        for n_0_oc_chunk_0_oh_0_fused_fused in T.parallel(T.int64(4), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(2), T.int64(30), T.int64(114)):
                for ax4_fused in T.vectorized(T.int64(64)):
                    with T.block("data_pad"):
                        v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                        v_i2 = T.axis.spatial(T.int64(114), n_0_oc_chunk_0_oh_0_fused_fused * T.int64(28) + ax2)
                        v_i3, v_i4 = T.axis.remap("SS", [ax3, ax4_fused])
                        T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                        T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                        data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(113) and T.int64(1) <= v_i3 and v_i3 < T.int64(113), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for ow_0, oc_block_0, n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(8), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(2)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(28), T.int64(56), T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(2), oc_chunk_1 + oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(112), n_0_oc_chunk_0_oh_0_fused_fused * T.int64(28) + oh_1 * T.int64(28) + oh_2_init + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(112), ow_0 * T.int64(112) + ow_1 * T.int64(112) + ow_2_init * T.int64(2) + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(64), oc_block_0 * T.int64(8) + oc_block_1 * T.int64(4) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(8), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(28), T.int64(56), T.int64(4), T.int64(16), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(2), oc_chunk_1 + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(112), n_0_oc_chunk_0_oh_0_fused_fused * T.int64(28) + oh_1 * T.int64(28) + oh_2 + oh_3)
                        v_ow = T.axis.spatial(T.int64(112), ow_0 * T.int64(112) + ow_1 * T.int64(112) + ow_2 * T.int64(2) + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(64), oc_block_0 * T.int64(8) + oc_block_1 * T.int64(4) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(128), ic_0 * T.int64(16) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(64), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(64)], p1[v_oc_chunk, v_ic // T.int64(64), v_kh, v_kw, v_ic % T.int64(64), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(64), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(64)] * p1[v_oc_chunk, v_ic // T.int64(64), v_kh, v_kw, v_ic % T.int64(64), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(28), T.int64(112)):
                    for ax4_fused in T.vectorized(T.int64(4)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(2), oc_chunk_1 + ax1)
                            v_ax2 = T.axis.spatial(T.int64(112), n_0_oc_chunk_0_oh_0_fused_fused * T.int64(28) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(112), ax3)
                            v_ax4 = T.axis.spatial(T.int64(64), oc_block_0 * T.int64(8) + oc_block_1 * T.int64(4) + ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 2, 1, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[4, 1, 28, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 56, 2])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[8, 2, 4, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[8, 16])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=2)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78 = sch.get_loops(block=b68)
l79 = sch.fuse(l71, l72, l73, preserve_unit_iters=True)
sch.parallel(loop=l79)
l80 = sch.fuse(l78, preserve_unit_iters=True)
sch.vectorize(loop=l80)
l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b69)
l105 = sch.fuse(l81, preserve_unit_iters=True)
sch.parallel(loop=l105)
sch.annotate(block_or_loop=l105, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l105, ann_key="pragma_unroll_explicit", ann_val=1)
l106, l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117, l118 = sch.get_loops(block=b70)
l119 = sch.fuse(l118, preserve_unit_iters=True)
sch.vectorize(loop=l119)
b120 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141, l142, l143, l144 = sch.get_loops(block=b120)
b145 = sch.decompose_reduction(block=b120, loop=l129)
2024-04-30 06:42:05 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #10: GFLOPs: 72.3436. Time: 51180.5857 us. Best GFLOPs: 198.4729
2024-04-30 06:42:05 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #11: GFLOPs: 61.5866. Time: 60120.0637 us. Best GFLOPs: 198.4729
2024-04-30 06:42:05 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #12: GFLOPs: 183.1250. Time: 20218.9078 us. Best GFLOPs: 198.4729
2024-04-30 06:42:05 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #13: GFLOPs: 72.9855. Time: 50730.4443 us. Best GFLOPs: 198.4729
2024-04-30 06:42:05 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #14: GFLOPs: 91.0854. Time: 40649.6200 us. Best GFLOPs: 198.4729
2024-04-30 06:42:05 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #15: GFLOPs: 218.3403. Time: 16957.8717 us. Best GFLOPs: 218.3403
2024-04-30 06:42:05 [INFO] [task_scheduler.cc:121] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #16: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(112), T.int64(112), T.int64(64)), "float32"), p1: T.Buffer((T.int64(2), T.int64(2), T.int64(3), T.int64(3), T.int64(64), T.int64(64)), "float32"), p2: T.Buffer((T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(64)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(2), T.int64(112), T.int64(112), T.int64(64)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(114), T.int64(114), T.int64(64)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(112), T.int64(112), T.int64(64)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused in T.parallel(T.int64(784), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(2), T.int64(4), T.int64(18)):
                for ax4_fused in T.vectorized(T.int64(64)):
                    with T.block("data_pad"):
                        v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                        v_i2 = T.axis.spatial(T.int64(114), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(56) * T.int64(2) + ax2)
                        v_i3 = T.axis.spatial(T.int64(114), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(112) * T.int64(16) + ax3)
                        v_i4 = T.axis.spatial(T.int64(64), ax4_fused)
                        T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                        T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                        data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(113) and T.int64(1) <= v_i3 and v_i3 < T.int64(113), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for ow_1, oc_block_1 in T.grid(T.int64(4), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(4), T.int64(8), T.int64(1), T.int64(1), T.int64(2), T.int64(1)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(2), oc_chunk_2_init + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(112), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(56) * T.int64(2) + oh_2_init * T.int64(2) + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(112), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(112) * T.int64(16) + ow_1 * T.int64(4) + ow_2_init + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(64), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(112) // T.int64(56) * T.int64(32) + oc_block_1 * T.int64(32) + oc_block_2_init * T.int64(4) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(16), T.int64(1), T.int64(3), T.int64(1), T.int64(2), T.int64(1), T.int64(4), T.int64(8), T.int64(8), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1)):
                    for oc_block_3_fused in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(2), oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(112), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(56) * T.int64(2) + oh_2 * T.int64(2) + oh_3)
                            v_ow = T.axis.spatial(T.int64(112), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(112) * T.int64(16) + ow_1 * T.int64(4) + ow_2 + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(64), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(112) // T.int64(56) * T.int64(32) + oc_block_1 * T.int64(32) + oc_block_2 * T.int64(4) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(128), ic_0 * T.int64(8) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(64), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(64)], p1[v_oc_chunk, v_ic // T.int64(64), v_kh, v_kw, v_ic % T.int64(64), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(64), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(64)] * p1[v_oc_chunk, v_ic // T.int64(64), v_kh, v_kw, v_ic % T.int64(64), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(2), T.int64(2), T.int64(4)):
                    for ax4_fused in T.vectorized(T.int64(32)):
                        with T.block("T_relu"):
                            v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                            v_ax2 = T.axis.spatial(T.int64(112), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(56) * T.int64(2) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(112), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(112) * T.int64(16) + ow_1 * T.int64(4) + ax3)
                            v_ax4 = T.axis.spatial(T.int64(64), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(112) // T.int64(56) * T.int64(32) + ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 2, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 56, 1, 2])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[7, 4, 4, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[2, 1, 8, 4])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[16, 8])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=7)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83 = sch.get_loops(block=b68)
l84 = sch.fuse(l71, l72, l73, l74, l75, l76, l77, l78, preserve_unit_iters=True)
sch.parallel(loop=l84)
l85 = sch.fuse(l83, preserve_unit_iters=True)
sch.vectorize(loop=l85)
l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b69)
l105 = sch.fuse(l86, preserve_unit_iters=True)
sch.parallel(loop=l105)
l106 = sch.fuse(l104, preserve_unit_iters=True)
sch.vectorize(loop=l106)
sch.annotate(block_or_loop=l105, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l105, ann_key="pragma_unroll_explicit", ann_val=1)
l107, l108, l109, l110, l111, l112, l113, l114 = sch.get_loops(block=b70)
l115 = sch.fuse(l114, preserve_unit_iters=True)
sch.vectorize(loop=l115)
b116 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135 = sch.get_loops(block=b116)
b136 = sch.decompose_reduction(block=b116, loop=l120)
2024-04-30 06:42:05 [INFO] [task_scheduler.cc:121] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #17: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(112), T.int64(112), T.int64(64)), "float32"), p1: T.Buffer((T.int64(2), T.int64(2), T.int64(3), T.int64(3), T.int64(64), T.int64(64)), "float32"), p2: T.Buffer((T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(64)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(2), T.int64(112), T.int64(112), T.int64(64)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(114), T.int64(114), T.int64(64)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(112), T.int64(112), T.int64(64)))
        for n_0_oc_chunk_0_oh_0_ow_0_fused_fused in T.parallel(T.int64(224), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(2), T.int64(4), T.int64(30)):
                for ax4_fused in T.vectorized(T.int64(64)):
                    with T.block("data_pad"):
                        v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                        v_i2 = T.axis.spatial(T.int64(114), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(4) * T.int64(2) + ax2)
                        v_i3 = T.axis.spatial(T.int64(114), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(4) * T.int64(28) + ax3)
                        v_i4 = T.axis.spatial(T.int64(64), ax4_fused)
                        T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                        T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                        data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(113) and T.int64(1) <= v_i3 and v_i3 < T.int64(113), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oc_block_0, n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(8), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(2), T.int64(4)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(2), oc_chunk_1 * T.int64(2) + oc_chunk_2_init + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(112), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(4) * T.int64(2) + oh_1 * T.int64(2) + oh_2_init * T.int64(2) + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(112), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(4) * T.int64(28) + ow_1 * T.int64(4) + ow_2_init * T.int64(4) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(64), oc_block_0 * T.int64(8) + oc_block_1 * T.int64(8) + oc_block_2_init * T.int64(4) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(2), T.int64(3), T.int64(3), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(2), T.int64(64), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(4)):
                    for oc_block_3_fused in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(2), oc_chunk_1 * T.int64(2) + oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(112), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(4) * T.int64(2) + oh_1 * T.int64(2) + oh_2 * T.int64(2) + oh_3)
                            v_ow = T.axis.spatial(T.int64(112), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(4) * T.int64(28) + ow_1 * T.int64(4) + ow_2 * T.int64(4) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(64), oc_block_0 * T.int64(8) + oc_block_1 * T.int64(8) + oc_block_2 * T.int64(4) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(128), ic_0 * T.int64(64) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(64), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(64)], p1[v_oc_chunk, v_ic // T.int64(64), v_kh, v_kw, v_ic % T.int64(64), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(64), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(64)] * p1[v_oc_chunk, v_ic // T.int64(64), v_kh, v_kw, v_ic % T.int64(64), v_oc_block]
        for ax0_ax1_ax2_ax3_ax4_fused_0 in T.parallel(T.int64(25088)):
            for ax0_ax1_ax2_ax3_ax4_fused_1 in T.vectorized(T.int64(64)):
                with T.block("T_relu"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(2), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) // T.int64(802816))
                    v_ax2 = T.axis.spatial(T.int64(112), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(802816) // T.int64(7168))
                    v_ax3 = T.axis.spatial(T.int64(112), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(7168) // T.int64(64))
                    v_ax4 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(64))
                    T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                    T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 2, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[56, 1, 1, 2])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[4, 7, 1, 4])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[8, 1, 2, 4])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[2, 64])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
l65 = sch.sample_compute_location(block=b0, decision=3)
sch.compute_at(block=b0, loop=l65, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b66 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.unroll_explicit")
b67, b68, b69 = sch.get_child_blocks(b66)
l70, l71, l72, l73, l74, l75, l76, l77, l78 = sch.get_loops(block=b67)
l79 = sch.fuse(l70, l71, l72, l73, preserve_unit_iters=True)
sch.parallel(loop=l79)
l80 = sch.fuse(l78, preserve_unit_iters=True)
sch.vectorize(loop=l80)
l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b68)
l104 = sch.fuse(l81, preserve_unit_iters=True)
sch.parallel(loop=l104)
l105 = sch.fuse(l103, preserve_unit_iters=True)
sch.vectorize(loop=l105)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l106, l107, l108, l109, l110 = sch.get_loops(block=b69)
l111 = sch.fuse(l106, l107, l108, l109, l110, preserve_unit_iters=True)
l112, l113 = sch.split(loop=l111, factors=[None, 64], preserve_unit_iters=True)
sch.parallel(loop=l112)
sch.vectorize(loop=l113)
b114 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137 = sch.get_loops(block=b114)
b138 = sch.decompose_reduction(block=b114, loop=l122)
2024-04-30 06:42:05 [INFO] [task_scheduler.cc:121] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #18: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(112), T.int64(112), T.int64(64)), "float32"), p1: T.Buffer((T.int64(2), T.int64(2), T.int64(3), T.int64(3), T.int64(64), T.int64(64)), "float32"), p2: T.Buffer((T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(64)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(2), T.int64(112), T.int64(112), T.int64(64)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(114), T.int64(114), T.int64(64)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(112), T.int64(112), T.int64(64)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused in T.parallel(T.int64(56), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(112), T.int64(2), T.int64(8)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(8)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(2), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(28) + oc_chunk_1 + oc_chunk_2_init + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(112), oh_1 + oh_2_init + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(112), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(28) * T.int64(4) + ow_1 * T.int64(2) + ow_2_init * T.int64(2) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(64), oc_block_1 * T.int64(8) + oc_block_2_init * T.int64(8) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1 in T.grid(T.int64(4), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(32), T.int64(3)):
                    for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1)):
                        with T.block("data_pad"):
                            v_i0 = T.axis.spatial(T.int64(1), ax0)
                            v_i1 = T.axis.spatial(T.int64(2), ic_0 // T.int64(2) + ax1)
                            v_i2 = T.axis.spatial(T.int64(114), oh_1 + kh_1 + ax2)
                            v_i3 = T.axis.spatial(T.int64(114), kw_0 + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(28) * T.int64(4) + ow_1 * T.int64(2) + ax3)
                            v_i4 = T.axis.spatial(T.int64(64), ic_0 % T.int64(2) * T.int64(32) + ic_1 + ax4)
                            T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                            T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                            data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(113) and T.int64(1) <= v_i3 and v_i3 < T.int64(113), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                    for kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2)):
                        for oc_block_3_fused in T.vectorized(T.int64(8)):
                            with T.block("conv2d_NCHWc_update"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                                v_oc_chunk = T.axis.spatial(T.int64(2), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(28) + oc_chunk_1 + oc_chunk_2 + oc_chunk_3)
                                v_oh = T.axis.spatial(T.int64(112), oh_1 + oh_2 + oh_3)
                                v_ow = T.axis.spatial(T.int64(112), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(28) * T.int64(4) + ow_1 * T.int64(2) + ow_2 * T.int64(2) + ow_3)
                                v_oc_block = T.axis.spatial(T.int64(64), oc_block_1 * T.int64(8) + oc_block_2 * T.int64(8) + oc_block_3_fused)
                                v_ic = T.axis.reduce(T.int64(128), ic_0 * T.int64(32) + ic_1)
                                v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                                v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                                T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(64), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(64)], p1[v_oc_chunk, v_ic // T.int64(64), v_kh, v_kw, v_ic % T.int64(64), v_oc_block])
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(64), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(64)] * p1[v_oc_chunk, v_ic // T.int64(64), v_kh, v_kw, v_ic % T.int64(64), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(112), T.int64(4)):
                for ax4_fused in T.vectorized(T.int64(64)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(2), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(28) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(112), ax2)
                        v_ax3 = T.axis.spatial(T.int64(112), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(28) * T.int64(4) + ax3)
                        v_ax4 = T.axis.spatial(T.int64(64), ax4_fused)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[2, 1, 1, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 112, 1, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[28, 2, 1, 2])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 8, 1, 8])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[4, 32])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=19)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95 = sch.get_loops(block=b68)
l96 = sch.fuse(l71, l72, l73, l74, l75, preserve_unit_iters=True)
sch.parallel(loop=l96)
l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117, l118 = sch.get_loops(block=b69)
l119 = sch.fuse(l97, preserve_unit_iters=True)
sch.parallel(loop=l119)
l120 = sch.fuse(l118, preserve_unit_iters=True)
sch.vectorize(loop=l120)
sch.annotate(block_or_loop=l119, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l119, ann_key="pragma_unroll_explicit", ann_val=1)
l121, l122, l123, l124, l125, l126 = sch.get_loops(block=b70)
l127 = sch.fuse(l126, preserve_unit_iters=True)
sch.vectorize(loop=l127)
b128 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141, l142, l143, l144, l145, l146, l147, l148, l149, l150 = sch.get_loops(block=b128)
b151 = sch.decompose_reduction(block=b128, loop=l135)
2024-04-30 06:42:05 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #19: GFLOPs: 44.8751. Time: 82508.7410 us. Best GFLOPs: 218.3403
2024-04-30 06:42:05 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #20: GFLOPs: 64.7990. Time: 57139.6020 us. Best GFLOPs: 218.3403
2024-04-30 06:42:05 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #21: GFLOPs: 82.6767. Time: 44783.9383 us. Best GFLOPs: 218.3403
2024-04-30 06:42:05 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #22: GFLOPs: 24.2612. Time: 152613.6940 us. Best GFLOPs: 218.3403
2024-04-30 06:42:05 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #23: GFLOPs: 54.9193. Time: 67418.6900 us. Best GFLOPs: 218.3403
2024-04-30 06:42:05 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #24: GFLOPs: 60.3197. Time: 61382.7120 us. Best GFLOPs: 218.3403
2024-04-30 06:42:05 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #25: GFLOPs: 46.3445. Time: 79892.7790 us. Best GFLOPs: 218.3403
2024-04-30 06:42:05 [INFO] [task_scheduler.cc:121] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #26: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(112), T.int64(112), T.int64(64)), "float32"), p1: T.Buffer((T.int64(2), T.int64(2), T.int64(3), T.int64(3), T.int64(64), T.int64(64)), "float32"), p2: T.Buffer((T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(64)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(2), T.int64(112), T.int64(112), T.int64(64)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(114), T.int64(114), T.int64(64)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(112), T.int64(112), T.int64(64)))
        for i0_i1_i2_i3_fused in T.parallel(T.int64(25992)):
            for i4_fused in T.vectorized(T.int64(64)):
                with T.block("data_pad"):
                    v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_i1 = T.axis.spatial(T.int64(2), i0_i1_i2_i3_fused // T.int64(12996))
                    v_i2 = T.axis.spatial(T.int64(114), i0_i1_i2_i3_fused % T.int64(12996) // T.int64(114))
                    v_i3 = T.axis.spatial(T.int64(114), i0_i1_i2_i3_fused % T.int64(114))
                    v_i4 = T.axis.spatial(T.int64(64), i4_fused)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(113) and T.int64(1) <= v_i3 and v_i3 < T.int64(113), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused in T.parallel(T.int64(8), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(14), T.int64(4)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(1), T.int64(14), T.int64(2), T.int64(2), T.int64(1), T.int64(1), T.int64(4), T.int64(2)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(2), oc_chunk_1 + oc_chunk_2_init + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(112), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused // T.int64(4) * T.int64(56) + oh_1 * T.int64(56) + oh_2_init * T.int64(4) + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(112), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused % T.int64(4) // T.int64(2) * T.int64(56) + ow_1 * T.int64(4) + ow_2_init * T.int64(2) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(64), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused % T.int64(2) * T.int64(32) + oc_block_1 * T.int64(8) + oc_block_2_init * T.int64(4) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(8), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(14), T.int64(2), T.int64(2), T.int64(16), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(4), T.int64(2)):
                    for oc_block_3_fused in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(2), oc_chunk_1 + oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(112), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused // T.int64(4) * T.int64(56) + oh_1 * T.int64(56) + oh_2 * T.int64(4) + oh_3)
                            v_ow = T.axis.spatial(T.int64(112), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused % T.int64(4) // T.int64(2) * T.int64(56) + ow_1 * T.int64(4) + ow_2 * T.int64(2) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(64), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused % T.int64(2) * T.int64(32) + oc_block_1 * T.int64(8) + oc_block_2 * T.int64(4) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(128), ic_0 * T.int64(16) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(64), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(64)], p1[v_oc_chunk, v_ic // T.int64(64), v_kh, v_kw, v_ic % T.int64(64), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(64), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(64)] * p1[v_oc_chunk, v_ic // T.int64(64), v_kh, v_kw, v_ic % T.int64(64), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(2), T.int64(56), T.int64(56)):
                for ax4_fused in T.vectorized(T.int64(32)):
                    with T.block("T_relu"):
                        v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                        v_ax2 = T.axis.spatial(T.int64(112), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused // T.int64(4) * T.int64(56) + ax2)
                        v_ax3 = T.axis.spatial(T.int64(112), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused % T.int64(4) // T.int64(2) * T.int64(56) + ax3)
                        v_ax4 = T.axis.spatial(T.int64(64), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused % T.int64(2) * T.int64(32) + ax4_fused)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 2, 1, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 1, 14, 4])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[2, 14, 2, 2])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[2, 4, 2, 4])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[8, 16])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=-1)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75 = sch.get_loops(block=b68)
l76 = sch.fuse(l71, l72, l73, l74, preserve_unit_iters=True)
sch.parallel(loop=l76)
l77 = sch.fuse(l75, preserve_unit_iters=True)
sch.vectorize(loop=l77)
l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l78, l79, l80, l81, l82, preserve_unit_iters=True)
sch.parallel(loop=l104)
l105 = sch.fuse(l103, preserve_unit_iters=True)
sch.vectorize(loop=l105)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l106, l107, l108, l109, l110, l111 = sch.get_loops(block=b70)
l112 = sch.fuse(l111, preserve_unit_iters=True)
sch.vectorize(loop=l112)
b113 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135 = sch.get_loops(block=b113)
b136 = sch.decompose_reduction(block=b113, loop=l120)
2024-04-30 06:42:05 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #27: GFLOPs: 65.0237. Time: 56942.1117 us. Best GFLOPs: 218.3403
2024-04-30 06:42:05 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #28: GFLOPs: 61.8725. Time: 59842.1687 us. Best GFLOPs: 218.3403
2024-04-30 06:42:05 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #29: GFLOPs: 5.0180. Time: 737866.8203 us. Best GFLOPs: 218.3403
2024-04-30 06:42:05 [INFO] [task_scheduler.cc:121] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #30: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(112), T.int64(112), T.int64(64)), "float32"), p1: T.Buffer((T.int64(2), T.int64(2), T.int64(3), T.int64(3), T.int64(64), T.int64(64)), "float32"), p2: T.Buffer((T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(64)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(2), T.int64(112), T.int64(112), T.int64(64)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(114), T.int64(114), T.int64(64)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(112), T.int64(112), T.int64(64)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused in T.parallel(T.int64(56), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(8), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(2), T.int64(2), T.int64(4), T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(8)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(2), oc_chunk_1 * T.int64(2) + oc_chunk_2_init + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(112), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(8) * T.int64(16) + oh_1 * T.int64(2) + oh_2_init + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(112), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(8) // T.int64(2) * T.int64(28) + ow_1 * T.int64(28) + ow_2_init * T.int64(7) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(64), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(2) * T.int64(32) + oc_block_1 * T.int64(32) + oc_block_2_init * T.int64(8) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0 in range(T.int64(16)):
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(30)):
                        for ax4_fused in T.vectorized(T.int64(8)):
                            with T.block("data_pad"):
                                v_i0 = T.axis.spatial(T.int64(1), ax0)
                                v_i1 = T.axis.spatial(T.int64(2), ic_0 // T.int64(8) + ax1)
                                v_i2 = T.axis.spatial(T.int64(114), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(8) * T.int64(16) + oh_1 * T.int64(2) + ax2)
                                v_i3 = T.axis.spatial(T.int64(114), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(8) // T.int64(2) * T.int64(28) + ax3)
                                v_i4 = T.axis.spatial(T.int64(64), ic_0 % T.int64(8) * T.int64(8) + ax4_fused)
                                T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                                T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                                data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(113) and T.int64(1) <= v_i3 and v_i3 < T.int64(113), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                    for kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(2), T.int64(4), T.int64(4), T.int64(8), T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                        for oc_block_3_fused in T.vectorized(T.int64(8)):
                            with T.block("conv2d_NCHWc_update"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                                v_oc_chunk = T.axis.spatial(T.int64(2), oc_chunk_1 * T.int64(2) + oc_chunk_2 + oc_chunk_3)
                                v_oh = T.axis.spatial(T.int64(112), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(8) * T.int64(16) + oh_1 * T.int64(2) + oh_2 + oh_3)
                                v_ow = T.axis.spatial(T.int64(112), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(8) // T.int64(2) * T.int64(28) + ow_1 * T.int64(28) + ow_2 * T.int64(7) + ow_3)
                                v_oc_block = T.axis.spatial(T.int64(64), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(2) * T.int64(32) + oc_block_1 * T.int64(32) + oc_block_2 * T.int64(8) + oc_block_3_fused)
                                v_ic = T.axis.reduce(T.int64(128), ic_0 * T.int64(8) + ic_1)
                                v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                                v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                                T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(64), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(64)], p1[v_oc_chunk, v_ic // T.int64(64), v_kh, v_kw, v_ic % T.int64(64), v_oc_block])
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(64), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(64)] * p1[v_oc_chunk, v_ic // T.int64(64), v_kh, v_kw, v_ic % T.int64(64), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(2), T.int64(16), T.int64(28)):
                for ax4_fused in T.vectorized(T.int64(32)):
                    with T.block("T_relu"):
                        v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                        v_ax2 = T.axis.spatial(T.int64(112), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(8) * T.int64(16) + ax2)
                        v_ax3 = T.axis.spatial(T.int64(112), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(8) // T.int64(2) * T.int64(28) + ax3)
                        v_ax4 = T.axis.spatial(T.int64(64), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(2) * T.int64(32) + ax4_fused)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 2, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[7, 8, 2, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[4, 1, 4, 7])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[2, 1, 4, 8])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[16, 8])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=10)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86 = sch.get_loops(block=b68)
l87 = sch.fuse(l71, l72, l73, l74, l75, preserve_unit_iters=True)
sch.parallel(loop=l87)
l88 = sch.fuse(l86, preserve_unit_iters=True)
sch.vectorize(loop=l88)
l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107, l108, l109, l110 = sch.get_loops(block=b69)
l111 = sch.fuse(l89, preserve_unit_iters=True)
sch.parallel(loop=l111)
l112 = sch.fuse(l110, preserve_unit_iters=True)
sch.vectorize(loop=l112)
sch.annotate(block_or_loop=l111, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l111, ann_key="pragma_unroll_explicit", ann_val=1)
l113, l114, l115, l116, l117, l118 = sch.get_loops(block=b70)
l119 = sch.fuse(l118, preserve_unit_iters=True)
sch.vectorize(loop=l119)
b120 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141, l142 = sch.get_loops(block=b120)
b143 = sch.decompose_reduction(block=b120, loop=l127)
2024-04-30 06:42:05 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #31: GFLOPs: 5.3312. Time: 694516.9437 us. Best GFLOPs: 218.3403
2024-04-30 06:42:05 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #32: GFLOPs: 40.1628. Time: 92189.4183 us. Best GFLOPs: 218.3403
2024-04-30 06:42:05 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #33: GFLOPs: 53.2898. Time: 69480.1720 us. Best GFLOPs: 218.3403
2024-04-30 06:42:05 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #34: GFLOPs: 2.7240. Time: 1359238.3200 us. Best GFLOPs: 218.3403
2024-04-30 06:42:05 [INFO] [task_scheduler.cc:121] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #35: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(112), T.int64(112), T.int64(64)), "float32"), p1: T.Buffer((T.int64(2), T.int64(2), T.int64(3), T.int64(3), T.int64(64), T.int64(64)), "float32"), p2: T.Buffer((T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(64)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(2), T.int64(112), T.int64(112), T.int64(64)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(114), T.int64(114), T.int64(64)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(112), T.int64(112), T.int64(64)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused in T.parallel(T.int64(28), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1, ow_1 in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(4)):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(2), T.int64(6), T.int64(30)):
                    for ax4_fused in T.vectorized(T.int64(64)):
                        with T.block("data_pad"):
                            v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                            v_i2 = T.axis.spatial(T.int64(114), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused * T.int64(4) + ax2)
                            v_i3 = T.axis.spatial(T.int64(114), ow_1 * T.int64(28) + ax3)
                            v_i4 = T.axis.spatial(T.int64(64), ax4_fused)
                            T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                            T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                            data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(113) and T.int64(1) <= v_i3 and v_i3 < T.int64(113), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                for oc_block_1 in range(T.int64(32)):
                    for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(14), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(2), oc_chunk_1 + oc_chunk_2_init + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(112), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused * T.int64(4) + oh_1 * T.int64(4) + oh_2_init + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(112), ow_1 * T.int64(28) + ow_2_init * T.int64(2) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(64), oc_block_1 * T.int64(2) + oc_block_2_init + oc_block_3_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                    for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(32), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(4), T.int64(14), T.int64(2), T.int64(4), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(2), oc_chunk_1 + oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(112), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused * T.int64(4) + oh_1 * T.int64(4) + oh_2 + oh_3)
                            v_ow = T.axis.spatial(T.int64(112), ow_1 * T.int64(28) + ow_2 * T.int64(2) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(64), oc_block_1 * T.int64(2) + oc_block_2 + oc_block_3)
                            v_ic = T.axis.reduce(T.int64(128), ic_0 * T.int64(4) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(64), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(64)], p1[v_oc_chunk, v_ic // T.int64(64), v_kh, v_kw, v_ic % T.int64(64), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(64), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(64)] * p1[v_oc_chunk, v_ic // T.int64(64), v_kh, v_kw, v_ic % T.int64(64), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(2), T.int64(4), T.int64(112)):
                for ax4_fused in T.vectorized(T.int64(64)):
                    with T.block("T_relu"):
                        v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                        v_ax2 = T.axis.spatial(T.int64(112), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused * T.int64(4) + ax2)
                        v_ax3, v_ax4 = T.axis.remap("SS", [ax3, ax4_fused])
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 2, 1, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[28, 1, 4, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 4, 14, 2])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 32, 2, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[32, 4])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=8)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b68)
l85 = sch.fuse(l71, l72, l73, l74, l75, preserve_unit_iters=True)
sch.parallel(loop=l85)
l86 = sch.fuse(l84, preserve_unit_iters=True)
sch.vectorize(loop=l86)
l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107, l108 = sch.get_loops(block=b69)
l109 = sch.fuse(l87, preserve_unit_iters=True)
sch.parallel(loop=l109)
sch.annotate(block_or_loop=l109, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l109, ann_key="pragma_unroll_explicit", ann_val=1)
l110, l111, l112, l113, l114, l115 = sch.get_loops(block=b70)
l116 = sch.fuse(l115, preserve_unit_iters=True)
sch.vectorize(loop=l116)
b117 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139 = sch.get_loops(block=b117)
b140 = sch.decompose_reduction(block=b117, loop=l124)
2024-04-30 06:42:05 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #36: GFLOPs: 6.6391. Time: 557690.4267 us. Best GFLOPs: 218.3403
2024-04-30 06:42:05 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #37: GFLOPs: 42.1551. Time: 87832.4550 us. Best GFLOPs: 218.3403
2024-04-30 06:42:05 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #38: GFLOPs: 147.5938. Time: 25086.3393 us. Best GFLOPs: 218.3403
2024-04-30 06:42:05 [INFO] [task_scheduler.cc:121] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #39: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(112), T.int64(112), T.int64(64)), "float32"), p1: T.Buffer((T.int64(2), T.int64(2), T.int64(3), T.int64(3), T.int64(64), T.int64(64)), "float32"), p2: T.Buffer((T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(64)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(2), T.int64(112), T.int64(112), T.int64(64)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(114), T.int64(114), T.int64(64)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(112), T.int64(112), T.int64(64)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused in T.parallel(T.int64(1024), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(2), T.int64(9), T.int64(16)):
                for ax4_fused in T.vectorized(T.int64(64)):
                    with T.block("data_pad"):
                        v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                        v_i2 = T.axis.spatial(T.int64(114), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(512) // T.int64(256) * T.int64(56) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(16) // T.int64(2) * T.int64(7) + ax2)
                        v_i3 = T.axis.spatial(T.int64(114), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(256) // T.int64(64) * T.int64(28) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(2) * T.int64(14) + ax3)
                        v_i4 = T.axis.spatial(T.int64(64), ax4_fused)
                        T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                        T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                        data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(113) and T.int64(1) <= v_i3 and v_i3 < T.int64(113), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oc_block_1 in range(T.int64(2)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(2), T.int64(1), T.int64(1), T.int64(7), T.int64(7)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(2), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(512) + oc_chunk_2_init + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(112), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(512) // T.int64(256) * T.int64(56) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(16) // T.int64(2) * T.int64(7) + oh_2_init * T.int64(7) + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(112), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(256) // T.int64(64) * T.int64(28) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(2) * T.int64(14) + ow_2_init * T.int64(7) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(64), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(64) // T.int64(16) * T.int64(16) + oc_block_1 * T.int64(8) + oc_block_2_init * T.int64(4) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(64), T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(2), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(7)):
                    for oc_block_3_fused in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(2), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(512) + oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(112), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(512) // T.int64(256) * T.int64(56) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(16) // T.int64(2) * T.int64(7) + oh_2 * T.int64(7) + oh_3)
                            v_ow = T.axis.spatial(T.int64(112), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(256) // T.int64(64) * T.int64(28) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(2) * T.int64(14) + ow_2 * T.int64(7) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(64), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(64) // T.int64(16) * T.int64(16) + oc_block_1 * T.int64(8) + oc_block_2 * T.int64(4) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(128), ic_0 * T.int64(2) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(64), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(64)], p1[v_oc_chunk, v_ic // T.int64(64), v_kh, v_kw, v_ic % T.int64(64), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(64), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(64)] * p1[v_oc_chunk, v_ic // T.int64(64), v_kh, v_kw, v_ic % T.int64(64), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(7), T.int64(14)):
                    for ax4_fused in T.vectorized(T.int64(8)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(2), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(512) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(112), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(512) // T.int64(256) * T.int64(56) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(16) // T.int64(2) * T.int64(7) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(112), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(256) // T.int64(64) * T.int64(28) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(2) * T.int64(14) + ax3)
                            v_ax4 = T.axis.spatial(T.int64(64), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(64) // T.int64(16) * T.int64(16) + oc_block_1 * T.int64(8) + ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[2, 1, 1, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 8, 1, 7])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[4, 2, 2, 7])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[4, 2, 2, 4])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[64, 2])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=8)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b68)
l85 = sch.fuse(l71, l72, l73, l74, l75, l76, l77, l78, l79, preserve_unit_iters=True)
sch.parallel(loop=l85)
l86 = sch.fuse(l84, preserve_unit_iters=True)
sch.vectorize(loop=l86)
l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b69)
l105 = sch.fuse(l87, preserve_unit_iters=True)
sch.parallel(loop=l105)
l106 = sch.fuse(l104, preserve_unit_iters=True)
sch.vectorize(loop=l106)
sch.annotate(block_or_loop=l105, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l105, ann_key="pragma_unroll_explicit", ann_val=1)
l107, l108, l109, l110, l111, l112, l113 = sch.get_loops(block=b70)
l114 = sch.fuse(l113, preserve_unit_iters=True)
sch.vectorize(loop=l114)
b115 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133 = sch.get_loops(block=b115)
b134 = sch.decompose_reduction(block=b115, loop=l118)
2024-04-30 06:42:05 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #40: GFLOPs: 54.7740. Time: 67597.5733 us. Best GFLOPs: 218.3403
2024-04-30 06:42:05 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #41: GFLOPs: 19.1561. Time: 193284.6727 us. Best GFLOPs: 218.3403
2024-04-30 06:42:05 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #42: GFLOPs: 1.6276. Time: 2274830.8953 us. Best GFLOPs: 218.3403
2024-04-30 06:42:05 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #43: GFLOPs: 16.3332. Time: 226691.3140 us. Best GFLOPs: 218.3403
2024-04-30 06:42:05 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #44: GFLOPs: 67.8127. Time: 54600.2163 us. Best GFLOPs: 218.3403
2024-04-30 06:42:05 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #45: GFLOPs: 16.9220. Time: 218803.3183 us. Best GFLOPs: 218.3403
2024-04-30 06:42:05 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #46: GFLOPs: 80.3873. Time: 46059.3427 us. Best GFLOPs: 218.3403
2024-04-30 06:42:05 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #47: GFLOPs: 150.1177. Time: 24664.5564 us. Best GFLOPs: 218.3403
2024-04-30 06:42:05 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #48: GFLOPs: 8.0685. Time: 458891.6763 us. Best GFLOPs: 218.3403
2024-04-30 06:42:05 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #49: GFLOPs: 47.3570. Time: 78184.6490 us. Best GFLOPs: 218.3403
2024-04-30 06:42:05 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #50: GFLOPs: 7.8296. Time: 472898.7043 us. Best GFLOPs: 218.3403
2024-04-30 06:42:05 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #51: GFLOPs: 3.5627. Time: 1039257.2433 us. Best GFLOPs: 218.3403
2024-04-30 06:42:05 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #52: GFLOPs: 96.4057. Time: 38406.2980 us. Best GFLOPs: 218.3403
2024-04-30 06:42:05 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #53: GFLOPs: 31.5575. Time: 117328.2063 us. Best GFLOPs: 218.3403
2024-04-30 06:42:05 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #54: GFLOPs: 31.8673. Time: 116187.8133 us. Best GFLOPs: 218.3403
2024-04-30 06:42:05 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #55: GFLOPs: 184.2842. Time: 20091.7242 us. Best GFLOPs: 218.3403
2024-04-30 06:42:05 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #56: GFLOPs: 14.3095. Time: 258750.1117 us. Best GFLOPs: 218.3403
2024-04-30 06:42:05 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #57: GFLOPs: 25.2343. Time: 146728.5963 us. Best GFLOPs: 218.3403
2024-04-30 06:42:05 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #58: GFLOPs: 17.9180. Time: 206641.2193 us. Best GFLOPs: 218.3403
2024-04-30 06:42:05 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #59: GFLOPs: 82.1755. Time: 45057.0687 us. Best GFLOPs: 218.3403
2024-04-30 06:42:05 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #60: GFLOPs: 64.3161. Time: 57568.5893 us. Best GFLOPs: 218.3403
2024-04-30 06:42:05 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #61: GFLOPs: 46.3057. Time: 79959.7160 us. Best GFLOPs: 218.3403
2024-04-30 06:42:05 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #62: GFLOPs: 75.6222. Time: 48961.6287 us. Best GFLOPs: 218.3403
2024-04-30 06:42:05 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #63: GFLOPs: 35.1646. Time: 105293.1733 us. Best GFLOPs: 218.3403
2024-04-30 06:42:05 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #64: GFLOPs: 605.0122. Time: 6119.8560 us. Best GFLOPs: 605.0122
2024-04-30 07:17:45 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-30 07:17:46 [INFO] [evolutionary_search.cc:715] Picked top 56 candidate(s) from database
2024-04-30 07:17:51 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x315e438)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x371f878)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3352b68)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x36bf9a8)]: 0 failure(s)
2024-04-30 07:17:51 [INFO] [evolutionary_search.cc:723] Sampled 456 candidate(s)
2024-04-30 07:18:05 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x315e438)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x371f878)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3352b68)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x36bf9a8)]: 0 failure(s)
2024-04-30 07:18:18 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x315e438)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x371f878)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3352b68)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x36bf9a8)]: 0 failure(s)
2024-04-30 07:18:36 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x315e438)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x371f878)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3352b68)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x36bf9a8)]: 0 failure(s)
2024-04-30 07:18:50 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x315e438)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x371f878)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3352b68)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x36bf9a8)]: 0 failure(s)
2024-04-30 07:18:59 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	1.0140  1.0140  1.0002  1.0002  0.9998  0.9998  0.9998  0.9998  0.9926  0.9673  0.9673  0.9673  0.9662  0.9610  0.9455  0.9451
[17 : 32]:	0.9451  0.9451  0.9379  0.9275  0.9246  0.9239  0.9239  0.9235  0.9235  0.9087  0.9053  0.8995  0.8992  0.8950  0.8926  0.8843
[33 : 48]:	0.8452  0.8449  0.8449  0.8406  0.8406  0.8406  0.8406  0.8406  0.8376  0.8343  0.8316  0.8293  0.8290  0.8245  0.8068  0.8064
[49 : 64]:	0.8064  0.8041  0.7975  0.7921  0.7921  0.7921  0.7921  0.7921  0.7909  0.7905  0.7833  0.7815  0.7779  0.7731  0.7631  0.7631
2024-04-30 07:18:59 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-30 07:18:59 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-30 07:20:41 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #65: GFLOPs: 616.4880. Time: 6005.9361 us. Best GFLOPs: 616.4880
2024-04-30 07:20:41 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #66: GFLOPs: 602.0782. Time: 6149.6786 us. Best GFLOPs: 616.4880
2024-04-30 07:20:41 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #67: GFLOPs: 612.8434. Time: 6041.6538 us. Best GFLOPs: 616.4880
2024-04-30 07:20:41 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #68: GFLOPs: 618.0371. Time: 5990.8823 us. Best GFLOPs: 618.0371
2024-04-30 07:20:41 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #69: GFLOPs: 618.3989. Time: 5987.3775 us. Best GFLOPs: 618.3989
2024-04-30 07:20:41 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #70: GFLOPs: 616.1836. Time: 6008.9026 us. Best GFLOPs: 618.3989
2024-04-30 07:20:41 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #71: GFLOPs: 617.2702. Time: 5998.3248 us. Best GFLOPs: 618.3989
2024-04-30 07:20:41 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #72: GFLOPs: 609.5584. Time: 6074.2132 us. Best GFLOPs: 618.3989
2024-04-30 07:20:41 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #73: GFLOPs: 617.2482. Time: 5998.5395 us. Best GFLOPs: 618.3989
2024-04-30 07:20:41 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #74: GFLOPs: 383.1637. Time: 9663.2006 us. Best GFLOPs: 618.3989
2024-04-30 07:20:41 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #75: GFLOPs: 386.1861. Time: 9587.5720 us. Best GFLOPs: 618.3989
2024-04-30 07:20:41 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #76: GFLOPs: 487.2347. Time: 7599.1863 us. Best GFLOPs: 618.3989
2024-04-30 07:20:41 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #77: GFLOPs: 469.0152. Time: 7894.3872 us. Best GFLOPs: 618.3989
2024-04-30 07:20:41 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #78: GFLOPs: 637.0026. Time: 5812.5155 us. Best GFLOPs: 637.0026
2024-04-30 07:20:41 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #79: GFLOPs: 578.4037. Time: 6401.3894 us. Best GFLOPs: 637.0026
2024-04-30 07:20:41 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #80: GFLOPs: 569.3892. Time: 6502.7356 us. Best GFLOPs: 637.0026
2024-04-30 07:20:41 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #81: GFLOPs: 581.6400. Time: 6365.7719 us. Best GFLOPs: 637.0026
2024-04-30 07:20:41 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #82: GFLOPs: 581.7969. Time: 6364.0550 us. Best GFLOPs: 637.0026
2024-04-30 07:20:41 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #83: GFLOPs: 564.1619. Time: 6562.9878 us. Best GFLOPs: 637.0026
2024-04-30 07:20:41 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #84: GFLOPs: 629.3811. Time: 5882.9021 us. Best GFLOPs: 637.0026
2024-04-30 07:20:41 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #85: GFLOPs: 608.1368. Time: 6088.4117 us. Best GFLOPs: 637.0026
2024-04-30 07:20:41 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #86: GFLOPs: 484.1230. Time: 7648.0301 us. Best GFLOPs: 637.0026
2024-04-30 07:20:41 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #87: GFLOPs: 557.1918. Time: 6645.0854 us. Best GFLOPs: 637.0026
2024-04-30 07:20:41 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #88: GFLOPs: 332.8426. Time: 11124.1380 us. Best GFLOPs: 637.0026
2024-04-30 07:20:41 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #89: GFLOPs: 487.1327. Time: 7600.7785 us. Best GFLOPs: 637.0026
2024-04-30 07:20:41 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #90: GFLOPs: 496.1655. Time: 7462.4033 us. Best GFLOPs: 637.0026
2024-04-30 07:20:41 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #91: GFLOPs: 433.6630. Time: 8537.9368 us. Best GFLOPs: 637.0026
2024-04-30 07:20:41 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #92: GFLOPs: 429.7363. Time: 8615.9523 us. Best GFLOPs: 637.0026
2024-04-30 07:20:41 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #93: GFLOPs: 391.2038. Time: 9464.5990 us. Best GFLOPs: 637.0026
2024-04-30 07:20:41 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #94: GFLOPs: 513.3776. Time: 7212.2104 us. Best GFLOPs: 637.0026
2024-04-30 07:20:41 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #95: GFLOPs: 403.8130. Time: 9169.0639 us. Best GFLOPs: 637.0026
2024-04-30 07:20:41 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #96: GFLOPs: 414.3643. Time: 8935.5845 us. Best GFLOPs: 637.0026
2024-04-30 07:20:41 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #97: GFLOPs: 429.3398. Time: 8623.9099 us. Best GFLOPs: 637.0026
2024-04-30 07:20:41 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #98: GFLOPs: 426.7621. Time: 8675.9983 us. Best GFLOPs: 637.0026
2024-04-30 07:20:41 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #99: GFLOPs: 438.2764. Time: 8448.0652 us. Best GFLOPs: 637.0026
2024-04-30 07:20:41 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #100: GFLOPs: 498.1768. Time: 7432.2756 us. Best GFLOPs: 637.0026
2024-04-30 07:20:41 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #101: GFLOPs: 494.3957. Time: 7489.1166 us. Best GFLOPs: 637.0026
2024-04-30 07:20:41 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #102: GFLOPs: 490.5168. Time: 7548.3398 us. Best GFLOPs: 637.0026
2024-04-30 07:20:41 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #103: GFLOPs: 174.5352. Time: 21213.9817 us. Best GFLOPs: 637.0026
2024-04-30 07:20:41 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #104: GFLOPs: 266.6148. Time: 13887.4025 us. Best GFLOPs: 637.0026
2024-04-30 07:20:41 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #105: GFLOPs: 437.7942. Time: 8457.3703 us. Best GFLOPs: 637.0026
2024-04-30 07:20:41 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #106: GFLOPs: 314.7095. Time: 11765.0944 us. Best GFLOPs: 637.0026
2024-04-30 07:20:41 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #107: GFLOPs: 503.9559. Time: 7347.0462 us. Best GFLOPs: 637.0026
2024-04-30 07:20:41 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #108: GFLOPs: 131.8223. Time: 28087.7096 us. Best GFLOPs: 637.0026
2024-04-30 07:20:41 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #109: GFLOPs: 205.6715. Time: 18002.4312 us. Best GFLOPs: 637.0026
2024-04-30 07:20:41 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #110: GFLOPs: 406.9193. Time: 9099.0709 us. Best GFLOPs: 637.0026
2024-04-30 07:20:41 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #111: GFLOPs: 101.2561. Time: 36566.5520 us. Best GFLOPs: 637.0026
2024-04-30 07:20:41 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #112: GFLOPs: 211.4845. Time: 17507.6092 us. Best GFLOPs: 637.0026
2024-04-30 07:20:41 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #113: GFLOPs: 101.2427. Time: 36571.3953 us. Best GFLOPs: 637.0026
2024-04-30 07:20:41 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #114: GFLOPs: 563.1236. Time: 6575.0886 us. Best GFLOPs: 637.0026
2024-04-30 07:20:41 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #115: GFLOPs: 602.7185. Time: 6143.1456 us. Best GFLOPs: 637.0026
2024-04-30 07:20:41 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #116: GFLOPs: 47.1314. Time: 78558.8313 us. Best GFLOPs: 637.0026
2024-04-30 07:20:41 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #117: GFLOPs: 37.6354. Time: 98380.5103 us. Best GFLOPs: 637.0026
2024-04-30 07:20:41 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #118: GFLOPs: 46.1308. Time: 80262.7440 us. Best GFLOPs: 637.0026
2024-04-30 07:20:41 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #119: GFLOPs: 13.1652. Time: 281240.3910 us. Best GFLOPs: 637.0026
2024-04-30 07:20:41 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #120: GFLOPs: 46.3090. Time: 79954.0220 us. Best GFLOPs: 637.0026
2024-04-30 07:20:41 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #121: GFLOPs: 108.6627. Time: 34074.1323 us. Best GFLOPs: 637.0026
2024-04-30 07:20:41 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #122: GFLOPs: 108.6889. Time: 34065.9353 us. Best GFLOPs: 637.0026
2024-04-30 07:20:41 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #123: GFLOPs: 130.2330. Time: 28430.4863 us. Best GFLOPs: 637.0026
2024-04-30 07:20:41 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #124: GFLOPs: 511.3648. Time: 7240.5994 us. Best GFLOPs: 637.0026
2024-04-30 07:20:41 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #125: GFLOPs: 515.2246. Time: 7186.3556 us. Best GFLOPs: 637.0026
2024-04-30 07:20:41 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #126: GFLOPs: 158.6557. Time: 23337.2514 us. Best GFLOPs: 637.0026
2024-04-30 07:20:41 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #127: GFLOPs: 14.6747. Time: 252311.5143 us. Best GFLOPs: 637.0026
2024-04-30 07:20:41 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #128: GFLOPs: 136.0522. Time: 27214.4530 us. Best GFLOPs: 637.0026
2024-04-30 07:46:52 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-30 07:46:53 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-30 07:46:58 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x315e438)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x371f878)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3352b68)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x36bf9a8)]: 0 failure(s)
2024-04-30 07:46:58 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-30 07:47:12 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x315e438)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x371f878)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3352b68)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x36bf9a8)]: 0 failure(s)
2024-04-30 07:47:26 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x315e438)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x371f878)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3352b68)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x36bf9a8)]: 0 failure(s)
2024-04-30 07:47:39 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x315e438)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x371f878)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3352b68)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x36bf9a8)]: 0 failure(s)
2024-04-30 07:47:53 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x315e438)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x371f878)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3352b68)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x36bf9a8)]: 0 failure(s)
2024-04-30 07:48:01 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9833  0.9833  0.9637  0.9621  0.9576  0.9576  0.9498  0.9430  0.9415  0.9394  0.9389  0.9365  0.9336  0.9336  0.9242  0.9211
[17 : 32]:	0.9211  0.9195  0.9144  0.9129  0.9110  0.9098  0.9098  0.8989  0.8976  0.8968  0.8967  0.8958  0.8935  0.8923  0.8834  0.8759
[33 : 48]:	0.8740  0.8734  0.8681  0.8666  0.8622  0.8613  0.8593  0.8593  0.8581  0.8579  0.8574  0.8574  0.8554  0.8530  0.8506  0.8491
[49 : 64]:	0.8491  0.8490  0.8452  0.8445  0.8426  0.8396  0.8390  0.8330  0.8329  0.8328  0.8318  0.8315  0.8286  0.8284  0.8230  0.8230
2024-04-30 07:48:01 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-30 07:48:01 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-30 07:49:54 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #129: GFLOPs: 632.0246. Time: 5858.2963 us. Best GFLOPs: 637.0026
2024-04-30 07:49:54 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #130: GFLOPs: 628.5092. Time: 5891.0630 us. Best GFLOPs: 637.0026
2024-04-30 07:49:54 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #131: GFLOPs: 630.9607. Time: 5868.1742 us. Best GFLOPs: 637.0026
2024-04-30 07:49:54 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #132: GFLOPs: 611.0994. Time: 6058.8959 us. Best GFLOPs: 637.0026
2024-04-30 07:49:54 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #133: GFLOPs: 627.8392. Time: 5897.3496 us. Best GFLOPs: 637.0026
2024-04-30 07:49:54 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #134: GFLOPs: 625.6376. Time: 5918.1024 us. Best GFLOPs: 637.0026
2024-04-30 07:49:54 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #135: GFLOPs: 613.5109. Time: 6035.0802 us. Best GFLOPs: 637.0026
2024-04-30 07:49:54 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #136: GFLOPs: 606.9345. Time: 6100.4726 us. Best GFLOPs: 637.0026
2024-04-30 07:49:54 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #137: GFLOPs: 612.3947. Time: 6046.0804 us. Best GFLOPs: 637.0026
2024-04-30 07:49:54 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #138: GFLOPs: 585.6005. Time: 6322.7188 us. Best GFLOPs: 637.0026
2024-04-30 07:49:54 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #139: GFLOPs: 566.1483. Time: 6539.9600 us. Best GFLOPs: 637.0026
2024-04-30 07:49:54 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #140: GFLOPs: 613.7569. Time: 6032.6608 us. Best GFLOPs: 637.0026
2024-04-30 07:49:54 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #141: GFLOPs: 565.0078. Time: 6553.1614 us. Best GFLOPs: 637.0026
2024-04-30 07:49:54 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #142: GFLOPs: 591.2184. Time: 6262.6395 us. Best GFLOPs: 637.0026
2024-04-30 07:49:54 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #143: GFLOPs: 650.1020. Time: 5695.3946 us. Best GFLOPs: 650.1020
2024-04-30 07:49:54 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #144: GFLOPs: 574.9886. Time: 6439.4101 us. Best GFLOPs: 650.1020
2024-04-30 07:49:54 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #145: GFLOPs: 563.8223. Time: 6566.9404 us. Best GFLOPs: 650.1020
2024-04-30 07:49:54 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #146: GFLOPs: 499.8698. Time: 7407.1038 us. Best GFLOPs: 650.1020
2024-04-30 07:49:54 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #147: GFLOPs: 624.8984. Time: 5925.1030 us. Best GFLOPs: 650.1020
2024-04-30 07:49:54 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #148: GFLOPs: 769.3524. Time: 4812.6027 us. Best GFLOPs: 769.3524
2024-04-30 07:49:54 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #149: GFLOPs: 648.3723. Time: 5710.5882 us. Best GFLOPs: 769.3524
2024-04-30 07:49:54 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #150: GFLOPs: 622.8976. Time: 5944.1345 us. Best GFLOPs: 769.3524
2024-04-30 07:49:54 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #151: GFLOPs: 629.8408. Time: 5878.6083 us. Best GFLOPs: 769.3524
2024-04-30 07:49:54 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #152: GFLOPs: 642.9463. Time: 5758.7813 us. Best GFLOPs: 769.3524
2024-04-30 07:49:54 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #153: GFLOPs: 645.6901. Time: 5734.3103 us. Best GFLOPs: 769.3524
2024-04-30 07:49:54 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #154: GFLOPs: 546.6587. Time: 6773.1250 us. Best GFLOPs: 769.3524
2024-04-30 07:49:54 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #155: GFLOPs: 479.1059. Time: 7728.1182 us. Best GFLOPs: 769.3524
2024-04-30 07:49:54 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #156: GFLOPs: 483.1522. Time: 7663.3975 us. Best GFLOPs: 769.3524
2024-04-30 07:49:54 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #157: GFLOPs: 632.5136. Time: 5853.7673 us. Best GFLOPs: 769.3524
2024-04-30 07:49:54 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #158: GFLOPs: 600.2121. Time: 6168.7985 us. Best GFLOPs: 769.3524
2024-04-30 07:49:54 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #159: GFLOPs: 831.0427. Time: 4455.3518 us. Best GFLOPs: 831.0427
2024-04-30 07:49:54 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #160: GFLOPs: 495.7572. Time: 7468.5506 us. Best GFLOPs: 831.0427
2024-04-30 07:49:54 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #161: GFLOPs: 596.0696. Time: 6211.6698 us. Best GFLOPs: 831.0427
2024-04-30 07:49:54 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #162: GFLOPs: 320.9512. Time: 11536.2928 us. Best GFLOPs: 831.0427
2024-04-30 07:49:54 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #163: GFLOPs: 489.4844. Time: 7564.2601 us. Best GFLOPs: 831.0427
2024-04-30 07:49:54 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #164: GFLOPs: 600.6182. Time: 6164.6272 us. Best GFLOPs: 831.0427
2024-04-30 07:49:54 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #165: GFLOPs: 717.2616. Time: 5162.1157 us. Best GFLOPs: 831.0427
2024-04-30 07:49:54 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #166: GFLOPs: 719.1209. Time: 5148.7690 us. Best GFLOPs: 831.0427
2024-04-30 07:49:54 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #167: GFLOPs: 610.5749. Time: 6064.1002 us. Best GFLOPs: 831.0427
2024-04-30 07:49:54 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #168: GFLOPs: 604.2883. Time: 6127.1865 us. Best GFLOPs: 831.0427
2024-04-30 07:49:54 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #169: GFLOPs: 640.9304. Time: 5776.8943 us. Best GFLOPs: 831.0427
2024-04-30 07:49:54 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #170: GFLOPs: 596.3113. Time: 6209.1521 us. Best GFLOPs: 831.0427
2024-04-30 07:49:54 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #171: GFLOPs: 600.5971. Time: 6164.8443 us. Best GFLOPs: 831.0427
2024-04-30 07:49:54 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #172: GFLOPs: 714.9526. Time: 5178.7875 us. Best GFLOPs: 831.0427
2024-04-30 07:49:54 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #173: GFLOPs: 605.4199. Time: 6115.7346 us. Best GFLOPs: 831.0427
2024-04-30 07:49:54 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #174: GFLOPs: 647.1813. Time: 5721.0973 us. Best GFLOPs: 831.0427
2024-04-30 07:49:54 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #175: GFLOPs: 551.9741. Time: 6707.9007 us. Best GFLOPs: 831.0427
2024-04-30 07:49:54 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #176: GFLOPs: 896.9113. Time: 4128.1534 us. Best GFLOPs: 896.9113
2024-04-30 07:49:54 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #177: GFLOPs: 895.9953. Time: 4132.3738 us. Best GFLOPs: 896.9113
2024-04-30 07:49:54 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #178: GFLOPs: 624.7991. Time: 5926.0448 us. Best GFLOPs: 896.9113
2024-04-30 07:49:54 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #179: GFLOPs: 904.0501. Time: 4095.5556 us. Best GFLOPs: 904.0501
2024-04-30 07:49:54 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #180: GFLOPs: 752.7138. Time: 4918.9841 us. Best GFLOPs: 904.0501
2024-04-30 07:49:54 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #181: GFLOPs: 420.7035. Time: 8800.9430 us. Best GFLOPs: 904.0501
2024-04-30 07:49:54 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #182: GFLOPs: 871.5220. Time: 4248.4151 us. Best GFLOPs: 904.0501
2024-04-30 07:49:54 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #183: GFLOPs: 753.8521. Time: 4911.5565 us. Best GFLOPs: 904.0501
2024-04-30 07:49:54 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #184: GFLOPs: 741.9221. Time: 4990.5339 us. Best GFLOPs: 904.0501
2024-04-30 07:49:54 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #185: GFLOPs: 421.8335. Time: 8777.3659 us. Best GFLOPs: 904.0501
2024-04-30 07:49:54 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #186: GFLOPs: 511.7879. Time: 7234.6136 us. Best GFLOPs: 904.0501
2024-04-30 07:49:54 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #187: GFLOPs: 516.8364. Time: 7163.9446 us. Best GFLOPs: 904.0501
2024-04-30 07:49:54 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #188: GFLOPs: 513.1126. Time: 7215.9348 us. Best GFLOPs: 904.0501
2024-04-30 07:49:54 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #189: GFLOPs: 600.5072. Time: 6165.7666 us. Best GFLOPs: 904.0501
2024-04-30 07:49:54 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #190: GFLOPs: 60.8397. Time: 60858.0757 us. Best GFLOPs: 904.0501
2024-04-30 07:49:54 [INFO] [task_scheduler.cc:121] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #191: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(112), T.int64(112), T.int64(64)), "float32"), p1: T.Buffer((T.int64(2), T.int64(2), T.int64(3), T.int64(3), T.int64(64), T.int64(64)), "float32"), p2: T.Buffer((T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(64)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(2), T.int64(112), T.int64(112), T.int64(64)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(114), T.int64(114), T.int64(64)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(112), T.int64(112), T.int64(64)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused in T.parallel(T.int64(28), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1 in T.grid(T.int64(1), T.int64(2)):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(2), T.int64(58), T.int64(10)):
                    for ax4_fused in T.vectorized(T.int64(64)):
                        with T.block("data_pad"):
                            v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                            v_i2 = T.axis.spatial(T.int64(114), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(14) * T.int64(56) + ax2)
                            v_i3 = T.axis.spatial(T.int64(114), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(14) * T.int64(8) + ax3)
                            v_i4 = T.axis.spatial(T.int64(64), ax4_fused)
                            T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                            T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                            data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(113) and T.int64(1) <= v_i3 and v_i3 < T.int64(113), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                for oh_1, ow_1, oc_block_1 in T.grid(T.int64(7), T.int64(1), T.int64(1)):
                    for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(8)):
                        for oc_block_3_fused_init in T.vectorized(T.int64(64)):
                            with T.block("conv2d_NCHWc_init"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                                v_oc_chunk = T.axis.spatial(T.int64(2), oc_chunk_1 + oc_chunk_2_init + oc_chunk_3_init)
                                v_oh = T.axis.spatial(T.int64(112), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(14) * T.int64(56) + oh_1 * T.int64(8) + oh_2_init + oh_3_init)
                                v_ow = T.axis.spatial(T.int64(112), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(14) * T.int64(8) + ow_1 * T.int64(8) + ow_2_init * T.int64(8) + ow_3_init)
                                v_oc_block = T.axis.spatial(T.int64(64), oc_block_1 * T.int64(64) + oc_block_2_init * T.int64(64) + oc_block_3_fused_init)
                                T.reads()
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                    for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(4), T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(8)):
                        for oc_block_3_fused in T.vectorized(T.int64(64)):
                            with T.block("conv2d_NCHWc_update"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                                v_oc_chunk = T.axis.spatial(T.int64(2), oc_chunk_1 + oc_chunk_2 + oc_chunk_3)
                                v_oh = T.axis.spatial(T.int64(112), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(14) * T.int64(56) + oh_1 * T.int64(8) + oh_2 + oh_3)
                                v_ow = T.axis.spatial(T.int64(112), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(14) * T.int64(8) + ow_1 * T.int64(8) + ow_2 * T.int64(8) + ow_3)
                                v_oc_block = T.axis.spatial(T.int64(64), oc_block_1 * T.int64(64) + oc_block_2 * T.int64(64) + oc_block_3_fused)
                                v_ic = T.axis.reduce(T.int64(128), ic_0 * T.int64(32) + ic_1)
                                v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                                v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                                T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(64), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(64)], p1[v_oc_chunk, v_ic // T.int64(64), v_kh, v_kw, v_ic % T.int64(64), v_oc_block])
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(64), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(64)] * p1[v_oc_chunk, v_ic // T.int64(64), v_kh, v_kw, v_ic % T.int64(64), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(2), T.int64(56), T.int64(8)):
                for ax4_fused in T.vectorized(T.int64(64)):
                    with T.block("T_relu"):
                        v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                        v_ax2 = T.axis.spatial(T.int64(112), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(14) * T.int64(56) + ax2)
                        v_ax3 = T.axis.spatial(T.int64(112), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(14) * T.int64(8) + ax3)
                        v_ax4 = T.axis.spatial(T.int64(64), ax4_fused)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 2, 1, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 7, 8, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[14, 1, 1, 8])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 1, 64])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[4, 32])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=6)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82 = sch.get_loops(block=b68)
l83 = sch.fuse(l71, l72, l73, l74, l75, preserve_unit_iters=True)
sch.parallel(loop=l83)
l84 = sch.fuse(l82, preserve_unit_iters=True)
sch.vectorize(loop=l84)
l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106 = sch.get_loops(block=b69)
l107 = sch.fuse(l85, preserve_unit_iters=True)
sch.parallel(loop=l107)
l108 = sch.fuse(l106, preserve_unit_iters=True)
sch.vectorize(loop=l108)
sch.annotate(block_or_loop=l107, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l107, ann_key="pragma_unroll_explicit", ann_val=1)
l109, l110, l111, l112, l113, l114 = sch.get_loops(block=b70)
l115 = sch.fuse(l114, preserve_unit_iters=True)
sch.vectorize(loop=l115)
b116 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138 = sch.get_loops(block=b116)
b139 = sch.decompose_reduction(block=b116, loop=l123)
2024-04-30 07:49:54 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #192: GFLOPs: 128.1324. Time: 28896.5795 us. Best GFLOPs: 904.0501
2024-04-30 08:30:42 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-30 08:30:43 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-30 08:30:48 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x315e438)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x371f878)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3352b68)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x36bf9a8)]: 0 failure(s)
2024-04-30 08:30:48 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-30 08:31:01 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x315e438)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x371f878)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3352b68)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x36bf9a8)]: 0 failure(s)
2024-04-30 08:31:16 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x315e438)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x371f878)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3352b68)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x36bf9a8)]: 0 failure(s)
2024-04-30 08:31:29 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x315e438)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x371f878)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3352b68)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x36bf9a8)]: 0 failure(s)
2024-04-30 08:31:44 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x315e438)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x371f878)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3352b68)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x36bf9a8)]: 0 failure(s)
2024-04-30 08:31:51 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9932  0.9837  0.9769  0.9452  0.9319  0.9233  0.9111  0.9111  0.9111  0.9111  0.9017  0.8979  0.8976  0.8976  0.8957  0.8957
[17 : 32]:	0.8955  0.8853  0.8725  0.8634  0.8608  0.8602  0.8529  0.8474  0.8474  0.8458  0.8454  0.8376  0.8368  0.8368  0.8285  0.8268
[33 : 48]:	0.8239  0.8194  0.8187  0.8147  0.8113  0.8101  0.8075  0.8021  0.8002  0.7997  0.7989  0.7989  0.7989  0.7982  0.7930  0.7909
[49 : 64]:	0.7904  0.7891  0.7891  0.7891  0.7891  0.7891  0.7885  0.7818  0.7789  0.7786  0.7785  0.7782  0.7781  0.7777  0.7757  0.7743
2024-04-30 08:31:51 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-30 08:31:52 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-30 08:33:57 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #193: GFLOPs: 899.3402. Time: 4117.0041 us. Best GFLOPs: 904.0501
2024-04-30 08:33:57 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #194: GFLOPs: 892.0319. Time: 4150.7343 us. Best GFLOPs: 904.0501
2024-04-30 08:33:57 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #195: GFLOPs: 891.3268. Time: 4154.0180 us. Best GFLOPs: 904.0501
2024-04-30 08:33:57 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #196: GFLOPs: 866.1456. Time: 4274.7861 us. Best GFLOPs: 904.0501
2024-04-30 08:33:57 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #197: GFLOPs: 576.4012. Time: 6423.6288 us. Best GFLOPs: 904.0501
2024-04-30 08:33:57 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #198: GFLOPs: 967.0714. Time: 3828.6596 us. Best GFLOPs: 967.0714
2024-04-30 08:33:57 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #199: GFLOPs: 408.2982. Time: 9068.3412 us. Best GFLOPs: 967.0714
2024-04-30 08:33:57 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #200: GFLOPs: 457.9183. Time: 8085.6938 us. Best GFLOPs: 967.0714
2024-04-30 08:33:57 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #201: GFLOPs: 11.4095. Time: 324517.8360 us. Best GFLOPs: 967.0714
2024-04-30 08:33:57 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #202: GFLOPs: 455.7568. Time: 8124.0422 us. Best GFLOPs: 967.0714
2024-04-30 08:33:57 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #203: GFLOPs: 459.3332. Time: 8060.7873 us. Best GFLOPs: 967.0714
2024-04-30 08:33:57 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #204: GFLOPs: 583.3888. Time: 6346.6893 us. Best GFLOPs: 967.0714
2024-04-30 08:33:57 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #205: GFLOPs: 10.7897. Time: 343158.4603 us. Best GFLOPs: 967.0714
2024-04-30 08:33:57 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #206: GFLOPs: 10.0825. Time: 367228.3513 us. Best GFLOPs: 967.0714
2024-04-30 08:33:57 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #207: GFLOPs: 1094.4791. Time: 3382.9676 us. Best GFLOPs: 1094.4791
2024-04-30 08:33:57 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #208: GFLOPs: 1089.2535. Time: 3399.1972 us. Best GFLOPs: 1094.4791
2024-04-30 08:33:57 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #209: GFLOPs: 553.1487. Time: 6693.6559 us. Best GFLOPs: 1094.4791
2024-04-30 08:33:57 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #210: GFLOPs: 990.8676. Time: 3736.7125 us. Best GFLOPs: 1094.4791
2024-04-30 08:33:57 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #211: GFLOPs: 870.9141. Time: 4251.3807 us. Best GFLOPs: 1094.4791
2024-04-30 08:33:57 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #212: GFLOPs: 843.4112. Time: 4390.0143 us. Best GFLOPs: 1094.4791
2024-04-30 08:33:57 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #213: GFLOPs: 657.4627. Time: 5631.6314 us. Best GFLOPs: 1094.4791
2024-04-30 08:33:57 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #214: GFLOPs: 873.7610. Time: 4237.5288 us. Best GFLOPs: 1094.4791
2024-04-30 08:33:57 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #215: GFLOPs: 895.7258. Time: 4133.6172 us. Best GFLOPs: 1094.4791
2024-04-30 08:33:57 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #216: GFLOPs: 824.9556. Time: 4488.2260 us. Best GFLOPs: 1094.4791
2024-04-30 08:33:57 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #217: GFLOPs: 748.9865. Time: 4943.4637 us. Best GFLOPs: 1094.4791
2024-04-30 08:33:57 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #218: GFLOPs: 626.2290. Time: 5912.5136 us. Best GFLOPs: 1094.4791
2024-04-30 08:33:57 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #219: GFLOPs: 585.3976. Time: 6324.9102 us. Best GFLOPs: 1094.4791
2024-04-30 08:33:57 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #220: GFLOPs: 816.3633. Time: 4535.4655 us. Best GFLOPs: 1094.4791
2024-04-30 08:33:57 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #221: GFLOPs: 834.4149. Time: 4437.3456 us. Best GFLOPs: 1094.4791
2024-04-30 08:33:57 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #222: GFLOPs: 829.6056. Time: 4463.0695 us. Best GFLOPs: 1094.4791
2024-04-30 08:33:57 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #223: GFLOPs: 761.9899. Time: 4859.1032 us. Best GFLOPs: 1094.4791
2024-04-30 08:33:57 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #224: GFLOPs: 861.3663. Time: 4298.5049 us. Best GFLOPs: 1094.4791
2024-04-30 08:33:57 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #225: GFLOPs: 509.3995. Time: 7268.5331 us. Best GFLOPs: 1094.4791
2024-04-30 08:33:57 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #226: GFLOPs: 809.1540. Time: 4575.8747 us. Best GFLOPs: 1094.4791
2024-04-30 08:33:57 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #227: GFLOPs: 803.9889. Time: 4605.2716 us. Best GFLOPs: 1094.4791
2024-04-30 08:33:57 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #228: GFLOPs: 463.4066. Time: 7989.9322 us. Best GFLOPs: 1094.4791
2024-04-30 08:33:57 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #229: GFLOPs: 931.4926. Time: 3974.8973 us. Best GFLOPs: 1094.4791
2024-04-30 08:33:57 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #230: GFLOPs: 790.3114. Time: 4684.9730 us. Best GFLOPs: 1094.4791
2024-04-30 08:33:57 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #231: GFLOPs: 766.2913. Time: 4831.8275 us. Best GFLOPs: 1094.4791
2024-04-30 08:33:57 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #232: GFLOPs: 745.5819. Time: 4966.0374 us. Best GFLOPs: 1094.4791
2024-04-30 08:33:57 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #233: GFLOPs: 927.5589. Time: 3991.7545 us. Best GFLOPs: 1094.4791
2024-04-30 08:33:57 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #234: GFLOPs: 467.5473. Time: 7919.1710 us. Best GFLOPs: 1094.4791
2024-04-30 08:33:57 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #235: GFLOPs: 816.9620. Time: 4532.1415 us. Best GFLOPs: 1094.4791
2024-04-30 08:33:57 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #236: GFLOPs: 822.3767. Time: 4502.3010 us. Best GFLOPs: 1094.4791
2024-04-30 08:33:57 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #237: GFLOPs: 819.3909. Time: 4518.7070 us. Best GFLOPs: 1094.4791
2024-04-30 08:33:57 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #238: GFLOPs: 637.9408. Time: 5803.9667 us. Best GFLOPs: 1094.4791
2024-04-30 08:33:57 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #239: GFLOPs: 773.3849. Time: 4787.5091 us. Best GFLOPs: 1094.4791
2024-04-30 08:33:57 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #240: GFLOPs: 668.7467. Time: 5536.6069 us. Best GFLOPs: 1094.4791
2024-04-30 08:33:57 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #241: GFLOPs: 402.3907. Time: 9201.4730 us. Best GFLOPs: 1094.4791
2024-04-30 08:33:57 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #242: GFLOPs: 397.1301. Time: 9323.3605 us. Best GFLOPs: 1094.4791
2024-04-30 08:33:57 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #243: GFLOPs: 37.1950. Time: 99545.1913 us. Best GFLOPs: 1094.4791
2024-04-30 08:33:57 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #244: GFLOPs: 10.0667. Time: 367803.6980 us. Best GFLOPs: 1094.4791
2024-04-30 08:33:57 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #245: GFLOPs: 326.7937. Time: 11330.0459 us. Best GFLOPs: 1094.4791
2024-04-30 08:33:57 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #246: GFLOPs: 9.8946. Time: 374204.5920 us. Best GFLOPs: 1094.4791
2024-04-30 08:33:57 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #247: GFLOPs: 751.5958. Time: 4926.3011 us. Best GFLOPs: 1094.4791
2024-04-30 08:33:57 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #248: GFLOPs: 918.5190. Time: 4031.0406 us. Best GFLOPs: 1094.4791
2024-04-30 08:33:57 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #249: GFLOPs: 774.3334. Time: 4781.6447 us. Best GFLOPs: 1094.4791
2024-04-30 08:33:57 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #250: GFLOPs: 622.5713. Time: 5947.2506 us. Best GFLOPs: 1094.4791
2024-04-30 08:33:57 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #251: GFLOPs: 633.5382. Time: 5844.3001 us. Best GFLOPs: 1094.4791
2024-04-30 08:33:57 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #252: GFLOPs: 933.6408. Time: 3965.7513 us. Best GFLOPs: 1094.4791
2024-04-30 08:33:57 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #253: GFLOPs: 449.4313. Time: 8238.3834 us. Best GFLOPs: 1094.4791
2024-04-30 08:33:57 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #254: GFLOPs: 99.5175. Time: 37205.3840 us. Best GFLOPs: 1094.4791
2024-04-30 08:33:57 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #255: GFLOPs: 157.8125. Time: 23461.9402 us. Best GFLOPs: 1094.4791
2024-04-30 08:33:57 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #256: GFLOPs: 18.4594. Time: 200579.6380 us. Best GFLOPs: 1094.4791
2024-04-30 09:09:55 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-30 09:09:56 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-30 09:10:01 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x315e438)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x371f878)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3352b68)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x36bf9a8)]: 0 failure(s)
2024-04-30 09:10:01 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-30 09:10:15 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x315e438)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x371f878)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3352b68)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x36bf9a8)]: 0 failure(s)
2024-04-30 09:10:29 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x315e438)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x371f878)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3352b68)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x36bf9a8)]: 0 failure(s)
2024-04-30 09:10:43 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x315e438)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x371f878)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3352b68)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x36bf9a8)]: 0 failure(s)
2024-04-30 09:10:57 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x315e438)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x371f878)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3352b68)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x36bf9a8)]: 0 failure(s)
2024-04-30 09:11:05 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.8913  0.8608  0.8492  0.8374  0.8359  0.8331  0.8230  0.8215  0.8163  0.8163  0.8151  0.8137  0.8112  0.8107  0.8043  0.8035
[17 : 32]:	0.7993  0.7967  0.7959  0.7959  0.7946  0.7912  0.7903  0.7901  0.7888  0.7859  0.7822  0.7813  0.7797  0.7768  0.7747  0.7741
[33 : 48]:	0.7729  0.7716  0.7624  0.7624  0.7613  0.7605  0.7561  0.7551  0.7541  0.7541  0.7529  0.7525  0.7520  0.7520  0.7469  0.7467
[49 : 64]:	0.7460  0.7432  0.7410  0.7397  0.7397  0.7397  0.7378  0.7366  0.7360  0.7337  0.7332  0.7307  0.7289  0.7289  0.7288  0.7284
2024-04-30 09:11:05 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-30 09:11:06 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-30 09:13:16 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #257: GFLOPs: 1088.3084. Time: 3402.1491 us. Best GFLOPs: 1094.4791
2024-04-30 09:13:16 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #258: GFLOPs: 1004.3779. Time: 3686.4486 us. Best GFLOPs: 1094.4791
2024-04-30 09:13:16 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #259: GFLOPs: 696.4767. Time: 5316.1682 us. Best GFLOPs: 1094.4791
2024-04-30 09:13:16 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #260: GFLOPs: 982.1494. Time: 3769.8821 us. Best GFLOPs: 1094.4791
2024-04-30 09:13:16 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #261: GFLOPs: 957.1943. Time: 3868.1672 us. Best GFLOPs: 1094.4791
2024-04-30 09:13:16 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #262: GFLOPs: 82.4722. Time: 44894.9787 us. Best GFLOPs: 1094.4791
2024-04-30 09:13:16 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #263: GFLOPs: 1070.7614. Time: 3457.9014 us. Best GFLOPs: 1094.4791
2024-04-30 09:13:16 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #264: GFLOPs: 943.3577. Time: 3924.9028 us. Best GFLOPs: 1094.4791
2024-04-30 09:13:16 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #265: GFLOPs: 934.4574. Time: 3962.2861 us. Best GFLOPs: 1094.4791
2024-04-30 09:13:16 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #266: GFLOPs: 911.1951. Time: 4063.4410 us. Best GFLOPs: 1094.4791
2024-04-30 09:13:16 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #267: GFLOPs: 205.2174. Time: 18042.2717 us. Best GFLOPs: 1094.4791
2024-04-30 09:13:16 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #268: GFLOPs: 941.2367. Time: 3933.7472 us. Best GFLOPs: 1094.4791
2024-04-30 09:13:16 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #269: GFLOPs: 198.6224. Time: 18641.3368 us. Best GFLOPs: 1094.4791
2024-04-30 09:13:16 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #270: GFLOPs: 890.4704. Time: 4158.0130 us. Best GFLOPs: 1094.4791
2024-04-30 09:13:16 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #271: GFLOPs: 803.6084. Time: 4607.4523 us. Best GFLOPs: 1094.4791
2024-04-30 09:13:16 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #272: GFLOPs: 903.6538. Time: 4097.3516 us. Best GFLOPs: 1094.4791
2024-04-30 09:13:16 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #273: GFLOPs: 922.6073. Time: 4013.1781 us. Best GFLOPs: 1094.4791
2024-04-30 09:13:16 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #274: GFLOPs: 870.3307. Time: 4254.2305 us. Best GFLOPs: 1094.4791
2024-04-30 09:13:16 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #275: GFLOPs: 885.3991. Time: 4181.8285 us. Best GFLOPs: 1094.4791
2024-04-30 09:13:16 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #276: GFLOPs: 998.4338. Time: 3708.3955 us. Best GFLOPs: 1094.4791
2024-04-30 09:13:16 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #277: GFLOPs: 887.8352. Time: 4170.3545 us. Best GFLOPs: 1094.4791
2024-04-30 09:13:16 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #278: GFLOPs: 814.0140. Time: 4548.5550 us. Best GFLOPs: 1094.4791
2024-04-30 09:13:16 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #279: GFLOPs: 794.0053. Time: 4663.1773 us. Best GFLOPs: 1094.4791
2024-04-30 09:13:16 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #280: GFLOPs: 975.7511. Time: 3794.6022 us. Best GFLOPs: 1094.4791
2024-04-30 09:13:16 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #281: GFLOPs: 496.5190. Time: 7457.0909 us. Best GFLOPs: 1094.4791
2024-04-30 09:13:16 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #282: GFLOPs: 952.4952. Time: 3887.2506 us. Best GFLOPs: 1094.4791
2024-04-30 09:13:16 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #283: GFLOPs: 777.1909. Time: 4764.0642 us. Best GFLOPs: 1094.4791
2024-04-30 09:13:16 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #284: GFLOPs: 1118.3659. Time: 3310.7120 us. Best GFLOPs: 1118.3659
2024-04-30 09:13:16 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #285: GFLOPs: 1055.1714. Time: 3508.9913 us. Best GFLOPs: 1118.3659
2024-04-30 09:13:16 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #286: GFLOPs: 718.9310. Time: 5150.1290 us. Best GFLOPs: 1118.3659
2024-04-30 09:13:16 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #287: GFLOPs: 689.1779. Time: 5372.4696 us. Best GFLOPs: 1118.3659
2024-04-30 09:13:16 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #288: GFLOPs: 392.2567. Time: 9439.1957 us. Best GFLOPs: 1118.3659
2024-04-30 09:13:16 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #289: GFLOPs: 702.8659. Time: 5267.8436 us. Best GFLOPs: 1118.3659
2024-04-30 09:13:16 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #290: GFLOPs: 861.6958. Time: 4296.8613 us. Best GFLOPs: 1118.3659
2024-04-30 09:13:16 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #291: GFLOPs: 1041.8349. Time: 3553.9100 us. Best GFLOPs: 1118.3659
2024-04-30 09:13:16 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #292: GFLOPs: 808.5025. Time: 4579.5618 us. Best GFLOPs: 1118.3659
2024-04-30 09:13:16 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #293: GFLOPs: 675.7049. Time: 5479.5920 us. Best GFLOPs: 1118.3659
2024-04-30 09:13:16 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #294: GFLOPs: 831.0831. Time: 4455.1348 us. Best GFLOPs: 1118.3659
2024-04-30 09:13:16 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #295: GFLOPs: 828.7199. Time: 4467.8396 us. Best GFLOPs: 1118.3659
2024-04-30 09:13:16 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #296: GFLOPs: 820.8089. Time: 4510.9005 us. Best GFLOPs: 1118.3659
2024-04-30 09:13:16 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #297: GFLOPs: 918.3101. Time: 4031.9576 us. Best GFLOPs: 1118.3659
2024-04-30 09:13:16 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #298: GFLOPs: 914.1394. Time: 4050.3532 us. Best GFLOPs: 1118.3659
2024-04-30 09:13:16 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #299: GFLOPs: 869.8991. Time: 4256.3410 us. Best GFLOPs: 1118.3659
2024-04-30 09:13:16 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #300: GFLOPs: 812.9270. Time: 4554.6368 us. Best GFLOPs: 1118.3659
2024-04-30 09:13:16 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #301: GFLOPs: 1077.8866. Time: 3435.0436 us. Best GFLOPs: 1118.3659
2024-04-30 09:13:16 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #302: GFLOPs: 1070.2207. Time: 3459.6484 us. Best GFLOPs: 1118.3659
2024-04-30 09:13:16 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #303: GFLOPs: 568.9923. Time: 6507.2711 us. Best GFLOPs: 1118.3659
2024-04-30 09:13:16 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #304: GFLOPs: 912.0750. Time: 4059.5209 us. Best GFLOPs: 1118.3659
2024-04-30 09:13:16 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #305: GFLOPs: 834.9350. Time: 4434.5814 us. Best GFLOPs: 1118.3659
2024-04-30 09:13:16 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #306: GFLOPs: 906.0652. Time: 4086.4470 us. Best GFLOPs: 1118.3659
2024-04-30 09:13:16 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #307: GFLOPs: 640.2092. Time: 5783.4027 us. Best GFLOPs: 1118.3659
2024-04-30 09:13:16 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #308: GFLOPs: 920.3552. Time: 4022.9983 us. Best GFLOPs: 1118.3659
2024-04-30 09:13:16 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #309: GFLOPs: 909.1978. Time: 4072.3675 us. Best GFLOPs: 1118.3659
2024-04-30 09:13:16 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #310: GFLOPs: 923.6228. Time: 4008.7658 us. Best GFLOPs: 1118.3659
2024-04-30 09:13:16 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #311: GFLOPs: 839.5246. Time: 4410.3379 us. Best GFLOPs: 1118.3659
2024-04-30 09:13:16 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #312: GFLOPs: 1355.3370. Time: 2731.8575 us. Best GFLOPs: 1355.3370
2024-04-30 09:13:16 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #313: GFLOPs: 818.0628. Time: 4526.0430 us. Best GFLOPs: 1355.3370
2024-04-30 09:13:16 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #314: GFLOPs: 863.8918. Time: 4285.9390 us. Best GFLOPs: 1355.3370
2024-04-30 09:13:16 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #315: GFLOPs: 868.3550. Time: 4263.9099 us. Best GFLOPs: 1355.3370
2024-04-30 09:13:16 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #316: GFLOPs: 1158.7714. Time: 3195.2699 us. Best GFLOPs: 1355.3370
2024-04-30 09:13:16 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #317: GFLOPs: 872.0533. Time: 4245.8271 us. Best GFLOPs: 1355.3370
2024-04-30 09:13:16 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #318: GFLOPs: 9.2459. Time: 400456.9927 us. Best GFLOPs: 1355.3370
2024-04-30 09:13:16 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #319: GFLOPs: 1.6495. Time: 2244621.4343 us. Best GFLOPs: 1355.3370
2024-04-30 09:13:16 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #320: GFLOPs: 73.2786. Time: 50527.5693 us. Best GFLOPs: 1355.3370
2024-04-30 09:36:42 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-30 09:36:44 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-30 09:36:48 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x315e438)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x371f878)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3352b68)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x36bf9a8)]: 0 failure(s)
2024-04-30 09:36:48 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-30 09:37:02 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x315e438)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x371f878)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3352b68)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x36bf9a8)]: 0 failure(s)
2024-04-30 09:37:16 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x315e438)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x371f878)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3352b68)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x36bf9a8)]: 0 failure(s)
2024-04-30 09:37:31 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x315e438)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x371f878)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3352b68)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x36bf9a8)]: 0 failure(s)
2024-04-30 09:37:45 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x315e438)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x371f878)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3352b68)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x36bf9a8)]: 0 failure(s)
2024-04-30 09:37:53 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9932  0.9932  0.9627  0.8930  0.8710  0.8085  0.8085  0.7958  0.7949  0.7863  0.7804  0.7771  0.7770  0.7720  0.7720  0.7658
[17 : 32]:	0.7590  0.7551  0.7467  0.7467  0.7314  0.7285  0.7216  0.7208  0.7200  0.7177  0.7175  0.7169  0.7148  0.7100  0.7098  0.7073
[33 : 48]:	0.7062  0.7055  0.7028  0.7024  0.7018  0.7018  0.6958  0.6935  0.6932  0.6915  0.6902  0.6899  0.6898  0.6898  0.6885  0.6869
[49 : 64]:	0.6854  0.6850  0.6831  0.6830  0.6813  0.6813  0.6784  0.6779  0.6770  0.6765  0.6763  0.6750  0.6739  0.6732  0.6726  0.6723
2024-04-30 09:37:53 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-30 09:37:53 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-30 09:39:55 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #321: GFLOPs: 726.8783. Time: 5093.8200 us. Best GFLOPs: 1355.3370
2024-04-30 09:39:55 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #322: GFLOPs: 1395.6443. Time: 2652.9593 us. Best GFLOPs: 1395.6443
2024-04-30 09:39:55 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #323: GFLOPs: 1376.3084. Time: 2690.2309 us. Best GFLOPs: 1395.6443
2024-04-30 09:39:55 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #324: GFLOPs: 1290.8179. Time: 2868.4041 us. Best GFLOPs: 1395.6443
2024-04-30 09:39:55 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #325: GFLOPs: 1376.6640. Time: 2689.5359 us. Best GFLOPs: 1395.6443
2024-04-30 09:39:55 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #326: GFLOPs: 1095.8978. Time: 3378.5884 us. Best GFLOPs: 1395.6443
2024-04-30 09:39:55 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #327: GFLOPs: 1097.2312. Time: 3374.4823 us. Best GFLOPs: 1395.6443
2024-04-30 09:39:55 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #328: GFLOPs: 1285.1389. Time: 2881.0795 us. Best GFLOPs: 1395.6443
2024-04-30 09:39:55 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #329: GFLOPs: 1120.0021. Time: 3305.8755 us. Best GFLOPs: 1395.6443
2024-04-30 09:39:55 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #330: GFLOPs: 943.6020. Time: 3923.8866 us. Best GFLOPs: 1395.6443
2024-04-30 09:39:55 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #331: GFLOPs: 1163.6825. Time: 3181.7849 us. Best GFLOPs: 1395.6443
2024-04-30 09:39:55 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #332: GFLOPs: 1139.0315. Time: 3250.6452 us. Best GFLOPs: 1395.6443
2024-04-30 09:39:55 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #333: GFLOPs: 1100.5504. Time: 3364.3051 us. Best GFLOPs: 1395.6443
2024-04-30 09:39:55 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #334: GFLOPs: 1071.5353. Time: 3455.4042 us. Best GFLOPs: 1395.6443
2024-04-30 09:39:55 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #335: GFLOPs: 858.9823. Time: 4310.4351 us. Best GFLOPs: 1395.6443
2024-04-30 09:39:55 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #336: GFLOPs: 1071.1628. Time: 3456.6056 us. Best GFLOPs: 1395.6443
2024-04-30 09:39:55 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #337: GFLOPs: 933.4512. Time: 3966.5570 us. Best GFLOPs: 1395.6443
2024-04-30 09:39:55 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #338: GFLOPs: 956.1026. Time: 3872.5838 us. Best GFLOPs: 1395.6443
2024-04-30 09:39:55 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #339: GFLOPs: 1020.6474. Time: 3627.6851 us. Best GFLOPs: 1395.6443
2024-04-30 09:39:55 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #340: GFLOPs: 996.0428. Time: 3717.2976 us. Best GFLOPs: 1395.6443
2024-04-30 09:39:55 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #341: GFLOPs: 825.6620. Time: 4484.3862 us. Best GFLOPs: 1395.6443
2024-04-30 09:39:55 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #342: GFLOPs: 1062.6335. Time: 3484.3502 us. Best GFLOPs: 1395.6443
2024-04-30 09:39:55 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #343: GFLOPs: 1209.6466. Time: 3060.8836 us. Best GFLOPs: 1395.6443
2024-04-30 09:39:55 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #344: GFLOPs: 879.0817. Time: 4211.8807 us. Best GFLOPs: 1395.6443
2024-04-30 09:39:55 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #345: GFLOPs: 1042.6982. Time: 3550.9676 us. Best GFLOPs: 1395.6443
2024-04-30 09:39:55 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #346: GFLOPs: 1325.6421. Time: 2793.0521 us. Best GFLOPs: 1395.6443
2024-04-30 09:39:55 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #347: GFLOPs: 996.9448. Time: 3713.9344 us. Best GFLOPs: 1395.6443
2024-04-30 09:39:55 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #348: GFLOPs: 964.9796. Time: 3836.9593 us. Best GFLOPs: 1395.6443
2024-04-30 09:39:55 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #349: GFLOPs: 1035.4912. Time: 3575.6821 us. Best GFLOPs: 1395.6443
2024-04-30 09:39:55 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #350: GFLOPs: 1009.1243. Time: 3669.1094 us. Best GFLOPs: 1395.6443
2024-04-30 09:39:55 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #351: GFLOPs: 942.4383. Time: 3928.7317 us. Best GFLOPs: 1395.6443
2024-04-30 09:39:55 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #352: GFLOPs: 936.3068. Time: 3954.4595 us. Best GFLOPs: 1395.6443
2024-04-30 09:39:55 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #353: GFLOPs: 1008.9369. Time: 3669.7909 us. Best GFLOPs: 1395.6443
2024-04-30 09:39:55 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #354: GFLOPs: 857.7462. Time: 4316.6467 us. Best GFLOPs: 1395.6443
2024-04-30 09:39:55 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #355: GFLOPs: 697.7920. Time: 5306.1474 us. Best GFLOPs: 1395.6443
2024-04-30 09:39:55 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #356: GFLOPs: 1312.1026. Time: 2821.8735 us. Best GFLOPs: 1395.6443
2024-04-30 09:39:55 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #357: GFLOPs: 1064.5521. Time: 3478.0708 us. Best GFLOPs: 1395.6443
2024-04-30 09:39:55 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #358: GFLOPs: 1061.7714. Time: 3487.1796 us. Best GFLOPs: 1395.6443
2024-04-30 09:39:55 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #359: GFLOPs: 1317.1169. Time: 2811.1305 us. Best GFLOPs: 1395.6443
2024-04-30 09:39:55 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #360: GFLOPs: 891.5656. Time: 4152.9054 us. Best GFLOPs: 1395.6443
2024-04-30 09:39:55 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #361: GFLOPs: 1373.9325. Time: 2694.8831 us. Best GFLOPs: 1395.6443
2024-04-30 09:39:55 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #362: GFLOPs: 620.7091. Time: 5965.0925 us. Best GFLOPs: 1395.6443
2024-04-30 09:39:55 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #363: GFLOPs: 856.4811. Time: 4323.0230 us. Best GFLOPs: 1395.6443
2024-04-30 09:39:55 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #364: GFLOPs: 951.8156. Time: 3890.0260 us. Best GFLOPs: 1395.6443
2024-04-30 09:39:55 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #365: GFLOPs: 980.4582. Time: 3776.3849 us. Best GFLOPs: 1395.6443
2024-04-30 09:39:55 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #366: GFLOPs: 981.2896. Time: 3773.1852 us. Best GFLOPs: 1395.6443
2024-04-30 09:39:55 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #367: GFLOPs: 985.7787. Time: 3756.0026 us. Best GFLOPs: 1395.6443
2024-04-30 09:39:55 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #368: GFLOPs: 981.4227. Time: 3772.6733 us. Best GFLOPs: 1395.6443
2024-04-30 09:39:55 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #369: GFLOPs: 799.6944. Time: 4630.0027 us. Best GFLOPs: 1395.6443
2024-04-30 09:39:55 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #370: GFLOPs: 806.5259. Time: 4590.7856 us. Best GFLOPs: 1395.6443
2024-04-30 09:39:55 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #371: GFLOPs: 1052.4829. Time: 3517.9549 us. Best GFLOPs: 1395.6443
2024-04-30 09:39:55 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #372: GFLOPs: 844.0100. Time: 4386.9001 us. Best GFLOPs: 1395.6443
2024-04-30 09:39:55 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #373: GFLOPs: 1021.9413. Time: 3623.0922 us. Best GFLOPs: 1395.6443
2024-04-30 09:39:55 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #374: GFLOPs: 970.2084. Time: 3816.2804 us. Best GFLOPs: 1395.6443
2024-04-30 09:39:55 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #375: GFLOPs: 1011.4033. Time: 3660.8418 us. Best GFLOPs: 1395.6443
2024-04-30 09:39:55 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #376: GFLOPs: 1095.4395. Time: 3380.0017 us. Best GFLOPs: 1395.6443
2024-04-30 09:39:55 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #377: GFLOPs: 899.3250. Time: 4117.0739 us. Best GFLOPs: 1395.6443
2024-04-30 09:39:55 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #378: GFLOPs: 870.7471. Time: 4252.1960 us. Best GFLOPs: 1395.6443
2024-04-30 09:39:55 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #379: GFLOPs: 912.3824. Time: 4058.1529 us. Best GFLOPs: 1395.6443
2024-04-30 09:39:55 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #380: GFLOPs: 909.7345. Time: 4069.9647 us. Best GFLOPs: 1395.6443
2024-04-30 09:39:55 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #381: GFLOPs: 773.4003. Time: 4787.4141 us. Best GFLOPs: 1395.6443
2024-04-30 09:39:55 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #382: GFLOPs: 10.8580. Time: 341000.3500 us. Best GFLOPs: 1395.6443
2024-04-30 09:39:55 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #383: GFLOPs: 1.5478. Time: 2392190.3397 us. Best GFLOPs: 1395.6443
2024-04-30 09:39:55 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #384: GFLOPs: 25.8967. Time: 142975.0897 us. Best GFLOPs: 1395.6443
2024-04-30 10:22:02 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-30 10:22:03 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-30 10:22:08 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x315e438)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x371f878)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3352b68)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x36bf9a8)]: 0 failure(s)
2024-04-30 10:22:08 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-30 10:22:22 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x315e438)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x371f878)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3352b68)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x36bf9a8)]: 0 failure(s)
2024-04-30 10:22:36 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x315e438)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x371f878)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3352b68)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x36bf9a8)]: 0 failure(s)
2024-04-30 10:22:50 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x315e438)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x371f878)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3352b68)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x36bf9a8)]: 0 failure(s)
2024-04-30 10:23:04 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x315e438)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x371f878)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3352b68)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x36bf9a8)]: 0 failure(s)
2024-04-30 10:23:12 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9490  0.9384  0.9326  0.9309  0.9308  0.9300  0.9271  0.9260  0.9187  0.9178  0.9121  0.9024  0.8992  0.8855  0.8845  0.8799
[17 : 32]:	0.8714  0.8664  0.8664  0.8584  0.8581  0.8502  0.8491  0.8451  0.8390  0.8316  0.8206  0.8152  0.8136  0.8002  0.7987  0.7944
[33 : 48]:	0.7910  0.7852  0.7835  0.7814  0.7807  0.7743  0.7732  0.7720  0.7688  0.7636  0.7636  0.7636  0.7624  0.7606  0.7586  0.7521
[49 : 64]:	0.7516  0.7487  0.7473  0.7467  0.7452  0.7443  0.7438  0.7438  0.7420  0.7405  0.7402  0.7379  0.7358  0.7329  0.7321  0.7301
2024-04-30 10:23:12 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-30 10:23:12 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-30 10:25:09 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #385: GFLOPs: 1326.5961. Time: 2791.0434 us. Best GFLOPs: 1395.6443
2024-04-30 10:25:09 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #386: GFLOPs: 1243.8777. Time: 2976.6490 us. Best GFLOPs: 1395.6443
2024-04-30 10:25:09 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #387: GFLOPs: 1375.6049. Time: 2691.6067 us. Best GFLOPs: 1395.6443
2024-04-30 10:25:09 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #388: GFLOPs: 1405.0603. Time: 2635.1804 us. Best GFLOPs: 1405.0603
2024-04-30 10:25:09 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #389: GFLOPs: 1368.6612. Time: 2705.2622 us. Best GFLOPs: 1405.0603
2024-04-30 10:25:09 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #390: GFLOPs: 1349.7622. Time: 2743.1405 us. Best GFLOPs: 1405.0603
2024-04-30 10:25:09 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #391: GFLOPs: 1355.6431. Time: 2731.2406 us. Best GFLOPs: 1405.0603
2024-04-30 10:25:09 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #392: GFLOPs: 1363.2503. Time: 2715.9998 us. Best GFLOPs: 1405.0603
2024-04-30 10:25:09 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #393: GFLOPs: 1260.1521. Time: 2938.2068 us. Best GFLOPs: 1405.0603
2024-04-30 10:25:09 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #394: GFLOPs: 1369.6064. Time: 2703.3953 us. Best GFLOPs: 1405.0603
2024-04-30 10:25:09 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #395: GFLOPs: 1260.7569. Time: 2936.7972 us. Best GFLOPs: 1405.0603
2024-04-30 10:25:09 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #396: GFLOPs: 1248.8909. Time: 2964.7005 us. Best GFLOPs: 1405.0603
2024-04-30 10:25:09 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #397: GFLOPs: 1076.3497. Time: 3439.9483 us. Best GFLOPs: 1405.0603
2024-04-30 10:25:09 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #398: GFLOPs: 1361.5118. Time: 2719.4677 us. Best GFLOPs: 1405.0603
2024-04-30 10:25:09 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #399: GFLOPs: 729.7812. Time: 5073.5584 us. Best GFLOPs: 1405.0603
2024-04-30 10:25:09 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #400: GFLOPs: 1091.1673. Time: 3393.2352 us. Best GFLOPs: 1405.0603
2024-04-30 10:25:09 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #401: GFLOPs: 1293.8812. Time: 2861.6130 us. Best GFLOPs: 1405.0603
2024-04-30 10:25:09 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #402: GFLOPs: 1090.7196. Time: 3394.6282 us. Best GFLOPs: 1405.0603
2024-04-30 10:25:09 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #403: GFLOPs: 1095.6313. Time: 3379.4099 us. Best GFLOPs: 1405.0603
2024-04-30 10:25:09 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #404: GFLOPs: 688.1274. Time: 5380.6717 us. Best GFLOPs: 1405.0603
2024-04-30 10:25:09 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #405: GFLOPs: 706.7608. Time: 5238.8129 us. Best GFLOPs: 1405.0603
2024-04-30 10:25:09 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #406: GFLOPs: 720.7534. Time: 5137.1071 us. Best GFLOPs: 1405.0603
2024-04-30 10:25:09 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #407: GFLOPs: 1362.7178. Time: 2717.0611 us. Best GFLOPs: 1405.0603
2024-04-30 10:25:09 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #408: GFLOPs: 1220.4823. Time: 3033.7084 us. Best GFLOPs: 1405.0603
2024-04-30 10:25:09 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #409: GFLOPs: 1227.1922. Time: 3017.1211 us. Best GFLOPs: 1405.0603
2024-04-30 10:25:09 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #410: GFLOPs: 1305.8535. Time: 2835.3772 us. Best GFLOPs: 1405.0603
2024-04-30 10:25:09 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #411: GFLOPs: 694.2118. Time: 5333.5125 us. Best GFLOPs: 1405.0603
2024-04-30 10:25:09 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #412: GFLOPs: 1287.5191. Time: 2875.7533 us. Best GFLOPs: 1405.0603
2024-04-30 10:25:09 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #413: GFLOPs: 1321.1791. Time: 2802.4872 us. Best GFLOPs: 1405.0603
2024-04-30 10:25:09 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #414: GFLOPs: 1088.6335. Time: 3401.1330 us. Best GFLOPs: 1405.0603
2024-04-30 10:25:09 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #415: GFLOPs: 1074.8581. Time: 3444.7221 us. Best GFLOPs: 1405.0603
2024-04-30 10:25:09 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #416: GFLOPs: 1289.8659. Time: 2870.5212 us. Best GFLOPs: 1405.0603
2024-04-30 10:25:09 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #417: GFLOPs: 592.3503. Time: 6250.6724 us. Best GFLOPs: 1405.0603
2024-04-30 10:25:09 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #418: GFLOPs: 1051.9437. Time: 3519.7583 us. Best GFLOPs: 1405.0603
2024-04-30 10:25:09 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #419: GFLOPs: 1144.3342. Time: 3235.5822 us. Best GFLOPs: 1405.0603
2024-04-30 10:25:09 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #420: GFLOPs: 1095.0605. Time: 3381.1716 us. Best GFLOPs: 1405.0603
2024-04-30 10:25:09 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #421: GFLOPs: 1090.5133. Time: 3395.2702 us. Best GFLOPs: 1405.0603
2024-04-30 10:25:09 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #422: GFLOPs: 1116.0215. Time: 3317.6667 us. Best GFLOPs: 1405.0603
2024-04-30 10:25:09 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #423: GFLOPs: 237.1446. Time: 15613.2066 us. Best GFLOPs: 1405.0603
2024-04-30 10:25:09 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #424: GFLOPs: 1161.0357. Time: 3189.0384 us. Best GFLOPs: 1405.0603
2024-04-30 10:25:09 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #425: GFLOPs: 1126.1018. Time: 3287.9686 us. Best GFLOPs: 1405.0603
2024-04-30 10:25:09 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #426: GFLOPs: 8.9560. Time: 413420.4367 us. Best GFLOPs: 1405.0603
2024-04-30 10:25:09 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #427: GFLOPs: 29.3334. Time: 126224.2703 us. Best GFLOPs: 1405.0603
2024-04-30 10:25:09 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #428: GFLOPs: 444.0834. Time: 8337.5946 us. Best GFLOPs: 1405.0603
2024-04-30 10:25:09 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #429: GFLOPs: 1049.8999. Time: 3526.6098 us. Best GFLOPs: 1405.0603
2024-04-30 10:25:09 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #430: GFLOPs: 1089.1887. Time: 3399.3993 us. Best GFLOPs: 1405.0603
2024-04-30 10:25:09 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #431: GFLOPs: 1098.7441. Time: 3369.8361 us. Best GFLOPs: 1405.0603
2024-04-30 10:25:09 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #432: GFLOPs: 1059.3023. Time: 3495.3075 us. Best GFLOPs: 1405.0603
2024-04-30 10:25:09 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #433: GFLOPs: 1165.1962. Time: 3177.6513 us. Best GFLOPs: 1405.0603
2024-04-30 10:25:09 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #434: GFLOPs: 1034.4636. Time: 3579.2342 us. Best GFLOPs: 1405.0603
2024-04-30 10:25:09 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #435: GFLOPs: 1403.1262. Time: 2638.8129 us. Best GFLOPs: 1405.0603
2024-04-30 10:25:09 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #436: GFLOPs: 1082.8635. Time: 3419.2560 us. Best GFLOPs: 1405.0603
2024-04-30 10:25:09 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #437: GFLOPs: 1043.7789. Time: 3547.2908 us. Best GFLOPs: 1405.0603
2024-04-30 10:25:09 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #438: GFLOPs: 1071.1608. Time: 3456.6120 us. Best GFLOPs: 1405.0603
2024-04-30 10:25:09 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #439: GFLOPs: 1035.4321. Time: 3575.8863 us. Best GFLOPs: 1405.0603
2024-04-30 10:25:09 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #440: GFLOPs: 583.0923. Time: 6349.9169 us. Best GFLOPs: 1405.0603
2024-04-30 10:25:09 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #441: GFLOPs: 1124.0942. Time: 3293.8410 us. Best GFLOPs: 1405.0603
2024-04-30 10:25:09 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #442: GFLOPs: 963.5441. Time: 3842.6756 us. Best GFLOPs: 1405.0603
2024-04-30 10:25:09 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #443: GFLOPs: 1141.6299. Time: 3243.2465 us. Best GFLOPs: 1405.0603
2024-04-30 10:25:09 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #444: GFLOPs: 1108.8626. Time: 3339.0859 us. Best GFLOPs: 1405.0603
2024-04-30 10:25:09 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #445: GFLOPs: 1085.3172. Time: 3411.5255 us. Best GFLOPs: 1405.0603
2024-04-30 10:25:09 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #446: GFLOPs: 15.3984. Time: 240453.5033 us. Best GFLOPs: 1405.0603
2024-04-30 10:25:09 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #447: GFLOPs: 45.4065. Time: 81543.1587 us. Best GFLOPs: 1405.0603
2024-04-30 10:25:09 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #448: GFLOPs: 167.1005. Time: 22157.8516 us. Best GFLOPs: 1405.0603
2024-04-30 11:36:11 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-30 11:36:13 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-30 11:36:17 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x315e438)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x371f878)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3352b68)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x36bf9a8)]: 0 failure(s)
2024-04-30 11:36:17 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-30 11:36:31 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x315e438)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x371f878)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3352b68)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x36bf9a8)]: 0 failure(s)
2024-04-30 11:36:45 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x315e438)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x371f878)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3352b68)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x36bf9a8)]: 0 failure(s)
2024-04-30 11:37:00 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x315e438)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x371f878)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3352b68)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x36bf9a8)]: 0 failure(s)
2024-04-30 11:37:14 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x315e438)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x371f878)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3352b68)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x36bf9a8)]: 0 failure(s)
2024-04-30 11:37:22 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9808  0.9808  0.9808  0.9665  0.9642  0.9586  0.9586  0.9563  0.9538  0.9528  0.9520  0.9400  0.9391  0.9324  0.9300  0.9287
[17 : 32]:	0.9231  0.9212  0.9130  0.9106  0.9100  0.9065  0.9065  0.9052  0.9014  0.8999  0.8983  0.8981  0.8957  0.8890  0.8880  0.8834
[33 : 48]:	0.8801  0.8729  0.8680  0.8657  0.8544  0.8458  0.8449  0.8412  0.8398  0.8288  0.8279  0.8268  0.8170  0.8129  0.8116  0.8116
[49 : 64]:	0.8025  0.7988  0.7980  0.7966  0.7964  0.7931  0.7924  0.7896  0.7888  0.7886  0.7880  0.7880  0.7847  0.7845  0.7845  0.7845
2024-04-30 11:37:23 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-30 11:37:23 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-30 11:39:32 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #449: GFLOPs: 719.1272. Time: 5148.7241 us. Best GFLOPs: 1405.0603
2024-04-30 11:39:32 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #450: GFLOPs: 1407.6752. Time: 2630.2853 us. Best GFLOPs: 1407.6752
2024-04-30 11:39:32 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #451: GFLOPs: 1390.7484. Time: 2662.2984 us. Best GFLOPs: 1407.6752
2024-04-30 11:39:32 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #452: GFLOPs: 1382.8314. Time: 2677.5408 us. Best GFLOPs: 1407.6752
2024-04-30 11:39:32 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #453: GFLOPs: 786.4876. Time: 4707.7507 us. Best GFLOPs: 1407.6752
2024-04-30 11:39:32 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #454: GFLOPs: 1339.0638. Time: 2765.0568 us. Best GFLOPs: 1407.6752
2024-04-30 11:39:32 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #455: GFLOPs: 1342.8373. Time: 2757.2866 us. Best GFLOPs: 1407.6752
2024-04-30 11:39:32 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #456: GFLOPs: 1362.5567. Time: 2717.3822 us. Best GFLOPs: 1407.6752
2024-04-30 11:39:32 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #457: GFLOPs: 1318.8364. Time: 2807.4653 us. Best GFLOPs: 1407.6752
2024-04-30 11:39:32 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #458: GFLOPs: 1317.9411. Time: 2809.3725 us. Best GFLOPs: 1407.6752
2024-04-30 11:39:32 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #459: GFLOPs: 1381.2522. Time: 2680.6019 us. Best GFLOPs: 1407.6752
2024-04-30 11:39:32 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #460: GFLOPs: 1318.0708. Time: 2809.0961 us. Best GFLOPs: 1407.6752
2024-04-30 11:39:32 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #461: GFLOPs: 1212.4612. Time: 3053.7780 us. Best GFLOPs: 1407.6752
2024-04-30 11:39:32 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #462: GFLOPs: 688.7545. Time: 5375.7722 us. Best GFLOPs: 1407.6752
2024-04-30 11:39:32 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #463: GFLOPs: 692.9950. Time: 5342.8772 us. Best GFLOPs: 1407.6752
2024-04-30 11:39:32 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #464: GFLOPs: 1395.7922. Time: 2652.6780 us. Best GFLOPs: 1407.6752
2024-04-30 11:39:32 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #465: GFLOPs: 1417.8925. Time: 2611.3316 us. Best GFLOPs: 1417.8925
2024-04-30 11:39:32 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #466: GFLOPs: 1379.6457. Time: 2683.7233 us. Best GFLOPs: 1417.8925
2024-04-30 11:39:32 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #467: GFLOPs: 1325.8820. Time: 2792.5466 us. Best GFLOPs: 1417.8925
2024-04-30 11:39:32 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #468: GFLOPs: 1406.0697. Time: 2633.2887 us. Best GFLOPs: 1417.8925
2024-04-30 11:39:32 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #469: GFLOPs: 1325.9067. Time: 2792.4947 us. Best GFLOPs: 1417.8925
2024-04-30 11:39:32 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #470: GFLOPs: 1275.2651. Time: 2903.3865 us. Best GFLOPs: 1417.8925
2024-04-30 11:39:32 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #471: GFLOPs: 1337.5049. Time: 2768.2795 us. Best GFLOPs: 1417.8925
2024-04-30 11:39:32 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #472: GFLOPs: 1336.9677. Time: 2769.3917 us. Best GFLOPs: 1417.8925
2024-04-30 11:39:32 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #473: GFLOPs: 1295.6548. Time: 2857.6958 us. Best GFLOPs: 1417.8925
2024-04-30 11:39:32 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #474: GFLOPs: 1273.9462. Time: 2906.3923 us. Best GFLOPs: 1417.8925
2024-04-30 11:39:32 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #475: GFLOPs: 1304.6225. Time: 2838.0527 us. Best GFLOPs: 1417.8925
2024-04-30 11:39:32 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #476: GFLOPs: 1444.5631. Time: 2563.1191 us. Best GFLOPs: 1444.5631
2024-04-30 11:39:32 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #477: GFLOPs: 1270.2338. Time: 2914.8864 us. Best GFLOPs: 1444.5631
2024-04-30 11:39:32 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #478: GFLOPs: 1288.6359. Time: 2873.2611 us. Best GFLOPs: 1444.5631
2024-04-30 11:39:32 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #479: GFLOPs: 1272.8376. Time: 2908.9237 us. Best GFLOPs: 1444.5631
2024-04-30 11:39:32 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #480: GFLOPs: 1239.0454. Time: 2988.2580 us. Best GFLOPs: 1444.5631
2024-04-30 11:39:32 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #481: GFLOPs: 1278.6510. Time: 2895.6981 us. Best GFLOPs: 1444.5631
2024-04-30 11:39:32 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #482: GFLOPs: 1465.4959. Time: 2526.5082 us. Best GFLOPs: 1465.4959
2024-04-30 11:39:32 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #483: GFLOPs: 1252.3692. Time: 2956.4664 us. Best GFLOPs: 1465.4959
2024-04-30 11:39:32 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #484: GFLOPs: 1081.4149. Time: 3423.8362 us. Best GFLOPs: 1465.4959
2024-04-30 11:39:32 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #485: GFLOPs: 249.5851. Time: 14834.9681 us. Best GFLOPs: 1465.4959
2024-04-30 11:39:32 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #486: GFLOPs: 311.6111. Time: 11882.0773 us. Best GFLOPs: 1465.4959
2024-04-30 11:39:32 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #487: GFLOPs: 1184.4597. Time: 3125.9715 us. Best GFLOPs: 1465.4959
2024-04-30 11:39:32 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #488: GFLOPs: 1270.3277. Time: 2914.6710 us. Best GFLOPs: 1465.4959
2024-04-30 11:39:32 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #489: GFLOPs: 1242.0101. Time: 2981.1251 us. Best GFLOPs: 1465.4959
2024-04-30 11:39:32 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #490: GFLOPs: 13.7393. Time: 269488.5820 us. Best GFLOPs: 1465.4959
2024-04-30 11:39:32 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #491: GFLOPs: 1321.6358. Time: 2801.5188 us. Best GFLOPs: 1465.4959
2024-04-30 11:39:32 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #492: GFLOPs: 1316.2416. Time: 2812.9999 us. Best GFLOPs: 1465.4959
2024-04-30 11:39:32 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #493: GFLOPs: 593.7947. Time: 6235.4672 us. Best GFLOPs: 1465.4959
2024-04-30 11:39:32 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #494: GFLOPs: 1196.6540. Time: 3094.1169 us. Best GFLOPs: 1465.4959
2024-04-30 11:39:32 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #495: GFLOPs: 1350.7123. Time: 2741.2109 us. Best GFLOPs: 1465.4959
2024-04-30 11:39:32 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #496: GFLOPs: 1353.6955. Time: 2735.1700 us. Best GFLOPs: 1465.4959
2024-04-30 11:39:32 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #497: GFLOPs: 1094.0324. Time: 3384.3489 us. Best GFLOPs: 1465.4959
2024-04-30 11:39:32 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #498: GFLOPs: 1055.9819. Time: 3506.2982 us. Best GFLOPs: 1465.4959
2024-04-30 11:39:32 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #499: GFLOPs: 1337.7038. Time: 2767.8679 us. Best GFLOPs: 1465.4959
2024-04-30 11:39:32 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #500: GFLOPs: 249.7744. Time: 14823.7264 us. Best GFLOPs: 1465.4959
2024-04-30 11:39:32 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #501: GFLOPs: 1169.9203. Time: 3164.8201 us. Best GFLOPs: 1465.4959
2024-04-30 11:39:32 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #502: GFLOPs: 1136.6378. Time: 3257.4909 us. Best GFLOPs: 1465.4959
2024-04-30 11:39:32 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #503: GFLOPs: 1204.8876. Time: 3072.9732 us. Best GFLOPs: 1465.4959
2024-04-30 11:39:32 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #504: GFLOPs: 1137.6972. Time: 3254.4576 us. Best GFLOPs: 1465.4959
2024-04-30 11:39:32 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #505: GFLOPs: 1438.1793. Time: 2574.4963 us. Best GFLOPs: 1465.4959
2024-04-30 11:39:32 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #506: GFLOPs: 1261.4811. Time: 2935.1113 us. Best GFLOPs: 1465.4959
2024-04-30 11:39:32 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #507: GFLOPs: 1315.6163. Time: 2814.3368 us. Best GFLOPs: 1465.4959
2024-04-30 11:39:32 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #508: GFLOPs: 1259.7485. Time: 2939.1480 us. Best GFLOPs: 1465.4959
2024-04-30 11:39:32 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #509: GFLOPs: 1093.0761. Time: 3387.3099 us. Best GFLOPs: 1465.4959
2024-04-30 11:39:32 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #510: GFLOPs: 64.7674. Time: 57167.4523 us. Best GFLOPs: 1465.4959
2024-04-30 11:39:32 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #511: GFLOPs: 32.2107. Time: 114948.8853 us. Best GFLOPs: 1465.4959
2024-04-30 11:39:32 [INFO] [task_scheduler.cc:121] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #512: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(112), T.int64(112), T.int64(64)), "float32"), p1: T.Buffer((T.int64(2), T.int64(2), T.int64(3), T.int64(3), T.int64(64), T.int64(64)), "float32"), p2: T.Buffer((T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(64)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(2), T.int64(112), T.int64(112), T.int64(64)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(114), T.int64(114), T.int64(64)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(112), T.int64(112), T.int64(64)))
        for n_0_oc_chunk_0_oh_0_fused_fused in T.parallel(T.int64(28), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(2), T.int64(6), T.int64(114)):
                for ax4_fused in T.vectorized(T.int64(64)):
                    with T.block("data_pad"):
                        v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                        v_i2 = T.axis.spatial(T.int64(114), n_0_oc_chunk_0_oh_0_fused_fused * T.int64(4) + ax2)
                        v_i3, v_i4 = T.axis.remap("SS", [ax3, ax4_fused])
                        T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                        T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                        data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(113) and T.int64(1) <= v_i3 and v_i3 < T.int64(113), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for ow_0, oc_block_0, n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(2), T.int64(8), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(8), T.int64(8), T.int64(1), T.int64(2), T.int64(4), T.int64(7), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(2), oc_chunk_1 * T.int64(2) + oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(112), n_0_oc_chunk_0_oh_0_fused_fused * T.int64(4) + oh_1 * T.int64(4) + oh_2_init * T.int64(4) + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(112), ow_0 * T.int64(56) + ow_1 * T.int64(56) + ow_2_init * T.int64(7) + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(64), oc_block_0 * T.int64(8) + oc_block_1 * T.int64(8) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(128), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(8), T.int64(8), T.int64(1), T.int64(3), T.int64(3), T.int64(1), T.int64(2), T.int64(4), T.int64(7), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(2), oc_chunk_1 * T.int64(2) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(112), n_0_oc_chunk_0_oh_0_fused_fused * T.int64(4) + oh_1 * T.int64(4) + oh_2 * T.int64(4) + oh_3)
                        v_ow = T.axis.spatial(T.int64(112), ow_0 * T.int64(56) + ow_1 * T.int64(56) + ow_2 * T.int64(7) + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(64), oc_block_0 * T.int64(8) + oc_block_1 * T.int64(8) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(128), ic_0 + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(64), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(64)], p1[v_oc_chunk, v_ic // T.int64(64), v_kh, v_kw, v_ic % T.int64(64), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(64), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(64)] * p1[v_oc_chunk, v_ic // T.int64(64), v_kh, v_kw, v_ic % T.int64(64), v_oc_block]
        for ax0_ax1_ax2_ax3_ax4_fused_0 in T.parallel(T.int64(25088)):
            for ax0_ax1_ax2_ax3_ax4_fused_1 in T.vectorized(T.int64(64)):
                with T.block("T_relu"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(2), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) // T.int64(802816))
                    v_ax2 = T.axis.spatial(T.int64(112), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(802816) // T.int64(7168))
                    v_ax3 = T.axis.spatial(T.int64(112), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(7168) // T.int64(64))
                    v_ax4 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(64))
                    T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                    T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 2])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[28, 1, 1, 4])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[2, 1, 8, 7])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[8, 1, 8, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[128, 1])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
l65 = sch.sample_compute_location(block=b0, decision=2)
sch.compute_at(block=b0, loop=l65, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b66 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.unroll_explicit")
b67, b68, b69 = sch.get_child_blocks(b66)
l70, l71, l72, l73, l74, l75, l76, l77 = sch.get_loops(block=b67)
l78 = sch.fuse(l70, l71, l72, preserve_unit_iters=True)
sch.parallel(loop=l78)
l79 = sch.fuse(l77, preserve_unit_iters=True)
sch.vectorize(loop=l79)
l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b68)
l104 = sch.fuse(l80, preserve_unit_iters=True)
sch.parallel(loop=l104)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109 = sch.get_loops(block=b69)
l110 = sch.fuse(l105, l106, l107, l108, l109, preserve_unit_iters=True)
l111, l112 = sch.split(loop=l110, factors=[None, 64], preserve_unit_iters=True)
sch.parallel(loop=l111)
sch.vectorize(loop=l112)
b113 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137 = sch.get_loops(block=b113)
b138 = sch.decompose_reduction(block=b113, loop=l122)
2024-04-30 12:38:32 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-30 12:38:34 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-30 12:38:38 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x315e438)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x371f878)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3352b68)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x36bf9a8)]: 0 failure(s)
2024-04-30 12:38:38 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-30 12:38:52 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x315e438)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x371f878)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3352b68)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x36bf9a8)]: 0 failure(s)
2024-04-30 12:39:06 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x315e438)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x371f878)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3352b68)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x36bf9a8)]: 0 failure(s)
2024-04-30 12:39:20 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x315e438)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x371f878)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3352b68)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x36bf9a8)]: 0 failure(s)
2024-04-30 12:39:35 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x315e438)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x371f878)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3352b68)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x36bf9a8)]: 0 failure(s)
2024-04-30 12:39:43 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	1.0018  0.9973  0.9834  0.9788  0.9731  0.9518  0.9494  0.9436  0.9373  0.9353  0.9353  0.9307  0.9303  0.9301  0.9240  0.9208
[17 : 32]:	0.9152  0.9152  0.9128  0.9128  0.9125  0.9108  0.9107  0.9091  0.9035  0.9018  0.8926  0.8919  0.8919  0.8919  0.8900  0.8878
[33 : 48]:	0.8818  0.8803  0.8761  0.8720  0.8715  0.8710  0.8700  0.8622  0.8511  0.8410  0.8406  0.8404  0.8394  0.8389  0.8362  0.8327
[49 : 64]:	0.8327  0.8286  0.8261  0.8256  0.8244  0.8199  0.8156  0.8080  0.7984  0.7965  0.7944  0.7853  0.7852  0.7789  0.7789  0.7749
2024-04-30 12:39:44 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-30 12:39:44 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-30 12:41:49 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #513: GFLOPs: 1470.4188. Time: 2518.0496 us. Best GFLOPs: 1470.4188
2024-04-30 12:41:49 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #514: GFLOPs: 1343.1023. Time: 2756.7426 us. Best GFLOPs: 1470.4188
2024-04-30 12:41:49 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #515: GFLOPs: 1390.0739. Time: 2663.5903 us. Best GFLOPs: 1470.4188
2024-04-30 12:41:49 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #516: GFLOPs: 1335.2457. Time: 2772.9634 us. Best GFLOPs: 1470.4188
2024-04-30 12:41:49 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #517: GFLOPs: 1354.8300. Time: 2732.8797 us. Best GFLOPs: 1470.4188
2024-04-30 12:41:49 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #518: GFLOPs: 1355.9724. Time: 2730.5772 us. Best GFLOPs: 1470.4188
2024-04-30 12:41:49 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #519: GFLOPs: 1310.4620. Time: 2825.4061 us. Best GFLOPs: 1470.4188
2024-04-30 12:41:49 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #520: GFLOPs: 1347.3188. Time: 2748.1154 us. Best GFLOPs: 1470.4188
2024-04-30 12:41:49 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #521: GFLOPs: 1348.2545. Time: 2746.2081 us. Best GFLOPs: 1470.4188
2024-04-30 12:41:49 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #522: GFLOPs: 1332.3681. Time: 2778.9523 us. Best GFLOPs: 1470.4188
2024-04-30 12:41:49 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #523: GFLOPs: 1353.7407. Time: 2735.0787 us. Best GFLOPs: 1470.4188
2024-04-30 12:41:49 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #524: GFLOPs: 1353.4235. Time: 2735.7198 us. Best GFLOPs: 1470.4188
2024-04-30 12:41:49 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #525: GFLOPs: 1323.6302. Time: 2797.2975 us. Best GFLOPs: 1470.4188
2024-04-30 12:41:49 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #526: GFLOPs: 1342.0728. Time: 2758.8574 us. Best GFLOPs: 1470.4188
2024-04-30 12:41:49 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #527: GFLOPs: 1346.5702. Time: 2749.6431 us. Best GFLOPs: 1470.4188
2024-04-30 12:41:49 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #528: GFLOPs: 1296.4209. Time: 2856.0072 us. Best GFLOPs: 1470.4188
2024-04-30 12:41:49 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #529: GFLOPs: 1320.7366. Time: 2803.4260 us. Best GFLOPs: 1470.4188
2024-04-30 12:41:49 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #530: GFLOPs: 1369.7839. Time: 2703.0449 us. Best GFLOPs: 1470.4188
2024-04-30 12:41:49 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #531: GFLOPs: 1344.9179. Time: 2753.0211 us. Best GFLOPs: 1470.4188
2024-04-30 12:41:49 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #532: GFLOPs: 1362.8033. Time: 2716.8905 us. Best GFLOPs: 1470.4188
2024-04-30 12:41:49 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #533: GFLOPs: 1313.4690. Time: 2818.9378 us. Best GFLOPs: 1470.4188
2024-04-30 12:41:49 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #534: GFLOPs: 1238.6949. Time: 2989.1037 us. Best GFLOPs: 1470.4188
2024-04-30 12:41:49 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #535: GFLOPs: 1295.8316. Time: 2857.3060 us. Best GFLOPs: 1470.4188
2024-04-30 12:41:49 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #536: GFLOPs: 1359.9561. Time: 2722.5787 us. Best GFLOPs: 1470.4188
2024-04-30 12:41:49 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #537: GFLOPs: 1317.2979. Time: 2810.7442 us. Best GFLOPs: 1470.4188
2024-04-30 12:41:49 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #538: GFLOPs: 1357.1502. Time: 2728.2075 us. Best GFLOPs: 1470.4188
2024-04-30 12:41:49 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #539: GFLOPs: 1342.2467. Time: 2758.4999 us. Best GFLOPs: 1470.4188
2024-04-30 12:41:49 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #540: GFLOPs: 1339.5166. Time: 2764.1221 us. Best GFLOPs: 1470.4188
2024-04-30 12:41:49 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #541: GFLOPs: 1366.5558. Time: 2709.4301 us. Best GFLOPs: 1470.4188
2024-04-30 12:41:49 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #542: GFLOPs: 1355.1310. Time: 2732.2726 us. Best GFLOPs: 1470.4188
2024-04-30 12:41:49 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #543: GFLOPs: 1350.4073. Time: 2741.8301 us. Best GFLOPs: 1470.4188
2024-04-30 12:41:49 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #544: GFLOPs: 1270.7302. Time: 2913.7478 us. Best GFLOPs: 1470.4188
2024-04-30 12:41:49 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #545: GFLOPs: 1340.9097. Time: 2761.2505 us. Best GFLOPs: 1470.4188
2024-04-30 12:41:49 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #546: GFLOPs: 1238.8755. Time: 2988.6679 us. Best GFLOPs: 1470.4188
2024-04-30 12:41:49 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #547: GFLOPs: 1261.8904. Time: 2934.1593 us. Best GFLOPs: 1470.4188
2024-04-30 12:41:49 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #548: GFLOPs: 1262.8101. Time: 2932.0224 us. Best GFLOPs: 1470.4188
2024-04-30 12:41:49 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #549: GFLOPs: 1222.0906. Time: 3029.7159 us. Best GFLOPs: 1470.4188
2024-04-30 12:41:49 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #550: GFLOPs: 1324.8796. Time: 2794.6595 us. Best GFLOPs: 1470.4188
2024-04-30 12:41:49 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #551: GFLOPs: 1296.3384. Time: 2856.1889 us. Best GFLOPs: 1470.4188
2024-04-30 12:41:49 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #552: GFLOPs: 1256.2289. Time: 2947.3828 us. Best GFLOPs: 1470.4188
2024-04-30 12:41:49 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #553: GFLOPs: 1335.0111. Time: 2773.4507 us. Best GFLOPs: 1470.4188
2024-04-30 12:41:49 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #554: GFLOPs: 1369.6536. Time: 2703.3020 us. Best GFLOPs: 1470.4188
2024-04-30 12:41:49 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #555: GFLOPs: 1261.7162. Time: 2934.5645 us. Best GFLOPs: 1470.4188
2024-04-30 12:41:49 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #556: GFLOPs: 1314.8348. Time: 2816.0096 us. Best GFLOPs: 1470.4188
2024-04-30 12:41:49 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #557: GFLOPs: 1247.9467. Time: 2966.9436 us. Best GFLOPs: 1470.4188
2024-04-30 12:41:49 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #558: GFLOPs: 1116.8102. Time: 3315.3238 us. Best GFLOPs: 1470.4188
2024-04-30 12:41:49 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #559: GFLOPs: 1284.2595. Time: 2883.0523 us. Best GFLOPs: 1470.4188
2024-04-30 12:41:49 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #560: GFLOPs: 1263.2140. Time: 2931.0847 us. Best GFLOPs: 1470.4188
2024-04-30 12:41:49 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #561: GFLOPs: 1147.9538. Time: 3225.3802 us. Best GFLOPs: 1470.4188
2024-04-30 12:41:49 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #562: GFLOPs: 1165.2997. Time: 3177.3693 us. Best GFLOPs: 1470.4188
2024-04-30 12:41:49 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #563: GFLOPs: 1273.7077. Time: 2906.9365 us. Best GFLOPs: 1470.4188
2024-04-30 12:41:49 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #564: GFLOPs: 1248.9007. Time: 2964.6771 us. Best GFLOPs: 1470.4188
2024-04-30 12:41:49 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #565: GFLOPs: 14.2996. Time: 258929.2257 us. Best GFLOPs: 1470.4188
2024-04-30 12:41:49 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #566: GFLOPs: 1341.8494. Time: 2759.3166 us. Best GFLOPs: 1470.4188
2024-04-30 12:41:49 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #567: GFLOPs: 1259.0293. Time: 2940.8270 us. Best GFLOPs: 1470.4188
2024-04-30 12:41:49 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #568: GFLOPs: 1338.1061. Time: 2767.0357 us. Best GFLOPs: 1470.4188
2024-04-30 12:41:49 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #569: GFLOPs: 1313.0991. Time: 2819.7318 us. Best GFLOPs: 1470.4188
2024-04-30 12:41:49 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #570: GFLOPs: 1200.0059. Time: 3085.4742 us. Best GFLOPs: 1470.4188
2024-04-30 12:41:49 [INFO] [task_scheduler.cc:121] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #571: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(112), T.int64(112), T.int64(64)), "float32"), p1: T.Buffer((T.int64(2), T.int64(2), T.int64(3), T.int64(3), T.int64(64), T.int64(64)), "float32"), p2: T.Buffer((T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(64)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(2), T.int64(112), T.int64(112), T.int64(64)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(114), T.int64(114), T.int64(64)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(112), T.int64(112), T.int64(64)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused in T.parallel(T.int64(448), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(2), T.int64(3), T.int64(30)):
                for ax4_fused in T.vectorized(T.int64(64)):
                    with T.block("data_pad"):
                        v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                        v_i2 = T.axis.spatial(T.int64(114), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(32) * T.int64(8) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(8) + ax2)
                        v_i3 = T.axis.spatial(T.int64(114), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(32) // T.int64(8) * T.int64(28) + ax3)
                        v_i4 = T.axis.spatial(T.int64(64), ax4_fused)
                        T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                        T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                        data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(113) and T.int64(1) <= v_i3 and v_i3 < T.int64(113), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(14), T.int64(64), T.int64(1), T.int64(2), T.int64(1), T.int64(2), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(2), oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(112), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(32) * T.int64(8) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(8) + oh_2_init + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(112), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(32) // T.int64(8) * T.int64(28) + ow_1 * T.int64(28) + ow_2_init * T.int64(2) + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(64), oc_block_1 * T.int64(64) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(16), T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(14), T.int64(64), T.int64(8), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(2), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(2), oc_chunk_2 * T.int64(2) + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(112), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(32) * T.int64(8) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(8) + oh_2 + oh_3)
                        v_ow = T.axis.spatial(T.int64(112), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(32) // T.int64(8) * T.int64(28) + ow_1 * T.int64(28) + ow_2 * T.int64(2) + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(64), oc_block_1 * T.int64(64) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(128), ic_0 * T.int64(8) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(64), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(64)], p1[v_oc_chunk, v_ic // T.int64(64), v_kh, v_kw, v_ic % T.int64(64), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(64), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(64)] * p1[v_oc_chunk, v_ic // T.int64(64), v_kh, v_kw, v_ic % T.int64(64), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(28)):
                    for ax4_fused in T.vectorized(T.int64(64)):
                        with T.block("T_relu"):
                            v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                            v_ax2 = T.axis.spatial(T.int64(112), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(32) * T.int64(8) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(8) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(112), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(32) // T.int64(8) * T.int64(28) + ax3)
                            v_ax4 = T.axis.spatial(T.int64(64), ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 2])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[14, 8, 1, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[4, 1, 14, 2])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 64, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[16, 8])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=7)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83 = sch.get_loops(block=b68)
l84 = sch.fuse(l71, l72, l73, l74, l75, l76, l77, l78, preserve_unit_iters=True)
sch.parallel(loop=l84)
l85 = sch.fuse(l83, preserve_unit_iters=True)
sch.vectorize(loop=l85)
l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b69)
l105 = sch.fuse(l86, preserve_unit_iters=True)
sch.parallel(loop=l105)
sch.annotate(block_or_loop=l105, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l105, ann_key="pragma_unroll_explicit", ann_val=1)
l106, l107, l108, l109, l110, l111, l112, l113 = sch.get_loops(block=b70)
l114 = sch.fuse(l113, preserve_unit_iters=True)
sch.vectorize(loop=l114)
b115 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134 = sch.get_loops(block=b115)
b135 = sch.decompose_reduction(block=b115, loop=l119)
2024-04-30 12:41:49 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #572: GFLOPs: 1114.7815. Time: 3321.3571 us. Best GFLOPs: 1470.4188
2024-04-30 12:41:49 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #573: GFLOPs: 1364.8919. Time: 2712.7331 us. Best GFLOPs: 1470.4188
2024-04-30 12:41:49 [INFO] [task_scheduler.cc:121] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #574: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(112), T.int64(112), T.int64(64)), "float32"), p1: T.Buffer((T.int64(2), T.int64(2), T.int64(3), T.int64(3), T.int64(64), T.int64(64)), "float32"), p2: T.Buffer((T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(64)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(2), T.int64(112), T.int64(112), T.int64(64)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(112), T.int64(112), T.int64(64)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused in T.parallel(T.int64(1024), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(4), T.int64(1), T.int64(1), T.int64(14), T.int64(2)):
                for oc_block_3_fused_init in T.vectorized(T.int64(2)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(2), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(512) // T.int64(256) + oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(112), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused // T.int64(512) * T.int64(56) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(256) // T.int64(64) * T.int64(14) + oh_2_init * T.int64(14) + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(112), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(64) // T.int64(8) * T.int64(14) + ow_2_init * T.int64(2) + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(64), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(8) * T.int64(8) + oc_block_2_init * T.int64(2) + oc_block_3_fused_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
            for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(32), T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(4), T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(14), T.int64(2)):
                for oc_block_3_fused in T.vectorized(T.int64(2)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(2), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(512) // T.int64(256) + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(112), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused // T.int64(512) * T.int64(56) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(256) // T.int64(64) * T.int64(14) + oh_2 * T.int64(14) + oh_3)
                        v_ow = T.axis.spatial(T.int64(112), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(64) // T.int64(8) * T.int64(14) + ow_2 * T.int64(2) + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(64), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(8) * T.int64(8) + oc_block_2 * T.int64(2) + oc_block_3_fused)
                        v_ic = T.axis.reduce(T.int64(128), ic_0 * T.int64(4) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], p0[v_n, v_ic // T.int64(64), v_oh + v_kh - T.int64(1), v_ow + v_kw - T.int64(1), v_ic % T.int64(64)], p1[v_oc_chunk, v_ic // T.int64(64), v_kh, v_kw, v_ic % T.int64(64), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + T.if_then_else(T.int64(1) <= v_oh + v_kh and v_oh + v_kh < T.int64(113) and T.int64(1) <= v_ow + v_kw and v_ow + v_kw < T.int64(113), p0[v_n, v_ic // T.int64(64), v_oh + v_kh - T.int64(1), v_ow + v_kw - T.int64(1), v_ic % T.int64(64)], T.float32(0)) * p1[v_oc_chunk, v_ic // T.int64(64), v_kh, v_kw, v_ic % T.int64(64), v_oc_block]
        for ax0_ax1_ax2_ax3_ax4_fused_0 in T.parallel(T.int64(25088)):
            for ax0_ax1_ax2_ax3_ax4_fused_1 in T.vectorized(T.int64(64)):
                with T.block("T_relu"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(2), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) // T.int64(802816))
                    v_ax2 = T.axis.spatial(T.int64(112), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(802816) // T.int64(7168))
                    v_ax3 = T.axis.spatial(T.int64(112), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(7168) // T.int64(64))
                    v_ax4 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(64))
                    T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                    T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 2, 1, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 4, 1, 14])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 8, 7, 2])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 8, 4, 2])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[32, 4])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
l65 = sch.sample_compute_location(block=b0, decision=-2)
sch.compute_at(block=b0, loop=l65, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b66 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.unroll_explicit")
b67, b68 = sch.get_child_blocks(b66)
l69, l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94 = sch.get_loops(block=b67)
l95 = sch.fuse(l69, l70, l71, l72, l73, l74, l75, l76, l77, l78, preserve_unit_iters=True)
sch.parallel(loop=l95)
l96 = sch.fuse(l94, preserve_unit_iters=True)
sch.vectorize(loop=l96)
sch.annotate(block_or_loop=l95, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l95, ann_key="pragma_unroll_explicit", ann_val=1)
l97, l98, l99, l100, l101 = sch.get_loops(block=b68)
l102 = sch.fuse(l97, l98, l99, l100, l101, preserve_unit_iters=True)
l103, l104 = sch.split(loop=l102, factors=[None, 64], preserve_unit_iters=True)
sch.parallel(loop=l103)
sch.vectorize(loop=l104)
b105 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l106, l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117, l118, l119, l120, l121, l122 = sch.get_loops(block=b105)
b123 = sch.decompose_reduction(block=b105, loop=l107)
2024-04-30 12:41:49 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #575: GFLOPs: 42.8786. Time: 86350.3950 us. Best GFLOPs: 1470.4188
2024-04-30 12:41:49 [INFO] [task_scheduler.cc:121] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #576: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(112), T.int64(112), T.int64(64)), "float32"), p1: T.Buffer((T.int64(2), T.int64(2), T.int64(3), T.int64(3), T.int64(64), T.int64(64)), "float32"), p2: T.Buffer((T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(64)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(2), T.int64(112), T.int64(112), T.int64(64)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(114), T.int64(114), T.int64(64)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(112), T.int64(112), T.int64(64)))
        for n_0_oc_chunk_0_fused_fused in T.parallel(T.int64(2), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(2), T.int64(114), T.int64(114)):
                for ax4_fused in T.vectorized(T.int64(64)):
                    with T.block("data_pad"):
                        v_i0, v_i1, v_i2, v_i3, v_i4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4_fused])
                        T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                        T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                        data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(113) and T.int64(1) <= v_i3 and v_i3 < T.int64(113), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oh_0, ow_0, oc_block_0 in T.grid(T.int64(14), T.int64(2), T.int64(16)):
                for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(8), T.int64(28), T.int64(1)):
                    for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(2), n_0_oc_chunk_0_fused_fused + oc_chunk_1 + oc_chunk_2_init + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(112), oh_0 * T.int64(8) + oh_1 + oh_2_init + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(112), ow_0 * T.int64(56) + ow_1 * T.int64(2) + ow_2_init * T.int64(2) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(64), oc_block_0 * T.int64(4) + oc_block_1 * T.int64(4) + oc_block_2_init + oc_block_3_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                    for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(2), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(64), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(2), n_0_oc_chunk_0_fused_fused + oc_chunk_1 + oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(112), oh_0 * T.int64(8) + oh_1 + oh_2 + oh_3)
                            v_ow = T.axis.spatial(T.int64(112), ow_0 * T.int64(56) + ow_1 * T.int64(2) + ow_2 * T.int64(2) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(64), oc_block_0 * T.int64(4) + oc_block_1 * T.int64(4) + oc_block_2 + oc_block_3)
                            v_ic = T.axis.reduce(T.int64(128), ic_0 * T.int64(64) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(64), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(64)], p1[v_oc_chunk, v_ic // T.int64(64), v_kh, v_kw, v_ic % T.int64(64), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(64), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(64)] * p1[v_oc_chunk, v_ic // T.int64(64), v_kh, v_kw, v_ic % T.int64(64), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(8), T.int64(56)):
                    for ax4_fused in T.vectorized(T.int64(4)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(2), n_0_oc_chunk_0_fused_fused + ax1)
                            v_ax2 = T.axis.spatial(T.int64(112), oh_0 * T.int64(8) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(112), ow_0 * T.int64(56) + ax3)
                            v_ax4 = T.axis.spatial(T.int64(64), oc_block_0 * T.int64(4) + ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[2, 1, 1, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[14, 8, 1, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[2, 28, 1, 2])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[16, 1, 4, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[2, 64])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=1)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77 = sch.get_loops(block=b68)
l78 = sch.fuse(l71, l72, preserve_unit_iters=True)
sch.parallel(loop=l78)
l79 = sch.fuse(l77, preserve_unit_iters=True)
sch.vectorize(loop=l79)
l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b69)
l105 = sch.fuse(l80, preserve_unit_iters=True)
sch.parallel(loop=l105)
sch.annotate(block_or_loop=l105, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l105, ann_key="pragma_unroll_explicit", ann_val=1)
l106, l107, l108, l109, l110, l111, l112, l113, l114 = sch.get_loops(block=b70)
l115 = sch.fuse(l114, preserve_unit_iters=True)
sch.vectorize(loop=l115)
b116 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141 = sch.get_loops(block=b116)
b142 = sch.decompose_reduction(block=b116, loop=l126)
2024-04-30 13:50:45 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-30 13:50:46 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-30 13:50:51 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x315e438)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x371f878)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3352b68)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x36bf9a8)]: 0 failure(s)
2024-04-30 13:50:51 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-30 13:51:04 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x315e438)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x371f878)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3352b68)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x36bf9a8)]: 0 failure(s)
2024-04-30 13:51:18 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x315e438)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x371f878)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3352b68)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x36bf9a8)]: 0 failure(s)
2024-04-30 13:51:33 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x315e438)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x371f878)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3352b68)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x36bf9a8)]: 0 failure(s)
2024-04-30 13:51:47 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x315e438)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x371f878)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3352b68)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x36bf9a8)]: 0 failure(s)
2024-04-30 13:51:56 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9551  0.9551  0.9539  0.9499  0.9393  0.9380  0.9376  0.9310  0.9298  0.9298  0.9271  0.9270  0.9270  0.9270  0.9267  0.9253
[17 : 32]:	0.9249  0.9242  0.9239  0.9223  0.9196  0.9189  0.9169  0.9164  0.9163  0.9117  0.9115  0.9110  0.9109  0.9105  0.9101  0.9094
[33 : 48]:	0.9070  0.9062  0.9057  0.9022  0.8996  0.8989  0.8983  0.8968  0.8962  0.8957  0.8946  0.8922  0.8880  0.8873  0.8868  0.8866
[49 : 64]:	0.8866  0.8845  0.8822  0.8819  0.8815  0.8805  0.8791  0.8777  0.8760  0.8750  0.8747  0.8722  0.8662  0.8649  0.8568  0.8558
2024-04-30 13:51:56 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-30 13:51:56 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-30 13:53:59 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #577: GFLOPs: 1374.5298. Time: 2693.7121 us. Best GFLOPs: 1470.4188
2024-04-30 13:53:59 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #578: GFLOPs: 1396.6431. Time: 2651.0619 us. Best GFLOPs: 1470.4188
2024-04-30 13:53:59 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #579: GFLOPs: 1423.4816. Time: 2601.0785 us. Best GFLOPs: 1470.4188
2024-04-30 13:53:59 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #580: GFLOPs: 1455.1512. Time: 2544.4692 us. Best GFLOPs: 1470.4188
2024-04-30 13:53:59 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #581: GFLOPs: 1297.5675. Time: 2853.4834 us. Best GFLOPs: 1470.4188
2024-04-30 13:53:59 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #582: GFLOPs: 1471.2877. Time: 2516.5624 us. Best GFLOPs: 1471.2877
2024-04-30 13:53:59 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #583: GFLOPs: 1442.6784. Time: 2566.4676 us. Best GFLOPs: 1471.2877
2024-04-30 13:53:59 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #584: GFLOPs: 1330.4135. Time: 2783.0349 us. Best GFLOPs: 1471.2877
2024-04-30 13:53:59 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #585: GFLOPs: 1379.3304. Time: 2684.3368 us. Best GFLOPs: 1471.2877
2024-04-30 13:53:59 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #586: GFLOPs: 1382.4476. Time: 2678.2841 us. Best GFLOPs: 1471.2877
2024-04-30 13:53:59 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #587: GFLOPs: 1420.0148. Time: 2607.4288 us. Best GFLOPs: 1471.2877
2024-04-30 13:53:59 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #588: GFLOPs: 949.1490. Time: 3900.9549 us. Best GFLOPs: 1471.2877
2024-04-30 13:53:59 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #589: GFLOPs: 1351.0963. Time: 2740.4318 us. Best GFLOPs: 1471.2877
2024-04-30 13:53:59 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #590: GFLOPs: 1446.1444. Time: 2560.3165 us. Best GFLOPs: 1471.2877
2024-04-30 13:53:59 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #591: GFLOPs: 1338.8027. Time: 2765.5961 us. Best GFLOPs: 1471.2877
2024-04-30 13:53:59 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #592: GFLOPs: 1377.1749. Time: 2688.5382 us. Best GFLOPs: 1471.2877
2024-04-30 13:53:59 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #593: GFLOPs: 1334.6502. Time: 2774.2005 us. Best GFLOPs: 1471.2877
2024-04-30 13:53:59 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #594: GFLOPs: 1423.8778. Time: 2600.3548 us. Best GFLOPs: 1471.2877
2024-04-30 13:53:59 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #595: GFLOPs: 1397.9561. Time: 2648.5720 us. Best GFLOPs: 1471.2877
2024-04-30 13:53:59 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #596: GFLOPs: 1397.9839. Time: 2648.5193 us. Best GFLOPs: 1471.2877
2024-04-30 13:53:59 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #597: GFLOPs: 734.3773. Time: 5041.8050 us. Best GFLOPs: 1471.2877
2024-04-30 13:53:59 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #598: GFLOPs: 1372.6488. Time: 2697.4033 us. Best GFLOPs: 1471.2877
2024-04-30 13:53:59 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #599: GFLOPs: 1333.0724. Time: 2777.4840 us. Best GFLOPs: 1471.2877
2024-04-30 13:53:59 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #600: GFLOPs: 1426.5420. Time: 2595.4984 us. Best GFLOPs: 1471.2877
2024-04-30 13:53:59 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #601: GFLOPs: 1459.4508. Time: 2536.9730 us. Best GFLOPs: 1471.2877
2024-04-30 13:53:59 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #602: GFLOPs: 1214.5908. Time: 3048.4238 us. Best GFLOPs: 1471.2877
2024-04-30 13:53:59 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #603: GFLOPs: 1414.2857. Time: 2617.9910 us. Best GFLOPs: 1471.2877
2024-04-30 13:53:59 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #604: GFLOPs: 1248.2838. Time: 2966.1423 us. Best GFLOPs: 1471.2877
2024-04-30 13:53:59 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #605: GFLOPs: 1375.0853. Time: 2692.6238 us. Best GFLOPs: 1471.2877
2024-04-30 13:53:59 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #606: GFLOPs: 1417.6789. Time: 2611.7250 us. Best GFLOPs: 1471.2877
2024-04-30 13:53:59 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #607: GFLOPs: 1305.8606. Time: 2835.3619 us. Best GFLOPs: 1471.2877
2024-04-30 13:53:59 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #608: GFLOPs: 1195.6434. Time: 3096.7322 us. Best GFLOPs: 1471.2877
2024-04-30 13:53:59 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #609: GFLOPs: 1327.3625. Time: 2789.4320 us. Best GFLOPs: 1471.2877
2024-04-30 13:53:59 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #610: GFLOPs: 1309.6485. Time: 2827.1612 us. Best GFLOPs: 1471.2877
2024-04-30 13:53:59 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #611: GFLOPs: 1308.8835. Time: 2828.8135 us. Best GFLOPs: 1471.2877
2024-04-30 13:53:59 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #612: GFLOPs: 1397.7134. Time: 2649.0320 us. Best GFLOPs: 1471.2877
2024-04-30 13:53:59 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #613: GFLOPs: 1445.3053. Time: 2561.8030 us. Best GFLOPs: 1471.2877
2024-04-30 13:53:59 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #614: GFLOPs: 1338.4308. Time: 2766.3645 us. Best GFLOPs: 1471.2877
2024-04-30 13:53:59 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #615: GFLOPs: 1300.3442. Time: 2847.3902 us. Best GFLOPs: 1471.2877
2024-04-30 13:53:59 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #616: GFLOPs: 835.7552. Time: 4430.2295 us. Best GFLOPs: 1471.2877
2024-04-30 13:53:59 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #617: GFLOPs: 1378.3830. Time: 2686.1818 us. Best GFLOPs: 1471.2877
2024-04-30 13:53:59 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #618: GFLOPs: 1319.5415. Time: 2805.9651 us. Best GFLOPs: 1471.2877
2024-04-30 13:53:59 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #619: GFLOPs: 1422.4604. Time: 2602.9459 us. Best GFLOPs: 1471.2877
2024-04-30 13:53:59 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #620: GFLOPs: 1331.0139. Time: 2781.7797 us. Best GFLOPs: 1471.2877
2024-04-30 13:53:59 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #621: GFLOPs: 1340.8379. Time: 2761.3982 us. Best GFLOPs: 1471.2877
2024-04-30 13:53:59 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #622: GFLOPs: 1327.7724. Time: 2788.5709 us. Best GFLOPs: 1471.2877
2024-04-30 13:53:59 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #623: GFLOPs: 1342.4425. Time: 2758.0975 us. Best GFLOPs: 1471.2877
2024-04-30 13:53:59 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #624: GFLOPs: 1354.3334. Time: 2733.8817 us. Best GFLOPs: 1471.2877
2024-04-30 13:53:59 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #625: GFLOPs: 1343.0895. Time: 2756.7689 us. Best GFLOPs: 1471.2877
2024-04-30 13:53:59 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #626: GFLOPs: 1321.9411. Time: 2800.8716 us. Best GFLOPs: 1471.2877
2024-04-30 13:53:59 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #627: GFLOPs: 1283.1835. Time: 2885.4700 us. Best GFLOPs: 1471.2877
2024-04-30 13:53:59 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #628: GFLOPs: 1297.7310. Time: 2853.1239 us. Best GFLOPs: 1471.2877
2024-04-30 13:53:59 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #629: GFLOPs: 1340.8846. Time: 2761.3019 us. Best GFLOPs: 1471.2877
2024-04-30 13:53:59 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #630: GFLOPs: 1328.6335. Time: 2786.7636 us. Best GFLOPs: 1471.2877
2024-04-30 13:53:59 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #631: GFLOPs: 1319.4733. Time: 2806.1101 us. Best GFLOPs: 1471.2877
2024-04-30 13:53:59 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #632: GFLOPs: 1326.2514. Time: 2791.7690 us. Best GFLOPs: 1471.2877
2024-04-30 13:53:59 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #633: GFLOPs: 1332.8260. Time: 2777.9976 us. Best GFLOPs: 1471.2877
2024-04-30 13:53:59 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #634: GFLOPs: 1442.2636. Time: 2567.2058 us. Best GFLOPs: 1471.2877
2024-04-30 13:53:59 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #635: GFLOPs: 1430.9003. Time: 2587.5928 us. Best GFLOPs: 1471.2877
2024-04-30 13:53:59 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #636: GFLOPs: 1270.0899. Time: 2915.2169 us. Best GFLOPs: 1471.2877
2024-04-30 13:53:59 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #637: GFLOPs: 1259.8349. Time: 2938.9464 us. Best GFLOPs: 1471.2877
2024-04-30 13:53:59 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #638: GFLOPs: 6.2280. Time: 594503.1533 us. Best GFLOPs: 1471.2877
2024-04-30 13:53:59 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #639: GFLOPs: 85.2573. Time: 43428.4063 us. Best GFLOPs: 1471.2877
2024-04-30 13:53:59 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #640: GFLOPs: 86.4585. Time: 42825.0130 us. Best GFLOPs: 1471.2877
2024-04-30 14:15:34 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-30 14:15:36 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-30 14:15:40 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x315e438)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x371f878)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3352b68)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x36bf9a8)]: 0 failure(s)
2024-04-30 14:15:40 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-30 14:15:54 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x315e438)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x371f878)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3352b68)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x36bf9a8)]: 0 failure(s)
2024-04-30 14:16:09 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x315e438)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x371f878)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3352b68)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x36bf9a8)]: 0 failure(s)
2024-04-30 14:16:23 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x315e438)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x371f878)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3352b68)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x36bf9a8)]: 0 failure(s)
2024-04-30 14:16:38 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x315e438)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x371f878)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3352b68)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x36bf9a8)]: 0 failure(s)
2024-04-30 14:16:47 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9635  0.9557  0.9518  0.9506  0.9502  0.9497  0.9480  0.9478  0.9463  0.9411  0.9393  0.9392  0.9375  0.9341  0.9316  0.9294
[17 : 32]:	0.9289  0.9257  0.9231  0.9221  0.9221  0.9213  0.9213  0.9206  0.9165  0.9159  0.9111  0.9108  0.9100  0.9089  0.9074  0.9063
[33 : 48]:	0.9063  0.9040  0.9021  0.9021  0.9008  0.8992  0.8992  0.8989  0.8989  0.8986  0.8982  0.8967  0.8965  0.8958  0.8948  0.8946
[49 : 64]:	0.8945  0.8942  0.8940  0.8937  0.8935  0.8918  0.8907  0.8897  0.8854  0.8806  0.8750  0.8710  0.8674  0.8666  0.8665  0.8655
2024-04-30 14:16:48 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-30 14:16:48 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-30 14:18:37 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #641: GFLOPs: 733.7876. Time: 5045.8571 us. Best GFLOPs: 1471.2877
2024-04-30 14:18:37 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #642: GFLOPs: 1429.1332. Time: 2590.7923 us. Best GFLOPs: 1471.2877
2024-04-30 14:18:37 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #643: GFLOPs: 1447.5383. Time: 2557.8511 us. Best GFLOPs: 1471.2877
2024-04-30 14:18:37 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #644: GFLOPs: 1439.1791. Time: 2572.7079 us. Best GFLOPs: 1471.2877
2024-04-30 14:18:37 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #645: GFLOPs: 1191.4570. Time: 3107.6130 us. Best GFLOPs: 1471.2877
2024-04-30 14:18:37 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #646: GFLOPs: 1411.0554. Time: 2623.9843 us. Best GFLOPs: 1471.2877
2024-04-30 14:18:37 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #647: GFLOPs: 1406.7936. Time: 2631.9337 us. Best GFLOPs: 1471.2877
2024-04-30 14:18:37 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #648: GFLOPs: 1400.8279. Time: 2643.1422 us. Best GFLOPs: 1471.2877
2024-04-30 14:18:37 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #649: GFLOPs: 1442.3011. Time: 2567.1390 us. Best GFLOPs: 1471.2877
2024-04-30 14:18:37 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #650: GFLOPs: 1429.5889. Time: 2589.9665 us. Best GFLOPs: 1471.2877
2024-04-30 14:18:37 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #651: GFLOPs: 1376.5125. Time: 2689.8320 us. Best GFLOPs: 1471.2877
2024-04-30 14:18:37 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #652: GFLOPs: 1430.6984. Time: 2587.9580 us. Best GFLOPs: 1471.2877
2024-04-30 14:18:37 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #653: GFLOPs: 1355.5924. Time: 2731.3426 us. Best GFLOPs: 1471.2877
2024-04-30 14:18:37 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #654: GFLOPs: 1466.9516. Time: 2524.0011 us. Best GFLOPs: 1471.2877
2024-04-30 14:18:37 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #655: GFLOPs: 1357.3285. Time: 2727.8492 us. Best GFLOPs: 1471.2877
2024-04-30 14:18:37 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #656: GFLOPs: 1346.0212. Time: 2750.7646 us. Best GFLOPs: 1471.2877
2024-04-30 14:18:37 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #657: GFLOPs: 1383.6117. Time: 2676.0307 us. Best GFLOPs: 1471.2877
2024-04-30 14:18:37 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #658: GFLOPs: 1352.7386. Time: 2737.1049 us. Best GFLOPs: 1471.2877
2024-04-30 14:18:37 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #659: GFLOPs: 1343.3692. Time: 2756.1949 us. Best GFLOPs: 1471.2877
2024-04-30 14:18:37 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #660: GFLOPs: 1396.8922. Time: 2650.5892 us. Best GFLOPs: 1471.2877
2024-04-30 14:18:37 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #661: GFLOPs: 1401.0161. Time: 2642.7872 us. Best GFLOPs: 1471.2877
2024-04-30 14:18:37 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #662: GFLOPs: 1350.3224. Time: 2742.0025 us. Best GFLOPs: 1471.2877
2024-04-30 14:18:37 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #663: GFLOPs: 1367.3026. Time: 2707.9503 us. Best GFLOPs: 1471.2877
2024-04-30 14:18:37 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #664: GFLOPs: 1393.9794. Time: 2656.1277 us. Best GFLOPs: 1471.2877
2024-04-30 14:18:37 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #665: GFLOPs: 1330.8145. Time: 2782.1964 us. Best GFLOPs: 1471.2877
2024-04-30 14:18:37 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #666: GFLOPs: 1322.7123. Time: 2799.2386 us. Best GFLOPs: 1471.2877
2024-04-30 14:18:37 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #667: GFLOPs: 1370.3030. Time: 2702.0209 us. Best GFLOPs: 1471.2877
2024-04-30 14:18:37 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #668: GFLOPs: 1345.8654. Time: 2751.0829 us. Best GFLOPs: 1471.2877
2024-04-30 14:18:37 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #669: GFLOPs: 1328.0815. Time: 2787.9218 us. Best GFLOPs: 1471.2877
2024-04-30 14:18:37 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #670: GFLOPs: 1319.6088. Time: 2805.8221 us. Best GFLOPs: 1471.2877
2024-04-30 14:18:37 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #671: GFLOPs: 1338.3104. Time: 2766.6132 us. Best GFLOPs: 1471.2877
2024-04-30 14:18:37 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #672: GFLOPs: 1322.4447. Time: 2799.8050 us. Best GFLOPs: 1471.2877
2024-04-30 14:18:37 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #673: GFLOPs: 1329.7938. Time: 2784.3320 us. Best GFLOPs: 1471.2877
2024-04-30 14:18:37 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #674: GFLOPs: 1328.3233. Time: 2787.4143 us. Best GFLOPs: 1471.2877
2024-04-30 14:18:37 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #675: GFLOPs: 1329.9131. Time: 2784.0823 us. Best GFLOPs: 1471.2877
2024-04-30 14:18:37 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #676: GFLOPs: 1312.2217. Time: 2821.6174 us. Best GFLOPs: 1471.2877
2024-04-30 14:18:37 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #677: GFLOPs: 1393.3117. Time: 2657.4007 us. Best GFLOPs: 1471.2877
2024-04-30 14:18:37 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #678: GFLOPs: 1333.3077. Time: 2776.9940 us. Best GFLOPs: 1471.2877
2024-04-30 14:18:37 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #679: GFLOPs: 1327.8802. Time: 2788.3445 us. Best GFLOPs: 1471.2877
2024-04-30 14:18:37 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #680: GFLOPs: 1315.9789. Time: 2813.5614 us. Best GFLOPs: 1471.2877
2024-04-30 14:18:37 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #681: GFLOPs: 1383.0810. Time: 2677.0576 us. Best GFLOPs: 1471.2877
2024-04-30 14:18:37 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #682: GFLOPs: 1300.5666. Time: 2846.9034 us. Best GFLOPs: 1471.2877
2024-04-30 14:18:37 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #683: GFLOPs: 1275.6286. Time: 2902.5590 us. Best GFLOPs: 1471.2877
2024-04-30 14:18:37 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #684: GFLOPs: 1287.7697. Time: 2875.1937 us. Best GFLOPs: 1471.2877
2024-04-30 14:18:37 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #685: GFLOPs: 1337.8526. Time: 2767.5600 us. Best GFLOPs: 1471.2877
2024-04-30 14:18:37 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #686: GFLOPs: 1328.2951. Time: 2787.4734 us. Best GFLOPs: 1471.2877
2024-04-30 14:18:37 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #687: GFLOPs: 1292.2655. Time: 2865.1909 us. Best GFLOPs: 1471.2877
2024-04-30 14:18:37 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #688: GFLOPs: 1369.5867. Time: 2703.4340 us. Best GFLOPs: 1471.2877
2024-04-30 14:18:37 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #689: GFLOPs: 1387.0661. Time: 2669.3663 us. Best GFLOPs: 1471.2877
2024-04-30 14:18:37 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #690: GFLOPs: 1332.9573. Time: 2777.7239 us. Best GFLOPs: 1471.2877
2024-04-30 14:18:37 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #691: GFLOPs: 1296.5019. Time: 2855.8288 us. Best GFLOPs: 1471.2877
2024-04-30 14:18:37 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #692: GFLOPs: 1430.0445. Time: 2589.1414 us. Best GFLOPs: 1471.2877
2024-04-30 14:18:37 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #693: GFLOPs: 789.0378. Time: 4692.5350 us. Best GFLOPs: 1471.2877
2024-04-30 14:18:37 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #694: GFLOPs: 1319.3893. Time: 2806.2887 us. Best GFLOPs: 1471.2877
2024-04-30 14:18:37 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #695: GFLOPs: 1007.0669. Time: 3676.6053 us. Best GFLOPs: 1471.2877
2024-04-30 14:18:37 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #696: GFLOPs: 1362.2204. Time: 2718.0532 us. Best GFLOPs: 1471.2877
2024-04-30 14:18:37 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #697: GFLOPs: 1256.7461. Time: 2946.1697 us. Best GFLOPs: 1471.2877
2024-04-30 14:18:37 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #698: GFLOPs: 1316.3368. Time: 2812.7964 us. Best GFLOPs: 1471.2877
2024-04-30 14:18:37 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #699: GFLOPs: 1427.5303. Time: 2593.7015 us. Best GFLOPs: 1471.2877
2024-04-30 14:18:37 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #700: GFLOPs: 1235.8772. Time: 2995.9186 us. Best GFLOPs: 1471.2877
2024-04-30 14:18:37 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #701: GFLOPs: 1251.9257. Time: 2957.5137 us. Best GFLOPs: 1471.2877
2024-04-30 14:18:37 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #702: GFLOPs: 23.9491. Time: 154602.0747 us. Best GFLOPs: 1471.2877
2024-04-30 14:18:37 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #703: GFLOPs: 63.3902. Time: 58409.4297 us. Best GFLOPs: 1471.2877
2024-04-30 14:18:37 [INFO] [task_scheduler.cc:131] [Task #6: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3] Trial #704: GFLOPs: 16.2199. Time: 228274.7437 us. Best GFLOPs: 1471.2877
