2024-04-28 20:37:55 [INFO] [task_scheduler.cc:160] Initializing Task #26: "fused_nn_contrib_conv2d_NCHWc_add_add_4"
2024-04-28 20:37:55 [INFO] [task_scheduler.cc:35] 
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(240), T.int64(7), T.int64(7), T.int64(4)), "float32"), p1: T.Buffer((T.int64(40), T.int64(240), T.int64(1), T.int64(1), T.int64(4), T.int64(4)), "float32"), p2: T.Buffer((T.int64(1), T.int64(40), T.int64(1), T.int64(1), T.int64(4)), "float32"), p3: T.Buffer((T.int64(1), T.int64(40), T.int64(7), T.int64(7), T.int64(4)), "float32"), T_add: T.Buffer((T.int64(1), T.int64(40), T.int64(7), T.int64(7), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(40), T.int64(7), T.int64(7), T.int64(4)))
        T_add_1 = T.alloc_buffer((T.int64(1), T.int64(40), T.int64(7), T.int64(7), T.int64(4)))
        for n, oc_chunk, oh, ow, oc_block, ic, kh, kw in T.grid(T.int64(1), T.int64(40), T.int64(7), T.int64(7), T.int64(4), T.int64(960), T.int64(1), T.int64(1)):
            with T.block("conv2d_NCHWc"):
                v_n, v_oc_chunk, v_oh, v_ow, v_oc_block, v_ic, v_kh, v_kw = T.axis.remap("SSSSSRRR", [n, oc_chunk, oh, ow, oc_block, ic, kh, kw])
                T.reads(p0[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)], p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block])
                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                with T.init():
                    conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + p0[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)] * p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block]
        for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(40), T.int64(7), T.int64(7), T.int64(4)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                T.writes(T_add_1[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T_add_1[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4]
        for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(40), T.int64(7), T.int64(7), T.int64(4)):
            with T.block("T_add_1"):
                v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                T.reads(p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T_add_1[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T.writes(T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + T_add_1[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4]
2024-04-28 20:37:55 [INFO] [task_scheduler.cc:164] Total 3 design space(s) generated
2024-04-28 20:37:55 [INFO] [task_scheduler.cc:170] Design space #0:
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(240), T.int64(7), T.int64(7), T.int64(4)), "float32"), p1: T.Buffer((T.int64(40), T.int64(240), T.int64(1), T.int64(1), T.int64(4), T.int64(4)), "float32"), p2: T.Buffer((T.int64(1), T.int64(40), T.int64(1), T.int64(1), T.int64(4)), "float32"), p3: T.Buffer((T.int64(1), T.int64(40), T.int64(7), T.int64(7), T.int64(4)), "float32"), T_add: T.Buffer((T.int64(1), T.int64(40), T.int64(7), T.int64(7), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel": 768, "meta_schedule.unroll_explicit": 16, "meta_schedule.vectorize": 64})
            conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(40), T.int64(7), T.int64(7), T.int64(4)))
            for n_0, oc_chunk_0, oh_0, ow_0, oc_block_0, n_1, oc_chunk_1, oh_1, ow_1, oc_block_1, ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(4), T.int64(24), T.int64(1), T.int64(1), T.int64(1), T.int64(8), T.int64(7), T.int64(1), T.int64(1), T.int64(40), T.int64(1), T.int64(1), T.int64(1), T.int64(5), T.int64(1), T.int64(1), T.int64(1)):
                with T.block("conv2d_NCHWc"):
                    v_n = T.axis.spatial(T.int64(1), n_0 + n_1 + n_2 + n_3)
                    v_oc_chunk = T.axis.spatial(T.int64(40), oc_chunk_0 * T.int64(40) + oc_chunk_1 * T.int64(40) + oc_chunk_2 * T.int64(5) + oc_chunk_3)
                    v_oh = T.axis.spatial(T.int64(7), oh_0 * T.int64(7) + oh_1 * T.int64(7) + oh_2 + oh_3)
                    v_ow = T.axis.spatial(T.int64(7), ow_0 * T.int64(7) + ow_1 + ow_2 + ow_3)
                    v_oc_block = T.axis.spatial(T.int64(4), oc_block_0 * T.int64(4) + oc_block_1 + oc_block_2 + oc_block_3)
                    v_ic = T.axis.reduce(T.int64(960), ic_0 * T.int64(40) + ic_1)
                    v_kh = T.axis.reduce(T.int64(1), kh_0 + kh_1)
                    v_kw = T.axis.reduce(T.int64(1), kw_0 + kw_1)
                    T.reads(p0[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)], p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block])
                    T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                    T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                    with T.init():
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                    conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + p0[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)] * p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block]
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(40), T.int64(7), T.int64(7), T.int64(4)):
                with T.block("T_add_1"):
                    v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                    T.reads(p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                    T.writes(T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + (conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
b0 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b1 = sch.get_block(name="T_add", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l3, l4, l5, l6, l7, l8, l9, l10 = sch.get_loops(block=b0)
v11, v12, v13, v14 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l15, l16, l17, l18 = sch.split(loop=l3, factors=[v11, v12, v13, v14], preserve_unit_iters=True)
v19, v20, v21, v22 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 8, 5])
l23, l24, l25, l26 = sch.split(loop=l4, factors=[v19, v20, v21, v22], preserve_unit_iters=True)
v27, v28, v29, v30 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 7, 1])
l31, l32, l33, l34 = sch.split(loop=l5, factors=[v27, v28, v29, v30], preserve_unit_iters=True)
v35, v36, v37, v38 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 7, 1, 1])
l39, l40, l41, l42 = sch.split(loop=l6, factors=[v35, v36, v37, v38], preserve_unit_iters=True)
v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 4, 1, 1])
l47, l48, l49, l50 = sch.split(loop=l7, factors=[v43, v44, v45, v46], preserve_unit_iters=True)
v51, v52 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[24, 40])
l53, l54 = sch.split(loop=l8, factors=[v51, v52], preserve_unit_iters=True)
v55, v56 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[1, 1])
l57, l58 = sch.split(loop=l9, factors=[v55, v56], preserve_unit_iters=True)
v59, v60 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 1])
l61, l62 = sch.split(loop=l10, factors=[v59, v60], preserve_unit_iters=True)
sch.reorder(l15, l23, l31, l39, l47, l16, l24, l32, l40, l48, l53, l57, l61, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.vectorize", ann_val=64)
v63 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v63)
2024-04-28 20:37:55 [INFO] [task_scheduler.cc:170] Design space #1:
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(240), T.int64(7), T.int64(7), T.int64(4)), "float32"), p1: T.Buffer((T.int64(40), T.int64(240), T.int64(1), T.int64(1), T.int64(4), T.int64(4)), "float32"), p2: T.Buffer((T.int64(1), T.int64(40), T.int64(1), T.int64(1), T.int64(4)), "float32"), p3: T.Buffer((T.int64(1), T.int64(40), T.int64(7), T.int64(7), T.int64(4)), "float32"), T_add: T.Buffer((T.int64(1), T.int64(40), T.int64(7), T.int64(7), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel": 768, "meta_schedule.unroll_explicit": 64, "meta_schedule.vectorize": 64})
            conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(40), T.int64(7), T.int64(7), T.int64(4)))
            for n_0, oc_chunk_0, oh_0, ow_0, oc_block_0, n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(4)):
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(24), T.int64(1), T.int64(1), T.int64(1), T.int64(8), T.int64(7), T.int64(1), T.int64(1), T.int64(40), T.int64(1), T.int64(1), T.int64(1), T.int64(5), T.int64(1), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc"):
                        v_n = T.axis.spatial(T.int64(1), n_0 + n_1 + n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(40), oc_chunk_0 * T.int64(40) + oc_chunk_1 * T.int64(40) + oc_chunk_2 * T.int64(5) + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(7), oh_0 * T.int64(7) + oh_1 * T.int64(7) + oh_2 + oh_3)
                        v_ow = T.axis.spatial(T.int64(7), ow_0 * T.int64(7) + ow_1 + ow_2 + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(4), oc_block_0 * T.int64(4) + oc_block_1 + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(960), ic_0 * T.int64(40) + ic_1)
                        v_kh = T.axis.reduce(T.int64(1), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(1), kw_0 + kw_1)
                        T.reads(p0[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)], p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        with T.init():
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + p0[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)] * p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block]
                for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(40), T.int64(7), T.int64(1), T.int64(1)):
                    with T.block("T_add_1"):
                        v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                        v_ax3 = T.axis.spatial(T.int64(7), ow_1 + ax3)
                        v_ax4 = T.axis.spatial(T.int64(4), oc_block_1 + ax4)
                        T.reads(p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + (conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
b0 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b1 = sch.get_block(name="T_add", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l3, l4, l5, l6, l7, l8, l9, l10 = sch.get_loops(block=b0)
v11, v12, v13, v14 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l15, l16, l17, l18 = sch.split(loop=l3, factors=[v11, v12, v13, v14], preserve_unit_iters=True)
v19, v20, v21, v22 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 8, 5])
l23, l24, l25, l26 = sch.split(loop=l4, factors=[v19, v20, v21, v22], preserve_unit_iters=True)
v27, v28, v29, v30 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 7, 1])
l31, l32, l33, l34 = sch.split(loop=l5, factors=[v27, v28, v29, v30], preserve_unit_iters=True)
v35, v36, v37, v38 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 7, 1, 1])
l39, l40, l41, l42 = sch.split(loop=l6, factors=[v35, v36, v37, v38], preserve_unit_iters=True)
v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 4, 1, 1])
l47, l48, l49, l50 = sch.split(loop=l7, factors=[v43, v44, v45, v46], preserve_unit_iters=True)
v51, v52 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[24, 40])
l53, l54 = sch.split(loop=l8, factors=[v51, v52], preserve_unit_iters=True)
v55, v56 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[1, 1])
l57, l58 = sch.split(loop=l9, factors=[v55, v56], preserve_unit_iters=True)
v59, v60 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 1])
l61, l62 = sch.split(loop=l10, factors=[v59, v60], preserve_unit_iters=True)
sch.reorder(l15, l23, l31, l39, l47, l16, l24, l32, l40, l48, l53, l57, l61, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50)
b63, = sch.get_consumers(block=b0)
sch.reverse_compute_at(block=b63, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
2024-04-28 20:37:55 [INFO] [task_scheduler.cc:170] Design space #2:
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(240), T.int64(7), T.int64(7), T.int64(4)), "float32"), p1: T.Buffer((T.int64(40), T.int64(240), T.int64(1), T.int64(1), T.int64(4), T.int64(4)), "float32"), p2: T.Buffer((T.int64(1), T.int64(40), T.int64(1), T.int64(1), T.int64(4)), "float32"), p3: T.Buffer((T.int64(1), T.int64(40), T.int64(7), T.int64(7), T.int64(4)), "float32"), T_add: T.Buffer((T.int64(1), T.int64(40), T.int64(7), T.int64(7), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel": 768, "meta_schedule.unroll_explicit": 0, "meta_schedule.vectorize": 64})
            conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(40), T.int64(7), T.int64(7), T.int64(4)))
            for n_0, oc_chunk_0, oh_0, ow_0, oc_block_0 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1, ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(4), T.int64(24), T.int64(1), T.int64(1), T.int64(1), T.int64(8), T.int64(7), T.int64(1), T.int64(1), T.int64(40), T.int64(1), T.int64(1), T.int64(1), T.int64(5), T.int64(1), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc"):
                        v_n = T.axis.spatial(T.int64(1), n_0 + n_1 + n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(40), oc_chunk_0 * T.int64(40) + oc_chunk_1 * T.int64(40) + oc_chunk_2 * T.int64(5) + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(7), oh_0 * T.int64(7) + oh_1 * T.int64(7) + oh_2 + oh_3)
                        v_ow = T.axis.spatial(T.int64(7), ow_0 * T.int64(7) + ow_1 + ow_2 + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(4), oc_block_0 * T.int64(4) + oc_block_1 + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(960), ic_0 * T.int64(40) + ic_1)
                        v_kh = T.axis.reduce(T.int64(1), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(1), kw_0 + kw_1)
                        T.reads(p0[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)], p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        with T.init():
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + p0[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)] * p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block]
                for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(40), T.int64(7), T.int64(7), T.int64(4)):
                    with T.block("T_add_1"):
                        v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                        T.reads(p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + (conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
b0 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b1 = sch.get_block(name="T_add", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l3, l4, l5, l6, l7, l8, l9, l10 = sch.get_loops(block=b0)
v11, v12, v13, v14 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l15, l16, l17, l18 = sch.split(loop=l3, factors=[v11, v12, v13, v14], preserve_unit_iters=True)
v19, v20, v21, v22 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 8, 5])
l23, l24, l25, l26 = sch.split(loop=l4, factors=[v19, v20, v21, v22], preserve_unit_iters=True)
v27, v28, v29, v30 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 7, 1])
l31, l32, l33, l34 = sch.split(loop=l5, factors=[v27, v28, v29, v30], preserve_unit_iters=True)
v35, v36, v37, v38 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 7, 1, 1])
l39, l40, l41, l42 = sch.split(loop=l6, factors=[v35, v36, v37, v38], preserve_unit_iters=True)
v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 4, 1, 1])
l47, l48, l49, l50 = sch.split(loop=l7, factors=[v43, v44, v45, v46], preserve_unit_iters=True)
v51, v52 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[24, 40])
l53, l54 = sch.split(loop=l8, factors=[v51, v52], preserve_unit_iters=True)
v55, v56 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[1, 1])
l57, l58 = sch.split(loop=l9, factors=[v55, v56], preserve_unit_iters=True)
v59, v60 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 1])
l61, l62 = sch.split(loop=l10, factors=[v59, v60], preserve_unit_iters=True)
sch.reorder(l15, l23, l31, l39, l47, l16, l24, l32, l40, l48, l53, l57, l61, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50)
b63, = sch.get_consumers(block=b0)
sch.reverse_compute_at(block=b63, loop=l47, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
2024-04-28 21:20:48 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-28 21:20:48 [INFO] [evolutionary_search.cc:715] Picked top 0 candidate(s) from database
2024-04-28 21:20:50 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x38cb4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x529d4d8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x59926a8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x48ec1a8)]: 0 failure(s)
2024-04-28 21:20:50 [INFO] [evolutionary_search.cc:723] Sampled 512 candidate(s)
2024-04-28 21:20:53 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x38cb4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x529d4d8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x59926a8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x48ec1a8)]: 0 failure(s)
2024-04-28 21:20:56 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x38cb4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x529d4d8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x59926a8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x48ec1a8)]: 0 failure(s)
2024-04-28 21:20:59 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x38cb4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x529d4d8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x59926a8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x48ec1a8)]: 0 failure(s)
2024-04-28 21:21:03 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x38cb4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x529d4d8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x59926a8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x48ec1a8)]: 0 failure(s)
2024-04-28 21:21:04 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9997  0.9993  0.9989  0.9988  0.9981  0.9981  0.9978  0.9977  0.9976  0.9972  0.9970  0.9956  0.9952  0.9951  0.9948  0.9947
[17 : 32]:	0.9945  0.9945  0.9939  0.9936  0.9913  0.9912  0.9908  0.9907  0.9907  0.9906  0.9901  0.9877  0.9868  0.9852  0.9848  0.9845
[33 : 48]:	0.9844  0.9842  0.9839  0.9832  0.9830  0.9827  0.9823  0.9820  0.9816  0.9816  0.9812  0.9807  0.9804  0.9797  0.9796  0.9795
[49 : 64]:	0.9794  0.9790  0.9790  0.9788  0.9781  0.9776  0.9775  0.9773  0.9771  0.9766  0.9758  0.9757  0.9757  0.9754  0.9749  0.9748
2024-04-28 21:21:04 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-28 21:21:04 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-28 21:34:23 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #1: GFLOPs: 52.1991. Time: 288.6733 us. Best GFLOPs: 52.1991
2024-04-28 21:34:23 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #2: GFLOPs: 78.5144. Time: 191.9199 us. Best GFLOPs: 78.5144
2024-04-28 21:34:23 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #3: GFLOPs: 61.5267. Time: 244.9097 us. Best GFLOPs: 78.5144
2024-04-28 21:34:23 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #4: GFLOPs: 9.0312. Time: 1668.4855 us. Best GFLOPs: 78.5144
2024-04-28 21:34:23 [INFO] [task_scheduler.cc:121] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #5: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(240), T.int64(7), T.int64(7), T.int64(4)), "float32"), p1: T.Buffer((T.int64(40), T.int64(240), T.int64(1), T.int64(1), T.int64(4), T.int64(4)), "float32"), p2: T.Buffer((T.int64(1), T.int64(40), T.int64(1), T.int64(1), T.int64(4)), "float32"), p3: T.Buffer((T.int64(1), T.int64(40), T.int64(7), T.int64(7), T.int64(4)), "float32"), T_add: T.Buffer((T.int64(1), T.int64(40), T.int64(7), T.int64(7), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(40), T.int64(7), T.int64(7), T.int64(4)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused in T.parallel(T.int64(8), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(5), T.int64(1), T.int64(1), T.int64(2)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(2), T.int64(7), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(40), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused // T.int64(2) * T.int64(10) + oc_chunk_1 * T.int64(2) + oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(7), oh_1 * T.int64(7) + oh_2_init + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(7), ow_1 * T.int64(7) + ow_2_init * T.int64(7) + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(4), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused % T.int64(2) * T.int64(2) + oc_block_1 + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(96), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(7), T.int64(1), T.int64(1), T.int64(10), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(40), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused // T.int64(2) * T.int64(10) + oc_chunk_1 * T.int64(2) + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(7), oh_1 * T.int64(7) + oh_2 + oh_3)
                        v_ow = T.axis.spatial(T.int64(7), ow_1 * T.int64(7) + ow_2 * T.int64(7) + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(4), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused % T.int64(2) * T.int64(2) + oc_block_1 + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(960), ic_0 * T.int64(10) + ic_1)
                        v_kh = T.axis.reduce(T.int64(1), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(1), kw_0 + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], p0[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)], p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + p0[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)] * p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(10), T.int64(7), T.int64(7)):
                for ax4_fused in T.vectorized(T.int64(2)):
                    with T.block("T_add_1"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(40), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused // T.int64(2) * T.int64(10) + ax1)
                        v_ax2, v_ax3 = T.axis.remap("SS", [ax2, ax3])
                        v_ax4 = T.axis.spatial(T.int64(4), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused % T.int64(2) * T.int64(2) + ax4_fused)
                        T.reads(p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + (conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
b0 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b1 = sch.get_block(name="T_add", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l3, l4, l5, l6, l7, l8, l9, l10 = sch.get_loops(block=b0)
v11, v12, v13, v14 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l15, l16, l17, l18 = sch.split(loop=l3, factors=[v11, v12, v13, v14], preserve_unit_iters=True)
v19, v20, v21, v22 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[4, 5, 2, 1])
l23, l24, l25, l26 = sch.split(loop=l4, factors=[v19, v20, v21, v22], preserve_unit_iters=True)
v27, v28, v29, v30 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 7, 1])
l31, l32, l33, l34 = sch.split(loop=l5, factors=[v27, v28, v29, v30], preserve_unit_iters=True)
v35, v36, v37, v38 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 1, 7])
l39, l40, l41, l42 = sch.split(loop=l6, factors=[v35, v36, v37, v38], preserve_unit_iters=True)
v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[2, 2, 1, 1])
l47, l48, l49, l50 = sch.split(loop=l7, factors=[v43, v44, v45, v46], preserve_unit_iters=True)
v51, v52 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[96, 10])
l53, l54 = sch.split(loop=l8, factors=[v51, v52], preserve_unit_iters=True)
v55, v56 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[1, 1])
l57, l58 = sch.split(loop=l9, factors=[v55, v56], preserve_unit_iters=True)
v59, v60 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 1])
l61, l62 = sch.split(loop=l10, factors=[v59, v60], preserve_unit_iters=True)
sch.reorder(l15, l23, l31, l39, l47, l16, l24, l32, l40, l48, l53, l57, l61, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50)
b63, = sch.get_consumers(block=b0)
sch.reverse_compute_at(block=b63, loop=l47, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
sch.enter_postproc()
b65 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b65, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b65, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b65, ann_key="meta_schedule.unroll_explicit")
b66, b67 = sch.get_child_blocks(b65)
l68, l69, l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93 = sch.get_loops(block=b66)
l94 = sch.fuse(l68, l69, l70, l71, l72, preserve_unit_iters=True)
sch.parallel(loop=l94)
sch.annotate(block_or_loop=l94, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l94, ann_key="pragma_unroll_explicit", ann_val=1)
l95, l96, l97, l98, l99, l100 = sch.get_loops(block=b67)
l101 = sch.fuse(l100, preserve_unit_iters=True)
sch.vectorize(loop=l101)
b102 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l103, l104, l105, l106, l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124 = sch.get_loops(block=b102)
b125 = sch.decompose_reduction(block=b102, loop=l109)
2024-04-28 21:34:23 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #6: GFLOPs: 14.1933. Time: 1061.6640 us. Best GFLOPs: 78.5144
2024-04-28 21:34:23 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #7: GFLOPs: 20.6177. Time: 730.8515 us. Best GFLOPs: 78.5144
2024-04-28 21:34:23 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #8: GFLOPs: 8.1601. Time: 1846.6128 us. Best GFLOPs: 78.5144
2024-04-28 21:34:23 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #9: GFLOPs: 24.8807. Time: 605.6298 us. Best GFLOPs: 78.5144
2024-04-28 21:34:23 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #10: GFLOPs: 30.3455. Time: 496.5635 us. Best GFLOPs: 78.5144
2024-04-28 21:34:23 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #11: GFLOPs: 52.1432. Time: 288.9826 us. Best GFLOPs: 78.5144
2024-04-28 21:34:23 [INFO] [task_scheduler.cc:121] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #12: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(240), T.int64(7), T.int64(7), T.int64(4)), "float32"), p1: T.Buffer((T.int64(40), T.int64(240), T.int64(1), T.int64(1), T.int64(4), T.int64(4)), "float32"), p2: T.Buffer((T.int64(1), T.int64(40), T.int64(1), T.int64(1), T.int64(4)), "float32"), p3: T.Buffer((T.int64(1), T.int64(40), T.int64(7), T.int64(7), T.int64(4)), "float32"), T_add: T.Buffer((T.int64(1), T.int64(40), T.int64(7), T.int64(7), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(40), T.int64(7), T.int64(7), T.int64(4)))
        for n_0 in T.serial(T.int64(1), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for oc_chunk_0, oh_0, ow_0, oc_block_0 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(20), T.int64(7), T.int64(1), T.int64(2)):
                    for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1)):
                        for oc_block_3_fused_init in T.vectorized(T.int64(2)):
                            with T.block("conv2d_NCHWc_init"):
                                v_n = T.axis.spatial(T.int64(1), n_0 + n_1 + n_2_init + n_3_init)
                                v_oc_chunk = T.axis.spatial(T.int64(40), oc_chunk_0 * T.int64(40) + oc_chunk_1 * T.int64(2) + oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                                v_oh = T.axis.spatial(T.int64(7), oh_0 * T.int64(7) + oh_1 + oh_2_init + oh_3_init)
                                v_ow = T.axis.spatial(T.int64(7), ow_0 * T.int64(7) + ow_1 * T.int64(7) + ow_2_init + ow_3_init)
                                v_oc_block = T.axis.spatial(T.int64(4), oc_block_0 * T.int64(4) + oc_block_1 * T.int64(2) + oc_block_2_init * T.int64(2) + oc_block_3_fused_init)
                                T.reads()
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                    for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(24), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(40), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1)):
                        for oc_block_3_fused in T.vectorized(T.int64(2)):
                            with T.block("conv2d_NCHWc_update"):
                                v_n = T.axis.spatial(T.int64(1), n_0 + n_1 + n_2 + n_3)
                                v_oc_chunk = T.axis.spatial(T.int64(40), oc_chunk_0 * T.int64(40) + oc_chunk_1 * T.int64(2) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                                v_oh = T.axis.spatial(T.int64(7), oh_0 * T.int64(7) + oh_1 + oh_2 + oh_3)
                                v_ow = T.axis.spatial(T.int64(7), ow_0 * T.int64(7) + ow_1 * T.int64(7) + ow_2 + ow_3)
                                v_oc_block = T.axis.spatial(T.int64(4), oc_block_0 * T.int64(4) + oc_block_1 * T.int64(2) + oc_block_2 * T.int64(2) + oc_block_3_fused)
                                v_ic = T.axis.reduce(T.int64(960), ic_0 * T.int64(40) + ic_1)
                                v_kh = T.axis.reduce(T.int64(1), kh_0 + kh_1)
                                v_kw = T.axis.reduce(T.int64(1), kw_0 + kw_1)
                                T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], p0[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)], p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block])
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + p0[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)] * p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block]
                for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(40), T.int64(7)):
                    for ax3_ax4_fused in T.vectorized(T.int64(28)):
                        with T.block("T_add_1"):
                            v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                            v_ax3 = T.axis.spatial(T.int64(7), ax3_ax4_fused // T.int64(4))
                            v_ax4 = T.axis.spatial(T.int64(4), ax3_ax4_fused % T.int64(4))
                            T.reads(p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + (conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
b0 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b1 = sch.get_block(name="T_add", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l3, l4, l5, l6, l7, l8, l9, l10 = sch.get_loops(block=b0)
v11, v12, v13, v14 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l15, l16, l17, l18 = sch.split(loop=l3, factors=[v11, v12, v13, v14], preserve_unit_iters=True)
v19, v20, v21, v22 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 20, 1, 2])
l23, l24, l25, l26 = sch.split(loop=l4, factors=[v19, v20, v21, v22], preserve_unit_iters=True)
v27, v28, v29, v30 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 7, 1, 1])
l31, l32, l33, l34 = sch.split(loop=l5, factors=[v27, v28, v29, v30], preserve_unit_iters=True)
v35, v36, v37, v38 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 7, 1])
l39, l40, l41, l42 = sch.split(loop=l6, factors=[v35, v36, v37, v38], preserve_unit_iters=True)
v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 2, 1, 2])
l47, l48, l49, l50 = sch.split(loop=l7, factors=[v43, v44, v45, v46], preserve_unit_iters=True)
v51, v52 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[24, 40])
l53, l54 = sch.split(loop=l8, factors=[v51, v52], preserve_unit_iters=True)
v55, v56 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[1, 1])
l57, l58 = sch.split(loop=l9, factors=[v55, v56], preserve_unit_iters=True)
v59, v60 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 1])
l61, l62 = sch.split(loop=l10, factors=[v59, v60], preserve_unit_iters=True)
sch.reorder(l15, l23, l31, l39, l47, l16, l24, l32, l40, l48, l53, l57, l61, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50)
b63, = sch.get_consumers(block=b0)
sch.reverse_compute_at(block=b63, loop=l47, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
sch.enter_postproc()
b65 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b65, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b65, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b65, ann_key="meta_schedule.unroll_explicit")
b66, b67 = sch.get_child_blocks(b65)
l68, l69, l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93 = sch.get_loops(block=b66)
l94 = sch.fuse(l93, preserve_unit_iters=True)
sch.vectorize(loop=l94)
sch.annotate(block_or_loop=l68, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l68, ann_key="pragma_unroll_explicit", ann_val=1)
l95, l96, l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b67)
l105 = sch.fuse(l103, l104, preserve_unit_iters=True)
sch.vectorize(loop=l105)
b106 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132 = sch.get_loops(block=b106)
b133 = sch.decompose_reduction(block=b106, loop=l117)
2024-04-28 21:34:23 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #13: GFLOPs: 86.7066. Time: 173.7869 us. Best GFLOPs: 86.7066
2024-04-28 21:34:23 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #14: GFLOPs: 14.5746. Time: 1033.8832 us. Best GFLOPs: 86.7066
2024-04-28 21:34:23 [INFO] [task_scheduler.cc:121] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #15: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(240), T.int64(7), T.int64(7), T.int64(4)), "float32"), p1: T.Buffer((T.int64(40), T.int64(240), T.int64(1), T.int64(1), T.int64(4), T.int64(4)), "float32"), p2: T.Buffer((T.int64(1), T.int64(40), T.int64(1), T.int64(1), T.int64(4)), "float32"), p3: T.Buffer((T.int64(1), T.int64(40), T.int64(7), T.int64(7), T.int64(4)), "float32"), T_add: T.Buffer((T.int64(1), T.int64(40), T.int64(7), T.int64(7), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(40), T.int64(7), T.int64(7), T.int64(4)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused in T.parallel(T.int64(7), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(20), T.int64(7), T.int64(1)):
                for oc_block_3_fused_init in T.vectorized(T.int64(2)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(40), oc_chunk_2_init * T.int64(20) + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(7), oh_2_init * T.int64(7) + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused + ow_2_init + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(4), oc_block_2_init * T.int64(2) + oc_block_3_fused_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
            for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(160), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(2), T.int64(6), T.int64(1), T.int64(1), T.int64(1), T.int64(20), T.int64(7), T.int64(1)):
                for oc_block_3_fused in T.vectorized(T.int64(2)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(40), oc_chunk_2 * T.int64(20) + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(7), oh_2 * T.int64(7) + oh_3)
                        v_ow = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused + ow_2 + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(4), oc_block_2 * T.int64(2) + oc_block_3_fused)
                        v_ic = T.axis.reduce(T.int64(960), ic_0 * T.int64(6) + ic_1)
                        v_kh = T.axis.reduce(T.int64(1), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(1), kw_0 + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], p0[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)], p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + p0[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)] * p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block]
            for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(40), T.int64(7)):
                for ax3_ax4_fused in T.vectorized(T.int64(4)):
                    with T.block("T_add_1"):
                        v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused, ax3_ax4_fused])
                        T.reads(p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + (conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
b0 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b1 = sch.get_block(name="T_add", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l3, l4, l5, l6, l7, l8, l9, l10 = sch.get_loops(block=b0)
v11, v12, v13, v14 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l15, l16, l17, l18 = sch.split(loop=l3, factors=[v11, v12, v13, v14], preserve_unit_iters=True)
v19, v20, v21, v22 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 2, 20])
l23, l24, l25, l26 = sch.split(loop=l4, factors=[v19, v20, v21, v22], preserve_unit_iters=True)
v27, v28, v29, v30 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 7])
l31, l32, l33, l34 = sch.split(loop=l5, factors=[v27, v28, v29, v30], preserve_unit_iters=True)
v35, v36, v37, v38 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[7, 1, 1, 1])
l39, l40, l41, l42 = sch.split(loop=l6, factors=[v35, v36, v37, v38], preserve_unit_iters=True)
v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 2, 2])
l47, l48, l49, l50 = sch.split(loop=l7, factors=[v43, v44, v45, v46], preserve_unit_iters=True)
v51, v52 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[160, 6])
l53, l54 = sch.split(loop=l8, factors=[v51, v52], preserve_unit_iters=True)
v55, v56 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[1, 1])
l57, l58 = sch.split(loop=l9, factors=[v55, v56], preserve_unit_iters=True)
v59, v60 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 1])
l61, l62 = sch.split(loop=l10, factors=[v59, v60], preserve_unit_iters=True)
sch.reorder(l15, l23, l31, l39, l47, l16, l24, l32, l40, l48, l53, l57, l61, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50)
b63, = sch.get_consumers(block=b0)
sch.reverse_compute_at(block=b63, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
sch.enter_postproc()
b65 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b65, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b65, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b65, ann_key="meta_schedule.unroll_explicit")
b66, b67 = sch.get_child_blocks(b65)
l68, l69, l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93 = sch.get_loops(block=b66)
l94 = sch.fuse(l68, l69, l70, l71, l72, l73, l74, l75, l76, l77, preserve_unit_iters=True)
sch.parallel(loop=l94)
l95 = sch.fuse(l93, preserve_unit_iters=True)
sch.vectorize(loop=l95)
sch.annotate(block_or_loop=l94, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l94, ann_key="pragma_unroll_explicit", ann_val=1)
l96, l97, l98, l99, l100, l101 = sch.get_loops(block=b67)
l102 = sch.fuse(l100, l101, preserve_unit_iters=True)
sch.vectorize(loop=l102)
b103 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l104, l105, l106, l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117, l118, l119, l120 = sch.get_loops(block=b103)
b121 = sch.decompose_reduction(block=b103, loop=l105)
2024-04-28 21:34:23 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #16: GFLOPs: 0.2006. Time: 75100.7923 us. Best GFLOPs: 86.7066
2024-04-28 21:34:23 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #17: GFLOPs: 5.9547. Time: 2530.5247 us. Best GFLOPs: 86.7066
2024-04-28 21:34:23 [INFO] [task_scheduler.cc:121] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #18: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(240), T.int64(7), T.int64(7), T.int64(4)), "float32"), p1: T.Buffer((T.int64(40), T.int64(240), T.int64(1), T.int64(1), T.int64(4), T.int64(4)), "float32"), p2: T.Buffer((T.int64(1), T.int64(40), T.int64(1), T.int64(1), T.int64(4)), "float32"), p3: T.Buffer((T.int64(1), T.int64(40), T.int64(7), T.int64(7), T.int64(4)), "float32"), T_add: T.Buffer((T.int64(1), T.int64(40), T.int64(7), T.int64(7), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(40), T.int64(7), T.int64(7), T.int64(4)))
        for n_0 in T.serial(T.int64(1), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for oc_chunk_0, oh_0, ow_0, oc_block_0 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1)):
                    for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(8), T.int64(7), T.int64(1), T.int64(2), T.int64(1), T.int64(5), T.int64(1), T.int64(1)):
                        for oc_block_3_fused_init in T.vectorized(T.int64(2)):
                            with T.block("conv2d_NCHWc_init"):
                                v_n = T.axis.spatial(T.int64(1), n_0 + n_1 + n_2_init + n_3_init)
                                v_oc_chunk = T.axis.spatial(T.int64(40), oc_chunk_0 * T.int64(40) + oc_chunk_1 * T.int64(40) + oc_chunk_2_init * T.int64(5) + oc_chunk_3_init)
                                v_oh = T.axis.spatial(T.int64(7), oh_0 * T.int64(7) + oh_1 * T.int64(7) + oh_2_init + oh_3_init)
                                v_ow = T.axis.spatial(T.int64(7), ow_0 * T.int64(7) + ow_1 + ow_2_init + ow_3_init)
                                v_oc_block = T.axis.spatial(T.int64(4), oc_block_0 * T.int64(4) + oc_block_1 * T.int64(4) + oc_block_2_init * T.int64(2) + oc_block_3_fused_init)
                                T.reads()
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                    for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(480), T.int64(1), T.int64(1), T.int64(1), T.int64(8), T.int64(7), T.int64(1), T.int64(2), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(5), T.int64(1), T.int64(1)):
                        for oc_block_3_fused in T.vectorized(T.int64(2)):
                            with T.block("conv2d_NCHWc_update"):
                                v_n = T.axis.spatial(T.int64(1), n_0 + n_1 + n_2 + n_3)
                                v_oc_chunk = T.axis.spatial(T.int64(40), oc_chunk_0 * T.int64(40) + oc_chunk_1 * T.int64(40) + oc_chunk_2 * T.int64(5) + oc_chunk_3)
                                v_oh = T.axis.spatial(T.int64(7), oh_0 * T.int64(7) + oh_1 * T.int64(7) + oh_2 + oh_3)
                                v_ow = T.axis.spatial(T.int64(7), ow_0 * T.int64(7) + ow_1 + ow_2 + ow_3)
                                v_oc_block = T.axis.spatial(T.int64(4), oc_block_0 * T.int64(4) + oc_block_1 * T.int64(4) + oc_block_2 * T.int64(2) + oc_block_3_fused)
                                v_ic = T.axis.reduce(T.int64(960), ic_0 * T.int64(2) + ic_1)
                                v_kh = T.axis.reduce(T.int64(1), kh_0 + kh_1)
                                v_kw = T.axis.reduce(T.int64(1), kw_0 + kw_1)
                                T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], p0[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)], p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block])
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + p0[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)] * p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block]
                for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(40), T.int64(7)):
                    for ax3_ax4_fused in T.vectorized(T.int64(28)):
                        with T.block("T_add_1"):
                            v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                            v_ax3 = T.axis.spatial(T.int64(7), ax3_ax4_fused // T.int64(4))
                            v_ax4 = T.axis.spatial(T.int64(4), ax3_ax4_fused % T.int64(4))
                            T.reads(p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + (conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
b0 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b1 = sch.get_block(name="T_add", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l3, l4, l5, l6, l7, l8, l9, l10 = sch.get_loops(block=b0)
v11, v12, v13, v14 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l15, l16, l17, l18 = sch.split(loop=l3, factors=[v11, v12, v13, v14], preserve_unit_iters=True)
v19, v20, v21, v22 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 8, 5])
l23, l24, l25, l26 = sch.split(loop=l4, factors=[v19, v20, v21, v22], preserve_unit_iters=True)
v27, v28, v29, v30 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 7, 1])
l31, l32, l33, l34 = sch.split(loop=l5, factors=[v27, v28, v29, v30], preserve_unit_iters=True)
v35, v36, v37, v38 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 7, 1, 1])
l39, l40, l41, l42 = sch.split(loop=l6, factors=[v35, v36, v37, v38], preserve_unit_iters=True)
v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 2, 2])
l47, l48, l49, l50 = sch.split(loop=l7, factors=[v43, v44, v45, v46], preserve_unit_iters=True)
v51, v52 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[480, 2])
l53, l54 = sch.split(loop=l8, factors=[v51, v52], preserve_unit_iters=True)
v55, v56 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[1, 1])
l57, l58 = sch.split(loop=l9, factors=[v55, v56], preserve_unit_iters=True)
v59, v60 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 1])
l61, l62 = sch.split(loop=l10, factors=[v59, v60], preserve_unit_iters=True)
sch.reorder(l15, l23, l31, l39, l47, l16, l24, l32, l40, l48, l53, l57, l61, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50)
b63, = sch.get_consumers(block=b0)
sch.reverse_compute_at(block=b63, loop=l47, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
sch.enter_postproc()
b65 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b65, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b65, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b65, ann_key="meta_schedule.unroll_explicit")
b66, b67 = sch.get_child_blocks(b65)
l68, l69, l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93 = sch.get_loops(block=b66)
l94 = sch.fuse(l93, preserve_unit_iters=True)
sch.vectorize(loop=l94)
sch.annotate(block_or_loop=l68, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l68, ann_key="pragma_unroll_explicit", ann_val=1)
l95, l96, l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b67)
l105 = sch.fuse(l103, l104, preserve_unit_iters=True)
sch.vectorize(loop=l105)
b106 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132 = sch.get_loops(block=b106)
b133 = sch.decompose_reduction(block=b106, loop=l117)
2024-04-28 21:34:23 [INFO] [task_scheduler.cc:121] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #19: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(240), T.int64(7), T.int64(7), T.int64(4)), "float32"), p1: T.Buffer((T.int64(40), T.int64(240), T.int64(1), T.int64(1), T.int64(4), T.int64(4)), "float32"), p2: T.Buffer((T.int64(1), T.int64(40), T.int64(1), T.int64(1), T.int64(4)), "float32"), p3: T.Buffer((T.int64(1), T.int64(40), T.int64(7), T.int64(7), T.int64(4)), "float32"), T_add: T.Buffer((T.int64(1), T.int64(40), T.int64(7), T.int64(7), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(40), T.int64(7), T.int64(7), T.int64(4)))
        for n_0 in T.serial(T.int64(1), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for oc_chunk_0, oh_0, ow_0, oc_block_0 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(7), T.int64(2)):
                    for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(20), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(1)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_0 + n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(40), oc_chunk_0 * T.int64(40) + oc_chunk_1 * T.int64(20) + oc_chunk_2_init + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(7), oh_0 * T.int64(7) + oh_1 * T.int64(7) + oh_2_init * T.int64(7) + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(7), ow_0 * T.int64(7) + ow_1 + ow_2_init + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(4), oc_block_0 * T.int64(4) + oc_block_1 * T.int64(2) + oc_block_2_init + oc_block_3_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                    for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(40), T.int64(1), T.int64(1), T.int64(1), T.int64(20), T.int64(1), T.int64(1), T.int64(2), T.int64(24), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(1)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_0 + n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(40), oc_chunk_0 * T.int64(40) + oc_chunk_1 * T.int64(20) + oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(7), oh_0 * T.int64(7) + oh_1 * T.int64(7) + oh_2 * T.int64(7) + oh_3)
                            v_ow = T.axis.spatial(T.int64(7), ow_0 * T.int64(7) + ow_1 + ow_2 + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(4), oc_block_0 * T.int64(4) + oc_block_1 * T.int64(2) + oc_block_2 + oc_block_3)
                            v_ic = T.axis.reduce(T.int64(960), ic_0 * T.int64(24) + ic_1)
                            v_kh = T.axis.reduce(T.int64(1), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(1), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], p0[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)], p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + p0[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)] * p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block]
                for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(40), T.int64(7)):
                    for ax3_ax4_fused in T.vectorized(T.int64(28)):
                        with T.block("T_add_1"):
                            v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                            v_ax3 = T.axis.spatial(T.int64(7), ax3_ax4_fused // T.int64(4))
                            v_ax4 = T.axis.spatial(T.int64(4), ax3_ax4_fused % T.int64(4))
                            T.reads(p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + (conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
b0 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b1 = sch.get_block(name="T_add", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l3, l4, l5, l6, l7, l8, l9, l10 = sch.get_loops(block=b0)
v11, v12, v13, v14 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l15, l16, l17, l18 = sch.split(loop=l3, factors=[v11, v12, v13, v14], preserve_unit_iters=True)
v19, v20, v21, v22 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 2, 20, 1])
l23, l24, l25, l26 = sch.split(loop=l4, factors=[v19, v20, v21, v22], preserve_unit_iters=True)
v27, v28, v29, v30 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 7])
l31, l32, l33, l34 = sch.split(loop=l5, factors=[v27, v28, v29, v30], preserve_unit_iters=True)
v35, v36, v37, v38 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 7, 1, 1])
l39, l40, l41, l42 = sch.split(loop=l6, factors=[v35, v36, v37, v38], preserve_unit_iters=True)
v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 2, 2, 1])
l47, l48, l49, l50 = sch.split(loop=l7, factors=[v43, v44, v45, v46], preserve_unit_iters=True)
v51, v52 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[40, 24])
l53, l54 = sch.split(loop=l8, factors=[v51, v52], preserve_unit_iters=True)
v55, v56 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[1, 1])
l57, l58 = sch.split(loop=l9, factors=[v55, v56], preserve_unit_iters=True)
v59, v60 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 1])
l61, l62 = sch.split(loop=l10, factors=[v59, v60], preserve_unit_iters=True)
sch.reorder(l15, l23, l31, l39, l47, l16, l24, l32, l40, l48, l53, l57, l61, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50)
b63, = sch.get_consumers(block=b0)
sch.reverse_compute_at(block=b63, loop=l47, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
sch.enter_postproc()
b65 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b65, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b65, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b65, ann_key="meta_schedule.unroll_explicit")
b66, b67 = sch.get_child_blocks(b65)
l68, l69, l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93 = sch.get_loops(block=b66)
sch.annotate(block_or_loop=l68, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l68, ann_key="pragma_unroll_explicit", ann_val=1)
l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b67)
l104 = sch.fuse(l102, l103, preserve_unit_iters=True)
sch.vectorize(loop=l104)
b105 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l106, l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131 = sch.get_loops(block=b105)
b132 = sch.decompose_reduction(block=b105, loop=l116)
2024-04-28 21:34:23 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #20: GFLOPs: 4.0316. Time: 3737.6057 us. Best GFLOPs: 86.7066
2024-04-28 21:34:23 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #21: GFLOPs: 107.0019. Time: 140.8244 us. Best GFLOPs: 107.0019
2024-04-28 21:34:23 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #22: GFLOPs: 55.7511. Time: 270.2813 us. Best GFLOPs: 107.0019
2024-04-28 21:34:23 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #23: GFLOPs: 63.8616. Time: 235.9552 us. Best GFLOPs: 107.0019
2024-04-28 21:34:23 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #24: GFLOPs: 101.4434. Time: 148.5407 us. Best GFLOPs: 107.0019
2024-04-28 21:34:23 [INFO] [task_scheduler.cc:121] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #25: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(240), T.int64(7), T.int64(7), T.int64(4)), "float32"), p1: T.Buffer((T.int64(40), T.int64(240), T.int64(1), T.int64(1), T.int64(4), T.int64(4)), "float32"), p2: T.Buffer((T.int64(1), T.int64(40), T.int64(1), T.int64(1), T.int64(4)), "float32"), p3: T.Buffer((T.int64(1), T.int64(40), T.int64(7), T.int64(7), T.int64(4)), "float32"), T_add: T.Buffer((T.int64(1), T.int64(40), T.int64(7), T.int64(7), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(40), T.int64(7), T.int64(7), T.int64(4)))
        for n_0 in T.serial(T.int64(1), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for oc_chunk_0, oh_0, ow_0, oc_block_0 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(7), T.int64(7), T.int64(1)):
                    for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(20), T.int64(1), T.int64(1)):
                        for oc_block_3_fused_init in T.vectorized(T.int64(2)):
                            with T.block("conv2d_NCHWc_init"):
                                v_n = T.axis.spatial(T.int64(1), n_0 + n_1 + n_2_init + n_3_init)
                                v_oc_chunk = T.axis.spatial(T.int64(40), oc_chunk_0 * T.int64(40) + oc_chunk_1 * T.int64(40) + oc_chunk_2_init * T.int64(20) + oc_chunk_3_init)
                                v_oh = T.axis.spatial(T.int64(7), oh_0 * T.int64(7) + oh_1 + oh_2_init + oh_3_init)
                                v_ow = T.axis.spatial(T.int64(7), ow_0 * T.int64(7) + ow_1 + ow_2_init + ow_3_init)
                                v_oc_block = T.axis.spatial(T.int64(4), oc_block_0 * T.int64(4) + oc_block_1 * T.int64(4) + oc_block_2_init * T.int64(2) + oc_block_3_fused_init)
                                T.reads()
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                    for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(120), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(2), T.int64(8), T.int64(1), T.int64(1), T.int64(1), T.int64(20), T.int64(1), T.int64(1)):
                        for oc_block_3_fused in T.vectorized(T.int64(2)):
                            with T.block("conv2d_NCHWc_update"):
                                v_n = T.axis.spatial(T.int64(1), n_0 + n_1 + n_2 + n_3)
                                v_oc_chunk = T.axis.spatial(T.int64(40), oc_chunk_0 * T.int64(40) + oc_chunk_1 * T.int64(40) + oc_chunk_2 * T.int64(20) + oc_chunk_3)
                                v_oh = T.axis.spatial(T.int64(7), oh_0 * T.int64(7) + oh_1 + oh_2 + oh_3)
                                v_ow = T.axis.spatial(T.int64(7), ow_0 * T.int64(7) + ow_1 + ow_2 + ow_3)
                                v_oc_block = T.axis.spatial(T.int64(4), oc_block_0 * T.int64(4) + oc_block_1 * T.int64(4) + oc_block_2 * T.int64(2) + oc_block_3_fused)
                                v_ic = T.axis.reduce(T.int64(960), ic_0 * T.int64(8) + ic_1)
                                v_kh = T.axis.reduce(T.int64(1), kh_0 + kh_1)
                                v_kw = T.axis.reduce(T.int64(1), kw_0 + kw_1)
                                T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], p0[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)], p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block])
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + p0[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)] * p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block]
                for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(40), T.int64(7)):
                    for ax3_ax4_fused in T.vectorized(T.int64(28)):
                        with T.block("T_add_1"):
                            v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                            v_ax3 = T.axis.spatial(T.int64(7), ax3_ax4_fused // T.int64(4))
                            v_ax4 = T.axis.spatial(T.int64(4), ax3_ax4_fused % T.int64(4))
                            T.reads(p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + (conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
b0 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b1 = sch.get_block(name="T_add", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l3, l4, l5, l6, l7, l8, l9, l10 = sch.get_loops(block=b0)
v11, v12, v13, v14 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l15, l16, l17, l18 = sch.split(loop=l3, factors=[v11, v12, v13, v14], preserve_unit_iters=True)
v19, v20, v21, v22 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 2, 20])
l23, l24, l25, l26 = sch.split(loop=l4, factors=[v19, v20, v21, v22], preserve_unit_iters=True)
v27, v28, v29, v30 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 7, 1, 1])
l31, l32, l33, l34 = sch.split(loop=l5, factors=[v27, v28, v29, v30], preserve_unit_iters=True)
v35, v36, v37, v38 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 7, 1, 1])
l39, l40, l41, l42 = sch.split(loop=l6, factors=[v35, v36, v37, v38], preserve_unit_iters=True)
v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 2, 2])
l47, l48, l49, l50 = sch.split(loop=l7, factors=[v43, v44, v45, v46], preserve_unit_iters=True)
v51, v52 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[120, 8])
l53, l54 = sch.split(loop=l8, factors=[v51, v52], preserve_unit_iters=True)
v55, v56 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[1, 1])
l57, l58 = sch.split(loop=l9, factors=[v55, v56], preserve_unit_iters=True)
v59, v60 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 1])
l61, l62 = sch.split(loop=l10, factors=[v59, v60], preserve_unit_iters=True)
sch.reorder(l15, l23, l31, l39, l47, l16, l24, l32, l40, l48, l53, l57, l61, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50)
b63, = sch.get_consumers(block=b0)
sch.reverse_compute_at(block=b63, loop=l47, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
sch.enter_postproc()
b65 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b65, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b65, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b65, ann_key="meta_schedule.unroll_explicit")
b66, b67 = sch.get_child_blocks(b65)
l68, l69, l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93 = sch.get_loops(block=b66)
l94 = sch.fuse(l93, preserve_unit_iters=True)
sch.vectorize(loop=l94)
sch.annotate(block_or_loop=l68, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l68, ann_key="pragma_unroll_explicit", ann_val=1)
l95, l96, l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b67)
l105 = sch.fuse(l103, l104, preserve_unit_iters=True)
sch.vectorize(loop=l105)
b106 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132 = sch.get_loops(block=b106)
b133 = sch.decompose_reduction(block=b106, loop=l117)
2024-04-28 21:34:23 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #26: GFLOPs: 37.3192. Time: 403.7727 us. Best GFLOPs: 107.0019
2024-04-28 21:34:23 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #27: GFLOPs: 28.7789. Time: 523.5941 us. Best GFLOPs: 107.0019
2024-04-28 21:34:23 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #28: GFLOPs: 26.0692. Time: 578.0189 us. Best GFLOPs: 107.0019
2024-04-28 21:34:23 [INFO] [task_scheduler.cc:121] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #29: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(240), T.int64(7), T.int64(7), T.int64(4)), "float32"), p1: T.Buffer((T.int64(40), T.int64(240), T.int64(1), T.int64(1), T.int64(4), T.int64(4)), "float32"), p2: T.Buffer((T.int64(1), T.int64(40), T.int64(1), T.int64(1), T.int64(4)), "float32"), p3: T.Buffer((T.int64(1), T.int64(40), T.int64(7), T.int64(7), T.int64(4)), "float32"), T_add: T.Buffer((T.int64(1), T.int64(40), T.int64(7), T.int64(7), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(40), T.int64(7), T.int64(7), T.int64(4)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused in T.parallel(T.int64(14), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(10), T.int64(7), T.int64(1)):
                for oc_block_3_fused_init in T.vectorized(T.int64(2)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(40), oc_chunk_2_init * T.int64(10) + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(7), oh_2_init * T.int64(7) + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused // T.int64(2) + ow_2_init + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(4), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(2) * T.int64(2) + oc_block_2_init * T.int64(2) + oc_block_3_fused_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
            for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(40), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(24), T.int64(1), T.int64(1), T.int64(1), T.int64(10), T.int64(7), T.int64(1)):
                for oc_block_3_fused in T.vectorized(T.int64(2)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(40), oc_chunk_2 * T.int64(10) + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(7), oh_2 * T.int64(7) + oh_3)
                        v_ow = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused // T.int64(2) + ow_2 + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(4), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(2) * T.int64(2) + oc_block_2 * T.int64(2) + oc_block_3_fused)
                        v_ic = T.axis.reduce(T.int64(960), ic_0 * T.int64(24) + ic_1)
                        v_kh = T.axis.reduce(T.int64(1), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(1), kw_0 + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], p0[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)], p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + p0[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)] * p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(40), T.int64(7), T.int64(1)):
                for ax4_fused in T.vectorized(T.int64(2)):
                    with T.block("T_add_1"):
                        v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                        v_ax3 = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused // T.int64(2) + ax3)
                        v_ax4 = T.axis.spatial(T.int64(4), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(2) * T.int64(2) + ax4_fused)
                        T.reads(p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + (conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
b0 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b1 = sch.get_block(name="T_add", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l3, l4, l5, l6, l7, l8, l9, l10 = sch.get_loops(block=b0)
v11, v12, v13, v14 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l15, l16, l17, l18 = sch.split(loop=l3, factors=[v11, v12, v13, v14], preserve_unit_iters=True)
v19, v20, v21, v22 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 4, 10])
l23, l24, l25, l26 = sch.split(loop=l4, factors=[v19, v20, v21, v22], preserve_unit_iters=True)
v27, v28, v29, v30 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 7])
l31, l32, l33, l34 = sch.split(loop=l5, factors=[v27, v28, v29, v30], preserve_unit_iters=True)
v35, v36, v37, v38 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[7, 1, 1, 1])
l39, l40, l41, l42 = sch.split(loop=l6, factors=[v35, v36, v37, v38], preserve_unit_iters=True)
v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 2, 1, 2])
l47, l48, l49, l50 = sch.split(loop=l7, factors=[v43, v44, v45, v46], preserve_unit_iters=True)
v51, v52 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[40, 24])
l53, l54 = sch.split(loop=l8, factors=[v51, v52], preserve_unit_iters=True)
v55, v56 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[1, 1])
l57, l58 = sch.split(loop=l9, factors=[v55, v56], preserve_unit_iters=True)
v59, v60 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 1])
l61, l62 = sch.split(loop=l10, factors=[v59, v60], preserve_unit_iters=True)
sch.reorder(l15, l23, l31, l39, l47, l16, l24, l32, l40, l48, l53, l57, l61, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50)
b63, = sch.get_consumers(block=b0)
sch.reverse_compute_at(block=b63, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
sch.enter_postproc()
b65 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b65, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b65, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b65, ann_key="meta_schedule.unroll_explicit")
b66, b67 = sch.get_child_blocks(b65)
l68, l69, l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93 = sch.get_loops(block=b66)
l94 = sch.fuse(l68, l69, l70, l71, l72, l73, l74, l75, l76, l77, preserve_unit_iters=True)
sch.parallel(loop=l94)
l95 = sch.fuse(l93, preserve_unit_iters=True)
sch.vectorize(loop=l95)
sch.annotate(block_or_loop=l94, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l94, ann_key="pragma_unroll_explicit", ann_val=1)
l96, l97, l98, l99, l100, l101 = sch.get_loops(block=b67)
l102 = sch.fuse(l101, preserve_unit_iters=True)
sch.vectorize(loop=l102)
b103 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l104, l105, l106, l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117, l118, l119, l120 = sch.get_loops(block=b103)
b121 = sch.decompose_reduction(block=b103, loop=l105)
2024-04-28 21:34:23 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #30: GFLOPs: 15.5229. Time: 970.7229 us. Best GFLOPs: 107.0019
2024-04-28 21:34:23 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #31: GFLOPs: 59.2740. Time: 254.2173 us. Best GFLOPs: 107.0019
2024-04-28 21:34:23 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #32: GFLOPs: 77.9297. Time: 193.3599 us. Best GFLOPs: 107.0019
2024-04-28 21:34:23 [INFO] [task_scheduler.cc:121] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #33: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(240), T.int64(7), T.int64(7), T.int64(4)), "float32"), p1: T.Buffer((T.int64(40), T.int64(240), T.int64(1), T.int64(1), T.int64(4), T.int64(4)), "float32"), p2: T.Buffer((T.int64(1), T.int64(40), T.int64(1), T.int64(1), T.int64(4)), "float32"), p3: T.Buffer((T.int64(1), T.int64(40), T.int64(7), T.int64(7), T.int64(4)), "float32"), T_add: T.Buffer((T.int64(1), T.int64(40), T.int64(7), T.int64(7), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(40), T.int64(7), T.int64(7), T.int64(4)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused in T.parallel(T.int64(8), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(5), T.int64(7), T.int64(7), T.int64(1)):
                with T.block("conv2d_NCHWc_init"):
                    v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                    v_oc_chunk = T.axis.spatial(T.int64(40), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused // T.int64(2) * T.int64(10) + oc_chunk_2_init * T.int64(5) + oc_chunk_3_init)
                    v_oh = T.axis.spatial(T.int64(7), oh_2_init * T.int64(7) + oh_3_init)
                    v_ow = T.axis.spatial(T.int64(7), ow_2_init * T.int64(7) + ow_3_init)
                    v_oc_block = T.axis.spatial(T.int64(4), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(2) * T.int64(2) + oc_block_2_init + oc_block_3_init)
                    T.reads()
                    T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                    T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                    conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
            for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(240), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(2), T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(5), T.int64(7), T.int64(7), T.int64(1)):
                with T.block("conv2d_NCHWc_update"):
                    v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                    v_oc_chunk = T.axis.spatial(T.int64(40), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused // T.int64(2) * T.int64(10) + oc_chunk_2 * T.int64(5) + oc_chunk_3)
                    v_oh = T.axis.spatial(T.int64(7), oh_2 * T.int64(7) + oh_3)
                    v_ow = T.axis.spatial(T.int64(7), ow_2 * T.int64(7) + ow_3)
                    v_oc_block = T.axis.spatial(T.int64(4), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(2) * T.int64(2) + oc_block_2 + oc_block_3)
                    v_ic = T.axis.reduce(T.int64(960), ic_0 * T.int64(4) + ic_1)
                    v_kh = T.axis.reduce(T.int64(1), kh_0 + kh_1)
                    v_kw = T.axis.reduce(T.int64(1), kw_0 + kw_1)
                    T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], p0[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)], p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block])
                    T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                    T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                    conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + p0[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)] * p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(10), T.int64(7), T.int64(7)):
                for ax4_fused in T.vectorized(T.int64(2)):
                    with T.block("T_add_1"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(40), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused // T.int64(2) * T.int64(10) + ax1)
                        v_ax2, v_ax3 = T.axis.remap("SS", [ax2, ax3])
                        v_ax4 = T.axis.spatial(T.int64(4), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(2) * T.int64(2) + ax4_fused)
                        T.reads(p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + (conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
b0 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b1 = sch.get_block(name="T_add", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l3, l4, l5, l6, l7, l8, l9, l10 = sch.get_loops(block=b0)
v11, v12, v13, v14 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l15, l16, l17, l18 = sch.split(loop=l3, factors=[v11, v12, v13, v14], preserve_unit_iters=True)
v19, v20, v21, v22 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 4, 2, 5])
l23, l24, l25, l26 = sch.split(loop=l4, factors=[v19, v20, v21, v22], preserve_unit_iters=True)
v27, v28, v29, v30 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 7])
l31, l32, l33, l34 = sch.split(loop=l5, factors=[v27, v28, v29, v30], preserve_unit_iters=True)
v35, v36, v37, v38 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 1, 7])
l39, l40, l41, l42 = sch.split(loop=l6, factors=[v35, v36, v37, v38], preserve_unit_iters=True)
v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 2, 2, 1])
l47, l48, l49, l50 = sch.split(loop=l7, factors=[v43, v44, v45, v46], preserve_unit_iters=True)
v51, v52 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[240, 4])
l53, l54 = sch.split(loop=l8, factors=[v51, v52], preserve_unit_iters=True)
v55, v56 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[1, 1])
l57, l58 = sch.split(loop=l9, factors=[v55, v56], preserve_unit_iters=True)
v59, v60 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 1])
l61, l62 = sch.split(loop=l10, factors=[v59, v60], preserve_unit_iters=True)
sch.reorder(l15, l23, l31, l39, l47, l16, l24, l32, l40, l48, l53, l57, l61, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50)
b63, = sch.get_consumers(block=b0)
sch.reverse_compute_at(block=b63, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
sch.enter_postproc()
b65 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b65, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b65, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b65, ann_key="meta_schedule.unroll_explicit")
b66, b67 = sch.get_child_blocks(b65)
l68, l69, l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93 = sch.get_loops(block=b66)
l94 = sch.fuse(l68, l69, l70, l71, l72, l73, l74, l75, l76, l77, preserve_unit_iters=True)
sch.parallel(loop=l94)
sch.annotate(block_or_loop=l94, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l94, ann_key="pragma_unroll_explicit", ann_val=1)
l95, l96, l97, l98, l99, l100 = sch.get_loops(block=b67)
l101 = sch.fuse(l100, preserve_unit_iters=True)
sch.vectorize(loop=l101)
b102 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l103, l104, l105, l106, l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117, l118, l119 = sch.get_loops(block=b102)
b120 = sch.decompose_reduction(block=b102, loop=l104)
2024-04-28 21:34:23 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #34: GFLOPs: 68.9526. Time: 218.5339 us. Best GFLOPs: 107.0019
2024-04-28 21:34:23 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #35: GFLOPs: 65.5731. Time: 229.7967 us. Best GFLOPs: 107.0019
2024-04-28 21:34:23 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #36: GFLOPs: 5.0996. Time: 2954.8359 us. Best GFLOPs: 107.0019
2024-04-28 21:34:23 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #37: GFLOPs: 63.0363. Time: 239.0446 us. Best GFLOPs: 107.0019
2024-04-28 21:34:23 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #38: GFLOPs: 23.1542. Time: 650.7893 us. Best GFLOPs: 107.0019
2024-04-28 21:34:23 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #39: GFLOPs: 3.6817. Time: 4092.7530 us. Best GFLOPs: 107.0019
2024-04-28 21:34:23 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #40: GFLOPs: 37.5844. Time: 400.9234 us. Best GFLOPs: 107.0019
2024-04-28 21:34:23 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #41: GFLOPs: 85.6636. Time: 175.9029 us. Best GFLOPs: 107.0019
2024-04-28 21:34:23 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #42: GFLOPs: 43.2325. Time: 348.5453 us. Best GFLOPs: 107.0019
2024-04-28 21:34:23 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #43: GFLOPs: 38.4206. Time: 392.1982 us. Best GFLOPs: 107.0019
2024-04-28 21:34:23 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #44: GFLOPs: 17.0633. Time: 883.0929 us. Best GFLOPs: 107.0019
2024-04-28 21:34:23 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #45: GFLOPs: 0.4276. Time: 35237.4007 us. Best GFLOPs: 107.0019
2024-04-28 21:34:23 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #46: GFLOPs: 37.5519. Time: 401.2704 us. Best GFLOPs: 107.0019
2024-04-28 21:34:23 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #47: GFLOPs: 67.2346. Time: 224.1181 us. Best GFLOPs: 107.0019
2024-04-28 21:34:23 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #48: GFLOPs: 67.0362. Time: 224.7814 us. Best GFLOPs: 107.0019
2024-04-28 21:34:23 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #49: GFLOPs: 78.0945. Time: 192.9519 us. Best GFLOPs: 107.0019
2024-04-28 21:34:23 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #50: GFLOPs: 160.0186. Time: 94.1671 us. Best GFLOPs: 160.0186
2024-04-28 21:34:23 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #51: GFLOPs: 77.0628. Time: 195.5351 us. Best GFLOPs: 160.0186
2024-04-28 21:34:23 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #52: GFLOPs: 83.3732. Time: 180.7353 us. Best GFLOPs: 160.0186
2024-04-28 21:34:23 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #53: GFLOPs: 63.4846. Time: 237.3565 us. Best GFLOPs: 160.0186
2024-04-28 21:34:23 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #54: GFLOPs: 2.8920. Time: 5210.3151 us. Best GFLOPs: 160.0186
2024-04-28 21:34:23 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #55: GFLOPs: 57.9277. Time: 260.1258 us. Best GFLOPs: 160.0186
2024-04-28 21:34:23 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #56: GFLOPs: 26.6725. Time: 564.9449 us. Best GFLOPs: 160.0186
2024-04-28 21:34:23 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #57: GFLOPs: 85.4462. Time: 176.3505 us. Best GFLOPs: 160.0186
2024-04-28 21:34:23 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #58: GFLOPs: 43.4146. Time: 347.0831 us. Best GFLOPs: 160.0186
2024-04-28 21:34:23 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #59: GFLOPs: 14.9477. Time: 1008.0795 us. Best GFLOPs: 160.0186
2024-04-28 21:34:23 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #60: GFLOPs: 46.3128. Time: 325.3634 us. Best GFLOPs: 160.0186
2024-04-28 21:34:23 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #61: GFLOPs: 5.9096. Time: 2549.8459 us. Best GFLOPs: 160.0186
2024-04-28 21:34:23 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #62: GFLOPs: 1.1874. Time: 12690.4592 us. Best GFLOPs: 160.0186
2024-04-28 21:34:23 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #63: GFLOPs: 87.8241. Time: 171.5756 us. Best GFLOPs: 160.0186
2024-04-28 21:34:23 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #64: GFLOPs: 35.2774. Time: 427.1420 us. Best GFLOPs: 160.0186
2024-04-28 21:52:59 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-28 21:52:59 [INFO] [evolutionary_search.cc:715] Picked top 56 candidate(s) from database
2024-04-28 21:53:02 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x38cb4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x529d4d8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x59926a8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x48ec1a8)]: 0 failure(s)
2024-04-28 21:53:02 [INFO] [evolutionary_search.cc:723] Sampled 456 candidate(s)
2024-04-28 21:53:07 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x38cb4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x529d4d8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x59926a8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x48ec1a8)]: 0 failure(s)
2024-04-28 21:53:12 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x38cb4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x529d4d8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x59926a8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x48ec1a8)]: 0 failure(s)
2024-04-28 21:53:18 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x38cb4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x529d4d8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x59926a8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x48ec1a8)]: 0 failure(s)
2024-04-28 21:53:23 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x38cb4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x529d4d8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x59926a8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x48ec1a8)]: 0 failure(s)
2024-04-28 21:53:26 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9905  0.9462  0.9230  0.9020  0.8528  0.8528  0.8439  0.8426  0.8284  0.8191  0.8066  0.8033  0.8031  0.7977  0.7946  0.7918
[17 : 32]:	0.7872  0.7828  0.7817  0.7769  0.7744  0.7682  0.7626  0.7623  0.7469  0.7440  0.7405  0.7369  0.7350  0.7347  0.7299  0.7252
[33 : 48]:	0.7249  0.7239  0.7179  0.7168  0.7162  0.7129  0.7125  0.7125  0.7125  0.7101  0.7090  0.7065  0.7062  0.7018  0.6936  0.6930
[49 : 64]:	0.6925  0.6878  0.6833  0.6833  0.6819  0.6787  0.6786  0.6778  0.6778  0.6761  0.6761  0.6739  0.6689  0.6670  0.6655  0.6644
2024-04-28 21:53:26 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-28 21:53:27 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-28 21:54:46 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #65: GFLOPs: 160.3776. Time: 93.9563 us. Best GFLOPs: 160.3776
2024-04-28 21:54:46 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #66: GFLOPs: 152.0831. Time: 99.0806 us. Best GFLOPs: 160.3776
2024-04-28 21:54:46 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #67: GFLOPs: 107.0564. Time: 140.7528 us. Best GFLOPs: 160.3776
2024-04-28 21:54:46 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #68: GFLOPs: 130.1019. Time: 115.8206 us. Best GFLOPs: 160.3776
2024-04-28 21:54:46 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #69: GFLOPs: 124.8734. Time: 120.6700 us. Best GFLOPs: 160.3776
2024-04-28 21:54:46 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #70: GFLOPs: 104.2491. Time: 144.5431 us. Best GFLOPs: 160.3776
2024-04-28 21:54:46 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #71: GFLOPs: 107.2188. Time: 140.5395 us. Best GFLOPs: 160.3776
2024-04-28 21:54:46 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #72: GFLOPs: 92.7009. Time: 162.5494 us. Best GFLOPs: 160.3776
2024-04-28 21:54:46 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #73: GFLOPs: 162.0433. Time: 92.9905 us. Best GFLOPs: 162.0433
2024-04-28 21:54:46 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #74: GFLOPs: 183.5741. Time: 82.0839 us. Best GFLOPs: 183.5741
2024-04-28 21:54:46 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #75: GFLOPs: 90.4419. Time: 166.6095 us. Best GFLOPs: 183.5741
2024-04-28 21:54:46 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #76: GFLOPs: 101.2409. Time: 148.8379 us. Best GFLOPs: 183.5741
2024-04-28 21:54:46 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #77: GFLOPs: 95.4845. Time: 157.8108 us. Best GFLOPs: 183.5741
2024-04-28 21:54:46 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #78: GFLOPs: 147.3524. Time: 102.2615 us. Best GFLOPs: 183.5741
2024-04-28 21:54:46 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #79: GFLOPs: 114.6748. Time: 131.4018 us. Best GFLOPs: 183.5741
2024-04-28 21:54:46 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #80: GFLOPs: 175.9907. Time: 85.6209 us. Best GFLOPs: 183.5741
2024-04-28 21:54:46 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #81: GFLOPs: 110.0779. Time: 136.8892 us. Best GFLOPs: 183.5741
2024-04-28 21:54:46 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #82: GFLOPs: 40.4659. Time: 372.3748 us. Best GFLOPs: 183.5741
2024-04-28 21:54:46 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #83: GFLOPs: 61.3812. Time: 245.4902 us. Best GFLOPs: 183.5741
2024-04-28 21:54:46 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #84: GFLOPs: 102.6133. Time: 146.8473 us. Best GFLOPs: 183.5741
2024-04-28 21:54:46 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #85: GFLOPs: 105.9805. Time: 142.1816 us. Best GFLOPs: 183.5741
2024-04-28 21:54:46 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #86: GFLOPs: 112.2055. Time: 134.2936 us. Best GFLOPs: 183.5741
2024-04-28 21:54:46 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #87: GFLOPs: 98.2515. Time: 153.3665 us. Best GFLOPs: 183.5741
2024-04-28 21:54:46 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #88: GFLOPs: 95.9619. Time: 157.0256 us. Best GFLOPs: 183.5741
2024-04-28 21:54:46 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #89: GFLOPs: 97.7482. Time: 154.1561 us. Best GFLOPs: 183.5741
2024-04-28 21:54:46 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #90: GFLOPs: 133.5178. Time: 112.8575 us. Best GFLOPs: 183.5741
2024-04-28 21:54:46 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #91: GFLOPs: 100.4276. Time: 150.0432 us. Best GFLOPs: 183.5741
2024-04-28 21:54:46 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #92: GFLOPs: 164.1101. Time: 91.8193 us. Best GFLOPs: 183.5741
2024-04-28 21:54:46 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #93: GFLOPs: 92.4466. Time: 162.9966 us. Best GFLOPs: 183.5741
2024-04-28 21:54:46 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #94: GFLOPs: 94.0168. Time: 160.2744 us. Best GFLOPs: 183.5741
2024-04-28 21:54:46 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #95: GFLOPs: 103.1674. Time: 146.0586 us. Best GFLOPs: 183.5741
2024-04-28 21:54:46 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #96: GFLOPs: 103.8081. Time: 145.1570 us. Best GFLOPs: 183.5741
2024-04-28 21:54:46 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #97: GFLOPs: 106.2324. Time: 141.8445 us. Best GFLOPs: 183.5741
2024-04-28 21:54:46 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #98: GFLOPs: 129.3019. Time: 116.5372 us. Best GFLOPs: 183.5741
2024-04-28 21:54:46 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #99: GFLOPs: 98.2571. Time: 153.3576 us. Best GFLOPs: 183.5741
2024-04-28 21:54:46 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #100: GFLOPs: 210.4257. Time: 71.6095 us. Best GFLOPs: 210.4257
2024-04-28 21:54:46 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #101: GFLOPs: 103.7567. Time: 145.2290 us. Best GFLOPs: 210.4257
2024-04-28 21:54:46 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #102: GFLOPs: 86.4906. Time: 174.2210 us. Best GFLOPs: 210.4257
2024-04-28 21:54:46 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #103: GFLOPs: 106.5099. Time: 141.4750 us. Best GFLOPs: 210.4257
2024-04-28 21:54:46 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #104: GFLOPs: 106.5560. Time: 141.4137 us. Best GFLOPs: 210.4257
2024-04-28 21:54:46 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #105: GFLOPs: 113.8854. Time: 132.3126 us. Best GFLOPs: 210.4257
2024-04-28 21:54:46 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #106: GFLOPs: 102.9655. Time: 146.3449 us. Best GFLOPs: 210.4257
2024-04-28 21:54:46 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #107: GFLOPs: 150.0714. Time: 100.4088 us. Best GFLOPs: 210.4257
2024-04-28 21:54:46 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #108: GFLOPs: 165.1443. Time: 91.2443 us. Best GFLOPs: 210.4257
2024-04-28 21:54:46 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #109: GFLOPs: 44.1775. Time: 341.0898 us. Best GFLOPs: 210.4257
2024-04-28 21:54:46 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #110: GFLOPs: 149.9185. Time: 100.5112 us. Best GFLOPs: 210.4257
2024-04-28 21:54:46 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #111: GFLOPs: 103.2012. Time: 146.0107 us. Best GFLOPs: 210.4257
2024-04-28 21:54:46 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #112: GFLOPs: 101.9264. Time: 147.8368 us. Best GFLOPs: 210.4257
2024-04-28 21:54:46 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #113: GFLOPs: 101.4903. Time: 148.4721 us. Best GFLOPs: 210.4257
2024-04-28 21:54:46 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #114: GFLOPs: 98.3633. Time: 153.1921 us. Best GFLOPs: 210.4257
2024-04-28 21:54:46 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #115: GFLOPs: 86.3916. Time: 174.4207 us. Best GFLOPs: 210.4257
2024-04-28 21:54:46 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #116: GFLOPs: 85.4640. Time: 176.3138 us. Best GFLOPs: 210.4257
2024-04-28 21:54:46 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #117: GFLOPs: 127.2594. Time: 118.4076 us. Best GFLOPs: 210.4257
2024-04-28 21:54:46 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #118: GFLOPs: 41.6989. Time: 361.3642 us. Best GFLOPs: 210.4257
2024-04-28 21:54:46 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #119: GFLOPs: 128.7841. Time: 117.0058 us. Best GFLOPs: 210.4257
2024-04-28 21:54:46 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #120: GFLOPs: 38.5095. Time: 391.2924 us. Best GFLOPs: 210.4257
2024-04-28 21:54:46 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #121: GFLOPs: 41.6082. Time: 362.1513 us. Best GFLOPs: 210.4257
2024-04-28 21:54:46 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #122: GFLOPs: 107.3880. Time: 140.3182 us. Best GFLOPs: 210.4257
2024-04-28 21:54:46 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #123: GFLOPs: 107.2462. Time: 140.5036 us. Best GFLOPs: 210.4257
2024-04-28 21:54:46 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #124: GFLOPs: 124.2314. Time: 121.2937 us. Best GFLOPs: 210.4257
2024-04-28 21:54:46 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #125: GFLOPs: 75.0233. Time: 200.8507 us. Best GFLOPs: 210.4257
2024-04-28 21:54:46 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #126: GFLOPs: 71.0454. Time: 212.0963 us. Best GFLOPs: 210.4257
2024-04-28 21:54:46 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #127: GFLOPs: 60.7034. Time: 248.2311 us. Best GFLOPs: 210.4257
2024-04-28 21:54:46 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #128: GFLOPs: 47.9968. Time: 313.9478 us. Best GFLOPs: 210.4257
2024-04-28 22:28:39 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-28 22:28:39 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-28 22:28:41 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x38cb4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x529d4d8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x59926a8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x48ec1a8)]: 0 failure(s)
2024-04-28 22:28:41 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-28 22:28:47 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x38cb4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x529d4d8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x59926a8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x48ec1a8)]: 0 failure(s)
2024-04-28 22:28:52 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x38cb4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x529d4d8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x59926a8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x48ec1a8)]: 0 failure(s)
2024-04-28 22:28:57 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x38cb4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x529d4d8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x59926a8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x48ec1a8)]: 0 failure(s)
2024-04-28 22:29:03 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x38cb4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x529d4d8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x59926a8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x48ec1a8)]: 0 failure(s)
2024-04-28 22:29:06 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9615  0.8636  0.8636  0.8596  0.8309  0.8293  0.8273  0.8231  0.7949  0.7891  0.7860  0.7809  0.7802  0.7747  0.7667  0.7640
[17 : 32]:	0.7613  0.7613  0.7516  0.7492  0.7390  0.7348  0.7319  0.7303  0.7242  0.7171  0.7127  0.7127  0.7072  0.7042  0.7000  0.6964
[33 : 48]:	0.6964  0.6931  0.6926  0.6901  0.6896  0.6895  0.6715  0.6706  0.6697  0.6657  0.6608  0.6589  0.6568  0.6549  0.6548  0.6490
[49 : 64]:	0.6486  0.6472  0.6468  0.6464  0.6448  0.6446  0.6422  0.6405  0.6385  0.6374  0.6370  0.6365  0.6287  0.6233  0.6230  0.6226
2024-04-28 22:29:06 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-28 22:29:06 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-28 22:30:43 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #129: GFLOPs: 207.9360. Time: 72.4669 us. Best GFLOPs: 210.4257
2024-04-28 22:30:43 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #130: GFLOPs: 214.4251. Time: 70.2739 us. Best GFLOPs: 214.4251
2024-04-28 22:30:43 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #131: GFLOPs: 214.3187. Time: 70.3088 us. Best GFLOPs: 214.4251
2024-04-28 22:30:43 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #132: GFLOPs: 142.7132. Time: 105.5858 us. Best GFLOPs: 214.4251
2024-04-28 22:30:43 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #133: GFLOPs: 202.1226. Time: 74.5512 us. Best GFLOPs: 214.4251
2024-04-28 22:30:43 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #134: GFLOPs: 147.6544. Time: 102.0523 us. Best GFLOPs: 214.4251
2024-04-28 22:30:43 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #135: GFLOPs: 205.4738. Time: 73.3353 us. Best GFLOPs: 214.4251
2024-04-28 22:30:43 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #136: GFLOPs: 182.6137. Time: 82.5156 us. Best GFLOPs: 214.4251
2024-04-28 22:30:43 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #137: GFLOPs: 160.2332. Time: 94.0410 us. Best GFLOPs: 214.4251
2024-04-28 22:30:43 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #138: GFLOPs: 99.0882. Time: 152.0714 us. Best GFLOPs: 214.4251
2024-04-28 22:30:43 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #139: GFLOPs: 166.7312. Time: 90.3759 us. Best GFLOPs: 214.4251
2024-04-28 22:30:43 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #140: GFLOPs: 165.2410. Time: 91.1909 us. Best GFLOPs: 214.4251
2024-04-28 22:30:43 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #141: GFLOPs: 187.7662. Time: 80.2513 us. Best GFLOPs: 214.4251
2024-04-28 22:30:43 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #142: GFLOPs: 163.4377. Time: 92.1971 us. Best GFLOPs: 214.4251
2024-04-28 22:30:43 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #143: GFLOPs: 173.6158. Time: 86.7921 us. Best GFLOPs: 214.4251
2024-04-28 22:30:43 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #144: GFLOPs: 163.3569. Time: 92.2427 us. Best GFLOPs: 214.4251
2024-04-28 22:30:43 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #145: GFLOPs: 114.4581. Time: 131.6506 us. Best GFLOPs: 214.4251
2024-04-28 22:30:43 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #146: GFLOPs: 124.6138. Time: 120.9215 us. Best GFLOPs: 214.4251
2024-04-28 22:30:43 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #147: GFLOPs: 143.0034. Time: 105.3715 us. Best GFLOPs: 214.4251
2024-04-28 22:30:43 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #148: GFLOPs: 162.1475. Time: 92.9307 us. Best GFLOPs: 214.4251
2024-04-28 22:30:43 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #149: GFLOPs: 127.7395. Time: 117.9626 us. Best GFLOPs: 214.4251
2024-04-28 22:30:43 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #150: GFLOPs: 152.4734. Time: 98.8269 us. Best GFLOPs: 214.4251
2024-04-28 22:30:43 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #151: GFLOPs: 165.5365. Time: 91.0281 us. Best GFLOPs: 214.4251
2024-04-28 22:30:43 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #152: GFLOPs: 157.0582. Time: 95.9420 us. Best GFLOPs: 214.4251
2024-04-28 22:30:43 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #153: GFLOPs: 68.2797. Time: 220.6875 us. Best GFLOPs: 214.4251
2024-04-28 22:30:43 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #154: GFLOPs: 199.6123. Time: 75.4887 us. Best GFLOPs: 214.4251
2024-04-28 22:30:43 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #155: GFLOPs: 163.3762. Time: 92.2318 us. Best GFLOPs: 214.4251
2024-04-28 22:30:43 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #156: GFLOPs: 165.1472. Time: 91.2427 us. Best GFLOPs: 214.4251
2024-04-28 22:30:43 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #157: GFLOPs: 165.7279. Time: 90.9230 us. Best GFLOPs: 214.4251
2024-04-28 22:30:43 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #158: GFLOPs: 81.4706. Time: 184.9560 us. Best GFLOPs: 214.4251
2024-04-28 22:30:43 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #159: GFLOPs: 178.1194. Time: 84.5976 us. Best GFLOPs: 214.4251
2024-04-28 22:30:43 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #160: GFLOPs: 141.9193. Time: 106.1764 us. Best GFLOPs: 214.4251
2024-04-28 22:30:43 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #161: GFLOPs: 86.7705. Time: 173.6590 us. Best GFLOPs: 214.4251
2024-04-28 22:30:43 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #162: GFLOPs: 159.3702. Time: 94.5502 us. Best GFLOPs: 214.4251
2024-04-28 22:30:43 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #163: GFLOPs: 164.9070. Time: 91.3756 us. Best GFLOPs: 214.4251
2024-04-28 22:30:43 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #164: GFLOPs: 170.2859. Time: 88.4893 us. Best GFLOPs: 214.4251
2024-04-28 22:30:43 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #165: GFLOPs: 191.9089. Time: 78.5189 us. Best GFLOPs: 214.4251
2024-04-28 22:30:43 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #166: GFLOPs: 92.8574. Time: 162.2755 us. Best GFLOPs: 214.4251
2024-04-28 22:30:43 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #167: GFLOPs: 140.8592. Time: 106.9755 us. Best GFLOPs: 214.4251
2024-04-28 22:30:43 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #168: GFLOPs: 151.0486. Time: 99.7592 us. Best GFLOPs: 214.4251
2024-04-28 22:30:43 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #169: GFLOPs: 209.3695. Time: 71.9708 us. Best GFLOPs: 214.4251
2024-04-28 22:30:43 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #170: GFLOPs: 166.2096. Time: 90.6595 us. Best GFLOPs: 214.4251
2024-04-28 22:30:43 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #171: GFLOPs: 155.3192. Time: 97.0162 us. Best GFLOPs: 214.4251
2024-04-28 22:30:43 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #172: GFLOPs: 130.6266. Time: 115.3553 us. Best GFLOPs: 214.4251
2024-04-28 22:30:43 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #173: GFLOPs: 126.7212. Time: 118.9105 us. Best GFLOPs: 214.4251
2024-04-28 22:30:43 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #174: GFLOPs: 127.3978. Time: 118.2790 us. Best GFLOPs: 214.4251
2024-04-28 22:30:43 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #175: GFLOPs: 195.9980. Time: 76.8808 us. Best GFLOPs: 214.4251
2024-04-28 22:30:43 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #176: GFLOPs: 161.0776. Time: 93.5479 us. Best GFLOPs: 214.4251
2024-04-28 22:30:43 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #177: GFLOPs: 100.1910. Time: 150.3975 us. Best GFLOPs: 214.4251
2024-04-28 22:30:43 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #178: GFLOPs: 180.6904. Time: 83.3939 us. Best GFLOPs: 214.4251
2024-04-28 22:30:43 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #179: GFLOPs: 99.9837. Time: 150.7093 us. Best GFLOPs: 214.4251
2024-04-28 22:30:43 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #180: GFLOPs: 98.1685. Time: 153.4961 us. Best GFLOPs: 214.4251
2024-04-28 22:30:43 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #181: GFLOPs: 163.3991. Time: 92.2189 us. Best GFLOPs: 214.4251
2024-04-28 22:30:43 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #182: GFLOPs: 113.0510. Time: 133.2892 us. Best GFLOPs: 214.4251
2024-04-28 22:30:43 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #183: GFLOPs: 129.5669. Time: 116.2989 us. Best GFLOPs: 214.4251
2024-04-28 22:30:43 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #184: GFLOPs: 110.6454. Time: 136.1871 us. Best GFLOPs: 214.4251
2024-04-28 22:30:43 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #185: GFLOPs: 186.5143. Time: 80.7900 us. Best GFLOPs: 214.4251
2024-04-28 22:30:43 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #186: GFLOPs: 112.6814. Time: 133.7264 us. Best GFLOPs: 214.4251
2024-04-28 22:30:43 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #187: GFLOPs: 128.6111. Time: 117.1632 us. Best GFLOPs: 214.4251
2024-04-28 22:30:43 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #188: GFLOPs: 68.2992. Time: 220.6246 us. Best GFLOPs: 214.4251
2024-04-28 22:30:43 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #189: GFLOPs: 159.1130. Time: 94.7030 us. Best GFLOPs: 214.4251
2024-04-28 22:30:43 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #190: GFLOPs: 141.7229. Time: 106.3236 us. Best GFLOPs: 214.4251
2024-04-28 22:30:43 [INFO] [task_scheduler.cc:121] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #191: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(240), T.int64(7), T.int64(7), T.int64(4)), "float32"), p1: T.Buffer((T.int64(40), T.int64(240), T.int64(1), T.int64(1), T.int64(4), T.int64(4)), "float32"), p2: T.Buffer((T.int64(1), T.int64(40), T.int64(1), T.int64(1), T.int64(4)), "float32"), p3: T.Buffer((T.int64(1), T.int64(40), T.int64(7), T.int64(7), T.int64(4)), "float32"), T_add: T.Buffer((T.int64(1), T.int64(40), T.int64(7), T.int64(7), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(40), T.int64(7), T.int64(7), T.int64(4)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused in T.parallel(T.int64(28), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(5), T.int64(1), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(8), T.int64(7), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(40), oc_chunk_1 * T.int64(8) + oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(7), oh_1 * T.int64(7) + oh_2_init + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused // T.int64(4) + ow_1 + ow_2_init + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(4), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused % T.int64(4) + oc_block_1 + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(320), T.int64(1), T.int64(1), T.int64(1), T.int64(8), T.int64(7), T.int64(1), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(40), oc_chunk_1 * T.int64(8) + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(7), oh_1 * T.int64(7) + oh_2 + oh_3)
                        v_ow = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused // T.int64(4) + ow_1 + ow_2 + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(4), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused % T.int64(4) + oc_block_1 + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(960), ic_0 * T.int64(3) + ic_1)
                        v_kh = T.axis.reduce(T.int64(1), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(1), kw_0 + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], p0[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)], p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + p0[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)] * p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block]
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(40), T.int64(7), T.int64(1), T.int64(1)):
                with T.block("T_add_1"):
                    v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                    v_ax3 = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused // T.int64(4) + ax3)
                    v_ax4 = T.axis.spatial(T.int64(4), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused % T.int64(4) + ax4)
                    T.reads(p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                    T.writes(T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + (conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
b0 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b1 = sch.get_block(name="T_add", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l3, l4, l5, l6, l7, l8, l9, l10 = sch.get_loops(block=b0)
v11, v12, v13, v14 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l15, l16, l17, l18 = sch.split(loop=l3, factors=[v11, v12, v13, v14], preserve_unit_iters=True)
v19, v20, v21, v22 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 5, 8, 1])
l23, l24, l25, l26 = sch.split(loop=l4, factors=[v19, v20, v21, v22], preserve_unit_iters=True)
v27, v28, v29, v30 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 7, 1])
l31, l32, l33, l34 = sch.split(loop=l5, factors=[v27, v28, v29, v30], preserve_unit_iters=True)
v35, v36, v37, v38 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[7, 1, 1, 1])
l39, l40, l41, l42 = sch.split(loop=l6, factors=[v35, v36, v37, v38], preserve_unit_iters=True)
v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[4, 1, 1, 1])
l47, l48, l49, l50 = sch.split(loop=l7, factors=[v43, v44, v45, v46], preserve_unit_iters=True)
v51, v52 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[320, 3])
l53, l54 = sch.split(loop=l8, factors=[v51, v52], preserve_unit_iters=True)
v55, v56 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[1, 1])
l57, l58 = sch.split(loop=l9, factors=[v55, v56], preserve_unit_iters=True)
v59, v60 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 1])
l61, l62 = sch.split(loop=l10, factors=[v59, v60], preserve_unit_iters=True)
sch.reorder(l15, l23, l31, l39, l47, l16, l24, l32, l40, l48, l53, l57, l61, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50)
b63, = sch.get_consumers(block=b0)
sch.reverse_compute_at(block=b63, loop=l47, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
sch.enter_postproc()
b65 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b65, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b65, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b65, ann_key="meta_schedule.unroll_explicit")
b66, b67 = sch.get_child_blocks(b65)
l68, l69, l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93 = sch.get_loops(block=b66)
l94 = sch.fuse(l68, l69, l70, l71, l72, preserve_unit_iters=True)
sch.parallel(loop=l94)
sch.annotate(block_or_loop=l94, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l94, ann_key="pragma_unroll_explicit", ann_val=1)
l95, l96, l97, l98, l99, l100 = sch.get_loops(block=b67)
b101 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l102, l103, l104, l105, l106, l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117, l118, l119, l120, l121, l122, l123 = sch.get_loops(block=b101)
b124 = sch.decompose_reduction(block=b101, loop=l108)
2024-04-28 22:30:43 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #192: GFLOPs: 11.5989. Time: 1299.1314 us. Best GFLOPs: 214.4251
2024-04-28 23:14:59 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-28 23:15:00 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-28 23:15:02 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x38cb4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x529d4d8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x59926a8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x48ec1a8)]: 0 failure(s)
2024-04-28 23:15:02 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-28 23:15:07 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x38cb4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x529d4d8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x59926a8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x48ec1a8)]: 0 failure(s)
2024-04-28 23:15:12 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x38cb4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x529d4d8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x59926a8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x48ec1a8)]: 0 failure(s)
2024-04-28 23:15:18 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x38cb4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x529d4d8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x59926a8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x48ec1a8)]: 0 failure(s)
2024-04-28 23:15:23 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x38cb4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x529d4d8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x59926a8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x48ec1a8)]: 0 failure(s)
2024-04-28 23:15:26 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9934  0.9756  0.9755  0.9662  0.9576  0.9452  0.9362  0.9362  0.9308  0.9281  0.9260  0.9133  0.9050  0.8985  0.8910  0.8903
[17 : 32]:	0.8887  0.8778  0.8759  0.8749  0.8663  0.8649  0.8599  0.8570  0.8511  0.8479  0.8479  0.8380  0.8335  0.8335  0.8324  0.8194
[33 : 48]:	0.8159  0.8055  0.8035  0.8035  0.8018  0.8006  0.7987  0.7901  0.7874  0.7862  0.7823  0.7806  0.7802  0.7792  0.7782  0.7782
[49 : 64]:	0.7779  0.7779  0.7766  0.7715  0.7672  0.7671  0.7660  0.7651  0.7631  0.7631  0.7602  0.7575  0.7564  0.7562  0.7487  0.7464
2024-04-28 23:15:27 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-28 23:15:27 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-28 23:16:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #193: GFLOPs: 101.5872. Time: 148.3305 us. Best GFLOPs: 214.4251
2024-04-28 23:16:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #194: GFLOPs: 232.1693. Time: 64.9030 us. Best GFLOPs: 232.1693
2024-04-28 23:16:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #195: GFLOPs: 167.3067. Time: 90.0650 us. Best GFLOPs: 232.1693
2024-04-28 23:16:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #196: GFLOPs: 177.4309. Time: 84.9259 us. Best GFLOPs: 232.1693
2024-04-28 23:16:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #197: GFLOPs: 178.2199. Time: 84.5499 us. Best GFLOPs: 232.1693
2024-04-28 23:16:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #198: GFLOPs: 177.9762. Time: 84.6657 us. Best GFLOPs: 232.1693
2024-04-28 23:16:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #199: GFLOPs: 186.9210. Time: 80.6142 us. Best GFLOPs: 232.1693
2024-04-28 23:16:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #200: GFLOPs: 192.1851. Time: 78.4061 us. Best GFLOPs: 232.1693
2024-04-28 23:16:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #201: GFLOPs: 186.8784. Time: 80.6326 us. Best GFLOPs: 232.1693
2024-04-28 23:16:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #202: GFLOPs: 209.1327. Time: 72.0522 us. Best GFLOPs: 232.1693
2024-04-28 23:16:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #203: GFLOPs: 233.1004. Time: 64.6437 us. Best GFLOPs: 233.1004
2024-04-28 23:16:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #204: GFLOPs: 184.4394. Time: 81.6988 us. Best GFLOPs: 233.1004
2024-04-28 23:16:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #205: GFLOPs: 173.4716. Time: 86.8642 us. Best GFLOPs: 233.1004
2024-04-28 23:16:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #206: GFLOPs: 222.1386. Time: 67.8337 us. Best GFLOPs: 233.1004
2024-04-28 23:16:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #207: GFLOPs: 163.5604. Time: 92.1279 us. Best GFLOPs: 233.1004
2024-04-28 23:16:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #208: GFLOPs: 171.3046. Time: 87.9631 us. Best GFLOPs: 233.1004
2024-04-28 23:16:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #209: GFLOPs: 178.4503. Time: 84.4408 us. Best GFLOPs: 233.1004
2024-04-28 23:16:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #210: GFLOPs: 146.1295. Time: 103.1173 us. Best GFLOPs: 233.1004
2024-04-28 23:16:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #211: GFLOPs: 232.8736. Time: 64.7067 us. Best GFLOPs: 233.1004
2024-04-28 23:16:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #212: GFLOPs: 152.6860. Time: 98.6893 us. Best GFLOPs: 233.1004
2024-04-28 23:16:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #213: GFLOPs: 169.1427. Time: 89.0874 us. Best GFLOPs: 233.1004
2024-04-28 23:16:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #214: GFLOPs: 162.4303. Time: 92.7689 us. Best GFLOPs: 233.1004
2024-04-28 23:16:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #215: GFLOPs: 184.4805. Time: 81.6806 us. Best GFLOPs: 233.1004
2024-04-28 23:16:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #216: GFLOPs: 184.6669. Time: 81.5982 us. Best GFLOPs: 233.1004
2024-04-28 23:16:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #217: GFLOPs: 83.4964. Time: 180.4686 us. Best GFLOPs: 233.1004
2024-04-28 23:16:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #218: GFLOPs: 209.3443. Time: 71.9794 us. Best GFLOPs: 233.1004
2024-04-28 23:16:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #219: GFLOPs: 218.2303. Time: 69.0485 us. Best GFLOPs: 233.1004
2024-04-28 23:16:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #220: GFLOPs: 158.4094. Time: 95.1236 us. Best GFLOPs: 233.1004
2024-04-28 23:16:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #221: GFLOPs: 156.7049. Time: 96.1583 us. Best GFLOPs: 233.1004
2024-04-28 23:16:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #222: GFLOPs: 74.2452. Time: 202.9557 us. Best GFLOPs: 233.1004
2024-04-28 23:16:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #223: GFLOPs: 174.6327. Time: 86.2867 us. Best GFLOPs: 233.1004
2024-04-28 23:16:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #224: GFLOPs: 169.8728. Time: 88.7045 us. Best GFLOPs: 233.1004
2024-04-28 23:16:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #225: GFLOPs: 222.0052. Time: 67.8744 us. Best GFLOPs: 233.1004
2024-04-28 23:16:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #226: GFLOPs: 146.2442. Time: 103.0364 us. Best GFLOPs: 233.1004
2024-04-28 23:16:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #227: GFLOPs: 208.0517. Time: 72.4266 us. Best GFLOPs: 233.1004
2024-04-28 23:16:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #228: GFLOPs: 207.7675. Time: 72.5257 us. Best GFLOPs: 233.1004
2024-04-28 23:16:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #229: GFLOPs: 181.9793. Time: 82.8032 us. Best GFLOPs: 233.1004
2024-04-28 23:16:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #230: GFLOPs: 190.9884. Time: 78.8973 us. Best GFLOPs: 233.1004
2024-04-28 23:16:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #231: GFLOPs: 213.0680. Time: 70.7215 us. Best GFLOPs: 233.1004
2024-04-28 23:16:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #232: GFLOPs: 98.1314. Time: 153.5540 us. Best GFLOPs: 233.1004
2024-04-28 23:16:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #233: GFLOPs: 175.3246. Time: 85.9462 us. Best GFLOPs: 233.1004
2024-04-28 23:16:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #234: GFLOPs: 176.8880. Time: 85.1866 us. Best GFLOPs: 233.1004
2024-04-28 23:16:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #235: GFLOPs: 124.5970. Time: 120.9378 us. Best GFLOPs: 233.1004
2024-04-28 23:16:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #236: GFLOPs: 213.8957. Time: 70.4478 us. Best GFLOPs: 233.1004
2024-04-28 23:16:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #237: GFLOPs: 161.8852. Time: 93.0813 us. Best GFLOPs: 233.1004
2024-04-28 23:16:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #238: GFLOPs: 176.4351. Time: 85.4052 us. Best GFLOPs: 233.1004
2024-04-28 23:16:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #239: GFLOPs: 212.7966. Time: 70.8117 us. Best GFLOPs: 233.1004
2024-04-28 23:16:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #240: GFLOPs: 212.0304. Time: 71.0675 us. Best GFLOPs: 233.1004
2024-04-28 23:16:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #241: GFLOPs: 176.8661. Time: 85.1971 us. Best GFLOPs: 233.1004
2024-04-28 23:16:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #242: GFLOPs: 169.0340. Time: 89.1447 us. Best GFLOPs: 233.1004
2024-04-28 23:16:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #243: GFLOPs: 199.8703. Time: 75.3913 us. Best GFLOPs: 233.1004
2024-04-28 23:16:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #244: GFLOPs: 146.4523. Time: 102.8900 us. Best GFLOPs: 233.1004
2024-04-28 23:16:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #245: GFLOPs: 139.4090. Time: 108.0883 us. Best GFLOPs: 233.1004
2024-04-28 23:16:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #246: GFLOPs: 218.2907. Time: 69.0294 us. Best GFLOPs: 233.1004
2024-04-28 23:16:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #247: GFLOPs: 162.5225. Time: 92.7163 us. Best GFLOPs: 233.1004
2024-04-28 23:16:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #248: GFLOPs: 224.7765. Time: 67.0376 us. Best GFLOPs: 233.1004
2024-04-28 23:16:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #249: GFLOPs: 118.6053. Time: 127.0472 us. Best GFLOPs: 233.1004
2024-04-28 23:16:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #250: GFLOPs: 163.2508. Time: 92.3027 us. Best GFLOPs: 233.1004
2024-04-28 23:16:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #251: GFLOPs: 218.5723. Time: 68.9405 us. Best GFLOPs: 233.1004
2024-04-28 23:16:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #252: GFLOPs: 164.1620. Time: 91.7903 us. Best GFLOPs: 233.1004
2024-04-28 23:16:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #253: GFLOPs: 175.5617. Time: 85.8301 us. Best GFLOPs: 233.1004
2024-04-28 23:16:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #254: GFLOPs: 36.6274. Time: 411.3986 us. Best GFLOPs: 233.1004
2024-04-28 23:16:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #255: GFLOPs: 34.2764. Time: 439.6167 us. Best GFLOPs: 233.1004
2024-04-28 23:16:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #256: GFLOPs: 22.7626. Time: 661.9837 us. Best GFLOPs: 233.1004
2024-04-28 23:43:50 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-28 23:43:51 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-28 23:43:53 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x38cb4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x529d4d8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x59926a8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x48ec1a8)]: 0 failure(s)
2024-04-28 23:43:53 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-28 23:43:58 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x38cb4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x529d4d8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x59926a8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x48ec1a8)]: 0 failure(s)
2024-04-28 23:44:03 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x38cb4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x529d4d8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x59926a8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x48ec1a8)]: 0 failure(s)
2024-04-28 23:44:09 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x38cb4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x529d4d8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x59926a8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x48ec1a8)]: 0 failure(s)
2024-04-28 23:44:14 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x38cb4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x529d4d8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x59926a8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x48ec1a8)]: 0 failure(s)
2024-04-28 23:44:17 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9932  0.9916  0.9515  0.9407  0.9407  0.9366  0.9315  0.9252  0.9118  0.9029  0.9029  0.9029  0.9020  0.8905  0.8688  0.8688
[17 : 32]:	0.8632  0.8623  0.8596  0.8561  0.8499  0.8499  0.8484  0.8441  0.8441  0.8397  0.8339  0.8313  0.8272  0.8224  0.8213  0.8171
[33 : 48]:	0.8145  0.8129  0.8083  0.8076  0.8020  0.7969  0.7951  0.7945  0.7936  0.7893  0.7893  0.7883  0.7877  0.7874  0.7874  0.7867
[49 : 64]:	0.7853  0.7846  0.7772  0.7750  0.7730  0.7685  0.7651  0.7651  0.7651  0.7651  0.7651  0.7651  0.7623  0.7614  0.7599  0.7559
2024-04-28 23:44:17 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-28 23:44:18 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-28 23:45:37 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #257: GFLOPs: 230.3383. Time: 65.4189 us. Best GFLOPs: 233.1004
2024-04-28 23:45:37 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #258: GFLOPs: 229.2183. Time: 65.7385 us. Best GFLOPs: 233.1004
2024-04-28 23:45:37 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #259: GFLOPs: 165.2305. Time: 91.1967 us. Best GFLOPs: 233.1004
2024-04-28 23:45:37 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #260: GFLOPs: 165.2742. Time: 91.1726 us. Best GFLOPs: 233.1004
2024-04-28 23:45:37 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #261: GFLOPs: 222.6064. Time: 67.6911 us. Best GFLOPs: 233.1004
2024-04-28 23:45:37 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #262: GFLOPs: 187.6403. Time: 80.3051 us. Best GFLOPs: 233.1004
2024-04-28 23:45:37 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #263: GFLOPs: 184.5240. Time: 81.6614 us. Best GFLOPs: 233.1004
2024-04-28 23:45:37 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #264: GFLOPs: 216.9291. Time: 69.4627 us. Best GFLOPs: 233.1004
2024-04-28 23:45:37 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #265: GFLOPs: 120.1219. Time: 125.4432 us. Best GFLOPs: 233.1004
2024-04-28 23:45:37 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #266: GFLOPs: 207.2659. Time: 72.7012 us. Best GFLOPs: 233.1004
2024-04-28 23:45:37 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #267: GFLOPs: 119.7672. Time: 125.8148 us. Best GFLOPs: 233.1004
2024-04-28 23:45:37 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #268: GFLOPs: 120.9815. Time: 124.5519 us. Best GFLOPs: 233.1004
2024-04-28 23:45:37 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #269: GFLOPs: 215.4430. Time: 69.9418 us. Best GFLOPs: 233.1004
2024-04-28 23:45:37 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #270: GFLOPs: 142.4137. Time: 105.8078 us. Best GFLOPs: 233.1004
2024-04-28 23:45:37 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #271: GFLOPs: 175.7598. Time: 85.7334 us. Best GFLOPs: 233.1004
2024-04-28 23:45:37 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #272: GFLOPs: 175.8336. Time: 85.6974 us. Best GFLOPs: 233.1004
2024-04-28 23:45:37 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #273: GFLOPs: 197.9632. Time: 76.1176 us. Best GFLOPs: 233.1004
2024-04-28 23:45:37 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #274: GFLOPs: 146.3480. Time: 102.9633 us. Best GFLOPs: 233.1004
2024-04-28 23:45:37 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #275: GFLOPs: 182.9279. Time: 82.3739 us. Best GFLOPs: 233.1004
2024-04-28 23:45:37 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #276: GFLOPs: 196.4969. Time: 76.6856 us. Best GFLOPs: 233.1004
2024-04-28 23:45:37 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #277: GFLOPs: 229.7968. Time: 65.5731 us. Best GFLOPs: 233.1004
2024-04-28 23:45:37 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #278: GFLOPs: 161.3869. Time: 93.3687 us. Best GFLOPs: 233.1004
2024-04-28 23:45:37 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #279: GFLOPs: 225.4046. Time: 66.8508 us. Best GFLOPs: 233.1004
2024-04-28 23:45:37 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #280: GFLOPs: 212.3626. Time: 70.9564 us. Best GFLOPs: 233.1004
2024-04-28 23:45:37 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #281: GFLOPs: 230.3579. Time: 65.4133 us. Best GFLOPs: 233.1004
2024-04-28 23:45:37 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #282: GFLOPs: 170.9059. Time: 88.1683 us. Best GFLOPs: 233.1004
2024-04-28 23:45:37 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #283: GFLOPs: 163.4629. Time: 92.1829 us. Best GFLOPs: 233.1004
2024-04-28 23:45:37 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #284: GFLOPs: 212.4075. Time: 70.9414 us. Best GFLOPs: 233.1004
2024-04-28 23:45:37 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #285: GFLOPs: 219.6986. Time: 68.5870 us. Best GFLOPs: 233.1004
2024-04-28 23:45:37 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #286: GFLOPs: 170.4631. Time: 88.3973 us. Best GFLOPs: 233.1004
2024-04-28 23:45:37 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #287: GFLOPs: 177.4822. Time: 84.9014 us. Best GFLOPs: 233.1004
2024-04-28 23:45:37 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #288: GFLOPs: 206.5010. Time: 72.9705 us. Best GFLOPs: 233.1004
2024-04-28 23:45:37 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #289: GFLOPs: 197.9126. Time: 76.1370 us. Best GFLOPs: 233.1004
2024-04-28 23:45:37 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #290: GFLOPs: 165.7992. Time: 90.8839 us. Best GFLOPs: 233.1004
2024-04-28 23:45:37 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #291: GFLOPs: 58.8461. Time: 256.0660 us. Best GFLOPs: 233.1004
2024-04-28 23:45:37 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #292: GFLOPs: 169.3007. Time: 89.0043 us. Best GFLOPs: 233.1004
2024-04-28 23:45:37 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #293: GFLOPs: 215.7723. Time: 69.8351 us. Best GFLOPs: 233.1004
2024-04-28 23:45:37 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #294: GFLOPs: 207.6040. Time: 72.5828 us. Best GFLOPs: 233.1004
2024-04-28 23:45:37 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #295: GFLOPs: 160.0352. Time: 94.1573 us. Best GFLOPs: 233.1004
2024-04-28 23:45:37 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #296: GFLOPs: 182.4852. Time: 82.5737 us. Best GFLOPs: 233.1004
2024-04-28 23:45:37 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #297: GFLOPs: 205.4890. Time: 73.3299 us. Best GFLOPs: 233.1004
2024-04-28 23:45:37 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #298: GFLOPs: 217.1830. Time: 69.3815 us. Best GFLOPs: 233.1004
2024-04-28 23:45:37 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #299: GFLOPs: 217.3075. Time: 69.3418 us. Best GFLOPs: 233.1004
2024-04-28 23:45:37 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #300: GFLOPs: 124.3351. Time: 121.1925 us. Best GFLOPs: 233.1004
2024-04-28 23:45:37 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #301: GFLOPs: 140.0701. Time: 107.5781 us. Best GFLOPs: 233.1004
2024-04-28 23:45:37 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #302: GFLOPs: 218.0814. Time: 69.0957 us. Best GFLOPs: 233.1004
2024-04-28 23:45:37 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #303: GFLOPs: 216.7567. Time: 69.5180 us. Best GFLOPs: 233.1004
2024-04-28 23:45:37 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #304: GFLOPs: 202.9283. Time: 74.2552 us. Best GFLOPs: 233.1004
2024-04-28 23:45:37 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #305: GFLOPs: 206.4681. Time: 72.9821 us. Best GFLOPs: 233.1004
2024-04-28 23:45:37 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #306: GFLOPs: 167.9761. Time: 89.7061 us. Best GFLOPs: 233.1004
2024-04-28 23:45:37 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #307: GFLOPs: 177.8771. Time: 84.7129 us. Best GFLOPs: 233.1004
2024-04-28 23:45:37 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #308: GFLOPs: 210.5753. Time: 71.5586 us. Best GFLOPs: 233.1004
2024-04-28 23:45:37 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #309: GFLOPs: 88.2675. Time: 170.7139 us. Best GFLOPs: 233.1004
2024-04-28 23:45:37 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #310: GFLOPs: 206.7830. Time: 72.8710 us. Best GFLOPs: 233.1004
2024-04-28 23:45:37 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #311: GFLOPs: 209.3286. Time: 71.9848 us. Best GFLOPs: 233.1004
2024-04-28 23:45:37 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #312: GFLOPs: 208.8806. Time: 72.1392 us. Best GFLOPs: 233.1004
2024-04-28 23:45:37 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #313: GFLOPs: 208.4564. Time: 72.2860 us. Best GFLOPs: 233.1004
2024-04-28 23:45:37 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #314: GFLOPs: 210.6983. Time: 71.5169 us. Best GFLOPs: 233.1004
2024-04-28 23:45:37 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #315: GFLOPs: 210.2864. Time: 71.6569 us. Best GFLOPs: 233.1004
2024-04-28 23:45:37 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #316: GFLOPs: 208.3076. Time: 72.3377 us. Best GFLOPs: 233.1004
2024-04-28 23:45:37 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #317: GFLOPs: 210.3378. Time: 71.6394 us. Best GFLOPs: 233.1004
2024-04-28 23:45:37 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #318: GFLOPs: 23.9533. Time: 629.0766 us. Best GFLOPs: 233.1004
2024-04-28 23:45:37 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #319: GFLOPs: 47.9247. Time: 314.4199 us. Best GFLOPs: 233.1004
2024-04-28 23:45:37 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #320: GFLOPs: 118.1235. Time: 127.5655 us. Best GFLOPs: 233.1004
2024-04-29 00:23:36 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 00:23:36 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-29 00:23:38 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x38cb4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x529d4d8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x59926a8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x48ec1a8)]: 0 failure(s)
2024-04-29 00:23:38 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-29 00:23:43 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x38cb4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x529d4d8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x59926a8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x48ec1a8)]: 0 failure(s)
2024-04-29 00:23:49 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x38cb4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x529d4d8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x59926a8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x48ec1a8)]: 0 failure(s)
2024-04-29 00:23:54 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x38cb4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x529d4d8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x59926a8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x48ec1a8)]: 0 failure(s)
2024-04-29 00:23:59 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x38cb4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x529d4d8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x59926a8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x48ec1a8)]: 0 failure(s)
2024-04-29 00:24:02 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9774  0.9357  0.9142  0.9036  0.8970  0.8923  0.8923  0.8923  0.8923  0.8923  0.8884  0.8868  0.8788  0.8715  0.8711  0.8652
[17 : 32]:	0.8628  0.8623  0.8576  0.8498  0.8464  0.8457  0.8370  0.8370  0.8359  0.8354  0.8335  0.8333  0.8322  0.8290  0.8254  0.8136
[33 : 48]:	0.8135  0.8125  0.8094  0.8086  0.8074  0.8073  0.8040  0.8028  0.8023  0.8021  0.8021  0.8008  0.7982  0.7939  0.7916  0.7910
[49 : 64]:	0.7905  0.7898  0.7885  0.7818  0.7817  0.7759  0.7759  0.7759  0.7759  0.7731  0.7709  0.7675  0.7672  0.7672  0.7655  0.7653
2024-04-29 00:24:03 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 00:24:03 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 00:25:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #321: GFLOPs: 230.3441. Time: 65.4172 us. Best GFLOPs: 233.1004
2024-04-29 00:25:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #322: GFLOPs: 169.7111. Time: 88.7890 us. Best GFLOPs: 233.1004
2024-04-29 00:25:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #323: GFLOPs: 185.1793. Time: 81.3724 us. Best GFLOPs: 233.1004
2024-04-29 00:25:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #324: GFLOPs: 189.2360. Time: 79.6280 us. Best GFLOPs: 233.1004
2024-04-29 00:25:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #325: GFLOPs: 183.2343. Time: 82.2361 us. Best GFLOPs: 233.1004
2024-04-29 00:25:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #326: GFLOPs: 183.9707. Time: 81.9069 us. Best GFLOPs: 233.1004
2024-04-29 00:25:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #327: GFLOPs: 183.7118. Time: 82.0224 us. Best GFLOPs: 233.1004
2024-04-29 00:25:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #328: GFLOPs: 184.3149. Time: 81.7540 us. Best GFLOPs: 233.1004
2024-04-29 00:25:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #329: GFLOPs: 184.0122. Time: 81.8885 us. Best GFLOPs: 233.1004
2024-04-29 00:25:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #330: GFLOPs: 182.9462. Time: 82.3656 us. Best GFLOPs: 233.1004
2024-04-29 00:25:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #331: GFLOPs: 215.8416. Time: 69.8127 us. Best GFLOPs: 233.1004
2024-04-29 00:25:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #332: GFLOPs: 182.5530. Time: 82.5430 us. Best GFLOPs: 233.1004
2024-04-29 00:25:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #333: GFLOPs: 203.7741. Time: 73.9470 us. Best GFLOPs: 233.1004
2024-04-29 00:25:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #334: GFLOPs: 211.3823. Time: 71.2854 us. Best GFLOPs: 233.1004
2024-04-29 00:25:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #335: GFLOPs: 218.7369. Time: 68.8886 us. Best GFLOPs: 233.1004
2024-04-29 00:25:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #336: GFLOPs: 206.3328. Time: 73.0300 us. Best GFLOPs: 233.1004
2024-04-29 00:25:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #337: GFLOPs: 204.8347. Time: 73.5641 us. Best GFLOPs: 233.1004
2024-04-29 00:25:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #338: GFLOPs: 184.0246. Time: 81.8830 us. Best GFLOPs: 233.1004
2024-04-29 00:25:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #339: GFLOPs: 197.0596. Time: 76.4666 us. Best GFLOPs: 233.1004
2024-04-29 00:25:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #340: GFLOPs: 221.3249. Time: 68.0831 us. Best GFLOPs: 233.1004
2024-04-29 00:25:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #341: GFLOPs: 139.0946. Time: 108.3326 us. Best GFLOPs: 233.1004
2024-04-29 00:25:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #342: GFLOPs: 160.8974. Time: 93.6527 us. Best GFLOPs: 233.1004
2024-04-29 00:25:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #343: GFLOPs: 125.6068. Time: 119.9655 us. Best GFLOPs: 233.1004
2024-04-29 00:25:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #344: GFLOPs: 124.0261. Time: 121.4944 us. Best GFLOPs: 233.1004
2024-04-29 00:25:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #345: GFLOPs: 205.3318. Time: 73.3860 us. Best GFLOPs: 233.1004
2024-04-29 00:25:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #346: GFLOPs: 208.4144. Time: 72.3006 us. Best GFLOPs: 233.1004
2024-04-29 00:25:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #347: GFLOPs: 205.6222. Time: 73.2823 us. Best GFLOPs: 233.1004
2024-04-29 00:25:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #348: GFLOPs: 136.9794. Time: 110.0054 us. Best GFLOPs: 233.1004
2024-04-29 00:25:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #349: GFLOPs: 165.9531. Time: 90.7996 us. Best GFLOPs: 233.1004
2024-04-29 00:25:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #350: GFLOPs: 196.6825. Time: 76.6132 us. Best GFLOPs: 233.1004
2024-04-29 00:25:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #351: GFLOPs: 181.0766. Time: 83.2160 us. Best GFLOPs: 233.1004
2024-04-29 00:25:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #352: GFLOPs: 160.9878. Time: 93.6001 us. Best GFLOPs: 233.1004
2024-04-29 00:25:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #353: GFLOPs: 176.1434. Time: 85.5466 us. Best GFLOPs: 233.1004
2024-04-29 00:25:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #354: GFLOPs: 131.4133. Time: 114.6648 us. Best GFLOPs: 233.1004
2024-04-29 00:25:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #355: GFLOPs: 161.7836. Time: 93.1397 us. Best GFLOPs: 233.1004
2024-04-29 00:25:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #356: GFLOPs: 144.4889. Time: 104.2882 us. Best GFLOPs: 233.1004
2024-04-29 00:25:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #357: GFLOPs: 97.1094. Time: 155.1702 us. Best GFLOPs: 233.1004
2024-04-29 00:25:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #358: GFLOPs: 212.9736. Time: 70.7528 us. Best GFLOPs: 233.1004
2024-04-29 00:25:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #359: GFLOPs: 221.5966. Time: 67.9996 us. Best GFLOPs: 233.1004
2024-04-29 00:25:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #360: GFLOPs: 170.1343. Time: 88.5682 us. Best GFLOPs: 233.1004
2024-04-29 00:25:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #361: GFLOPs: 153.1811. Time: 98.3704 us. Best GFLOPs: 233.1004
2024-04-29 00:25:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #362: GFLOPs: 116.8554. Time: 128.9498 us. Best GFLOPs: 233.1004
2024-04-29 00:25:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #363: GFLOPs: 118.2470. Time: 127.4322 us. Best GFLOPs: 233.1004
2024-04-29 00:25:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #364: GFLOPs: 179.5224. Time: 83.9365 us. Best GFLOPs: 233.1004
2024-04-29 00:25:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #365: GFLOPs: 201.4529. Time: 74.7990 us. Best GFLOPs: 233.1004
2024-04-29 00:25:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #366: GFLOPs: 169.1681. Time: 89.0740 us. Best GFLOPs: 233.1004
2024-04-29 00:25:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #367: GFLOPs: 177.3323. Time: 84.9731 us. Best GFLOPs: 233.1004
2024-04-29 00:25:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #368: GFLOPs: 230.6684. Time: 65.3253 us. Best GFLOPs: 233.1004
2024-04-29 00:25:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #369: GFLOPs: 162.6068. Time: 92.6682 us. Best GFLOPs: 233.1004
2024-04-29 00:25:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #370: GFLOPs: 162.0813. Time: 92.9687 us. Best GFLOPs: 233.1004
2024-04-29 00:25:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #371: GFLOPs: 176.9079. Time: 85.1770 us. Best GFLOPs: 233.1004
2024-04-29 00:25:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #372: GFLOPs: 209.5690. Time: 71.9022 us. Best GFLOPs: 233.1004
2024-04-29 00:25:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #373: GFLOPs: 212.0494. Time: 71.0612 us. Best GFLOPs: 233.1004
2024-04-29 00:25:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #374: GFLOPs: 211.6328. Time: 71.2011 us. Best GFLOPs: 233.1004
2024-04-29 00:25:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #375: GFLOPs: 182.5816. Time: 82.5301 us. Best GFLOPs: 233.1004
2024-04-29 00:25:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #376: GFLOPs: 212.5366. Time: 70.8983 us. Best GFLOPs: 233.1004
2024-04-29 00:25:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #377: GFLOPs: 211.9630. Time: 71.0901 us. Best GFLOPs: 233.1004
2024-04-29 00:25:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #378: GFLOPs: 51.0335. Time: 295.2662 us. Best GFLOPs: 233.1004
2024-04-29 00:25:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #379: GFLOPs: 180.1348. Time: 83.6511 us. Best GFLOPs: 233.1004
2024-04-29 00:25:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #380: GFLOPs: 193.6828. Time: 77.7998 us. Best GFLOPs: 233.1004
2024-04-29 00:25:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #381: GFLOPs: 201.4249. Time: 74.8094 us. Best GFLOPs: 233.1004
2024-04-29 00:25:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #382: GFLOPs: 1.2233. Time: 12317.6582 us. Best GFLOPs: 233.1004
2024-04-29 00:25:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #383: GFLOPs: 3.1710. Time: 4751.9139 us. Best GFLOPs: 233.1004
2024-04-29 00:25:44 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #384: GFLOPs: 101.7524. Time: 148.0897 us. Best GFLOPs: 233.1004
2024-04-29 00:58:52 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 00:58:52 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-29 00:58:54 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x38cb4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x529d4d8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x59926a8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x48ec1a8)]: 0 failure(s)
2024-04-29 00:58:54 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-29 00:59:00 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x38cb4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x529d4d8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x59926a8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x48ec1a8)]: 0 failure(s)
2024-04-29 00:59:05 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x38cb4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x529d4d8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x59926a8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x48ec1a8)]: 0 failure(s)
2024-04-29 00:59:10 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x38cb4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x529d4d8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x59926a8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x48ec1a8)]: 0 failure(s)
2024-04-29 00:59:16 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x38cb4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x529d4d8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x59926a8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x48ec1a8)]: 0 failure(s)
2024-04-29 00:59:19 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9954  0.9438  0.9033  0.9033  0.8920  0.8894  0.8869  0.8807  0.8770  0.8768  0.8767  0.8738  0.8730  0.8702  0.8677  0.8677
[17 : 32]:	0.8677  0.8673  0.8655  0.8641  0.8619  0.8619  0.8619  0.8616  0.8602  0.8580  0.8563  0.8563  0.8418  0.8386  0.8348  0.8347
[33 : 48]:	0.8345  0.8334  0.8329  0.8303  0.8303  0.8303  0.8283  0.8271  0.8251  0.8240  0.8229  0.8229  0.8218  0.8217  0.8209  0.8166
[49 : 64]:	0.8103  0.8103  0.8084  0.8042  0.8032  0.8017  0.8013  0.8009  0.7975  0.7975  0.7916  0.7915  0.7910  0.7910  0.7905  0.7902
2024-04-29 00:59:19 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 00:59:19 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 01:01:03 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #385: GFLOPs: 111.1610. Time: 135.5554 us. Best GFLOPs: 233.1004
2024-04-29 01:01:03 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #386: GFLOPs: 166.3068. Time: 90.6065 us. Best GFLOPs: 233.1004
2024-04-29 01:01:03 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #387: GFLOPs: 189.5315. Time: 79.5038 us. Best GFLOPs: 233.1004
2024-04-29 01:01:03 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #388: GFLOPs: 190.9563. Time: 78.9106 us. Best GFLOPs: 233.1004
2024-04-29 01:01:03 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #389: GFLOPs: 182.5180. Time: 82.5589 us. Best GFLOPs: 233.1004
2024-04-29 01:01:03 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #390: GFLOPs: 220.3966. Time: 68.3698 us. Best GFLOPs: 233.1004
2024-04-29 01:01:03 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #391: GFLOPs: 185.4310. Time: 81.2619 us. Best GFLOPs: 233.1004
2024-04-29 01:01:03 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #392: GFLOPs: 117.1036. Time: 128.6765 us. Best GFLOPs: 233.1004
2024-04-29 01:01:03 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #393: GFLOPs: 85.4491. Time: 176.3444 us. Best GFLOPs: 233.1004
2024-04-29 01:01:03 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #394: GFLOPs: 219.0969. Time: 68.7754 us. Best GFLOPs: 233.1004
2024-04-29 01:01:03 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #395: GFLOPs: 223.8568. Time: 67.3130 us. Best GFLOPs: 233.1004
2024-04-29 01:01:03 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #396: GFLOPs: 222.3217. Time: 67.7778 us. Best GFLOPs: 233.1004
2024-04-29 01:01:03 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #397: GFLOPs: 183.0878. Time: 82.3019 us. Best GFLOPs: 233.1004
2024-04-29 01:01:03 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #398: GFLOPs: 199.5981. Time: 75.4941 us. Best GFLOPs: 233.1004
2024-04-29 01:01:03 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #399: GFLOPs: 230.2261. Time: 65.4508 us. Best GFLOPs: 233.1004
2024-04-29 01:01:03 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #400: GFLOPs: 227.9169. Time: 66.1139 us. Best GFLOPs: 233.1004
2024-04-29 01:01:03 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #401: GFLOPs: 226.9724. Time: 66.3890 us. Best GFLOPs: 233.1004
2024-04-29 01:01:03 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #402: GFLOPs: 187.6116. Time: 80.3174 us. Best GFLOPs: 233.1004
2024-04-29 01:01:03 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #403: GFLOPs: 203.7954. Time: 73.9392 us. Best GFLOPs: 233.1004
2024-04-29 01:01:03 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #404: GFLOPs: 172.7539. Time: 87.2251 us. Best GFLOPs: 233.1004
2024-04-29 01:01:03 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #405: GFLOPs: 179.2953. Time: 84.0428 us. Best GFLOPs: 233.1004
2024-04-29 01:01:03 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #406: GFLOPs: 186.9703. Time: 80.5929 us. Best GFLOPs: 233.1004
2024-04-29 01:01:03 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #407: GFLOPs: 204.9331. Time: 73.5288 us. Best GFLOPs: 233.1004
2024-04-29 01:01:03 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #408: GFLOPs: 212.1883. Time: 71.0147 us. Best GFLOPs: 233.1004
2024-04-29 01:01:03 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #409: GFLOPs: 205.4455. Time: 73.3454 us. Best GFLOPs: 233.1004
2024-04-29 01:01:03 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #410: GFLOPs: 165.0005. Time: 91.3238 us. Best GFLOPs: 233.1004
2024-04-29 01:01:03 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #411: GFLOPs: 180.3539. Time: 83.5495 us. Best GFLOPs: 233.1004
2024-04-29 01:01:03 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #412: GFLOPs: 181.7659. Time: 82.9005 us. Best GFLOPs: 233.1004
2024-04-29 01:01:03 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #413: GFLOPs: 138.8640. Time: 108.5125 us. Best GFLOPs: 233.1004
2024-04-29 01:01:03 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #414: GFLOPs: 211.0604. Time: 71.3942 us. Best GFLOPs: 233.1004
2024-04-29 01:01:03 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #415: GFLOPs: 210.6120. Time: 71.5462 us. Best GFLOPs: 233.1004
2024-04-29 01:01:03 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #416: GFLOPs: 201.3393. Time: 74.8412 us. Best GFLOPs: 233.1004
2024-04-29 01:01:03 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #417: GFLOPs: 208.6600. Time: 72.2155 us. Best GFLOPs: 233.1004
2024-04-29 01:01:03 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #418: GFLOPs: 223.1514. Time: 67.5258 us. Best GFLOPs: 233.1004
2024-04-29 01:01:03 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #419: GFLOPs: 161.1978. Time: 93.4782 us. Best GFLOPs: 233.1004
2024-04-29 01:01:03 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #420: GFLOPs: 134.1898. Time: 112.2923 us. Best GFLOPs: 233.1004
2024-04-29 01:01:03 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #421: GFLOPs: 120.4331. Time: 125.1191 us. Best GFLOPs: 233.1004
2024-04-29 01:01:03 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #422: GFLOPs: 130.3579. Time: 115.5931 us. Best GFLOPs: 233.1004
2024-04-29 01:01:03 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #423: GFLOPs: 234.6502. Time: 64.2168 us. Best GFLOPs: 234.6502
2024-04-29 01:01:03 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #424: GFLOPs: 209.8457. Time: 71.8074 us. Best GFLOPs: 234.6502
2024-04-29 01:01:03 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #425: GFLOPs: 216.5890. Time: 69.5718 us. Best GFLOPs: 234.6502
2024-04-29 01:01:03 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #426: GFLOPs: 182.7351. Time: 82.4608 us. Best GFLOPs: 234.6502
2024-04-29 01:01:03 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #427: GFLOPs: 181.7351. Time: 82.9145 us. Best GFLOPs: 234.6502
2024-04-29 01:01:03 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #428: GFLOPs: 182.6337. Time: 82.5066 us. Best GFLOPs: 234.6502
2024-04-29 01:01:03 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #429: GFLOPs: 159.0110. Time: 94.7637 us. Best GFLOPs: 234.6502
2024-04-29 01:01:03 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #430: GFLOPs: 229.1720. Time: 65.7518 us. Best GFLOPs: 234.6502
2024-04-29 01:01:03 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #431: GFLOPs: 192.9250. Time: 78.1054 us. Best GFLOPs: 234.6502
2024-04-29 01:01:03 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #432: GFLOPs: 121.2881. Time: 124.2371 us. Best GFLOPs: 234.6502
2024-04-29 01:01:03 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #433: GFLOPs: 159.5579. Time: 94.4390 us. Best GFLOPs: 234.6502
2024-04-29 01:01:03 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #434: GFLOPs: 158.3620. Time: 95.1521 us. Best GFLOPs: 234.6502
2024-04-29 01:01:03 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #435: GFLOPs: 168.0366. Time: 89.6738 us. Best GFLOPs: 234.6502
2024-04-29 01:01:03 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #436: GFLOPs: 173.9649. Time: 86.6179 us. Best GFLOPs: 234.6502
2024-04-29 01:01:03 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #437: GFLOPs: 228.5093. Time: 65.9425 us. Best GFLOPs: 234.6502
2024-04-29 01:01:03 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #438: GFLOPs: 181.7593. Time: 82.9035 us. Best GFLOPs: 234.6502
2024-04-29 01:01:03 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #439: GFLOPs: 211.1859. Time: 71.3517 us. Best GFLOPs: 234.6502
2024-04-29 01:01:03 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #440: GFLOPs: 207.8268. Time: 72.5050 us. Best GFLOPs: 234.6502
2024-04-29 01:01:03 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #441: GFLOPs: 234.8798. Time: 64.1540 us. Best GFLOPs: 234.8798
2024-04-29 01:01:03 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #442: GFLOPs: 233.6130. Time: 64.5019 us. Best GFLOPs: 234.8798
2024-04-29 01:01:03 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #443: GFLOPs: 148.6581. Time: 101.3633 us. Best GFLOPs: 234.8798
2024-04-29 01:01:03 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #444: GFLOPs: 180.5381. Time: 83.4643 us. Best GFLOPs: 234.8798
2024-04-29 01:01:03 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #445: GFLOPs: 198.9651. Time: 75.7343 us. Best GFLOPs: 234.8798
2024-04-29 01:01:03 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #446: GFLOPs: 130.4645. Time: 115.4987 us. Best GFLOPs: 234.8798
2024-04-29 01:01:03 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #447: GFLOPs: 3.9747. Time: 3791.1190 us. Best GFLOPs: 234.8798
2024-04-29 01:01:03 [INFO] [task_scheduler.cc:121] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #448: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(240), T.int64(7), T.int64(7), T.int64(4)), "float32"), p1: T.Buffer((T.int64(40), T.int64(240), T.int64(1), T.int64(1), T.int64(4), T.int64(4)), "float32"), p2: T.Buffer((T.int64(1), T.int64(40), T.int64(1), T.int64(1), T.int64(4)), "float32"), p3: T.Buffer((T.int64(1), T.int64(40), T.int64(7), T.int64(7), T.int64(4)), "float32"), T_add: T.Buffer((T.int64(1), T.int64(40), T.int64(7), T.int64(7), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(40), T.int64(7), T.int64(7), T.int64(4)))
        for n_0 in T.serial(T.int64(1), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for oc_chunk_0, oh_0, ow_0, oc_block_0 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                    for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(7), T.int64(1), T.int64(1), T.int64(20), T.int64(7), T.int64(1)):
                        for oc_block_3_fused_init in T.vectorized(T.int64(4)):
                            with T.block("conv2d_NCHWc_init"):
                                v_n = T.axis.spatial(T.int64(1), n_0 + n_1 + n_2_init + n_3_init)
                                v_oc_chunk = T.axis.spatial(T.int64(40), oc_chunk_0 * T.int64(40) + oc_chunk_1 * T.int64(40) + oc_chunk_2_init * T.int64(20) + oc_chunk_3_init)
                                v_oh = T.axis.spatial(T.int64(7), oh_0 * T.int64(7) + oh_1 * T.int64(7) + oh_2_init * T.int64(7) + oh_3_init)
                                v_ow = T.axis.spatial(T.int64(7), ow_0 * T.int64(7) + ow_1 * T.int64(7) + ow_2_init + ow_3_init)
                                v_oc_block = T.axis.spatial(T.int64(4), oc_block_0 * T.int64(4) + oc_block_1 * T.int64(4) + oc_block_2_init * T.int64(4) + oc_block_3_fused_init)
                                T.reads()
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                    for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(160), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(7), T.int64(1), T.int64(6), T.int64(1), T.int64(1), T.int64(1), T.int64(20), T.int64(7), T.int64(1)):
                        for oc_block_3_fused in T.vectorized(T.int64(4)):
                            with T.block("conv2d_NCHWc_update"):
                                v_n = T.axis.spatial(T.int64(1), n_0 + n_1 + n_2 + n_3)
                                v_oc_chunk = T.axis.spatial(T.int64(40), oc_chunk_0 * T.int64(40) + oc_chunk_1 * T.int64(40) + oc_chunk_2 * T.int64(20) + oc_chunk_3)
                                v_oh = T.axis.spatial(T.int64(7), oh_0 * T.int64(7) + oh_1 * T.int64(7) + oh_2 * T.int64(7) + oh_3)
                                v_ow = T.axis.spatial(T.int64(7), ow_0 * T.int64(7) + ow_1 * T.int64(7) + ow_2 + ow_3)
                                v_oc_block = T.axis.spatial(T.int64(4), oc_block_0 * T.int64(4) + oc_block_1 * T.int64(4) + oc_block_2 * T.int64(4) + oc_block_3_fused)
                                v_ic = T.axis.reduce(T.int64(960), ic_0 * T.int64(6) + ic_1)
                                v_kh = T.axis.reduce(T.int64(1), kh_0 + kh_1)
                                v_kw = T.axis.reduce(T.int64(1), kw_0 + kw_1)
                                T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], p0[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)], p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block])
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + p0[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)] * p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block]
                for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(40), T.int64(7)):
                    for ax3_ax4_fused in T.vectorized(T.int64(28)):
                        with T.block("T_add_1"):
                            v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                            v_ax3 = T.axis.spatial(T.int64(7), ax3_ax4_fused // T.int64(4))
                            v_ax4 = T.axis.spatial(T.int64(4), ax3_ax4_fused % T.int64(4))
                            T.reads(p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + (conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
b0 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b1 = sch.get_block(name="T_add", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l3, l4, l5, l6, l7, l8, l9, l10 = sch.get_loops(block=b0)
v11, v12, v13, v14 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l15, l16, l17, l18 = sch.split(loop=l3, factors=[v11, v12, v13, v14], preserve_unit_iters=True)
v19, v20, v21, v22 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 2, 20])
l23, l24, l25, l26 = sch.split(loop=l4, factors=[v19, v20, v21, v22], preserve_unit_iters=True)
v27, v28, v29, v30 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 7])
l31, l32, l33, l34 = sch.split(loop=l5, factors=[v27, v28, v29, v30], preserve_unit_iters=True)
v35, v36, v37, v38 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 7, 1])
l39, l40, l41, l42 = sch.split(loop=l6, factors=[v35, v36, v37, v38], preserve_unit_iters=True)
v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 1, 4])
l47, l48, l49, l50 = sch.split(loop=l7, factors=[v43, v44, v45, v46], preserve_unit_iters=True)
v51, v52 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[160, 6])
l53, l54 = sch.split(loop=l8, factors=[v51, v52], preserve_unit_iters=True)
v55, v56 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[1, 1])
l57, l58 = sch.split(loop=l9, factors=[v55, v56], preserve_unit_iters=True)
v59, v60 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 1])
l61, l62 = sch.split(loop=l10, factors=[v59, v60], preserve_unit_iters=True)
sch.reorder(l15, l23, l31, l39, l47, l16, l24, l32, l40, l48, l53, l57, l61, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50)
b63, = sch.get_consumers(block=b0)
sch.reverse_compute_at(block=b63, loop=l47, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
sch.enter_postproc()
b65 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b65, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b65, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b65, ann_key="meta_schedule.unroll_explicit")
b66, b67 = sch.get_child_blocks(b65)
l68, l69, l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93 = sch.get_loops(block=b66)
l94 = sch.fuse(l93, preserve_unit_iters=True)
sch.vectorize(loop=l94)
sch.annotate(block_or_loop=l68, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l68, ann_key="pragma_unroll_explicit", ann_val=1)
l95, l96, l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b67)
l105 = sch.fuse(l103, l104, preserve_unit_iters=True)
sch.vectorize(loop=l105)
b106 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132 = sch.get_loops(block=b106)
b133 = sch.decompose_reduction(block=b106, loop=l117)
2024-04-29 01:55:43 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 01:55:43 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-29 01:55:45 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x38cb4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x529d4d8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x59926a8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x48ec1a8)]: 0 failure(s)
2024-04-29 01:55:45 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-29 01:55:51 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x38cb4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x529d4d8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x59926a8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x48ec1a8)]: 0 failure(s)
2024-04-29 01:55:56 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x38cb4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x529d4d8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x59926a8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x48ec1a8)]: 0 failure(s)
2024-04-29 01:56:01 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x38cb4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x529d4d8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x59926a8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x48ec1a8)]: 0 failure(s)
2024-04-29 01:56:06 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x38cb4f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x529d4d8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x59926a8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x48ec1a8)]: 0 failure(s)
2024-04-29 01:56:09 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9607  0.9145  0.9133  0.9074  0.8844  0.8588  0.8512  0.8429  0.8429  0.8377  0.8377  0.8336  0.8322  0.8311  0.8300  0.8245
[17 : 32]:	0.8240  0.8219  0.8208  0.8099  0.8059  0.8043  0.8028  0.8026  0.8024  0.8011  0.8011  0.8011  0.8009  0.7988  0.7985  0.7937
[33 : 48]:	0.7925  0.7906  0.7883  0.7851  0.7839  0.7817  0.7781  0.7755  0.7700  0.7698  0.7682  0.7681  0.7655  0.7613  0.7582  0.7555
[49 : 64]:	0.7491  0.7459  0.7459  0.7452  0.7396  0.7396  0.7366  0.7365  0.7350  0.7348  0.7340  0.7330  0.7298  0.7298  0.7298  0.7289
2024-04-29 01:56:10 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 01:56:10 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 01:57:57 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #449: GFLOPs: 116.0893. Time: 129.8008 us. Best GFLOPs: 234.8798
2024-04-29 01:57:57 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #450: GFLOPs: 95.4352. Time: 157.8923 us. Best GFLOPs: 234.8798
2024-04-29 01:57:57 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #451: GFLOPs: 231.6186. Time: 65.0573 us. Best GFLOPs: 234.8798
2024-04-29 01:57:57 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #452: GFLOPs: 222.3247. Time: 67.7769 us. Best GFLOPs: 234.8798
2024-04-29 01:57:57 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #453: GFLOPs: 230.7307. Time: 65.3077 us. Best GFLOPs: 234.8798
2024-04-29 01:57:57 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #454: GFLOPs: 131.8981. Time: 114.2433 us. Best GFLOPs: 234.8798
2024-04-29 01:57:57 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #455: GFLOPs: 214.2969. Time: 70.3159 us. Best GFLOPs: 234.8798
2024-04-29 01:57:57 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #456: GFLOPs: 180.7345. Time: 83.3736 us. Best GFLOPs: 234.8798
2024-04-29 01:57:57 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #457: GFLOPs: 209.0222. Time: 72.0903 us. Best GFLOPs: 234.8798
2024-04-29 01:57:57 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #458: GFLOPs: 171.3136. Time: 87.9585 us. Best GFLOPs: 234.8798
2024-04-29 01:57:57 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #459: GFLOPs: 154.5959. Time: 97.4701 us. Best GFLOPs: 234.8798
2024-04-29 01:57:57 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #460: GFLOPs: 222.2797. Time: 67.7906 us. Best GFLOPs: 234.8798
2024-04-29 01:57:57 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #461: GFLOPs: 181.5039. Time: 83.0201 us. Best GFLOPs: 234.8798
2024-04-29 01:57:57 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #462: GFLOPs: 173.1199. Time: 87.0407 us. Best GFLOPs: 234.8798
2024-04-29 01:57:57 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #463: GFLOPs: 162.2950. Time: 92.8462 us. Best GFLOPs: 234.8798
2024-04-29 01:57:57 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #464: GFLOPs: 84.0840. Time: 179.2074 us. Best GFLOPs: 234.8798
2024-04-29 01:57:57 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #465: GFLOPs: 202.6532. Time: 74.3560 us. Best GFLOPs: 234.8798
2024-04-29 01:57:57 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #466: GFLOPs: 186.7198. Time: 80.7010 us. Best GFLOPs: 234.8798
2024-04-29 01:57:57 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #467: GFLOPs: 208.4262. Time: 72.2965 us. Best GFLOPs: 234.8798
2024-04-29 01:57:57 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #468: GFLOPs: 201.5245. Time: 74.7724 us. Best GFLOPs: 234.8798
2024-04-29 01:57:57 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #469: GFLOPs: 195.3199. Time: 77.1477 us. Best GFLOPs: 234.8798
2024-04-29 01:57:57 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #470: GFLOPs: 143.9548. Time: 104.6751 us. Best GFLOPs: 234.8798
2024-04-29 01:57:57 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #471: GFLOPs: 183.0117. Time: 82.3362 us. Best GFLOPs: 234.8798
2024-04-29 01:57:57 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #472: GFLOPs: 199.5202. Time: 75.5236 us. Best GFLOPs: 234.8798
2024-04-29 01:57:57 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #473: GFLOPs: 181.6965. Time: 82.9321 us. Best GFLOPs: 234.8798
2024-04-29 01:57:57 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #474: GFLOPs: 182.5115. Time: 82.5618 us. Best GFLOPs: 234.8798
2024-04-29 01:57:57 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #475: GFLOPs: 182.1409. Time: 82.7298 us. Best GFLOPs: 234.8798
2024-04-29 01:57:57 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #476: GFLOPs: 183.0203. Time: 82.3323 us. Best GFLOPs: 234.8798
2024-04-29 01:57:57 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #477: GFLOPs: 182.8943. Time: 82.3890 us. Best GFLOPs: 234.8798
2024-04-29 01:57:57 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #478: GFLOPs: 198.3484. Time: 75.9698 us. Best GFLOPs: 234.8798
2024-04-29 01:57:57 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #479: GFLOPs: 139.0662. Time: 108.3547 us. Best GFLOPs: 234.8798
2024-04-29 01:57:57 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #480: GFLOPs: 179.0525. Time: 84.1568 us. Best GFLOPs: 234.8798
2024-04-29 01:57:57 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #481: GFLOPs: 157.7416. Time: 95.5263 us. Best GFLOPs: 234.8798
2024-04-29 01:57:57 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #482: GFLOPs: 169.9298. Time: 88.6747 us. Best GFLOPs: 234.8798
2024-04-29 01:57:57 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #483: GFLOPs: 146.3337. Time: 102.9734 us. Best GFLOPs: 234.8798
2024-04-29 01:57:57 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #484: GFLOPs: 185.4384. Time: 81.2587 us. Best GFLOPs: 234.8798
2024-04-29 01:57:57 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #485: GFLOPs: 225.4431. Time: 66.8394 us. Best GFLOPs: 234.8798
2024-04-29 01:57:57 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #486: GFLOPs: 141.6969. Time: 106.3430 us. Best GFLOPs: 234.8798
2024-04-29 01:57:57 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #487: GFLOPs: 176.5562. Time: 85.3467 us. Best GFLOPs: 234.8798
2024-04-29 01:57:57 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #488: GFLOPs: 196.8633. Time: 76.5429 us. Best GFLOPs: 234.8798
2024-04-29 01:57:57 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #489: GFLOPs: 204.3130. Time: 73.7519 us. Best GFLOPs: 234.8798
2024-04-29 01:57:57 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #490: GFLOPs: 104.8070. Time: 143.7735 us. Best GFLOPs: 234.8798
2024-04-29 01:57:57 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #491: GFLOPs: 176.7553. Time: 85.2505 us. Best GFLOPs: 234.8798
2024-04-29 01:57:57 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #492: GFLOPs: 167.1209. Time: 90.1651 us. Best GFLOPs: 234.8798
2024-04-29 01:57:57 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #493: GFLOPs: 134.9345. Time: 111.6726 us. Best GFLOPs: 234.8798
2024-04-29 01:57:57 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #494: GFLOPs: 202.6551. Time: 74.3553 us. Best GFLOPs: 234.8798
2024-04-29 01:57:57 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #495: GFLOPs: 207.5545. Time: 72.6001 us. Best GFLOPs: 234.8798
2024-04-29 01:57:57 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #496: GFLOPs: 207.3563. Time: 72.6695 us. Best GFLOPs: 234.8798
2024-04-29 01:57:57 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #497: GFLOPs: 207.4986. Time: 72.6197 us. Best GFLOPs: 234.8798
2024-04-29 01:57:57 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #498: GFLOPs: 193.0652. Time: 78.0487 us. Best GFLOPs: 234.8798
2024-04-29 01:57:57 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #499: GFLOPs: 191.1647. Time: 78.8246 us. Best GFLOPs: 234.8798
2024-04-29 01:57:57 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #500: GFLOPs: 165.0892. Time: 91.2748 us. Best GFLOPs: 234.8798
2024-04-29 01:57:57 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #501: GFLOPs: 155.4312. Time: 96.9463 us. Best GFLOPs: 234.8798
2024-04-29 01:57:57 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #502: GFLOPs: 165.9440. Time: 90.8046 us. Best GFLOPs: 234.8798
2024-04-29 01:57:57 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #503: GFLOPs: 166.7525. Time: 90.3643 us. Best GFLOPs: 234.8798
2024-04-29 01:57:57 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #504: GFLOPs: 216.5231. Time: 69.5930 us. Best GFLOPs: 234.8798
2024-04-29 01:57:57 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #505: GFLOPs: 177.3929. Time: 84.9441 us. Best GFLOPs: 234.8798
2024-04-29 01:57:57 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #506: GFLOPs: 225.4899. Time: 66.8255 us. Best GFLOPs: 234.8798
2024-04-29 01:57:57 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #507: GFLOPs: 146.8680. Time: 102.5988 us. Best GFLOPs: 234.8798
2024-04-29 01:57:57 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #508: GFLOPs: 178.4578. Time: 84.4372 us. Best GFLOPs: 234.8798
2024-04-29 01:57:57 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #509: GFLOPs: 211.1817. Time: 71.3531 us. Best GFLOPs: 234.8798
2024-04-29 01:57:57 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #510: GFLOPs: 187.8877. Time: 80.1994 us. Best GFLOPs: 234.8798
2024-04-29 01:57:57 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #511: GFLOPs: 28.8681. Time: 521.9760 us. Best GFLOPs: 234.8798
2024-04-29 01:57:57 [INFO] [task_scheduler.cc:131] [Task #26: fused_nn_contrib_conv2d_NCHWc_add_add_4] Trial #512: GFLOPs: 87.1527. Time: 172.8974 us. Best GFLOPs: 234.8798
