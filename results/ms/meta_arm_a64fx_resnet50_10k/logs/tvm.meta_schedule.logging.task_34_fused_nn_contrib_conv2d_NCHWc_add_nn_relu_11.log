2024-04-29 19:38:38 [INFO] [task_scheduler.cc:160] Initializing Task #34: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11"
2024-04-29 19:38:38 [INFO] [task_scheduler.cc:35] 
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(14), T.int64(14), T.int64(128)), "float32"), p1: T.Buffer((T.int64(16), T.int64(2), T.int64(3), T.int64(3), T.int64(128), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(16), T.int64(16), T.int64(128)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)))
        T_add = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)))
        for i0, i1, i2, i3, i4 in T.grid(T.int64(1), T.int64(2), T.int64(16), T.int64(16), T.int64(128)):
            with T.block("data_pad"):
                v_i0, v_i1, v_i2, v_i3, v_i4 = T.axis.remap("SSSSS", [i0, i1, i2, i3, i4])
                T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(15) and T.int64(1) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
        for n, oc_chunk, oh, ow, oc_block, ic, kh, kw in T.grid(T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16), T.int64(256), T.int64(3), T.int64(3)):
            with T.block("conv2d_NCHWc"):
                v_n, v_oc_chunk, v_oh, v_ow, v_oc_block, v_ic, v_kh, v_kw = T.axis.remap("SSSSSRRR", [n, oc_chunk, oh, ow, oc_block, ic, kh, kw])
                T.reads(data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                with T.init():
                    conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
        for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                T.writes(T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4]
        for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)):
            with T.block("T_relu"):
                v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                T.reads(T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
2024-04-29 19:38:39 [INFO] [task_scheduler.cc:164] Total 3 design space(s) generated
2024-04-29 19:38:39 [INFO] [task_scheduler.cc:170] Design space #0:
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(14), T.int64(14), T.int64(128)), "float32"), p1: T.Buffer((T.int64(16), T.int64(2), T.int64(3), T.int64(3), T.int64(128), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel": 768, "meta_schedule.unroll_explicit": 0, "meta_schedule.vectorize": 64})
            data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(16), T.int64(16), T.int64(128)))
            conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)))
            for n_0, oc_chunk_0, oh_0, ow_0 in T.grid(T.int64(1), T.int64(4), T.int64(1), T.int64(2)):
                for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(2), T.int64(16), T.int64(9), T.int64(128)):
                    with T.block("data_pad"):
                        v_i0, v_i1, v_i2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                        v_i3 = T.axis.spatial(T.int64(16), ow_0 * T.int64(7) + ax3)
                        v_i4 = T.axis.spatial(T.int64(128), ax4)
                        T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                        T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                        data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(15) and T.int64(1) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                for oc_block_0, n_1, oc_chunk_1, oh_1, ow_1, oc_block_1, ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(4), T.int64(1), T.int64(4), T.int64(14), T.int64(1), T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(4), T.int64(32), T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc"):
                        v_n = T.axis.spatial(T.int64(1), n_0 + n_1 + n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(16), oc_chunk_0 * T.int64(4) + oc_chunk_1 + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(14), oh_0 * T.int64(14) + oh_1 + oh_2 + oh_3)
                        v_ow = T.axis.spatial(T.int64(14), ow_0 * T.int64(7) + ow_1 * T.int64(7) + ow_2 + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(4) + oc_block_1 * T.int64(4) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(32) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                        T.reads(data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        with T.init():
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)):
                with T.block("T_relu"):
                    v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                    T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                    T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[4, 4, 1, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 14, 1, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[2, 1, 7, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[4, 1, 4, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[8, 32])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
l65 = sch.sample_compute_location(block=b0, decision=3)
sch.compute_at(block=b0, loop=l65, preserve_unit_loops=True, index=-1)
2024-04-29 19:38:39 [INFO] [task_scheduler.cc:170] Design space #1:
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(14), T.int64(14), T.int64(128)), "float32"), p1: T.Buffer((T.int64(16), T.int64(2), T.int64(3), T.int64(3), T.int64(128), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel": 768, "meta_schedule.unroll_explicit": 0, "meta_schedule.vectorize": 64})
            data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(16), T.int64(16), T.int64(128)))
            conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)))
            for n_0, oc_chunk_0, oh_0, ow_0, oc_block_0, n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(4), T.int64(1), T.int64(2), T.int64(4), T.int64(1), T.int64(4), T.int64(14), T.int64(1), T.int64(1)):
                for ic_0 in range(T.int64(8)):
                    for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(3), T.int64(9), T.int64(32)):
                        with T.block("data_pad"):
                            v_i0 = T.axis.spatial(T.int64(1), ax0)
                            v_i1 = T.axis.spatial(T.int64(2), ic_0 // T.int64(4) + ax1)
                            v_i2 = T.axis.spatial(T.int64(16), oh_1 + ax2)
                            v_i3 = T.axis.spatial(T.int64(16), ow_0 * T.int64(7) + ax3)
                            v_i4 = T.axis.spatial(T.int64(128), ic_0 % T.int64(4) * T.int64(32) + ax4)
                            T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                            T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                            data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(15) and T.int64(1) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                    for kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(4), T.int64(32), T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                        with T.block("conv2d_NCHWc"):
                            v_n = T.axis.spatial(T.int64(1), n_0 + n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(16), oc_chunk_0 * T.int64(4) + oc_chunk_1 + oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(14), oh_0 * T.int64(14) + oh_1 + oh_2 + oh_3)
                            v_ow = T.axis.spatial(T.int64(14), ow_0 * T.int64(7) + ow_1 * T.int64(7) + ow_2 + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(4) + oc_block_1 * T.int64(4) + oc_block_2 + oc_block_3)
                            v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(32) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                            T.reads(data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            with T.init():
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
                for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(4)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(16), oc_chunk_0 * T.int64(4) + oc_chunk_1 + ax1)
                        v_ax2 = T.axis.spatial(T.int64(14), oh_1 + ax2)
                        v_ax3 = T.axis.spatial(T.int64(14), ow_0 * T.int64(7) + ax3)
                        v_ax4 = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(4) + ax4)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[4, 4, 1, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 14, 1, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[2, 1, 7, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[4, 1, 4, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[8, 32])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=10)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
2024-04-29 19:38:39 [INFO] [task_scheduler.cc:170] Design space #2:
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(14), T.int64(14), T.int64(128)), "float32"), p1: T.Buffer((T.int64(16), T.int64(2), T.int64(3), T.int64(3), T.int64(128), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel": 768, "meta_schedule.unroll_explicit": 64, "meta_schedule.vectorize": 64})
            data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(16), T.int64(16), T.int64(128)))
            conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)))
            for n_0, oc_chunk_0, oh_0, ow_0, oc_block_0 in T.grid(T.int64(1), T.int64(4), T.int64(1), T.int64(2), T.int64(4)):
                for n_1, oc_chunk_1 in T.grid(T.int64(1), T.int64(4)):
                    for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(2), T.int64(16), T.int64(9), T.int64(128)):
                        with T.block("data_pad"):
                            v_i0, v_i1, v_i2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                            v_i3 = T.axis.spatial(T.int64(16), ow_0 * T.int64(7) + ax3)
                            v_i4 = T.axis.spatial(T.int64(128), ax4)
                            T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                            T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                            data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(15) and T.int64(1) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                    for oh_1, ow_1, oc_block_1, ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(14), T.int64(1), T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(4), T.int64(32), T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                        with T.block("conv2d_NCHWc"):
                            v_n = T.axis.spatial(T.int64(1), n_0 + n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(16), oc_chunk_0 * T.int64(4) + oc_chunk_1 + oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(14), oh_0 * T.int64(14) + oh_1 + oh_2 + oh_3)
                            v_ow = T.axis.spatial(T.int64(14), ow_0 * T.int64(7) + ow_1 * T.int64(7) + ow_2 + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(4) + oc_block_1 * T.int64(4) + oc_block_2 + oc_block_3)
                            v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(32) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                            T.reads(data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            with T.init():
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
                for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(4), T.int64(14), T.int64(7), T.int64(4)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(16), oc_chunk_0 * T.int64(4) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(14), ax2)
                        v_ax3 = T.axis.spatial(T.int64(14), ow_0 * T.int64(7) + ax3)
                        v_ax4 = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(4) + ax4)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[4, 4, 1, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 14, 1, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[2, 1, 7, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[4, 1, 4, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[8, 32])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=6)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
2024-04-29 20:12:36 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 20:12:36 [INFO] [evolutionary_search.cc:715] Picked top 0 candidate(s) from database
2024-04-29 20:12:42 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xcae1558)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x11641818)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x6b93998)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xda39458)]: 0 failure(s)
2024-04-29 20:12:42 [INFO] [evolutionary_search.cc:723] Sampled 512 candidate(s)
2024-04-29 20:12:48 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xcae1558)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x11641818)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x6b93998)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xda39458)]: 0 failure(s)
2024-04-29 20:12:54 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xcae1558)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x11641818)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x6b93998)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xda39458)]: 0 failure(s)
2024-04-29 20:13:00 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xcae1558)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x11641818)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x6b93998)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xda39458)]: 0 failure(s)
2024-04-29 20:13:07 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xcae1558)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x11641818)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x6b93998)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xda39458)]: 0 failure(s)
2024-04-29 20:13:08 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9991  0.9987  0.9970  0.9968  0.9965  0.9961  0.9954  0.9948  0.9947  0.9945  0.9941  0.9939  0.9935  0.9934  0.9930  0.9923
[17 : 32]:	0.9922  0.9915  0.9905  0.9897  0.9894  0.9890  0.9883  0.9881  0.9877  0.9866  0.9862  0.9862  0.9861  0.9856  0.9854  0.9854
[33 : 48]:	0.9854  0.9854  0.9849  0.9844  0.9838  0.9838  0.9831  0.9819  0.9804  0.9798  0.9794  0.9791  0.9784  0.9783  0.9777  0.9752
[49 : 64]:	0.9747  0.9742  0.9726  0.9724  0.9713  0.9705  0.9697  0.9694  0.9686  0.9686  0.9682  0.9678  0.9676  0.9668  0.9665  0.9652
2024-04-29 20:13:08 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 20:13:08 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 20:33:21 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #1: GFLOPs: 20.7132. Time: 11167.3333 us. Best GFLOPs: 20.7132
2024-04-29 20:33:21 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #2: GFLOPs: 13.4374. Time: 17213.9543 us. Best GFLOPs: 20.7132
2024-04-29 20:33:21 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #3: GFLOPs: 22.3220. Time: 10362.4849 us. Best GFLOPs: 22.3220
2024-04-29 20:33:21 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #4: GFLOPs: 34.1103. Time: 6781.2798 us. Best GFLOPs: 34.1103
2024-04-29 20:33:21 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #5: GFLOPs: 6.0294. Time: 38363.7717 us. Best GFLOPs: 34.1103
2024-04-29 20:33:21 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #6: GFLOPs: 44.6058. Time: 5185.6769 us. Best GFLOPs: 44.6058
2024-04-29 20:33:21 [INFO] [task_scheduler.cc:121] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #7: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(14), T.int64(14), T.int64(128)), "float32"), p1: T.Buffer((T.int64(16), T.int64(2), T.int64(3), T.int64(3), T.int64(128), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(16), T.int64(16), T.int64(128)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused in T.parallel(T.int64(8), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(4), T.int64(1), T.int64(7), T.int64(4)):
                for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(2), T.int64(9), T.int64(3), T.int64(128)):
                    with T.block("data_pad"):
                        v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                        v_i2 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(4) * T.int64(7) + ax2)
                        v_i3 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(4) // T.int64(2) * T.int64(7) + ow_1 + ax3)
                        v_i4 = T.axis.spatial(T.int64(128), ax4)
                        T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                        T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                        data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(15) and T.int64(1) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(2), T.int64(7), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(16), oc_chunk_1 * T.int64(4) + oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(4) * T.int64(7) + oh_1 * T.int64(7) + oh_2_init * T.int64(7) + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(4) // T.int64(2) * T.int64(7) + ow_1 + ow_2_init + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(2) * T.int64(8) + oc_block_1 * T.int64(2) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(64), T.int64(1), T.int64(3), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(2), T.int64(4), T.int64(3), T.int64(1), T.int64(1), T.int64(2), T.int64(7), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(16), oc_chunk_1 * T.int64(4) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(4) * T.int64(7) + oh_1 * T.int64(7) + oh_2 * T.int64(7) + oh_3)
                        v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(4) // T.int64(2) * T.int64(7) + ow_1 + ow_2 + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(2) * T.int64(8) + oc_block_1 * T.int64(2) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(4) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(16), T.int64(7), T.int64(7)):
                for ax4_fused in T.vectorized(T.int64(8)):
                    with T.block("T_relu"):
                        v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                        v_ax2 = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(4) * T.int64(7) + ax2)
                        v_ax3 = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(4) // T.int64(2) * T.int64(7) + ax3)
                        v_ax4 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(2) * T.int64(8) + ax4_fused)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 4, 2, 2])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 1, 1, 7])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[2, 7, 1, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[2, 4, 2, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[64, 4])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=9)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85 = sch.get_loops(block=b68)
l86 = sch.fuse(l71, l72, l73, l74, l75, preserve_unit_iters=True)
sch.parallel(loop=l86)
l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107, l108 = sch.get_loops(block=b69)
l109 = sch.fuse(l87, preserve_unit_iters=True)
sch.parallel(loop=l109)
sch.annotate(block_or_loop=l109, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l109, ann_key="pragma_unroll_explicit", ann_val=1)
l110, l111, l112, l113, l114, l115 = sch.get_loops(block=b70)
l116 = sch.fuse(l115, preserve_unit_iters=True)
sch.vectorize(loop=l116)
b117 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139 = sch.get_loops(block=b117)
b140 = sch.decompose_reduction(block=b117, loop=l124)
2024-04-29 20:33:21 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #8: GFLOPs: 13.0053. Time: 17785.9910 us. Best GFLOPs: 44.6058
2024-04-29 20:33:21 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #9: GFLOPs: 89.4561. Time: 2585.7521 us. Best GFLOPs: 89.4561
2024-04-29 20:33:21 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #10: GFLOPs: 4.1291. Time: 56019.4557 us. Best GFLOPs: 89.4561
2024-04-29 20:33:21 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #11: GFLOPs: 2.1458. Time: 107798.1997 us. Best GFLOPs: 89.4561
2024-04-29 20:33:21 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #12: GFLOPs: 14.7637. Time: 15667.5777 us. Best GFLOPs: 89.4561
2024-04-29 20:33:21 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #13: GFLOPs: 0.6273. Time: 368756.9717 us. Best GFLOPs: 89.4561
2024-04-29 20:33:21 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #14: GFLOPs: 56.3315. Time: 4106.2537 us. Best GFLOPs: 89.4561
2024-04-29 20:33:21 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #15: GFLOPs: 72.4637. Time: 3192.0984 us. Best GFLOPs: 89.4561
2024-04-29 20:33:21 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #16: GFLOPs: 192.6339. Time: 1200.7819 us. Best GFLOPs: 192.6339
2024-04-29 20:33:21 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #17: GFLOPs: 8.0250. Time: 28823.9542 us. Best GFLOPs: 192.6339
2024-04-29 20:33:21 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #18: GFLOPs: 56.5787. Time: 4088.3136 us. Best GFLOPs: 192.6339
2024-04-29 20:33:21 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #19: GFLOPs: 122.2242. Time: 1892.5166 us. Best GFLOPs: 192.6339
2024-04-29 20:33:21 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #20: GFLOPs: 10.2203. Time: 22632.5068 us. Best GFLOPs: 192.6339
2024-04-29 20:33:21 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #21: GFLOPs: 26.2164. Time: 8823.1660 us. Best GFLOPs: 192.6339
2024-04-29 20:33:21 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #22: GFLOPs: 11.8190. Time: 19571.0682 us. Best GFLOPs: 192.6339
2024-04-29 20:33:21 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #23: GFLOPs: 36.9579. Time: 6258.7774 us. Best GFLOPs: 192.6339
2024-04-29 20:33:21 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #24: GFLOPs: 111.5452. Time: 2073.7006 us. Best GFLOPs: 192.6339
2024-04-29 20:33:21 [INFO] [task_scheduler.cc:121] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #25: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(14), T.int64(14), T.int64(128)), "float32"), p1: T.Buffer((T.int64(16), T.int64(2), T.int64(3), T.int64(3), T.int64(128), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(16), T.int64(16), T.int64(128)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused in T.parallel(T.int64(196), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(2), T.int64(4), T.int64(4), T.int64(128)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(7) * T.int64(2) + ax2)
                    v_i3 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(98) // T.int64(14) * T.int64(2) + ax3)
                    v_i4 = T.axis.spatial(T.int64(128), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(15) and T.int64(1) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(4)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(8), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(2)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(98) * T.int64(8) + oc_chunk_2_init + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(7) * T.int64(2) + oh_2_init + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(98) // T.int64(14) * T.int64(2) + ow_1 * T.int64(2) + ow_2_init * T.int64(2) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(14) // T.int64(7) * T.int64(8) + oc_block_1 * T.int64(2) + oc_block_2_init * T.int64(2) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(4), T.int64(3), T.int64(1), T.int64(1), T.int64(8), T.int64(2), T.int64(1), T.int64(1), T.int64(64), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(2)):
                    for oc_block_3_fused in T.vectorized(T.int64(2)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(98) * T.int64(8) + oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(7) * T.int64(2) + oh_2 + oh_3)
                            v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(98) // T.int64(14) * T.int64(2) + ow_1 * T.int64(2) + ow_2 * T.int64(2) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(14) // T.int64(7) * T.int64(8) + oc_block_1 * T.int64(2) + oc_block_2 * T.int64(2) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(64) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(8), T.int64(2), T.int64(2)):
                    for ax4_fused in T.vectorized(T.int64(2)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(98) * T.int64(8) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(7) * T.int64(2) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(98) // T.int64(14) * T.int64(2) + ax3)
                            v_ax4 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(14) // T.int64(7) * T.int64(8) + oc_block_1 * T.int64(2) + ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[2, 1, 8, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 7, 2, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[7, 1, 1, 2])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[2, 4, 1, 2])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[4, 64])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=7)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83 = sch.get_loops(block=b68)
l84 = sch.fuse(l71, l72, l73, l74, l75, l76, l77, l78, preserve_unit_iters=True)
sch.parallel(loop=l84)
l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l85, preserve_unit_iters=True)
sch.parallel(loop=l104)
l105 = sch.fuse(l103, preserve_unit_iters=True)
sch.vectorize(loop=l105)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l106, l107, l108, l109, l110, l111, l112, l113 = sch.get_loops(block=b70)
l114 = sch.fuse(l113, preserve_unit_iters=True)
sch.vectorize(loop=l114)
b115 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134 = sch.get_loops(block=b115)
b135 = sch.decompose_reduction(block=b115, loop=l119)
2024-04-29 20:33:21 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #26: GFLOPs: 17.9769. Time: 12867.1694 us. Best GFLOPs: 192.6339
2024-04-29 20:33:21 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #27: GFLOPs: 1.5332. Time: 150870.8793 us. Best GFLOPs: 192.6339
2024-04-29 20:33:21 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #28: GFLOPs: 48.0299. Time: 4815.9916 us. Best GFLOPs: 192.6339
2024-04-29 20:33:21 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #29: GFLOPs: 33.1571. Time: 6976.2143 us. Best GFLOPs: 192.6339
2024-04-29 20:33:21 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #30: GFLOPs: 101.1350. Time: 2287.1543 us. Best GFLOPs: 192.6339
2024-04-29 20:33:21 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #31: GFLOPs: 69.7188. Time: 3317.7756 us. Best GFLOPs: 192.6339
2024-04-29 20:33:21 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #32: GFLOPs: 11.7972. Time: 19607.2452 us. Best GFLOPs: 192.6339
2024-04-29 20:33:21 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #33: GFLOPs: 2.4854. Time: 93069.6197 us. Best GFLOPs: 192.6339
2024-04-29 20:33:21 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #34: GFLOPs: 4.0109. Time: 57670.4353 us. Best GFLOPs: 192.6339
2024-04-29 20:33:21 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #35: GFLOPs: 1.6088. Time: 143778.2577 us. Best GFLOPs: 192.6339
2024-04-29 20:33:21 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #36: GFLOPs: 24.9032. Time: 9288.4191 us. Best GFLOPs: 192.6339
2024-04-29 20:33:21 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #37: GFLOPs: 32.4897. Time: 7119.5379 us. Best GFLOPs: 192.6339
2024-04-29 20:33:21 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #38: GFLOPs: 10.1094. Time: 22880.9082 us. Best GFLOPs: 192.6339
2024-04-29 20:33:21 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #39: GFLOPs: 57.8662. Time: 3997.3470 us. Best GFLOPs: 192.6339
2024-04-29 20:33:21 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #40: GFLOPs: 0.6616. Time: 349611.2760 us. Best GFLOPs: 192.6339
2024-04-29 20:33:21 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #41: GFLOPs: 85.4973. Time: 2705.4810 us. Best GFLOPs: 192.6339
2024-04-29 20:33:21 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #42: GFLOPs: 9.9048. Time: 23353.4892 us. Best GFLOPs: 192.6339
2024-04-29 20:33:21 [INFO] [task_scheduler.cc:121] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #43: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(14), T.int64(14), T.int64(128)), "float32"), p1: T.Buffer((T.int64(16), T.int64(2), T.int64(3), T.int64(3), T.int64(128), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(16), T.int64(16), T.int64(128)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused in T.parallel(T.int64(256), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(2), T.int64(9), T.int64(9), T.int64(128)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(64) // T.int64(32) * T.int64(7) + ax2)
                    v_i3 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(32) // T.int64(16) * T.int64(7) + ax3)
                    v_i4 = T.axis.spatial(T.int64(128), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(15) and T.int64(1) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(4), T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(1)):
                with T.block("conv2d_NCHWc_init"):
                    v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                    v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(64) * T.int64(4) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(16) // T.int64(4) + oc_chunk_2_init + oc_chunk_3_init)
                    v_oh = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(64) // T.int64(32) * T.int64(7) + oh_2_init * T.int64(7) + oh_3_init)
                    v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(32) // T.int64(16) * T.int64(7) + ow_2_init + ow_3_init)
                    v_oc_block = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(4) * T.int64(4) + oc_block_2_init + oc_block_3_init)
                    T.reads()
                    T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                    T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                    conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
            for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(256), T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(1)):
                with T.block("conv2d_NCHWc_update"):
                    v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                    v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(64) * T.int64(4) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(16) // T.int64(4) + oc_chunk_2 + oc_chunk_3)
                    v_oh = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(64) // T.int64(32) * T.int64(7) + oh_2 * T.int64(7) + oh_3)
                    v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(32) // T.int64(16) * T.int64(7) + ow_2 + ow_3)
                    v_oc_block = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(4) * T.int64(4) + oc_block_2 + oc_block_3)
                    v_ic = T.axis.reduce(T.int64(256), ic_0 + ic_1)
                    v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                    v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                    T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                    T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                    T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                    conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
        for ax0_ax1_ax2_ax3_ax4_fused_0 in T.parallel(T.int64(784)):
            for ax0_ax1_ax2_ax3_ax4_fused_1 in T.vectorized(T.int64(64)):
                with T.block("T_relu"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) // T.int64(3136))
                    v_ax2 = T.axis.spatial(T.int64(14), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(3136) // T.int64(224))
                    v_ax3 = T.axis.spatial(T.int64(14), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(224) // T.int64(16))
                    v_ax4 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(16))
                    T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                    T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[4, 4, 1, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 1, 1, 7])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[2, 1, 7, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 4, 4, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[256, 1])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
l65 = sch.sample_compute_location(block=b0, decision=9)
sch.compute_at(block=b0, loop=l65, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b66 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.unroll_explicit")
b67, b68, b69 = sch.get_child_blocks(b66)
l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b67)
l85 = sch.fuse(l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, preserve_unit_iters=True)
sch.parallel(loop=l85)
l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102 = sch.get_loops(block=b68)
l103 = sch.fuse(l86, preserve_unit_iters=True)
sch.parallel(loop=l103)
sch.annotate(block_or_loop=l103, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l103, ann_key="pragma_unroll_explicit", ann_val=1)
l104, l105, l106, l107, l108 = sch.get_loops(block=b69)
l109 = sch.fuse(l104, l105, l106, l107, l108, preserve_unit_iters=True)
l110, l111 = sch.split(loop=l109, factors=[None, 64], preserve_unit_iters=True)
sch.parallel(loop=l110)
sch.vectorize(loop=l111)
b112 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l113, l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129 = sch.get_loops(block=b112)
b130 = sch.decompose_reduction(block=b112, loop=l114)
2024-04-29 20:33:21 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #44: GFLOPs: 12.1454. Time: 19045.1068 us. Best GFLOPs: 192.6339
2024-04-29 20:33:21 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #45: GFLOPs: 38.2128. Time: 6053.2496 us. Best GFLOPs: 192.6339
2024-04-29 20:33:21 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #46: GFLOPs: 5.2509. Time: 44051.4383 us. Best GFLOPs: 192.6339
2024-04-29 20:33:21 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #47: GFLOPs: 100.0392. Time: 2312.2083 us. Best GFLOPs: 192.6339
2024-04-29 20:33:21 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #48: GFLOPs: 16.6504. Time: 13892.2415 us. Best GFLOPs: 192.6339
2024-04-29 20:33:21 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #49: GFLOPs: 21.4188. Time: 10799.4544 us. Best GFLOPs: 192.6339
2024-04-29 20:33:21 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #50: GFLOPs: 15.5715. Time: 14854.7773 us. Best GFLOPs: 192.6339
2024-04-29 20:33:21 [INFO] [task_scheduler.cc:121] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #51: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(14), T.int64(14), T.int64(128)), "float32"), p1: T.Buffer((T.int64(16), T.int64(2), T.int64(3), T.int64(3), T.int64(128), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(16), T.int64(16), T.int64(128)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused in T.parallel(T.int64(392), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(2), T.int64(4), T.int64(3), T.int64(128)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(7) * T.int64(2) + ax2)
                    v_i3 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(196) // T.int64(14) + ax3)
                    v_i4 = T.axis.spatial(T.int64(128), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(15) and T.int64(1) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(196) * T.int64(8) + oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(7) * T.int64(2) + oh_2_init * T.int64(2) + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(196) // T.int64(14) + ow_1 + ow_2_init + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(14) // T.int64(7) * T.int64(8) + oc_block_1 * T.int64(8) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(4), T.int64(3), T.int64(1), T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(8), T.int64(64), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(196) * T.int64(8) + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(7) * T.int64(2) + oh_2 * T.int64(2) + oh_3)
                        v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(196) // T.int64(14) + ow_1 + ow_2 + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(14) // T.int64(7) * T.int64(8) + oc_block_1 * T.int64(8) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(64) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(8), T.int64(2), T.int64(1)):
                    for ax4_fused in T.vectorized(T.int64(8)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(196) * T.int64(8) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(7) * T.int64(2) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(196) // T.int64(14) + ax3)
                            v_ax4 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(14) // T.int64(7) * T.int64(8) + ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[2, 1, 8, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 7, 1, 2])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[14, 1, 1, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[2, 1, 8, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[4, 64])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=7)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83 = sch.get_loops(block=b68)
l84 = sch.fuse(l71, l72, l73, l74, l75, l76, l77, l78, preserve_unit_iters=True)
sch.parallel(loop=l84)
l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l85, preserve_unit_iters=True)
sch.parallel(loop=l104)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109, l110, l111, l112 = sch.get_loops(block=b70)
l113 = sch.fuse(l112, preserve_unit_iters=True)
sch.vectorize(loop=l113)
b114 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133 = sch.get_loops(block=b114)
b134 = sch.decompose_reduction(block=b114, loop=l118)
2024-04-29 20:33:21 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #52: GFLOPs: 53.5639. Time: 4318.4229 us. Best GFLOPs: 192.6339
2024-04-29 20:33:21 [INFO] [task_scheduler.cc:121] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #53: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(14), T.int64(14), T.int64(128)), "float32"), p1: T.Buffer((T.int64(16), T.int64(2), T.int64(3), T.int64(3), T.int64(128), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(16), T.int64(16), T.int64(128)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused in T.parallel(T.int64(1568), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(2)):
                for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(2), T.int64(4), T.int64(3), T.int64(128)):
                    with T.block("data_pad"):
                        v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                        v_i2 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(784) // T.int64(112) * T.int64(2) + ax2)
                        v_i3 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(112) // T.int64(8) + ax3)
                        v_i4 = T.axis.spatial(T.int64(128), ax4)
                        T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                        T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                        data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(15) and T.int64(1) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(4), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(784) * T.int64(8) + oc_chunk_1 * T.int64(4) + oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(784) // T.int64(112) * T.int64(2) + oh_1 * T.int64(2) + oh_2_init + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(112) // T.int64(8) + ow_1 + ow_2_init + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(8) * T.int64(2) + oc_block_1 + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(16), T.int64(3), T.int64(1), T.int64(1), T.int64(4), T.int64(2), T.int64(1), T.int64(1), T.int64(16), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(784) * T.int64(8) + oc_chunk_1 * T.int64(4) + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(784) // T.int64(112) * T.int64(2) + oh_1 * T.int64(2) + oh_2 + oh_3)
                        v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(112) // T.int64(8) + ow_1 + ow_2 + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(8) * T.int64(2) + oc_block_1 + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(16) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
        for ax0_ax1_ax2_ax3_ax4_fused_0 in T.parallel(T.int64(784)):
            for ax0_ax1_ax2_ax3_ax4_fused_1 in T.vectorized(T.int64(64)):
                with T.block("T_relu"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) // T.int64(3136))
                    v_ax2 = T.axis.spatial(T.int64(14), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(3136) // T.int64(224))
                    v_ax3 = T.axis.spatial(T.int64(14), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(224) // T.int64(16))
                    v_ax4 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(16))
                    T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                    T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[2, 2, 4, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[7, 1, 2, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[14, 1, 1, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[8, 2, 1, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[16, 16])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
l65 = sch.sample_compute_location(block=b0, decision=9)
sch.compute_at(block=b0, loop=l65, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b66 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.unroll_explicit")
b67, b68, b69 = sch.get_child_blocks(b66)
l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b67)
l85 = sch.fuse(l70, l71, l72, l73, l74, preserve_unit_iters=True)
sch.parallel(loop=l85)
l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107 = sch.get_loops(block=b68)
l108 = sch.fuse(l86, preserve_unit_iters=True)
sch.parallel(loop=l108)
sch.annotate(block_or_loop=l108, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l108, ann_key="pragma_unroll_explicit", ann_val=1)
l109, l110, l111, l112, l113 = sch.get_loops(block=b69)
l114 = sch.fuse(l109, l110, l111, l112, l113, preserve_unit_iters=True)
l115, l116 = sch.split(loop=l114, factors=[None, 64], preserve_unit_iters=True)
sch.parallel(loop=l115)
sch.vectorize(loop=l116)
b117 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139 = sch.get_loops(block=b117)
b140 = sch.decompose_reduction(block=b117, loop=l124)
2024-04-29 20:33:21 [INFO] [task_scheduler.cc:121] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #54: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(14), T.int64(14), T.int64(128)), "float32"), p1: T.Buffer((T.int64(16), T.int64(2), T.int64(3), T.int64(3), T.int64(128), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(16), T.int64(16), T.int64(128)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)))
        for n_0_oc_chunk_0_fused_fused in T.parallel(T.int64(2), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(2), T.int64(16), T.int64(16), T.int64(128)):
                with T.block("data_pad"):
                    v_i0, v_i1, v_i2, v_i3, v_i4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(15) and T.int64(1) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oh_0, ow_0, oc_block_0 in T.grid(T.int64(1), T.int64(7), T.int64(8)):
                for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2)):
                    for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(2), T.int64(14), T.int64(2), T.int64(1), T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(1)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_fused_fused * T.int64(8) + oc_chunk_1 * T.int64(8) + oc_chunk_2_init * T.int64(4) + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(14), oh_0 * T.int64(14) + oh_1 * T.int64(14) + oh_2_init + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(14), ow_0 * T.int64(2) + ow_1 * T.int64(2) + ow_2_init + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(2) + oc_block_1 + oc_block_2_init + oc_block_3_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                    for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(64), T.int64(3), T.int64(3), T.int64(1), T.int64(2), T.int64(14), T.int64(2), T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(1)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_fused_fused * T.int64(8) + oc_chunk_1 * T.int64(8) + oc_chunk_2 * T.int64(4) + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(14), oh_0 * T.int64(14) + oh_1 * T.int64(14) + oh_2 + oh_3)
                            v_ow = T.axis.spatial(T.int64(14), ow_0 * T.int64(2) + ow_1 * T.int64(2) + ow_2 + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(2) + oc_block_1 + oc_block_2 + oc_block_3)
                            v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(4) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(8), T.int64(14), T.int64(2)):
                    for ax4_fused in T.vectorized(T.int64(2)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_fused_fused * T.int64(8) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(14), ax2)
                            v_ax3 = T.axis.spatial(T.int64(14), ow_0 * T.int64(2) + ax3)
                            v_ax4 = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(2) + ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[2, 1, 2, 4])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 14, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[7, 1, 2, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[8, 2, 1, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[64, 4])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=1)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77 = sch.get_loops(block=b68)
l78 = sch.fuse(l71, l72, preserve_unit_iters=True)
sch.parallel(loop=l78)
l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l79, preserve_unit_iters=True)
sch.parallel(loop=l104)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109, l110, l111, l112, l113 = sch.get_loops(block=b70)
l114 = sch.fuse(l113, preserve_unit_iters=True)
sch.vectorize(loop=l114)
b115 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140 = sch.get_loops(block=b115)
b141 = sch.decompose_reduction(block=b115, loop=l125)
2024-04-29 20:33:21 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #55: GFLOPs: 54.4958. Time: 4244.5741 us. Best GFLOPs: 192.6339
2024-04-29 20:33:21 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #56: GFLOPs: 32.3526. Time: 7149.6941 us. Best GFLOPs: 192.6339
2024-04-29 20:33:21 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #57: GFLOPs: 109.5220. Time: 2112.0086 us. Best GFLOPs: 192.6339
2024-04-29 20:33:21 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #58: GFLOPs: 12.2085. Time: 18946.6945 us. Best GFLOPs: 192.6339
2024-04-29 20:33:21 [INFO] [task_scheduler.cc:121] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #59: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(14), T.int64(14), T.int64(128)), "float32"), p1: T.Buffer((T.int64(16), T.int64(2), T.int64(3), T.int64(3), T.int64(128), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(16), T.int64(16), T.int64(128)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused in T.parallel(T.int64(56), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(4)):
                for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(2), T.int64(9), T.int64(3), T.int64(128)):
                    with T.block("data_pad"):
                        v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                        v_i2 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(28) * T.int64(7) + ax2)
                        v_i3 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(28) // T.int64(2) + ax3)
                        v_i4 = T.axis.spatial(T.int64(128), ax4)
                        T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                        T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                        data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(15) and T.int64(1) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(2), T.int64(7), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(16), oc_chunk_1 * T.int64(4) + oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(28) * T.int64(7) + oh_1 * T.int64(7) + oh_2_init * T.int64(7) + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(28) // T.int64(2) + ow_1 + ow_2_init + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(2) * T.int64(8) + oc_block_1 * T.int64(2) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(256), T.int64(3), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(3), T.int64(1), T.int64(2), T.int64(7), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(16), oc_chunk_1 * T.int64(4) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(28) * T.int64(7) + oh_1 * T.int64(7) + oh_2 * T.int64(7) + oh_3)
                        v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(28) // T.int64(2) + ow_1 + ow_2 + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(2) * T.int64(8) + oc_block_1 * T.int64(2) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(256), ic_0 + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(16), T.int64(7), T.int64(1)):
                for ax4_fused in T.vectorized(T.int64(8)):
                    with T.block("T_relu"):
                        v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                        v_ax2 = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(28) * T.int64(7) + ax2)
                        v_ax3 = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(28) // T.int64(2) + ax3)
                        v_ax4 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(2) * T.int64(8) + ax4_fused)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 4, 2, 2])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 1, 1, 7])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[14, 1, 1, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[2, 4, 2, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[256, 1])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=9)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85 = sch.get_loops(block=b68)
l86 = sch.fuse(l71, l72, l73, l74, l75, preserve_unit_iters=True)
sch.parallel(loop=l86)
l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107, l108 = sch.get_loops(block=b69)
l109 = sch.fuse(l87, preserve_unit_iters=True)
sch.parallel(loop=l109)
sch.annotate(block_or_loop=l109, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l109, ann_key="pragma_unroll_explicit", ann_val=1)
l110, l111, l112, l113, l114, l115 = sch.get_loops(block=b70)
l116 = sch.fuse(l115, preserve_unit_iters=True)
sch.vectorize(loop=l116)
b117 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139 = sch.get_loops(block=b117)
b140 = sch.decompose_reduction(block=b117, loop=l124)
2024-04-29 20:33:21 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #60: GFLOPs: 16.3159. Time: 14177.0632 us. Best GFLOPs: 192.6339
2024-04-29 20:33:21 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #61: GFLOPs: 86.2841. Time: 2680.8107 us. Best GFLOPs: 192.6339
2024-04-29 20:33:21 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #62: GFLOPs: 41.4700. Time: 5577.8022 us. Best GFLOPs: 192.6339
2024-04-29 20:33:21 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #63: GFLOPs: 29.1170. Time: 7944.2144 us. Best GFLOPs: 192.6339
2024-04-29 20:33:21 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #64: GFLOPs: 1.0394. Time: 222539.0000 us. Best GFLOPs: 192.6339
2024-04-29 20:34:39 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 20:34:40 [INFO] [evolutionary_search.cc:715] Picked top 57 candidate(s) from database
2024-04-29 20:34:45 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xcae1558)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x11641818)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x6b93998)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xda39458)]: 0 failure(s)
2024-04-29 20:34:45 [INFO] [evolutionary_search.cc:723] Sampled 455 candidate(s)
2024-04-29 20:34:57 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xcae1558)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x11641818)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x6b93998)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xda39458)]: 0 failure(s)
2024-04-29 20:35:09 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xcae1558)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x11641818)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x6b93998)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xda39458)]: 0 failure(s)
2024-04-29 20:35:22 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xcae1558)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x11641818)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x6b93998)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xda39458)]: 0 failure(s)
2024-04-29 20:35:36 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xcae1558)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x11641818)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x6b93998)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xda39458)]: 0 failure(s)
2024-04-29 20:35:44 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9711  0.9681  0.9479  0.9479  0.9322  0.9273  0.9256  0.9256  0.9085  0.9078  0.9021  0.9021  0.8926  0.8925  0.8875  0.8845
[17 : 32]:	0.8831  0.8807  0.8668  0.8592  0.8511  0.8469  0.8469  0.8416  0.8409  0.8293  0.8176  0.8153  0.8093  0.8087  0.7980  0.7980
[33 : 48]:	0.7971  0.7961  0.7931  0.7924  0.7813  0.7804  0.7787  0.7780  0.7760  0.7712  0.7707  0.7696  0.7618  0.7593  0.7478  0.7445
[49 : 64]:	0.7429  0.7419  0.7419  0.7419  0.7416  0.7410  0.7405  0.7398  0.7375  0.7361  0.7361  0.7326  0.7316  0.7307  0.7302  0.7302
2024-04-29 20:35:44 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 20:35:44 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 20:37:07 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #65: GFLOPs: 138.8346. Time: 1666.0934 us. Best GFLOPs: 192.6339
2024-04-29 20:37:07 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #66: GFLOPs: 123.1313. Time: 1878.5742 us. Best GFLOPs: 192.6339
2024-04-29 20:37:07 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #67: GFLOPs: 212.2815. Time: 1089.6446 us. Best GFLOPs: 212.2815
2024-04-29 20:37:07 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #68: GFLOPs: 9.8046. Time: 23592.1030 us. Best GFLOPs: 212.2815
2024-04-29 20:37:07 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #69: GFLOPs: 86.9431. Time: 2660.4917 us. Best GFLOPs: 212.2815
2024-04-29 20:37:07 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #70: GFLOPs: 119.7048. Time: 1932.3487 us. Best GFLOPs: 212.2815
2024-04-29 20:37:07 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #71: GFLOPs: 159.8212. Time: 1447.3131 us. Best GFLOPs: 212.2815
2024-04-29 20:37:07 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #72: GFLOPs: 151.3578. Time: 1528.2425 us. Best GFLOPs: 212.2815
2024-04-29 20:37:07 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #73: GFLOPs: 71.7449. Time: 3224.0815 us. Best GFLOPs: 212.2815
2024-04-29 20:37:07 [INFO] [task_scheduler.cc:121] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #74: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(14), T.int64(14), T.int64(128)), "float32"), p1: T.Buffer((T.int64(16), T.int64(2), T.int64(3), T.int64(3), T.int64(128), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(16), T.int64(16), T.int64(128)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused in T.parallel(T.int64(32), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(16), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(2) + oc_chunk_1 + oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(14), oh_1 * T.int64(2) + oh_2_init * T.int64(2) + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(2) * T.int64(7) + ow_1 * T.int64(7) + ow_2_init + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(16), oc_block_1 * T.int64(16) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0 in T.grid(T.int64(4), T.int64(3)):
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(2), T.int64(9)):
                        for ax4_fused in T.vectorized(T.int64(64)):
                            with T.block("data_pad"):
                                v_i0 = T.axis.spatial(T.int64(1), ax0)
                                v_i1 = T.axis.spatial(T.int64(2), ic_0 // T.int64(2) + ax1)
                                v_i2 = T.axis.spatial(T.int64(16), kh_0 + oh_1 * T.int64(2) + ax2)
                                v_i3 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(2) * T.int64(7) + ax3)
                                v_i4 = T.axis.spatial(T.int64(128), ic_0 % T.int64(2) * T.int64(64) + ax4_fused)
                                T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                                T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                                data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(15) and T.int64(1) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                    for kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(16), T.int64(64), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(2) + oc_chunk_1 + oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(14), oh_1 * T.int64(2) + oh_2 * T.int64(2) + oh_3)
                            v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(2) * T.int64(7) + ow_1 * T.int64(7) + ow_2 + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_1 * T.int64(16) + oc_block_2 + oc_block_3)
                            v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(64) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(14), T.int64(7)):
                for ax4_fused in T.vectorized(T.int64(16)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(2) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(14), ax2)
                        v_ax3 = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(2) * T.int64(7) + ax3)
                        v_ax4 = T.axis.spatial(T.int64(16), ax4_fused)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[16, 1, 1, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 7, 1, 2])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[2, 1, 7, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 16, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[4, 64])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=11)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87 = sch.get_loops(block=b68)
l88 = sch.fuse(l71, l72, l73, l74, l75, preserve_unit_iters=True)
sch.parallel(loop=l88)
l89 = sch.fuse(l87, preserve_unit_iters=True)
sch.vectorize(loop=l89)
l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107, l108, l109, l110, l111 = sch.get_loops(block=b69)
l112 = sch.fuse(l90, preserve_unit_iters=True)
sch.parallel(loop=l112)
sch.annotate(block_or_loop=l112, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l112, ann_key="pragma_unroll_explicit", ann_val=1)
l113, l114, l115, l116, l117, l118 = sch.get_loops(block=b70)
l119 = sch.fuse(l118, preserve_unit_iters=True)
sch.vectorize(loop=l119)
b120 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141, l142 = sch.get_loops(block=b120)
b143 = sch.decompose_reduction(block=b120, loop=l127)
2024-04-29 20:37:07 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #75: GFLOPs: 6.8904. Time: 33570.2513 us. Best GFLOPs: 212.2815
2024-04-29 20:37:07 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #76: GFLOPs: 185.7885. Time: 1245.0252 us. Best GFLOPs: 212.2815
2024-04-29 20:37:07 [INFO] [task_scheduler.cc:121] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #77: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(14), T.int64(14), T.int64(128)), "float32"), p1: T.Buffer((T.int64(16), T.int64(2), T.int64(3), T.int64(3), T.int64(128), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(16), T.int64(16), T.int64(128)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused in T.parallel(T.int64(32), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(7), T.int64(7), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(16), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(4) * T.int64(2) + oc_chunk_1 * T.int64(2) + oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(4) // T.int64(2) * T.int64(7) + oh_1 + oh_2_init + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(2) * T.int64(7) + ow_1 + ow_2_init + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(16), oc_block_1 * T.int64(16) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0 in range(T.int64(4)):
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(3), T.int64(3)):
                        for ax4_fused in T.vectorized(T.int64(64)):
                            with T.block("data_pad"):
                                v_i0 = T.axis.spatial(T.int64(1), ax0)
                                v_i1 = T.axis.spatial(T.int64(2), ic_0 // T.int64(2) + ax1)
                                v_i2 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(4) // T.int64(2) * T.int64(7) + oh_1 + ax2)
                                v_i3 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(2) * T.int64(7) + ow_1 + ax3)
                                v_i4 = T.axis.spatial(T.int64(128), ic_0 % T.int64(2) * T.int64(64) + ax4_fused)
                                T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                                T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                                data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(15) and T.int64(1) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                    for kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(16), T.int64(64), T.int64(1), T.int64(3), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(4) * T.int64(2) + oc_chunk_1 * T.int64(2) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(4) // T.int64(2) * T.int64(7) + oh_1 + oh_2 + oh_3)
                            v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(2) * T.int64(7) + ow_1 + ow_2 + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_1 * T.int64(16) + oc_block_2 + oc_block_3)
                            v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(64) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(2), T.int64(7), T.int64(7)):
                for ax4_fused in T.vectorized(T.int64(16)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(4) * T.int64(2) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(4) // T.int64(2) * T.int64(7) + ax2)
                        v_ax3 = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(2) * T.int64(7) + ax3)
                        v_ax4 = T.axis.spatial(T.int64(16), ax4_fused)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[8, 1, 1, 2])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 7, 1, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[2, 7, 1, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 16, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[4, 64])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=10)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86 = sch.get_loops(block=b68)
l87 = sch.fuse(l71, l72, l73, l74, l75, preserve_unit_iters=True)
sch.parallel(loop=l87)
l88 = sch.fuse(l86, preserve_unit_iters=True)
sch.vectorize(loop=l88)
l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107, l108, l109, l110 = sch.get_loops(block=b69)
l111 = sch.fuse(l89, preserve_unit_iters=True)
sch.parallel(loop=l111)
sch.annotate(block_or_loop=l111, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l111, ann_key="pragma_unroll_explicit", ann_val=1)
l112, l113, l114, l115, l116, l117 = sch.get_loops(block=b70)
l118 = sch.fuse(l117, preserve_unit_iters=True)
sch.vectorize(loop=l118)
b119 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141 = sch.get_loops(block=b119)
b142 = sch.decompose_reduction(block=b119, loop=l126)
2024-04-29 20:37:07 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #78: GFLOPs: 120.5560. Time: 1918.7048 us. Best GFLOPs: 212.2815
2024-04-29 20:37:07 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #79: GFLOPs: 214.4665. Time: 1078.5429 us. Best GFLOPs: 214.4665
2024-04-29 20:37:07 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #80: GFLOPs: 62.1786. Time: 3720.1149 us. Best GFLOPs: 214.4665
2024-04-29 20:37:07 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #81: GFLOPs: 67.2785. Time: 3438.1173 us. Best GFLOPs: 214.4665
2024-04-29 20:37:07 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #82: GFLOPs: 63.0417. Time: 3669.1824 us. Best GFLOPs: 214.4665
2024-04-29 20:37:07 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #83: GFLOPs: 149.7588. Time: 1544.5597 us. Best GFLOPs: 214.4665
2024-04-29 20:37:07 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #84: GFLOPs: 74.1259. Time: 3120.5208 us. Best GFLOPs: 214.4665
2024-04-29 20:37:07 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #85: GFLOPs: 89.5000. Time: 2584.4832 us. Best GFLOPs: 214.4665
2024-04-29 20:37:07 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #86: GFLOPs: 118.1691. Time: 1957.4604 us. Best GFLOPs: 214.4665
2024-04-29 20:37:07 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #87: GFLOPs: 149.4082. Time: 1548.1839 us. Best GFLOPs: 214.4665
2024-04-29 20:37:07 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #88: GFLOPs: 99.4140. Time: 2326.7478 us. Best GFLOPs: 214.4665
2024-04-29 20:37:07 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #89: GFLOPs: 90.4099. Time: 2558.4731 us. Best GFLOPs: 214.4665
2024-04-29 20:37:07 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #90: GFLOPs: 67.1398. Time: 3445.2180 us. Best GFLOPs: 214.4665
2024-04-29 20:37:07 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #91: GFLOPs: 172.5233. Time: 1340.7544 us. Best GFLOPs: 214.4665
2024-04-29 20:37:07 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #92: GFLOPs: 155.4903. Time: 1487.6255 us. Best GFLOPs: 214.4665
2024-04-29 20:37:07 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #93: GFLOPs: 43.4732. Time: 5320.7782 us. Best GFLOPs: 214.4665
2024-04-29 20:37:07 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #94: GFLOPs: 107.8819. Time: 2144.1165 us. Best GFLOPs: 214.4665
2024-04-29 20:37:07 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #95: GFLOPs: 76.8760. Time: 3008.8877 us. Best GFLOPs: 214.4665
2024-04-29 20:37:07 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #96: GFLOPs: 68.8523. Time: 3359.5288 us. Best GFLOPs: 214.4665
2024-04-29 20:37:07 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #97: GFLOPs: 166.1900. Time: 1391.8485 us. Best GFLOPs: 214.4665
2024-04-29 20:37:07 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #98: GFLOPs: 85.3704. Time: 2709.5019 us. Best GFLOPs: 214.4665
2024-04-29 20:37:07 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #99: GFLOPs: 80.0988. Time: 2887.8265 us. Best GFLOPs: 214.4665
2024-04-29 20:37:07 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #100: GFLOPs: 119.9462. Time: 1928.4586 us. Best GFLOPs: 214.4665
2024-04-29 20:37:07 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #101: GFLOPs: 61.7848. Time: 3743.8258 us. Best GFLOPs: 214.4665
2024-04-29 20:37:07 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #102: GFLOPs: 62.8472. Time: 3680.5374 us. Best GFLOPs: 214.4665
2024-04-29 20:37:07 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #103: GFLOPs: 137.1523. Time: 1686.5286 us. Best GFLOPs: 214.4665
2024-04-29 20:37:07 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #104: GFLOPs: 62.9565. Time: 3674.1449 us. Best GFLOPs: 214.4665
2024-04-29 20:37:07 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #105: GFLOPs: 165.6120. Time: 1396.7066 us. Best GFLOPs: 214.4665
2024-04-29 20:37:07 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #106: GFLOPs: 75.8840. Time: 3048.2232 us. Best GFLOPs: 214.4665
2024-04-29 20:37:07 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #107: GFLOPs: 51.7484. Time: 4469.9220 us. Best GFLOPs: 214.4665
2024-04-29 20:37:07 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #108: GFLOPs: 9.3919. Time: 24628.8834 us. Best GFLOPs: 214.4665
2024-04-29 20:37:07 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #109: GFLOPs: 192.5946. Time: 1201.0273 us. Best GFLOPs: 214.4665
2024-04-29 20:37:07 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #110: GFLOPs: 139.7341. Time: 1655.3675 us. Best GFLOPs: 214.4665
2024-04-29 20:37:07 [INFO] [task_scheduler.cc:121] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #111: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(14), T.int64(14), T.int64(128)), "float32"), p1: T.Buffer((T.int64(16), T.int64(2), T.int64(3), T.int64(3), T.int64(128), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(16), T.int64(16), T.int64(128)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused in T.parallel(T.int64(784), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(2)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(2), T.int64(1), T.int64(2), T.int64(1), T.int64(1)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(196) * T.int64(4) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(2) * T.int64(2) + oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(196) // T.int64(14) + oh_1 + oh_2_init + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(14) // T.int64(2) * T.int64(2) + ow_1 * T.int64(2) + ow_2_init + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_1 * T.int64(8) + oc_block_2_init * T.int64(4) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0 in T.grid(T.int64(4), T.int64(3)):
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(4)):
                        for ax4_fused in T.vectorized(T.int64(64)):
                            with T.block("data_pad"):
                                v_i0 = T.axis.spatial(T.int64(1), ax0)
                                v_i1 = T.axis.spatial(T.int64(2), ic_0 // T.int64(2) + ax1)
                                v_i2 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(196) // T.int64(14) + kh_0 + ax2)
                                v_i3 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(14) // T.int64(2) * T.int64(2) + ax3)
                                v_i4 = T.axis.spatial(T.int64(128), ic_0 % T.int64(2) * T.int64(64) + ax4_fused)
                                T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                                T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                                data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(15) and T.int64(1) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                    for kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(2), T.int64(64), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1)):
                        for oc_block_3_fused in T.vectorized(T.int64(4)):
                            with T.block("conv2d_NCHWc_update"):
                                v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                                v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(196) * T.int64(4) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(2) * T.int64(2) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                                v_oh = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(196) // T.int64(14) + oh_1 + oh_2 + oh_3)
                                v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(14) // T.int64(2) * T.int64(2) + ow_1 * T.int64(2) + ow_2 + ow_3)
                                v_oc_block = T.axis.spatial(T.int64(16), oc_block_1 * T.int64(8) + oc_block_2 * T.int64(4) + oc_block_3_fused)
                                v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(64) + ic_1)
                                v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                                v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                                T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(2)):
                    for ax4_fused in T.vectorized(T.int64(8)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(196) * T.int64(4) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(2) * T.int64(2) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(196) // T.int64(14) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(14) // T.int64(2) * T.int64(2) + ax3)
                            v_ax4 = T.axis.spatial(T.int64(16), oc_block_1 * T.int64(8) + ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[4, 2, 1, 2])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[14, 1, 1, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[7, 1, 2, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 2, 2, 4])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[4, 64])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=11)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87 = sch.get_loops(block=b68)
l88 = sch.fuse(l71, l72, l73, l74, l75, l76, l77, preserve_unit_iters=True)
sch.parallel(loop=l88)
l89 = sch.fuse(l87, preserve_unit_iters=True)
sch.vectorize(loop=l89)
l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107, l108, l109 = sch.get_loops(block=b69)
l110 = sch.fuse(l90, preserve_unit_iters=True)
sch.parallel(loop=l110)
l111 = sch.fuse(l109, preserve_unit_iters=True)
sch.vectorize(loop=l111)
sch.annotate(block_or_loop=l110, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l110, ann_key="pragma_unroll_explicit", ann_val=1)
l112, l113, l114, l115, l116, l117, l118, l119, l120 = sch.get_loops(block=b70)
l121 = sch.fuse(l120, preserve_unit_iters=True)
sch.vectorize(loop=l121)
b122 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141, l142 = sch.get_loops(block=b122)
b143 = sch.decompose_reduction(block=b122, loop=l127)
2024-04-29 20:37:07 [INFO] [task_scheduler.cc:121] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #112: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(14), T.int64(14), T.int64(128)), "float32"), p1: T.Buffer((T.int64(16), T.int64(2), T.int64(3), T.int64(3), T.int64(128), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(16), T.int64(16), T.int64(128)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused in T.parallel(T.int64(448), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(2), T.int64(1)):
                for oc_block_3_fused_init in T.vectorized(T.int64(4)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(56) * T.int64(2) + oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(14), oh_2_init * T.int64(2) + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(56) // T.int64(4) + ow_2_init + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(4) * T.int64(4) + oc_block_2_init * T.int64(4) + oc_block_3_fused_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
            for ic_0 in range(T.int64(8)):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(16), T.int64(3)):
                    for ax4_fused in T.vectorized(T.int64(32)):
                        with T.block("data_pad"):
                            v_i0 = T.axis.spatial(T.int64(1), ax0)
                            v_i1 = T.axis.spatial(T.int64(2), ic_0 // T.int64(4) + ax1)
                            v_i2 = T.axis.spatial(T.int64(16), ax2)
                            v_i3 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(56) // T.int64(4) + ax3)
                            v_i4 = T.axis.spatial(T.int64(128), ic_0 % T.int64(4) * T.int64(32) + ax4_fused)
                            T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                            T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                            data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(15) and T.int64(1) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                for kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(1), T.int64(32), T.int64(1), T.int64(3), T.int64(1), T.int64(2), T.int64(2), T.int64(1)):
                    for oc_block_3_fused in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(56) * T.int64(2) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(14), oh_2 * T.int64(2) + oh_3)
                            v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(56) // T.int64(4) + ow_2 + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(4) * T.int64(4) + oc_block_2 * T.int64(4) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(32) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(2), T.int64(14), T.int64(1)):
                for ax4_fused in T.vectorized(T.int64(4)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(56) * T.int64(2) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(14), ax2)
                        v_ax3 = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(56) // T.int64(4) + ax3)
                        v_ax4 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(4) * T.int64(4) + ax4_fused)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[8, 1, 1, 2])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 7, 2])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[14, 1, 1, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 4, 1, 4])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[8, 32])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=10)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86 = sch.get_loops(block=b68)
l87 = sch.fuse(l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, preserve_unit_iters=True)
sch.parallel(loop=l87)
l88 = sch.fuse(l86, preserve_unit_iters=True)
sch.vectorize(loop=l88)
l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105 = sch.get_loops(block=b69)
l106 = sch.fuse(l89, preserve_unit_iters=True)
sch.parallel(loop=l106)
l107 = sch.fuse(l105, preserve_unit_iters=True)
sch.vectorize(loop=l107)
sch.annotate(block_or_loop=l106, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l106, ann_key="pragma_unroll_explicit", ann_val=1)
l108, l109, l110, l111, l112, l113 = sch.get_loops(block=b70)
l114 = sch.fuse(l113, preserve_unit_iters=True)
sch.vectorize(loop=l114)
b115 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132 = sch.get_loops(block=b115)
b133 = sch.decompose_reduction(block=b115, loop=l117)
2024-04-29 20:37:07 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #113: GFLOPs: 57.9288. Time: 3993.0285 us. Best GFLOPs: 214.4665
2024-04-29 20:37:07 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #114: GFLOPs: 111.3835. Time: 2076.7108 us. Best GFLOPs: 214.4665
2024-04-29 20:37:07 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #115: GFLOPs: 46.5275. Time: 4971.4974 us. Best GFLOPs: 214.4665
2024-04-29 20:37:07 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #116: GFLOPs: 94.4302. Time: 2449.5493 us. Best GFLOPs: 214.4665
2024-04-29 20:37:07 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #117: GFLOPs: 162.4027. Time: 1424.3077 us. Best GFLOPs: 214.4665
2024-04-29 20:37:07 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #118: GFLOPs: 154.5473. Time: 1496.7030 us. Best GFLOPs: 214.4665
2024-04-29 20:37:07 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #119: GFLOPs: 23.4531. Time: 9862.7273 us. Best GFLOPs: 214.4665
2024-04-29 20:37:07 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #120: GFLOPs: 128.8088. Time: 1795.7736 us. Best GFLOPs: 214.4665
2024-04-29 20:37:07 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #121: GFLOPs: 125.7323. Time: 1839.7132 us. Best GFLOPs: 214.4665
2024-04-29 20:37:07 [INFO] [task_scheduler.cc:121] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #122: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(14), T.int64(14), T.int64(128)), "float32"), p1: T.Buffer((T.int64(16), T.int64(2), T.int64(3), T.int64(3), T.int64(128), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(16), T.int64(16), T.int64(128)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused in T.parallel(T.int64(784), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(2)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(2), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(196) * T.int64(4) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(2) * T.int64(2) + oc_chunk_2_init + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(196) // T.int64(14) + oh_1 + oh_2_init + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(14) // T.int64(2) * T.int64(2) + ow_1 * T.int64(2) + ow_2_init + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_1 * T.int64(8) + oc_block_2_init * T.int64(4) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0 in T.grid(T.int64(4), T.int64(3)):
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(4)):
                        for ax4_fused in T.vectorized(T.int64(64)):
                            with T.block("data_pad"):
                                v_i0 = T.axis.spatial(T.int64(1), ax0)
                                v_i1 = T.axis.spatial(T.int64(2), ic_0 // T.int64(2) + ax1)
                                v_i2 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(196) // T.int64(14) + kh_0 + ax2)
                                v_i3 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(14) // T.int64(2) * T.int64(2) + ax3)
                                v_i4 = T.axis.spatial(T.int64(128), ic_0 % T.int64(2) * T.int64(64) + ax4_fused)
                                T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                                T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                                data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(15) and T.int64(1) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                    for kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(3), T.int64(1), T.int64(2), T.int64(1), T.int64(2), T.int64(2), T.int64(64), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                        for oc_block_3_fused in T.vectorized(T.int64(4)):
                            with T.block("conv2d_NCHWc_update"):
                                v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                                v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(196) * T.int64(4) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(2) * T.int64(2) + oc_chunk_2 + oc_chunk_3)
                                v_oh = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(196) // T.int64(14) + oh_1 + oh_2 + oh_3)
                                v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(14) // T.int64(2) * T.int64(2) + ow_1 * T.int64(2) + ow_2 + ow_3)
                                v_oc_block = T.axis.spatial(T.int64(16), oc_block_1 * T.int64(8) + oc_block_2 * T.int64(4) + oc_block_3_fused)
                                v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(64) + ic_1)
                                v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                                v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                                T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(2)):
                    for ax4_fused in T.vectorized(T.int64(8)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(196) * T.int64(4) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(2) * T.int64(2) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(196) // T.int64(14) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(14) // T.int64(2) * T.int64(2) + ax3)
                            v_ax4 = T.axis.spatial(T.int64(16), oc_block_1 * T.int64(8) + ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[4, 2, 2, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[14, 1, 1, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[7, 1, 2, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 2, 2, 4])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[4, 64])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=11)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87 = sch.get_loops(block=b68)
l88 = sch.fuse(l71, l72, l73, l74, l75, l76, l77, preserve_unit_iters=True)
sch.parallel(loop=l88)
l89 = sch.fuse(l87, preserve_unit_iters=True)
sch.vectorize(loop=l89)
l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107, l108, l109 = sch.get_loops(block=b69)
l110 = sch.fuse(l90, preserve_unit_iters=True)
sch.parallel(loop=l110)
l111 = sch.fuse(l109, preserve_unit_iters=True)
sch.vectorize(loop=l111)
sch.annotate(block_or_loop=l110, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l110, ann_key="pragma_unroll_explicit", ann_val=1)
l112, l113, l114, l115, l116, l117, l118, l119, l120 = sch.get_loops(block=b70)
l121 = sch.fuse(l120, preserve_unit_iters=True)
sch.vectorize(loop=l121)
b122 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141, l142 = sch.get_loops(block=b122)
b143 = sch.decompose_reduction(block=b122, loop=l127)
2024-04-29 20:37:07 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #123: GFLOPs: 62.3780. Time: 3708.2200 us. Best GFLOPs: 214.4665
2024-04-29 20:37:07 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #124: GFLOPs: 177.1778. Time: 1305.5326 us. Best GFLOPs: 214.4665
2024-04-29 20:37:07 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #125: GFLOPs: 104.4454. Time: 2214.6628 us. Best GFLOPs: 214.4665
2024-04-29 20:37:07 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #126: GFLOPs: 42.2315. Time: 5477.2271 us. Best GFLOPs: 214.4665
2024-04-29 20:37:07 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #127: GFLOPs: 6.7473. Time: 34282.1520 us. Best GFLOPs: 214.4665
2024-04-29 20:37:07 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #128: GFLOPs: 91.2932. Time: 2533.7195 us. Best GFLOPs: 214.4665
2024-04-29 20:46:31 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 20:46:33 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-29 20:46:37 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xcae1558)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x11641818)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x6b93998)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xda39458)]: 0 failure(s)
2024-04-29 20:46:37 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-29 20:46:50 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xcae1558)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x11641818)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x6b93998)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xda39458)]: 0 failure(s)
2024-04-29 20:47:03 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xcae1558)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x11641818)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x6b93998)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xda39458)]: 0 failure(s)
2024-04-29 20:47:17 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xcae1558)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x11641818)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x6b93998)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xda39458)]: 0 failure(s)
2024-04-29 20:47:31 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xcae1558)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x11641818)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x6b93998)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xda39458)]: 0 failure(s)
2024-04-29 20:47:39 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9551  0.8770  0.8431  0.8366  0.8002  0.7909  0.7909  0.7878  0.7878  0.7866  0.7811  0.7755  0.7702  0.7681  0.7650  0.7635
[17 : 32]:	0.7624  0.7624  0.7624  0.7592  0.7534  0.7534  0.7522  0.7521  0.7521  0.7517  0.7517  0.7517  0.7514  0.7514  0.7500  0.7444
[33 : 48]:	0.7434  0.7394  0.7394  0.7368  0.7284  0.7254  0.7254  0.7251  0.7251  0.7251  0.7198  0.7198  0.7184  0.7184  0.7172  0.7156
[49 : 64]:	0.7149  0.7136  0.7129  0.7115  0.7098  0.7098  0.7089  0.7089  0.7089  0.7063  0.7061  0.7052  0.7052  0.7045  0.7044  0.7026
2024-04-29 20:47:40 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 20:47:40 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 20:49:01 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #129: GFLOPs: 210.3412. Time: 1099.6959 us. Best GFLOPs: 214.4665
2024-04-29 20:49:01 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #130: GFLOPs: 213.9336. Time: 1081.2298 us. Best GFLOPs: 214.4665
2024-04-29 20:49:01 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #131: GFLOPs: 88.0264. Time: 2627.7493 us. Best GFLOPs: 214.4665
2024-04-29 20:49:01 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #132: GFLOPs: 175.6130. Time: 1317.1651 us. Best GFLOPs: 214.4665
2024-04-29 20:49:01 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #133: GFLOPs: 80.4184. Time: 2876.3489 us. Best GFLOPs: 214.4665
2024-04-29 20:49:01 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #134: GFLOPs: 187.8873. Time: 1231.1177 us. Best GFLOPs: 214.4665
2024-04-29 20:49:01 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #135: GFLOPs: 215.7020. Time: 1072.3654 us. Best GFLOPs: 215.7020
2024-04-29 20:49:01 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #136: GFLOPs: 170.4452. Time: 1357.1012 us. Best GFLOPs: 215.7020
2024-04-29 20:49:01 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #137: GFLOPs: 151.8877. Time: 1522.9106 us. Best GFLOPs: 215.7020
2024-04-29 20:49:01 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #138: GFLOPs: 139.7830. Time: 1654.7892 us. Best GFLOPs: 215.7020
2024-04-29 20:49:01 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #139: GFLOPs: 231.9165. Time: 997.3908 us. Best GFLOPs: 231.9165
2024-04-29 20:49:01 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #140: GFLOPs: 232.4674. Time: 995.0270 us. Best GFLOPs: 232.4674
2024-04-29 20:49:01 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #141: GFLOPs: 465.3296. Time: 497.0914 us. Best GFLOPs: 465.3296
2024-04-29 20:49:01 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #142: GFLOPs: 163.1853. Time: 1417.4765 us. Best GFLOPs: 465.3296
2024-04-29 20:49:01 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #143: GFLOPs: 146.7800. Time: 1575.9049 us. Best GFLOPs: 465.3296
2024-04-29 20:49:01 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #144: GFLOPs: 98.9595. Time: 2337.4353 us. Best GFLOPs: 465.3296
2024-04-29 20:49:01 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #145: GFLOPs: 150.5649. Time: 1536.2901 us. Best GFLOPs: 465.3296
2024-04-29 20:49:01 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #146: GFLOPs: 150.7821. Time: 1534.0772 us. Best GFLOPs: 465.3296
2024-04-29 20:49:01 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #147: GFLOPs: 156.7737. Time: 1475.4474 us. Best GFLOPs: 465.3296
2024-04-29 20:49:01 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #148: GFLOPs: 26.2983. Time: 8795.6809 us. Best GFLOPs: 465.3296
2024-04-29 20:49:01 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #149: GFLOPs: 186.0112. Time: 1243.5346 us. Best GFLOPs: 465.3296
2024-04-29 20:49:01 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #150: GFLOPs: 170.3770. Time: 1357.6441 us. Best GFLOPs: 465.3296
2024-04-29 20:49:01 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #151: GFLOPs: 91.6644. Time: 2523.4578 us. Best GFLOPs: 465.3296
2024-04-29 20:49:01 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #152: GFLOPs: 305.6226. Time: 756.8529 us. Best GFLOPs: 465.3296
2024-04-29 20:49:01 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #153: GFLOPs: 304.7895. Time: 758.9217 us. Best GFLOPs: 465.3296
2024-04-29 20:49:01 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #154: GFLOPs: 150.7207. Time: 1534.7022 us. Best GFLOPs: 465.3296
2024-04-29 20:49:01 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #155: GFLOPs: 317.2970. Time: 729.0057 us. Best GFLOPs: 465.3296
2024-04-29 20:49:01 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #156: GFLOPs: 107.3348. Time: 2155.0457 us. Best GFLOPs: 465.3296
2024-04-29 20:49:01 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #157: GFLOPs: 214.0316. Time: 1080.7348 us. Best GFLOPs: 465.3296
2024-04-29 20:49:01 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #158: GFLOPs: 218.8615. Time: 1056.8847 us. Best GFLOPs: 465.3296
2024-04-29 20:49:01 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #159: GFLOPs: 177.8183. Time: 1300.8298 us. Best GFLOPs: 465.3296
2024-04-29 20:49:01 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #160: GFLOPs: 45.7755. Time: 5053.1648 us. Best GFLOPs: 465.3296
2024-04-29 20:49:01 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #161: GFLOPs: 165.5801. Time: 1396.9760 us. Best GFLOPs: 465.3296
2024-04-29 20:49:01 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #162: GFLOPs: 175.9522. Time: 1314.6258 us. Best GFLOPs: 465.3296
2024-04-29 20:49:01 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #163: GFLOPs: 245.1308. Time: 943.6241 us. Best GFLOPs: 465.3296
2024-04-29 20:49:01 [INFO] [task_scheduler.cc:121] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #164: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(14), T.int64(14), T.int64(128)), "float32"), p1: T.Buffer((T.int64(16), T.int64(2), T.int64(3), T.int64(3), T.int64(128), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(16), T.int64(16), T.int64(128)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused in T.parallel(T.int64(6272), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(2), T.int64(2), T.int64(1), T.int64(1)):
                with T.block("conv2d_NCHWc_init"):
                    v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                    v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(1568) * T.int64(4) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(32) // T.int64(16) * T.int64(2) + oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                    v_oh = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(1568) // T.int64(224) * T.int64(2) + oh_2_init * T.int64(2) + oh_3_init)
                    v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(224) // T.int64(32) * T.int64(2) + ow_2_init + ow_3_init)
                    v_oc_block = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(16) + oc_block_2_init + oc_block_3_init)
                    T.reads()
                    T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                    T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                    conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
            for ic_0, kh_0 in T.grid(T.int64(4), T.int64(3)):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(2), T.int64(4)):
                    for ax4_fused in T.vectorized(T.int64(64)):
                        with T.block("data_pad"):
                            v_i0 = T.axis.spatial(T.int64(1), ax0)
                            v_i1 = T.axis.spatial(T.int64(2), ic_0 // T.int64(2) + ax1)
                            v_i2 = T.axis.spatial(T.int64(16), kh_0 + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(1568) // T.int64(224) * T.int64(2) + ax2)
                            v_i3 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(224) // T.int64(32) * T.int64(2) + ax3)
                            v_i4 = T.axis.spatial(T.int64(128), ic_0 % T.int64(2) * T.int64(64) + ax4_fused)
                            T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                            T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                            data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(15) and T.int64(1) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                for kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(64), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(2), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(1568) * T.int64(4) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(32) // T.int64(16) * T.int64(2) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(1568) // T.int64(224) * T.int64(2) + oh_2 * T.int64(2) + oh_3)
                        v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(224) // T.int64(32) * T.int64(2) + ow_2 + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(16) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(64) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(2), T.int64(2), T.int64(2), T.int64(1)):
                with T.block("T_relu"):
                    v_ax0 = T.axis.spatial(T.int64(1), ax0)
                    v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(1568) * T.int64(4) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(32) // T.int64(16) * T.int64(2) + ax1)
                    v_ax2 = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(1568) // T.int64(224) * T.int64(2) + ax2)
                    v_ax3 = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(224) // T.int64(32) * T.int64(2) + ax3)
                    v_ax4 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(16) + ax4)
                    T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                    T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[4, 2, 1, 2])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[7, 1, 1, 2])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[7, 1, 2, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 16, 1, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[4, 64])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=11)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87 = sch.get_loops(block=b68)
l88 = sch.fuse(l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, preserve_unit_iters=True)
sch.parallel(loop=l88)
l89 = sch.fuse(l87, preserve_unit_iters=True)
sch.vectorize(loop=l89)
l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106 = sch.get_loops(block=b69)
l107 = sch.fuse(l90, preserve_unit_iters=True)
sch.parallel(loop=l107)
sch.annotate(block_or_loop=l107, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l107, ann_key="pragma_unroll_explicit", ann_val=1)
l108, l109, l110, l111, l112, l113 = sch.get_loops(block=b70)
b114 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131 = sch.get_loops(block=b114)
b132 = sch.decompose_reduction(block=b114, loop=l116)
2024-04-29 20:49:01 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #165: GFLOPs: 143.3804. Time: 1613.2708 us. Best GFLOPs: 465.3296
2024-04-29 20:49:01 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #166: GFLOPs: 183.5520. Time: 1260.1952 us. Best GFLOPs: 465.3296
2024-04-29 20:49:01 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #167: GFLOPs: 164.3891. Time: 1407.0965 us. Best GFLOPs: 465.3296
2024-04-29 20:49:01 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #168: GFLOPs: 271.7949. Time: 851.0512 us. Best GFLOPs: 465.3296
2024-04-29 20:49:01 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #169: GFLOPs: 8.8994. Time: 25991.7880 us. Best GFLOPs: 465.3296
2024-04-29 20:49:01 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #170: GFLOPs: 144.0136. Time: 1606.1770 us. Best GFLOPs: 465.3296
2024-04-29 20:49:01 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #171: GFLOPs: 120.1952. Time: 1924.4650 us. Best GFLOPs: 465.3296
2024-04-29 20:49:01 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #172: GFLOPs: 184.9486. Time: 1250.6789 us. Best GFLOPs: 465.3296
2024-04-29 20:49:01 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #173: GFLOPs: 218.4007. Time: 1059.1143 us. Best GFLOPs: 465.3296
2024-04-29 20:49:01 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #174: GFLOPs: 221.3810. Time: 1044.8565 us. Best GFLOPs: 465.3296
2024-04-29 20:49:01 [INFO] [task_scheduler.cc:121] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #175: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(14), T.int64(14), T.int64(128)), "float32"), p1: T.Buffer((T.int64(16), T.int64(2), T.int64(3), T.int64(3), T.int64(128), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(16), T.int64(16), T.int64(128)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused in T.parallel(T.int64(1568), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(2), T.int64(2)):
                for oc_block_3_fused_init in T.vectorized(T.int64(4)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(392) * T.int64(4) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(8) // T.int64(4) * T.int64(2) + oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(392) // T.int64(56) * T.int64(2) + oh_2_init * T.int64(2) + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(56) // T.int64(8) * T.int64(2) + ow_2_init * T.int64(2) + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(4) * T.int64(4) + oc_block_2_init * T.int64(4) + oc_block_3_fused_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
            for ic_0, kh_0 in T.grid(T.int64(4), T.int64(3)):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(2), T.int64(4)):
                    for ax4_fused in T.vectorized(T.int64(64)):
                        with T.block("data_pad"):
                            v_i0 = T.axis.spatial(T.int64(1), ax0)
                            v_i1 = T.axis.spatial(T.int64(2), ic_0 // T.int64(2) + ax1)
                            v_i2 = T.axis.spatial(T.int64(16), kh_0 + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(392) // T.int64(56) * T.int64(2) + ax2)
                            v_i3 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(56) // T.int64(8) * T.int64(2) + ax3)
                            v_i4 = T.axis.spatial(T.int64(128), ic_0 % T.int64(2) * T.int64(64) + ax4_fused)
                            T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                            T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                            data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(15) and T.int64(1) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                for kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(64), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(2), T.int64(2)):
                    for oc_block_3_fused in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(392) * T.int64(4) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(8) // T.int64(4) * T.int64(2) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(392) // T.int64(56) * T.int64(2) + oh_2 * T.int64(2) + oh_3)
                            v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(56) // T.int64(8) * T.int64(2) + ow_2 * T.int64(2) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(4) * T.int64(4) + oc_block_2 * T.int64(4) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(64) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(2), T.int64(2), T.int64(2)):
                for ax4_fused in T.vectorized(T.int64(4)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(392) * T.int64(4) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(8) // T.int64(4) * T.int64(2) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(392) // T.int64(56) * T.int64(2) + ax2)
                        v_ax3 = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(56) // T.int64(8) * T.int64(2) + ax3)
                        v_ax4 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(4) * T.int64(4) + ax4_fused)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[4, 2, 1, 2])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[7, 1, 1, 2])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[7, 1, 1, 2])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 4, 1, 4])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[4, 64])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=11)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87 = sch.get_loops(block=b68)
l88 = sch.fuse(l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, preserve_unit_iters=True)
sch.parallel(loop=l88)
l89 = sch.fuse(l87, preserve_unit_iters=True)
sch.vectorize(loop=l89)
l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106 = sch.get_loops(block=b69)
l107 = sch.fuse(l90, preserve_unit_iters=True)
sch.parallel(loop=l107)
l108 = sch.fuse(l106, preserve_unit_iters=True)
sch.vectorize(loop=l108)
sch.annotate(block_or_loop=l107, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l107, ann_key="pragma_unroll_explicit", ann_val=1)
l109, l110, l111, l112, l113, l114 = sch.get_loops(block=b70)
l115 = sch.fuse(l114, preserve_unit_iters=True)
sch.vectorize(loop=l115)
b116 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133 = sch.get_loops(block=b116)
b134 = sch.decompose_reduction(block=b116, loop=l118)
2024-04-29 20:49:01 [INFO] [task_scheduler.cc:121] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #176: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(14), T.int64(14), T.int64(128)), "float32"), p1: T.Buffer((T.int64(16), T.int64(2), T.int64(3), T.int64(3), T.int64(128), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(16), T.int64(16), T.int64(128)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused in T.parallel(T.int64(224), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(16), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(28) * T.int64(2) + oc_chunk_1 * T.int64(2) + oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(28) // T.int64(14) * T.int64(7) + oh_1 + oh_2_init + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(14) + ow_1 + ow_2_init + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(16), oc_block_1 * T.int64(16) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0 in range(T.int64(4)):
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(3), T.int64(3)):
                        for ax4_fused in T.vectorized(T.int64(64)):
                            with T.block("data_pad"):
                                v_i0 = T.axis.spatial(T.int64(1), ax0)
                                v_i1 = T.axis.spatial(T.int64(2), ic_0 // T.int64(2) + ax1)
                                v_i2 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(28) // T.int64(14) * T.int64(7) + oh_1 + ax2)
                                v_i3 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(14) + ax3)
                                v_i4 = T.axis.spatial(T.int64(128), ic_0 % T.int64(2) * T.int64(64) + ax4_fused)
                                T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                                T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                                data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(15) and T.int64(1) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                    for kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(16), T.int64(64), T.int64(1), T.int64(3), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(28) * T.int64(2) + oc_chunk_1 * T.int64(2) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(28) // T.int64(14) * T.int64(7) + oh_1 + oh_2 + oh_3)
                            v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(14) + ow_1 + ow_2 + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_1 * T.int64(16) + oc_block_2 + oc_block_3)
                            v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(64) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
            for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(2), T.int64(7)):
                for ax3_ax4_fused in T.vectorized(T.int64(16)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(28) * T.int64(2) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(28) // T.int64(14) * T.int64(7) + ax2)
                        v_ax3 = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(14))
                        v_ax4 = T.axis.spatial(T.int64(16), ax3_ax4_fused)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[8, 1, 1, 2])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 7, 1, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[14, 1, 1, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 16, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[4, 64])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=10)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86 = sch.get_loops(block=b68)
l87 = sch.fuse(l71, l72, l73, l74, l75, preserve_unit_iters=True)
sch.parallel(loop=l87)
l88 = sch.fuse(l86, preserve_unit_iters=True)
sch.vectorize(loop=l88)
l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107, l108, l109, l110 = sch.get_loops(block=b69)
l111 = sch.fuse(l89, preserve_unit_iters=True)
sch.parallel(loop=l111)
sch.annotate(block_or_loop=l111, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l111, ann_key="pragma_unroll_explicit", ann_val=1)
l112, l113, l114, l115, l116, l117 = sch.get_loops(block=b70)
l118 = sch.fuse(l116, l117, preserve_unit_iters=True)
sch.vectorize(loop=l118)
b119 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141 = sch.get_loops(block=b119)
b142 = sch.decompose_reduction(block=b119, loop=l126)
2024-04-29 20:49:01 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #177: GFLOPs: 70.1847. Time: 3295.7536 us. Best GFLOPs: 465.3296
2024-04-29 20:49:01 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #178: GFLOPs: 200.0197. Time: 1156.4431 us. Best GFLOPs: 465.3296
2024-04-29 20:49:01 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #179: GFLOPs: 158.5425. Time: 1458.9864 us. Best GFLOPs: 465.3296
2024-04-29 20:49:01 [INFO] [task_scheduler.cc:121] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #180: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(14), T.int64(14), T.int64(128)), "float32"), p1: T.Buffer((T.int64(16), T.int64(2), T.int64(3), T.int64(3), T.int64(128), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(16), T.int64(16), T.int64(128)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused in T.parallel(T.int64(32), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(16), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(4) * T.int64(2) + oc_chunk_1 * T.int64(2) + oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(4) // T.int64(2) * T.int64(7) + oh_1 * T.int64(7) + oh_2_init + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(2) * T.int64(7) + ow_1 + ow_2_init + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(16), oc_block_1 * T.int64(16) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0 in T.grid(T.int64(4), T.int64(3)):
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(7), T.int64(3)):
                        for ax4_fused in T.vectorized(T.int64(64)):
                            with T.block("data_pad"):
                                v_i0 = T.axis.spatial(T.int64(1), ax0)
                                v_i1 = T.axis.spatial(T.int64(2), ic_0 // T.int64(2) + ax1)
                                v_i2 = T.axis.spatial(T.int64(16), kh_0 + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(4) // T.int64(2) * T.int64(7) + ax2)
                                v_i3 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(2) * T.int64(7) + ow_1 + ax3)
                                v_i4 = T.axis.spatial(T.int64(128), ic_0 % T.int64(2) * T.int64(64) + ax4_fused)
                                T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                                T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                                data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(15) and T.int64(1) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                    for kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(16), T.int64(64), T.int64(1), T.int64(3), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(4) * T.int64(2) + oc_chunk_1 * T.int64(2) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(4) // T.int64(2) * T.int64(7) + oh_1 * T.int64(7) + oh_2 + oh_3)
                            v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(2) * T.int64(7) + ow_1 + ow_2 + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_1 * T.int64(16) + oc_block_2 + oc_block_3)
                            v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(64) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(2), T.int64(7), T.int64(7)):
                for ax4_fused in T.vectorized(T.int64(16)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(4) * T.int64(2) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(4) // T.int64(2) * T.int64(7) + ax2)
                        v_ax3 = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(2) * T.int64(7) + ax3)
                        v_ax4 = T.axis.spatial(T.int64(16), ax4_fused)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[8, 1, 1, 2])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 1, 7, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[2, 7, 1, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 16, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[4, 64])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=11)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87 = sch.get_loops(block=b68)
l88 = sch.fuse(l71, l72, l73, l74, l75, preserve_unit_iters=True)
sch.parallel(loop=l88)
l89 = sch.fuse(l87, preserve_unit_iters=True)
sch.vectorize(loop=l89)
l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107, l108, l109, l110, l111 = sch.get_loops(block=b69)
l112 = sch.fuse(l90, preserve_unit_iters=True)
sch.parallel(loop=l112)
sch.annotate(block_or_loop=l112, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l112, ann_key="pragma_unroll_explicit", ann_val=1)
l113, l114, l115, l116, l117, l118 = sch.get_loops(block=b70)
l119 = sch.fuse(l118, preserve_unit_iters=True)
sch.vectorize(loop=l119)
b120 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141, l142 = sch.get_loops(block=b120)
b143 = sch.decompose_reduction(block=b120, loop=l127)
2024-04-29 20:49:01 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #181: GFLOPs: 159.8274. Time: 1447.2574 us. Best GFLOPs: 465.3296
2024-04-29 20:49:01 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #182: GFLOPs: 127.9529. Time: 1807.7847 us. Best GFLOPs: 465.3296
2024-04-29 20:49:01 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #183: GFLOPs: 115.7057. Time: 1999.1355 us. Best GFLOPs: 465.3296
2024-04-29 20:49:01 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #184: GFLOPs: 138.2979. Time: 1672.5585 us. Best GFLOPs: 465.3296
2024-04-29 20:49:01 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #185: GFLOPs: 116.2498. Time: 1989.7790 us. Best GFLOPs: 465.3296
2024-04-29 20:49:01 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #186: GFLOPs: 142.7426. Time: 1620.4784 us. Best GFLOPs: 465.3296
2024-04-29 20:49:01 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #187: GFLOPs: 134.4617. Time: 1720.2770 us. Best GFLOPs: 465.3296
2024-04-29 20:49:01 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #188: GFLOPs: 116.2736. Time: 1989.3715 us. Best GFLOPs: 465.3296
2024-04-29 20:49:01 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #189: GFLOPs: 123.9213. Time: 1866.5991 us. Best GFLOPs: 465.3296
2024-04-29 20:49:01 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #190: GFLOPs: 14.8827. Time: 15542.2771 us. Best GFLOPs: 465.3296
2024-04-29 20:49:01 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #191: GFLOPs: 138.3639. Time: 1671.7610 us. Best GFLOPs: 465.3296
2024-04-29 20:49:01 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #192: GFLOPs: 2.6690. Time: 86665.7207 us. Best GFLOPs: 465.3296
2024-04-29 21:23:31 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 21:23:33 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-29 21:23:37 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xcae1558)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x11641818)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x6b93998)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xda39458)]: 0 failure(s)
2024-04-29 21:23:37 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-29 21:23:50 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xcae1558)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x11641818)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x6b93998)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xda39458)]: 0 failure(s)
2024-04-29 21:24:04 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xcae1558)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x11641818)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x6b93998)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xda39458)]: 0 failure(s)
2024-04-29 21:24:18 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xcae1558)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x11641818)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x6b93998)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xda39458)]: 0 failure(s)
2024-04-29 21:24:32 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xcae1558)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x11641818)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x6b93998)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xda39458)]: 0 failure(s)
2024-04-29 21:24:40 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9666  0.9666  0.9572  0.9572  0.9511  0.9483  0.9483  0.9483  0.9417  0.9328  0.9328  0.9234  0.9132  0.9132  0.9132  0.9132
[17 : 32]:	0.9132  0.9132  0.7871  0.7739  0.7689  0.7422  0.7422  0.7327  0.7220  0.7196  0.6941  0.6930  0.6831  0.6829  0.6814  0.6806
[33 : 48]:	0.6486  0.6486  0.6385  0.6385  0.6359  0.6333  0.6165  0.6165  0.6112  0.6111  0.6111  0.6110  0.6084  0.6064  0.6044  0.5971
[49 : 64]:	0.5944  0.5922  0.5890  0.5890  0.5887  0.5887  0.5856  0.5708  0.5708  0.5706  0.5706  0.5688  0.5639  0.5601  0.5601  0.5598
2024-04-29 21:24:41 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 21:24:41 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 21:26:08 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #193: GFLOPs: 434.1486. Time: 532.7930 us. Best GFLOPs: 465.3296
2024-04-29 21:26:08 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #194: GFLOPs: 503.1563. Time: 459.7207 us. Best GFLOPs: 503.1563
2024-04-29 21:26:08 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #195: GFLOPs: 208.4401. Time: 1109.7257 us. Best GFLOPs: 503.1563
2024-04-29 21:26:08 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #196: GFLOPs: 196.9935. Time: 1174.2083 us. Best GFLOPs: 503.1563
2024-04-29 21:26:08 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #197: GFLOPs: 184.9992. Time: 1250.3372 us. Best GFLOPs: 503.1563
2024-04-29 21:26:08 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #198: GFLOPs: 504.2363. Time: 458.7360 us. Best GFLOPs: 504.2363
2024-04-29 21:26:08 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #199: GFLOPs: 143.3149. Time: 1614.0076 us. Best GFLOPs: 504.2363
2024-04-29 21:26:08 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #200: GFLOPs: 190.2095. Time: 1216.0876 us. Best GFLOPs: 504.2363
2024-04-29 21:26:08 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #201: GFLOPs: 158.5498. Time: 1458.9197 us. Best GFLOPs: 504.2363
2024-04-29 21:26:08 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #202: GFLOPs: 175.1836. Time: 1320.3936 us. Best GFLOPs: 504.2363
2024-04-29 21:26:08 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #203: GFLOPs: 183.2818. Time: 1262.0533 us. Best GFLOPs: 504.2363
2024-04-29 21:26:08 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #204: GFLOPs: 170.3748. Time: 1357.6615 us. Best GFLOPs: 504.2363
2024-04-29 21:26:08 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #205: GFLOPs: 466.2532. Time: 496.1067 us. Best GFLOPs: 504.2363
2024-04-29 21:26:08 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #206: GFLOPs: 461.5299. Time: 501.1839 us. Best GFLOPs: 504.2363
2024-04-29 21:26:08 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #207: GFLOPs: 436.8363. Time: 529.5150 us. Best GFLOPs: 504.2363
2024-04-29 21:26:08 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #208: GFLOPs: 504.5484. Time: 458.4523 us. Best GFLOPs: 504.5484
2024-04-29 21:26:08 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #209: GFLOPs: 439.0889. Time: 526.7985 us. Best GFLOPs: 504.5484
2024-04-29 21:26:08 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #210: GFLOPs: 401.3077. Time: 576.3940 us. Best GFLOPs: 504.5484
2024-04-29 21:26:08 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #211: GFLOPs: 602.6207. Time: 383.8424 us. Best GFLOPs: 602.6207
2024-04-29 21:26:08 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #212: GFLOPs: 186.2435. Time: 1241.9833 us. Best GFLOPs: 602.6207
2024-04-29 21:26:08 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #213: GFLOPs: 145.4730. Time: 1590.0641 us. Best GFLOPs: 602.6207
2024-04-29 21:26:08 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #214: GFLOPs: 501.1544. Time: 461.5571 us. Best GFLOPs: 602.6207
2024-04-29 21:26:08 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #215: GFLOPs: 178.0863. Time: 1298.8726 us. Best GFLOPs: 602.6207
2024-04-29 21:26:08 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #216: GFLOPs: 155.9693. Time: 1483.0567 us. Best GFLOPs: 602.6207
2024-04-29 21:26:08 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #217: GFLOPs: 148.7703. Time: 1554.8227 us. Best GFLOPs: 602.6207
2024-04-29 21:26:08 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #218: GFLOPs: 349.1444. Time: 662.5091 us. Best GFLOPs: 602.6207
2024-04-29 21:26:08 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #219: GFLOPs: 168.4944. Time: 1372.8133 us. Best GFLOPs: 602.6207
2024-04-29 21:26:08 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #220: GFLOPs: 231.4896. Time: 999.2299 us. Best GFLOPs: 602.6207
2024-04-29 21:26:08 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #221: GFLOPs: 247.2394. Time: 935.5766 us. Best GFLOPs: 602.6207
2024-04-29 21:26:08 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #222: GFLOPs: 194.9873. Time: 1186.2891 us. Best GFLOPs: 602.6207
2024-04-29 21:26:08 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #223: GFLOPs: 358.0237. Time: 646.0784 us. Best GFLOPs: 602.6207
2024-04-29 21:26:08 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #224: GFLOPs: 144.0130. Time: 1606.1842 us. Best GFLOPs: 602.6207
2024-04-29 21:26:08 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #225: GFLOPs: 304.2794. Time: 760.1939 us. Best GFLOPs: 602.6207
2024-04-29 21:26:08 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #226: GFLOPs: 303.8022. Time: 761.3880 us. Best GFLOPs: 602.6207
2024-04-29 21:26:08 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #227: GFLOPs: 183.9119. Time: 1257.7289 us. Best GFLOPs: 602.6207
2024-04-29 21:26:08 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #228: GFLOPs: 177.7487. Time: 1301.3395 us. Best GFLOPs: 602.6207
2024-04-29 21:26:08 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #229: GFLOPs: 425.9685. Time: 543.0246 us. Best GFLOPs: 602.6207
2024-04-29 21:26:08 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #230: GFLOPs: 246.3476. Time: 938.9635 us. Best GFLOPs: 602.6207
2024-04-29 21:26:08 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #231: GFLOPs: 352.9379. Time: 655.3884 us. Best GFLOPs: 602.6207
2024-04-29 21:26:08 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #232: GFLOPs: 190.1873. Time: 1216.2290 us. Best GFLOPs: 602.6207
2024-04-29 21:26:08 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #233: GFLOPs: 117.3923. Time: 1970.4141 us. Best GFLOPs: 602.6207
2024-04-29 21:26:08 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #234: GFLOPs: 207.5194. Time: 1114.6496 us. Best GFLOPs: 602.6207
2024-04-29 21:26:08 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #235: GFLOPs: 162.5070. Time: 1423.3932 us. Best GFLOPs: 602.6207
2024-04-29 21:26:08 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #236: GFLOPs: 143.2330. Time: 1614.9302 us. Best GFLOPs: 602.6207
2024-04-29 21:26:08 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #237: GFLOPs: 151.5853. Time: 1525.9488 us. Best GFLOPs: 602.6207
2024-04-29 21:26:08 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #238: GFLOPs: 147.5407. Time: 1567.7798 us. Best GFLOPs: 602.6207
2024-04-29 21:26:08 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #239: GFLOPs: 710.1062. Time: 325.7419 us. Best GFLOPs: 710.1062
2024-04-29 21:26:08 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #240: GFLOPs: 128.3896. Time: 1801.6361 us. Best GFLOPs: 710.1062
2024-04-29 21:26:08 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #241: GFLOPs: 150.2991. Time: 1539.0072 us. Best GFLOPs: 710.1062
2024-04-29 21:26:08 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #242: GFLOPs: 149.5574. Time: 1546.6391 us. Best GFLOPs: 710.1062
2024-04-29 21:26:08 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #243: GFLOPs: 13.2125. Time: 17507.0397 us. Best GFLOPs: 710.1062
2024-04-29 21:26:08 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #244: GFLOPs: 13.0324. Time: 17748.9077 us. Best GFLOPs: 710.1062
2024-04-29 21:26:08 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #245: GFLOPs: 139.4224. Time: 1659.0689 us. Best GFLOPs: 710.1062
2024-04-29 21:26:08 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #246: GFLOPs: 147.6652. Time: 1566.4581 us. Best GFLOPs: 710.1062
2024-04-29 21:26:08 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #247: GFLOPs: 246.5399. Time: 938.2310 us. Best GFLOPs: 710.1062
2024-04-29 21:26:08 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #248: GFLOPs: 327.8240. Time: 705.5963 us. Best GFLOPs: 710.1062
2024-04-29 21:26:08 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #249: GFLOPs: 401.0061. Time: 576.8275 us. Best GFLOPs: 710.1062
2024-04-29 21:26:08 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #250: GFLOPs: 271.1422. Time: 853.0997 us. Best GFLOPs: 710.1062
2024-04-29 21:26:08 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #251: GFLOPs: 230.8117. Time: 1002.1650 us. Best GFLOPs: 710.1062
2024-04-29 21:26:08 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #252: GFLOPs: 317.6857. Time: 728.1138 us. Best GFLOPs: 710.1062
2024-04-29 21:26:08 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #253: GFLOPs: 151.0588. Time: 1531.2675 us. Best GFLOPs: 710.1062
2024-04-29 21:26:08 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #254: GFLOPs: 78.8454. Time: 2933.7335 us. Best GFLOPs: 710.1062
2024-04-29 21:26:08 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #255: GFLOPs: 3.9316. Time: 58834.0793 us. Best GFLOPs: 710.1062
2024-04-29 21:26:08 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #256: GFLOPs: 55.6136. Time: 4159.2613 us. Best GFLOPs: 710.1062
2024-04-29 21:26:08 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 21:26:09 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-29 21:26:14 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xcae1558)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x11641818)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x6b93998)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xda39458)]: 0 failure(s)
2024-04-29 21:26:14 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-29 21:26:27 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xcae1558)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x11641818)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x6b93998)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xda39458)]: 0 failure(s)
2024-04-29 21:26:40 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xcae1558)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x11641818)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x6b93998)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xda39458)]: 0 failure(s)
2024-04-29 21:26:54 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xcae1558)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x11641818)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x6b93998)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xda39458)]: 0 failure(s)
2024-04-29 21:27:08 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xcae1558)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x11641818)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x6b93998)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xda39458)]: 0 failure(s)
2024-04-29 21:27:16 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9572  0.9199  0.9199  0.9159  0.8792  0.8781  0.8722  0.8719  0.8625  0.8381  0.8381  0.8125  0.8041  0.7942  0.7942  0.7874
[17 : 32]:	0.7868  0.7815  0.7775  0.7746  0.7565  0.7398  0.7315  0.7296  0.7088  0.7061  0.7025  0.6975  0.6932  0.6874  0.6836  0.6735
[33 : 48]:	0.6688  0.6688  0.6688  0.6643  0.6643  0.6588  0.6439  0.6439  0.6348  0.6348  0.6348  0.6348  0.6120  0.5999  0.5936  0.5936
[49 : 64]:	0.5936  0.5901  0.5860  0.5851  0.5841  0.5656  0.5643  0.5643  0.5626  0.5616  0.5616  0.5616  0.5616  0.5616  0.5616  0.5597
2024-04-29 21:27:17 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 21:27:17 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 21:28:40 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #257: GFLOPs: 364.2230. Time: 635.0817 us. Best GFLOPs: 710.1062
2024-04-29 21:28:40 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #258: GFLOPs: 721.2315. Time: 320.7172 us. Best GFLOPs: 721.2315
2024-04-29 21:28:40 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #259: GFLOPs: 739.1345. Time: 312.9489 us. Best GFLOPs: 739.1345
2024-04-29 21:28:40 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #260: GFLOPs: 144.5295. Time: 1600.4434 us. Best GFLOPs: 739.1345
2024-04-29 21:28:40 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #261: GFLOPs: 737.9306. Time: 313.4595 us. Best GFLOPs: 739.1345
2024-04-29 21:28:40 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #262: GFLOPs: 163.6636. Time: 1413.3339 us. Best GFLOPs: 739.1345
2024-04-29 21:28:40 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #263: GFLOPs: 163.5342. Time: 1414.4528 us. Best GFLOPs: 739.1345
2024-04-29 21:28:40 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #264: GFLOPs: 185.8649. Time: 1244.5136 us. Best GFLOPs: 739.1345
2024-04-29 21:28:40 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #265: GFLOPs: 702.5484. Time: 329.2462 us. Best GFLOPs: 739.1345
2024-04-29 21:28:40 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #266: GFLOPs: 598.3974. Time: 386.5514 us. Best GFLOPs: 739.1345
2024-04-29 21:28:40 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #267: GFLOPs: 598.5077. Time: 386.4802 us. Best GFLOPs: 739.1345
2024-04-29 21:28:40 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #268: GFLOPs: 145.5627. Time: 1589.0843 us. Best GFLOPs: 739.1345
2024-04-29 21:28:40 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #269: GFLOPs: 678.5522. Time: 340.8896 us. Best GFLOPs: 739.1345
2024-04-29 21:28:40 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #270: GFLOPs: 576.4865. Time: 401.2434 us. Best GFLOPs: 739.1345
2024-04-29 21:28:40 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #271: GFLOPs: 575.8645. Time: 401.6767 us. Best GFLOPs: 739.1345
2024-04-29 21:28:40 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #272: GFLOPs: 159.3752. Time: 1451.3636 us. Best GFLOPs: 739.1345
2024-04-29 21:28:40 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #273: GFLOPs: 176.7675. Time: 1308.5624 us. Best GFLOPs: 739.1345
2024-04-29 21:28:40 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #274: GFLOPs: 158.1737. Time: 1462.3885 us. Best GFLOPs: 739.1345
2024-04-29 21:28:40 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #275: GFLOPs: 164.9522. Time: 1402.2932 us. Best GFLOPs: 739.1345
2024-04-29 21:28:40 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #276: GFLOPs: 658.9108. Time: 351.0511 us. Best GFLOPs: 739.1345
2024-04-29 21:28:40 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #277: GFLOPs: 413.3290. Time: 559.6301 us. Best GFLOPs: 739.1345
2024-04-29 21:28:40 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #278: GFLOPs: 81.3486. Time: 2843.4578 us. Best GFLOPs: 739.1345
2024-04-29 21:28:40 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #279: GFLOPs: 595.5373. Time: 388.4078 us. Best GFLOPs: 739.1345
2024-04-29 21:28:40 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #280: GFLOPs: 808.2654. Time: 286.1824 us. Best GFLOPs: 808.2654
2024-04-29 21:28:40 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #281: GFLOPs: 380.0381. Time: 608.6531 us. Best GFLOPs: 808.2654
2024-04-29 21:28:40 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #282: GFLOPs: 122.5945. Time: 1886.8006 us. Best GFLOPs: 808.2654
2024-04-29 21:28:40 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #283: GFLOPs: 260.9205. Time: 886.5205 us. Best GFLOPs: 808.2654
2024-04-29 21:28:40 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #284: GFLOPs: 750.3003. Time: 308.2917 us. Best GFLOPs: 808.2654
2024-04-29 21:28:40 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #285: GFLOPs: 597.6025. Time: 387.0656 us. Best GFLOPs: 808.2654
2024-04-29 21:28:40 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #286: GFLOPs: 447.4594. Time: 516.9438 us. Best GFLOPs: 808.2654
2024-04-29 21:28:40 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #287: GFLOPs: 761.7284. Time: 303.6664 us. Best GFLOPs: 808.2654
2024-04-29 21:28:40 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #288: GFLOPs: 443.3898. Time: 521.6885 us. Best GFLOPs: 808.2654
2024-04-29 21:28:40 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #289: GFLOPs: 465.8217. Time: 496.5664 us. Best GFLOPs: 808.2654
2024-04-29 21:28:40 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #290: GFLOPs: 469.1978. Time: 492.9933 us. Best GFLOPs: 808.2654
2024-04-29 21:28:40 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #291: GFLOPs: 514.8468. Time: 449.2819 us. Best GFLOPs: 808.2654
2024-04-29 21:28:40 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #292: GFLOPs: 442.5278. Time: 522.7047 us. Best GFLOPs: 808.2654
2024-04-29 21:28:40 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #293: GFLOPs: 443.2931. Time: 521.8023 us. Best GFLOPs: 808.2654
2024-04-29 21:28:40 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #294: GFLOPs: 160.6654. Time: 1439.7087 us. Best GFLOPs: 808.2654
2024-04-29 21:28:40 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #295: GFLOPs: 651.7918. Time: 354.8854 us. Best GFLOPs: 808.2654
2024-04-29 21:28:40 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #296: GFLOPs: 644.3412. Time: 358.9890 us. Best GFLOPs: 808.2654
2024-04-29 21:28:40 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #297: GFLOPs: 489.6730. Time: 472.3792 us. Best GFLOPs: 808.2654
2024-04-29 21:28:40 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #298: GFLOPs: 477.8904. Time: 484.0260 us. Best GFLOPs: 808.2654
2024-04-29 21:28:40 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #299: GFLOPs: 422.8463. Time: 547.0341 us. Best GFLOPs: 808.2654
2024-04-29 21:28:40 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #300: GFLOPs: 445.1466. Time: 519.6296 us. Best GFLOPs: 808.2654
2024-04-29 21:28:40 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #301: GFLOPs: 545.5549. Time: 423.9928 us. Best GFLOPs: 808.2654
2024-04-29 21:28:40 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #302: GFLOPs: 442.7822. Time: 522.4043 us. Best GFLOPs: 808.2654
2024-04-29 21:28:40 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #303: GFLOPs: 466.7308. Time: 495.5991 us. Best GFLOPs: 808.2654
2024-04-29 21:28:40 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #304: GFLOPs: 501.7955. Time: 460.9674 us. Best GFLOPs: 808.2654
2024-04-29 21:28:40 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #305: GFLOPs: 503.0122. Time: 459.8524 us. Best GFLOPs: 808.2654
2024-04-29 21:28:40 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #306: GFLOPs: 588.2177. Time: 393.2411 us. Best GFLOPs: 808.2654
2024-04-29 21:28:40 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #307: GFLOPs: 521.8626. Time: 443.2419 us. Best GFLOPs: 808.2654
2024-04-29 21:28:40 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #308: GFLOPs: 480.4867. Time: 481.4106 us. Best GFLOPs: 808.2654
2024-04-29 21:28:40 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #309: GFLOPs: 688.5146. Time: 335.9571 us. Best GFLOPs: 808.2654
2024-04-29 21:28:40 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #310: GFLOPs: 588.9770. Time: 392.7341 us. Best GFLOPs: 808.2654
2024-04-29 21:28:40 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #311: GFLOPs: 245.7640. Time: 941.1930 us. Best GFLOPs: 808.2654
2024-04-29 21:28:40 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #312: GFLOPs: 175.9809. Time: 1314.4115 us. Best GFLOPs: 808.2654
2024-04-29 21:28:40 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #313: GFLOPs: 170.8456. Time: 1353.9205 us. Best GFLOPs: 808.2654
2024-04-29 21:28:40 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #314: GFLOPs: 170.8643. Time: 1353.7723 us. Best GFLOPs: 808.2654
2024-04-29 21:28:40 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #315: GFLOPs: 160.4988. Time: 1441.2028 us. Best GFLOPs: 808.2654
2024-04-29 21:28:40 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #316: GFLOPs: 412.5824. Time: 560.6429 us. Best GFLOPs: 808.2654
2024-04-29 21:28:40 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #317: GFLOPs: 488.9492. Time: 473.0785 us. Best GFLOPs: 808.2654
2024-04-29 21:28:40 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #318: GFLOPs: 87.2736. Time: 2650.4148 us. Best GFLOPs: 808.2654
2024-04-29 21:28:40 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #319: GFLOPs: 93.7655. Time: 2466.9145 us. Best GFLOPs: 808.2654
2024-04-29 21:28:40 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #320: GFLOPs: 49.7428. Time: 4650.1460 us. Best GFLOPs: 808.2654
2024-04-29 21:43:10 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 21:43:11 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-29 21:43:16 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xcae1558)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x11641818)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x6b93998)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xda39458)]: 0 failure(s)
2024-04-29 21:43:16 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-29 21:43:28 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xcae1558)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x11641818)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x6b93998)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xda39458)]: 0 failure(s)
2024-04-29 21:43:42 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xcae1558)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x11641818)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x6b93998)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xda39458)]: 0 failure(s)
2024-04-29 21:43:56 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xcae1558)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x11641818)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x6b93998)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xda39458)]: 0 failure(s)
2024-04-29 21:44:09 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xcae1558)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x11641818)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x6b93998)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xda39458)]: 0 failure(s)
2024-04-29 21:44:18 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9901  0.9901  0.9461  0.9375  0.9375  0.9302  0.9219  0.9218  0.9150  0.8791  0.8758  0.8689  0.8688  0.8683  0.8683  0.8673
[17 : 32]:	0.8666  0.8579  0.8579  0.8532  0.8525  0.8525  0.8495  0.8434  0.8432  0.8396  0.8389  0.8381  0.8381  0.8381  0.8320  0.8288
[33 : 48]:	0.8280  0.8256  0.8256  0.8221  0.8221  0.8210  0.8175  0.8141  0.8113  0.7982  0.7859  0.7745  0.7745  0.7740  0.7716  0.7699
[49 : 64]:	0.7652  0.7636  0.7616  0.7616  0.7600  0.7540  0.7527  0.7507  0.7507  0.7507  0.7438  0.7349  0.7327  0.7245  0.7235  0.7230
2024-04-29 21:44:18 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 21:44:18 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 21:45:58 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #321: GFLOPs: 403.2155. Time: 573.6669 us. Best GFLOPs: 808.2654
2024-04-29 21:45:58 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #322: GFLOPs: 802.0202. Time: 288.4109 us. Best GFLOPs: 808.2654
2024-04-29 21:45:58 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #323: GFLOPs: 865.7989. Time: 267.1652 us. Best GFLOPs: 865.7989
2024-04-29 21:45:58 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #324: GFLOPs: 819.0528. Time: 282.4132 us. Best GFLOPs: 865.7989
2024-04-29 21:45:58 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #325: GFLOPs: 811.8362. Time: 284.9237 us. Best GFLOPs: 865.7989
2024-04-29 21:45:58 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #326: GFLOPs: 600.8852. Time: 384.9510 us. Best GFLOPs: 865.7989
2024-04-29 21:45:58 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #327: GFLOPs: 691.3093. Time: 334.5989 us. Best GFLOPs: 865.7989
2024-04-29 21:45:58 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #328: GFLOPs: 599.4707. Time: 385.8594 us. Best GFLOPs: 865.7989
2024-04-29 21:45:58 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #329: GFLOPs: 605.5644. Time: 381.9765 us. Best GFLOPs: 865.7989
2024-04-29 21:45:58 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #330: GFLOPs: 720.2306. Time: 321.1629 us. Best GFLOPs: 865.7989
2024-04-29 21:45:58 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #331: GFLOPs: 528.1462. Time: 437.9684 us. Best GFLOPs: 865.7989
2024-04-29 21:45:58 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #332: GFLOPs: 596.1870. Time: 387.9846 us. Best GFLOPs: 865.7989
2024-04-29 21:45:58 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #333: GFLOPs: 664.0864. Time: 348.3152 us. Best GFLOPs: 865.7989
2024-04-29 21:45:58 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #334: GFLOPs: 618.5931. Time: 373.9314 us. Best GFLOPs: 865.7989
2024-04-29 21:45:58 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #335: GFLOPs: 614.7082. Time: 376.2946 us. Best GFLOPs: 865.7989
2024-04-29 21:45:58 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #336: GFLOPs: 801.7627. Time: 288.5035 us. Best GFLOPs: 865.7989
2024-04-29 21:45:58 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #337: GFLOPs: 686.7319. Time: 336.8292 us. Best GFLOPs: 865.7989
2024-04-29 21:45:58 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #338: GFLOPs: 505.2488. Time: 457.8167 us. Best GFLOPs: 865.7989
2024-04-29 21:45:58 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #339: GFLOPs: 501.6335. Time: 461.1163 us. Best GFLOPs: 865.7989
2024-04-29 21:45:58 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #340: GFLOPs: 672.9902. Time: 343.7069 us. Best GFLOPs: 865.7989
2024-04-29 21:45:58 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #341: GFLOPs: 566.4585. Time: 408.3465 us. Best GFLOPs: 865.7989
2024-04-29 21:45:58 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #342: GFLOPs: 701.1083. Time: 329.9224 us. Best GFLOPs: 865.7989
2024-04-29 21:45:58 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #343: GFLOPs: 134.7449. Time: 1716.6608 us. Best GFLOPs: 865.7989
2024-04-29 21:45:58 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #344: GFLOPs: 696.0821. Time: 332.3047 us. Best GFLOPs: 865.7989
2024-04-29 21:45:58 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #345: GFLOPs: 826.3313. Time: 279.9257 us. Best GFLOPs: 865.7989
2024-04-29 21:45:58 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #346: GFLOPs: 543.9168. Time: 425.2698 us. Best GFLOPs: 865.7989
2024-04-29 21:45:58 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #347: GFLOPs: 540.3174. Time: 428.1027 us. Best GFLOPs: 865.7989
2024-04-29 21:45:58 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #348: GFLOPs: 718.3801. Time: 321.9902 us. Best GFLOPs: 865.7989
2024-04-29 21:45:58 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #349: GFLOPs: 651.1649. Time: 355.2270 us. Best GFLOPs: 865.7989
2024-04-29 21:45:58 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #350: GFLOPs: 739.1936. Time: 312.9239 us. Best GFLOPs: 865.7989
2024-04-29 21:45:58 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #351: GFLOPs: 727.8473. Time: 317.8020 us. Best GFLOPs: 865.7989
2024-04-29 21:45:58 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #352: GFLOPs: 727.9761. Time: 317.7458 us. Best GFLOPs: 865.7989
2024-04-29 21:45:58 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #353: GFLOPs: 703.5326. Time: 328.7856 us. Best GFLOPs: 865.7989
2024-04-29 21:45:58 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #354: GFLOPs: 739.9107. Time: 312.6206 us. Best GFLOPs: 865.7989
2024-04-29 21:45:58 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #355: GFLOPs: 807.2834. Time: 286.5306 us. Best GFLOPs: 865.7989
2024-04-29 21:45:58 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #356: GFLOPs: 599.4408. Time: 385.8786 us. Best GFLOPs: 865.7989
2024-04-29 21:45:58 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #357: GFLOPs: 600.1811. Time: 385.4026 us. Best GFLOPs: 865.7989
2024-04-29 21:45:58 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #358: GFLOPs: 594.0648. Time: 389.3706 us. Best GFLOPs: 865.7989
2024-04-29 21:45:58 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #359: GFLOPs: 544.3645. Time: 424.9200 us. Best GFLOPs: 865.7989
2024-04-29 21:45:58 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #360: GFLOPs: 669.1564. Time: 345.6761 us. Best GFLOPs: 865.7989
2024-04-29 21:45:58 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #361: GFLOPs: 689.4854. Time: 335.4840 us. Best GFLOPs: 865.7989
2024-04-29 21:45:58 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #362: GFLOPs: 826.3195. Time: 279.9297 us. Best GFLOPs: 865.7989
2024-04-29 21:45:58 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #363: GFLOPs: 827.1441. Time: 279.6506 us. Best GFLOPs: 865.7989
2024-04-29 21:45:58 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #364: GFLOPs: 594.9271. Time: 388.8062 us. Best GFLOPs: 865.7989
2024-04-29 21:45:58 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #365: GFLOPs: 592.1182. Time: 390.6507 us. Best GFLOPs: 865.7989
2024-04-29 21:45:58 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #366: GFLOPs: 589.4179. Time: 392.4403 us. Best GFLOPs: 865.7989
2024-04-29 21:45:58 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #367: GFLOPs: 798.2687. Time: 289.7663 us. Best GFLOPs: 865.7989
2024-04-29 21:45:58 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #368: GFLOPs: 569.1911. Time: 406.3861 us. Best GFLOPs: 865.7989
2024-04-29 21:45:58 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #369: GFLOPs: 160.3666. Time: 1442.3910 us. Best GFLOPs: 865.7989
2024-04-29 21:45:58 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #370: GFLOPs: 588.8173. Time: 392.8406 us. Best GFLOPs: 865.7989
2024-04-29 21:45:58 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #371: GFLOPs: 806.1472. Time: 286.9344 us. Best GFLOPs: 865.7989
2024-04-29 21:45:58 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #372: GFLOPs: 808.9920. Time: 285.9254 us. Best GFLOPs: 865.7989
2024-04-29 21:45:58 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #373: GFLOPs: 158.8312. Time: 1456.3341 us. Best GFLOPs: 865.7989
2024-04-29 21:45:58 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #374: GFLOPs: 569.3493. Time: 406.2732 us. Best GFLOPs: 865.7989
2024-04-29 21:45:58 [INFO] [task_scheduler.cc:121] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #375: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(14), T.int64(14), T.int64(128)), "float32"), p1: T.Buffer((T.int64(16), T.int64(2), T.int64(3), T.int64(3), T.int64(128), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(16), T.int64(16), T.int64(128)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused in T.parallel(T.int64(112), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(2), T.int64(7), T.int64(1)):
                with T.block("conv2d_NCHWc_init"):
                    v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                    v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(8) * T.int64(2) + oc_chunk_2_init + oc_chunk_3_init)
                    v_oh = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(16) * T.int64(2) + oh_2_init * T.int64(2) + oh_3_init)
                    v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(16) // T.int64(8) * T.int64(7) + ow_2_init * T.int64(7) + ow_3_init)
                    v_oc_block = T.axis.spatial(T.int64(16), oc_block_2_init + oc_block_3_init)
                    T.reads()
                    T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                    T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                    conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
            for ic_0 in range(T.int64(128)):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(9)):
                    for ax4_fused in T.vectorized(T.int64(2)):
                        with T.block("data_pad"):
                            v_i0 = T.axis.spatial(T.int64(1), ax0)
                            v_i1 = T.axis.spatial(T.int64(2), ic_0 // T.int64(64) + ax1)
                            v_i2 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(16) * T.int64(2) + ax2)
                            v_i3 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(16) // T.int64(8) * T.int64(7) + ax3)
                            v_i4 = T.axis.spatial(T.int64(128), ic_0 % T.int64(64) * T.int64(2) + ax4_fused)
                            T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                            T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                            data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(15) and T.int64(1) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                for kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(3), T.int64(3), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(16), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(7), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(8) * T.int64(2) + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(16) * T.int64(2) + oh_2 * T.int64(2) + oh_3)
                        v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(16) // T.int64(8) * T.int64(7) + ow_2 * T.int64(7) + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(16), oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(2) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(2), T.int64(2), T.int64(7)):
                for ax4_fused in T.vectorized(T.int64(16)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(8) * T.int64(2) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(16) * T.int64(2) + ax2)
                        v_ax3 = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(16) // T.int64(8) * T.int64(7) + ax3)
                        v_ax4 = T.axis.spatial(T.int64(16), ax4_fused)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 8, 2, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[7, 1, 1, 2])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[2, 1, 1, 7])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 16, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[128, 2])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=448)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=10)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86 = sch.get_loops(block=b68)
l87 = sch.fuse(l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, preserve_unit_iters=True)
sch.parallel(loop=l87)
l88 = sch.fuse(l86, preserve_unit_iters=True)
sch.vectorize(loop=l88)
l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105 = sch.get_loops(block=b69)
l106 = sch.fuse(l89, preserve_unit_iters=True)
sch.parallel(loop=l106)
sch.annotate(block_or_loop=l106, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l106, ann_key="pragma_unroll_explicit", ann_val=1)
l107, l108, l109, l110, l111, l112 = sch.get_loops(block=b70)
l113 = sch.fuse(l112, preserve_unit_iters=True)
sch.vectorize(loop=l113)
b114 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131 = sch.get_loops(block=b114)
b132 = sch.decompose_reduction(block=b114, loop=l116)
2024-04-29 21:45:58 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #376: GFLOPs: 576.4920. Time: 401.2395 us. Best GFLOPs: 865.7989
2024-04-29 21:45:58 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #377: GFLOPs: 574.7628. Time: 402.4466 us. Best GFLOPs: 865.7989
2024-04-29 21:45:58 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #378: GFLOPs: 572.3652. Time: 404.1325 us. Best GFLOPs: 865.7989
2024-04-29 21:45:58 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #379: GFLOPs: 736.6613. Time: 313.9996 us. Best GFLOPs: 865.7989
2024-04-29 21:45:58 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #380: GFLOPs: 689.4908. Time: 335.4814 us. Best GFLOPs: 865.7989
2024-04-29 21:45:58 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #381: GFLOPs: 536.2154. Time: 431.3777 us. Best GFLOPs: 865.7989
2024-04-29 21:45:58 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #382: GFLOPs: 19.5617. Time: 11824.6999 us. Best GFLOPs: 865.7989
2024-04-29 21:45:58 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #383: GFLOPs: 83.4213. Time: 2772.8078 us. Best GFLOPs: 865.7989
2024-04-29 21:45:58 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #384: GFLOPs: 1.2277. Time: 188413.8900 us. Best GFLOPs: 865.7989
2024-04-29 22:23:23 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 22:23:24 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-29 22:23:29 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xcae1558)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x11641818)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x6b93998)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xda39458)]: 0 failure(s)
2024-04-29 22:23:29 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-29 22:23:41 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xcae1558)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x11641818)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x6b93998)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xda39458)]: 0 failure(s)
2024-04-29 22:23:55 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xcae1558)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x11641818)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x6b93998)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xda39458)]: 0 failure(s)
2024-04-29 22:24:08 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xcae1558)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x11641818)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x6b93998)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xda39458)]: 0 failure(s)
2024-04-29 22:24:22 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xcae1558)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x11641818)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x6b93998)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xda39458)]: 0 failure(s)
2024-04-29 22:24:31 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9455  0.9315  0.9297  0.9177  0.9176  0.9030  0.8899  0.8899  0.8831  0.8801  0.8733  0.8733  0.8543  0.8507  0.8403  0.8381
[17 : 32]:	0.8381  0.8377  0.8377  0.8377  0.8331  0.8302  0.8156  0.8137  0.8125  0.8073  0.8060  0.8011  0.8011  0.8011  0.7937  0.7928
[33 : 48]:	0.7916  0.7843  0.7843  0.7820  0.7816  0.7816  0.7787  0.7775  0.7756  0.7756  0.7719  0.7703  0.7703  0.7686  0.7655  0.7632
[49 : 64]:	0.7605  0.7574  0.7561  0.7531  0.7525  0.7510  0.7483  0.7449  0.7449  0.7410  0.7408  0.7385  0.7377  0.7372  0.7365  0.7365
2024-04-29 22:24:31 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 22:24:31 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 22:26:12 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #385: GFLOPs: 759.2108. Time: 304.6734 us. Best GFLOPs: 865.7989
2024-04-29 22:26:12 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #386: GFLOPs: 693.8524. Time: 333.3726 us. Best GFLOPs: 865.7989
2024-04-29 22:26:12 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #387: GFLOPs: 685.4003. Time: 337.4836 us. Best GFLOPs: 865.7989
2024-04-29 22:26:12 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #388: GFLOPs: 649.8060. Time: 355.9699 us. Best GFLOPs: 865.7989
2024-04-29 22:26:12 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #389: GFLOPs: 259.1634. Time: 892.5310 us. Best GFLOPs: 865.7989
2024-04-29 22:26:12 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #390: GFLOPs: 742.8466. Time: 311.3851 us. Best GFLOPs: 865.7989
2024-04-29 22:26:12 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #391: GFLOPs: 825.5940. Time: 280.1757 us. Best GFLOPs: 865.7989
2024-04-29 22:26:12 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #392: GFLOPs: 822.6682. Time: 281.1721 us. Best GFLOPs: 865.7989
2024-04-29 22:26:12 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #393: GFLOPs: 455.4102. Time: 507.9187 us. Best GFLOPs: 865.7989
2024-04-29 22:26:12 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #394: GFLOPs: 834.8090. Time: 277.0830 us. Best GFLOPs: 865.7989
2024-04-29 22:26:12 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #395: GFLOPs: 795.7288. Time: 290.6912 us. Best GFLOPs: 865.7989
2024-04-29 22:26:12 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #396: GFLOPs: 809.3500. Time: 285.7989 us. Best GFLOPs: 865.7989
2024-04-29 22:26:12 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #397: GFLOPs: 591.7269. Time: 390.9090 us. Best GFLOPs: 865.7989
2024-04-29 22:26:12 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #398: GFLOPs: 737.6566. Time: 313.5759 us. Best GFLOPs: 865.7989
2024-04-29 22:26:12 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #399: GFLOPs: 511.7572. Time: 451.9943 us. Best GFLOPs: 865.7989
2024-04-29 22:26:12 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #400: GFLOPs: 744.9951. Time: 310.4871 us. Best GFLOPs: 865.7989
2024-04-29 22:26:12 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #401: GFLOPs: 740.7843. Time: 312.2520 us. Best GFLOPs: 865.7989
2024-04-29 22:26:12 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #402: GFLOPs: 589.2298. Time: 392.5656 us. Best GFLOPs: 865.7989
2024-04-29 22:26:12 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #403: GFLOPs: 508.2573. Time: 455.1068 us. Best GFLOPs: 865.7989
2024-04-29 22:26:12 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #404: GFLOPs: 712.8730. Time: 324.4776 us. Best GFLOPs: 865.7989
2024-04-29 22:26:12 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #405: GFLOPs: 703.1103. Time: 328.9830 us. Best GFLOPs: 865.7989
2024-04-29 22:26:12 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #406: GFLOPs: 552.2824. Time: 418.8281 us. Best GFLOPs: 865.7989
2024-04-29 22:26:12 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #407: GFLOPs: 701.0366. Time: 329.9562 us. Best GFLOPs: 865.7989
2024-04-29 22:26:12 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #408: GFLOPs: 514.2128. Time: 449.8359 us. Best GFLOPs: 865.7989
2024-04-29 22:26:12 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #409: GFLOPs: 628.1998. Time: 368.2130 us. Best GFLOPs: 865.7989
2024-04-29 22:26:12 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #410: GFLOPs: 524.7740. Time: 440.7828 us. Best GFLOPs: 865.7989
2024-04-29 22:26:12 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #411: GFLOPs: 730.6075. Time: 316.6014 us. Best GFLOPs: 865.7989
2024-04-29 22:26:12 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #412: GFLOPs: 711.6233. Time: 325.0475 us. Best GFLOPs: 865.7989
2024-04-29 22:26:12 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #413: GFLOPs: 708.9778. Time: 326.2604 us. Best GFLOPs: 865.7989
2024-04-29 22:26:12 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #414: GFLOPs: 712.4733. Time: 324.6597 us. Best GFLOPs: 865.7989
2024-04-29 22:26:12 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #415: GFLOPs: 683.2875. Time: 338.5271 us. Best GFLOPs: 865.7989
2024-04-29 22:26:12 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #416: GFLOPs: 455.4151. Time: 507.9133 us. Best GFLOPs: 865.7989
2024-04-29 22:26:12 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #417: GFLOPs: 730.7584. Time: 316.5360 us. Best GFLOPs: 865.7989
2024-04-29 22:26:12 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #418: GFLOPs: 710.0414. Time: 325.7716 us. Best GFLOPs: 865.7989
2024-04-29 22:26:12 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #419: GFLOPs: 707.8121. Time: 326.7977 us. Best GFLOPs: 865.7989
2024-04-29 22:26:12 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #420: GFLOPs: 651.3912. Time: 355.1036 us. Best GFLOPs: 865.7989
2024-04-29 22:26:12 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #421: GFLOPs: 797.3705. Time: 290.0927 us. Best GFLOPs: 865.7989
2024-04-29 22:26:12 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #422: GFLOPs: 797.5211. Time: 290.0379 us. Best GFLOPs: 865.7989
2024-04-29 22:26:12 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #423: GFLOPs: 615.5252. Time: 375.7951 us. Best GFLOPs: 865.7989
2024-04-29 22:26:12 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #424: GFLOPs: 688.0365. Time: 336.1905 us. Best GFLOPs: 865.7989
2024-04-29 22:26:12 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #425: GFLOPs: 399.3843. Time: 579.1699 us. Best GFLOPs: 865.7989
2024-04-29 22:26:12 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #426: GFLOPs: 447.7662. Time: 516.5896 us. Best GFLOPs: 865.7989
2024-04-29 22:26:12 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #427: GFLOPs: 735.1984. Time: 314.6244 us. Best GFLOPs: 865.7989
2024-04-29 22:26:12 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #428: GFLOPs: 302.0032. Time: 765.9235 us. Best GFLOPs: 865.7989
2024-04-29 22:26:12 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #429: GFLOPs: 526.3574. Time: 439.4568 us. Best GFLOPs: 865.7989
2024-04-29 22:26:12 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #430: GFLOPs: 804.3571. Time: 287.5730 us. Best GFLOPs: 865.7989
2024-04-29 22:26:12 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #431: GFLOPs: 735.8402. Time: 314.3500 us. Best GFLOPs: 865.7989
2024-04-29 22:26:12 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #432: GFLOPs: 615.4789. Time: 375.8234 us. Best GFLOPs: 865.7989
2024-04-29 22:26:12 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #433: GFLOPs: 631.7469. Time: 366.1456 us. Best GFLOPs: 865.7989
2024-04-29 22:26:12 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #434: GFLOPs: 795.4592. Time: 290.7897 us. Best GFLOPs: 865.7989
2024-04-29 22:26:12 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #435: GFLOPs: 67.3410. Time: 3434.9255 us. Best GFLOPs: 865.7989
2024-04-29 22:26:12 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #436: GFLOPs: 574.2706. Time: 402.7916 us. Best GFLOPs: 865.7989
2024-04-29 22:26:12 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #437: GFLOPs: 599.6726. Time: 385.7294 us. Best GFLOPs: 865.7989
2024-04-29 22:26:12 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #438: GFLOPs: 426.7935. Time: 541.9749 us. Best GFLOPs: 865.7989
2024-04-29 22:26:12 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #439: GFLOPs: 708.7199. Time: 326.3791 us. Best GFLOPs: 865.7989
2024-04-29 22:26:12 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #440: GFLOPs: 542.7422. Time: 426.1901 us. Best GFLOPs: 865.7989
2024-04-29 22:26:12 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #441: GFLOPs: 801.8105. Time: 288.4863 us. Best GFLOPs: 865.7989
2024-04-29 22:26:12 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #442: GFLOPs: 734.5947. Time: 314.8830 us. Best GFLOPs: 865.7989
2024-04-29 22:26:12 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #443: GFLOPs: 723.1273. Time: 319.8764 us. Best GFLOPs: 865.7989
2024-04-29 22:26:12 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #444: GFLOPs: 571.2389. Time: 404.9293 us. Best GFLOPs: 865.7989
2024-04-29 22:26:12 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #445: GFLOPs: 615.1846. Time: 376.0032 us. Best GFLOPs: 865.7989
2024-04-29 22:26:12 [INFO] [task_scheduler.cc:121] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #446: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(14), T.int64(14), T.int64(128)), "float32"), p1: T.Buffer((T.int64(16), T.int64(2), T.int64(3), T.int64(3), T.int64(128), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(16), T.int64(16), T.int64(128)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_fused_fused in T.parallel(T.int64(4), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(2), T.int64(9), T.int64(9), T.int64(128)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(2) * T.int64(7) + ax2)
                    v_i3 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(2) * T.int64(7) + ax3)
                    v_i4 = T.axis.spatial(T.int64(128), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(15) and T.int64(1) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oc_block_0 in range(T.int64(1)):
                for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(2)):
                    for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(7), T.int64(7)):
                        for oc_block_3_fused_init in T.vectorized(T.int64(8)):
                            with T.block("conv2d_NCHWc_init"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                                v_oc_chunk = T.axis.spatial(T.int64(16), oc_chunk_1 * T.int64(8) + oc_chunk_2_init * T.int64(4) + oc_chunk_3_init)
                                v_oh = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(2) * T.int64(7) + oh_1 * T.int64(7) + oh_2_init * T.int64(7) + oh_3_init)
                                v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(2) * T.int64(7) + ow_1 * T.int64(7) + ow_2_init * T.int64(7) + ow_3_init)
                                v_oc_block = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(16) + oc_block_1 * T.int64(8) + oc_block_2_init * T.int64(8) + oc_block_3_fused_init)
                                T.reads()
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                    for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(64), T.int64(3), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(1), T.int64(3), T.int64(1), T.int64(4), T.int64(7), T.int64(7)):
                        for oc_block_3_fused in T.vectorized(T.int64(8)):
                            with T.block("conv2d_NCHWc_update"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                                v_oc_chunk = T.axis.spatial(T.int64(16), oc_chunk_1 * T.int64(8) + oc_chunk_2 * T.int64(4) + oc_chunk_3)
                                v_oh = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(2) * T.int64(7) + oh_1 * T.int64(7) + oh_2 * T.int64(7) + oh_3)
                                v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(2) * T.int64(7) + ow_1 * T.int64(7) + ow_2 * T.int64(7) + ow_3)
                                v_oc_block = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(16) + oc_block_1 * T.int64(8) + oc_block_2 * T.int64(8) + oc_block_3_fused)
                                v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(4) + ic_1)
                                v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                                v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                                T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(16), T.int64(7), T.int64(7)):
                    for ax4_fused in T.vectorized(T.int64(16)):
                        with T.block("T_relu"):
                            v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                            v_ax2 = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(2) * T.int64(7) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(2) * T.int64(7) + ax3)
                            v_ax4 = T.axis.spatial(T.int64(16), ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 2, 2, 4])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 1, 1, 7])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[2, 1, 1, 7])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 2, 1, 8])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[64, 4])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=3)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79 = sch.get_loops(block=b68)
l80 = sch.fuse(l71, l72, l73, l74, preserve_unit_iters=True)
sch.parallel(loop=l80)
l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l81, preserve_unit_iters=True)
sch.parallel(loop=l104)
l105 = sch.fuse(l103, preserve_unit_iters=True)
sch.vectorize(loop=l105)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l106, l107, l108, l109, l110, l111, l112 = sch.get_loops(block=b70)
l113 = sch.fuse(l112, preserve_unit_iters=True)
sch.vectorize(loop=l113)
b114 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137 = sch.get_loops(block=b114)
b138 = sch.decompose_reduction(block=b114, loop=l122)
2024-04-29 22:26:12 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #447: GFLOPs: 4.3031. Time: 53755.0250 us. Best GFLOPs: 865.7989
2024-04-29 22:26:12 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #448: GFLOPs: 25.3993. Time: 9106.9820 us. Best GFLOPs: 865.7989
2024-04-29 23:06:10 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 23:06:11 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-29 23:06:15 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xcae1558)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x11641818)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x6b93998)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xda39458)]: 0 failure(s)
2024-04-29 23:06:15 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-29 23:06:28 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xcae1558)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x11641818)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x6b93998)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xda39458)]: 0 failure(s)
2024-04-29 23:06:41 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xcae1558)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x11641818)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x6b93998)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xda39458)]: 0 failure(s)
2024-04-29 23:06:55 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xcae1558)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x11641818)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x6b93998)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xda39458)]: 0 failure(s)
2024-04-29 23:07:09 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xcae1558)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x11641818)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x6b93998)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xda39458)]: 0 failure(s)
2024-04-29 23:07:18 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9081  0.9061  0.9061  0.9022  0.9014  0.8985  0.8946  0.8900  0.8876  0.8844  0.8648  0.8648  0.8595  0.8529  0.8513  0.8512
[17 : 32]:	0.8512  0.8459  0.8450  0.8450  0.8425  0.8425  0.8424  0.8413  0.8413  0.8408  0.8356  0.8341  0.8340  0.8328  0.8273  0.8244
[33 : 48]:	0.8216  0.8216  0.8171  0.8094  0.8060  0.8037  0.7958  0.7934  0.7928  0.7915  0.7895  0.7880  0.7865  0.7832  0.7745  0.7745
[49 : 64]:	0.7694  0.7670  0.7635  0.7577  0.7480  0.7468  0.7457  0.7428  0.7428  0.7419  0.7403  0.7393  0.7391  0.7371  0.7370  0.7370
2024-04-29 23:07:18 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 23:07:18 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 23:08:54 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #449: GFLOPs: 803.2070. Time: 287.9847 us. Best GFLOPs: 865.7989
2024-04-29 23:08:54 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #450: GFLOPs: 800.2255. Time: 289.0577 us. Best GFLOPs: 865.7989
2024-04-29 23:08:54 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #451: GFLOPs: 812.3895. Time: 284.7296 us. Best GFLOPs: 865.7989
2024-04-29 23:08:54 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #452: GFLOPs: 834.4202. Time: 277.2121 us. Best GFLOPs: 865.7989
2024-04-29 23:08:54 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #453: GFLOPs: 798.5072. Time: 289.6797 us. Best GFLOPs: 865.7989
2024-04-29 23:08:54 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #454: GFLOPs: 764.8972. Time: 302.4084 us. Best GFLOPs: 865.7989
2024-04-29 23:08:54 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #455: GFLOPs: 810.5284. Time: 285.3834 us. Best GFLOPs: 865.7989
2024-04-29 23:08:54 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #456: GFLOPs: 831.6631. Time: 278.1311 us. Best GFLOPs: 865.7989
2024-04-29 23:08:54 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #457: GFLOPs: 830.1245. Time: 278.6466 us. Best GFLOPs: 865.7989
2024-04-29 23:08:54 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #458: GFLOPs: 830.3643. Time: 278.5661 us. Best GFLOPs: 865.7989
2024-04-29 23:08:54 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #459: GFLOPs: 796.3390. Time: 290.4685 us. Best GFLOPs: 865.7989
2024-04-29 23:08:54 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #460: GFLOPs: 804.4316. Time: 287.5463 us. Best GFLOPs: 865.7989
2024-04-29 23:08:54 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #461: GFLOPs: 779.7727. Time: 296.6395 us. Best GFLOPs: 865.7989
2024-04-29 23:08:54 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #462: GFLOPs: 416.3169. Time: 555.6137 us. Best GFLOPs: 865.7989
2024-04-29 23:08:54 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #463: GFLOPs: 735.5102. Time: 314.4910 us. Best GFLOPs: 865.7989
2024-04-29 23:08:54 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #464: GFLOPs: 740.4031. Time: 312.4127 us. Best GFLOPs: 865.7989
2024-04-29 23:08:54 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #465: GFLOPs: 802.7339. Time: 288.1545 us. Best GFLOPs: 865.7989
2024-04-29 23:08:54 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #466: GFLOPs: 742.0262. Time: 311.7294 us. Best GFLOPs: 865.7989
2024-04-29 23:08:54 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #467: GFLOPs: 737.0908. Time: 313.8166 us. Best GFLOPs: 865.7989
2024-04-29 23:08:54 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #468: GFLOPs: 349.1558. Time: 662.4875 us. Best GFLOPs: 865.7989
2024-04-29 23:08:54 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #469: GFLOPs: 374.4586. Time: 617.7222 us. Best GFLOPs: 865.7989
2024-04-29 23:08:54 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #470: GFLOPs: 365.7108. Time: 632.4980 us. Best GFLOPs: 865.7989
2024-04-29 23:08:54 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #471: GFLOPs: 709.3969. Time: 326.0676 us. Best GFLOPs: 865.7989
2024-04-29 23:08:54 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #472: GFLOPs: 601.2951. Time: 384.6886 us. Best GFLOPs: 865.7989
2024-04-29 23:08:54 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #473: GFLOPs: 772.0564. Time: 299.6042 us. Best GFLOPs: 865.7989
2024-04-29 23:08:54 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #474: GFLOPs: 739.6391. Time: 312.7354 us. Best GFLOPs: 865.7989
2024-04-29 23:08:54 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #475: GFLOPs: 818.2321. Time: 282.6965 us. Best GFLOPs: 865.7989
2024-04-29 23:08:54 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #476: GFLOPs: 719.0080. Time: 321.7090 us. Best GFLOPs: 865.7989
2024-04-29 23:08:54 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #477: GFLOPs: 731.6248. Time: 316.1612 us. Best GFLOPs: 865.7989
2024-04-29 23:08:54 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #478: GFLOPs: 748.6622. Time: 308.9663 us. Best GFLOPs: 865.7989
2024-04-29 23:08:54 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #479: GFLOPs: 750.6745. Time: 308.1380 us. Best GFLOPs: 865.7989
2024-04-29 23:08:54 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #480: GFLOPs: 518.7391. Time: 445.9108 us. Best GFLOPs: 865.7989
2024-04-29 23:08:54 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #481: GFLOPs: 621.7172. Time: 372.0524 us. Best GFLOPs: 865.7989
2024-04-29 23:08:54 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #482: GFLOPs: 635.2236. Time: 364.1416 us. Best GFLOPs: 865.7989
2024-04-29 23:08:54 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #483: GFLOPs: 634.0507. Time: 364.8152 us. Best GFLOPs: 865.7989
2024-04-29 23:08:54 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #484: GFLOPs: 653.4833. Time: 353.9668 us. Best GFLOPs: 865.7989
2024-04-29 23:08:54 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #485: GFLOPs: 701.0045. Time: 329.9713 us. Best GFLOPs: 865.7989
2024-04-29 23:08:54 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #486: GFLOPs: 707.7497. Time: 326.8265 us. Best GFLOPs: 865.7989
2024-04-29 23:08:54 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #487: GFLOPs: 664.6856. Time: 348.0012 us. Best GFLOPs: 865.7989
2024-04-29 23:08:54 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #488: GFLOPs: 671.2304. Time: 344.6080 us. Best GFLOPs: 865.7989
2024-04-29 23:08:54 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #489: GFLOPs: 708.2949. Time: 326.5750 us. Best GFLOPs: 865.7989
2024-04-29 23:08:54 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #490: GFLOPs: 654.9547. Time: 353.1715 us. Best GFLOPs: 865.7989
2024-04-29 23:08:54 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #491: GFLOPs: 505.0643. Time: 457.9840 us. Best GFLOPs: 865.7989
2024-04-29 23:08:54 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #492: GFLOPs: 675.2506. Time: 342.5563 us. Best GFLOPs: 865.7989
2024-04-29 23:08:54 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #493: GFLOPs: 672.2046. Time: 344.1085 us. Best GFLOPs: 865.7989
2024-04-29 23:08:54 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #494: GFLOPs: 615.2603. Time: 375.9569 us. Best GFLOPs: 865.7989
2024-04-29 23:08:54 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #495: GFLOPs: 583.5503. Time: 396.3863 us. Best GFLOPs: 865.7989
2024-04-29 23:08:54 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #496: GFLOPs: 588.9855. Time: 392.7284 us. Best GFLOPs: 865.7989
2024-04-29 23:08:54 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #497: GFLOPs: 675.0308. Time: 342.6679 us. Best GFLOPs: 865.7989
2024-04-29 23:08:54 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #498: GFLOPs: 761.5821. Time: 303.7248 us. Best GFLOPs: 865.7989
2024-04-29 23:08:54 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #499: GFLOPs: 726.0548. Time: 318.5866 us. Best GFLOPs: 865.7989
2024-04-29 23:08:54 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #500: GFLOPs: 723.7759. Time: 319.5897 us. Best GFLOPs: 865.7989
2024-04-29 23:08:54 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #501: GFLOPs: 734.5185. Time: 314.9156 us. Best GFLOPs: 865.7989
2024-04-29 23:08:54 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #502: GFLOPs: 596.1179. Time: 388.0296 us. Best GFLOPs: 865.7989
2024-04-29 23:08:54 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #503: GFLOPs: 603.1522. Time: 383.5041 us. Best GFLOPs: 865.7989
2024-04-29 23:08:54 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #504: GFLOPs: 673.1572. Time: 343.6216 us. Best GFLOPs: 865.7989
2024-04-29 23:08:54 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #505: GFLOPs: 683.6121. Time: 338.3664 us. Best GFLOPs: 865.7989
2024-04-29 23:08:54 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #506: GFLOPs: 139.0244. Time: 1663.8183 us. Best GFLOPs: 865.7989
2024-04-29 23:08:54 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #507: GFLOPs: 620.7325. Time: 372.6426 us. Best GFLOPs: 865.7989
2024-04-29 23:08:54 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #508: GFLOPs: 560.8387. Time: 412.4383 us. Best GFLOPs: 865.7989
2024-04-29 23:08:54 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #509: GFLOPs: 136.3102. Time: 1696.9486 us. Best GFLOPs: 865.7989
2024-04-29 23:08:54 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #510: GFLOPs: 3.2122. Time: 72010.1150 us. Best GFLOPs: 865.7989
2024-04-29 23:08:54 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #511: GFLOPs: 65.4117. Time: 3536.2370 us. Best GFLOPs: 865.7989
2024-04-29 23:08:54 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #512: GFLOPs: 59.8540. Time: 3864.5900 us. Best GFLOPs: 865.7989
2024-04-29 23:29:51 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 23:29:52 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-29 23:29:57 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xcae1558)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x11641818)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x6b93998)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xda39458)]: 0 failure(s)
2024-04-29 23:29:57 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-29 23:30:09 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xcae1558)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x11641818)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x6b93998)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xda39458)]: 0 failure(s)
2024-04-29 23:30:23 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xcae1558)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x11641818)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x6b93998)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xda39458)]: 0 failure(s)
2024-04-29 23:30:37 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xcae1558)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x11641818)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x6b93998)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xda39458)]: 0 failure(s)
2024-04-29 23:30:51 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xcae1558)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x11641818)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x6b93998)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xda39458)]: 0 failure(s)
2024-04-29 23:30:59 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9381  0.9222  0.9222  0.9128  0.9128  0.8990  0.8946  0.8830  0.8638  0.8635  0.8533  0.8496  0.8457  0.8406  0.8400  0.8396
[17 : 32]:	0.8181  0.8181  0.8161  0.8075  0.7994  0.7968  0.7963  0.7956  0.7948  0.7939  0.7892  0.7868  0.7864  0.7800  0.7799  0.7773
[33 : 48]:	0.7766  0.7709  0.7684  0.7658  0.7654  0.7617  0.7615  0.7615  0.7597  0.7597  0.7588  0.7588  0.7575  0.7569  0.7549  0.7548
[49 : 64]:	0.7507  0.7491  0.7491  0.7486  0.7476  0.7419  0.7392  0.7333  0.7323  0.7318  0.7318  0.7289  0.7288  0.7270  0.7225  0.7225
2024-04-29 23:31:00 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 23:31:00 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 23:32:44 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #513: GFLOPs: 856.3671. Time: 270.1077 us. Best GFLOPs: 865.7989
2024-04-29 23:32:44 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #514: GFLOPs: 799.1133. Time: 289.4600 us. Best GFLOPs: 865.7989
2024-04-29 23:32:44 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #515: GFLOPs: 796.7996. Time: 290.3005 us. Best GFLOPs: 865.7989
2024-04-29 23:32:44 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #516: GFLOPs: 830.7493. Time: 278.4370 us. Best GFLOPs: 865.7989
2024-04-29 23:32:44 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #517: GFLOPs: 827.1134. Time: 279.6610 us. Best GFLOPs: 865.7989
2024-04-29 23:32:44 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #518: GFLOPs: 663.0248. Time: 348.8729 us. Best GFLOPs: 865.7989
2024-04-29 23:32:44 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #519: GFLOPs: 815.7903. Time: 283.5427 us. Best GFLOPs: 865.7989
2024-04-29 23:32:44 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #520: GFLOPs: 770.7355. Time: 300.1177 us. Best GFLOPs: 865.7989
2024-04-29 23:32:44 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #521: GFLOPs: 817.8573. Time: 282.8261 us. Best GFLOPs: 865.7989
2024-04-29 23:32:44 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #522: GFLOPs: 757.8806. Time: 305.2082 us. Best GFLOPs: 865.7989
2024-04-29 23:32:44 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #523: GFLOPs: 751.1780. Time: 307.9315 us. Best GFLOPs: 865.7989
2024-04-29 23:32:44 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #524: GFLOPs: 740.4207. Time: 312.4053 us. Best GFLOPs: 865.7989
2024-04-29 23:32:44 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #525: GFLOPs: 770.1656. Time: 300.3398 us. Best GFLOPs: 865.7989
2024-04-29 23:32:44 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #526: GFLOPs: 722.8758. Time: 319.9877 us. Best GFLOPs: 865.7989
2024-04-29 23:32:44 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #527: GFLOPs: 827.6254. Time: 279.4880 us. Best GFLOPs: 865.7989
2024-04-29 23:32:44 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #528: GFLOPs: 720.3583. Time: 321.1060 us. Best GFLOPs: 865.7989
2024-04-29 23:32:44 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #529: GFLOPs: 802.5183. Time: 288.2319 us. Best GFLOPs: 865.7989
2024-04-29 23:32:44 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #530: GFLOPs: 806.5547. Time: 286.7894 us. Best GFLOPs: 865.7989
2024-04-29 23:32:44 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #531: GFLOPs: 722.2010. Time: 320.2867 us. Best GFLOPs: 865.7989
2024-04-29 23:32:44 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #532: GFLOPs: 765.8095. Time: 302.0482 us. Best GFLOPs: 865.7989
2024-04-29 23:32:44 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #533: GFLOPs: 717.1854. Time: 322.5266 us. Best GFLOPs: 865.7989
2024-04-29 23:32:44 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #534: GFLOPs: 730.1311. Time: 316.8080 us. Best GFLOPs: 865.7989
2024-04-29 23:32:44 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #535: GFLOPs: 664.9702. Time: 347.8522 us. Best GFLOPs: 865.7989
2024-04-29 23:32:44 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #536: GFLOPs: 739.9749. Time: 312.5935 us. Best GFLOPs: 865.7989
2024-04-29 23:32:44 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #537: GFLOPs: 714.8938. Time: 323.5605 us. Best GFLOPs: 865.7989
2024-04-29 23:32:44 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #538: GFLOPs: 666.8113. Time: 346.8918 us. Best GFLOPs: 865.7989
2024-04-29 23:32:44 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #539: GFLOPs: 717.5407. Time: 322.3669 us. Best GFLOPs: 865.7989
2024-04-29 23:32:44 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #540: GFLOPs: 783.4228. Time: 295.2574 us. Best GFLOPs: 865.7989
2024-04-29 23:32:44 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #541: GFLOPs: 807.2471. Time: 286.5434 us. Best GFLOPs: 865.7989
2024-04-29 23:32:44 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #542: GFLOPs: 687.0335. Time: 336.6813 us. Best GFLOPs: 865.7989
2024-04-29 23:32:44 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #543: GFLOPs: 807.9673. Time: 286.2880 us. Best GFLOPs: 865.7989
2024-04-29 23:32:44 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #544: GFLOPs: 669.1320. Time: 345.6887 us. Best GFLOPs: 865.7989
2024-04-29 23:32:44 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #545: GFLOPs: 344.6120. Time: 671.2225 us. Best GFLOPs: 865.7989
2024-04-29 23:32:44 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #546: GFLOPs: 658.6238. Time: 351.2041 us. Best GFLOPs: 865.7989
2024-04-29 23:32:44 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #547: GFLOPs: 227.8756. Time: 1015.0773 us. Best GFLOPs: 865.7989
2024-04-29 23:32:44 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #548: GFLOPs: 588.9775. Time: 392.7338 us. Best GFLOPs: 865.7989
2024-04-29 23:32:44 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #549: GFLOPs: 702.9467. Time: 329.0596 us. Best GFLOPs: 865.7989
2024-04-29 23:32:44 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #550: GFLOPs: 812.7622. Time: 284.5991 us. Best GFLOPs: 865.7989
2024-04-29 23:32:44 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #551: GFLOPs: 539.2036. Time: 428.9870 us. Best GFLOPs: 865.7989
2024-04-29 23:32:44 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #552: GFLOPs: 748.3088. Time: 309.1122 us. Best GFLOPs: 865.7989
2024-04-29 23:32:44 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #553: GFLOPs: 674.7008. Time: 342.8355 us. Best GFLOPs: 865.7989
2024-04-29 23:32:44 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #554: GFLOPs: 678.4416. Time: 340.9451 us. Best GFLOPs: 865.7989
2024-04-29 23:32:44 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #555: GFLOPs: 811.9420. Time: 284.8865 us. Best GFLOPs: 865.7989
2024-04-29 23:32:44 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #556: GFLOPs: 812.9773. Time: 284.5238 us. Best GFLOPs: 865.7989
2024-04-29 23:32:44 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #557: GFLOPs: 352.8270. Time: 655.5943 us. Best GFLOPs: 865.7989
2024-04-29 23:32:44 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #558: GFLOPs: 531.1201. Time: 435.5161 us. Best GFLOPs: 865.7989
2024-04-29 23:32:44 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #559: GFLOPs: 667.8468. Time: 346.3539 us. Best GFLOPs: 865.7989
2024-04-29 23:32:44 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #560: GFLOPs: 658.7576. Time: 351.1327 us. Best GFLOPs: 865.7989
2024-04-29 23:32:44 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #561: GFLOPs: 609.5802. Time: 379.4601 us. Best GFLOPs: 865.7989
2024-04-29 23:32:44 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #562: GFLOPs: 685.5994. Time: 337.3856 us. Best GFLOPs: 865.7989
2024-04-29 23:32:44 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #563: GFLOPs: 698.7054. Time: 331.0571 us. Best GFLOPs: 865.7989
2024-04-29 23:32:44 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #564: GFLOPs: 709.7654. Time: 325.8983 us. Best GFLOPs: 865.7989
2024-04-29 23:32:44 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #565: GFLOPs: 549.3933. Time: 421.0305 us. Best GFLOPs: 865.7989
2024-04-29 23:32:44 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #566: GFLOPs: 724.9761. Time: 319.0607 us. Best GFLOPs: 865.7989
2024-04-29 23:32:44 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #567: GFLOPs: 693.5491. Time: 333.5184 us. Best GFLOPs: 865.7989
2024-04-29 23:32:44 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #568: GFLOPs: 516.1425. Time: 448.1541 us. Best GFLOPs: 865.7989
2024-04-29 23:32:44 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #569: GFLOPs: 645.6628. Time: 358.2541 us. Best GFLOPs: 865.7989
2024-04-29 23:32:44 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #570: GFLOPs: 678.6773. Time: 340.8267 us. Best GFLOPs: 865.7989
2024-04-29 23:32:44 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #571: GFLOPs: 653.3184. Time: 354.0561 us. Best GFLOPs: 865.7989
2024-04-29 23:32:44 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #572: GFLOPs: 605.7116. Time: 381.8836 us. Best GFLOPs: 865.7989
2024-04-29 23:32:44 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #573: GFLOPs: 657.8574. Time: 351.6132 us. Best GFLOPs: 865.7989
2024-04-29 23:32:44 [INFO] [task_scheduler.cc:121] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #574: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(14), T.int64(14), T.int64(128)), "float32"), p1: T.Buffer((T.int64(16), T.int64(2), T.int64(3), T.int64(3), T.int64(128), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(16), T.int64(16), T.int64(128)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused in T.parallel(T.int64(112), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(2), T.int64(16), T.int64(4), T.int64(128)):
                with T.block("data_pad"):
                    v_i0, v_i1, v_i2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                    v_i3 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(14) // T.int64(2) * T.int64(2) + ax3)
                    v_i4 = T.axis.spatial(T.int64(128), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(15) and T.int64(1) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(2), T.int64(2), T.int64(1), T.int64(2)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(7), T.int64(2), T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(14) * T.int64(2) + oc_chunk_1 + oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(14), oh_1 * T.int64(7) + oh_2_init + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(14) // T.int64(2) * T.int64(2) + ow_1 * T.int64(2) + ow_2_init + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(2) * T.int64(8) + oc_block_1 * T.int64(4) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(128), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(7), T.int64(2), T.int64(4), T.int64(2), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(14) * T.int64(2) + oc_chunk_1 + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(14), oh_1 * T.int64(7) + oh_2 + oh_3)
                        v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(14) // T.int64(2) * T.int64(2) + ow_1 * T.int64(2) + ow_2 + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(2) * T.int64(8) + oc_block_1 * T.int64(4) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(2) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(7), T.int64(2)):
                    for ax4_fused in T.vectorized(T.int64(4)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(14) * T.int64(2) + oc_chunk_1 + ax1)
                            v_ax2 = T.axis.spatial(T.int64(14), oh_1 * T.int64(7) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(14) // T.int64(2) * T.int64(2) + ax3)
                            v_ax4 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(2) * T.int64(8) + oc_block_1 * T.int64(4) + ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[8, 2, 1, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 2, 7, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[7, 1, 2, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[2, 2, 4, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[128, 2])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=4)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80 = sch.get_loops(block=b68)
l81 = sch.fuse(l71, l72, l73, l74, l75, preserve_unit_iters=True)
sch.parallel(loop=l81)
l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l82, preserve_unit_iters=True)
sch.parallel(loop=l104)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109, l110, l111, l112, l113, l114, l115 = sch.get_loops(block=b70)
l116 = sch.fuse(l115, preserve_unit_iters=True)
sch.vectorize(loop=l116)
b117 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139 = sch.get_loops(block=b117)
b140 = sch.decompose_reduction(block=b117, loop=l124)
2024-04-29 23:32:44 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #575: GFLOPs: 50.0417. Time: 4622.3752 us. Best GFLOPs: 865.7989
2024-04-29 23:32:44 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #576: GFLOPs: 6.4462. Time: 35883.1217 us. Best GFLOPs: 865.7989
2024-04-29 23:56:00 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 23:56:01 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-29 23:56:05 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xcae1558)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x11641818)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x6b93998)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xda39458)]: 0 failure(s)
2024-04-29 23:56:05 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-29 23:56:18 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xcae1558)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x11641818)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x6b93998)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xda39458)]: 0 failure(s)
2024-04-29 23:56:32 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xcae1558)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x11641818)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x6b93998)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xda39458)]: 0 failure(s)
2024-04-29 23:56:46 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xcae1558)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x11641818)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x6b93998)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xda39458)]: 0 failure(s)
2024-04-29 23:57:00 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xcae1558)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x11641818)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x6b93998)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xda39458)]: 0 failure(s)
2024-04-29 23:57:09 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9422  0.9422  0.9381  0.9365  0.9365  0.9365  0.9295  0.9196  0.9180  0.9164  0.9131  0.9130  0.9130  0.9114  0.9113  0.9108
[17 : 32]:	0.8927  0.8926  0.8902  0.8869  0.8837  0.8803  0.8711  0.8665  0.8656  0.8656  0.8656  0.8646  0.8642  0.8638  0.8611  0.8596
[33 : 48]:	0.8502  0.8486  0.8476  0.8464  0.8464  0.8462  0.8358  0.8331  0.8304  0.8275  0.8262  0.8236  0.8187  0.8171  0.8164  0.8157
[49 : 64]:	0.8157  0.8148  0.8111  0.8105  0.8066  0.8060  0.7986  0.7925  0.7716  0.7691  0.7618  0.7602  0.7568  0.7555  0.7413  0.7411
2024-04-29 23:57:09 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 23:57:09 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 23:58:45 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #577: GFLOPs: 815.7267. Time: 283.5648 us. Best GFLOPs: 865.7989
2024-04-29 23:58:45 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #578: GFLOPs: 829.6327. Time: 278.8118 us. Best GFLOPs: 865.7989
2024-04-29 23:58:45 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #579: GFLOPs: 826.5432. Time: 279.8539 us. Best GFLOPs: 865.7989
2024-04-29 23:58:45 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #580: GFLOPs: 813.7210. Time: 284.2637 us. Best GFLOPs: 865.7989
2024-04-29 23:58:45 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #581: GFLOPs: 814.9850. Time: 283.8228 us. Best GFLOPs: 865.7989
2024-04-29 23:58:45 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #582: GFLOPs: 817.5821. Time: 282.9213 us. Best GFLOPs: 865.7989
2024-04-29 23:58:45 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #583: GFLOPs: 805.0867. Time: 287.3123 us. Best GFLOPs: 865.7989
2024-04-29 23:58:45 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #584: GFLOPs: 799.9191. Time: 289.1685 us. Best GFLOPs: 865.7989
2024-04-29 23:58:45 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #585: GFLOPs: 776.5131. Time: 297.8847 us. Best GFLOPs: 865.7989
2024-04-29 23:58:45 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #586: GFLOPs: 790.4757. Time: 292.6230 us. Best GFLOPs: 865.7989
2024-04-29 23:58:45 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #587: GFLOPs: 802.5515. Time: 288.2200 us. Best GFLOPs: 865.7989
2024-04-29 23:58:45 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #588: GFLOPs: 796.8243. Time: 290.2915 us. Best GFLOPs: 865.7989
2024-04-29 23:58:45 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #589: GFLOPs: 714.9850. Time: 323.5192 us. Best GFLOPs: 865.7989
2024-04-29 23:58:45 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #590: GFLOPs: 749.3117. Time: 308.6985 us. Best GFLOPs: 865.7989
2024-04-29 23:58:45 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #591: GFLOPs: 809.4217. Time: 285.7736 us. Best GFLOPs: 865.7989
2024-04-29 23:58:45 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #592: GFLOPs: 802.6759. Time: 288.1753 us. Best GFLOPs: 865.7989
2024-04-29 23:58:45 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #593: GFLOPs: 804.2154. Time: 287.6236 us. Best GFLOPs: 865.7989
2024-04-29 23:58:45 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #594: GFLOPs: 800.1946. Time: 289.0689 us. Best GFLOPs: 865.7989
2024-04-29 23:58:45 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #595: GFLOPs: 811.5231. Time: 285.0336 us. Best GFLOPs: 865.7989
2024-04-29 23:58:45 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #596: GFLOPs: 731.0771. Time: 316.3980 us. Best GFLOPs: 865.7989
2024-04-29 23:58:45 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #597: GFLOPs: 695.8252. Time: 332.4274 us. Best GFLOPs: 865.7989
2024-04-29 23:58:45 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #598: GFLOPs: 696.3642. Time: 332.1701 us. Best GFLOPs: 865.7989
2024-04-29 23:58:45 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #599: GFLOPs: 664.9933. Time: 347.8401 us. Best GFLOPs: 865.7989
2024-04-29 23:58:45 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #600: GFLOPs: 748.0006. Time: 309.2395 us. Best GFLOPs: 865.7989
2024-04-29 23:58:45 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #601: GFLOPs: 793.8673. Time: 291.3728 us. Best GFLOPs: 865.7989
2024-04-29 23:58:45 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #602: GFLOPs: 790.0119. Time: 292.7948 us. Best GFLOPs: 865.7989
2024-04-29 23:58:45 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #603: GFLOPs: 794.5289. Time: 291.1302 us. Best GFLOPs: 865.7989
2024-04-29 23:58:45 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #604: GFLOPs: 786.9262. Time: 293.9429 us. Best GFLOPs: 865.7989
2024-04-29 23:58:45 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #605: GFLOPs: 660.8332. Time: 350.0299 us. Best GFLOPs: 865.7989
2024-04-29 23:58:45 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #606: GFLOPs: 755.5622. Time: 306.1447 us. Best GFLOPs: 865.7989
2024-04-29 23:58:45 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #607: GFLOPs: 843.1803. Time: 274.3320 us. Best GFLOPs: 865.7989
2024-04-29 23:58:45 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #608: GFLOPs: 439.3359. Time: 526.5023 us. Best GFLOPs: 865.7989
2024-04-29 23:58:45 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #609: GFLOPs: 731.0139. Time: 316.4254 us. Best GFLOPs: 865.7989
2024-04-29 23:58:45 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #610: GFLOPs: 725.8244. Time: 318.6878 us. Best GFLOPs: 865.7989
2024-04-29 23:58:45 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #611: GFLOPs: 732.9023. Time: 315.6101 us. Best GFLOPs: 865.7989
2024-04-29 23:58:45 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #612: GFLOPs: 746.1523. Time: 310.0056 us. Best GFLOPs: 865.7989
2024-04-29 23:58:45 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #613: GFLOPs: 352.0634. Time: 657.0163 us. Best GFLOPs: 865.7989
2024-04-29 23:58:45 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #614: GFLOPs: 724.2914. Time: 319.3623 us. Best GFLOPs: 865.7989
2024-04-29 23:58:45 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #615: GFLOPs: 718.1845. Time: 322.0779 us. Best GFLOPs: 865.7989
2024-04-29 23:58:45 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #616: GFLOPs: 696.1648. Time: 332.2652 us. Best GFLOPs: 865.7989
2024-04-29 23:58:45 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #617: GFLOPs: 698.4089. Time: 331.1976 us. Best GFLOPs: 865.7989
2024-04-29 23:58:45 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #618: GFLOPs: 821.8749. Time: 281.4435 us. Best GFLOPs: 865.7989
2024-04-29 23:58:45 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #619: GFLOPs: 694.2467. Time: 333.1832 us. Best GFLOPs: 865.7989
2024-04-29 23:58:45 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #620: GFLOPs: 728.6237. Time: 317.4634 us. Best GFLOPs: 865.7989
2024-04-29 23:58:45 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #621: GFLOPs: 699.7500. Time: 330.5628 us. Best GFLOPs: 865.7989
2024-04-29 23:58:45 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #622: GFLOPs: 670.6028. Time: 344.9305 us. Best GFLOPs: 865.7989
2024-04-29 23:58:45 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #623: GFLOPs: 730.8781. Time: 316.4842 us. Best GFLOPs: 865.7989
2024-04-29 23:58:45 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #624: GFLOPs: 771.3453. Time: 299.8804 us. Best GFLOPs: 865.7989
2024-04-29 23:58:45 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #625: GFLOPs: 774.8474. Time: 298.5251 us. Best GFLOPs: 865.7989
2024-04-29 23:58:45 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #626: GFLOPs: 648.2085. Time: 356.8471 us. Best GFLOPs: 865.7989
2024-04-29 23:58:45 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #627: GFLOPs: 686.4739. Time: 336.9558 us. Best GFLOPs: 865.7989
2024-04-29 23:58:45 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #628: GFLOPs: 732.3482. Time: 315.8489 us. Best GFLOPs: 865.7989
2024-04-29 23:58:45 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #629: GFLOPs: 763.1532. Time: 303.0995 us. Best GFLOPs: 865.7989
2024-04-29 23:58:45 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #630: GFLOPs: 841.2583. Time: 274.9588 us. Best GFLOPs: 865.7989
2024-04-29 23:58:45 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #631: GFLOPs: 576.5612. Time: 401.1913 us. Best GFLOPs: 865.7989
2024-04-29 23:58:45 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #632: GFLOPs: 608.1798. Time: 380.3338 us. Best GFLOPs: 865.7989
2024-04-29 23:58:45 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #633: GFLOPs: 758.9581. Time: 304.7749 us. Best GFLOPs: 865.7989
2024-04-29 23:58:45 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #634: GFLOPs: 792.2257. Time: 291.9766 us. Best GFLOPs: 865.7989
2024-04-29 23:58:45 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #635: GFLOPs: 793.4036. Time: 291.5431 us. Best GFLOPs: 865.7989
2024-04-29 23:58:45 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #636: GFLOPs: 532.9883. Time: 433.9896 us. Best GFLOPs: 865.7989
2024-04-29 23:58:45 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #637: GFLOPs: 780.6653. Time: 296.3003 us. Best GFLOPs: 865.7989
2024-04-29 23:58:45 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #638: GFLOPs: 111.9921. Time: 2065.4259 us. Best GFLOPs: 865.7989
2024-04-29 23:58:45 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #639: GFLOPs: 54.5387. Time: 4241.2341 us. Best GFLOPs: 865.7989
2024-04-29 23:58:45 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #640: GFLOPs: 6.6873. Time: 34589.4873 us. Best GFLOPs: 865.7989
2024-04-30 00:23:15 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-30 00:23:16 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-30 00:23:20 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xcae1558)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x11641818)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x6b93998)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xda39458)]: 0 failure(s)
2024-04-30 00:23:20 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-30 00:23:33 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xcae1558)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x11641818)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x6b93998)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xda39458)]: 0 failure(s)
2024-04-30 00:23:47 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xcae1558)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x11641818)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x6b93998)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xda39458)]: 0 failure(s)
2024-04-30 00:24:01 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xcae1558)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x11641818)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x6b93998)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xda39458)]: 0 failure(s)
2024-04-30 00:24:15 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xcae1558)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x11641818)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x6b93998)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xda39458)]: 0 failure(s)
2024-04-30 00:24:23 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9844  0.9844  0.9491  0.9419  0.9419  0.9414  0.9414  0.9414  0.9289  0.9213  0.9213  0.9162  0.9160  0.9160  0.9062  0.9004
[17 : 32]:	0.8950  0.8913  0.8888  0.8877  0.8847  0.8835  0.8809  0.8809  0.8734  0.8718  0.8671  0.8636  0.8631  0.8552  0.8536  0.8535
[33 : 48]:	0.8527  0.8515  0.8477  0.8422  0.8422  0.8420  0.8402  0.8356  0.8345  0.8317  0.8317  0.8264  0.8261  0.8261  0.8220  0.8197
[49 : 64]:	0.8176  0.8172  0.8172  0.8133  0.8133  0.8117  0.8117  0.8117  0.8059  0.8059  0.8040  0.8026  0.8023  0.7978  0.7928  0.7900
2024-04-30 00:24:24 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-30 00:24:24 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-30 00:26:06 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #641: GFLOPs: 428.7968. Time: 539.4429 us. Best GFLOPs: 865.7989
2024-04-30 00:26:06 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #642: GFLOPs: 852.2133. Time: 271.4243 us. Best GFLOPs: 865.7989
2024-04-30 00:26:06 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #643: GFLOPs: 849.4747. Time: 272.2993 us. Best GFLOPs: 865.7989
2024-04-30 00:26:06 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #644: GFLOPs: 830.0095. Time: 278.6852 us. Best GFLOPs: 865.7989
2024-04-30 00:26:06 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #645: GFLOPs: 791.9984. Time: 292.0604 us. Best GFLOPs: 865.7989
2024-04-30 00:26:06 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #646: GFLOPs: 837.4781. Time: 276.1999 us. Best GFLOPs: 865.7989
2024-04-30 00:26:06 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #647: GFLOPs: 835.6489. Time: 276.8045 us. Best GFLOPs: 865.7989
2024-04-30 00:26:06 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #648: GFLOPs: 837.7966. Time: 276.0949 us. Best GFLOPs: 865.7989
2024-04-30 00:26:06 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #649: GFLOPs: 803.4442. Time: 287.8997 us. Best GFLOPs: 865.7989
2024-04-30 00:26:06 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #650: GFLOPs: 331.0771. Time: 698.6632 us. Best GFLOPs: 865.7989
2024-04-30 00:26:06 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #651: GFLOPs: 235.9699. Time: 980.2580 us. Best GFLOPs: 865.7989
2024-04-30 00:26:06 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #652: GFLOPs: 836.1509. Time: 276.6383 us. Best GFLOPs: 865.7989
2024-04-30 00:26:06 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #653: GFLOPs: 826.7842. Time: 279.7724 us. Best GFLOPs: 865.7989
2024-04-30 00:26:06 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #654: GFLOPs: 836.6436. Time: 276.4754 us. Best GFLOPs: 865.7989
2024-04-30 00:26:06 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #655: GFLOPs: 786.0764. Time: 294.2607 us. Best GFLOPs: 865.7989
2024-04-30 00:26:06 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #656: GFLOPs: 786.4180. Time: 294.1328 us. Best GFLOPs: 865.7989
2024-04-30 00:26:06 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #657: GFLOPs: 789.8721. Time: 292.8466 us. Best GFLOPs: 865.7989
2024-04-30 00:26:06 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #658: GFLOPs: 522.2852. Time: 442.8832 us. Best GFLOPs: 865.7989
2024-04-30 00:26:06 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #659: GFLOPs: 804.6406. Time: 287.4717 us. Best GFLOPs: 865.7989
2024-04-30 00:26:06 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #660: GFLOPs: 771.5396. Time: 299.8049 us. Best GFLOPs: 865.7989
2024-04-30 00:26:06 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #661: GFLOPs: 761.2594. Time: 303.8535 us. Best GFLOPs: 865.7989
2024-04-30 00:26:06 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #662: GFLOPs: 797.8828. Time: 289.9064 us. Best GFLOPs: 865.7989
2024-04-30 00:26:06 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #663: GFLOPs: 760.0882. Time: 304.3218 us. Best GFLOPs: 865.7989
2024-04-30 00:26:06 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #664: GFLOPs: 762.9651. Time: 303.1742 us. Best GFLOPs: 865.7989
2024-04-30 00:26:06 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #665: GFLOPs: 818.6538. Time: 282.5509 us. Best GFLOPs: 865.7989
2024-04-30 00:26:06 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #666: GFLOPs: 821.0233. Time: 281.7354 us. Best GFLOPs: 865.7989
2024-04-30 00:26:06 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #667: GFLOPs: 807.4708. Time: 286.4640 us. Best GFLOPs: 865.7989
2024-04-30 00:26:06 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #668: GFLOPs: 789.1550. Time: 293.1127 us. Best GFLOPs: 865.7989
2024-04-30 00:26:06 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #669: GFLOPs: 783.2156. Time: 295.3355 us. Best GFLOPs: 865.7989
2024-04-30 00:26:06 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #670: GFLOPs: 654.0189. Time: 353.6769 us. Best GFLOPs: 865.7989
2024-04-30 00:26:06 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #671: GFLOPs: 753.4286. Time: 307.0116 us. Best GFLOPs: 865.7989
2024-04-30 00:26:06 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #672: GFLOPs: 752.1398. Time: 307.5377 us. Best GFLOPs: 865.7989
2024-04-30 00:26:06 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #673: GFLOPs: 806.7516. Time: 286.7194 us. Best GFLOPs: 865.7989
2024-04-30 00:26:06 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #674: GFLOPs: 767.0177. Time: 301.5724 us. Best GFLOPs: 865.7989
2024-04-30 00:26:06 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #675: GFLOPs: 786.1612. Time: 294.2289 us. Best GFLOPs: 865.7989
2024-04-30 00:26:06 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #676: GFLOPs: 753.9279. Time: 306.8083 us. Best GFLOPs: 865.7989
2024-04-30 00:26:06 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #677: GFLOPs: 796.2497. Time: 290.5010 us. Best GFLOPs: 865.7989
2024-04-30 00:26:06 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #678: GFLOPs: 667.1319. Time: 346.7251 us. Best GFLOPs: 865.7989
2024-04-30 00:26:06 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #679: GFLOPs: 743.4473. Time: 311.1335 us. Best GFLOPs: 865.7989
2024-04-30 00:26:06 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #680: GFLOPs: 792.2730. Time: 291.9592 us. Best GFLOPs: 865.7989
2024-04-30 00:26:06 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #681: GFLOPs: 760.9927. Time: 303.9600 us. Best GFLOPs: 865.7989
2024-04-30 00:26:06 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #682: GFLOPs: 776.8443. Time: 297.7577 us. Best GFLOPs: 865.7989
2024-04-30 00:26:06 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #683: GFLOPs: 616.4721. Time: 375.2179 us. Best GFLOPs: 865.7989
2024-04-30 00:26:06 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #684: GFLOPs: 737.5636. Time: 313.6155 us. Best GFLOPs: 865.7989
2024-04-30 00:26:06 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #685: GFLOPs: 724.4983. Time: 319.2711 us. Best GFLOPs: 865.7989
2024-04-30 00:26:06 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #686: GFLOPs: 747.5707. Time: 309.4174 us. Best GFLOPs: 865.7989
2024-04-30 00:26:06 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #687: GFLOPs: 733.9202. Time: 315.1723 us. Best GFLOPs: 865.7989
2024-04-30 00:26:06 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #688: GFLOPs: 748.7884. Time: 308.9142 us. Best GFLOPs: 865.7989
2024-04-30 00:26:06 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #689: GFLOPs: 709.8370. Time: 325.8655 us. Best GFLOPs: 865.7989
2024-04-30 00:26:06 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #690: GFLOPs: 774.6979. Time: 298.5827 us. Best GFLOPs: 865.7989
2024-04-30 00:26:06 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #691: GFLOPs: 783.6772. Time: 295.1615 us. Best GFLOPs: 865.7989
2024-04-30 00:26:06 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #692: GFLOPs: 604.4116. Time: 382.7050 us. Best GFLOPs: 865.7989
2024-04-30 00:26:06 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #693: GFLOPs: 600.9581. Time: 384.9043 us. Best GFLOPs: 865.7989
2024-04-30 00:26:06 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #694: GFLOPs: 734.7017. Time: 314.8371 us. Best GFLOPs: 865.7989
2024-04-30 00:26:06 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #695: GFLOPs: 722.1802. Time: 320.2959 us. Best GFLOPs: 865.7989
2024-04-30 00:26:06 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #696: GFLOPs: 724.8035. Time: 319.1366 us. Best GFLOPs: 865.7989
2024-04-30 00:26:06 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #697: GFLOPs: 735.6127. Time: 314.4472 us. Best GFLOPs: 865.7989
2024-04-30 00:26:06 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #698: GFLOPs: 741.8283. Time: 311.8125 us. Best GFLOPs: 865.7989
2024-04-30 00:26:06 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #699: GFLOPs: 739.0171. Time: 312.9987 us. Best GFLOPs: 865.7989
2024-04-30 00:26:06 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #700: GFLOPs: 737.2086. Time: 313.7665 us. Best GFLOPs: 865.7989
2024-04-30 00:26:06 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #701: GFLOPs: 570.7162. Time: 405.3002 us. Best GFLOPs: 865.7989
2024-04-30 00:26:06 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #702: GFLOPs: 5.7783. Time: 40031.3780 us. Best GFLOPs: 865.7989
2024-04-30 00:26:06 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #703: GFLOPs: 76.8687. Time: 3009.1732 us. Best GFLOPs: 865.7989
2024-04-30 00:26:06 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #704: GFLOPs: 22.9577. Time: 10075.5289 us. Best GFLOPs: 865.7989
2024-04-30 00:36:11 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-30 00:36:12 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-30 00:36:17 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xcae1558)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x11641818)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x6b93998)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xda39458)]: 0 failure(s)
2024-04-30 00:36:17 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-30 00:36:30 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xcae1558)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x11641818)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x6b93998)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xda39458)]: 0 failure(s)
2024-04-30 00:36:44 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xcae1558)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x11641818)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x6b93998)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xda39458)]: 0 failure(s)
2024-04-30 00:36:58 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xcae1558)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x11641818)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x6b93998)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xda39458)]: 0 failure(s)
2024-04-30 00:37:12 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xcae1558)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x11641818)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x6b93998)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xda39458)]: 0 failure(s)
2024-04-30 00:37:20 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9688  0.9571  0.9571  0.9456  0.9413  0.9365  0.9355  0.9354  0.9257  0.9229  0.9170  0.9155  0.9155  0.9104  0.9095  0.9095
[17 : 32]:	0.9008  0.9008  0.8995  0.8995  0.8979  0.8975  0.8962  0.8962  0.8938  0.8929  0.8917  0.8913  0.8893  0.8893  0.8888  0.8888
[33 : 48]:	0.8883  0.8878  0.8848  0.8796  0.8776  0.8757  0.8757  0.8715  0.8691  0.8657  0.8615  0.8536  0.8523  0.8506  0.8501  0.8501
[49 : 64]:	0.8492  0.8492  0.8492  0.8488  0.8423  0.8383  0.8345  0.8295  0.8219  0.8216  0.8201  0.8156  0.8133  0.8111  0.8093  0.8019
2024-04-30 00:37:21 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-30 00:37:21 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-30 00:39:07 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #705: GFLOPs: 860.1659. Time: 268.9148 us. Best GFLOPs: 865.7989
2024-04-30 00:39:07 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #706: GFLOPs: 419.3537. Time: 551.5901 us. Best GFLOPs: 865.7989
2024-04-30 00:39:07 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #707: GFLOPs: 837.0367. Time: 276.3455 us. Best GFLOPs: 865.7989
2024-04-30 00:39:07 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #708: GFLOPs: 835.2720. Time: 276.9294 us. Best GFLOPs: 865.7989
2024-04-30 00:39:07 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #709: GFLOPs: 783.7203. Time: 295.1453 us. Best GFLOPs: 865.7989
2024-04-30 00:39:07 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #710: GFLOPs: 817.8152. Time: 282.8406 us. Best GFLOPs: 865.7989
2024-04-30 00:39:07 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #711: GFLOPs: 795.4866. Time: 290.7797 us. Best GFLOPs: 865.7989
2024-04-30 00:39:07 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #712: GFLOPs: 832.9703. Time: 277.6946 us. Best GFLOPs: 865.7989
2024-04-30 00:39:07 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #713: GFLOPs: 686.1908. Time: 337.0948 us. Best GFLOPs: 865.7989
2024-04-30 00:39:07 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #714: GFLOPs: 820.2137. Time: 282.0135 us. Best GFLOPs: 865.7989
2024-04-30 00:39:07 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #715: GFLOPs: 798.7848. Time: 289.5791 us. Best GFLOPs: 865.7989
2024-04-30 00:39:07 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #716: GFLOPs: 685.8057. Time: 337.2841 us. Best GFLOPs: 865.7989
2024-04-30 00:39:07 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #717: GFLOPs: 681.0457. Time: 339.6415 us. Best GFLOPs: 865.7989
2024-04-30 00:39:07 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #718: GFLOPs: 662.9580. Time: 348.9080 us. Best GFLOPs: 865.7989
2024-04-30 00:39:07 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #719: GFLOPs: 805.2958. Time: 287.2378 us. Best GFLOPs: 865.7989
2024-04-30 00:39:07 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #720: GFLOPs: 806.5132. Time: 286.8042 us. Best GFLOPs: 865.7989
2024-04-30 00:39:07 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #721: GFLOPs: 674.9739. Time: 342.6967 us. Best GFLOPs: 865.7989
2024-04-30 00:39:07 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #722: GFLOPs: 677.8616. Time: 341.2369 us. Best GFLOPs: 865.7989
2024-04-30 00:39:07 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #723: GFLOPs: 709.3821. Time: 326.0744 us. Best GFLOPs: 865.7989
2024-04-30 00:39:07 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #724: GFLOPs: 784.2700. Time: 294.9384 us. Best GFLOPs: 865.7989
2024-04-30 00:39:07 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #725: GFLOPs: 785.2158. Time: 294.5832 us. Best GFLOPs: 865.7989
2024-04-30 00:39:07 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #726: GFLOPs: 786.2857. Time: 294.1823 us. Best GFLOPs: 865.7989
2024-04-30 00:39:07 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #727: GFLOPs: 768.0942. Time: 301.1497 us. Best GFLOPs: 865.7989
2024-04-30 00:39:07 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #728: GFLOPs: 800.8748. Time: 288.8234 us. Best GFLOPs: 865.7989
2024-04-30 00:39:07 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #729: GFLOPs: 777.6399. Time: 297.4531 us. Best GFLOPs: 865.7989
2024-04-30 00:39:07 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #730: GFLOPs: 684.9576. Time: 337.7017 us. Best GFLOPs: 865.7989
2024-04-30 00:39:07 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #731: GFLOPs: 793.6491. Time: 291.4529 us. Best GFLOPs: 865.7989
2024-04-30 00:39:07 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #732: GFLOPs: 782.4825. Time: 295.6122 us. Best GFLOPs: 865.7989
2024-04-30 00:39:07 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #733: GFLOPs: 811.5258. Time: 285.0327 us. Best GFLOPs: 865.7989
2024-04-30 00:39:07 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #734: GFLOPs: 787.3244. Time: 293.7942 us. Best GFLOPs: 865.7989
2024-04-30 00:39:07 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #735: GFLOPs: 781.3528. Time: 296.0396 us. Best GFLOPs: 865.7989
2024-04-30 00:39:07 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #736: GFLOPs: 772.6297. Time: 299.3819 us. Best GFLOPs: 865.7989
2024-04-30 00:39:07 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #737: GFLOPs: 816.6621. Time: 283.2400 us. Best GFLOPs: 865.7989
2024-04-30 00:39:07 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #738: GFLOPs: 748.3924. Time: 309.0776 us. Best GFLOPs: 865.7989
2024-04-30 00:39:07 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #739: GFLOPs: 785.6147. Time: 294.4336 us. Best GFLOPs: 865.7989
2024-04-30 00:39:07 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #740: GFLOPs: 649.9510. Time: 355.8905 us. Best GFLOPs: 865.7989
2024-04-30 00:39:07 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #741: GFLOPs: 807.4889. Time: 286.4576 us. Best GFLOPs: 865.7989
2024-04-30 00:39:07 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #742: GFLOPs: 761.7502. Time: 303.6578 us. Best GFLOPs: 865.7989
2024-04-30 00:39:07 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #743: GFLOPs: 766.4450. Time: 301.7977 us. Best GFLOPs: 865.7989
2024-04-30 00:39:07 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #744: GFLOPs: 768.6964. Time: 300.9138 us. Best GFLOPs: 865.7989
2024-04-30 00:39:07 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #745: GFLOPs: 562.4855. Time: 411.2308 us. Best GFLOPs: 865.7989
2024-04-30 00:39:07 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #746: GFLOPs: 770.0831. Time: 300.3719 us. Best GFLOPs: 865.7989
2024-04-30 00:39:07 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #747: GFLOPs: 672.3524. Time: 344.0329 us. Best GFLOPs: 865.7989
2024-04-30 00:39:07 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #748: GFLOPs: 615.8321. Time: 375.6078 us. Best GFLOPs: 865.7989
2024-04-30 00:39:07 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #749: GFLOPs: 774.7301. Time: 298.5703 us. Best GFLOPs: 865.7989
2024-04-30 00:39:07 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #750: GFLOPs: 633.7636. Time: 364.9805 us. Best GFLOPs: 865.7989
2024-04-30 00:39:07 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #751: GFLOPs: 727.0144. Time: 318.1661 us. Best GFLOPs: 865.7989
2024-04-30 00:39:07 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #752: GFLOPs: 726.7186. Time: 318.2956 us. Best GFLOPs: 865.7989
2024-04-30 00:39:07 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #753: GFLOPs: 743.5515. Time: 311.0899 us. Best GFLOPs: 865.7989
2024-04-30 00:39:07 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #754: GFLOPs: 610.2597. Time: 379.0376 us. Best GFLOPs: 865.7989
2024-04-30 00:39:07 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #755: GFLOPs: 848.3736. Time: 272.6527 us. Best GFLOPs: 865.7989
2024-04-30 00:39:07 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #756: GFLOPs: 743.2547. Time: 311.2141 us. Best GFLOPs: 865.7989
2024-04-30 00:39:07 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #757: GFLOPs: 753.2130. Time: 307.0995 us. Best GFLOPs: 865.7989
2024-04-30 00:39:07 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #758: GFLOPs: 730.2223. Time: 316.7684 us. Best GFLOPs: 865.7989
2024-04-30 00:39:07 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #759: GFLOPs: 700.3637. Time: 330.2732 us. Best GFLOPs: 865.7989
2024-04-30 00:39:07 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #760: GFLOPs: 794.9497. Time: 290.9761 us. Best GFLOPs: 865.7989
2024-04-30 00:39:07 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #761: GFLOPs: 509.5609. Time: 453.9425 us. Best GFLOPs: 865.7989
2024-04-30 00:39:07 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #762: GFLOPs: 677.5989. Time: 341.3692 us. Best GFLOPs: 865.7989
2024-04-30 00:39:07 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #763: GFLOPs: 647.6642. Time: 357.1470 us. Best GFLOPs: 865.7989
2024-04-30 00:39:07 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #764: GFLOPs: 742.9088. Time: 311.3590 us. Best GFLOPs: 865.7989
2024-04-30 00:39:07 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #765: GFLOPs: 723.7676. Time: 319.5934 us. Best GFLOPs: 865.7989
2024-04-30 00:39:07 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #766: GFLOPs: 6.1182. Time: 37806.8050 us. Best GFLOPs: 865.7989
2024-04-30 00:39:07 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #767: GFLOPs: 52.7906. Time: 4381.6748 us. Best GFLOPs: 865.7989
2024-04-30 00:39:07 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #768: GFLOPs: 67.8728. Time: 3408.0119 us. Best GFLOPs: 865.7989
2024-04-30 00:51:11 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-30 00:51:12 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-30 00:51:17 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xcae1558)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x11641818)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x6b93998)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xda39458)]: 0 failure(s)
2024-04-30 00:51:17 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-30 00:51:30 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xcae1558)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x11641818)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x6b93998)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xda39458)]: 0 failure(s)
2024-04-30 00:51:43 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xcae1558)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x11641818)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x6b93998)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xda39458)]: 0 failure(s)
2024-04-30 00:51:58 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xcae1558)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x11641818)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x6b93998)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xda39458)]: 0 failure(s)
2024-04-30 00:52:12 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xcae1558)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x11641818)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x6b93998)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xda39458)]: 0 failure(s)
2024-04-30 00:52:20 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9425  0.9412  0.9405  0.9394  0.9371  0.9371  0.9359  0.9318  0.9318  0.9318  0.9318  0.9312  0.9249  0.9239  0.9227  0.9214
[17 : 32]:	0.9214  0.9194  0.9189  0.9188  0.9139  0.9139  0.9129  0.9129  0.9120  0.9114  0.9081  0.9000  0.8990  0.8972  0.8969  0.8929
[33 : 48]:	0.8904  0.8904  0.8858  0.8803  0.8803  0.8783  0.8707  0.8581  0.8557  0.8551  0.8550  0.8522  0.8522  0.8504  0.8495  0.8487
[49 : 64]:	0.8452  0.8452  0.8439  0.8434  0.8434  0.8424  0.8322  0.8261  0.8257  0.8256  0.8239  0.8238  0.8226  0.8226  0.8218  0.8215
2024-04-30 00:52:21 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-30 00:52:21 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-30 00:54:09 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #769: GFLOPs: 835.1780. Time: 276.9605 us. Best GFLOPs: 865.7989
2024-04-30 00:54:09 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #770: GFLOPs: 827.1184. Time: 279.6593 us. Best GFLOPs: 865.7989
2024-04-30 00:54:09 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #771: GFLOPs: 817.7275. Time: 282.8710 us. Best GFLOPs: 865.7989
2024-04-30 00:54:09 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #772: GFLOPs: 819.7713. Time: 282.1657 us. Best GFLOPs: 865.7989
2024-04-30 00:54:09 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #773: GFLOPs: 795.5068. Time: 290.7723 us. Best GFLOPs: 865.7989
2024-04-30 00:54:09 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #774: GFLOPs: 800.0473. Time: 289.1221 us. Best GFLOPs: 865.7989
2024-04-30 00:54:09 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #775: GFLOPs: 822.7689. Time: 281.1377 us. Best GFLOPs: 865.7989
2024-04-30 00:54:09 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #776: GFLOPs: 808.6569. Time: 286.0439 us. Best GFLOPs: 865.7989
2024-04-30 00:54:09 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #777: GFLOPs: 798.0108. Time: 289.8599 us. Best GFLOPs: 865.7989
2024-04-30 00:54:09 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #778: GFLOPs: 802.3333. Time: 288.2984 us. Best GFLOPs: 865.7989
2024-04-30 00:54:09 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #779: GFLOPs: 807.5139. Time: 286.4488 us. Best GFLOPs: 865.7989
2024-04-30 00:54:09 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #780: GFLOPs: 825.2313. Time: 280.2988 us. Best GFLOPs: 865.7989
2024-04-30 00:54:09 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #781: GFLOPs: 785.5548. Time: 294.4560 us. Best GFLOPs: 865.7989
2024-04-30 00:54:09 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #782: GFLOPs: 803.7177. Time: 287.8018 us. Best GFLOPs: 865.7989
2024-04-30 00:54:09 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #783: GFLOPs: 811.7694. Time: 284.9471 us. Best GFLOPs: 865.7989
2024-04-30 00:54:09 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #784: GFLOPs: 806.7247. Time: 286.7290 us. Best GFLOPs: 865.7989
2024-04-30 00:54:09 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #785: GFLOPs: 800.5075. Time: 288.9559 us. Best GFLOPs: 865.7989
2024-04-30 00:54:09 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #786: GFLOPs: 833.3880. Time: 277.5554 us. Best GFLOPs: 865.7989
2024-04-30 00:54:09 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #787: GFLOPs: 771.9858. Time: 299.6316 us. Best GFLOPs: 865.7989
2024-04-30 00:54:09 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #788: GFLOPs: 806.4176. Time: 286.8382 us. Best GFLOPs: 865.7989
2024-04-30 00:54:09 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #789: GFLOPs: 658.2186. Time: 351.4203 us. Best GFLOPs: 865.7989
2024-04-30 00:54:09 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #790: GFLOPs: 812.1579. Time: 284.8108 us. Best GFLOPs: 865.7989
2024-04-30 00:54:09 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #791: GFLOPs: 777.8447. Time: 297.3747 us. Best GFLOPs: 865.7989
2024-04-30 00:54:09 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #792: GFLOPs: 806.4131. Time: 286.8398 us. Best GFLOPs: 865.7989
2024-04-30 00:54:09 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #793: GFLOPs: 816.2720. Time: 283.3753 us. Best GFLOPs: 865.7989
2024-04-30 00:54:09 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #794: GFLOPs: 812.3404. Time: 284.7468 us. Best GFLOPs: 865.7989
2024-04-30 00:54:09 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #795: GFLOPs: 789.3233. Time: 293.0502 us. Best GFLOPs: 865.7989
2024-04-30 00:54:09 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #796: GFLOPs: 820.4153. Time: 281.9442 us. Best GFLOPs: 865.7989
2024-04-30 00:54:09 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #797: GFLOPs: 791.7985. Time: 292.1341 us. Best GFLOPs: 865.7989
2024-04-30 00:54:09 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #798: GFLOPs: 781.7828. Time: 295.8767 us. Best GFLOPs: 865.7989
2024-04-30 00:54:09 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #799: GFLOPs: 860.0486. Time: 268.9515 us. Best GFLOPs: 865.7989
2024-04-30 00:54:09 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #800: GFLOPs: 703.3393. Time: 328.8759 us. Best GFLOPs: 865.7989
2024-04-30 00:54:09 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #801: GFLOPs: 427.9075. Time: 540.5639 us. Best GFLOPs: 865.7989
2024-04-30 00:54:09 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #802: GFLOPs: 448.1907. Time: 516.1003 us. Best GFLOPs: 865.7989
2024-04-30 00:54:09 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #803: GFLOPs: 412.5873. Time: 560.6362 us. Best GFLOPs: 865.7989
2024-04-30 00:54:09 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #804: GFLOPs: 423.6647. Time: 545.9774 us. Best GFLOPs: 865.7989
2024-04-30 00:54:09 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #805: GFLOPs: 412.3494. Time: 560.9596 us. Best GFLOPs: 865.7989
2024-04-30 00:54:09 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #806: GFLOPs: 347.5317. Time: 665.5835 us. Best GFLOPs: 865.7989
2024-04-30 00:54:09 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #807: GFLOPs: 741.3094. Time: 312.0308 us. Best GFLOPs: 865.7989
2024-04-30 00:54:09 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #808: GFLOPs: 716.7649. Time: 322.7158 us. Best GFLOPs: 865.7989
2024-04-30 00:54:09 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #809: GFLOPs: 663.9179. Time: 348.4036 us. Best GFLOPs: 865.7989
2024-04-30 00:54:09 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #810: GFLOPs: 760.9857. Time: 303.9628 us. Best GFLOPs: 865.7989
2024-04-30 00:54:09 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #811: GFLOPs: 734.4748. Time: 314.9344 us. Best GFLOPs: 865.7989
2024-04-30 00:54:09 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #812: GFLOPs: 702.9859. Time: 329.0412 us. Best GFLOPs: 865.7989
2024-04-30 00:54:09 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #813: GFLOPs: 699.9584. Time: 330.4644 us. Best GFLOPs: 865.7989
2024-04-30 00:54:09 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #814: GFLOPs: 664.9893. Time: 347.8422 us. Best GFLOPs: 865.7989
2024-04-30 00:54:09 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #815: GFLOPs: 733.1740. Time: 315.4931 us. Best GFLOPs: 865.7989
2024-04-30 00:54:09 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #816: GFLOPs: 801.9020. Time: 288.4534 us. Best GFLOPs: 865.7989
2024-04-30 00:54:09 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #817: GFLOPs: 727.0629. Time: 318.1449 us. Best GFLOPs: 865.7989
2024-04-30 00:54:09 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #818: GFLOPs: 736.3072. Time: 314.1506 us. Best GFLOPs: 865.7989
2024-04-30 00:54:09 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #819: GFLOPs: 763.6239. Time: 302.9127 us. Best GFLOPs: 865.7989
2024-04-30 00:54:09 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #820: GFLOPs: 716.7659. Time: 322.7154 us. Best GFLOPs: 865.7989
2024-04-30 00:54:09 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #821: GFLOPs: 716.2265. Time: 322.9584 us. Best GFLOPs: 865.7989
2024-04-30 00:54:09 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #822: GFLOPs: 547.3109. Time: 422.6325 us. Best GFLOPs: 865.7989
2024-04-30 00:54:09 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #823: GFLOPs: 817.2719. Time: 283.0286 us. Best GFLOPs: 865.7989
2024-04-30 00:54:09 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #824: GFLOPs: 746.5582. Time: 309.8370 us. Best GFLOPs: 865.7989
2024-04-30 00:54:09 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #825: GFLOPs: 726.5905. Time: 318.3518 us. Best GFLOPs: 865.7989
2024-04-30 00:54:09 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #826: GFLOPs: 720.8633. Time: 320.8810 us. Best GFLOPs: 865.7989
2024-04-30 00:54:09 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #827: GFLOPs: 793.6605. Time: 291.4488 us. Best GFLOPs: 865.7989
2024-04-30 00:54:09 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #828: GFLOPs: 668.2739. Time: 346.1326 us. Best GFLOPs: 865.7989
2024-04-30 00:54:09 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #829: GFLOPs: 662.3545. Time: 349.2259 us. Best GFLOPs: 865.7989
2024-04-30 00:54:09 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #830: GFLOPs: 4.5717. Time: 50596.4937 us. Best GFLOPs: 865.7989
2024-04-30 00:54:09 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #831: GFLOPs: 83.8380. Time: 2759.0271 us. Best GFLOPs: 865.7989
2024-04-30 00:54:09 [INFO] [task_scheduler.cc:121] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #832: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(14), T.int64(14), T.int64(128)), "float32"), p1: T.Buffer((T.int64(16), T.int64(2), T.int64(3), T.int64(3), T.int64(128), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(16), T.int64(16), T.int64(128)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused in T.parallel(T.int64(64), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(4), T.int64(2), T.int64(14), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(1)):
                with T.block("conv2d_NCHWc_init"):
                    v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                    v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(32) * T.int64(8) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(16) // T.int64(8) * T.int64(4) + oc_chunk_2_init + oc_chunk_3_init)
                    v_oh = T.axis.spatial(T.int64(14), oh_2_init * T.int64(7) + oh_3_init)
                    v_ow = T.axis.spatial(T.int64(14), ow_2_init + ow_3_init)
                    v_oc_block = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(32) // T.int64(16) * T.int64(8) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(8) + oc_block_2_init + oc_block_3_init)
                    T.reads()
                    T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                    T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                    conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
            for ic_0 in range(T.int64(256)):
                for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(16), T.int64(16), T.int64(1)):
                    with T.block("data_pad"):
                        v_i0 = T.axis.spatial(T.int64(1), ax0)
                        v_i1 = T.axis.spatial(T.int64(2), ic_0 // T.int64(128) + ax1)
                        v_i2, v_i3 = T.axis.remap("SS", [ax2, ax3])
                        v_i4 = T.axis.spatial(T.int64(128), ic_0 % T.int64(128) + ax4)
                        T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                        T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                        data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(15) and T.int64(1) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                for kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(3), T.int64(3), T.int64(1), T.int64(4), T.int64(2), T.int64(14), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(32) * T.int64(8) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(16) // T.int64(8) * T.int64(4) + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(14), oh_2 * T.int64(7) + oh_3)
                        v_ow = T.axis.spatial(T.int64(14), ow_2 + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(32) // T.int64(16) * T.int64(8) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(8) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(256), ic_0 + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(4), T.int64(14), T.int64(14), T.int64(1)):
                with T.block("T_relu"):
                    v_ax0 = T.axis.spatial(T.int64(1), ax0)
                    v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(32) * T.int64(8) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(16) // T.int64(8) * T.int64(4) + ax1)
                    v_ax2, v_ax3 = T.axis.remap("SS", [ax2, ax3])
                    v_ax4 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(32) // T.int64(16) * T.int64(8) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(8) + ax4)
                    T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                    T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[2, 2, 4, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 2, 7])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 14, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[2, 8, 1, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[256, 1])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=10)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86 = sch.get_loops(block=b68)
l87 = sch.fuse(l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, preserve_unit_iters=True)
sch.parallel(loop=l87)
l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b69)
l105 = sch.fuse(l88, preserve_unit_iters=True)
sch.parallel(loop=l105)
sch.annotate(block_or_loop=l105, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l105, ann_key="pragma_unroll_explicit", ann_val=1)
l106, l107, l108, l109, l110, l111 = sch.get_loops(block=b70)
b112 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l113, l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129 = sch.get_loops(block=b112)
b130 = sch.decompose_reduction(block=b112, loop=l114)
2024-04-30 01:11:55 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-30 01:11:56 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-30 01:12:01 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xcae1558)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x11641818)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x6b93998)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xda39458)]: 0 failure(s)
2024-04-30 01:12:01 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-30 01:12:14 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xcae1558)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x11641818)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x6b93998)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xda39458)]: 0 failure(s)
2024-04-30 01:12:28 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xcae1558)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x11641818)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x6b93998)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xda39458)]: 0 failure(s)
2024-04-30 01:12:43 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xcae1558)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x11641818)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x6b93998)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xda39458)]: 0 failure(s)
2024-04-30 01:12:57 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xcae1558)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x11641818)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x6b93998)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xda39458)]: 0 failure(s)
2024-04-30 01:13:06 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9751  0.9543  0.9543  0.9459  0.9382  0.9382  0.9382  0.9282  0.9255  0.9234  0.9131  0.9131  0.9099  0.9048  0.9032  0.9031
[17 : 32]:	0.8940  0.8907  0.8906  0.8893  0.8877  0.8816  0.8813  0.8813  0.8813  0.8717  0.8687  0.8683  0.8661  0.8661  0.8654  0.8549
[33 : 48]:	0.8549  0.8469  0.8448  0.8427  0.8416  0.8387  0.8307  0.8286  0.8270  0.8261  0.8173  0.8173  0.8166  0.8025  0.8005  0.7990
[49 : 64]:	0.7900  0.7893  0.7884  0.7883  0.7876  0.7857  0.7772  0.7772  0.7757  0.7725  0.7717  0.7716  0.7681  0.7632  0.7575  0.7575
2024-04-30 01:13:06 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-30 01:13:06 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-30 01:14:49 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #833: GFLOPs: 852.9432. Time: 271.1920 us. Best GFLOPs: 865.7989
2024-04-30 01:14:49 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #834: GFLOPs: 855.9530. Time: 270.2384 us. Best GFLOPs: 865.7989
2024-04-30 01:14:49 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #835: GFLOPs: 848.8285. Time: 272.5066 us. Best GFLOPs: 865.7989
2024-04-30 01:14:49 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #836: GFLOPs: 808.8957. Time: 285.9594 us. Best GFLOPs: 865.7989
2024-04-30 01:14:49 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #837: GFLOPs: 811.5643. Time: 285.0191 us. Best GFLOPs: 865.7989
2024-04-30 01:14:49 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #838: GFLOPs: 822.6452. Time: 281.1800 us. Best GFLOPs: 865.7989
2024-04-30 01:14:49 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #839: GFLOPs: 822.7739. Time: 281.1360 us. Best GFLOPs: 865.7989
2024-04-30 01:14:49 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #840: GFLOPs: 794.5558. Time: 291.1203 us. Best GFLOPs: 865.7989
2024-04-30 01:14:49 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #841: GFLOPs: 839.3778. Time: 275.5748 us. Best GFLOPs: 865.7989
2024-04-30 01:14:49 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #842: GFLOPs: 799.0041. Time: 289.4996 us. Best GFLOPs: 865.7989
2024-04-30 01:14:49 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #843: GFLOPs: 833.0179. Time: 277.6787 us. Best GFLOPs: 865.7989
2024-04-30 01:14:49 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #844: GFLOPs: 845.3611. Time: 273.6243 us. Best GFLOPs: 865.7989
2024-04-30 01:14:49 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #845: GFLOPs: 798.6243. Time: 289.6373 us. Best GFLOPs: 865.7989
2024-04-30 01:14:49 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #846: GFLOPs: 791.6969. Time: 292.1716 us. Best GFLOPs: 865.7989
2024-04-30 01:14:49 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #847: GFLOPs: 792.8921. Time: 291.7312 us. Best GFLOPs: 865.7989
2024-04-30 01:14:49 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #848: GFLOPs: 804.0312. Time: 287.6895 us. Best GFLOPs: 865.7989
2024-04-30 01:14:49 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #849: GFLOPs: 808.5178. Time: 286.0931 us. Best GFLOPs: 865.7989
2024-04-30 01:14:49 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #850: GFLOPs: 752.2993. Time: 307.4725 us. Best GFLOPs: 865.7989
2024-04-30 01:14:49 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #851: GFLOPs: 785.2076. Time: 294.5863 us. Best GFLOPs: 865.7989
2024-04-30 01:14:49 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #852: GFLOPs: 751.4069. Time: 307.8377 us. Best GFLOPs: 865.7989
2024-04-30 01:14:49 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #853: GFLOPs: 682.4006. Time: 338.9671 us. Best GFLOPs: 865.7989
2024-04-30 01:14:49 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #854: GFLOPs: 780.6549. Time: 296.3043 us. Best GFLOPs: 865.7989
2024-04-30 01:14:49 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #855: GFLOPs: 791.2603. Time: 292.3328 us. Best GFLOPs: 865.7989
2024-04-30 01:14:49 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #856: GFLOPs: 796.4472. Time: 290.4290 us. Best GFLOPs: 865.7989
2024-04-30 01:14:49 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #857: GFLOPs: 796.2730. Time: 290.4925 us. Best GFLOPs: 865.7989
2024-04-30 01:14:49 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #858: GFLOPs: 739.9812. Time: 312.5909 us. Best GFLOPs: 865.7989
2024-04-30 01:14:49 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #859: GFLOPs: 777.7970. Time: 297.3930 us. Best GFLOPs: 865.7989
2024-04-30 01:14:49 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #860: GFLOPs: 804.6269. Time: 287.4765 us. Best GFLOPs: 865.7989
2024-04-30 01:14:49 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #861: GFLOPs: 750.7934. Time: 308.0892 us. Best GFLOPs: 865.7989
2024-04-30 01:14:49 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #862: GFLOPs: 748.4788. Time: 309.0420 us. Best GFLOPs: 865.7989
2024-04-30 01:14:49 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #863: GFLOPs: 817.1536. Time: 283.0696 us. Best GFLOPs: 865.7989
2024-04-30 01:14:49 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #864: GFLOPs: 704.0534. Time: 328.5424 us. Best GFLOPs: 865.7989
2024-04-30 01:14:49 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #865: GFLOPs: 794.3584. Time: 291.1927 us. Best GFLOPs: 865.7989
2024-04-30 01:14:49 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #866: GFLOPs: 748.3654. Time: 309.0888 us. Best GFLOPs: 865.7989
2024-04-30 01:14:49 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #867: GFLOPs: 734.5569. Time: 314.8992 us. Best GFLOPs: 865.7989
2024-04-30 01:14:49 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #868: GFLOPs: 508.7098. Time: 454.7020 us. Best GFLOPs: 865.7989
2024-04-30 01:14:49 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #869: GFLOPs: 734.2691. Time: 315.0226 us. Best GFLOPs: 865.7989
2024-04-30 01:14:49 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #870: GFLOPs: 789.1938. Time: 293.0983 us. Best GFLOPs: 865.7989
2024-04-30 01:14:49 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #871: GFLOPs: 745.5450. Time: 310.2581 us. Best GFLOPs: 865.7989
2024-04-30 01:14:49 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #872: GFLOPs: 809.1113. Time: 285.8833 us. Best GFLOPs: 865.7989
2024-04-30 01:14:49 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #873: GFLOPs: 352.6095. Time: 655.9986 us. Best GFLOPs: 865.7989
2024-04-30 01:14:49 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #874: GFLOPs: 365.4756. Time: 632.9051 us. Best GFLOPs: 865.7989
2024-04-30 01:14:49 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #875: GFLOPs: 716.1447. Time: 322.9953 us. Best GFLOPs: 865.7989
2024-04-30 01:14:49 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #876: GFLOPs: 727.1621. Time: 318.1015 us. Best GFLOPs: 865.7989
2024-04-30 01:14:49 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #877: GFLOPs: 778.6266. Time: 297.0761 us. Best GFLOPs: 865.7989
2024-04-30 01:14:49 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #878: GFLOPs: 682.2848. Time: 339.0246 us. Best GFLOPs: 865.7989
2024-04-30 01:14:49 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #879: GFLOPs: 575.0965. Time: 402.2131 us. Best GFLOPs: 865.7989
2024-04-30 01:14:49 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #880: GFLOPs: 808.4911. Time: 286.1026 us. Best GFLOPs: 865.7989
2024-04-30 01:14:49 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #881: GFLOPs: 765.1961. Time: 302.2903 us. Best GFLOPs: 865.7989
2024-04-30 01:14:49 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #882: GFLOPs: 630.9558. Time: 366.6047 us. Best GFLOPs: 865.7989
2024-04-30 01:14:49 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #883: GFLOPs: 696.0011. Time: 332.3434 us. Best GFLOPs: 865.7989
2024-04-30 01:14:49 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #884: GFLOPs: 773.1235. Time: 299.1907 us. Best GFLOPs: 865.7989
2024-04-30 01:14:49 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #885: GFLOPs: 768.4384. Time: 301.0148 us. Best GFLOPs: 865.7989
2024-04-30 01:14:49 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #886: GFLOPs: 650.6838. Time: 355.4897 us. Best GFLOPs: 865.7989
2024-04-30 01:14:49 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #887: GFLOPs: 756.3200. Time: 305.8379 us. Best GFLOPs: 865.7989
2024-04-30 01:14:49 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #888: GFLOPs: 727.1571. Time: 318.1037 us. Best GFLOPs: 865.7989
2024-04-30 01:14:49 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #889: GFLOPs: 719.3345. Time: 321.5630 us. Best GFLOPs: 865.7989
2024-04-30 01:14:49 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #890: GFLOPs: 519.7814. Time: 445.0166 us. Best GFLOPs: 865.7989
2024-04-30 01:14:49 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #891: GFLOPs: 536.9049. Time: 430.8237 us. Best GFLOPs: 865.7989
2024-04-30 01:14:49 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #892: GFLOPs: 770.9356. Time: 300.0398 us. Best GFLOPs: 865.7989
2024-04-30 01:14:49 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #893: GFLOPs: 642.8472. Time: 359.8233 us. Best GFLOPs: 865.7989
2024-04-30 01:14:49 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #894: GFLOPs: 1.2846. Time: 180064.5990 us. Best GFLOPs: 865.7989
2024-04-30 01:14:49 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #895: GFLOPs: 31.8749. Time: 7256.8417 us. Best GFLOPs: 865.7989
2024-04-30 01:14:49 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #896: GFLOPs: 3.0469. Time: 75918.0223 us. Best GFLOPs: 865.7989
2024-04-30 01:24:07 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-30 01:24:08 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-30 01:24:12 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xcae1558)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x11641818)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x6b93998)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xda39458)]: 0 failure(s)
2024-04-30 01:24:12 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-30 01:24:25 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xcae1558)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x11641818)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x6b93998)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xda39458)]: 0 failure(s)
2024-04-30 01:24:39 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xcae1558)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x11641818)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x6b93998)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xda39458)]: 0 failure(s)
2024-04-30 01:24:53 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xcae1558)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x11641818)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x6b93998)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xda39458)]: 0 failure(s)
2024-04-30 01:25:08 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xcae1558)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x11641818)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x6b93998)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xda39458)]: 0 failure(s)
2024-04-30 01:25:16 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9557  0.9412  0.9409  0.9396  0.9396  0.9376  0.9353  0.9332  0.9332  0.9229  0.9219  0.9150  0.9148  0.9125  0.9101  0.9065
[17 : 32]:	0.9065  0.9065  0.8967  0.8960  0.8953  0.8953  0.8953  0.8903  0.8895  0.8894  0.8865  0.8821  0.8777  0.8751  0.8751  0.8751
[33 : 48]:	0.8715  0.8690  0.8583  0.8519  0.8511  0.8449  0.8414  0.8360  0.8358  0.8356  0.8339  0.8319  0.8315  0.8302  0.8272  0.8268
[49 : 64]:	0.8268  0.8259  0.8235  0.8235  0.8235  0.8230  0.8215  0.8192  0.8190  0.8151  0.8111  0.8086  0.8060  0.8034  0.8034  0.8024
2024-04-30 01:25:17 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-30 01:25:17 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-30 01:27:09 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #897: GFLOPs: 451.1797. Time: 512.6812 us. Best GFLOPs: 865.7989
2024-04-30 01:27:09 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #898: GFLOPs: 429.3552. Time: 538.7413 us. Best GFLOPs: 865.7989
2024-04-30 01:27:09 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #899: GFLOPs: 829.6371. Time: 278.8103 us. Best GFLOPs: 865.7989
2024-04-30 01:27:09 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #900: GFLOPs: 831.0741. Time: 278.3282 us. Best GFLOPs: 865.7989
2024-04-30 01:27:09 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #901: GFLOPs: 855.7550. Time: 270.3009 us. Best GFLOPs: 865.7989
2024-04-30 01:27:09 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #902: GFLOPs: 814.8695. Time: 283.8631 us. Best GFLOPs: 865.7989
2024-04-30 01:27:09 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #903: GFLOPs: 840.3614. Time: 275.2522 us. Best GFLOPs: 865.7989
2024-04-30 01:27:09 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #904: GFLOPs: 850.0961. Time: 272.1002 us. Best GFLOPs: 865.7989
2024-04-30 01:27:09 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #905: GFLOPs: 859.8002. Time: 269.0292 us. Best GFLOPs: 865.7989
2024-04-30 01:27:09 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #906: GFLOPs: 721.7543. Time: 320.4849 us. Best GFLOPs: 865.7989
2024-04-30 01:27:09 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #907: GFLOPs: 810.4732. Time: 285.4028 us. Best GFLOPs: 865.7989
2024-04-30 01:27:09 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #908: GFLOPs: 733.2122. Time: 315.4767 us. Best GFLOPs: 865.7989
2024-04-30 01:27:09 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #909: GFLOPs: 632.6002. Time: 365.6518 us. Best GFLOPs: 865.7989
2024-04-30 01:27:09 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #910: GFLOPs: 833.8457. Time: 277.4031 us. Best GFLOPs: 865.7989
2024-04-30 01:27:09 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #911: GFLOPs: 760.8560. Time: 304.0147 us. Best GFLOPs: 865.7989
2024-04-30 01:27:09 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #912: GFLOPs: 814.6064. Time: 283.9547 us. Best GFLOPs: 865.7989
2024-04-30 01:27:09 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #913: GFLOPs: 815.3637. Time: 283.6910 us. Best GFLOPs: 865.7989
2024-04-30 01:27:09 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #914: GFLOPs: 809.0999. Time: 285.8873 us. Best GFLOPs: 865.7989
2024-04-30 01:27:09 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #915: GFLOPs: 810.0329. Time: 285.5580 us. Best GFLOPs: 865.7989
2024-04-30 01:27:09 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #916: GFLOPs: 803.2978. Time: 287.9522 us. Best GFLOPs: 865.7989
2024-04-30 01:27:09 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #917: GFLOPs: 780.3543. Time: 296.4184 us. Best GFLOPs: 865.7989
2024-04-30 01:27:09 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #918: GFLOPs: 774.6882. Time: 298.5864 us. Best GFLOPs: 865.7989
2024-04-30 01:27:09 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #919: GFLOPs: 732.9829. Time: 315.5754 us. Best GFLOPs: 865.7989
2024-04-30 01:27:09 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #920: GFLOPs: 801.4177. Time: 288.6277 us. Best GFLOPs: 865.7989
2024-04-30 01:27:09 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #921: GFLOPs: 733.7085. Time: 315.2633 us. Best GFLOPs: 865.7989
2024-04-30 01:27:09 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #922: GFLOPs: 793.9601. Time: 291.3388 us. Best GFLOPs: 865.7989
2024-04-30 01:27:09 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #923: GFLOPs: 769.9002. Time: 300.4433 us. Best GFLOPs: 865.7989
2024-04-30 01:27:09 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #924: GFLOPs: 778.0817. Time: 297.2841 us. Best GFLOPs: 865.7989
2024-04-30 01:27:09 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #925: GFLOPs: 778.8058. Time: 297.0078 us. Best GFLOPs: 865.7989
2024-04-30 01:27:09 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #926: GFLOPs: 756.6308. Time: 305.7123 us. Best GFLOPs: 865.7989
2024-04-30 01:27:09 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #927: GFLOPs: 755.2897. Time: 306.2551 us. Best GFLOPs: 865.7989
2024-04-30 01:27:09 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #928: GFLOPs: 754.4326. Time: 306.6031 us. Best GFLOPs: 865.7989
2024-04-30 01:27:09 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #929: GFLOPs: 783.1394. Time: 295.3642 us. Best GFLOPs: 865.7989
2024-04-30 01:27:09 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #930: GFLOPs: 736.4239. Time: 314.1008 us. Best GFLOPs: 865.7989
2024-04-30 01:27:09 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #931: GFLOPs: 793.4056. Time: 291.5424 us. Best GFLOPs: 865.7989
2024-04-30 01:27:09 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #932: GFLOPs: 721.1322. Time: 320.7614 us. Best GFLOPs: 865.7989
2024-04-30 01:27:09 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #933: GFLOPs: 817.2803. Time: 283.0257 us. Best GFLOPs: 865.7989
2024-04-30 01:27:09 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #934: GFLOPs: 784.4098. Time: 294.8859 us. Best GFLOPs: 865.7989
2024-04-30 01:27:09 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #935: GFLOPs: 746.2569. Time: 309.9621 us. Best GFLOPs: 865.7989
2024-04-30 01:27:09 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #936: GFLOPs: 670.1782. Time: 345.1490 us. Best GFLOPs: 865.7989
2024-04-30 01:27:09 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #937: GFLOPs: 780.1887. Time: 296.4813 us. Best GFLOPs: 865.7989
2024-04-30 01:27:09 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #938: GFLOPs: 762.4002. Time: 303.3989 us. Best GFLOPs: 865.7989
2024-04-30 01:27:09 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #939: GFLOPs: 707.6068. Time: 326.8925 us. Best GFLOPs: 865.7989
2024-04-30 01:27:09 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #940: GFLOPs: 728.2675. Time: 317.6187 us. Best GFLOPs: 865.7989
2024-04-30 01:27:09 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #941: GFLOPs: 657.6249. Time: 351.7375 us. Best GFLOPs: 865.7989
2024-04-30 01:27:09 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #942: GFLOPs: 541.8144. Time: 426.9199 us. Best GFLOPs: 865.7989
2024-04-30 01:27:09 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #943: GFLOPs: 615.9649. Time: 375.5268 us. Best GFLOPs: 865.7989
2024-04-30 01:27:09 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #944: GFLOPs: 677.5742. Time: 341.3816 us. Best GFLOPs: 865.7989
2024-04-30 01:27:09 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #945: GFLOPs: 751.5898. Time: 307.7628 us. Best GFLOPs: 865.7989
2024-04-30 01:27:09 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #946: GFLOPs: 681.6187. Time: 339.3560 us. Best GFLOPs: 865.7989
2024-04-30 01:27:09 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #947: GFLOPs: 729.6309. Time: 317.0252 us. Best GFLOPs: 865.7989
2024-04-30 01:27:09 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #948: GFLOPs: 734.0767. Time: 315.1052 us. Best GFLOPs: 865.7989
2024-04-30 01:27:09 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #949: GFLOPs: 726.3463. Time: 318.4588 us. Best GFLOPs: 865.7989
2024-04-30 01:27:09 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #950: GFLOPs: 776.1902. Time: 298.0086 us. Best GFLOPs: 865.7989
2024-04-30 01:27:09 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #951: GFLOPs: 102.5023. Time: 2256.6450 us. Best GFLOPs: 865.7989
2024-04-30 01:27:09 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #952: GFLOPs: 751.5458. Time: 307.7808 us. Best GFLOPs: 865.7989
2024-04-30 01:27:09 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #953: GFLOPs: 533.5403. Time: 433.5406 us. Best GFLOPs: 865.7989
2024-04-30 01:27:09 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #954: GFLOPs: 728.7364. Time: 317.4143 us. Best GFLOPs: 865.7989
2024-04-30 01:27:09 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #955: GFLOPs: 652.9720. Time: 354.2439 us. Best GFLOPs: 865.7989
2024-04-30 01:27:09 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #956: GFLOPs: 800.1086. Time: 289.1000 us. Best GFLOPs: 865.7989
2024-04-30 01:27:09 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #957: GFLOPs: 865.8739. Time: 267.1421 us. Best GFLOPs: 865.8739
2024-04-30 01:27:09 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #958: GFLOPs: 0.9951. Time: 232448.3680 us. Best GFLOPs: 865.8739
2024-04-30 01:27:09 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #959: GFLOPs: 4.6510. Time: 49733.7083 us. Best GFLOPs: 865.8739
2024-04-30 01:27:09 [INFO] [task_scheduler.cc:131] [Task #34: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11] Trial #960: GFLOPs: 8.7790. Time: 26348.3155 us. Best GFLOPs: 865.8739
