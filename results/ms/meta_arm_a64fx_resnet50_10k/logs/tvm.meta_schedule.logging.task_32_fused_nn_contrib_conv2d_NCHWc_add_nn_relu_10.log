2024-04-29 19:38:33 [INFO] [task_scheduler.cc:160] Initializing Task #32: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10"
2024-04-29 19:38:33 [INFO] [task_scheduler.cc:35] 
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(14), T.int64(14), T.int64(512)), "float32"), p1: T.Buffer((T.int64(4), T.int64(2), T.int64(1), T.int64(1), T.int64(512), T.int64(64)), "float32"), p2: T.Buffer((T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(64)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(4), T.int64(14), T.int64(14), T.int64(64)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(4), T.int64(14), T.int64(14), T.int64(64)))
        T_add = T.alloc_buffer((T.int64(1), T.int64(4), T.int64(14), T.int64(14), T.int64(64)))
        for n, oc_chunk, oh, ow, oc_block, ic, kh, kw in T.grid(T.int64(1), T.int64(4), T.int64(14), T.int64(14), T.int64(64), T.int64(1024), T.int64(1), T.int64(1)):
            with T.block("conv2d_NCHWc"):
                v_n, v_oc_chunk, v_oh, v_ow, v_oc_block, v_ic, v_kh, v_kw = T.axis.remap("SSSSSRRR", [n, oc_chunk, oh, ow, oc_block, ic, kh, kw])
                T.reads(p0[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                with T.init():
                    conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + p0[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
        for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(4), T.int64(14), T.int64(14), T.int64(64)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                T.writes(T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4]
        for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(4), T.int64(14), T.int64(14), T.int64(64)):
            with T.block("T_relu"):
                v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                T.reads(T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
2024-04-29 19:38:33 [INFO] [task_scheduler.cc:164] Total 3 design space(s) generated
2024-04-29 19:38:33 [INFO] [task_scheduler.cc:170] Design space #0:
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(14), T.int64(14), T.int64(512)), "float32"), p1: T.Buffer((T.int64(4), T.int64(2), T.int64(1), T.int64(1), T.int64(512), T.int64(64)), "float32"), p2: T.Buffer((T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(64)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(4), T.int64(14), T.int64(14), T.int64(64)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel": 768, "meta_schedule.unroll_explicit": 512, "meta_schedule.vectorize": 64})
            conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(4), T.int64(14), T.int64(14), T.int64(64)))
            for n_0, oc_chunk_0, oh_0, ow_0, oc_block_0, n_1, oc_chunk_1, oh_1, ow_1, oc_block_1, ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(2), T.int64(1), T.int64(2), T.int64(1), T.int64(2), T.int64(2), T.int64(128), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(14), T.int64(1), T.int64(16), T.int64(8), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1)):
                with T.block("conv2d_NCHWc"):
                    v_n = T.axis.spatial(T.int64(1), n_0 + n_1 + n_2 + n_3)
                    v_oc_chunk = T.axis.spatial(T.int64(4), oc_chunk_0 * T.int64(4) + oc_chunk_1 * T.int64(2) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                    v_oh = T.axis.spatial(T.int64(14), oh_0 * T.int64(14) + oh_1 * T.int64(14) + oh_2 + oh_3)
                    v_ow = T.axis.spatial(T.int64(14), ow_0 * T.int64(2) + ow_1 + ow_2 + ow_3)
                    v_oc_block = T.axis.spatial(T.int64(64), oc_block_0 * T.int64(32) + oc_block_1 * T.int64(16) + oc_block_2 + oc_block_3)
                    v_ic = T.axis.reduce(T.int64(1024), ic_0 * T.int64(8) + ic_1)
                    v_kh = T.axis.reduce(T.int64(1), kh_0 + kh_1)
                    v_kw = T.axis.reduce(T.int64(1), kw_0 + kw_1)
                    T.reads(p0[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                    T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                    T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                    with T.init():
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                    conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + p0[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(4), T.int64(14), T.int64(14), T.int64(64)):
                with T.block("T_relu"):
                    v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                    T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                    T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b1 = sch.get_block(name="T_add", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l3, l4, l5, l6, l7, l8, l9, l10 = sch.get_loops(block=b0)
v11, v12, v13, v14 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l15, l16, l17, l18 = sch.split(loop=l3, factors=[v11, v12, v13, v14], preserve_unit_iters=True)
v19, v20, v21, v22 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 2, 1, 2])
l23, l24, l25, l26 = sch.split(loop=l4, factors=[v19, v20, v21, v22], preserve_unit_iters=True)
v27, v28, v29, v30 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 14, 1])
l31, l32, l33, l34 = sch.split(loop=l5, factors=[v27, v28, v29, v30], preserve_unit_iters=True)
v35, v36, v37, v38 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[7, 2, 1, 1])
l39, l40, l41, l42 = sch.split(loop=l6, factors=[v35, v36, v37, v38], preserve_unit_iters=True)
v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[2, 2, 16, 1])
l47, l48, l49, l50 = sch.split(loop=l7, factors=[v43, v44, v45, v46], preserve_unit_iters=True)
v51, v52 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[128, 8])
l53, l54 = sch.split(loop=l8, factors=[v51, v52], preserve_unit_iters=True)
v55, v56 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[1, 1])
l57, l58 = sch.split(loop=l9, factors=[v55, v56], preserve_unit_iters=True)
v59, v60 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 1])
l61, l62 = sch.split(loop=l10, factors=[v59, v60], preserve_unit_iters=True)
sch.reorder(l15, l23, l31, l39, l47, l16, l24, l32, l40, l48, l53, l57, l61, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.vectorize", ann_val=64)
v63 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v63)
2024-04-29 19:38:33 [INFO] [task_scheduler.cc:170] Design space #1:
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(14), T.int64(14), T.int64(512)), "float32"), p1: T.Buffer((T.int64(4), T.int64(2), T.int64(1), T.int64(1), T.int64(512), T.int64(64)), "float32"), p2: T.Buffer((T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(64)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(4), T.int64(14), T.int64(14), T.int64(64)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel": 768, "meta_schedule.unroll_explicit": 512, "meta_schedule.vectorize": 64})
            conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(4), T.int64(14), T.int64(14), T.int64(64)))
            for n_0, oc_chunk_0, oh_0, ow_0, oc_block_0, n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(2), T.int64(1), T.int64(2), T.int64(1), T.int64(2), T.int64(2)):
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(128), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(14), T.int64(1), T.int64(16), T.int64(8), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc"):
                        v_n = T.axis.spatial(T.int64(1), n_0 + n_1 + n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(4), oc_chunk_0 * T.int64(4) + oc_chunk_1 * T.int64(2) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(14), oh_0 * T.int64(14) + oh_1 * T.int64(14) + oh_2 + oh_3)
                        v_ow = T.axis.spatial(T.int64(14), ow_0 * T.int64(2) + ow_1 + ow_2 + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(64), oc_block_0 * T.int64(32) + oc_block_1 * T.int64(16) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(1024), ic_0 * T.int64(8) + ic_1)
                        v_kh = T.axis.reduce(T.int64(1), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(1), kw_0 + kw_1)
                        T.reads(p0[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        with T.init():
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + p0[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
                for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(2), T.int64(14), T.int64(1), T.int64(16)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(4), oc_chunk_1 * T.int64(2) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(14), ax2)
                        v_ax3 = T.axis.spatial(T.int64(14), ow_0 * T.int64(2) + ow_1 + ax3)
                        v_ax4 = T.axis.spatial(T.int64(64), oc_block_0 * T.int64(32) + oc_block_1 * T.int64(16) + ax4)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b1 = sch.get_block(name="T_add", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l3, l4, l5, l6, l7, l8, l9, l10 = sch.get_loops(block=b0)
v11, v12, v13, v14 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l15, l16, l17, l18 = sch.split(loop=l3, factors=[v11, v12, v13, v14], preserve_unit_iters=True)
v19, v20, v21, v22 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 2, 1, 2])
l23, l24, l25, l26 = sch.split(loop=l4, factors=[v19, v20, v21, v22], preserve_unit_iters=True)
v27, v28, v29, v30 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 14, 1])
l31, l32, l33, l34 = sch.split(loop=l5, factors=[v27, v28, v29, v30], preserve_unit_iters=True)
v35, v36, v37, v38 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[7, 2, 1, 1])
l39, l40, l41, l42 = sch.split(loop=l6, factors=[v35, v36, v37, v38], preserve_unit_iters=True)
v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[2, 2, 16, 1])
l47, l48, l49, l50 = sch.split(loop=l7, factors=[v43, v44, v45, v46], preserve_unit_iters=True)
v51, v52 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[128, 8])
l53, l54 = sch.split(loop=l8, factors=[v51, v52], preserve_unit_iters=True)
v55, v56 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[1, 1])
l57, l58 = sch.split(loop=l9, factors=[v55, v56], preserve_unit_iters=True)
v59, v60 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 1])
l61, l62 = sch.split(loop=l10, factors=[v59, v60], preserve_unit_iters=True)
sch.reorder(l15, l23, l31, l39, l47, l16, l24, l32, l40, l48, l53, l57, l61, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50)
b63, = sch.get_consumers(block=b0)
sch.reverse_compute_at(block=b63, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
2024-04-29 19:38:33 [INFO] [task_scheduler.cc:170] Design space #2:
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(14), T.int64(14), T.int64(512)), "float32"), p1: T.Buffer((T.int64(4), T.int64(2), T.int64(1), T.int64(1), T.int64(512), T.int64(64)), "float32"), p2: T.Buffer((T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(64)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(4), T.int64(14), T.int64(14), T.int64(64)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel": 768, "meta_schedule.unroll_explicit": 64, "meta_schedule.vectorize": 64})
            conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(4), T.int64(14), T.int64(14), T.int64(64)))
            for n_0, oc_chunk_0, oh_0, ow_0, oc_block_0 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(2)):
                for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1, ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(2), T.int64(2), T.int64(128), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(14), T.int64(1), T.int64(16), T.int64(8), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc"):
                        v_n = T.axis.spatial(T.int64(1), n_0 + n_1 + n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(4), oc_chunk_0 * T.int64(4) + oc_chunk_1 * T.int64(2) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(14), oh_0 * T.int64(14) + oh_1 * T.int64(14) + oh_2 + oh_3)
                        v_ow = T.axis.spatial(T.int64(14), ow_0 * T.int64(2) + ow_1 + ow_2 + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(64), oc_block_0 * T.int64(32) + oc_block_1 * T.int64(16) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(1024), ic_0 * T.int64(8) + ic_1)
                        v_kh = T.axis.reduce(T.int64(1), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(1), kw_0 + kw_1)
                        T.reads(p0[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        with T.init():
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + p0[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
                for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(4), T.int64(14), T.int64(2), T.int64(32)):
                    with T.block("T_relu"):
                        v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                        v_ax3 = T.axis.spatial(T.int64(14), ow_0 * T.int64(2) + ax3)
                        v_ax4 = T.axis.spatial(T.int64(64), oc_block_0 * T.int64(32) + ax4)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b1 = sch.get_block(name="T_add", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l3, l4, l5, l6, l7, l8, l9, l10 = sch.get_loops(block=b0)
v11, v12, v13, v14 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l15, l16, l17, l18 = sch.split(loop=l3, factors=[v11, v12, v13, v14], preserve_unit_iters=True)
v19, v20, v21, v22 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 2, 1, 2])
l23, l24, l25, l26 = sch.split(loop=l4, factors=[v19, v20, v21, v22], preserve_unit_iters=True)
v27, v28, v29, v30 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 14, 1])
l31, l32, l33, l34 = sch.split(loop=l5, factors=[v27, v28, v29, v30], preserve_unit_iters=True)
v35, v36, v37, v38 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[7, 2, 1, 1])
l39, l40, l41, l42 = sch.split(loop=l6, factors=[v35, v36, v37, v38], preserve_unit_iters=True)
v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[2, 2, 16, 1])
l47, l48, l49, l50 = sch.split(loop=l7, factors=[v43, v44, v45, v46], preserve_unit_iters=True)
v51, v52 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[128, 8])
l53, l54 = sch.split(loop=l8, factors=[v51, v52], preserve_unit_iters=True)
v55, v56 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[1, 1])
l57, l58 = sch.split(loop=l9, factors=[v55, v56], preserve_unit_iters=True)
v59, v60 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 1])
l61, l62 = sch.split(loop=l10, factors=[v59, v60], preserve_unit_iters=True)
sch.reorder(l15, l23, l31, l39, l47, l16, l24, l32, l40, l48, l53, l57, l61, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50)
b63, = sch.get_consumers(block=b0)
sch.reverse_compute_at(block=b63, loop=l47, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
2024-04-29 20:10:58 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 20:10:58 [INFO] [evolutionary_search.cc:715] Picked top 0 candidate(s) from database
2024-04-29 20:11:01 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4800b58)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x48148c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0xbdcc888)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x91ae188)]: 0 failure(s)
2024-04-29 20:11:01 [INFO] [evolutionary_search.cc:723] Sampled 512 candidate(s)
2024-04-29 20:11:04 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4800b58)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x48148c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0xbdcc888)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x91ae188)]: 0 failure(s)
2024-04-29 20:11:07 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4800b58)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x48148c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0xbdcc888)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x91ae188)]: 0 failure(s)
2024-04-29 20:11:10 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4800b58)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x48148c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0xbdcc888)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x91ae188)]: 0 failure(s)
2024-04-29 20:11:13 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4800b58)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x48148c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0xbdcc888)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x91ae188)]: 0 failure(s)
2024-04-29 20:11:14 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9999  0.9998  0.9986  0.9982  0.9981  0.9981  0.9980  0.9966  0.9963  0.9957  0.9955  0.9947  0.9943  0.9942  0.9938  0.9937
[17 : 32]:	0.9932  0.9922  0.9919  0.9915  0.9915  0.9908  0.9890  0.9887  0.9885  0.9882  0.9881  0.9879  0.9879  0.9872  0.9869  0.9855
[33 : 48]:	0.9836  0.9831  0.9828  0.9826  0.9821  0.9818  0.9817  0.9814  0.9813  0.9812  0.9812  0.9804  0.9804  0.9803  0.9798  0.9798
[49 : 64]:	0.9797  0.9793  0.9782  0.9775  0.9769  0.9742  0.9742  0.9729  0.9729  0.9717  0.9717  0.9713  0.9710  0.9710  0.9707  0.9706
2024-04-29 20:11:14 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 20:11:14 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 20:33:14 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #1: GFLOPs: 30.4444. Time: 3378.6400 us. Best GFLOPs: 30.4444
2024-04-29 20:33:14 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #2: GFLOPs: 4.9548. Time: 20759.7292 us. Best GFLOPs: 30.4444
2024-04-29 20:33:14 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #3: GFLOPs: 50.9923. Time: 2017.1842 us. Best GFLOPs: 50.9923
2024-04-29 20:33:14 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #4: GFLOPs: 175.3582. Time: 586.5755 us. Best GFLOPs: 175.3582
2024-04-29 20:33:14 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #5: GFLOPs: 194.5384. Time: 528.7430 us. Best GFLOPs: 194.5384
2024-04-29 20:33:14 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #6: GFLOPs: 37.1212. Time: 2770.9474 us. Best GFLOPs: 194.5384
2024-04-29 20:33:14 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #7: GFLOPs: 12.6810. Time: 8111.4157 us. Best GFLOPs: 194.5384
2024-04-29 20:33:14 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #8: GFLOPs: 19.3653. Time: 5311.6146 us. Best GFLOPs: 194.5384
2024-04-29 20:33:14 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #9: GFLOPs: 10.3662. Time: 9922.7514 us. Best GFLOPs: 194.5384
2024-04-29 20:33:14 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #10: GFLOPs: 23.9097. Time: 4302.0542 us. Best GFLOPs: 194.5384
2024-04-29 20:33:14 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #11: GFLOPs: 5.6266. Time: 18281.1297 us. Best GFLOPs: 194.5384
2024-04-29 20:33:14 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #12: GFLOPs: 64.2043. Time: 1602.0860 us. Best GFLOPs: 194.5384
2024-04-29 20:33:14 [INFO] [task_scheduler.cc:121] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #13: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(14), T.int64(14), T.int64(512)), "float32"), p1: T.Buffer((T.int64(4), T.int64(2), T.int64(1), T.int64(1), T.int64(512), T.int64(64)), "float32"), p2: T.Buffer((T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(64)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(4), T.int64(14), T.int64(14), T.int64(64)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(4), T.int64(14), T.int64(14), T.int64(64)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused in T.parallel(T.int64(112), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(2), T.int64(2), T.int64(2), T.int64(4), T.int64(1), T.int64(2), T.int64(7), T.int64(1), T.int64(1)):
                with T.block("conv2d_NCHWc_init"):
                    v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                    v_oc_chunk = T.axis.spatial(T.int64(4), oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                    v_oh = T.axis.spatial(T.int64(14), oh_2_init * T.int64(7) + oh_3_init)
                    v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused // T.int64(16) * T.int64(2) + ow_2_init + ow_3_init)
                    v_oc_block = T.axis.spatial(T.int64(64), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(16) * T.int64(4) + oc_block_2_init + oc_block_3_init)
                    T.reads()
                    T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                    T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                    conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
            for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(512), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(2), T.int64(2), T.int64(4), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(7), T.int64(1), T.int64(1)):
                with T.block("conv2d_NCHWc_update"):
                    v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                    v_oc_chunk = T.axis.spatial(T.int64(4), oc_chunk_2 * T.int64(2) + oc_chunk_3)
                    v_oh = T.axis.spatial(T.int64(14), oh_2 * T.int64(7) + oh_3)
                    v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused // T.int64(16) * T.int64(2) + ow_2 + ow_3)
                    v_oc_block = T.axis.spatial(T.int64(64), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(16) * T.int64(4) + oc_block_2 + oc_block_3)
                    v_ic = T.axis.reduce(T.int64(1024), ic_0 * T.int64(2) + ic_1)
                    v_kh = T.axis.reduce(T.int64(1), kh_0 + kh_1)
                    v_kw = T.axis.reduce(T.int64(1), kw_0 + kw_1)
                    T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], p0[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                    T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                    T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                    conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + p0[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
        for ax0_ax1_ax2_ax3_ax4_fused_0 in T.parallel(T.int64(784)):
            for ax0_ax1_ax2_ax3_ax4_fused_1 in T.vectorized(T.int64(64)):
                with T.block("T_relu"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) // T.int64(12544))
                    v_ax2 = T.axis.spatial(T.int64(14), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(12544) // T.int64(896))
                    v_ax3 = T.axis.spatial(T.int64(14), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(896) // T.int64(64))
                    v_ax4 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(64))
                    T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                    T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b1 = sch.get_block(name="T_add", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l3, l4, l5, l6, l7, l8, l9, l10 = sch.get_loops(block=b0)
v11, v12, v13, v14 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l15, l16, l17, l18 = sch.split(loop=l3, factors=[v11, v12, v13, v14], preserve_unit_iters=True)
v19, v20, v21, v22 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 2, 2])
l23, l24, l25, l26 = sch.split(loop=l4, factors=[v19, v20, v21, v22], preserve_unit_iters=True)
v27, v28, v29, v30 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 2, 7])
l31, l32, l33, l34 = sch.split(loop=l5, factors=[v27, v28, v29, v30], preserve_unit_iters=True)
v35, v36, v37, v38 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[7, 1, 2, 1])
l39, l40, l41, l42 = sch.split(loop=l6, factors=[v35, v36, v37, v38], preserve_unit_iters=True)
v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[8, 2, 4, 1])
l47, l48, l49, l50 = sch.split(loop=l7, factors=[v43, v44, v45, v46], preserve_unit_iters=True)
v51, v52 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[512, 2])
l53, l54 = sch.split(loop=l8, factors=[v51, v52], preserve_unit_iters=True)
v55, v56 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[1, 1])
l57, l58 = sch.split(loop=l9, factors=[v55, v56], preserve_unit_iters=True)
v59, v60 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 1])
l61, l62 = sch.split(loop=l10, factors=[v59, v60], preserve_unit_iters=True)
sch.reorder(l15, l23, l31, l39, l47, l16, l24, l32, l40, l48, l53, l57, l61, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.vectorize", ann_val=64)
v63 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v63)
sch.enter_postproc()
b64 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b64, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b64, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b64, ann_key="meta_schedule.unroll_explicit")
b65, b66 = sch.get_child_blocks(b64)
l67, l68, l69, l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92 = sch.get_loops(block=b65)
l93 = sch.fuse(l67, l68, l69, l70, l71, l72, l73, l74, l75, l76, preserve_unit_iters=True)
sch.parallel(loop=l93)
sch.annotate(block_or_loop=l93, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l93, ann_key="pragma_unroll_explicit", ann_val=1)
l94, l95, l96, l97, l98 = sch.get_loops(block=b66)
l99 = sch.fuse(l94, l95, l96, l97, l98, preserve_unit_iters=True)
l100, l101 = sch.split(loop=l99, factors=[None, 64], preserve_unit_iters=True)
sch.parallel(loop=l100)
sch.vectorize(loop=l101)
b102 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l103, l104, l105, l106, l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117, l118, l119 = sch.get_loops(block=b102)
b120 = sch.decompose_reduction(block=b102, loop=l104)
2024-04-29 20:33:14 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #14: GFLOPs: 1.4993. Time: 68605.5093 us. Best GFLOPs: 194.5384
2024-04-29 20:33:14 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #15: GFLOPs: 22.4435. Time: 4583.1099 us. Best GFLOPs: 194.5384
2024-04-29 20:33:14 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #16: GFLOPs: 7.0849. Time: 14518.2489 us. Best GFLOPs: 194.5384
2024-04-29 20:33:14 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #17: GFLOPs: 141.1817. Time: 728.5704 us. Best GFLOPs: 194.5384
2024-04-29 20:33:14 [INFO] [task_scheduler.cc:121] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #18: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(14), T.int64(14), T.int64(512)), "float32"), p1: T.Buffer((T.int64(4), T.int64(2), T.int64(1), T.int64(1), T.int64(512), T.int64(64)), "float32"), p2: T.Buffer((T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(64)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(4), T.int64(14), T.int64(14), T.int64(64)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(4), T.int64(14), T.int64(14), T.int64(64)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused in T.parallel(T.int64(64), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(1), T.int64(2), T.int64(7), T.int64(2), T.int64(1), T.int64(1), T.int64(7), T.int64(1)):
                for oc_block_3_fused_init in T.vectorized(T.int64(4)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(4), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused // T.int64(16) + oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(14), oh_2_init * T.int64(7) + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(8) // T.int64(4) * T.int64(7) + ow_2_init + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(64), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(16) // T.int64(8) * T.int64(32) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(4) * T.int64(8) + oc_block_2_init * T.int64(4) + oc_block_3_fused_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
            for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(512), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(7), T.int64(2), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1)):
                for oc_block_3_fused in T.vectorized(T.int64(4)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(4), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused // T.int64(16) + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(14), oh_2 * T.int64(7) + oh_3)
                        v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(8) // T.int64(4) * T.int64(7) + ow_2 + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(64), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(16) // T.int64(8) * T.int64(32) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(4) * T.int64(8) + oc_block_2 * T.int64(4) + oc_block_3_fused)
                        v_ic = T.axis.reduce(T.int64(1024), ic_0 * T.int64(2) + ic_1)
                        v_kh = T.axis.reduce(T.int64(1), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(1), kw_0 + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], p0[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + p0[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
        for ax0_ax1_ax2_ax3_ax4_fused_0 in T.parallel(T.int64(784)):
            for ax0_ax1_ax2_ax3_ax4_fused_1 in T.vectorized(T.int64(64)):
                with T.block("T_relu"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) // T.int64(12544))
                    v_ax2 = T.axis.spatial(T.int64(14), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(12544) // T.int64(896))
                    v_ax3 = T.axis.spatial(T.int64(14), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(896) // T.int64(64))
                    v_ax4 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(64))
                    T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                    T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b1 = sch.get_block(name="T_add", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l3, l4, l5, l6, l7, l8, l9, l10 = sch.get_loops(block=b0)
v11, v12, v13, v14 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l15, l16, l17, l18 = sch.split(loop=l3, factors=[v11, v12, v13, v14], preserve_unit_iters=True)
v19, v20, v21, v22 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[4, 1, 1, 1])
l23, l24, l25, l26 = sch.split(loop=l4, factors=[v19, v20, v21, v22], preserve_unit_iters=True)
v27, v28, v29, v30 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 2, 7])
l31, l32, l33, l34 = sch.split(loop=l5, factors=[v27, v28, v29, v30], preserve_unit_iters=True)
v35, v36, v37, v38 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 2, 7, 1])
l39, l40, l41, l42 = sch.split(loop=l6, factors=[v35, v36, v37, v38], preserve_unit_iters=True)
v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[2, 4, 2, 4])
l47, l48, l49, l50 = sch.split(loop=l7, factors=[v43, v44, v45, v46], preserve_unit_iters=True)
v51, v52 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[512, 2])
l53, l54 = sch.split(loop=l8, factors=[v51, v52], preserve_unit_iters=True)
v55, v56 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[1, 1])
l57, l58 = sch.split(loop=l9, factors=[v55, v56], preserve_unit_iters=True)
v59, v60 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 1])
l61, l62 = sch.split(loop=l10, factors=[v59, v60], preserve_unit_iters=True)
sch.reorder(l15, l23, l31, l39, l47, l16, l24, l32, l40, l48, l53, l57, l61, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.vectorize", ann_val=64)
v63 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v63)
sch.enter_postproc()
b64 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b64, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b64, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b64, ann_key="meta_schedule.unroll_explicit")
b65, b66 = sch.get_child_blocks(b64)
l67, l68, l69, l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92 = sch.get_loops(block=b65)
l93 = sch.fuse(l67, l68, l69, l70, l71, l72, l73, l74, l75, l76, preserve_unit_iters=True)
sch.parallel(loop=l93)
l94 = sch.fuse(l92, preserve_unit_iters=True)
sch.vectorize(loop=l94)
sch.annotate(block_or_loop=l93, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l93, ann_key="pragma_unroll_explicit", ann_val=1)
l95, l96, l97, l98, l99 = sch.get_loops(block=b66)
l100 = sch.fuse(l95, l96, l97, l98, l99, preserve_unit_iters=True)
l101, l102 = sch.split(loop=l100, factors=[None, 64], preserve_unit_iters=True)
sch.parallel(loop=l101)
sch.vectorize(loop=l102)
b103 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l104, l105, l106, l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117, l118, l119, l120 = sch.get_loops(block=b103)
b121 = sch.decompose_reduction(block=b103, loop=l105)
2024-04-29 20:33:14 [INFO] [task_scheduler.cc:121] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #19: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(14), T.int64(14), T.int64(512)), "float32"), p1: T.Buffer((T.int64(4), T.int64(2), T.int64(1), T.int64(1), T.int64(512), T.int64(64)), "float32"), p2: T.Buffer((T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(64)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(4), T.int64(14), T.int64(14), T.int64(64)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(4), T.int64(14), T.int64(14), T.int64(64)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused in T.parallel(T.int64(56), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(2), T.int64(2), T.int64(1), T.int64(8), T.int64(1), T.int64(2), T.int64(7), T.int64(2), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(4), oc_chunk_1 * T.int64(4) + oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(14), oh_1 * T.int64(14) + oh_2_init * T.int64(7) + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused // T.int64(8) * T.int64(2) + ow_1 * T.int64(2) + ow_2_init * T.int64(2) + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(64), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused % T.int64(8) * T.int64(8) + oc_block_1 * T.int64(8) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(1024), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(2), T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(7), T.int64(2), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(4), oc_chunk_1 * T.int64(4) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(14), oh_1 * T.int64(14) + oh_2 * T.int64(7) + oh_3)
                        v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused // T.int64(8) * T.int64(2) + ow_1 * T.int64(2) + ow_2 * T.int64(2) + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(64), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused % T.int64(8) * T.int64(8) + oc_block_1 * T.int64(8) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(1024), ic_0 + ic_1)
                        v_kh = T.axis.reduce(T.int64(1), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(1), kw_0 + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], p0[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + p0[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(4), T.int64(14), T.int64(2)):
                for ax4_fused in T.vectorized(T.int64(8)):
                    with T.block("T_relu"):
                        v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                        v_ax3 = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused // T.int64(8) * T.int64(2) + ax3)
                        v_ax4 = T.axis.spatial(T.int64(64), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused % T.int64(8) * T.int64(8) + ax4_fused)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b1 = sch.get_block(name="T_add", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l3, l4, l5, l6, l7, l8, l9, l10 = sch.get_loops(block=b0)
v11, v12, v13, v14 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l15, l16, l17, l18 = sch.split(loop=l3, factors=[v11, v12, v13, v14], preserve_unit_iters=True)
v19, v20, v21, v22 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 2, 2])
l23, l24, l25, l26 = sch.split(loop=l4, factors=[v19, v20, v21, v22], preserve_unit_iters=True)
v27, v28, v29, v30 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 2, 7])
l31, l32, l33, l34 = sch.split(loop=l5, factors=[v27, v28, v29, v30], preserve_unit_iters=True)
v35, v36, v37, v38 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[7, 1, 1, 2])
l39, l40, l41, l42 = sch.split(loop=l6, factors=[v35, v36, v37, v38], preserve_unit_iters=True)
v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[8, 1, 8, 1])
l47, l48, l49, l50 = sch.split(loop=l7, factors=[v43, v44, v45, v46], preserve_unit_iters=True)
v51, v52 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[1024, 1])
l53, l54 = sch.split(loop=l8, factors=[v51, v52], preserve_unit_iters=True)
v55, v56 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[1, 1])
l57, l58 = sch.split(loop=l9, factors=[v55, v56], preserve_unit_iters=True)
v59, v60 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 1])
l61, l62 = sch.split(loop=l10, factors=[v59, v60], preserve_unit_iters=True)
sch.reorder(l15, l23, l31, l39, l47, l16, l24, l32, l40, l48, l53, l57, l61, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50)
b63, = sch.get_consumers(block=b0)
sch.reverse_compute_at(block=b63, loop=l47, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
sch.enter_postproc()
b65 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b65, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b65, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b65, ann_key="meta_schedule.unroll_explicit")
b66, b67 = sch.get_child_blocks(b65)
l68, l69, l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93 = sch.get_loops(block=b66)
l94 = sch.fuse(l68, l69, l70, l71, l72, preserve_unit_iters=True)
sch.parallel(loop=l94)
sch.annotate(block_or_loop=l94, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l94, ann_key="pragma_unroll_explicit", ann_val=1)
l95, l96, l97, l98, l99, l100 = sch.get_loops(block=b67)
l101 = sch.fuse(l100, preserve_unit_iters=True)
sch.vectorize(loop=l101)
b102 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l103, l104, l105, l106, l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124 = sch.get_loops(block=b102)
b125 = sch.decompose_reduction(block=b102, loop=l109)
2024-04-29 20:33:14 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #20: GFLOPs: 8.7949. Time: 11695.4553 us. Best GFLOPs: 194.5384
2024-04-29 20:33:14 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #21: GFLOPs: 40.0029. Time: 2571.3320 us. Best GFLOPs: 194.5384
2024-04-29 20:33:14 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #22: GFLOPs: 69.5631. Time: 1478.6694 us. Best GFLOPs: 194.5384
2024-04-29 20:33:14 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #23: GFLOPs: 163.3383. Time: 629.7410 us. Best GFLOPs: 194.5384
2024-04-29 20:33:14 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #24: GFLOPs: 82.4871. Time: 1246.9918 us. Best GFLOPs: 194.5384
2024-04-29 20:33:14 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #25: GFLOPs: 60.3771. Time: 1703.6391 us. Best GFLOPs: 194.5384
2024-04-29 20:33:14 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #26: GFLOPs: 6.3378. Time: 16229.7673 us. Best GFLOPs: 194.5384
2024-04-29 20:33:14 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #27: GFLOPs: 57.8204. Time: 1778.9696 us. Best GFLOPs: 194.5384
2024-04-29 20:33:14 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #28: GFLOPs: 111.2454. Time: 924.6297 us. Best GFLOPs: 194.5384
2024-04-29 20:33:14 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #29: GFLOPs: 182.3852. Time: 563.9755 us. Best GFLOPs: 194.5384
2024-04-29 20:33:14 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #30: GFLOPs: 110.9964. Time: 926.7042 us. Best GFLOPs: 194.5384
2024-04-29 20:33:14 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #31: GFLOPs: 99.7348. Time: 1031.3435 us. Best GFLOPs: 194.5384
2024-04-29 20:33:14 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #32: GFLOPs: 174.2847. Time: 590.1884 us. Best GFLOPs: 194.5384
2024-04-29 20:33:14 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #33: GFLOPs: 61.7091. Time: 1666.8649 us. Best GFLOPs: 194.5384
2024-04-29 20:33:14 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #34: GFLOPs: 7.0007. Time: 14692.9670 us. Best GFLOPs: 194.5384
2024-04-29 20:33:14 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #35: GFLOPs: 32.9861. Time: 3118.3069 us. Best GFLOPs: 194.5384
2024-04-29 20:33:14 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #36: GFLOPs: 125.7335. Time: 818.0859 us. Best GFLOPs: 194.5384
2024-04-29 20:33:14 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #37: GFLOPs: 19.7886. Time: 5197.9827 us. Best GFLOPs: 194.5384
2024-04-29 20:33:14 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #38: GFLOPs: 280.8070. Time: 366.3043 us. Best GFLOPs: 280.8070
2024-04-29 20:33:14 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #39: GFLOPs: 141.7112. Time: 725.8481 us. Best GFLOPs: 280.8070
2024-04-29 20:33:14 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #40: GFLOPs: 35.8024. Time: 2873.0130 us. Best GFLOPs: 280.8070
2024-04-29 20:33:14 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #41: GFLOPs: 94.4434. Time: 1089.1260 us. Best GFLOPs: 280.8070
2024-04-29 20:33:14 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #42: GFLOPs: 4.4977. Time: 22869.8412 us. Best GFLOPs: 280.8070
2024-04-29 20:33:14 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #43: GFLOPs: 31.9464. Time: 3219.7915 us. Best GFLOPs: 280.8070
2024-04-29 20:33:14 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #44: GFLOPs: 0.9522. Time: 108021.0387 us. Best GFLOPs: 280.8070
2024-04-29 20:33:14 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #45: GFLOPs: 59.6585. Time: 1724.1593 us. Best GFLOPs: 280.8070
2024-04-29 20:33:14 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #46: GFLOPs: 127.9541. Time: 803.8881 us. Best GFLOPs: 280.8070
2024-04-29 20:33:14 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #47: GFLOPs: 104.2696. Time: 986.4886 us. Best GFLOPs: 280.8070
2024-04-29 20:33:14 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #48: GFLOPs: 97.1489. Time: 1058.7956 us. Best GFLOPs: 280.8070
2024-04-29 20:33:14 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #49: GFLOPs: 23.2248. Time: 4428.9262 us. Best GFLOPs: 280.8070
2024-04-29 20:33:14 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #50: GFLOPs: 70.0186. Time: 1469.0500 us. Best GFLOPs: 280.8070
2024-04-29 20:33:14 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #51: GFLOPs: 3.7632. Time: 27333.0565 us. Best GFLOPs: 280.8070
2024-04-29 20:33:14 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #52: GFLOPs: 82.9760. Time: 1239.6453 us. Best GFLOPs: 280.8070
2024-04-29 20:33:14 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #53: GFLOPs: 57.1494. Time: 1799.8585 us. Best GFLOPs: 280.8070
2024-04-29 20:33:14 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #54: GFLOPs: 76.8401. Time: 1338.6343 us. Best GFLOPs: 280.8070
2024-04-29 20:33:14 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #55: GFLOPs: 33.4149. Time: 3078.2888 us. Best GFLOPs: 280.8070
2024-04-29 20:33:14 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #56: GFLOPs: 17.6674. Time: 5822.0678 us. Best GFLOPs: 280.8070
2024-04-29 20:33:14 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #57: GFLOPs: 23.4690. Time: 4382.8429 us. Best GFLOPs: 280.8070
2024-04-29 20:33:14 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #58: GFLOPs: 82.1872. Time: 1251.5425 us. Best GFLOPs: 280.8070
2024-04-29 20:33:14 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #59: GFLOPs: 17.1574. Time: 5995.1343 us. Best GFLOPs: 280.8070
2024-04-29 20:33:14 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #60: GFLOPs: 88.1827. Time: 1166.4505 us. Best GFLOPs: 280.8070
2024-04-29 20:33:14 [INFO] [task_scheduler.cc:121] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #61: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(14), T.int64(14), T.int64(512)), "float32"), p1: T.Buffer((T.int64(4), T.int64(2), T.int64(1), T.int64(1), T.int64(512), T.int64(64)), "float32"), p2: T.Buffer((T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(64)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(4), T.int64(14), T.int64(14), T.int64(64)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(4), T.int64(14), T.int64(14), T.int64(64)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused in T.parallel(T.int64(16), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(8), T.int64(1), T.int64(4), T.int64(2), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(4), oc_chunk_1 * T.int64(4) + oc_chunk_2_init * T.int64(4) + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(14), oh_1 * T.int64(14) + oh_2_init * T.int64(2) + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused // T.int64(8) * T.int64(7) + ow_1 + ow_2_init + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(64), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused % T.int64(8) * T.int64(8) + oc_block_1 * T.int64(8) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(128), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(8), T.int64(8), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(2), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(4), oc_chunk_1 * T.int64(4) + oc_chunk_2 * T.int64(4) + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(14), oh_1 * T.int64(14) + oh_2 * T.int64(2) + oh_3)
                        v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused // T.int64(8) * T.int64(7) + ow_1 + ow_2 + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(64), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused % T.int64(8) * T.int64(8) + oc_block_1 * T.int64(8) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(1024), ic_0 * T.int64(8) + ic_1)
                        v_kh = T.axis.reduce(T.int64(1), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(1), kw_0 + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], p0[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + p0[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(4), T.int64(14), T.int64(7)):
                for ax4_fused in T.vectorized(T.int64(8)):
                    with T.block("T_relu"):
                        v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                        v_ax3 = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused // T.int64(8) * T.int64(7) + ax3)
                        v_ax4 = T.axis.spatial(T.int64(64), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused % T.int64(8) * T.int64(8) + ax4_fused)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b1 = sch.get_block(name="T_add", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l3, l4, l5, l6, l7, l8, l9, l10 = sch.get_loops(block=b0)
v11, v12, v13, v14 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l15, l16, l17, l18 = sch.split(loop=l3, factors=[v11, v12, v13, v14], preserve_unit_iters=True)
v19, v20, v21, v22 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 4])
l23, l24, l25, l26 = sch.split(loop=l4, factors=[v19, v20, v21, v22], preserve_unit_iters=True)
v27, v28, v29, v30 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 7, 2])
l31, l32, l33, l34 = sch.split(loop=l5, factors=[v27, v28, v29, v30], preserve_unit_iters=True)
v35, v36, v37, v38 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 7, 1, 1])
l39, l40, l41, l42 = sch.split(loop=l6, factors=[v35, v36, v37, v38], preserve_unit_iters=True)
v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[8, 1, 8, 1])
l47, l48, l49, l50 = sch.split(loop=l7, factors=[v43, v44, v45, v46], preserve_unit_iters=True)
v51, v52 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[128, 8])
l53, l54 = sch.split(loop=l8, factors=[v51, v52], preserve_unit_iters=True)
v55, v56 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[1, 1])
l57, l58 = sch.split(loop=l9, factors=[v55, v56], preserve_unit_iters=True)
v59, v60 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 1])
l61, l62 = sch.split(loop=l10, factors=[v59, v60], preserve_unit_iters=True)
sch.reorder(l15, l23, l31, l39, l47, l16, l24, l32, l40, l48, l53, l57, l61, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50)
b63, = sch.get_consumers(block=b0)
sch.reverse_compute_at(block=b63, loop=l47, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
sch.enter_postproc()
b65 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b65, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b65, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b65, ann_key="meta_schedule.unroll_explicit")
b66, b67 = sch.get_child_blocks(b65)
l68, l69, l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93 = sch.get_loops(block=b66)
l94 = sch.fuse(l68, l69, l70, l71, l72, preserve_unit_iters=True)
sch.parallel(loop=l94)
sch.annotate(block_or_loop=l94, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l94, ann_key="pragma_unroll_explicit", ann_val=1)
l95, l96, l97, l98, l99, l100 = sch.get_loops(block=b67)
l101 = sch.fuse(l100, preserve_unit_iters=True)
sch.vectorize(loop=l101)
b102 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l103, l104, l105, l106, l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124 = sch.get_loops(block=b102)
b125 = sch.decompose_reduction(block=b102, loop=l109)
2024-04-29 20:33:14 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #62: GFLOPs: 24.7700. Time: 4152.6418 us. Best GFLOPs: 280.8070
2024-04-29 20:33:14 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #63: GFLOPs: 22.9597. Time: 4480.0618 us. Best GFLOPs: 280.8070
2024-04-29 20:33:14 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #64: GFLOPs: 151.3043. Time: 679.8275 us. Best GFLOPs: 280.8070
2024-04-29 20:51:10 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 20:51:11 [INFO] [evolutionary_search.cc:715] Picked top 60 candidate(s) from database
2024-04-29 20:51:13 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4800b58)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x48148c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0xbdcc888)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x91ae188)]: 0 failure(s)
2024-04-29 20:51:13 [INFO] [evolutionary_search.cc:723] Sampled 452 candidate(s)
2024-04-29 20:51:19 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4800b58)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x48148c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0xbdcc888)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x91ae188)]: 0 failure(s)
2024-04-29 20:51:24 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4800b58)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x48148c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0xbdcc888)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x91ae188)]: 0 failure(s)
2024-04-29 20:51:29 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4800b58)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x48148c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0xbdcc888)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x91ae188)]: 0 failure(s)
2024-04-29 20:51:34 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4800b58)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x48148c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0xbdcc888)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x91ae188)]: 0 failure(s)
2024-04-29 20:51:37 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9878  0.9526  0.7683  0.7683  0.7657  0.7390  0.7090  0.7087  0.6794  0.6743  0.6664  0.6632  0.6632  0.6577  0.6538  0.6532
[17 : 32]:	0.6433  0.6377  0.6311  0.6256  0.6188  0.6081  0.6080  0.6075  0.6051  0.6027  0.6027  0.6018  0.6015  0.6013  0.6008  0.5991
[33 : 48]:	0.5991  0.5991  0.5991  0.5987  0.5984  0.5937  0.5931  0.5929  0.5922  0.5910  0.5900  0.5899  0.5893  0.5889  0.5842  0.5831
[49 : 64]:	0.5829  0.5769  0.5766  0.5761  0.5745  0.5733  0.5711  0.5706  0.5706  0.5702  0.5689  0.5680  0.5677  0.5659  0.5635  0.5635
2024-04-29 20:51:38 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 20:51:38 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 20:52:55 [INFO] [task_scheduler.cc:121] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #65: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(14), T.int64(14), T.int64(512)), "float32"), p1: T.Buffer((T.int64(4), T.int64(2), T.int64(1), T.int64(1), T.int64(512), T.int64(64)), "float32"), p2: T.Buffer((T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(64)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(4), T.int64(14), T.int64(14), T.int64(64)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(4), T.int64(14), T.int64(14), T.int64(64)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused in T.parallel(T.int64(1568), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for oc_block_1 in range(T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(16), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(4), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused % T.int64(196) // T.int64(49) + oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused // T.int64(784) * T.int64(7) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused % T.int64(49) // T.int64(7) + oh_2_init + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused % T.int64(7) * T.int64(2) + ow_2_init + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(64), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused % T.int64(784) // T.int64(196) * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(64), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(16), T.int64(16), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(4), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused % T.int64(196) // T.int64(49) + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused // T.int64(784) * T.int64(7) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused % T.int64(49) // T.int64(7) + oh_2 + oh_3)
                        v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused % T.int64(7) * T.int64(2) + ow_2 + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(64), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused % T.int64(784) // T.int64(196) * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(1024), ic_0 * T.int64(16) + ic_1)
                        v_kh = T.axis.reduce(T.int64(1), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(1), kw_0 + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], p0[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + p0[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
        for ax0_ax1_ax2_ax3_ax4_fused_0 in T.parallel(T.int64(784)):
            for ax0_ax1_ax2_ax3_ax4_fused_1 in T.vectorized(T.int64(64)):
                with T.block("T_relu"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) // T.int64(12544))
                    v_ax2 = T.axis.spatial(T.int64(14), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(12544) // T.int64(896))
                    v_ax3 = T.axis.spatial(T.int64(14), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(896) // T.int64(64))
                    v_ax4 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(64))
                    T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                    T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b1 = sch.get_block(name="T_add", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l3, l4, l5, l6, l7, l8, l9, l10 = sch.get_loops(block=b0)
v11, v12, v13, v14 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l15, l16, l17, l18 = sch.split(loop=l3, factors=[v11, v12, v13, v14], preserve_unit_iters=True)
v19, v20, v21, v22 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 4, 1, 1])
l23, l24, l25, l26 = sch.split(loop=l4, factors=[v19, v20, v21, v22], preserve_unit_iters=True)
v27, v28, v29, v30 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[2, 7, 1, 1])
l31, l32, l33, l34 = sch.split(loop=l5, factors=[v27, v28, v29, v30], preserve_unit_iters=True)
v35, v36, v37, v38 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 7, 2, 1])
l39, l40, l41, l42 = sch.split(loop=l6, factors=[v35, v36, v37, v38], preserve_unit_iters=True)
v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[4, 1, 16, 1])
l47, l48, l49, l50 = sch.split(loop=l7, factors=[v43, v44, v45, v46], preserve_unit_iters=True)
v51, v52 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[64, 16])
l53, l54 = sch.split(loop=l8, factors=[v51, v52], preserve_unit_iters=True)
v55, v56 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[1, 1])
l57, l58 = sch.split(loop=l9, factors=[v55, v56], preserve_unit_iters=True)
v59, v60 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 1])
l61, l62 = sch.split(loop=l10, factors=[v59, v60], preserve_unit_iters=True)
sch.reorder(l15, l23, l31, l39, l47, l16, l24, l32, l40, l48, l53, l57, l61, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.vectorize", ann_val=64)
v63 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v63)
sch.enter_postproc()
b64 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b64, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b64, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b64, ann_key="meta_schedule.unroll_explicit")
b65, b66 = sch.get_child_blocks(b64)
l67, l68, l69, l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92 = sch.get_loops(block=b65)
l93 = sch.fuse(l67, l68, l69, l70, l71, l72, l73, l74, l75, preserve_unit_iters=True)
sch.parallel(loop=l93)
sch.annotate(block_or_loop=l93, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l93, ann_key="pragma_unroll_explicit", ann_val=1)
l94, l95, l96, l97, l98 = sch.get_loops(block=b66)
l99 = sch.fuse(l94, l95, l96, l97, l98, preserve_unit_iters=True)
l100, l101 = sch.split(loop=l99, factors=[None, 64], preserve_unit_iters=True)
sch.parallel(loop=l100)
sch.vectorize(loop=l101)
b102 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l103, l104, l105, l106, l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117, l118, l119, l120 = sch.get_loops(block=b102)
b121 = sch.decompose_reduction(block=b102, loop=l105)
2024-04-29 20:52:55 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #66: GFLOPs: 260.0922. Time: 395.4782 us. Best GFLOPs: 280.8070
2024-04-29 20:52:55 [INFO] [task_scheduler.cc:121] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #67: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(14), T.int64(14), T.int64(512)), "float32"), p1: T.Buffer((T.int64(4), T.int64(2), T.int64(1), T.int64(1), T.int64(512), T.int64(64)), "float32"), p2: T.Buffer((T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(64)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(4), T.int64(14), T.int64(14), T.int64(64)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(4), T.int64(14), T.int64(14), T.int64(64)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused in T.parallel(T.int64(1568), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for oc_block_1 in range(T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(16), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(4), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused % T.int64(392) // T.int64(98) + oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused % T.int64(98) // T.int64(7) + oh_2_init + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused % T.int64(7) * T.int64(2) + ow_2_init + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(64), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused // T.int64(392) * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(64), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(16), T.int64(16), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(4), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused % T.int64(392) // T.int64(98) + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused % T.int64(98) // T.int64(7) + oh_2 + oh_3)
                        v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused % T.int64(7) * T.int64(2) + ow_2 + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(64), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused // T.int64(392) * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(1024), ic_0 * T.int64(16) + ic_1)
                        v_kh = T.axis.reduce(T.int64(1), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(1), kw_0 + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], p0[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + p0[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
        for ax0_ax1_ax2_ax3_ax4_fused_0 in T.parallel(T.int64(784)):
            for ax0_ax1_ax2_ax3_ax4_fused_1 in T.vectorized(T.int64(64)):
                with T.block("T_relu"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) // T.int64(12544))
                    v_ax2 = T.axis.spatial(T.int64(14), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(12544) // T.int64(896))
                    v_ax3 = T.axis.spatial(T.int64(14), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(896) // T.int64(64))
                    v_ax4 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(64))
                    T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                    T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b1 = sch.get_block(name="T_add", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l3, l4, l5, l6, l7, l8, l9, l10 = sch.get_loops(block=b0)
v11, v12, v13, v14 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l15, l16, l17, l18 = sch.split(loop=l3, factors=[v11, v12, v13, v14], preserve_unit_iters=True)
v19, v20, v21, v22 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 4, 1, 1])
l23, l24, l25, l26 = sch.split(loop=l4, factors=[v19, v20, v21, v22], preserve_unit_iters=True)
v27, v28, v29, v30 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 14, 1, 1])
l31, l32, l33, l34 = sch.split(loop=l5, factors=[v27, v28, v29, v30], preserve_unit_iters=True)
v35, v36, v37, v38 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 7, 2, 1])
l39, l40, l41, l42 = sch.split(loop=l6, factors=[v35, v36, v37, v38], preserve_unit_iters=True)
v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[4, 1, 16, 1])
l47, l48, l49, l50 = sch.split(loop=l7, factors=[v43, v44, v45, v46], preserve_unit_iters=True)
v51, v52 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[64, 16])
l53, l54 = sch.split(loop=l8, factors=[v51, v52], preserve_unit_iters=True)
v55, v56 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[1, 1])
l57, l58 = sch.split(loop=l9, factors=[v55, v56], preserve_unit_iters=True)
v59, v60 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 1])
l61, l62 = sch.split(loop=l10, factors=[v59, v60], preserve_unit_iters=True)
sch.reorder(l15, l23, l31, l39, l47, l16, l24, l32, l40, l48, l53, l57, l61, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.vectorize", ann_val=64)
v63 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v63)
sch.enter_postproc()
b64 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b64, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b64, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b64, ann_key="meta_schedule.unroll_explicit")
b65, b66 = sch.get_child_blocks(b64)
l67, l68, l69, l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92 = sch.get_loops(block=b65)
l93 = sch.fuse(l67, l68, l69, l70, l71, l72, l73, l74, l75, preserve_unit_iters=True)
sch.parallel(loop=l93)
sch.annotate(block_or_loop=l93, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l93, ann_key="pragma_unroll_explicit", ann_val=1)
l94, l95, l96, l97, l98 = sch.get_loops(block=b66)
l99 = sch.fuse(l94, l95, l96, l97, l98, preserve_unit_iters=True)
l100, l101 = sch.split(loop=l99, factors=[None, 64], preserve_unit_iters=True)
sch.parallel(loop=l100)
sch.vectorize(loop=l101)
b102 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l103, l104, l105, l106, l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117, l118, l119, l120 = sch.get_loops(block=b102)
b121 = sch.decompose_reduction(block=b102, loop=l105)
2024-04-29 20:52:55 [INFO] [task_scheduler.cc:121] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #68: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(14), T.int64(14), T.int64(512)), "float32"), p1: T.Buffer((T.int64(4), T.int64(2), T.int64(1), T.int64(1), T.int64(512), T.int64(64)), "float32"), p2: T.Buffer((T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(64)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(4), T.int64(14), T.int64(14), T.int64(64)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(4), T.int64(14), T.int64(14), T.int64(64)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused in T.parallel(T.int64(1568), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for oc_block_1 in range(T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(16), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(4), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused % T.int64(28) // T.int64(7) + oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused // T.int64(112) + oh_2_init + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused % T.int64(7) * T.int64(2) + ow_2_init + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(64), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused % T.int64(112) // T.int64(28) * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(64), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(16), T.int64(16), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(4), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused % T.int64(28) // T.int64(7) + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused // T.int64(112) + oh_2 + oh_3)
                        v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused % T.int64(7) * T.int64(2) + ow_2 + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(64), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused % T.int64(112) // T.int64(28) * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(1024), ic_0 * T.int64(16) + ic_1)
                        v_kh = T.axis.reduce(T.int64(1), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(1), kw_0 + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], p0[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + p0[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
        for ax0_ax1_ax2_ax3_ax4_fused_0 in T.parallel(T.int64(784)):
            for ax0_ax1_ax2_ax3_ax4_fused_1 in T.vectorized(T.int64(64)):
                with T.block("T_relu"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) // T.int64(12544))
                    v_ax2 = T.axis.spatial(T.int64(14), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(12544) // T.int64(896))
                    v_ax3 = T.axis.spatial(T.int64(14), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(896) // T.int64(64))
                    v_ax4 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(64))
                    T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                    T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b1 = sch.get_block(name="T_add", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l3, l4, l5, l6, l7, l8, l9, l10 = sch.get_loops(block=b0)
v11, v12, v13, v14 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l15, l16, l17, l18 = sch.split(loop=l3, factors=[v11, v12, v13, v14], preserve_unit_iters=True)
v19, v20, v21, v22 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 4, 1, 1])
l23, l24, l25, l26 = sch.split(loop=l4, factors=[v19, v20, v21, v22], preserve_unit_iters=True)
v27, v28, v29, v30 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[14, 1, 1, 1])
l31, l32, l33, l34 = sch.split(loop=l5, factors=[v27, v28, v29, v30], preserve_unit_iters=True)
v35, v36, v37, v38 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 7, 2, 1])
l39, l40, l41, l42 = sch.split(loop=l6, factors=[v35, v36, v37, v38], preserve_unit_iters=True)
v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[4, 1, 16, 1])
l47, l48, l49, l50 = sch.split(loop=l7, factors=[v43, v44, v45, v46], preserve_unit_iters=True)
v51, v52 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[64, 16])
l53, l54 = sch.split(loop=l8, factors=[v51, v52], preserve_unit_iters=True)
v55, v56 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[1, 1])
l57, l58 = sch.split(loop=l9, factors=[v55, v56], preserve_unit_iters=True)
v59, v60 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 1])
l61, l62 = sch.split(loop=l10, factors=[v59, v60], preserve_unit_iters=True)
sch.reorder(l15, l23, l31, l39, l47, l16, l24, l32, l40, l48, l53, l57, l61, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.vectorize", ann_val=64)
v63 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v63)
sch.enter_postproc()
b64 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b64, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b64, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b64, ann_key="meta_schedule.unroll_explicit")
b65, b66 = sch.get_child_blocks(b64)
l67, l68, l69, l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92 = sch.get_loops(block=b65)
l93 = sch.fuse(l67, l68, l69, l70, l71, l72, l73, l74, l75, preserve_unit_iters=True)
sch.parallel(loop=l93)
sch.annotate(block_or_loop=l93, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l93, ann_key="pragma_unroll_explicit", ann_val=1)
l94, l95, l96, l97, l98 = sch.get_loops(block=b66)
l99 = sch.fuse(l94, l95, l96, l97, l98, preserve_unit_iters=True)
l100, l101 = sch.split(loop=l99, factors=[None, 64], preserve_unit_iters=True)
sch.parallel(loop=l100)
sch.vectorize(loop=l101)
b102 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l103, l104, l105, l106, l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117, l118, l119, l120 = sch.get_loops(block=b102)
b121 = sch.decompose_reduction(block=b102, loop=l105)
2024-04-29 20:52:55 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #69: GFLOPs: 281.3197. Time: 365.6367 us. Best GFLOPs: 281.3197
2024-04-29 20:52:55 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #70: GFLOPs: 59.2944. Time: 1734.7459 us. Best GFLOPs: 281.3197
2024-04-29 20:52:55 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #71: GFLOPs: 193.7163. Time: 530.9868 us. Best GFLOPs: 281.3197
2024-04-29 20:52:55 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #72: GFLOPs: 336.7031. Time: 305.4940 us. Best GFLOPs: 336.7031
2024-04-29 20:52:55 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #73: GFLOPs: 31.7488. Time: 3239.8314 us. Best GFLOPs: 336.7031
2024-04-29 20:52:55 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #74: GFLOPs: 90.3468. Time: 1138.5105 us. Best GFLOPs: 336.7031
2024-04-29 20:52:55 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #75: GFLOPs: 476.0097. Time: 216.0897 us. Best GFLOPs: 476.0097
2024-04-29 20:52:55 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #76: GFLOPs: 228.5016. Time: 450.1536 us. Best GFLOPs: 476.0097
2024-04-29 20:52:55 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #77: GFLOPs: 486.1659. Time: 211.5755 us. Best GFLOPs: 486.1659
2024-04-29 20:52:55 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #78: GFLOPs: 175.1597. Time: 587.2401 us. Best GFLOPs: 486.1659
2024-04-29 20:52:55 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #79: GFLOPs: 300.4403. Time: 342.3668 us. Best GFLOPs: 486.1659
2024-04-29 20:52:55 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #80: GFLOPs: 475.9419. Time: 216.1205 us. Best GFLOPs: 486.1659
2024-04-29 20:52:55 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #81: GFLOPs: 114.4460. Time: 898.7715 us. Best GFLOPs: 486.1659
2024-04-29 20:52:55 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #82: GFLOPs: 142.6817. Time: 720.9110 us. Best GFLOPs: 486.1659
2024-04-29 20:52:55 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #83: GFLOPs: 122.3820. Time: 840.4895 us. Best GFLOPs: 486.1659
2024-04-29 20:52:55 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #84: GFLOPs: 145.2181. Time: 708.3192 us. Best GFLOPs: 486.1659
2024-04-29 20:52:55 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #85: GFLOPs: 185.0916. Time: 555.7291 us. Best GFLOPs: 486.1659
2024-04-29 20:52:55 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #86: GFLOPs: 186.4868. Time: 551.5715 us. Best GFLOPs: 486.1659
2024-04-29 20:52:55 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #87: GFLOPs: 95.7929. Time: 1073.7827 us. Best GFLOPs: 486.1659
2024-04-29 20:52:55 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #88: GFLOPs: 61.5547. Time: 1671.0477 us. Best GFLOPs: 486.1659
2024-04-29 20:52:55 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #89: GFLOPs: 98.3165. Time: 1046.2209 us. Best GFLOPs: 486.1659
2024-04-29 20:52:55 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #90: GFLOPs: 405.6831. Time: 253.5496 us. Best GFLOPs: 486.1659
2024-04-29 20:52:55 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #91: GFLOPs: 100.1318. Time: 1027.2539 us. Best GFLOPs: 486.1659
2024-04-29 20:52:55 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #92: GFLOPs: 152.9299. Time: 672.6009 us. Best GFLOPs: 486.1659
2024-04-29 20:52:55 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #93: GFLOPs: 134.6973. Time: 763.6443 us. Best GFLOPs: 486.1659
2024-04-29 20:52:55 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #94: GFLOPs: 133.5529. Time: 770.1880 us. Best GFLOPs: 486.1659
2024-04-29 20:52:55 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #95: GFLOPs: 167.3589. Time: 614.6120 us. Best GFLOPs: 486.1659
2024-04-29 20:52:55 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #96: GFLOPs: 186.6251. Time: 551.1628 us. Best GFLOPs: 486.1659
2024-04-29 20:52:55 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #97: GFLOPs: 160.5872. Time: 640.5294 us. Best GFLOPs: 486.1659
2024-04-29 20:52:55 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #98: GFLOPs: 162.7543. Time: 632.0006 us. Best GFLOPs: 486.1659
2024-04-29 20:52:55 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #99: GFLOPs: 166.7985. Time: 616.6772 us. Best GFLOPs: 486.1659
2024-04-29 20:52:55 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #100: GFLOPs: 184.2178. Time: 558.3651 us. Best GFLOPs: 486.1659
2024-04-29 20:52:55 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #101: GFLOPs: 247.5779. Time: 415.4684 us. Best GFLOPs: 486.1659
2024-04-29 20:52:55 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #102: GFLOPs: 200.0234. Time: 514.2438 us. Best GFLOPs: 486.1659
2024-04-29 20:52:55 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #103: GFLOPs: 106.9989. Time: 961.3259 us. Best GFLOPs: 486.1659
2024-04-29 20:52:55 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #104: GFLOPs: 154.9460. Time: 663.8492 us. Best GFLOPs: 486.1659
2024-04-29 20:52:55 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #105: GFLOPs: 178.6571. Time: 575.7443 us. Best GFLOPs: 486.1659
2024-04-29 20:52:55 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #106: GFLOPs: 132.3283. Time: 777.3153 us. Best GFLOPs: 486.1659
2024-04-29 20:52:55 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #107: GFLOPs: 132.0291. Time: 779.0765 us. Best GFLOPs: 486.1659
2024-04-29 20:52:55 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #108: GFLOPs: 205.3842. Time: 500.8213 us. Best GFLOPs: 486.1659
2024-04-29 20:52:55 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #109: GFLOPs: 90.0185. Time: 1142.6625 us. Best GFLOPs: 486.1659
2024-04-29 20:52:55 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #110: GFLOPs: 119.4983. Time: 860.7722 us. Best GFLOPs: 486.1659
2024-04-29 20:52:55 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #111: GFLOPs: 90.0146. Time: 1142.7124 us. Best GFLOPs: 486.1659
2024-04-29 20:52:55 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #112: GFLOPs: 223.0842. Time: 461.0851 us. Best GFLOPs: 486.1659
2024-04-29 20:52:55 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #113: GFLOPs: 203.7186. Time: 504.9160 us. Best GFLOPs: 486.1659
2024-04-29 20:52:55 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #114: GFLOPs: 241.2661. Time: 426.3375 us. Best GFLOPs: 486.1659
2024-04-29 20:52:55 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #115: GFLOPs: 78.9019. Time: 1303.6542 us. Best GFLOPs: 486.1659
2024-04-29 20:52:55 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #116: GFLOPs: 155.8087. Time: 660.1735 us. Best GFLOPs: 486.1659
2024-04-29 20:52:55 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #117: GFLOPs: 181.8045. Time: 565.7770 us. Best GFLOPs: 486.1659
2024-04-29 20:52:55 [INFO] [task_scheduler.cc:121] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #118: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(14), T.int64(14), T.int64(512)), "float32"), p1: T.Buffer((T.int64(4), T.int64(2), T.int64(1), T.int64(1), T.int64(512), T.int64(64)), "float32"), p2: T.Buffer((T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(64)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(4), T.int64(14), T.int64(14), T.int64(64)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(4), T.int64(14), T.int64(14), T.int64(64)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused in T.parallel(T.int64(196), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(2), T.int64(2), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                for oc_block_3_fused_init in T.vectorized(T.int64(32)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(4), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused // T.int64(98) * T.int64(2) + oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(98) // T.int64(14) * T.int64(2) + oh_2_init + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(14) // T.int64(2) * T.int64(2) + ow_2_init + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(64), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(2) * T.int64(32) + oc_block_2_init * T.int64(32) + oc_block_3_fused_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
            for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(16), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(2), T.int64(2), T.int64(1), T.int64(64), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                for oc_block_3_fused in T.vectorized(T.int64(32)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(4), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused // T.int64(98) * T.int64(2) + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(98) // T.int64(14) * T.int64(2) + oh_2 + oh_3)
                        v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(14) // T.int64(2) * T.int64(2) + ow_2 + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(64), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(2) * T.int64(32) + oc_block_2 * T.int64(32) + oc_block_3_fused)
                        v_ic = T.axis.reduce(T.int64(1024), ic_0 * T.int64(64) + ic_1)
                        v_kh = T.axis.reduce(T.int64(1), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(1), kw_0 + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], p0[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + p0[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
        for ax0_ax1_ax2_ax3_ax4_fused_0 in T.parallel(T.int64(784)):
            for ax0_ax1_ax2_ax3_ax4_fused_1 in T.vectorized(T.int64(64)):
                with T.block("T_relu"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) // T.int64(12544))
                    v_ax2 = T.axis.spatial(T.int64(14), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(12544) // T.int64(896))
                    v_ax3 = T.axis.spatial(T.int64(14), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(896) // T.int64(64))
                    v_ax4 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(64))
                    T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                    T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b1 = sch.get_block(name="T_add", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l3, l4, l5, l6, l7, l8, l9, l10 = sch.get_loops(block=b0)
v11, v12, v13, v14 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l15, l16, l17, l18 = sch.split(loop=l3, factors=[v11, v12, v13, v14], preserve_unit_iters=True)
v19, v20, v21, v22 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[2, 1, 2, 1])
l23, l24, l25, l26 = sch.split(loop=l4, factors=[v19, v20, v21, v22], preserve_unit_iters=True)
v27, v28, v29, v30 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 7, 2, 1])
l31, l32, l33, l34 = sch.split(loop=l5, factors=[v27, v28, v29, v30], preserve_unit_iters=True)
v35, v36, v37, v38 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 7, 2, 1])
l39, l40, l41, l42 = sch.split(loop=l6, factors=[v35, v36, v37, v38], preserve_unit_iters=True)
v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 2, 1, 32])
l47, l48, l49, l50 = sch.split(loop=l7, factors=[v43, v44, v45, v46], preserve_unit_iters=True)
v51, v52 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[16, 64])
l53, l54 = sch.split(loop=l8, factors=[v51, v52], preserve_unit_iters=True)
v55, v56 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[1, 1])
l57, l58 = sch.split(loop=l9, factors=[v55, v56], preserve_unit_iters=True)
v59, v60 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 1])
l61, l62 = sch.split(loop=l10, factors=[v59, v60], preserve_unit_iters=True)
sch.reorder(l15, l23, l31, l39, l47, l16, l24, l32, l40, l48, l53, l57, l61, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.vectorize", ann_val=64)
v63 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v63)
sch.enter_postproc()
b64 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b64, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b64, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b64, ann_key="meta_schedule.unroll_explicit")
b65, b66 = sch.get_child_blocks(b64)
l67, l68, l69, l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92 = sch.get_loops(block=b65)
l93 = sch.fuse(l67, l68, l69, l70, l71, l72, l73, l74, l75, l76, preserve_unit_iters=True)
sch.parallel(loop=l93)
l94 = sch.fuse(l92, preserve_unit_iters=True)
sch.vectorize(loop=l94)
sch.annotate(block_or_loop=l93, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l93, ann_key="pragma_unroll_explicit", ann_val=1)
l95, l96, l97, l98, l99 = sch.get_loops(block=b66)
l100 = sch.fuse(l95, l96, l97, l98, l99, preserve_unit_iters=True)
l101, l102 = sch.split(loop=l100, factors=[None, 64], preserve_unit_iters=True)
sch.parallel(loop=l101)
sch.vectorize(loop=l102)
b103 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l104, l105, l106, l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117, l118, l119, l120 = sch.get_loops(block=b103)
b121 = sch.decompose_reduction(block=b103, loop=l105)
2024-04-29 20:52:55 [INFO] [task_scheduler.cc:121] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #119: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(14), T.int64(14), T.int64(512)), "float32"), p1: T.Buffer((T.int64(4), T.int64(2), T.int64(1), T.int64(1), T.int64(512), T.int64(64)), "float32"), p2: T.Buffer((T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(64)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(4), T.int64(14), T.int64(14), T.int64(64)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(4), T.int64(14), T.int64(14), T.int64(64)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused in T.parallel(T.int64(14), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(2)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(2), T.int64(16), T.int64(1), T.int64(2), T.int64(1), T.int64(7), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(4), oc_chunk_1 * T.int64(4) + oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused // T.int64(2) * T.int64(2) + oh_1 + oh_2_init + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(14), ow_1 * T.int64(14) + ow_2_init * T.int64(7) + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(64), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused % T.int64(2) * T.int64(32) + oc_block_1 * T.int64(16) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(1024), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(2), T.int64(16), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(7), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(4), oc_chunk_1 * T.int64(4) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused // T.int64(2) * T.int64(2) + oh_1 + oh_2 + oh_3)
                        v_ow = T.axis.spatial(T.int64(14), ow_1 * T.int64(14) + ow_2 * T.int64(7) + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(64), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused % T.int64(2) * T.int64(32) + oc_block_1 * T.int64(16) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(1024), ic_0 + ic_1)
                        v_kh = T.axis.reduce(T.int64(1), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(1), kw_0 + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], p0[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + p0[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(4), T.int64(2), T.int64(14)):
                for ax4_fused in T.vectorized(T.int64(32)):
                    with T.block("T_relu"):
                        v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                        v_ax2 = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused // T.int64(2) * T.int64(2) + ax2)
                        v_ax3 = T.axis.spatial(T.int64(14), ax3)
                        v_ax4 = T.axis.spatial(T.int64(64), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused % T.int64(2) * T.int64(32) + ax4_fused)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b1 = sch.get_block(name="T_add", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l3, l4, l5, l6, l7, l8, l9, l10 = sch.get_loops(block=b0)
v11, v12, v13, v14 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l15, l16, l17, l18 = sch.split(loop=l3, factors=[v11, v12, v13, v14], preserve_unit_iters=True)
v19, v20, v21, v22 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 2, 2])
l23, l24, l25, l26 = sch.split(loop=l4, factors=[v19, v20, v21, v22], preserve_unit_iters=True)
v27, v28, v29, v30 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[7, 2, 1, 1])
l31, l32, l33, l34 = sch.split(loop=l5, factors=[v27, v28, v29, v30], preserve_unit_iters=True)
v35, v36, v37, v38 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 2, 7])
l39, l40, l41, l42 = sch.split(loop=l6, factors=[v35, v36, v37, v38], preserve_unit_iters=True)
v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[2, 2, 16, 1])
l47, l48, l49, l50 = sch.split(loop=l7, factors=[v43, v44, v45, v46], preserve_unit_iters=True)
v51, v52 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[1024, 1])
l53, l54 = sch.split(loop=l8, factors=[v51, v52], preserve_unit_iters=True)
v55, v56 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[1, 1])
l57, l58 = sch.split(loop=l9, factors=[v55, v56], preserve_unit_iters=True)
v59, v60 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 1])
l61, l62 = sch.split(loop=l10, factors=[v59, v60], preserve_unit_iters=True)
sch.reorder(l15, l23, l31, l39, l47, l16, l24, l32, l40, l48, l53, l57, l61, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50)
b63, = sch.get_consumers(block=b0)
sch.reverse_compute_at(block=b63, loop=l47, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
sch.enter_postproc()
b65 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b65, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b65, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b65, ann_key="meta_schedule.unroll_explicit")
b66, b67 = sch.get_child_blocks(b65)
l68, l69, l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93 = sch.get_loops(block=b66)
l94 = sch.fuse(l68, l69, l70, l71, l72, preserve_unit_iters=True)
sch.parallel(loop=l94)
sch.annotate(block_or_loop=l94, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l94, ann_key="pragma_unroll_explicit", ann_val=1)
l95, l96, l97, l98, l99, l100 = sch.get_loops(block=b67)
l101 = sch.fuse(l100, preserve_unit_iters=True)
sch.vectorize(loop=l101)
b102 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l103, l104, l105, l106, l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124 = sch.get_loops(block=b102)
b125 = sch.decompose_reduction(block=b102, loop=l109)
2024-04-29 20:52:55 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #120: GFLOPs: 30.3850. Time: 3385.2541 us. Best GFLOPs: 486.1659
2024-04-29 20:52:55 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #121: GFLOPs: 78.1334. Time: 1316.4759 us. Best GFLOPs: 486.1659
2024-04-29 20:52:55 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #122: GFLOPs: 5.1838. Time: 19842.7170 us. Best GFLOPs: 486.1659
2024-04-29 20:52:55 [INFO] [task_scheduler.cc:121] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #123: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(14), T.int64(14), T.int64(512)), "float32"), p1: T.Buffer((T.int64(4), T.int64(2), T.int64(1), T.int64(1), T.int64(512), T.int64(64)), "float32"), p2: T.Buffer((T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(64)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(4), T.int64(14), T.int64(14), T.int64(64)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(4), T.int64(14), T.int64(14), T.int64(64)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused in T.parallel(T.int64(224), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(7), T.int64(2), T.int64(16), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                with T.block("conv2d_NCHWc_init"):
                    v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                    v_oc_chunk = T.axis.spatial(T.int64(4), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(28) // T.int64(7) + oc_chunk_2_init + oc_chunk_3_init)
                    v_oh = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused // T.int64(112) * T.int64(7) + oh_2_init + oh_3_init)
                    v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(7) * T.int64(2) + ow_2_init + ow_3_init)
                    v_oc_block = T.axis.spatial(T.int64(64), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(112) // T.int64(28) * T.int64(16) + oc_block_2_init + oc_block_3_init)
                    T.reads()
                    T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                    T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                    conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
            for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(64), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(2), T.int64(16), T.int64(16), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                with T.block("conv2d_NCHWc_update"):
                    v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                    v_oc_chunk = T.axis.spatial(T.int64(4), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(28) // T.int64(7) + oc_chunk_2 + oc_chunk_3)
                    v_oh = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused // T.int64(112) * T.int64(7) + oh_2 + oh_3)
                    v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(7) * T.int64(2) + ow_2 + ow_3)
                    v_oc_block = T.axis.spatial(T.int64(64), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(112) // T.int64(28) * T.int64(16) + oc_block_2 + oc_block_3)
                    v_ic = T.axis.reduce(T.int64(1024), ic_0 * T.int64(16) + ic_1)
                    v_kh = T.axis.reduce(T.int64(1), kh_0 + kh_1)
                    v_kw = T.axis.reduce(T.int64(1), kw_0 + kw_1)
                    T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], p0[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                    T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                    T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                    conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + p0[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
        for ax0_ax1_ax2_ax3_ax4_fused_0 in T.parallel(T.int64(784)):
            for ax0_ax1_ax2_ax3_ax4_fused_1 in T.vectorized(T.int64(64)):
                with T.block("T_relu"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) // T.int64(12544))
                    v_ax2 = T.axis.spatial(T.int64(14), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(12544) // T.int64(896))
                    v_ax3 = T.axis.spatial(T.int64(14), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(896) // T.int64(64))
                    v_ax4 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(64))
                    T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                    T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b1 = sch.get_block(name="T_add", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l3, l4, l5, l6, l7, l8, l9, l10 = sch.get_loops(block=b0)
v11, v12, v13, v14 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l15, l16, l17, l18 = sch.split(loop=l3, factors=[v11, v12, v13, v14], preserve_unit_iters=True)
v19, v20, v21, v22 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 4, 1, 1])
l23, l24, l25, l26 = sch.split(loop=l4, factors=[v19, v20, v21, v22], preserve_unit_iters=True)
v27, v28, v29, v30 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[2, 1, 7, 1])
l31, l32, l33, l34 = sch.split(loop=l5, factors=[v27, v28, v29, v30], preserve_unit_iters=True)
v35, v36, v37, v38 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 7, 2, 1])
l39, l40, l41, l42 = sch.split(loop=l6, factors=[v35, v36, v37, v38], preserve_unit_iters=True)
v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[4, 1, 16, 1])
l47, l48, l49, l50 = sch.split(loop=l7, factors=[v43, v44, v45, v46], preserve_unit_iters=True)
v51, v52 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[64, 16])
l53, l54 = sch.split(loop=l8, factors=[v51, v52], preserve_unit_iters=True)
v55, v56 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[1, 1])
l57, l58 = sch.split(loop=l9, factors=[v55, v56], preserve_unit_iters=True)
v59, v60 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 1])
l61, l62 = sch.split(loop=l10, factors=[v59, v60], preserve_unit_iters=True)
sch.reorder(l15, l23, l31, l39, l47, l16, l24, l32, l40, l48, l53, l57, l61, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.vectorize", ann_val=64)
v63 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v63)
sch.enter_postproc()
b64 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b64, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b64, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b64, ann_key="meta_schedule.unroll_explicit")
b65, b66 = sch.get_child_blocks(b64)
l67, l68, l69, l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92 = sch.get_loops(block=b65)
l93 = sch.fuse(l67, l68, l69, l70, l71, l72, l73, l74, l75, l76, preserve_unit_iters=True)
sch.parallel(loop=l93)
sch.annotate(block_or_loop=l93, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l93, ann_key="pragma_unroll_explicit", ann_val=1)
l94, l95, l96, l97, l98 = sch.get_loops(block=b66)
l99 = sch.fuse(l94, l95, l96, l97, l98, preserve_unit_iters=True)
l100, l101 = sch.split(loop=l99, factors=[None, 64], preserve_unit_iters=True)
sch.parallel(loop=l100)
sch.vectorize(loop=l101)
b102 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l103, l104, l105, l106, l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117, l118, l119 = sch.get_loops(block=b102)
b120 = sch.decompose_reduction(block=b102, loop=l104)
2024-04-29 20:52:55 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #124: GFLOPs: 101.5010. Time: 1013.3966 us. Best GFLOPs: 486.1659
2024-04-29 20:52:55 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #125: GFLOPs: 379.1419. Time: 271.2990 us. Best GFLOPs: 486.1659
2024-04-29 20:52:55 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #126: GFLOPs: 111.0295. Time: 926.4279 us. Best GFLOPs: 486.1659
2024-04-29 20:52:55 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #127: GFLOPs: 93.6409. Time: 1098.4606 us. Best GFLOPs: 486.1659
2024-04-29 20:52:55 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #128: GFLOPs: 58.2510. Time: 1765.8195 us. Best GFLOPs: 486.1659
2024-04-29 21:59:49 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 21:59:50 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-29 21:59:52 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4800b58)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x48148c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0xbdcc888)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x91ae188)]: 0 failure(s)
2024-04-29 21:59:52 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-29 21:59:57 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4800b58)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x48148c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0xbdcc888)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x91ae188)]: 0 failure(s)
2024-04-29 22:00:03 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4800b58)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x48148c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0xbdcc888)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x91ae188)]: 0 failure(s)
2024-04-29 22:00:08 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4800b58)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x48148c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0xbdcc888)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x91ae188)]: 0 failure(s)
2024-04-29 22:00:13 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4800b58)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x48148c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0xbdcc888)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x91ae188)]: 0 failure(s)
2024-04-29 22:00:16 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	1.0170  0.9688  0.9650  0.9650  0.9540  0.9443  0.9323  0.9065  0.8993  0.8951  0.8886  0.8868  0.8847  0.8775  0.8775  0.8550
[17 : 32]:	0.8217  0.8075  0.7909  0.7778  0.7714  0.7590  0.7554  0.7466  0.7318  0.7245  0.7224  0.7170  0.7095  0.7095  0.7082  0.7074
[33 : 48]:	0.7038  0.7032  0.6928  0.6912  0.6906  0.6859  0.6798  0.6798  0.6720  0.6695  0.6663  0.6654  0.6642  0.6640  0.6632  0.6628
[49 : 64]:	0.6628  0.6602  0.6569  0.6562  0.6536  0.6535  0.6526  0.6499  0.6462  0.6457  0.6454  0.6454  0.6427  0.6411  0.6406  0.6397
2024-04-29 22:00:17 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 22:00:17 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 22:01:47 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #129: GFLOPs: 470.4071. Time: 218.6634 us. Best GFLOPs: 486.1659
2024-04-29 22:01:47 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #130: GFLOPs: 501.9017. Time: 204.9421 us. Best GFLOPs: 501.9017
2024-04-29 22:01:47 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #131: GFLOPs: 445.8553. Time: 230.7045 us. Best GFLOPs: 501.9017
2024-04-29 22:01:47 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #132: GFLOPs: 451.0069. Time: 228.0693 us. Best GFLOPs: 501.9017
2024-04-29 22:01:47 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #133: GFLOPs: 231.9232. Time: 443.5123 us. Best GFLOPs: 501.9017
2024-04-29 22:01:47 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #134: GFLOPs: 310.6230. Time: 331.1436 us. Best GFLOPs: 501.9017
2024-04-29 22:01:47 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #135: GFLOPs: 356.3597. Time: 288.6432 us. Best GFLOPs: 501.9017
2024-04-29 22:01:47 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #136: GFLOPs: 472.7889. Time: 217.5618 us. Best GFLOPs: 501.9017
2024-04-29 22:01:47 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #137: GFLOPs: 337.2056. Time: 305.0388 us. Best GFLOPs: 501.9017
2024-04-29 22:01:47 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #138: GFLOPs: 860.7183. Time: 119.5058 us. Best GFLOPs: 860.7183
2024-04-29 22:01:47 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #139: GFLOPs: 485.2092. Time: 211.9927 us. Best GFLOPs: 860.7183
2024-04-29 22:01:47 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #140: GFLOPs: 402.7052. Time: 255.4246 us. Best GFLOPs: 860.7183
2024-04-29 22:01:47 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #141: GFLOPs: 402.5817. Time: 255.5029 us. Best GFLOPs: 860.7183
2024-04-29 22:01:47 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #142: GFLOPs: 307.1823. Time: 334.8526 us. Best GFLOPs: 860.7183
2024-04-29 22:01:47 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #143: GFLOPs: 246.8671. Time: 416.6646 us. Best GFLOPs: 860.7183
2024-04-29 22:01:47 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #144: GFLOPs: 374.7412. Time: 274.4849 us. Best GFLOPs: 860.7183
2024-04-29 22:01:47 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #145: GFLOPs: 484.8253. Time: 212.1606 us. Best GFLOPs: 860.7183
2024-04-29 22:01:47 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #146: GFLOPs: 399.2408. Time: 257.6410 us. Best GFLOPs: 860.7183
2024-04-29 22:01:47 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #147: GFLOPs: 406.1212. Time: 253.2761 us. Best GFLOPs: 860.7183
2024-04-29 22:01:47 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #148: GFLOPs: 402.4143. Time: 255.6092 us. Best GFLOPs: 860.7183
2024-04-29 22:01:47 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #149: GFLOPs: 683.1175. Time: 150.5756 us. Best GFLOPs: 860.7183
2024-04-29 22:01:47 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #150: GFLOPs: 185.2207. Time: 555.3420 us. Best GFLOPs: 860.7183
2024-04-29 22:01:47 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #151: GFLOPs: 500.0052. Time: 205.7195 us. Best GFLOPs: 860.7183
2024-04-29 22:01:47 [INFO] [task_scheduler.cc:121] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #152: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(14), T.int64(14), T.int64(512)), "float32"), p1: T.Buffer((T.int64(4), T.int64(2), T.int64(1), T.int64(1), T.int64(512), T.int64(64)), "float32"), p2: T.Buffer((T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(64)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(4), T.int64(14), T.int64(14), T.int64(64)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(4), T.int64(14), T.int64(14), T.int64(64)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused in T.parallel(T.int64(112), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(1)):
                with T.block("conv2d_NCHWc_init"):
                    v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                    v_oc_chunk = T.axis.spatial(T.int64(4), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused // T.int64(56) * T.int64(2) + oc_chunk_2_init + oc_chunk_3_init)
                    v_oh = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(14) // T.int64(7) * T.int64(7) + oh_2_init * T.int64(7) + oh_3_init)
                    v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(56) // T.int64(28) * T.int64(7) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(7) + ow_2_init + ow_3_init)
                    v_oc_block = T.axis.spatial(T.int64(64), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(28) // T.int64(14) * T.int64(32) + oc_block_2_init + oc_block_3_init)
                    T.reads()
                    T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                    T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                    conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
            for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(512), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(32), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(1)):
                with T.block("conv2d_NCHWc_update"):
                    v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                    v_oc_chunk = T.axis.spatial(T.int64(4), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused // T.int64(56) * T.int64(2) + oc_chunk_2 + oc_chunk_3)
                    v_oh = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(14) // T.int64(7) * T.int64(7) + oh_2 * T.int64(7) + oh_3)
                    v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(56) // T.int64(28) * T.int64(7) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(7) + ow_2 + ow_3)
                    v_oc_block = T.axis.spatial(T.int64(64), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(28) // T.int64(14) * T.int64(32) + oc_block_2 + oc_block_3)
                    v_ic = T.axis.reduce(T.int64(1024), ic_0 * T.int64(2) + ic_1)
                    v_kh = T.axis.reduce(T.int64(1), kh_0 + kh_1)
                    v_kw = T.axis.reduce(T.int64(1), kw_0 + kw_1)
                    T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], p0[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                    T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                    T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                    conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + p0[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(2), T.int64(7), T.int64(1)):
                for ax4_fused in T.vectorized(T.int64(32)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(4), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused // T.int64(56) * T.int64(2) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(14) // T.int64(7) * T.int64(7) + ax2)
                        v_ax3 = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(56) // T.int64(28) * T.int64(7) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(7) + ax3)
                        v_ax4 = T.axis.spatial(T.int64(64), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(28) // T.int64(14) * T.int64(32) + ax4_fused)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b1 = sch.get_block(name="T_add", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l3, l4, l5, l6, l7, l8, l9, l10 = sch.get_loops(block=b0)
v11, v12, v13, v14 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l15, l16, l17, l18 = sch.split(loop=l3, factors=[v11, v12, v13, v14], preserve_unit_iters=True)
v19, v20, v21, v22 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[2, 1, 2, 1])
l23, l24, l25, l26 = sch.split(loop=l4, factors=[v19, v20, v21, v22], preserve_unit_iters=True)
v27, v28, v29, v30 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 2, 1, 7])
l31, l32, l33, l34 = sch.split(loop=l5, factors=[v27, v28, v29, v30], preserve_unit_iters=True)
v35, v36, v37, v38 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 7, 1, 1])
l39, l40, l41, l42 = sch.split(loop=l6, factors=[v35, v36, v37, v38], preserve_unit_iters=True)
v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[2, 1, 32, 1])
l47, l48, l49, l50 = sch.split(loop=l7, factors=[v43, v44, v45, v46], preserve_unit_iters=True)
v51, v52 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[512, 2])
l53, l54 = sch.split(loop=l8, factors=[v51, v52], preserve_unit_iters=True)
v55, v56 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[1, 1])
l57, l58 = sch.split(loop=l9, factors=[v55, v56], preserve_unit_iters=True)
v59, v60 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 1])
l61, l62 = sch.split(loop=l10, factors=[v59, v60], preserve_unit_iters=True)
sch.reorder(l15, l23, l31, l39, l47, l16, l24, l32, l40, l48, l53, l57, l61, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50)
b63, = sch.get_consumers(block=b0)
sch.reverse_compute_at(block=b63, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
sch.enter_postproc()
b65 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b65, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b65, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b65, ann_key="meta_schedule.unroll_explicit")
b66, b67 = sch.get_child_blocks(b65)
l68, l69, l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93 = sch.get_loops(block=b66)
l94 = sch.fuse(l68, l69, l70, l71, l72, l73, l74, l75, l76, l77, preserve_unit_iters=True)
sch.parallel(loop=l94)
sch.annotate(block_or_loop=l94, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l94, ann_key="pragma_unroll_explicit", ann_val=1)
l95, l96, l97, l98, l99, l100 = sch.get_loops(block=b67)
l101 = sch.fuse(l100, preserve_unit_iters=True)
sch.vectorize(loop=l101)
b102 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l103, l104, l105, l106, l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117, l118, l119 = sch.get_loops(block=b102)
b120 = sch.decompose_reduction(block=b102, loop=l104)
2024-04-29 22:01:47 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #153: GFLOPs: 289.4939. Time: 355.3125 us. Best GFLOPs: 860.7183
2024-04-29 22:01:47 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #154: GFLOPs: 260.6674. Time: 394.6055 us. Best GFLOPs: 860.7183
2024-04-29 22:01:47 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #155: GFLOPs: 258.7191. Time: 397.5771 us. Best GFLOPs: 860.7183
2024-04-29 22:01:47 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #156: GFLOPs: 629.6369. Time: 163.3653 us. Best GFLOPs: 860.7183
2024-04-29 22:01:47 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #157: GFLOPs: 260.1544. Time: 395.3836 us. Best GFLOPs: 860.7183
2024-04-29 22:01:47 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #158: GFLOPs: 259.1098. Time: 396.9777 us. Best GFLOPs: 860.7183
2024-04-29 22:01:47 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #159: GFLOPs: 92.6861. Time: 1109.7762 us. Best GFLOPs: 860.7183
2024-04-29 22:01:47 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #160: GFLOPs: 190.0175. Time: 541.3229 us. Best GFLOPs: 860.7183
2024-04-29 22:01:47 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #161: GFLOPs: 197.6712. Time: 520.3630 us. Best GFLOPs: 860.7183
2024-04-29 22:01:47 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #162: GFLOPs: 541.9534. Time: 189.7964 us. Best GFLOPs: 860.7183
2024-04-29 22:01:47 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #163: GFLOPs: 471.2416. Time: 218.2761 us. Best GFLOPs: 860.7183
2024-04-29 22:01:47 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #164: GFLOPs: 272.3605. Time: 377.6642 us. Best GFLOPs: 860.7183
2024-04-29 22:01:47 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #165: GFLOPs: 479.4041. Time: 214.5597 us. Best GFLOPs: 860.7183
2024-04-29 22:01:47 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #166: GFLOPs: 181.1751. Time: 567.7424 us. Best GFLOPs: 860.7183
2024-04-29 22:01:47 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #167: GFLOPs: 307.2787. Time: 334.7476 us. Best GFLOPs: 860.7183
2024-04-29 22:01:47 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #168: GFLOPs: 310.2099. Time: 331.5845 us. Best GFLOPs: 860.7183
2024-04-29 22:01:47 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #169: GFLOPs: 189.6118. Time: 542.4810 us. Best GFLOPs: 860.7183
2024-04-29 22:01:47 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #170: GFLOPs: 236.2570. Time: 435.3768 us. Best GFLOPs: 860.7183
2024-04-29 22:01:47 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #171: GFLOPs: 177.9679. Time: 577.9739 us. Best GFLOPs: 860.7183
2024-04-29 22:01:47 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #172: GFLOPs: 168.8377. Time: 609.2287 us. Best GFLOPs: 860.7183
2024-04-29 22:01:47 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #173: GFLOPs: 265.5261. Time: 387.3849 us. Best GFLOPs: 860.7183
2024-04-29 22:01:47 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #174: GFLOPs: 200.4894. Time: 513.0487 us. Best GFLOPs: 860.7183
2024-04-29 22:01:47 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #175: GFLOPs: 370.2861. Time: 277.7874 us. Best GFLOPs: 860.7183
2024-04-29 22:01:47 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #176: GFLOPs: 232.4636. Time: 442.4813 us. Best GFLOPs: 860.7183
2024-04-29 22:01:47 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #177: GFLOPs: 183.6451. Time: 560.1065 us. Best GFLOPs: 860.7183
2024-04-29 22:01:47 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #178: GFLOPs: 174.5288. Time: 589.3629 us. Best GFLOPs: 860.7183
2024-04-29 22:01:47 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #179: GFLOPs: 536.2629. Time: 191.8104 us. Best GFLOPs: 860.7183
2024-04-29 22:01:47 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #180: GFLOPs: 182.4433. Time: 563.7961 us. Best GFLOPs: 860.7183
2024-04-29 22:01:47 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #181: GFLOPs: 245.0160. Time: 419.8126 us. Best GFLOPs: 860.7183
2024-04-29 22:01:47 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #182: GFLOPs: 168.4331. Time: 610.6923 us. Best GFLOPs: 860.7183
2024-04-29 22:01:47 [INFO] [task_scheduler.cc:121] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #183: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(14), T.int64(14), T.int64(512)), "float32"), p1: T.Buffer((T.int64(4), T.int64(2), T.int64(1), T.int64(1), T.int64(512), T.int64(64)), "float32"), p2: T.Buffer((T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(64)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(4), T.int64(14), T.int64(14), T.int64(64)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(4), T.int64(14), T.int64(14), T.int64(64)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused in T.parallel(T.int64(112), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(1)):
                with T.block("conv2d_NCHWc_init"):
                    v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                    v_oc_chunk = T.axis.spatial(T.int64(4), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(16) // T.int64(4) + oc_chunk_2_init + oc_chunk_3_init)
                    v_oh = T.axis.spatial(T.int64(14), oh_2_init * T.int64(7) + oh_3_init)
                    v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused // T.int64(16) * T.int64(2) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(4) // T.int64(2) + ow_2_init + ow_3_init)
                    v_oc_block = T.axis.spatial(T.int64(64), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(2) * T.int64(32) + oc_block_2_init + oc_block_3_init)
                    T.reads()
                    T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                    T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                    conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
            for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(512), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(32), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(1)):
                with T.block("conv2d_NCHWc_update"):
                    v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                    v_oc_chunk = T.axis.spatial(T.int64(4), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(16) // T.int64(4) + oc_chunk_2 + oc_chunk_3)
                    v_oh = T.axis.spatial(T.int64(14), oh_2 * T.int64(7) + oh_3)
                    v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused // T.int64(16) * T.int64(2) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(4) // T.int64(2) + ow_2 + ow_3)
                    v_oc_block = T.axis.spatial(T.int64(64), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(2) * T.int64(32) + oc_block_2 + oc_block_3)
                    v_ic = T.axis.reduce(T.int64(1024), ic_0 * T.int64(2) + ic_1)
                    v_kh = T.axis.reduce(T.int64(1), kh_0 + kh_1)
                    v_kw = T.axis.reduce(T.int64(1), kw_0 + kw_1)
                    T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], p0[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                    T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                    T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                    conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + p0[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(14), T.int64(1)):
                for ax4_fused in T.vectorized(T.int64(32)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(4), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(16) // T.int64(4) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(14), ax2)
                        v_ax3 = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused // T.int64(16) * T.int64(2) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(4) // T.int64(2) + ax3)
                        v_ax4 = T.axis.spatial(T.int64(64), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(2) * T.int64(32) + ax4_fused)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b1 = sch.get_block(name="T_add", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l3, l4, l5, l6, l7, l8, l9, l10 = sch.get_loops(block=b0)
v11, v12, v13, v14 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l15, l16, l17, l18 = sch.split(loop=l3, factors=[v11, v12, v13, v14], preserve_unit_iters=True)
v19, v20, v21, v22 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 4, 1, 1])
l23, l24, l25, l26 = sch.split(loop=l4, factors=[v19, v20, v21, v22], preserve_unit_iters=True)
v27, v28, v29, v30 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 2, 7])
l31, l32, l33, l34 = sch.split(loop=l5, factors=[v27, v28, v29, v30], preserve_unit_iters=True)
v35, v36, v37, v38 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[7, 2, 1, 1])
l39, l40, l41, l42 = sch.split(loop=l6, factors=[v35, v36, v37, v38], preserve_unit_iters=True)
v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 2, 32, 1])
l47, l48, l49, l50 = sch.split(loop=l7, factors=[v43, v44, v45, v46], preserve_unit_iters=True)
v51, v52 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[512, 2])
l53, l54 = sch.split(loop=l8, factors=[v51, v52], preserve_unit_iters=True)
v55, v56 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[1, 1])
l57, l58 = sch.split(loop=l9, factors=[v55, v56], preserve_unit_iters=True)
v59, v60 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 1])
l61, l62 = sch.split(loop=l10, factors=[v59, v60], preserve_unit_iters=True)
sch.reorder(l15, l23, l31, l39, l47, l16, l24, l32, l40, l48, l53, l57, l61, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50)
b63, = sch.get_consumers(block=b0)
sch.reverse_compute_at(block=b63, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
sch.enter_postproc()
b65 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b65, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b65, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b65, ann_key="meta_schedule.unroll_explicit")
b66, b67 = sch.get_child_blocks(b65)
l68, l69, l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93 = sch.get_loops(block=b66)
l94 = sch.fuse(l68, l69, l70, l71, l72, l73, l74, l75, l76, l77, preserve_unit_iters=True)
sch.parallel(loop=l94)
sch.annotate(block_or_loop=l94, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l94, ann_key="pragma_unroll_explicit", ann_val=1)
l95, l96, l97, l98, l99, l100 = sch.get_loops(block=b67)
l101 = sch.fuse(l100, preserve_unit_iters=True)
sch.vectorize(loop=l101)
b102 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l103, l104, l105, l106, l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117, l118, l119 = sch.get_loops(block=b102)
b120 = sch.decompose_reduction(block=b102, loop=l104)
2024-04-29 22:01:47 [INFO] [task_scheduler.cc:121] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #184: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(14), T.int64(14), T.int64(512)), "float32"), p1: T.Buffer((T.int64(4), T.int64(2), T.int64(1), T.int64(1), T.int64(512), T.int64(64)), "float32"), p2: T.Buffer((T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(64)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(4), T.int64(14), T.int64(14), T.int64(64)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(4), T.int64(14), T.int64(14), T.int64(64)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused in T.parallel(T.int64(112), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(8), T.int64(1), T.int64(2), T.int64(1), T.int64(7)):
                for oc_block_3_fused_init in T.vectorized(T.int64(4)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(4), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused // T.int64(56) * T.int64(2) + oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(56) // T.int64(4) + oh_2_init + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(4) // T.int64(2) * T.int64(7) + ow_2_init * T.int64(7) + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(64), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(2) * T.int64(32) + oc_block_2_init * T.int64(4) + oc_block_3_fused_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
            for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(32), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(8), T.int64(32), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(7)):
                for oc_block_3_fused in T.vectorized(T.int64(4)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(4), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused // T.int64(56) * T.int64(2) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(56) // T.int64(4) + oh_2 + oh_3)
                        v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(4) // T.int64(2) * T.int64(7) + ow_2 * T.int64(7) + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(64), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(2) * T.int64(32) + oc_block_2 * T.int64(4) + oc_block_3_fused)
                        v_ic = T.axis.reduce(T.int64(1024), ic_0 * T.int64(32) + ic_1)
                        v_kh = T.axis.reduce(T.int64(1), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(1), kw_0 + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], p0[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + p0[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(7)):
                for ax4_fused in T.vectorized(T.int64(32)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(4), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused // T.int64(56) * T.int64(2) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(56) // T.int64(4) + ax2)
                        v_ax3 = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(4) // T.int64(2) * T.int64(7) + ax3)
                        v_ax4 = T.axis.spatial(T.int64(64), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(2) * T.int64(32) + ax4_fused)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b1 = sch.get_block(name="T_add", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l3, l4, l5, l6, l7, l8, l9, l10 = sch.get_loops(block=b0)
v11, v12, v13, v14 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l15, l16, l17, l18 = sch.split(loop=l3, factors=[v11, v12, v13, v14], preserve_unit_iters=True)
v19, v20, v21, v22 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 2, 1, 2])
l23, l24, l25, l26 = sch.split(loop=l4, factors=[v19, v20, v21, v22], preserve_unit_iters=True)
v27, v28, v29, v30 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 14, 1, 1])
l31, l32, l33, l34 = sch.split(loop=l5, factors=[v27, v28, v29, v30], preserve_unit_iters=True)
v35, v36, v37, v38 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 2, 1, 7])
l39, l40, l41, l42 = sch.split(loop=l6, factors=[v35, v36, v37, v38], preserve_unit_iters=True)
v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 2, 8, 4])
l47, l48, l49, l50 = sch.split(loop=l7, factors=[v43, v44, v45, v46], preserve_unit_iters=True)
v51, v52 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[32, 32])
l53, l54 = sch.split(loop=l8, factors=[v51, v52], preserve_unit_iters=True)
v55, v56 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[1, 1])
l57, l58 = sch.split(loop=l9, factors=[v55, v56], preserve_unit_iters=True)
v59, v60 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 1])
l61, l62 = sch.split(loop=l10, factors=[v59, v60], preserve_unit_iters=True)
sch.reorder(l15, l23, l31, l39, l47, l16, l24, l32, l40, l48, l53, l57, l61, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50)
b63, = sch.get_consumers(block=b0)
sch.reverse_compute_at(block=b63, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
sch.enter_postproc()
b65 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b65, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b65, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b65, ann_key="meta_schedule.unroll_explicit")
b66, b67 = sch.get_child_blocks(b65)
l68, l69, l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93 = sch.get_loops(block=b66)
l94 = sch.fuse(l68, l69, l70, l71, l72, l73, l74, l75, l76, l77, preserve_unit_iters=True)
sch.parallel(loop=l94)
l95 = sch.fuse(l93, preserve_unit_iters=True)
sch.vectorize(loop=l95)
sch.annotate(block_or_loop=l94, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l94, ann_key="pragma_unroll_explicit", ann_val=1)
l96, l97, l98, l99, l100, l101 = sch.get_loops(block=b67)
l102 = sch.fuse(l101, preserve_unit_iters=True)
sch.vectorize(loop=l102)
b103 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l104, l105, l106, l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117, l118, l119, l120 = sch.get_loops(block=b103)
b121 = sch.decompose_reduction(block=b103, loop=l105)
2024-04-29 22:01:47 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #185: GFLOPs: 164.3250. Time: 625.9597 us. Best GFLOPs: 860.7183
2024-04-29 22:01:47 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #186: GFLOPs: 233.5567. Time: 440.4105 us. Best GFLOPs: 860.7183
2024-04-29 22:01:47 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #187: GFLOPs: 215.8546. Time: 476.5282 us. Best GFLOPs: 860.7183
2024-04-29 22:01:47 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #188: GFLOPs: 301.6376. Time: 341.0079 us. Best GFLOPs: 860.7183
2024-04-29 22:01:47 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #189: GFLOPs: 657.6604. Time: 156.4041 us. Best GFLOPs: 860.7183
2024-04-29 22:01:47 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #190: GFLOPs: 20.9307. Time: 4914.3546 us. Best GFLOPs: 860.7183
2024-04-29 22:01:47 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #191: GFLOPs: 143.7976. Time: 715.3165 us. Best GFLOPs: 860.7183
2024-04-29 22:01:47 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #192: GFLOPs: 7.5189. Time: 13680.3330 us. Best GFLOPs: 860.7183
2024-04-29 23:20:30 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 23:20:30 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-29 23:20:32 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4800b58)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x48148c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0xbdcc888)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x91ae188)]: 0 failure(s)
2024-04-29 23:20:32 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-29 23:20:38 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4800b58)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x48148c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0xbdcc888)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x91ae188)]: 0 failure(s)
2024-04-29 23:20:43 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4800b58)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x48148c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0xbdcc888)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x91ae188)]: 0 failure(s)
2024-04-29 23:20:49 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4800b58)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x48148c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0xbdcc888)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x91ae188)]: 0 failure(s)
2024-04-29 23:20:54 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4800b58)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x48148c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0xbdcc888)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x91ae188)]: 0 failure(s)
2024-04-29 23:20:57 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9784  0.9701  0.9689  0.9689  0.8964  0.8926  0.8839  0.8560  0.8308  0.8284  0.8112  0.8039  0.8032  0.8022  0.8022  0.7984
[17 : 32]:	0.7976  0.7958  0.7871  0.7839  0.7839  0.7834  0.7816  0.7804  0.7715  0.7715  0.7699  0.7699  0.7616  0.7571  0.7540  0.7490
[33 : 48]:	0.7474  0.7419  0.7390  0.7383  0.7320  0.7320  0.7269  0.7245  0.7186  0.7085  0.7079  0.7060  0.7022  0.6879  0.6871  0.6871
[49 : 64]:	0.6868  0.6836  0.6821  0.6815  0.6782  0.6748  0.6733  0.6730  0.6728  0.6701  0.6667  0.6636  0.6631  0.6631  0.6596  0.6594
2024-04-29 23:20:57 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 23:20:57 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 23:22:39 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #193: GFLOPs: 860.0922. Time: 119.5928 us. Best GFLOPs: 860.7183
2024-04-29 23:22:39 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #194: GFLOPs: 866.4673. Time: 118.7128 us. Best GFLOPs: 866.4673
2024-04-29 23:22:39 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #195: GFLOPs: 860.4517. Time: 119.5428 us. Best GFLOPs: 866.4673
2024-04-29 23:22:39 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #196: GFLOPs: 856.1559. Time: 120.1426 us. Best GFLOPs: 866.4673
2024-04-29 23:22:39 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #197: GFLOPs: 843.8989. Time: 121.8876 us. Best GFLOPs: 866.4673
2024-04-29 23:22:39 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #198: GFLOPs: 837.9039. Time: 122.7597 us. Best GFLOPs: 866.4673
2024-04-29 23:22:39 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #199: GFLOPs: 958.8960. Time: 107.2700 us. Best GFLOPs: 958.8960
2024-04-29 23:22:39 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #200: GFLOPs: 536.9099. Time: 191.5793 us. Best GFLOPs: 958.8960
2024-04-29 23:22:39 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #201: GFLOPs: 187.2606. Time: 549.2923 us. Best GFLOPs: 958.8960
2024-04-29 23:22:39 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #202: GFLOPs: 982.1421. Time: 104.7311 us. Best GFLOPs: 982.1421
2024-04-29 23:22:39 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #203: GFLOPs: 745.6846. Time: 137.9414 us. Best GFLOPs: 982.1421
2024-04-29 23:22:39 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #204: GFLOPs: 142.1942. Time: 723.3828 us. Best GFLOPs: 982.1421
2024-04-29 23:22:39 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #205: GFLOPs: 663.7498. Time: 154.9692 us. Best GFLOPs: 982.1421
2024-04-29 23:22:39 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #206: GFLOPs: 797.4559. Time: 128.9862 us. Best GFLOPs: 982.1421
2024-04-29 23:22:39 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #207: GFLOPs: 795.6551. Time: 129.2781 us. Best GFLOPs: 982.1421
2024-04-29 23:22:39 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #208: GFLOPs: 746.8092. Time: 137.7337 us. Best GFLOPs: 982.1421
2024-04-29 23:22:39 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #209: GFLOPs: 759.5288. Time: 135.4271 us. Best GFLOPs: 982.1421
2024-04-29 23:22:39 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #210: GFLOPs: 842.6035. Time: 122.0750 us. Best GFLOPs: 982.1421
2024-04-29 23:22:39 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #211: GFLOPs: 795.6301. Time: 129.2822 us. Best GFLOPs: 982.1421
2024-04-29 23:22:39 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #212: GFLOPs: 112.4413. Time: 914.7955 us. Best GFLOPs: 982.1421
2024-04-29 23:22:39 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #213: GFLOPs: 112.7812. Time: 912.0388 us. Best GFLOPs: 982.1421
2024-04-29 23:22:39 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #214: GFLOPs: 755.5015. Time: 136.1490 us. Best GFLOPs: 982.1421
2024-04-29 23:22:39 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #215: GFLOPs: 610.0276. Time: 168.6166 us. Best GFLOPs: 982.1421
2024-04-29 23:22:39 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #216: GFLOPs: 748.7876. Time: 137.3698 us. Best GFLOPs: 982.1421
2024-04-29 23:22:39 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #217: GFLOPs: 537.2251. Time: 191.4669 us. Best GFLOPs: 982.1421
2024-04-29 23:22:39 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #218: GFLOPs: 536.8153. Time: 191.6130 us. Best GFLOPs: 982.1421
2024-04-29 23:22:39 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #219: GFLOPs: 111.9063. Time: 919.1693 us. Best GFLOPs: 982.1421
2024-04-29 23:22:39 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #220: GFLOPs: 111.8798. Time: 919.3865 us. Best GFLOPs: 982.1421
2024-04-29 23:22:39 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #221: GFLOPs: 102.5808. Time: 1002.7298 us. Best GFLOPs: 982.1421
2024-04-29 23:22:39 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #222: GFLOPs: 702.5882. Time: 146.4027 us. Best GFLOPs: 982.1421
2024-04-29 23:22:39 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #223: GFLOPs: 493.0787. Time: 208.6093 us. Best GFLOPs: 982.1421
2024-04-29 23:22:39 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #224: GFLOPs: 784.8399. Time: 131.0596 us. Best GFLOPs: 982.1421
2024-04-29 23:22:39 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #225: GFLOPs: 570.9928. Time: 180.1438 us. Best GFLOPs: 982.1421
2024-04-29 23:22:39 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #226: GFLOPs: 753.5090. Time: 136.5091 us. Best GFLOPs: 982.1421
2024-04-29 23:22:39 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #227: GFLOPs: 682.1745. Time: 150.7837 us. Best GFLOPs: 982.1421
2024-04-29 23:22:39 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #228: GFLOPs: 611.2285. Time: 168.2854 us. Best GFLOPs: 982.1421
2024-04-29 23:22:39 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #229: GFLOPs: 680.7308. Time: 151.1035 us. Best GFLOPs: 982.1421
2024-04-29 23:22:39 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #230: GFLOPs: 670.8665. Time: 153.3253 us. Best GFLOPs: 982.1421
2024-04-29 23:22:39 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #231: GFLOPs: 650.1513. Time: 158.2106 us. Best GFLOPs: 982.1421
2024-04-29 23:22:39 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #232: GFLOPs: 629.3011. Time: 163.4524 us. Best GFLOPs: 982.1421
2024-04-29 23:22:39 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #233: GFLOPs: 330.4942. Time: 311.2333 us. Best GFLOPs: 982.1421
2024-04-29 23:22:39 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #234: GFLOPs: 794.3258. Time: 129.4945 us. Best GFLOPs: 982.1421
2024-04-29 23:22:39 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #235: GFLOPs: 510.9689. Time: 201.3054 us. Best GFLOPs: 982.1421
2024-04-29 23:22:39 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #236: GFLOPs: 220.7541. Time: 465.9519 us. Best GFLOPs: 982.1421
2024-04-29 23:22:39 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #237: GFLOPs: 610.1610. Time: 168.5798 us. Best GFLOPs: 982.1421
2024-04-29 23:22:39 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #238: GFLOPs: 658.9859. Time: 156.0895 us. Best GFLOPs: 982.1421
2024-04-29 23:22:39 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #239: GFLOPs: 690.2182. Time: 149.0265 us. Best GFLOPs: 982.1421
2024-04-29 23:22:39 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #240: GFLOPs: 690.4937. Time: 148.9670 us. Best GFLOPs: 982.1421
2024-04-29 23:22:39 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #241: GFLOPs: 666.2378. Time: 154.3905 us. Best GFLOPs: 982.1421
2024-04-29 23:22:39 [INFO] [task_scheduler.cc:121] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #242: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(14), T.int64(14), T.int64(512)), "float32"), p1: T.Buffer((T.int64(4), T.int64(2), T.int64(1), T.int64(1), T.int64(512), T.int64(64)), "float32"), p2: T.Buffer((T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(64)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(4), T.int64(14), T.int64(14), T.int64(64)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(4), T.int64(14), T.int64(14), T.int64(64)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused in T.parallel(T.int64(56), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(64), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1)):
                with T.block("conv2d_NCHWc_init"):
                    v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                    v_oc_chunk = T.axis.spatial(T.int64(4), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(4) // T.int64(2) * T.int64(2) + oc_chunk_2_init + oc_chunk_3_init)
                    v_oh = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused // T.int64(8) * T.int64(2) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(2) + oh_2_init + oh_3_init)
                    v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(8) // T.int64(4) * T.int64(7) + ow_2_init * T.int64(7) + ow_3_init)
                    v_oc_block = T.axis.spatial(T.int64(64), oc_block_2_init + oc_block_3_init)
                    T.reads()
                    T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                    T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                    conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
            for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(1024), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(64), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1)):
                with T.block("conv2d_NCHWc_update"):
                    v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                    v_oc_chunk = T.axis.spatial(T.int64(4), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(4) // T.int64(2) * T.int64(2) + oc_chunk_2 + oc_chunk_3)
                    v_oh = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused // T.int64(8) * T.int64(2) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(2) + oh_2 + oh_3)
                    v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(8) // T.int64(4) * T.int64(7) + ow_2 * T.int64(7) + ow_3)
                    v_oc_block = T.axis.spatial(T.int64(64), oc_block_2 + oc_block_3)
                    v_ic = T.axis.reduce(T.int64(1024), ic_0 + ic_1)
                    v_kh = T.axis.reduce(T.int64(1), kh_0 + kh_1)
                    v_kw = T.axis.reduce(T.int64(1), kw_0 + kw_1)
                    T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], p0[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                    T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                    T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                    conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + p0[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(7)):
                for ax4_fused in T.vectorized(T.int64(64)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(4), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(4) // T.int64(2) * T.int64(2) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused // T.int64(8) * T.int64(2) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(2) + ax2)
                        v_ax3 = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(8) // T.int64(4) * T.int64(7) + ax3)
                        v_ax4 = T.axis.spatial(T.int64(64), ax4_fused)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b1 = sch.get_block(name="T_add", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l3, l4, l5, l6, l7, l8, l9, l10 = sch.get_loops(block=b0)
v11, v12, v13, v14 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l15, l16, l17, l18 = sch.split(loop=l3, factors=[v11, v12, v13, v14], preserve_unit_iters=True)
v19, v20, v21, v22 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 2, 2, 1])
l23, l24, l25, l26 = sch.split(loop=l4, factors=[v19, v20, v21, v22], preserve_unit_iters=True)
v27, v28, v29, v30 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[7, 2, 1, 1])
l31, l32, l33, l34 = sch.split(loop=l5, factors=[v27, v28, v29, v30], preserve_unit_iters=True)
v35, v36, v37, v38 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 1, 1, 7])
l39, l40, l41, l42 = sch.split(loop=l6, factors=[v35, v36, v37, v38], preserve_unit_iters=True)
v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 64, 1])
l47, l48, l49, l50 = sch.split(loop=l7, factors=[v43, v44, v45, v46], preserve_unit_iters=True)
v51, v52 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[1024, 1])
l53, l54 = sch.split(loop=l8, factors=[v51, v52], preserve_unit_iters=True)
v55, v56 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[1, 1])
l57, l58 = sch.split(loop=l9, factors=[v55, v56], preserve_unit_iters=True)
v59, v60 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 1])
l61, l62 = sch.split(loop=l10, factors=[v59, v60], preserve_unit_iters=True)
sch.reorder(l15, l23, l31, l39, l47, l16, l24, l32, l40, l48, l53, l57, l61, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50)
b63, = sch.get_consumers(block=b0)
sch.reverse_compute_at(block=b63, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
sch.enter_postproc()
b65 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b65, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b65, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b65, ann_key="meta_schedule.unroll_explicit")
b66, b67 = sch.get_child_blocks(b65)
l68, l69, l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93 = sch.get_loops(block=b66)
l94 = sch.fuse(l68, l69, l70, l71, l72, l73, l74, l75, l76, l77, preserve_unit_iters=True)
sch.parallel(loop=l94)
sch.annotate(block_or_loop=l94, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l94, ann_key="pragma_unroll_explicit", ann_val=1)
l95, l96, l97, l98, l99, l100 = sch.get_loops(block=b67)
l101 = sch.fuse(l100, preserve_unit_iters=True)
sch.vectorize(loop=l101)
b102 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l103, l104, l105, l106, l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117, l118, l119 = sch.get_loops(block=b102)
b120 = sch.decompose_reduction(block=b102, loop=l104)
2024-04-29 23:22:39 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #243: GFLOPs: 707.1975. Time: 145.4485 us. Best GFLOPs: 982.1421
2024-04-29 23:22:39 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #244: GFLOPs: 542.5879. Time: 189.5745 us. Best GFLOPs: 982.1421
2024-04-29 23:22:39 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #245: GFLOPs: 671.3379. Time: 153.2176 us. Best GFLOPs: 982.1421
2024-04-29 23:22:39 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #246: GFLOPs: 607.2289. Time: 169.3938 us. Best GFLOPs: 982.1421
2024-04-29 23:22:39 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #247: GFLOPs: 621.8279. Time: 165.4168 us. Best GFLOPs: 982.1421
2024-04-29 23:22:39 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #248: GFLOPs: 662.4760. Time: 155.2672 us. Best GFLOPs: 982.1421
2024-04-29 23:22:39 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #249: GFLOPs: 703.8622. Time: 146.1377 us. Best GFLOPs: 982.1421
2024-04-29 23:22:39 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #250: GFLOPs: 666.0171. Time: 154.4417 us. Best GFLOPs: 982.1421
2024-04-29 23:22:39 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #251: GFLOPs: 666.3745. Time: 154.3589 us. Best GFLOPs: 982.1421
2024-04-29 23:22:39 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #252: GFLOPs: 651.8016. Time: 157.8100 us. Best GFLOPs: 982.1421
2024-04-29 23:22:39 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #253: GFLOPs: 692.0238. Time: 148.6377 us. Best GFLOPs: 982.1421
2024-04-29 23:22:39 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #254: GFLOPs: 4.2838. Time: 24011.3654 us. Best GFLOPs: 982.1421
2024-04-29 23:22:39 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #255: GFLOPs: 3.4557. Time: 29765.1877 us. Best GFLOPs: 982.1421
2024-04-29 23:22:39 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #256: GFLOPs: 209.7285. Time: 490.4475 us. Best GFLOPs: 982.1421
2024-04-29 23:22:39 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 23:22:40 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-29 23:22:42 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4800b58)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x48148c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0xbdcc888)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x91ae188)]: 0 failure(s)
2024-04-29 23:22:42 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-29 23:22:47 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4800b58)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x48148c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0xbdcc888)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x91ae188)]: 0 failure(s)
2024-04-29 23:22:53 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4800b58)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x48148c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0xbdcc888)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x91ae188)]: 0 failure(s)
2024-04-29 23:22:58 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4800b58)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x48148c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0xbdcc888)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x91ae188)]: 0 failure(s)
2024-04-29 23:23:04 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4800b58)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x48148c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0xbdcc888)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x91ae188)]: 0 failure(s)
2024-04-29 23:23:06 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9686  0.9674  0.9674  0.9674  0.9674  0.9662  0.9661  0.9643  0.9535  0.9535  0.9535  0.9491  0.9242  0.8740  0.8732  0.8703
[17 : 32]:	0.8696  0.8696  0.8693  0.8673  0.8632  0.8589  0.8588  0.8539  0.8504  0.8501  0.8237  0.8224  0.8213  0.8213  0.8133  0.8097
[33 : 48]:	0.8097  0.8097  0.8089  0.8088  0.8075  0.8075  0.8075  0.8052  0.8052  0.7913  0.7749  0.7607  0.7584  0.7571  0.7555  0.7555
[49 : 64]:	0.7487  0.7364  0.7203  0.7126  0.7126  0.7111  0.7095  0.6980  0.6980  0.6955  0.6952  0.6952  0.6952  0.6952  0.6952  0.6945
2024-04-29 23:23:07 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 23:23:07 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 23:24:30 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #257: GFLOPs: 488.2606. Time: 210.6678 us. Best GFLOPs: 982.1421
2024-04-29 23:24:30 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #258: GFLOPs: 979.8238. Time: 104.9789 us. Best GFLOPs: 982.1421
2024-04-29 23:24:30 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #259: GFLOPs: 978.6210. Time: 105.1079 us. Best GFLOPs: 982.1421
2024-04-29 23:24:30 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #260: GFLOPs: 978.0695. Time: 105.1672 us. Best GFLOPs: 982.1421
2024-04-29 23:24:30 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #261: GFLOPs: 971.4343. Time: 105.8855 us. Best GFLOPs: 982.1421
2024-04-29 23:24:30 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #262: GFLOPs: 949.2616. Time: 108.3587 us. Best GFLOPs: 982.1421
2024-04-29 23:24:30 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #263: GFLOPs: 968.9110. Time: 106.1612 us. Best GFLOPs: 982.1421
2024-04-29 23:24:30 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #264: GFLOPs: 972.3513. Time: 105.7856 us. Best GFLOPs: 982.1421
2024-04-29 23:24:30 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #265: GFLOPs: 970.2011. Time: 106.0201 us. Best GFLOPs: 982.1421
2024-04-29 23:24:30 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #266: GFLOPs: 968.1885. Time: 106.2405 us. Best GFLOPs: 982.1421
2024-04-29 23:24:30 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #267: GFLOPs: 978.0492. Time: 105.1693 us. Best GFLOPs: 982.1421
2024-04-29 23:24:30 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #268: GFLOPs: 975.7757. Time: 105.4144 us. Best GFLOPs: 982.1421
2024-04-29 23:24:30 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #269: GFLOPs: 968.9119. Time: 106.1611 us. Best GFLOPs: 982.1421
2024-04-29 23:24:30 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #270: GFLOPs: 866.0854. Time: 118.7652 us. Best GFLOPs: 982.1421
2024-04-29 23:24:30 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #271: GFLOPs: 866.5169. Time: 118.7061 us. Best GFLOPs: 982.1421
2024-04-29 23:24:30 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #272: GFLOPs: 856.3161. Time: 120.1201 us. Best GFLOPs: 982.1421
2024-04-29 23:24:30 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #273: GFLOPs: 867.4351. Time: 118.5804 us. Best GFLOPs: 982.1421
2024-04-29 23:24:30 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #274: GFLOPs: 861.4260. Time: 119.4076 us. Best GFLOPs: 982.1421
2024-04-29 23:24:30 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #275: GFLOPs: 869.9291. Time: 118.2404 us. Best GFLOPs: 982.1421
2024-04-29 23:24:30 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #276: GFLOPs: 870.0717. Time: 118.2211 us. Best GFLOPs: 982.1421
2024-04-29 23:24:30 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #277: GFLOPs: 843.1879. Time: 121.9904 us. Best GFLOPs: 982.1421
2024-04-29 23:24:30 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #278: GFLOPs: 842.8473. Time: 122.0397 us. Best GFLOPs: 982.1421
2024-04-29 23:24:30 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #279: GFLOPs: 839.4651. Time: 122.5314 us. Best GFLOPs: 982.1421
2024-04-29 23:24:30 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #280: GFLOPs: 864.6083. Time: 118.9681 us. Best GFLOPs: 982.1421
2024-04-29 23:24:30 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #281: GFLOPs: 760.3544. Time: 135.2801 us. Best GFLOPs: 982.1421
2024-04-29 23:24:30 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #282: GFLOPs: 863.1674. Time: 119.1667 us. Best GFLOPs: 982.1421
2024-04-29 23:24:30 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #283: GFLOPs: 796.4525. Time: 129.1487 us. Best GFLOPs: 982.1421
2024-04-29 23:24:30 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #284: GFLOPs: 795.2111. Time: 129.3503 us. Best GFLOPs: 982.1421
2024-04-29 23:24:30 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #285: GFLOPs: 795.7248. Time: 129.2668 us. Best GFLOPs: 982.1421
2024-04-29 23:24:30 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #286: GFLOPs: 796.3247. Time: 129.1694 us. Best GFLOPs: 982.1421
2024-04-29 23:24:30 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #287: GFLOPs: 795.6980. Time: 129.2712 us. Best GFLOPs: 982.1421
2024-04-29 23:24:30 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #288: GFLOPs: 795.1175. Time: 129.3655 us. Best GFLOPs: 982.1421
2024-04-29 23:24:30 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #289: GFLOPs: 794.8424. Time: 129.4103 us. Best GFLOPs: 982.1421
2024-04-29 23:24:30 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #290: GFLOPs: 794.2936. Time: 129.4997 us. Best GFLOPs: 982.1421
2024-04-29 23:24:30 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #291: GFLOPs: 796.9084. Time: 129.0748 us. Best GFLOPs: 982.1421
2024-04-29 23:24:30 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #292: GFLOPs: 789.9766. Time: 130.2074 us. Best GFLOPs: 982.1421
2024-04-29 23:24:30 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #293: GFLOPs: 462.7143. Time: 222.2987 us. Best GFLOPs: 982.1421
2024-04-29 23:24:30 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #294: GFLOPs: 796.5339. Time: 129.1355 us. Best GFLOPs: 982.1421
2024-04-29 23:24:30 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #295: GFLOPs: 795.2334. Time: 129.3467 us. Best GFLOPs: 982.1421
2024-04-29 23:24:30 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #296: GFLOPs: 789.9891. Time: 130.2053 us. Best GFLOPs: 982.1421
2024-04-29 23:24:30 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #297: GFLOPs: 792.8465. Time: 129.7361 us. Best GFLOPs: 982.1421
2024-04-29 23:24:30 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #298: GFLOPs: 752.7014. Time: 136.6555 us. Best GFLOPs: 982.1421
2024-04-29 23:24:30 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #299: GFLOPs: 790.2609. Time: 130.1606 us. Best GFLOPs: 982.1421
2024-04-29 23:24:30 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #300: GFLOPs: 756.9112. Time: 135.8955 us. Best GFLOPs: 982.1421
2024-04-29 23:24:30 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #301: GFLOPs: 736.4992. Time: 139.6618 us. Best GFLOPs: 982.1421
2024-04-29 23:24:30 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #302: GFLOPs: 752.4478. Time: 136.7016 us. Best GFLOPs: 982.1421
2024-04-29 23:24:30 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #303: GFLOPs: 797.8279. Time: 128.9260 us. Best GFLOPs: 982.1421
2024-04-29 23:24:30 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #304: GFLOPs: 225.5177. Time: 456.1097 us. Best GFLOPs: 982.1421
2024-04-29 23:24:30 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #305: GFLOPs: 800.9132. Time: 128.4294 us. Best GFLOPs: 982.1421
2024-04-29 23:24:30 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #306: GFLOPs: 796.4478. Time: 129.1495 us. Best GFLOPs: 982.1421
2024-04-29 23:24:30 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #307: GFLOPs: 723.9167. Time: 142.0893 us. Best GFLOPs: 982.1421
2024-04-29 23:24:30 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #308: GFLOPs: 749.5148. Time: 137.2365 us. Best GFLOPs: 982.1421
2024-04-29 23:24:30 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #309: GFLOPs: 733.9254. Time: 140.1516 us. Best GFLOPs: 982.1421
2024-04-29 23:24:30 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #310: GFLOPs: 587.4890. Time: 175.0855 us. Best GFLOPs: 982.1421
2024-04-29 23:24:30 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #311: GFLOPs: 702.9566. Time: 146.3260 us. Best GFLOPs: 982.1421
2024-04-29 23:24:30 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #312: GFLOPs: 703.3093. Time: 146.2526 us. Best GFLOPs: 982.1421
2024-04-29 23:24:30 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #313: GFLOPs: 699.6596. Time: 147.0155 us. Best GFLOPs: 982.1421
2024-04-29 23:24:30 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #314: GFLOPs: 674.9120. Time: 152.4062 us. Best GFLOPs: 982.1421
2024-04-29 23:24:30 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #315: GFLOPs: 672.9029. Time: 152.8613 us. Best GFLOPs: 982.1421
2024-04-29 23:24:30 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #316: GFLOPs: 633.1941. Time: 162.4475 us. Best GFLOPs: 982.1421
2024-04-29 23:24:30 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #317: GFLOPs: 466.4847. Time: 220.5020 us. Best GFLOPs: 982.1421
2024-04-29 23:24:30 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #318: GFLOPs: 19.3908. Time: 5304.6305 us. Best GFLOPs: 982.1421
2024-04-29 23:24:30 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #319: GFLOPs: 73.8466. Time: 1392.8983 us. Best GFLOPs: 982.1421
2024-04-29 23:24:30 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #320: GFLOPs: 65.6402. Time: 1567.0398 us. Best GFLOPs: 982.1421
2024-04-29 23:54:13 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 23:54:13 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-29 23:54:16 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4800b58)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x48148c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0xbdcc888)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x91ae188)]: 0 failure(s)
2024-04-29 23:54:16 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-29 23:54:21 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4800b58)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x48148c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0xbdcc888)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x91ae188)]: 0 failure(s)
2024-04-29 23:54:26 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4800b58)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x48148c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0xbdcc888)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x91ae188)]: 0 failure(s)
2024-04-29 23:54:32 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4800b58)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x48148c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0xbdcc888)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x91ae188)]: 0 failure(s)
2024-04-29 23:54:37 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4800b58)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x48148c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0xbdcc888)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x91ae188)]: 0 failure(s)
2024-04-29 23:54:40 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9881  0.9862  0.9845  0.9845  0.9841  0.9776  0.9776  0.9776  0.9683  0.9647  0.9647  0.9638  0.9613  0.9613  0.9552  0.9485
[17 : 32]:	0.9393  0.9393  0.9380  0.9249  0.9249  0.9183  0.9082  0.9075  0.9012  0.9001  0.8923  0.8883  0.8852  0.8836  0.8824  0.8817
[33 : 48]:	0.8633  0.8633  0.8501  0.8481  0.8481  0.8461  0.8461  0.8374  0.8286  0.8283  0.8245  0.8207  0.8197  0.8125  0.8125  0.8104
[49 : 64]:	0.8020  0.7975  0.7939  0.7922  0.7908  0.7902  0.7901  0.7901  0.7895  0.7763  0.7763  0.7751  0.7726  0.7718  0.7683  0.7624
2024-04-29 23:54:40 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 23:54:40 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 23:56:00 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #321: GFLOPs: 951.9715. Time: 108.0503 us. Best GFLOPs: 982.1421
2024-04-29 23:56:00 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #322: GFLOPs: 958.5070. Time: 107.3136 us. Best GFLOPs: 982.1421
2024-04-29 23:56:00 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #323: GFLOPs: 975.7448. Time: 105.4177 us. Best GFLOPs: 982.1421
2024-04-29 23:56:00 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #324: GFLOPs: 968.5816. Time: 106.1973 us. Best GFLOPs: 982.1421
2024-04-29 23:56:00 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #325: GFLOPs: 962.3422. Time: 106.8859 us. Best GFLOPs: 982.1421
2024-04-29 23:56:00 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #326: GFLOPs: 980.9960. Time: 104.8534 us. Best GFLOPs: 982.1421
2024-04-29 23:56:00 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #327: GFLOPs: 969.5141. Time: 106.0952 us. Best GFLOPs: 982.1421
2024-04-29 23:56:00 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #328: GFLOPs: 980.5755. Time: 104.8984 us. Best GFLOPs: 982.1421
2024-04-29 23:56:00 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #329: GFLOPs: 908.4572. Time: 113.2258 us. Best GFLOPs: 982.1421
2024-04-29 23:56:00 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #330: GFLOPs: 959.3759. Time: 107.2164 us. Best GFLOPs: 982.1421
2024-04-29 23:56:00 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #331: GFLOPs: 926.2546. Time: 111.0502 us. Best GFLOPs: 982.1421
2024-04-29 23:56:00 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #332: GFLOPs: 283.1978. Time: 363.2118 us. Best GFLOPs: 982.1421
2024-04-29 23:56:00 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #333: GFLOPs: 971.7790. Time: 105.8479 us. Best GFLOPs: 982.1421
2024-04-29 23:56:00 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #334: GFLOPs: 976.1969. Time: 105.3689 us. Best GFLOPs: 982.1421
2024-04-29 23:56:00 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #335: GFLOPs: 896.1030. Time: 114.7868 us. Best GFLOPs: 982.1421
2024-04-29 23:56:00 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #336: GFLOPs: 978.5864. Time: 105.1116 us. Best GFLOPs: 982.1421
2024-04-29 23:56:00 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #337: GFLOPs: 965.1115. Time: 106.5792 us. Best GFLOPs: 982.1421
2024-04-29 23:56:00 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #338: GFLOPs: 973.0766. Time: 105.7068 us. Best GFLOPs: 982.1421
2024-04-29 23:56:00 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #339: GFLOPs: 972.4501. Time: 105.7749 us. Best GFLOPs: 982.1421
2024-04-29 23:56:00 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #340: GFLOPs: 980.7437. Time: 104.8804 us. Best GFLOPs: 982.1421
2024-04-29 23:56:00 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #341: GFLOPs: 978.4223. Time: 105.1292 us. Best GFLOPs: 982.1421
2024-04-29 23:56:00 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #342: GFLOPs: 857.5004. Time: 119.9542 us. Best GFLOPs: 982.1421
2024-04-29 23:56:00 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #343: GFLOPs: 824.1412. Time: 124.8097 us. Best GFLOPs: 982.1421
2024-04-29 23:56:00 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #344: GFLOPs: 979.2530. Time: 105.0401 us. Best GFLOPs: 982.1421
2024-04-29 23:56:00 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #345: GFLOPs: 827.2509. Time: 124.3405 us. Best GFLOPs: 982.1421
2024-04-29 23:56:00 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #346: GFLOPs: 981.8933. Time: 104.7576 us. Best GFLOPs: 982.1421
2024-04-29 23:56:00 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #347: GFLOPs: 855.9283. Time: 120.1746 us. Best GFLOPs: 982.1421
2024-04-29 23:56:00 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #348: GFLOPs: 865.0158. Time: 118.9120 us. Best GFLOPs: 982.1421
2024-04-29 23:56:00 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #349: GFLOPs: 863.3883. Time: 119.1362 us. Best GFLOPs: 982.1421
2024-04-29 23:56:00 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #350: GFLOPs: 865.3365. Time: 118.8680 us. Best GFLOPs: 982.1421
2024-04-29 23:56:00 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #351: GFLOPs: 960.0206. Time: 107.1444 us. Best GFLOPs: 982.1421
2024-04-29 23:56:00 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #352: GFLOPs: 861.2033. Time: 119.4385 us. Best GFLOPs: 982.1421
2024-04-29 23:56:00 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #353: GFLOPs: 823.5752. Time: 124.8955 us. Best GFLOPs: 982.1421
2024-04-29 23:56:00 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #354: GFLOPs: 841.6044. Time: 122.2199 us. Best GFLOPs: 982.1421
2024-04-29 23:56:00 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #355: GFLOPs: 871.6772. Time: 118.0033 us. Best GFLOPs: 982.1421
2024-04-29 23:56:00 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #356: GFLOPs: 864.0135. Time: 119.0500 us. Best GFLOPs: 982.1421
2024-04-29 23:56:00 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #357: GFLOPs: 854.1025. Time: 120.4314 us. Best GFLOPs: 982.1421
2024-04-29 23:56:00 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #358: GFLOPs: 865.5550. Time: 118.8380 us. Best GFLOPs: 982.1421
2024-04-29 23:56:00 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #359: GFLOPs: 858.0028. Time: 119.8840 us. Best GFLOPs: 982.1421
2024-04-29 23:56:00 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #360: GFLOPs: 866.0801. Time: 118.7659 us. Best GFLOPs: 982.1421
2024-04-29 23:56:00 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #361: GFLOPs: 789.9418. Time: 130.2131 us. Best GFLOPs: 982.1421
2024-04-29 23:56:00 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #362: GFLOPs: 785.4246. Time: 130.9620 us. Best GFLOPs: 982.1421
2024-04-29 23:56:00 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #363: GFLOPs: 795.2062. Time: 129.3511 us. Best GFLOPs: 982.1421
2024-04-29 23:56:00 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #364: GFLOPs: 849.0897. Time: 121.1424 us. Best GFLOPs: 982.1421
2024-04-29 23:56:00 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #365: GFLOPs: 854.5150. Time: 120.3733 us. Best GFLOPs: 982.1421
2024-04-29 23:56:00 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #366: GFLOPs: 785.7814. Time: 130.9026 us. Best GFLOPs: 982.1421
2024-04-29 23:56:00 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #367: GFLOPs: 591.5380. Time: 173.8871 us. Best GFLOPs: 982.1421
2024-04-29 23:56:00 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #368: GFLOPs: 776.4225. Time: 132.4804 us. Best GFLOPs: 982.1421
2024-04-29 23:56:00 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #369: GFLOPs: 789.0619. Time: 130.3583 us. Best GFLOPs: 982.1421
2024-04-29 23:56:00 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #370: GFLOPs: 736.4714. Time: 139.6671 us. Best GFLOPs: 982.1421
2024-04-29 23:56:00 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #371: GFLOPs: 750.6006. Time: 137.0380 us. Best GFLOPs: 982.1421
2024-04-29 23:56:00 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #372: GFLOPs: 783.8686. Time: 131.2220 us. Best GFLOPs: 982.1421
2024-04-29 23:56:00 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #373: GFLOPs: 349.5937. Time: 294.2296 us. Best GFLOPs: 982.1421
2024-04-29 23:56:00 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #374: GFLOPs: 790.9255. Time: 130.0512 us. Best GFLOPs: 982.1421
2024-04-29 23:56:00 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #375: GFLOPs: 778.0226. Time: 132.2080 us. Best GFLOPs: 982.1421
2024-04-29 23:56:00 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #376: GFLOPs: 778.8234. Time: 132.0720 us. Best GFLOPs: 982.1421
2024-04-29 23:56:00 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #377: GFLOPs: 766.9679. Time: 134.1136 us. Best GFLOPs: 982.1421
2024-04-29 23:56:00 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #378: GFLOPs: 733.3201. Time: 140.2673 us. Best GFLOPs: 982.1421
2024-04-29 23:56:00 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #379: GFLOPs: 737.5630. Time: 139.4604 us. Best GFLOPs: 982.1421
2024-04-29 23:56:00 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #380: GFLOPs: 769.8243. Time: 133.6159 us. Best GFLOPs: 982.1421
2024-04-29 23:56:00 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #381: GFLOPs: 733.7362. Time: 140.1877 us. Best GFLOPs: 982.1421
2024-04-29 23:56:00 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #382: GFLOPs: 50.9910. Time: 2017.2325 us. Best GFLOPs: 982.1421
2024-04-29 23:56:00 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #383: GFLOPs: 62.0029. Time: 1658.9667 us. Best GFLOPs: 982.1421
2024-04-29 23:56:00 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #384: GFLOPs: 62.8603. Time: 1636.3407 us. Best GFLOPs: 982.1421
