2024-04-29 03:19:59 [INFO] [task_scheduler.cc:160] Initializing Task #10: "fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu"
2024-04-29 03:19:59 [INFO] [task_scheduler.cc:35] 
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(56), T.int64(56), T.int64(64)), "float32"), p1: T.Buffer((T.int64(2), T.int64(1), T.int64(3), T.int64(3), T.int64(64), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(32)), "float32"), p3: T.Buffer((T.int64(1), T.int64(2), T.int64(56), T.int64(56), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(2), T.int64(56), T.int64(56), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(58), T.int64(58), T.int64(64)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(56), T.int64(56), T.int64(32)))
        T_add = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(56), T.int64(56), T.int64(32)))
        T_add_1 = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(56), T.int64(56), T.int64(32)))
        for i0, i1, i2, i3, i4 in T.grid(T.int64(1), T.int64(1), T.int64(58), T.int64(58), T.int64(64)):
            with T.block("data_pad"):
                v_i0, v_i1, v_i2, v_i3, v_i4 = T.axis.remap("SSSSS", [i0, i1, i2, i3, i4])
                T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(57) and T.int64(1) <= v_i3 and v_i3 < T.int64(57), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
        for n, oc_chunk, oh, ow, oc_block, ic, kh, kw in T.grid(T.int64(1), T.int64(2), T.int64(56), T.int64(56), T.int64(32), T.int64(64), T.int64(3), T.int64(3)):
            with T.block("conv2d_NCHWc"):
                v_n, v_oc_chunk, v_oh, v_ow, v_oc_block, v_ic, v_kh, v_kw = T.axis.remap("SSSSSRRR", [n, oc_chunk, oh, ow, oc_block, ic, kh, kw])
                T.reads(data_pad[v_n, v_ic // T.int64(64), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(64)], p1[v_oc_chunk, v_ic // T.int64(64), v_kh, v_kw, v_ic % T.int64(64), v_oc_block])
                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                with T.init():
                    conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(64), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(64)] * p1[v_oc_chunk, v_ic // T.int64(64), v_kh, v_kw, v_ic % T.int64(64), v_oc_block]
        for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(2), T.int64(56), T.int64(56), T.int64(32)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                T.writes(T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4]
        for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(2), T.int64(56), T.int64(56), T.int64(32)):
            with T.block("T_add_1"):
                v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                T.reads(T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T.writes(T_add_1[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T_add_1[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4]
        for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(2), T.int64(56), T.int64(56), T.int64(32)):
            with T.block("T_relu"):
                v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                T.reads(T_add_1[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(T_add_1[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
2024-04-29 03:19:59 [INFO] [task_scheduler.cc:164] Total 3 design space(s) generated
2024-04-29 03:20:00 [INFO] [task_scheduler.cc:170] Design space #0:
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(56), T.int64(56), T.int64(64)), "float32"), p1: T.Buffer((T.int64(2), T.int64(1), T.int64(3), T.int64(3), T.int64(64), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(32)), "float32"), p3: T.Buffer((T.int64(1), T.int64(2), T.int64(56), T.int64(56), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(2), T.int64(56), T.int64(56), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel": 768, "meta_schedule.unroll_explicit": 512, "meta_schedule.vectorize": 64})
            data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(58), T.int64(58), T.int64(64)))
            conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(56), T.int64(56), T.int64(32)))
            for n_0, oc_chunk_0, oh_0, ow_0, oc_block_0, n_1, oc_chunk_1, oh_1, ow_1, oc_block_1, ic_0, kh_0, kw_0 in T.grid(T.int64(1), T.int64(2), T.int64(28), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(16), T.int64(1), T.int64(3)):
                for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(28), T.int64(4)):
                    with T.block("data_pad"):
                        v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                        v_i2 = T.axis.spatial(T.int64(58), oh_0 * T.int64(2) + ax2)
                        v_i3 = T.axis.spatial(T.int64(58), ow_1 * T.int64(28) + kw_0 + ax3)
                        v_i4 = T.axis.spatial(T.int64(64), ic_0 * T.int64(4) + ax4)
                        T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                        T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                        data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(57) and T.int64(1) <= v_i3 and v_i3 < T.int64(57), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                for n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(1), T.int64(1), T.int64(2), T.int64(7), T.int64(2), T.int64(4), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(16)):
                    with T.block("conv2d_NCHWc"):
                        v_n = T.axis.spatial(T.int64(1), n_0 + n_1 + n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(2), oc_chunk_0 + oc_chunk_1 + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(56), oh_0 * T.int64(2) + oh_1 * T.int64(2) + oh_2 + oh_3)
                        v_ow = T.axis.spatial(T.int64(56), ow_0 * T.int64(56) + ow_1 * T.int64(28) + ow_2 * T.int64(4) + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_0 * T.int64(32) + oc_block_1 * T.int64(32) + oc_block_2 * T.int64(16) + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(64), ic_0 * T.int64(4) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                        T.reads(data_pad[v_n, v_ic // T.int64(64), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(64)], p1[v_oc_chunk, v_ic // T.int64(64), v_kh, v_kw, v_ic % T.int64(64), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        with T.init():
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(64), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(64)] * p1[v_oc_chunk, v_ic // T.int64(64), v_kh, v_kw, v_ic % T.int64(64), v_oc_block]
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(2), T.int64(56), T.int64(56), T.int64(32)):
                with T.block("T_relu"):
                    v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                    T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 1, 1, 1])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[28, 1, 2, 1])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 2, 7, 4])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[1, 1, 2, 16])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[16, 4])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[3, 1])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=12)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
2024-04-29 03:20:00 [INFO] [task_scheduler.cc:170] Design space #1:
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(56), T.int64(56), T.int64(64)), "float32"), p1: T.Buffer((T.int64(2), T.int64(1), T.int64(3), T.int64(3), T.int64(64), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(32)), "float32"), p3: T.Buffer((T.int64(1), T.int64(2), T.int64(56), T.int64(56), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(2), T.int64(56), T.int64(56), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel": 768, "meta_schedule.unroll_explicit": 0, "meta_schedule.vectorize": 64})
            data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(58), T.int64(58), T.int64(64)))
            conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(56), T.int64(56), T.int64(32)))
            for n_0, oc_chunk_0, oh_0, ow_0, oc_block_0, n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(2), T.int64(28), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1)):
                for ic_0 in range(T.int64(16)):
                    for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(30), T.int64(4)):
                        with T.block("data_pad"):
                            v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                            v_i2 = T.axis.spatial(T.int64(58), oh_0 * T.int64(2) + ax2)
                            v_i3 = T.axis.spatial(T.int64(58), ow_1 * T.int64(28) + ax3)
                            v_i4 = T.axis.spatial(T.int64(64), ic_0 * T.int64(4) + ax4)
                            T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                            T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                            data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(57) and T.int64(1) <= v_i3 and v_i3 < T.int64(57), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                    for kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(2), T.int64(7), T.int64(2), T.int64(4), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(16)):
                        with T.block("conv2d_NCHWc"):
                            v_n = T.axis.spatial(T.int64(1), n_0 + n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(2), oc_chunk_0 + oc_chunk_1 + oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(56), oh_0 * T.int64(2) + oh_1 * T.int64(2) + oh_2 + oh_3)
                            v_ow = T.axis.spatial(T.int64(56), ow_0 * T.int64(56) + ow_1 * T.int64(28) + ow_2 * T.int64(4) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(32), oc_block_0 * T.int64(32) + oc_block_1 * T.int64(32) + oc_block_2 * T.int64(16) + oc_block_3)
                            v_ic = T.axis.reduce(T.int64(64), ic_0 * T.int64(4) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(data_pad[v_n, v_ic // T.int64(64), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(64)], p1[v_oc_chunk, v_ic // T.int64(64), v_kh, v_kw, v_ic % T.int64(64), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            with T.init():
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(64), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(64)] * p1[v_oc_chunk, v_ic // T.int64(64), v_kh, v_kw, v_ic % T.int64(64), v_oc_block]
                for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(2), T.int64(28), T.int64(32)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(2), oc_chunk_0 + ax1)
                        v_ax2 = T.axis.spatial(T.int64(56), oh_0 * T.int64(2) + ax2)
                        v_ax3 = T.axis.spatial(T.int64(56), ow_1 * T.int64(28) + ax3)
                        v_ax4 = T.axis.spatial(T.int64(32), ax4)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 1, 1, 1])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[28, 1, 2, 1])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 2, 7, 4])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[1, 1, 2, 16])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[16, 4])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[3, 1])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l50, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=10)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
2024-04-29 03:20:00 [INFO] [task_scheduler.cc:170] Design space #2:
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(56), T.int64(56), T.int64(64)), "float32"), p1: T.Buffer((T.int64(2), T.int64(1), T.int64(3), T.int64(3), T.int64(64), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(32)), "float32"), p3: T.Buffer((T.int64(1), T.int64(2), T.int64(56), T.int64(56), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(2), T.int64(56), T.int64(56), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel": 768, "meta_schedule.unroll_explicit": 0, "meta_schedule.vectorize": 64})
            data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(58), T.int64(58), T.int64(64)))
            conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(56), T.int64(56), T.int64(32)))
            for n_0, oc_chunk_0, oh_0 in T.grid(T.int64(1), T.int64(2), T.int64(28)):
                for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(58), T.int64(64)):
                    with T.block("data_pad"):
                        v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                        v_i2 = T.axis.spatial(T.int64(58), oh_0 * T.int64(2) + ax2)
                        v_i3, v_i4 = T.axis.remap("SS", [ax3, ax4])
                        T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                        T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                        data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(57) and T.int64(1) <= v_i3 and v_i3 < T.int64(57), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                for ow_0, oc_block_0 in T.grid(T.int64(1), T.int64(1)):
                    for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1, ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(16), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(2), T.int64(7), T.int64(2), T.int64(4), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(16)):
                        with T.block("conv2d_NCHWc"):
                            v_n = T.axis.spatial(T.int64(1), n_0 + n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(2), oc_chunk_0 + oc_chunk_1 + oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(56), oh_0 * T.int64(2) + oh_1 * T.int64(2) + oh_2 + oh_3)
                            v_ow = T.axis.spatial(T.int64(56), ow_0 * T.int64(56) + ow_1 * T.int64(28) + ow_2 * T.int64(4) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(32), oc_block_0 * T.int64(32) + oc_block_1 * T.int64(32) + oc_block_2 * T.int64(16) + oc_block_3)
                            v_ic = T.axis.reduce(T.int64(64), ic_0 * T.int64(4) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(data_pad[v_n, v_ic // T.int64(64), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(64)], p1[v_oc_chunk, v_ic // T.int64(64), v_kh, v_kw, v_ic % T.int64(64), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            with T.init():
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(64), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(64)] * p1[v_oc_chunk, v_ic // T.int64(64), v_kh, v_kw, v_ic % T.int64(64), v_oc_block]
                    for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(2), T.int64(56), T.int64(32)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(2), oc_chunk_0 + ax1)
                            v_ax2 = T.axis.spatial(T.int64(56), oh_0 * T.int64(2) + ax2)
                            v_ax3, v_ax4 = T.axis.remap("SS", [ax3, ax4])
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 1, 1, 1])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[28, 1, 2, 1])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 2, 7, 4])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[1, 1, 2, 16])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[16, 4])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[3, 1])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=2)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
2024-04-29 03:32:07 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 03:32:07 [INFO] [evolutionary_search.cc:715] Picked top 0 candidate(s) from database
2024-04-29 03:32:13 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x6d7cf18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3529928)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35fad28)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x42e62b8)]: 0 failure(s)
2024-04-29 03:32:13 [INFO] [evolutionary_search.cc:723] Sampled 512 candidate(s)
2024-04-29 03:32:19 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x6d7cf18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3529928)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35fad28)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x42e62b8)]: 0 failure(s)
2024-04-29 03:32:25 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x6d7cf18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3529928)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35fad28)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x42e62b8)]: 0 failure(s)
2024-04-29 03:32:32 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x6d7cf18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3529928)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35fad28)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x42e62b8)]: 0 failure(s)
2024-04-29 03:32:38 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x6d7cf18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3529928)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35fad28)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x42e62b8)]: 0 failure(s)
2024-04-29 03:32:39 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9997  0.9993  0.9992  0.9988  0.9979  0.9978  0.9976  0.9975  0.9969  0.9967  0.9966  0.9956  0.9956  0.9956  0.9955  0.9947
[17 : 32]:	0.9937  0.9921  0.9918  0.9912  0.9909  0.9908  0.9905  0.9889  0.9879  0.9878  0.9878  0.9875  0.9873  0.9872  0.9859  0.9859
[33 : 48]:	0.9857  0.9852  0.9847  0.9846  0.9839  0.9835  0.9830  0.9819  0.9811  0.9810  0.9808  0.9807  0.9798  0.9798  0.9794  0.9790
[49 : 64]:	0.9788  0.9786  0.9784  0.9784  0.9775  0.9754  0.9747  0.9738  0.9735  0.9728  0.9711  0.9705  0.9695  0.9693  0.9689  0.9687
2024-04-29 03:32:40 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 03:32:40 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 03:57:07 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #1: GFLOPs: 30.2315. Time: 7667.9224 us. Best GFLOPs: 30.2315
2024-04-29 03:57:07 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #2: GFLOPs: 1.1437. Time: 202687.5707 us. Best GFLOPs: 30.2315
2024-04-29 03:57:07 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #3: GFLOPs: 101.2324. Time: 2289.9100 us. Best GFLOPs: 101.2324
2024-04-29 03:57:07 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #4: GFLOPs: 63.1512. Time: 3670.7609 us. Best GFLOPs: 101.2324
2024-04-29 03:57:07 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #5: GFLOPs: 146.4524. Time: 1582.8559 us. Best GFLOPs: 146.4524
2024-04-29 03:57:07 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #6: GFLOPs: 76.8923. Time: 3014.7756 us. Best GFLOPs: 146.4524
2024-04-29 03:57:07 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #7: GFLOPs: 98.8768. Time: 2344.4632 us. Best GFLOPs: 146.4524
2024-04-29 03:57:07 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #8: GFLOPs: 60.0025. Time: 3863.3897 us. Best GFLOPs: 146.4524
2024-04-29 03:57:07 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #9: GFLOPs: 0.4732. Time: 489909.0453 us. Best GFLOPs: 146.4524
2024-04-29 03:57:07 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #10: GFLOPs: 35.4867. Time: 6532.3916 us. Best GFLOPs: 146.4524
2024-04-29 03:57:07 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #11: GFLOPs: 101.3623. Time: 2286.9767 us. Best GFLOPs: 146.4524
2024-04-29 03:57:07 [INFO] [task_scheduler.cc:121] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #12: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(56), T.int64(56), T.int64(64)), "float32"), p1: T.Buffer((T.int64(2), T.int64(1), T.int64(3), T.int64(3), T.int64(64), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(32)), "float32"), p3: T.Buffer((T.int64(1), T.int64(2), T.int64(56), T.int64(56), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(2), T.int64(56), T.int64(56), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(58), T.int64(58), T.int64(64)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(56), T.int64(56), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused in T.parallel(T.int64(56), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1, ow_1 in T.grid(T.int64(1), T.int64(1), T.int64(2), T.int64(2)):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(16)):
                    for ax4_fused in T.vectorized(T.int64(64)):
                        with T.block("data_pad"):
                            v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                            v_i2 = T.axis.spatial(T.int64(58), oh_1 * T.int64(2) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(4) * T.int64(4) + ax2)
                            v_i3 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(4) // T.int64(2) * T.int64(28) + ow_1 * T.int64(14) + ax3)
                            v_i4 = T.axis.spatial(T.int64(64), ax4_fused)
                            T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                            T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                            data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(57) and T.int64(1) <= v_i3 and v_i3 < T.int64(57), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                for oc_block_1 in range(T.int64(1)):
                    for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(14), T.int64(2), T.int64(1), T.int64(1), T.int64(2), T.int64(1)):
                        for oc_block_3_fused_init in T.vectorized(T.int64(8)):
                            with T.block("conv2d_NCHWc_init"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                                v_oc_chunk = T.axis.spatial(T.int64(2), oc_chunk_1 * T.int64(2) + oc_chunk_2_init + oc_chunk_3_init)
                                v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(4) * T.int64(4) + oh_1 * T.int64(2) + oh_2_init * T.int64(2) + oh_3_init)
                                v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(4) // T.int64(2) * T.int64(28) + ow_1 * T.int64(14) + ow_2_init + ow_3_init)
                                v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(2) * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2_init * T.int64(8) + oc_block_3_fused_init)
                                T.reads()
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                    for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(8), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(14), T.int64(2), T.int64(8), T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(2), T.int64(1)):
                        for oc_block_3_fused in T.vectorized(T.int64(8)):
                            with T.block("conv2d_NCHWc_update"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                                v_oc_chunk = T.axis.spatial(T.int64(2), oc_chunk_1 * T.int64(2) + oc_chunk_2 + oc_chunk_3)
                                v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(4) * T.int64(4) + oh_1 * T.int64(2) + oh_2 * T.int64(2) + oh_3)
                                v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(4) // T.int64(2) * T.int64(28) + ow_1 * T.int64(14) + ow_2 + ow_3)
                                v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(2) * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2 * T.int64(8) + oc_block_3_fused)
                                v_ic = T.axis.reduce(T.int64(64), ic_0 * T.int64(8) + ic_1)
                                v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                                v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                                T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(64), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(64)], p1[v_oc_chunk, v_ic // T.int64(64), v_kh, v_kw, v_ic % T.int64(64), v_oc_block])
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(64), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(64)] * p1[v_oc_chunk, v_ic // T.int64(64), v_kh, v_kw, v_ic % T.int64(64), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(2), T.int64(4), T.int64(28)):
                for ax4_fused in T.vectorized(T.int64(16)):
                    with T.block("T_relu"):
                        v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                        v_ax2 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(4) * T.int64(4) + ax2)
                        v_ax3 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(4) // T.int64(2) * T.int64(28) + ax3)
                        v_ax4 = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(2) * T.int64(16) + ax4_fused)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 2, 1])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[14, 2, 1, 2])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[2, 2, 14, 1])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[2, 1, 2, 8])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[8, 8])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[1, 3])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=8)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85 = sch.get_loops(block=b69)
l86 = sch.fuse(l72, l73, l74, l75, l76, preserve_unit_iters=True)
sch.parallel(loop=l86)
l87 = sch.fuse(l85, preserve_unit_iters=True)
sch.vectorize(loop=l87)
l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107, l108, l109 = sch.get_loops(block=b70)
l110 = sch.fuse(l88, preserve_unit_iters=True)
sch.parallel(loop=l110)
l111 = sch.fuse(l109, preserve_unit_iters=True)
sch.vectorize(loop=l111)
sch.annotate(block_or_loop=l110, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l110, ann_key="pragma_unroll_explicit", ann_val=1)
l112, l113, l114, l115, l116, l117 = sch.get_loops(block=b71)
l118 = sch.fuse(l117, preserve_unit_iters=True)
sch.vectorize(loop=l118)
b119 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141 = sch.get_loops(block=b119)
b142 = sch.decompose_reduction(block=b119, loop=l126)
2024-04-29 03:57:07 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #13: GFLOPs: 29.6435. Time: 7820.0242 us. Best GFLOPs: 146.4524
2024-04-29 03:57:07 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #14: GFLOPs: 54.2705. Time: 4271.4352 us. Best GFLOPs: 146.4524
2024-04-29 03:57:07 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #15: GFLOPs: 156.4529. Time: 1481.6803 us. Best GFLOPs: 156.4529
2024-04-29 03:57:07 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #16: GFLOPs: 2.6265. Time: 88259.1223 us. Best GFLOPs: 156.4529
2024-04-29 03:57:07 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #17: GFLOPs: 14.2388. Time: 16280.3929 us. Best GFLOPs: 156.4529
2024-04-29 03:57:07 [INFO] [task_scheduler.cc:121] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #18: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(56), T.int64(56), T.int64(64)), "float32"), p1: T.Buffer((T.int64(2), T.int64(1), T.int64(3), T.int64(3), T.int64(64), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(32)), "float32"), p3: T.Buffer((T.int64(1), T.int64(2), T.int64(56), T.int64(56), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(2), T.int64(56), T.int64(56), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(56), T.int64(56), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused in T.parallel(T.int64(896), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(14), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(2), T.int64(2), T.int64(2), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(2), oc_chunk_1 * T.int64(2) + oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused // T.int64(448) * T.int64(28) + oh_1 * T.int64(2) + oh_2_init + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused % T.int64(448) // T.int64(16) * T.int64(2) + ow_1 * T.int64(2) + ow_2_init + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused % T.int64(16) * T.int64(2) + oc_block_1 * T.int64(2) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(8), T.int64(3), T.int64(3), T.int64(1), T.int64(2), T.int64(2), T.int64(2), T.int64(2), T.int64(8), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(2), oc_chunk_1 * T.int64(2) + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused // T.int64(448) * T.int64(28) + oh_1 * T.int64(2) + oh_2 + oh_3)
                        v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused % T.int64(448) // T.int64(16) * T.int64(2) + ow_1 * T.int64(2) + ow_2 + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused % T.int64(16) * T.int64(2) + oc_block_1 * T.int64(2) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(64), ic_0 * T.int64(8) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], p0[v_n, v_ic // T.int64(64), v_oh + v_kh - T.int64(1), v_ow + v_kw - T.int64(1), v_ic % T.int64(64)], p1[v_oc_chunk, v_ic // T.int64(64), v_kh, v_kw, v_ic % T.int64(64), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + T.if_then_else(T.int64(1) <= v_oh + v_kh and v_oh + v_kh < T.int64(57) and T.int64(1) <= v_ow + v_kw and v_ow + v_kw < T.int64(57), p0[v_n, v_ic // T.int64(64), v_oh + v_kh - T.int64(1), v_ow + v_kw - T.int64(1), v_ic % T.int64(64)], T.float32(0)) * p1[v_oc_chunk, v_ic // T.int64(64), v_kh, v_kw, v_ic % T.int64(64), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(2), T.int64(28), T.int64(2)):
                for ax4_fused in T.vectorized(T.int64(2)):
                    with T.block("T_relu"):
                        v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                        v_ax2 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused // T.int64(448) * T.int64(28) + ax2)
                        v_ax3 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused % T.int64(448) // T.int64(16) * T.int64(2) + ax3)
                        v_ax4 = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused % T.int64(16) * T.int64(2) + ax4_fused)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 2, 1])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[2, 14, 2, 1])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[28, 1, 2, 1])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[16, 1, 2, 1])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[8, 8])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[3, 1])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=-2)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70 = sch.get_child_blocks(b68)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96 = sch.get_loops(block=b69)
l97 = sch.fuse(l71, l72, l73, l74, l75, preserve_unit_iters=True)
sch.parallel(loop=l97)
sch.annotate(block_or_loop=l97, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l97, ann_key="pragma_unroll_explicit", ann_val=1)
l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b70)
l104 = sch.fuse(l103, preserve_unit_iters=True)
sch.vectorize(loop=l104)
b105 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l106, l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127 = sch.get_loops(block=b105)
b128 = sch.decompose_reduction(block=b105, loop=l112)
2024-04-29 03:57:07 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #19: GFLOPs: 142.3060. Time: 1628.9767 us. Best GFLOPs: 156.4529
2024-04-29 03:57:07 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #20: GFLOPs: 1.9132. Time: 121165.4633 us. Best GFLOPs: 156.4529
2024-04-29 03:57:07 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #21: GFLOPs: 132.6762. Time: 1747.2089 us. Best GFLOPs: 156.4529
2024-04-29 03:57:07 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #22: GFLOPs: 40.6560. Time: 5701.8228 us. Best GFLOPs: 156.4529
2024-04-29 03:57:07 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #23: GFLOPs: 19.7974. Time: 11709.2772 us. Best GFLOPs: 156.4529
2024-04-29 03:57:07 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #24: GFLOPs: 9.6237. Time: 24087.7006 us. Best GFLOPs: 156.4529
2024-04-29 03:57:07 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #25: GFLOPs: 5.1799. Time: 44752.2020 us. Best GFLOPs: 156.4529
2024-04-29 03:57:07 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #26: GFLOPs: 62.7900. Time: 3691.8815 us. Best GFLOPs: 156.4529
2024-04-29 03:57:07 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #27: GFLOPs: 88.0683. Time: 2632.1983 us. Best GFLOPs: 156.4529
2024-04-29 03:57:07 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #28: GFLOPs: 6.8307. Time: 33937.0490 us. Best GFLOPs: 156.4529
2024-04-29 03:57:07 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #29: GFLOPs: 8.7012. Time: 26641.4977 us. Best GFLOPs: 156.4529
2024-04-29 03:57:07 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #30: GFLOPs: 33.1356. Time: 6995.8895 us. Best GFLOPs: 156.4529
2024-04-29 03:57:07 [INFO] [task_scheduler.cc:121] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #31: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(56), T.int64(56), T.int64(64)), "float32"), p1: T.Buffer((T.int64(2), T.int64(1), T.int64(3), T.int64(3), T.int64(64), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(32)), "float32"), p3: T.Buffer((T.int64(1), T.int64(2), T.int64(56), T.int64(56), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(2), T.int64(56), T.int64(56), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(56), T.int64(56), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused in T.parallel(T.int64(112), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4), T.int64(2)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(7)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(2), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused // T.int64(56) + oc_chunk_1 + oc_chunk_2_init + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused % T.int64(56) // T.int64(8) * T.int64(8) + oh_1 * T.int64(2) + oh_2_init * T.int64(2) + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused % T.int64(8) // T.int64(4) * T.int64(28) + ow_1 * T.int64(7) + ow_2_init * T.int64(7) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused % T.int64(4) * T.int64(8) + oc_block_1 * T.int64(4) + oc_block_2_init * T.int64(4) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(32), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(2), T.int64(7)):
                    for oc_block_3_fused in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(2), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused // T.int64(56) + oc_chunk_1 + oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused % T.int64(56) // T.int64(8) * T.int64(8) + oh_1 * T.int64(2) + oh_2 * T.int64(2) + oh_3)
                            v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused % T.int64(8) // T.int64(4) * T.int64(28) + ow_1 * T.int64(7) + ow_2 * T.int64(7) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused % T.int64(4) * T.int64(8) + oc_block_1 * T.int64(4) + oc_block_2 * T.int64(4) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(64), ic_0 * T.int64(2) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], p0[v_n, v_ic // T.int64(64), v_oh + v_kh - T.int64(1), v_ow + v_kw - T.int64(1), v_ic % T.int64(64)], p1[v_oc_chunk, v_ic // T.int64(64), v_kh, v_kw, v_ic % T.int64(64), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + T.if_then_else(T.int64(1) <= v_oh + v_kh and v_oh + v_kh < T.int64(57) and T.int64(1) <= v_ow + v_kw and v_ow + v_kw < T.int64(57), p0[v_n, v_ic // T.int64(64), v_oh + v_kh - T.int64(1), v_ow + v_kw - T.int64(1), v_ic % T.int64(64)], T.float32(0)) * p1[v_oc_chunk, v_ic // T.int64(64), v_kh, v_kw, v_ic % T.int64(64), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(8), T.int64(28)):
                for ax4_fused in T.vectorized(T.int64(8)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(2), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused // T.int64(56) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused % T.int64(56) // T.int64(8) * T.int64(8) + ax2)
                        v_ax3 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused % T.int64(8) // T.int64(4) * T.int64(28) + ax3)
                        v_ax4 = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused % T.int64(4) * T.int64(8) + ax4_fused)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 1, 1, 1])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[7, 4, 1, 2])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[2, 4, 1, 7])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[4, 2, 1, 4])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[32, 2])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[1, 3])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=-2)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70 = sch.get_child_blocks(b68)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96 = sch.get_loops(block=b69)
l97 = sch.fuse(l71, l72, l73, l74, l75, preserve_unit_iters=True)
sch.parallel(loop=l97)
l98 = sch.fuse(l96, preserve_unit_iters=True)
sch.vectorize(loop=l98)
sch.annotate(block_or_loop=l97, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l97, ann_key="pragma_unroll_explicit", ann_val=1)
l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b70)
l105 = sch.fuse(l104, preserve_unit_iters=True)
sch.vectorize(loop=l105)
b106 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128 = sch.get_loops(block=b106)
b129 = sch.decompose_reduction(block=b106, loop=l113)
2024-04-29 03:57:07 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #32: GFLOPs: 2.2398. Time: 103498.1133 us. Best GFLOPs: 156.4529
2024-04-29 03:57:07 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #33: GFLOPs: 89.7176. Time: 2583.8094 us. Best GFLOPs: 156.4529
2024-04-29 03:57:07 [INFO] [task_scheduler.cc:121] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #34: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(56), T.int64(56), T.int64(64)), "float32"), p1: T.Buffer((T.int64(2), T.int64(1), T.int64(3), T.int64(3), T.int64(64), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(32)), "float32"), p3: T.Buffer((T.int64(1), T.int64(2), T.int64(56), T.int64(56), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(2), T.int64(56), T.int64(56), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(58), T.int64(58), T.int64(64)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(56), T.int64(56), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused in T.parallel(T.int64(7), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1, ow_1 in T.grid(T.int64(1), T.int64(2), T.int64(2), T.int64(2)):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(6), T.int64(30)):
                    for ax4_fused in T.vectorized(T.int64(64)):
                        with T.block("data_pad"):
                            v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                            v_i2 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused * T.int64(8) + oh_1 * T.int64(4) + ax2)
                            v_i3 = T.axis.spatial(T.int64(58), ow_1 * T.int64(28) + ax3)
                            v_i4 = T.axis.spatial(T.int64(64), ax4_fused)
                            T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                            T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                            data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(57) and T.int64(1) <= v_i3 and v_i3 < T.int64(57), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                for oc_block_1 in range(T.int64(1)):
                    for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(1), T.int64(2), T.int64(7), T.int64(8), T.int64(1), T.int64(1), T.int64(2), T.int64(4)):
                        for oc_block_3_fused_init in T.vectorized(T.int64(4)):
                            with T.block("conv2d_NCHWc_init"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                                v_oc_chunk = T.axis.spatial(T.int64(2), oc_chunk_1 + oc_chunk_2_init + oc_chunk_3_init)
                                v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused * T.int64(8) + oh_1 * T.int64(4) + oh_2_init * T.int64(2) + oh_3_init)
                                v_ow = T.axis.spatial(T.int64(56), ow_1 * T.int64(28) + ow_2_init * T.int64(4) + ow_3_init)
                                v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2_init * T.int64(4) + oc_block_3_fused_init)
                                T.reads()
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                    for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(64), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(7), T.int64(8), T.int64(1), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(2), T.int64(4)):
                        for oc_block_3_fused in T.vectorized(T.int64(4)):
                            with T.block("conv2d_NCHWc_update"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                                v_oc_chunk = T.axis.spatial(T.int64(2), oc_chunk_1 + oc_chunk_2 + oc_chunk_3)
                                v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused * T.int64(8) + oh_1 * T.int64(4) + oh_2 * T.int64(2) + oh_3)
                                v_ow = T.axis.spatial(T.int64(56), ow_1 * T.int64(28) + ow_2 * T.int64(4) + ow_3)
                                v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2 * T.int64(4) + oc_block_3_fused)
                                v_ic = T.axis.reduce(T.int64(64), ic_0 + ic_1)
                                v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                                v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                                T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(64), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(64)], p1[v_oc_chunk, v_ic // T.int64(64), v_kh, v_kw, v_ic % T.int64(64), v_oc_block])
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(64), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(64)] * p1[v_oc_chunk, v_ic // T.int64(64), v_kh, v_kw, v_ic % T.int64(64), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(2), T.int64(8), T.int64(56)):
                for ax4_fused in T.vectorized(T.int64(32)):
                    with T.block("T_relu"):
                        v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                        v_ax2 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused * T.int64(8) + ax2)
                        v_ax3, v_ax4 = T.axis.remap("SS", [ax3, ax4_fused])
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 2, 1, 1])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[7, 2, 2, 2])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 2, 7, 4])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[1, 1, 8, 4])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[64, 1])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[1, 3])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=8)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85 = sch.get_loops(block=b69)
l86 = sch.fuse(l72, l73, l74, l75, l76, preserve_unit_iters=True)
sch.parallel(loop=l86)
l87 = sch.fuse(l85, preserve_unit_iters=True)
sch.vectorize(loop=l87)
l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107, l108, l109 = sch.get_loops(block=b70)
l110 = sch.fuse(l88, preserve_unit_iters=True)
sch.parallel(loop=l110)
l111 = sch.fuse(l109, preserve_unit_iters=True)
sch.vectorize(loop=l111)
sch.annotate(block_or_loop=l110, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l110, ann_key="pragma_unroll_explicit", ann_val=1)
l112, l113, l114, l115, l116, l117 = sch.get_loops(block=b71)
l118 = sch.fuse(l117, preserve_unit_iters=True)
sch.vectorize(loop=l118)
b119 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141 = sch.get_loops(block=b119)
b142 = sch.decompose_reduction(block=b119, loop=l126)
2024-04-29 03:57:07 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #35: GFLOPs: 82.7603. Time: 2801.0183 us. Best GFLOPs: 156.4529
2024-04-29 03:57:07 [INFO] [task_scheduler.cc:121] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #36: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(56), T.int64(56), T.int64(64)), "float32"), p1: T.Buffer((T.int64(2), T.int64(1), T.int64(3), T.int64(3), T.int64(64), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(32)), "float32"), p3: T.Buffer((T.int64(1), T.int64(2), T.int64(56), T.int64(56), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(2), T.int64(56), T.int64(56), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(58), T.int64(58), T.int64(64)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(56), T.int64(56), T.int64(32)))
        for n_0 in T.serial(T.int64(1), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for oc_chunk_0, oh_0, ow_0, oc_block_0 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                for n_1, oc_chunk_1, oh_1 in T.grid(T.int64(1), T.int64(1), T.int64(14)):
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(6), T.int64(58)):
                        for ax4_fused in T.vectorized(T.int64(64)):
                            with T.block("data_pad"):
                                v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                                v_i2 = T.axis.spatial(T.int64(58), oh_1 * T.int64(4) + ax2)
                                v_i3, v_i4 = T.axis.remap("SS", [ax3, ax4_fused])
                                T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                                T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                                data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(57) and T.int64(1) <= v_i3 and v_i3 < T.int64(57), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                    for ow_1, oc_block_1 in T.grid(T.int64(2), T.int64(16)):
                        for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(2), T.int64(4), T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                            for oc_block_3_fused_init in T.vectorized(T.int64(2)):
                                with T.block("conv2d_NCHWc_init"):
                                    v_n = T.axis.spatial(T.int64(1), n_0 + n_1 + n_2_init + n_3_init)
                                    v_oc_chunk = T.axis.spatial(T.int64(2), oc_chunk_0 * T.int64(2) + oc_chunk_1 * T.int64(2) + oc_chunk_2_init + oc_chunk_3_init)
                                    v_oh = T.axis.spatial(T.int64(56), oh_0 * T.int64(56) + oh_1 * T.int64(4) + oh_2_init + oh_3_init)
                                    v_ow = T.axis.spatial(T.int64(56), ow_0 * T.int64(56) + ow_1 * T.int64(28) + ow_2_init * T.int64(7) + ow_3_init)
                                    v_oc_block = T.axis.spatial(T.int64(32), oc_block_0 * T.int64(32) + oc_block_1 * T.int64(2) + oc_block_2_init * T.int64(2) + oc_block_3_fused_init)
                                    T.reads()
                                    T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                    T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                    conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                        for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(4), T.int64(3), T.int64(1), T.int64(1), T.int64(2), T.int64(4), T.int64(4), T.int64(1), T.int64(16), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                            for oc_block_3_fused in T.vectorized(T.int64(2)):
                                with T.block("conv2d_NCHWc_update"):
                                    v_n = T.axis.spatial(T.int64(1), n_0 + n_1 + n_2 + n_3)
                                    v_oc_chunk = T.axis.spatial(T.int64(2), oc_chunk_0 * T.int64(2) + oc_chunk_1 * T.int64(2) + oc_chunk_2 + oc_chunk_3)
                                    v_oh = T.axis.spatial(T.int64(56), oh_0 * T.int64(56) + oh_1 * T.int64(4) + oh_2 + oh_3)
                                    v_ow = T.axis.spatial(T.int64(56), ow_0 * T.int64(56) + ow_1 * T.int64(28) + ow_2 * T.int64(7) + ow_3)
                                    v_oc_block = T.axis.spatial(T.int64(32), oc_block_0 * T.int64(32) + oc_block_1 * T.int64(2) + oc_block_2 * T.int64(2) + oc_block_3_fused)
                                    v_ic = T.axis.reduce(T.int64(64), ic_0 * T.int64(16) + ic_1)
                                    v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                                    v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                                    T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(64), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(64)], p1[v_oc_chunk, v_ic // T.int64(64), v_kh, v_kw, v_ic % T.int64(64), v_oc_block])
                                    T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                    T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                    conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(64), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(64)] * p1[v_oc_chunk, v_ic // T.int64(64), v_kh, v_kw, v_ic % T.int64(64), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(2), T.int64(56), T.int64(56)):
                    for ax4_fused in T.vectorized(T.int64(32)):
                        with T.block("T_relu"):
                            v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4_fused])
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 2, 1])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 14, 4, 1])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 2, 4, 7])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[1, 16, 1, 2])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[4, 16])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[1, 3])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=7)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b69)
l85 = sch.fuse(l84, preserve_unit_iters=True)
sch.vectorize(loop=l85)
l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107, l108, l109, l110, l111 = sch.get_loops(block=b70)
l112 = sch.fuse(l111, preserve_unit_iters=True)
sch.vectorize(loop=l112)
sch.annotate(block_or_loop=l86, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l86, ann_key="pragma_unroll_explicit", ann_val=1)
l113, l114, l115, l116, l117, l118, l119, l120, l121, l122 = sch.get_loops(block=b71)
l123 = sch.fuse(l122, preserve_unit_iters=True)
sch.vectorize(loop=l123)
b124 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141, l142, l143, l144, l145, l146, l147, l148, l149, l150 = sch.get_loops(block=b124)
b151 = sch.decompose_reduction(block=b124, loop=l135)
2024-04-29 03:57:07 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #37: GFLOPs: 34.3261. Time: 6753.2559 us. Best GFLOPs: 156.4529
2024-04-29 03:57:07 [INFO] [task_scheduler.cc:121] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #38: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(56), T.int64(56), T.int64(64)), "float32"), p1: T.Buffer((T.int64(2), T.int64(1), T.int64(3), T.int64(3), T.int64(64), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(32)), "float32"), p3: T.Buffer((T.int64(1), T.int64(2), T.int64(56), T.int64(56), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(2), T.int64(56), T.int64(56), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(58), T.int64(58), T.int64(64)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(56), T.int64(56), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused in T.parallel(T.int64(8), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(58), T.int64(58)):
                for ax4_fused in T.vectorized(T.int64(64)):
                    with T.block("data_pad"):
                        v_i0, v_i1, v_i2, v_i3, v_i4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4_fused])
                        T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                        T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                        data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(57) and T.int64(1) <= v_i3 and v_i3 < T.int64(57), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(2), T.int64(8), T.int64(4), T.int64(2)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(7), T.int64(7), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(2), oc_chunk_1 + oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(56), oh_1 * T.int64(7) + oh_2_init + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(56), ow_1 * T.int64(14) + ow_2_init * T.int64(2) + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused * T.int64(4) + oc_block_1 * T.int64(2) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(32), T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(7), T.int64(7), T.int64(2), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(2), oc_chunk_1 + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(56), oh_1 * T.int64(7) + oh_2 + oh_3)
                        v_ow = T.axis.spatial(T.int64(56), ow_1 * T.int64(14) + ow_2 * T.int64(2) + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused * T.int64(4) + oc_block_1 * T.int64(2) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(64), ic_0 * T.int64(2) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(64), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(64)], p1[v_oc_chunk, v_ic // T.int64(64), v_kh, v_kw, v_ic % T.int64(64), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(64), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(64)] * p1[v_oc_chunk, v_ic // T.int64(64), v_kh, v_kw, v_ic % T.int64(64), v_oc_block]
        for ax0_ax1_ax2_ax3_ax4_fused_0 in T.parallel(T.int64(3136)):
            for ax0_ax1_ax2_ax3_ax4_fused_1 in T.vectorized(T.int64(64)):
                with T.block("T_relu"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(2), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) // T.int64(100352))
                    v_ax2 = T.axis.spatial(T.int64(56), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(100352) // T.int64(1792))
                    v_ax3 = T.axis.spatial(T.int64(56), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(1792) // T.int64(32))
                    v_ax4 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(32))
                    T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 2, 1, 1])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 8, 7, 1])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 4, 7, 2])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[8, 2, 2, 1])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[32, 2])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[3, 1])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=4)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80 = sch.get_loops(block=b68)
l81 = sch.fuse(l71, l72, l73, l74, l75, preserve_unit_iters=True)
sch.parallel(loop=l81)
l82 = sch.fuse(l80, preserve_unit_iters=True)
sch.vectorize(loop=l82)
l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b69)
l105 = sch.fuse(l83, preserve_unit_iters=True)
sch.parallel(loop=l105)
sch.annotate(block_or_loop=l105, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l105, ann_key="pragma_unroll_explicit", ann_val=1)
l106, l107, l108, l109, l110 = sch.get_loops(block=b70)
l111 = sch.fuse(l106, l107, l108, l109, l110, preserve_unit_iters=True)
l112, l113 = sch.split(loop=l111, factors=[None, 64], preserve_unit_iters=True)
sch.parallel(loop=l112)
sch.vectorize(loop=l113)
b114 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136 = sch.get_loops(block=b114)
b137 = sch.decompose_reduction(block=b114, loop=l121)
2024-04-29 03:57:07 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #39: GFLOPs: 8.9833. Time: 25804.9878 us. Best GFLOPs: 156.4529
2024-04-29 03:57:07 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #40: GFLOPs: 101.3665. Time: 2286.8810 us. Best GFLOPs: 156.4529
2024-04-29 03:57:07 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #41: GFLOPs: 101.4401. Time: 2285.2209 us. Best GFLOPs: 156.4529
2024-04-29 03:57:07 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #42: GFLOPs: 160.4977. Time: 1444.3395 us. Best GFLOPs: 160.4977
2024-04-29 03:57:07 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #43: GFLOPs: 30.3291. Time: 7643.2606 us. Best GFLOPs: 160.4977
2024-04-29 03:57:07 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #44: GFLOPs: 98.5116. Time: 2353.1548 us. Best GFLOPs: 160.4977
2024-04-29 03:57:07 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #45: GFLOPs: 155.0524. Time: 1495.0634 us. Best GFLOPs: 160.4977
2024-04-29 03:57:07 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #46: GFLOPs: 33.9891. Time: 6820.2251 us. Best GFLOPs: 160.4977
2024-04-29 03:57:07 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #47: GFLOPs: 3.2550. Time: 71217.4933 us. Best GFLOPs: 160.4977
2024-04-29 03:57:07 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #48: GFLOPs: 75.3284. Time: 3077.3667 us. Best GFLOPs: 160.4977
2024-04-29 03:57:07 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #49: GFLOPs: 22.4794. Time: 10312.2290 us. Best GFLOPs: 160.4977
2024-04-29 03:57:07 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #50: GFLOPs: 24.1916. Time: 9582.3709 us. Best GFLOPs: 160.4977
2024-04-29 03:57:07 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #51: GFLOPs: 2.7336. Time: 84802.2050 us. Best GFLOPs: 160.4977
2024-04-29 03:57:07 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #52: GFLOPs: 114.7007. Time: 2021.0269 us. Best GFLOPs: 160.4977
2024-04-29 03:57:07 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #53: GFLOPs: 119.7805. Time: 1935.3159 us. Best GFLOPs: 160.4977
2024-04-29 03:57:07 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #54: GFLOPs: 44.5268. Time: 5206.1439 us. Best GFLOPs: 160.4977
2024-04-29 03:57:07 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #55: GFLOPs: 21.4134. Time: 10825.6190 us. Best GFLOPs: 160.4977
2024-04-29 03:57:07 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #56: GFLOPs: 22.9361. Time: 10106.9128 us. Best GFLOPs: 160.4977
2024-04-29 03:57:07 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #57: GFLOPs: 0.6626. Time: 349849.5640 us. Best GFLOPs: 160.4977
2024-04-29 03:57:07 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #58: GFLOPs: 21.6475. Time: 10708.5463 us. Best GFLOPs: 160.4977
2024-04-29 03:57:07 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #59: GFLOPs: 297.3346. Time: 779.6373 us. Best GFLOPs: 297.3346
2024-04-29 03:57:07 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #60: GFLOPs: 65.9853. Time: 3513.1046 us. Best GFLOPs: 297.3346
2024-04-29 03:57:07 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #61: GFLOPs: 42.7007. Time: 5428.7860 us. Best GFLOPs: 297.3346
2024-04-29 03:57:07 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #62: GFLOPs: 62.3009. Time: 3720.8629 us. Best GFLOPs: 297.3346
2024-04-29 03:57:07 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #63: GFLOPs: 9.5604. Time: 24247.2326 us. Best GFLOPs: 297.3346
2024-04-29 03:57:07 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #64: GFLOPs: 131.3470. Time: 1764.8910 us. Best GFLOPs: 297.3346
2024-04-29 04:15:15 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 04:15:16 [INFO] [evolutionary_search.cc:715] Picked top 58 candidate(s) from database
2024-04-29 04:15:21 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x6d7cf18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3529928)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35fad28)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x42e62b8)]: 0 failure(s)
2024-04-29 04:15:21 [INFO] [evolutionary_search.cc:723] Sampled 454 candidate(s)
2024-04-29 04:15:34 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x6d7cf18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3529928)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35fad28)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x42e62b8)]: 0 failure(s)
2024-04-29 04:15:51 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x6d7cf18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3529928)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35fad28)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x42e62b8)]: 0 failure(s)
2024-04-29 04:16:04 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x6d7cf18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3529928)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35fad28)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x42e62b8)]: 0 failure(s)
2024-04-29 04:16:18 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x6d7cf18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3529928)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35fad28)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x42e62b8)]: 0 failure(s)
2024-04-29 04:16:26 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9880  0.9880  0.9854  0.9854  0.9854  0.9854  0.9854  0.9854  0.9854  0.9854  0.9672  0.9672  0.9459  0.9459  0.9459  0.9374
[17 : 32]:	0.9374  0.9374  0.9349  0.9135  0.9135  0.8926  0.8842  0.8687  0.8687  0.8564  0.8518  0.8492  0.8492  0.8492  0.8492  0.8379
[33 : 48]:	0.8337  0.8227  0.8173  0.8173  0.8144  0.7977  0.7892  0.7829  0.7798  0.7708  0.7641  0.7627  0.7584  0.7421  0.7421  0.7362
[49 : 64]:	0.7247  0.7243  0.7172  0.7096  0.7043  0.6939  0.6856  0.6830  0.6828  0.6815  0.6565  0.6547  0.6470  0.6470  0.6439  0.6439
2024-04-29 04:16:26 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 04:16:26 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 04:17:47 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #65: GFLOPs: 236.2120. Time: 981.3773 us. Best GFLOPs: 297.3346
2024-04-29 04:17:47 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #66: GFLOPs: 110.2400. Time: 2102.8035 us. Best GFLOPs: 297.3346
2024-04-29 04:17:47 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #67: GFLOPs: 147.3748. Time: 1572.9497 us. Best GFLOPs: 297.3346
2024-04-29 04:17:47 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #68: GFLOPs: 161.2473. Time: 1437.6245 us. Best GFLOPs: 297.3346
2024-04-29 04:17:47 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #69: GFLOPs: 133.2644. Time: 1739.4984 us. Best GFLOPs: 297.3346
2024-04-29 04:17:47 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #70: GFLOPs: 56.3383. Time: 4114.6596 us. Best GFLOPs: 297.3346
2024-04-29 04:17:47 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #71: GFLOPs: 99.8428. Time: 2321.7810 us. Best GFLOPs: 297.3346
2024-04-29 04:17:47 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #72: GFLOPs: 111.1752. Time: 2085.1152 us. Best GFLOPs: 297.3346
2024-04-29 04:17:47 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #73: GFLOPs: 145.2451. Time: 1596.0135 us. Best GFLOPs: 297.3346
2024-04-29 04:17:47 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #74: GFLOPs: 67.8863. Time: 3414.7261 us. Best GFLOPs: 297.3346
2024-04-29 04:17:47 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #75: GFLOPs: 173.4542. Time: 1336.4517 us. Best GFLOPs: 297.3346
2024-04-29 04:17:47 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #76: GFLOPs: 201.2388. Time: 1151.9307 us. Best GFLOPs: 297.3346
2024-04-29 04:17:47 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #77: GFLOPs: 113.4714. Time: 2042.9210 us. Best GFLOPs: 297.3346
2024-04-29 04:17:47 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #78: GFLOPs: 70.0941. Time: 3307.1698 us. Best GFLOPs: 297.3346
2024-04-29 04:17:47 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #79: GFLOPs: 59.4777. Time: 3897.4820 us. Best GFLOPs: 297.3346
2024-04-29 04:17:47 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #80: GFLOPs: 117.9770. Time: 1964.9003 us. Best GFLOPs: 297.3346
2024-04-29 04:17:47 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #81: GFLOPs: 124.8619. Time: 1856.5566 us. Best GFLOPs: 297.3346
2024-04-29 04:17:47 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #82: GFLOPs: 46.2033. Time: 5017.2433 us. Best GFLOPs: 297.3346
2024-04-29 04:17:47 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #83: GFLOPs: 142.7560. Time: 1623.8410 us. Best GFLOPs: 297.3346
2024-04-29 04:17:47 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #84: GFLOPs: 156.7686. Time: 1478.6963 us. Best GFLOPs: 297.3346
2024-04-29 04:17:47 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #85: GFLOPs: 91.3845. Time: 2536.6774 us. Best GFLOPs: 297.3346
2024-04-29 04:17:47 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #86: GFLOPs: 60.7789. Time: 3814.0382 us. Best GFLOPs: 297.3346
2024-04-29 04:17:47 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #87: GFLOPs: 69.7437. Time: 3323.7862 us. Best GFLOPs: 297.3346
2024-04-29 04:17:47 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #88: GFLOPs: 116.0677. Time: 1997.2235 us. Best GFLOPs: 297.3346
2024-04-29 04:17:47 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #89: GFLOPs: 85.9117. Time: 2698.2709 us. Best GFLOPs: 297.3346
2024-04-29 04:17:47 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #90: GFLOPs: 197.2229. Time: 1175.3866 us. Best GFLOPs: 297.3346
2024-04-29 04:17:47 [INFO] [task_scheduler.cc:121] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #91: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(56), T.int64(56), T.int64(64)), "float32"), p1: T.Buffer((T.int64(2), T.int64(1), T.int64(3), T.int64(3), T.int64(64), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(32)), "float32"), p3: T.Buffer((T.int64(1), T.int64(2), T.int64(56), T.int64(56), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(2), T.int64(56), T.int64(56), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(58), T.int64(58), T.int64(64)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(56), T.int64(56), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused in T.parallel(T.int64(56), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1 in T.grid(T.int64(1), T.int64(1), T.int64(2)):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(6), T.int64(16)):
                    for ax4_fused in T.vectorized(T.int64(64)):
                        with T.block("data_pad"):
                            v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                            v_i2 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(8) * T.int64(8) + oh_1 * T.int64(4) + ax2)
                            v_i3 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(8) // T.int64(2) * T.int64(14) + ax3)
                            v_i4 = T.axis.spatial(T.int64(64), ax4_fused)
                            T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                            T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                            data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(57) and T.int64(1) <= v_i3 and v_i3 < T.int64(57), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                for ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1)):
                    for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(1), T.int64(2), T.int64(14), T.int64(4), T.int64(1), T.int64(2), T.int64(2), T.int64(1)):
                        for oc_block_3_fused_init in T.vectorized(T.int64(4)):
                            with T.block("conv2d_NCHWc_init"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                                v_oc_chunk = T.axis.spatial(T.int64(2), oc_chunk_1 * T.int64(2) + oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                                v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(8) * T.int64(8) + oh_1 * T.int64(4) + oh_2_init * T.int64(2) + oh_3_init)
                                v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(8) // T.int64(2) * T.int64(14) + ow_1 * T.int64(14) + ow_2_init + ow_3_init)
                                v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(2) * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2_init * T.int64(4) + oc_block_3_fused_init)
                                T.reads()
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                    for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(2), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(2), T.int64(14), T.int64(4), T.int64(32), T.int64(3), T.int64(1), T.int64(1), T.int64(2), T.int64(2), T.int64(1)):
                        for oc_block_3_fused in T.vectorized(T.int64(4)):
                            with T.block("conv2d_NCHWc_update"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                                v_oc_chunk = T.axis.spatial(T.int64(2), oc_chunk_1 * T.int64(2) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                                v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(8) * T.int64(8) + oh_1 * T.int64(4) + oh_2 * T.int64(2) + oh_3)
                                v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(8) // T.int64(2) * T.int64(14) + ow_1 * T.int64(14) + ow_2 + ow_3)
                                v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(2) * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2 * T.int64(4) + oc_block_3_fused)
                                v_ic = T.axis.reduce(T.int64(64), ic_0 * T.int64(32) + ic_1)
                                v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                                v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                                T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(64), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(64)], p1[v_oc_chunk, v_ic // T.int64(64), v_kh, v_kw, v_ic % T.int64(64), v_oc_block])
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(64), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(64)] * p1[v_oc_chunk, v_ic // T.int64(64), v_kh, v_kw, v_ic % T.int64(64), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(2), T.int64(8), T.int64(14)):
                for ax4_fused in T.vectorized(T.int64(16)):
                    with T.block("T_relu"):
                        v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                        v_ax2 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(8) * T.int64(8) + ax2)
                        v_ax3 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(8) // T.int64(2) * T.int64(14) + ax3)
                        v_ax4 = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(2) * T.int64(16) + ax4_fused)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 1, 2])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[7, 2, 2, 2])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[4, 1, 14, 1])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[2, 1, 4, 4])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[2, 32])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[3, 1])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=7)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b69)
l85 = sch.fuse(l72, l73, l74, l75, l76, preserve_unit_iters=True)
sch.parallel(loop=l85)
l86 = sch.fuse(l84, preserve_unit_iters=True)
sch.vectorize(loop=l86)
l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107, l108 = sch.get_loops(block=b70)
l109 = sch.fuse(l87, preserve_unit_iters=True)
sch.parallel(loop=l109)
l110 = sch.fuse(l108, preserve_unit_iters=True)
sch.vectorize(loop=l110)
sch.annotate(block_or_loop=l109, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l109, ann_key="pragma_unroll_explicit", ann_val=1)
l111, l112, l113, l114, l115, l116 = sch.get_loops(block=b71)
l117 = sch.fuse(l116, preserve_unit_iters=True)
sch.vectorize(loop=l117)
b118 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140 = sch.get_loops(block=b118)
b141 = sch.decompose_reduction(block=b118, loop=l125)
2024-04-29 04:17:47 [INFO] [task_scheduler.cc:121] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #92: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(56), T.int64(56), T.int64(64)), "float32"), p1: T.Buffer((T.int64(2), T.int64(1), T.int64(3), T.int64(3), T.int64(64), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(32)), "float32"), p3: T.Buffer((T.int64(1), T.int64(2), T.int64(56), T.int64(56), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(2), T.int64(56), T.int64(56), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(58), T.int64(58), T.int64(64)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(56), T.int64(56), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused in T.parallel(T.int64(56), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1 in T.grid(T.int64(1), T.int64(1), T.int64(2)):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(6), T.int64(16)):
                    for ax4_fused in T.vectorized(T.int64(64)):
                        with T.block("data_pad"):
                            v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                            v_i2 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(8) * T.int64(8) + oh_1 * T.int64(4) + ax2)
                            v_i3 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(8) // T.int64(2) * T.int64(14) + ax3)
                            v_i4 = T.axis.spatial(T.int64(64), ax4_fused)
                            T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                            T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                            data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(57) and T.int64(1) <= v_i3 and v_i3 < T.int64(57), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                for ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1)):
                    for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(2), T.int64(2), T.int64(14), T.int64(4), T.int64(1), T.int64(1), T.int64(2), T.int64(1)):
                        for oc_block_3_fused_init in T.vectorized(T.int64(4)):
                            with T.block("conv2d_NCHWc_init"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                                v_oc_chunk = T.axis.spatial(T.int64(2), oc_chunk_1 * T.int64(2) + oc_chunk_2_init + oc_chunk_3_init)
                                v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(8) * T.int64(8) + oh_1 * T.int64(4) + oh_2_init * T.int64(2) + oh_3_init)
                                v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(8) // T.int64(2) * T.int64(14) + ow_1 * T.int64(14) + ow_2_init + ow_3_init)
                                v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(2) * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2_init * T.int64(4) + oc_block_3_fused_init)
                                T.reads()
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                    for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(2), T.int64(14), T.int64(4), T.int64(32), T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(2), T.int64(1)):
                        for oc_block_3_fused in T.vectorized(T.int64(4)):
                            with T.block("conv2d_NCHWc_update"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                                v_oc_chunk = T.axis.spatial(T.int64(2), oc_chunk_1 * T.int64(2) + oc_chunk_2 + oc_chunk_3)
                                v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(8) * T.int64(8) + oh_1 * T.int64(4) + oh_2 * T.int64(2) + oh_3)
                                v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(8) // T.int64(2) * T.int64(14) + ow_1 * T.int64(14) + ow_2 + ow_3)
                                v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(2) * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2 * T.int64(4) + oc_block_3_fused)
                                v_ic = T.axis.reduce(T.int64(64), ic_0 * T.int64(32) + ic_1)
                                v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                                v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                                T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(64), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(64)], p1[v_oc_chunk, v_ic // T.int64(64), v_kh, v_kw, v_ic % T.int64(64), v_oc_block])
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(64), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(64)] * p1[v_oc_chunk, v_ic // T.int64(64), v_kh, v_kw, v_ic % T.int64(64), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(2), T.int64(8), T.int64(14)):
                for ax4_fused in T.vectorized(T.int64(16)):
                    with T.block("T_relu"):
                        v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                        v_ax2 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(8) * T.int64(8) + ax2)
                        v_ax3 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(8) // T.int64(2) * T.int64(14) + ax3)
                        v_ax4 = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(2) * T.int64(16) + ax4_fused)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 2, 1])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[7, 2, 2, 2])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[4, 1, 14, 1])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[2, 1, 4, 4])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[2, 32])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[1, 3])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=7)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b69)
l85 = sch.fuse(l72, l73, l74, l75, l76, preserve_unit_iters=True)
sch.parallel(loop=l85)
l86 = sch.fuse(l84, preserve_unit_iters=True)
sch.vectorize(loop=l86)
l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107, l108 = sch.get_loops(block=b70)
l109 = sch.fuse(l87, preserve_unit_iters=True)
sch.parallel(loop=l109)
l110 = sch.fuse(l108, preserve_unit_iters=True)
sch.vectorize(loop=l110)
sch.annotate(block_or_loop=l109, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l109, ann_key="pragma_unroll_explicit", ann_val=1)
l111, l112, l113, l114, l115, l116 = sch.get_loops(block=b71)
l117 = sch.fuse(l116, preserve_unit_iters=True)
sch.vectorize(loop=l117)
b118 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140 = sch.get_loops(block=b118)
b141 = sch.decompose_reduction(block=b118, loop=l125)
2024-04-29 04:17:47 [INFO] [task_scheduler.cc:121] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #93: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(56), T.int64(56), T.int64(64)), "float32"), p1: T.Buffer((T.int64(2), T.int64(1), T.int64(3), T.int64(3), T.int64(64), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(32)), "float32"), p3: T.Buffer((T.int64(1), T.int64(2), T.int64(56), T.int64(56), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(2), T.int64(56), T.int64(56), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(58), T.int64(58), T.int64(64)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(56), T.int64(56), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused in T.parallel(T.int64(56), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1 in T.grid(T.int64(1), T.int64(1), T.int64(2)):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(6), T.int64(16)):
                    for ax4_fused in T.vectorized(T.int64(64)):
                        with T.block("data_pad"):
                            v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                            v_i2 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(8) * T.int64(8) + oh_1 * T.int64(4) + ax2)
                            v_i3 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(8) // T.int64(2) * T.int64(14) + ax3)
                            v_i4 = T.axis.spatial(T.int64(64), ax4_fused)
                            T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                            T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                            data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(57) and T.int64(1) <= v_i3 and v_i3 < T.int64(57), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                for ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1)):
                    for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(2), T.int64(2), T.int64(14), T.int64(4), T.int64(1), T.int64(1), T.int64(2), T.int64(1)):
                        for oc_block_3_fused_init in T.vectorized(T.int64(4)):
                            with T.block("conv2d_NCHWc_init"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                                v_oc_chunk = T.axis.spatial(T.int64(2), oc_chunk_1 * T.int64(2) + oc_chunk_2_init + oc_chunk_3_init)
                                v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(8) * T.int64(8) + oh_1 * T.int64(4) + oh_2_init * T.int64(2) + oh_3_init)
                                v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(8) // T.int64(2) * T.int64(14) + ow_1 * T.int64(14) + ow_2_init + ow_3_init)
                                v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(2) * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2_init * T.int64(4) + oc_block_3_fused_init)
                                T.reads()
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                    for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(2), T.int64(1), T.int64(3), T.int64(1), T.int64(2), T.int64(2), T.int64(14), T.int64(4), T.int64(32), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1)):
                        for oc_block_3_fused in T.vectorized(T.int64(4)):
                            with T.block("conv2d_NCHWc_update"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                                v_oc_chunk = T.axis.spatial(T.int64(2), oc_chunk_1 * T.int64(2) + oc_chunk_2 + oc_chunk_3)
                                v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(8) * T.int64(8) + oh_1 * T.int64(4) + oh_2 * T.int64(2) + oh_3)
                                v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(8) // T.int64(2) * T.int64(14) + ow_1 * T.int64(14) + ow_2 + ow_3)
                                v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(2) * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2 * T.int64(4) + oc_block_3_fused)
                                v_ic = T.axis.reduce(T.int64(64), ic_0 * T.int64(32) + ic_1)
                                v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                                v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                                T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(64), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(64)], p1[v_oc_chunk, v_ic // T.int64(64), v_kh, v_kw, v_ic % T.int64(64), v_oc_block])
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(64), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(64)] * p1[v_oc_chunk, v_ic // T.int64(64), v_kh, v_kw, v_ic % T.int64(64), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(2), T.int64(8), T.int64(14)):
                for ax4_fused in T.vectorized(T.int64(16)):
                    with T.block("T_relu"):
                        v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                        v_ax2 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(8) * T.int64(8) + ax2)
                        v_ax3 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(8) // T.int64(2) * T.int64(14) + ax3)
                        v_ax4 = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(2) * T.int64(16) + ax4_fused)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 2, 1])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[7, 2, 2, 2])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[4, 1, 14, 1])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[2, 1, 4, 4])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[2, 32])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[3, 1])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=7)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b69)
l85 = sch.fuse(l72, l73, l74, l75, l76, preserve_unit_iters=True)
sch.parallel(loop=l85)
l86 = sch.fuse(l84, preserve_unit_iters=True)
sch.vectorize(loop=l86)
l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107, l108 = sch.get_loops(block=b70)
l109 = sch.fuse(l87, preserve_unit_iters=True)
sch.parallel(loop=l109)
l110 = sch.fuse(l108, preserve_unit_iters=True)
sch.vectorize(loop=l110)
sch.annotate(block_or_loop=l109, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l109, ann_key="pragma_unroll_explicit", ann_val=1)
l111, l112, l113, l114, l115, l116 = sch.get_loops(block=b71)
l117 = sch.fuse(l116, preserve_unit_iters=True)
sch.vectorize(loop=l117)
b118 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140 = sch.get_loops(block=b118)
b141 = sch.decompose_reduction(block=b118, loop=l125)
2024-04-29 04:17:47 [INFO] [task_scheduler.cc:121] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #94: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(56), T.int64(56), T.int64(64)), "float32"), p1: T.Buffer((T.int64(2), T.int64(1), T.int64(3), T.int64(3), T.int64(64), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(32)), "float32"), p3: T.Buffer((T.int64(1), T.int64(2), T.int64(56), T.int64(56), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(2), T.int64(56), T.int64(56), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(58), T.int64(58), T.int64(64)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(56), T.int64(56), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused in T.parallel(T.int64(56), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1 in T.grid(T.int64(1), T.int64(1), T.int64(2)):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(6), T.int64(16)):
                    for ax4_fused in T.vectorized(T.int64(64)):
                        with T.block("data_pad"):
                            v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                            v_i2 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(8) * T.int64(8) + oh_1 * T.int64(4) + ax2)
                            v_i3 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(8) // T.int64(2) * T.int64(14) + ax3)
                            v_i4 = T.axis.spatial(T.int64(64), ax4_fused)
                            T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                            T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                            data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(57) and T.int64(1) <= v_i3 and v_i3 < T.int64(57), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                for ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1)):
                    for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(2), T.int64(2), T.int64(14), T.int64(4), T.int64(1), T.int64(1), T.int64(2), T.int64(1)):
                        for oc_block_3_fused_init in T.vectorized(T.int64(4)):
                            with T.block("conv2d_NCHWc_init"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                                v_oc_chunk = T.axis.spatial(T.int64(2), oc_chunk_1 * T.int64(2) + oc_chunk_2_init + oc_chunk_3_init)
                                v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(8) * T.int64(8) + oh_1 * T.int64(4) + oh_2_init * T.int64(2) + oh_3_init)
                                v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(8) // T.int64(2) * T.int64(14) + ow_1 * T.int64(14) + ow_2_init + ow_3_init)
                                v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(2) * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2_init * T.int64(4) + oc_block_3_fused_init)
                                T.reads()
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                    for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(4), T.int64(1), T.int64(3), T.int64(1), T.int64(2), T.int64(2), T.int64(14), T.int64(4), T.int64(16), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1)):
                        for oc_block_3_fused in T.vectorized(T.int64(4)):
                            with T.block("conv2d_NCHWc_update"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                                v_oc_chunk = T.axis.spatial(T.int64(2), oc_chunk_1 * T.int64(2) + oc_chunk_2 + oc_chunk_3)
                                v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(8) * T.int64(8) + oh_1 * T.int64(4) + oh_2 * T.int64(2) + oh_3)
                                v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(8) // T.int64(2) * T.int64(14) + ow_1 * T.int64(14) + ow_2 + ow_3)
                                v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(2) * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2 * T.int64(4) + oc_block_3_fused)
                                v_ic = T.axis.reduce(T.int64(64), ic_0 * T.int64(16) + ic_1)
                                v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                                v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                                T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(64), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(64)], p1[v_oc_chunk, v_ic // T.int64(64), v_kh, v_kw, v_ic % T.int64(64), v_oc_block])
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(64), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(64)] * p1[v_oc_chunk, v_ic // T.int64(64), v_kh, v_kw, v_ic % T.int64(64), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(2), T.int64(8), T.int64(14)):
                for ax4_fused in T.vectorized(T.int64(16)):
                    with T.block("T_relu"):
                        v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                        v_ax2 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(8) * T.int64(8) + ax2)
                        v_ax3 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(8) // T.int64(2) * T.int64(14) + ax3)
                        v_ax4 = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(2) * T.int64(16) + ax4_fused)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 2, 1])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[7, 2, 2, 2])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[4, 1, 14, 1])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[2, 1, 4, 4])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[4, 16])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[3, 1])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=7)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b69)
l85 = sch.fuse(l72, l73, l74, l75, l76, preserve_unit_iters=True)
sch.parallel(loop=l85)
l86 = sch.fuse(l84, preserve_unit_iters=True)
sch.vectorize(loop=l86)
l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107, l108 = sch.get_loops(block=b70)
l109 = sch.fuse(l87, preserve_unit_iters=True)
sch.parallel(loop=l109)
l110 = sch.fuse(l108, preserve_unit_iters=True)
sch.vectorize(loop=l110)
sch.annotate(block_or_loop=l109, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l109, ann_key="pragma_unroll_explicit", ann_val=1)
l111, l112, l113, l114, l115, l116 = sch.get_loops(block=b71)
l117 = sch.fuse(l116, preserve_unit_iters=True)
sch.vectorize(loop=l117)
b118 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140 = sch.get_loops(block=b118)
b141 = sch.decompose_reduction(block=b118, loop=l125)
2024-04-29 04:17:47 [INFO] [task_scheduler.cc:121] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #95: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(56), T.int64(56), T.int64(64)), "float32"), p1: T.Buffer((T.int64(2), T.int64(1), T.int64(3), T.int64(3), T.int64(64), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(32)), "float32"), p3: T.Buffer((T.int64(1), T.int64(2), T.int64(56), T.int64(56), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(2), T.int64(56), T.int64(56), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(58), T.int64(58), T.int64(64)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(56), T.int64(56), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused in T.parallel(T.int64(56), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1 in T.grid(T.int64(1), T.int64(1), T.int64(2)):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(6), T.int64(16)):
                    for ax4_fused in T.vectorized(T.int64(64)):
                        with T.block("data_pad"):
                            v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                            v_i2 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(8) * T.int64(8) + oh_1 * T.int64(4) + ax2)
                            v_i3 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(8) // T.int64(2) * T.int64(14) + ax3)
                            v_i4 = T.axis.spatial(T.int64(64), ax4_fused)
                            T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                            T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                            data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(57) and T.int64(1) <= v_i3 and v_i3 < T.int64(57), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                for ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1)):
                    for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(2), T.int64(2), T.int64(14), T.int64(4), T.int64(1), T.int64(1), T.int64(2), T.int64(1)):
                        for oc_block_3_fused_init in T.vectorized(T.int64(4)):
                            with T.block("conv2d_NCHWc_init"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                                v_oc_chunk = T.axis.spatial(T.int64(2), oc_chunk_1 * T.int64(2) + oc_chunk_2_init + oc_chunk_3_init)
                                v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(8) * T.int64(8) + oh_1 * T.int64(4) + oh_2_init * T.int64(2) + oh_3_init)
                                v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(8) // T.int64(2) * T.int64(14) + ow_1 * T.int64(14) + ow_2_init + ow_3_init)
                                v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(2) * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2_init * T.int64(4) + oc_block_3_fused_init)
                                T.reads()
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                    for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(16), T.int64(1), T.int64(3), T.int64(1), T.int64(2), T.int64(2), T.int64(14), T.int64(4), T.int64(4), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1)):
                        for oc_block_3_fused in T.vectorized(T.int64(4)):
                            with T.block("conv2d_NCHWc_update"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                                v_oc_chunk = T.axis.spatial(T.int64(2), oc_chunk_1 * T.int64(2) + oc_chunk_2 + oc_chunk_3)
                                v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(8) * T.int64(8) + oh_1 * T.int64(4) + oh_2 * T.int64(2) + oh_3)
                                v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(8) // T.int64(2) * T.int64(14) + ow_1 * T.int64(14) + ow_2 + ow_3)
                                v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(2) * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2 * T.int64(4) + oc_block_3_fused)
                                v_ic = T.axis.reduce(T.int64(64), ic_0 * T.int64(4) + ic_1)
                                v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                                v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                                T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(64), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(64)], p1[v_oc_chunk, v_ic // T.int64(64), v_kh, v_kw, v_ic % T.int64(64), v_oc_block])
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(64), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(64)] * p1[v_oc_chunk, v_ic // T.int64(64), v_kh, v_kw, v_ic % T.int64(64), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(2), T.int64(8), T.int64(14)):
                for ax4_fused in T.vectorized(T.int64(16)):
                    with T.block("T_relu"):
                        v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                        v_ax2 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(8) * T.int64(8) + ax2)
                        v_ax3 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(8) // T.int64(2) * T.int64(14) + ax3)
                        v_ax4 = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(2) * T.int64(16) + ax4_fused)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 2, 1])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[7, 2, 2, 2])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[4, 1, 14, 1])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[2, 1, 4, 4])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[16, 4])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[3, 1])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=7)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b69)
l85 = sch.fuse(l72, l73, l74, l75, l76, preserve_unit_iters=True)
sch.parallel(loop=l85)
l86 = sch.fuse(l84, preserve_unit_iters=True)
sch.vectorize(loop=l86)
l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107, l108 = sch.get_loops(block=b70)
l109 = sch.fuse(l87, preserve_unit_iters=True)
sch.parallel(loop=l109)
l110 = sch.fuse(l108, preserve_unit_iters=True)
sch.vectorize(loop=l110)
sch.annotate(block_or_loop=l109, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l109, ann_key="pragma_unroll_explicit", ann_val=1)
l111, l112, l113, l114, l115, l116 = sch.get_loops(block=b71)
l117 = sch.fuse(l116, preserve_unit_iters=True)
sch.vectorize(loop=l117)
b118 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140 = sch.get_loops(block=b118)
b141 = sch.decompose_reduction(block=b118, loop=l125)
2024-04-29 04:17:47 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #96: GFLOPs: 117.0877. Time: 1979.8250 us. Best GFLOPs: 297.3346
2024-04-29 04:17:47 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #97: GFLOPs: 41.8088. Time: 5544.6028 us. Best GFLOPs: 297.3346
2024-04-29 04:17:47 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #98: GFLOPs: 140.7380. Time: 1647.1250 us. Best GFLOPs: 297.3346
2024-04-29 04:17:47 [INFO] [task_scheduler.cc:121] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #99: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(56), T.int64(56), T.int64(64)), "float32"), p1: T.Buffer((T.int64(2), T.int64(1), T.int64(3), T.int64(3), T.int64(64), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(32)), "float32"), p3: T.Buffer((T.int64(1), T.int64(2), T.int64(56), T.int64(56), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(2), T.int64(56), T.int64(56), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(58), T.int64(58), T.int64(64)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(56), T.int64(56), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused in T.parallel(T.int64(56), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1 in T.grid(T.int64(1), T.int64(1), T.int64(2)):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(6), T.int64(16)):
                    for ax4_fused in T.vectorized(T.int64(64)):
                        with T.block("data_pad"):
                            v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                            v_i2 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(8) * T.int64(8) + oh_1 * T.int64(4) + ax2)
                            v_i3 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(8) // T.int64(2) * T.int64(14) + ax3)
                            v_i4 = T.axis.spatial(T.int64(64), ax4_fused)
                            T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                            T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                            data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(57) and T.int64(1) <= v_i3 and v_i3 < T.int64(57), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                for ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1)):
                    for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(2), T.int64(2), T.int64(7), T.int64(4), T.int64(1), T.int64(1), T.int64(2), T.int64(2)):
                        for oc_block_3_fused_init in T.vectorized(T.int64(4)):
                            with T.block("conv2d_NCHWc_init"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                                v_oc_chunk = T.axis.spatial(T.int64(2), oc_chunk_1 * T.int64(2) + oc_chunk_2_init + oc_chunk_3_init)
                                v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(8) * T.int64(8) + oh_1 * T.int64(4) + oh_2_init * T.int64(2) + oh_3_init)
                                v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(8) // T.int64(2) * T.int64(14) + ow_1 * T.int64(14) + ow_2_init * T.int64(2) + ow_3_init)
                                v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(2) * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2_init * T.int64(4) + oc_block_3_fused_init)
                                T.reads()
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                    for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(16), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(2), T.int64(7), T.int64(4), T.int64(4), T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(2), T.int64(2)):
                        for oc_block_3_fused in T.vectorized(T.int64(4)):
                            with T.block("conv2d_NCHWc_update"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                                v_oc_chunk = T.axis.spatial(T.int64(2), oc_chunk_1 * T.int64(2) + oc_chunk_2 + oc_chunk_3)
                                v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(8) * T.int64(8) + oh_1 * T.int64(4) + oh_2 * T.int64(2) + oh_3)
                                v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(8) // T.int64(2) * T.int64(14) + ow_1 * T.int64(14) + ow_2 * T.int64(2) + ow_3)
                                v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(2) * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2 * T.int64(4) + oc_block_3_fused)
                                v_ic = T.axis.reduce(T.int64(64), ic_0 * T.int64(4) + ic_1)
                                v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                                v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                                T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(64), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(64)], p1[v_oc_chunk, v_ic // T.int64(64), v_kh, v_kw, v_ic % T.int64(64), v_oc_block])
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(64), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(64)] * p1[v_oc_chunk, v_ic // T.int64(64), v_kh, v_kw, v_ic % T.int64(64), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(2), T.int64(8), T.int64(14)):
                for ax4_fused in T.vectorized(T.int64(16)):
                    with T.block("T_relu"):
                        v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                        v_ax2 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(8) * T.int64(8) + ax2)
                        v_ax3 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(8) // T.int64(2) * T.int64(14) + ax3)
                        v_ax4 = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(2) * T.int64(16) + ax4_fused)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 2, 1])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[7, 2, 2, 2])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[4, 1, 7, 2])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[2, 1, 4, 4])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[16, 4])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[1, 3])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=7)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b69)
l85 = sch.fuse(l72, l73, l74, l75, l76, preserve_unit_iters=True)
sch.parallel(loop=l85)
l86 = sch.fuse(l84, preserve_unit_iters=True)
sch.vectorize(loop=l86)
l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107, l108 = sch.get_loops(block=b70)
l109 = sch.fuse(l87, preserve_unit_iters=True)
sch.parallel(loop=l109)
l110 = sch.fuse(l108, preserve_unit_iters=True)
sch.vectorize(loop=l110)
sch.annotate(block_or_loop=l109, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l109, ann_key="pragma_unroll_explicit", ann_val=1)
l111, l112, l113, l114, l115, l116 = sch.get_loops(block=b71)
l117 = sch.fuse(l116, preserve_unit_iters=True)
sch.vectorize(loop=l117)
b118 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140 = sch.get_loops(block=b118)
b141 = sch.decompose_reduction(block=b118, loop=l125)
2024-04-29 04:17:47 [INFO] [task_scheduler.cc:121] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #100: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(56), T.int64(56), T.int64(64)), "float32"), p1: T.Buffer((T.int64(2), T.int64(1), T.int64(3), T.int64(3), T.int64(64), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(32)), "float32"), p3: T.Buffer((T.int64(1), T.int64(2), T.int64(56), T.int64(56), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(2), T.int64(56), T.int64(56), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(58), T.int64(58), T.int64(64)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(56), T.int64(56), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused in T.parallel(T.int64(56), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1 in T.grid(T.int64(1), T.int64(1), T.int64(2)):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(6), T.int64(16)):
                    for ax4_fused in T.vectorized(T.int64(64)):
                        with T.block("data_pad"):
                            v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                            v_i2 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(8) * T.int64(8) + oh_1 * T.int64(4) + ax2)
                            v_i3 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(8) // T.int64(2) * T.int64(14) + ax3)
                            v_i4 = T.axis.spatial(T.int64(64), ax4_fused)
                            T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                            T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                            data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(57) and T.int64(1) <= v_i3 and v_i3 < T.int64(57), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                for ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1)):
                    for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(2), T.int64(2), T.int64(7), T.int64(4), T.int64(1), T.int64(1), T.int64(2), T.int64(2)):
                        for oc_block_3_fused_init in T.vectorized(T.int64(4)):
                            with T.block("conv2d_NCHWc_init"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                                v_oc_chunk = T.axis.spatial(T.int64(2), oc_chunk_1 * T.int64(2) + oc_chunk_2_init + oc_chunk_3_init)
                                v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(8) * T.int64(8) + oh_1 * T.int64(4) + oh_2_init * T.int64(2) + oh_3_init)
                                v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(8) // T.int64(2) * T.int64(14) + ow_1 * T.int64(14) + ow_2_init * T.int64(2) + ow_3_init)
                                v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(2) * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2_init * T.int64(4) + oc_block_3_fused_init)
                                T.reads()
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                    for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(16), T.int64(1), T.int64(3), T.int64(1), T.int64(2), T.int64(2), T.int64(7), T.int64(4), T.int64(4), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(2)):
                        for oc_block_3_fused in T.vectorized(T.int64(4)):
                            with T.block("conv2d_NCHWc_update"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                                v_oc_chunk = T.axis.spatial(T.int64(2), oc_chunk_1 * T.int64(2) + oc_chunk_2 + oc_chunk_3)
                                v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(8) * T.int64(8) + oh_1 * T.int64(4) + oh_2 * T.int64(2) + oh_3)
                                v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(8) // T.int64(2) * T.int64(14) + ow_1 * T.int64(14) + ow_2 * T.int64(2) + ow_3)
                                v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(2) * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2 * T.int64(4) + oc_block_3_fused)
                                v_ic = T.axis.reduce(T.int64(64), ic_0 * T.int64(4) + ic_1)
                                v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                                v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                                T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(64), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(64)], p1[v_oc_chunk, v_ic // T.int64(64), v_kh, v_kw, v_ic % T.int64(64), v_oc_block])
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(64), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(64)] * p1[v_oc_chunk, v_ic // T.int64(64), v_kh, v_kw, v_ic % T.int64(64), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(2), T.int64(8), T.int64(14)):
                for ax4_fused in T.vectorized(T.int64(16)):
                    with T.block("T_relu"):
                        v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                        v_ax2 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(8) * T.int64(8) + ax2)
                        v_ax3 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(8) // T.int64(2) * T.int64(14) + ax3)
                        v_ax4 = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(2) * T.int64(16) + ax4_fused)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 2, 1])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[7, 2, 2, 2])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[4, 1, 7, 2])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[2, 1, 4, 4])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[16, 4])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[3, 1])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=7)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b69)
l85 = sch.fuse(l72, l73, l74, l75, l76, preserve_unit_iters=True)
sch.parallel(loop=l85)
l86 = sch.fuse(l84, preserve_unit_iters=True)
sch.vectorize(loop=l86)
l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107, l108 = sch.get_loops(block=b70)
l109 = sch.fuse(l87, preserve_unit_iters=True)
sch.parallel(loop=l109)
l110 = sch.fuse(l108, preserve_unit_iters=True)
sch.vectorize(loop=l110)
sch.annotate(block_or_loop=l109, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l109, ann_key="pragma_unroll_explicit", ann_val=1)
l111, l112, l113, l114, l115, l116 = sch.get_loops(block=b71)
l117 = sch.fuse(l116, preserve_unit_iters=True)
sch.vectorize(loop=l117)
b118 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140 = sch.get_loops(block=b118)
b141 = sch.decompose_reduction(block=b118, loop=l125)
2024-04-29 04:17:47 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #101: GFLOPs: 139.3369. Time: 1663.6884 us. Best GFLOPs: 297.3346
2024-04-29 04:17:47 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #102: GFLOPs: 143.4797. Time: 1615.6512 us. Best GFLOPs: 297.3346
2024-04-29 04:17:47 [INFO] [task_scheduler.cc:121] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #103: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(56), T.int64(56), T.int64(64)), "float32"), p1: T.Buffer((T.int64(2), T.int64(1), T.int64(3), T.int64(3), T.int64(64), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(32)), "float32"), p3: T.Buffer((T.int64(1), T.int64(2), T.int64(56), T.int64(56), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(2), T.int64(56), T.int64(56), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(58), T.int64(58), T.int64(64)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(56), T.int64(56), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused in T.parallel(T.int64(56), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1 in T.grid(T.int64(1), T.int64(1), T.int64(2)):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(6), T.int64(16)):
                    for ax4_fused in T.vectorized(T.int64(64)):
                        with T.block("data_pad"):
                            v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                            v_i2 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(8) * T.int64(8) + oh_1 * T.int64(4) + ax2)
                            v_i3 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(8) // T.int64(2) * T.int64(14) + ax3)
                            v_i4 = T.axis.spatial(T.int64(64), ax4_fused)
                            T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                            T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                            data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(57) and T.int64(1) <= v_i3 and v_i3 < T.int64(57), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                for ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1)):
                    for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(2), T.int64(2), T.int64(2), T.int64(4), T.int64(1), T.int64(1), T.int64(2), T.int64(7)):
                        for oc_block_3_fused_init in T.vectorized(T.int64(4)):
                            with T.block("conv2d_NCHWc_init"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                                v_oc_chunk = T.axis.spatial(T.int64(2), oc_chunk_1 * T.int64(2) + oc_chunk_2_init + oc_chunk_3_init)
                                v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(8) * T.int64(8) + oh_1 * T.int64(4) + oh_2_init * T.int64(2) + oh_3_init)
                                v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(8) // T.int64(2) * T.int64(14) + ow_1 * T.int64(14) + ow_2_init * T.int64(7) + ow_3_init)
                                v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(2) * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2_init * T.int64(4) + oc_block_3_fused_init)
                                T.reads()
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                    for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(16), T.int64(3), T.int64(3), T.int64(1), T.int64(2), T.int64(2), T.int64(2), T.int64(4), T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(7)):
                        for oc_block_3_fused in T.vectorized(T.int64(4)):
                            with T.block("conv2d_NCHWc_update"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                                v_oc_chunk = T.axis.spatial(T.int64(2), oc_chunk_1 * T.int64(2) + oc_chunk_2 + oc_chunk_3)
                                v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(8) * T.int64(8) + oh_1 * T.int64(4) + oh_2 * T.int64(2) + oh_3)
                                v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(8) // T.int64(2) * T.int64(14) + ow_1 * T.int64(14) + ow_2 * T.int64(7) + ow_3)
                                v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(2) * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2 * T.int64(4) + oc_block_3_fused)
                                v_ic = T.axis.reduce(T.int64(64), ic_0 * T.int64(4) + ic_1)
                                v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                                v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                                T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(64), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(64)], p1[v_oc_chunk, v_ic // T.int64(64), v_kh, v_kw, v_ic % T.int64(64), v_oc_block])
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(64), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(64)] * p1[v_oc_chunk, v_ic // T.int64(64), v_kh, v_kw, v_ic % T.int64(64), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(2), T.int64(8), T.int64(14)):
                for ax4_fused in T.vectorized(T.int64(16)):
                    with T.block("T_relu"):
                        v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                        v_ax2 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(8) * T.int64(8) + ax2)
                        v_ax3 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(8) // T.int64(2) * T.int64(14) + ax3)
                        v_ax4 = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(2) * T.int64(16) + ax4_fused)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 2, 1])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[7, 2, 2, 2])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[4, 1, 2, 7])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[2, 1, 4, 4])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[16, 4])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[3, 1])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=7)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b69)
l85 = sch.fuse(l72, l73, l74, l75, l76, preserve_unit_iters=True)
sch.parallel(loop=l85)
l86 = sch.fuse(l84, preserve_unit_iters=True)
sch.vectorize(loop=l86)
l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107, l108 = sch.get_loops(block=b70)
l109 = sch.fuse(l87, preserve_unit_iters=True)
sch.parallel(loop=l109)
l110 = sch.fuse(l108, preserve_unit_iters=True)
sch.vectorize(loop=l110)
sch.annotate(block_or_loop=l109, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l109, ann_key="pragma_unroll_explicit", ann_val=1)
l111, l112, l113, l114, l115, l116 = sch.get_loops(block=b71)
l117 = sch.fuse(l116, preserve_unit_iters=True)
sch.vectorize(loop=l117)
b118 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140 = sch.get_loops(block=b118)
b141 = sch.decompose_reduction(block=b118, loop=l125)
2024-04-29 04:17:47 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #104: GFLOPs: 71.2133. Time: 3255.1929 us. Best GFLOPs: 297.3346
2024-04-29 04:17:47 [INFO] [task_scheduler.cc:121] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #105: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(56), T.int64(56), T.int64(64)), "float32"), p1: T.Buffer((T.int64(2), T.int64(1), T.int64(3), T.int64(3), T.int64(64), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(32)), "float32"), p3: T.Buffer((T.int64(1), T.int64(2), T.int64(56), T.int64(56), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(2), T.int64(56), T.int64(56), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(58), T.int64(58), T.int64(64)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(56), T.int64(56), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused in T.parallel(T.int64(56), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1 in T.grid(T.int64(1), T.int64(1), T.int64(2)):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(6), T.int64(16)):
                    for ax4_fused in T.vectorized(T.int64(64)):
                        with T.block("data_pad"):
                            v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                            v_i2 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(8) * T.int64(8) + oh_1 * T.int64(4) + ax2)
                            v_i3 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(8) // T.int64(2) * T.int64(14) + ax3)
                            v_i4 = T.axis.spatial(T.int64(64), ax4_fused)
                            T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                            T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                            data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(57) and T.int64(1) <= v_i3 and v_i3 < T.int64(57), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                for ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1)):
                    for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(2), T.int64(2), T.int64(2), T.int64(4), T.int64(1), T.int64(1), T.int64(2), T.int64(7)):
                        for oc_block_3_fused_init in T.vectorized(T.int64(4)):
                            with T.block("conv2d_NCHWc_init"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                                v_oc_chunk = T.axis.spatial(T.int64(2), oc_chunk_1 * T.int64(2) + oc_chunk_2_init + oc_chunk_3_init)
                                v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(8) * T.int64(8) + oh_1 * T.int64(4) + oh_2_init * T.int64(2) + oh_3_init)
                                v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(8) // T.int64(2) * T.int64(14) + ow_1 * T.int64(14) + ow_2_init * T.int64(7) + ow_3_init)
                                v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(2) * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2_init * T.int64(4) + oc_block_3_fused_init)
                                T.reads()
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                    for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(16), T.int64(1), T.int64(3), T.int64(1), T.int64(2), T.int64(2), T.int64(2), T.int64(4), T.int64(4), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(7)):
                        for oc_block_3_fused in T.vectorized(T.int64(4)):
                            with T.block("conv2d_NCHWc_update"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                                v_oc_chunk = T.axis.spatial(T.int64(2), oc_chunk_1 * T.int64(2) + oc_chunk_2 + oc_chunk_3)
                                v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(8) * T.int64(8) + oh_1 * T.int64(4) + oh_2 * T.int64(2) + oh_3)
                                v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(8) // T.int64(2) * T.int64(14) + ow_1 * T.int64(14) + ow_2 * T.int64(7) + ow_3)
                                v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(2) * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2 * T.int64(4) + oc_block_3_fused)
                                v_ic = T.axis.reduce(T.int64(64), ic_0 * T.int64(4) + ic_1)
                                v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                                v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                                T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(64), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(64)], p1[v_oc_chunk, v_ic // T.int64(64), v_kh, v_kw, v_ic % T.int64(64), v_oc_block])
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(64), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(64)] * p1[v_oc_chunk, v_ic // T.int64(64), v_kh, v_kw, v_ic % T.int64(64), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(2), T.int64(8), T.int64(14)):
                for ax4_fused in T.vectorized(T.int64(16)):
                    with T.block("T_relu"):
                        v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                        v_ax2 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(8) * T.int64(8) + ax2)
                        v_ax3 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(8) // T.int64(2) * T.int64(14) + ax3)
                        v_ax4 = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(2) * T.int64(16) + ax4_fused)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 2, 1])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[7, 2, 2, 2])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[4, 1, 2, 7])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[2, 1, 4, 4])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[16, 4])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[3, 1])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=7)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b69)
l85 = sch.fuse(l72, l73, l74, l75, l76, preserve_unit_iters=True)
sch.parallel(loop=l85)
l86 = sch.fuse(l84, preserve_unit_iters=True)
sch.vectorize(loop=l86)
l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107, l108 = sch.get_loops(block=b70)
l109 = sch.fuse(l87, preserve_unit_iters=True)
sch.parallel(loop=l109)
l110 = sch.fuse(l108, preserve_unit_iters=True)
sch.vectorize(loop=l110)
sch.annotate(block_or_loop=l109, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l109, ann_key="pragma_unroll_explicit", ann_val=1)
l111, l112, l113, l114, l115, l116 = sch.get_loops(block=b71)
l117 = sch.fuse(l116, preserve_unit_iters=True)
sch.vectorize(loop=l117)
b118 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140 = sch.get_loops(block=b118)
b141 = sch.decompose_reduction(block=b118, loop=l125)
2024-04-29 04:17:47 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #106: GFLOPs: 69.8165. Time: 3320.3213 us. Best GFLOPs: 297.3346
2024-04-29 04:17:47 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #107: GFLOPs: 321.3678. Time: 721.3327 us. Best GFLOPs: 321.3678
2024-04-29 04:17:47 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #108: GFLOPs: 83.1014. Time: 2789.5211 us. Best GFLOPs: 321.3678
2024-04-29 04:17:47 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #109: GFLOPs: 44.7095. Time: 5184.8737 us. Best GFLOPs: 321.3678
2024-04-29 04:17:47 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #110: GFLOPs: 146.7063. Time: 1580.1167 us. Best GFLOPs: 321.3678
2024-04-29 04:17:47 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #111: GFLOPs: 109.3981. Time: 2118.9858 us. Best GFLOPs: 321.3678
2024-04-29 04:17:47 [INFO] [task_scheduler.cc:121] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #112: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(56), T.int64(56), T.int64(64)), "float32"), p1: T.Buffer((T.int64(2), T.int64(1), T.int64(3), T.int64(3), T.int64(64), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(32)), "float32"), p3: T.Buffer((T.int64(1), T.int64(2), T.int64(56), T.int64(56), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(2), T.int64(56), T.int64(56), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(58), T.int64(58), T.int64(64)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(56), T.int64(56), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused in T.parallel(T.int64(56), annotations={"pragma_auto_unroll_max_step": 64, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1, ow_1 in T.grid(T.int64(1), T.int64(1), T.int64(2), T.int64(2)):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(16), T.int64(3)):
                    for ax4_fused in T.vectorized(T.int64(64)):
                        with T.block("data_pad"):
                            v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                            v_i2 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(28) * T.int64(28) + oh_1 * T.int64(14) + ax2)
                            v_i3 = T.axis.spatial(T.int64(58), ow_1 + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(28) * T.int64(2) + ax3)
                            v_i4 = T.axis.spatial(T.int64(64), ax4_fused)
                            T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                            T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                            data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(57) and T.int64(1) <= v_i3 and v_i3 < T.int64(57), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                for oc_block_1 in range(T.int64(2)):
                    for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(2), T.int64(1), T.int64(2), T.int64(2), T.int64(1)):
                        for oc_block_3_fused_init in T.vectorized(T.int64(8)):
                            with T.block("conv2d_NCHWc_init"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                                v_oc_chunk = T.axis.spatial(T.int64(2), oc_chunk_1 * T.int64(2) + oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                                v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(28) * T.int64(28) + oh_1 * T.int64(14) + oh_2_init * T.int64(2) + oh_3_init)
                                v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(28) * T.int64(2) + ow_1 + ow_2_init + ow_3_init)
                                v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(16) + oc_block_2_init * T.int64(8) + oc_block_3_fused_init)
                                T.reads()
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                    for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(2), T.int64(32), T.int64(3), T.int64(3), T.int64(1), T.int64(2), T.int64(2), T.int64(1)):
                        for oc_block_3_fused in T.vectorized(T.int64(8)):
                            with T.block("conv2d_NCHWc_update"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                                v_oc_chunk = T.axis.spatial(T.int64(2), oc_chunk_1 * T.int64(2) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                                v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(28) * T.int64(28) + oh_1 * T.int64(14) + oh_2 * T.int64(2) + oh_3)
                                v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(28) * T.int64(2) + ow_1 + ow_2 + ow_3)
                                v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(16) + oc_block_2 * T.int64(8) + oc_block_3_fused)
                                v_ic = T.axis.reduce(T.int64(64), ic_0 * T.int64(32) + ic_1)
                                v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                                v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                                T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(64), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(64)], p1[v_oc_chunk, v_ic // T.int64(64), v_kh, v_kw, v_ic % T.int64(64), v_oc_block])
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(64), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(64)] * p1[v_oc_chunk, v_ic // T.int64(64), v_kh, v_kw, v_ic % T.int64(64), v_oc_block]
            for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(2), T.int64(28)):
                for ax3_ax4_fused in T.vectorized(T.int64(64)):
                    with T.block("T_relu"):
                        v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                        v_ax2 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(28) * T.int64(28) + ax2)
                        v_ax3 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(28) * T.int64(2) + ax3_ax4_fused // T.int64(32))
                        v_ax4 = T.axis.spatial(T.int64(32), ax3_ax4_fused % T.int64(32))
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 1, 2])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[2, 2, 7, 2])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[28, 2, 1, 1])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[1, 2, 2, 8])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[2, 32])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[1, 3])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=8)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85 = sch.get_loops(block=b69)
l86 = sch.fuse(l72, l73, l74, l75, l76, preserve_unit_iters=True)
sch.parallel(loop=l86)
l87 = sch.fuse(l85, preserve_unit_iters=True)
sch.vectorize(loop=l87)
l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107, l108, l109 = sch.get_loops(block=b70)
l110 = sch.fuse(l88, preserve_unit_iters=True)
sch.parallel(loop=l110)
l111 = sch.fuse(l109, preserve_unit_iters=True)
sch.vectorize(loop=l111)
sch.annotate(block_or_loop=l110, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l110, ann_key="pragma_unroll_explicit", ann_val=1)
l112, l113, l114, l115, l116, l117 = sch.get_loops(block=b71)
l118 = sch.fuse(l116, l117, preserve_unit_iters=True)
sch.vectorize(loop=l118)
b119 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141 = sch.get_loops(block=b119)
b142 = sch.decompose_reduction(block=b119, loop=l126)
2024-04-29 04:17:47 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #113: GFLOPs: 132.9524. Time: 1743.5798 us. Best GFLOPs: 321.3678
2024-04-29 04:17:47 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #114: GFLOPs: 131.7838. Time: 1759.0406 us. Best GFLOPs: 321.3678
2024-04-29 04:17:47 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #115: GFLOPs: 542.7123. Time: 427.1382 us. Best GFLOPs: 542.7123
2024-04-29 04:17:47 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #116: GFLOPs: 85.6032. Time: 2707.9947 us. Best GFLOPs: 542.7123
2024-04-29 04:17:47 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #117: GFLOPs: 116.9597. Time: 1981.9921 us. Best GFLOPs: 542.7123
2024-04-29 04:17:47 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #118: GFLOPs: 419.4701. Time: 552.6332 us. Best GFLOPs: 542.7123
2024-04-29 04:17:47 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #119: GFLOPs: 157.6131. Time: 1470.7728 us. Best GFLOPs: 542.7123
2024-04-29 04:17:47 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #120: GFLOPs: 171.0808. Time: 1354.9920 us. Best GFLOPs: 542.7123
2024-04-29 04:17:47 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #121: GFLOPs: 108.4860. Time: 2136.8018 us. Best GFLOPs: 542.7123
2024-04-29 04:17:47 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #122: GFLOPs: 708.2643. Time: 327.2975 us. Best GFLOPs: 708.2643
2024-04-29 04:17:47 [INFO] [task_scheduler.cc:121] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #123: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(56), T.int64(56), T.int64(64)), "float32"), p1: T.Buffer((T.int64(2), T.int64(1), T.int64(3), T.int64(3), T.int64(64), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(32)), "float32"), p3: T.Buffer((T.int64(1), T.int64(2), T.int64(56), T.int64(56), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(2), T.int64(56), T.int64(56), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(58), T.int64(58), T.int64(64)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(56), T.int64(56), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused in T.parallel(T.int64(56), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(8), T.int64(2)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(8)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(2), oc_chunk_1 * T.int64(2) + oc_chunk_2_init + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(56), oh_1 * T.int64(8) + oh_2_init * T.int64(8) + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(2) * T.int64(2) + ow_1 * T.int64(2) + ow_2_init * T.int64(2) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(2) * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2_init * T.int64(8) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0 in range(T.int64(4)):
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(10), T.int64(4)):
                        for ax4_fused in T.vectorized(T.int64(16)):
                            with T.block("data_pad"):
                                v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                                v_i2 = T.axis.spatial(T.int64(58), oh_1 * T.int64(8) + ax2)
                                v_i3 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(2) * T.int64(2) + ax3)
                                v_i4 = T.axis.spatial(T.int64(64), ic_0 * T.int64(16) + ax4_fused)
                                T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                                T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                                data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(57) and T.int64(1) <= v_i3 and v_i3 < T.int64(57), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                    for kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(2), T.int64(16), T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(8), T.int64(2)):
                        for oc_block_3_fused in T.vectorized(T.int64(8)):
                            with T.block("conv2d_NCHWc_update"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                                v_oc_chunk = T.axis.spatial(T.int64(2), oc_chunk_1 * T.int64(2) + oc_chunk_2 + oc_chunk_3)
                                v_oh = T.axis.spatial(T.int64(56), oh_1 * T.int64(8) + oh_2 * T.int64(8) + oh_3)
                                v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(2) * T.int64(2) + ow_1 * T.int64(2) + ow_2 * T.int64(2) + ow_3)
                                v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(2) * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2 * T.int64(8) + oc_block_3_fused)
                                v_ic = T.axis.reduce(T.int64(64), ic_0 * T.int64(16) + ic_1)
                                v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                                v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                                T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(64), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(64)], p1[v_oc_chunk, v_ic // T.int64(64), v_kh, v_kw, v_ic % T.int64(64), v_oc_block])
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(64), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(64)] * p1[v_oc_chunk, v_ic // T.int64(64), v_kh, v_kw, v_ic % T.int64(64), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(2), T.int64(56), T.int64(2)):
                for ax4_fused in T.vectorized(T.int64(16)):
                    with T.block("T_relu"):
                        v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                        v_ax3 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(2) * T.int64(2) + ax3)
                        v_ax4 = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(2) * T.int64(16) + ax4_fused)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 2, 1])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 7, 1, 8])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[28, 1, 1, 2])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[2, 1, 2, 8])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[4, 16])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[1, 3])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=10)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87 = sch.get_loops(block=b69)
l88 = sch.fuse(l72, l73, l74, l75, l76, preserve_unit_iters=True)
sch.parallel(loop=l88)
l89 = sch.fuse(l87, preserve_unit_iters=True)
sch.vectorize(loop=l89)
l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107, l108, l109, l110, l111 = sch.get_loops(block=b70)
l112 = sch.fuse(l90, preserve_unit_iters=True)
sch.parallel(loop=l112)
l113 = sch.fuse(l111, preserve_unit_iters=True)
sch.vectorize(loop=l113)
sch.annotate(block_or_loop=l112, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l112, ann_key="pragma_unroll_explicit", ann_val=1)
l114, l115, l116, l117, l118, l119 = sch.get_loops(block=b71)
l120 = sch.fuse(l119, preserve_unit_iters=True)
sch.vectorize(loop=l120)
b121 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141, l142, l143 = sch.get_loops(block=b121)
b144 = sch.decompose_reduction(block=b121, loop=l128)
2024-04-29 04:17:47 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #124: GFLOPs: 77.0335. Time: 3009.2521 us. Best GFLOPs: 708.2643
2024-04-29 04:17:47 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #125: GFLOPs: 137.3618. Time: 1687.6099 us. Best GFLOPs: 708.2643
2024-04-29 04:17:47 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #126: GFLOPs: 50.1910. Time: 4618.6176 us. Best GFLOPs: 708.2643
2024-04-29 04:17:47 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #127: GFLOPs: 78.2514. Time: 2962.4148 us. Best GFLOPs: 708.2643
2024-04-29 04:17:47 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #128: GFLOPs: 3.7432. Time: 61929.4240 us. Best GFLOPs: 708.2643
2024-04-29 05:11:19 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 05:11:20 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-29 05:11:25 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x6d7cf18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3529928)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35fad28)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x42e62b8)]: 0 failure(s)
2024-04-29 05:11:25 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-29 05:11:38 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x6d7cf18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3529928)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35fad28)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x42e62b8)]: 0 failure(s)
2024-04-29 05:11:51 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x6d7cf18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3529928)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35fad28)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x42e62b8)]: 0 failure(s)
2024-04-29 05:12:05 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x6d7cf18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3529928)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35fad28)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x42e62b8)]: 0 failure(s)
2024-04-29 05:12:19 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x6d7cf18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3529928)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35fad28)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x42e62b8)]: 0 failure(s)
2024-04-29 05:12:28 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9937  0.9607  0.9491  0.9258  0.9178  0.9178  0.9011  0.8956  0.8757  0.8690  0.8661  0.8577  0.8514  0.8456  0.8217  0.8044
[17 : 32]:	0.8043  0.8037  0.7934  0.7836  0.7816  0.7774  0.7774  0.7773  0.7741  0.7708  0.7642  0.7628  0.7593  0.7549  0.7537  0.7436
[33 : 48]:	0.7349  0.7323  0.7293  0.7287  0.7272  0.7227  0.7217  0.7197  0.7173  0.7173  0.7059  0.7042  0.7026  0.7010  0.6995  0.6989
[49 : 64]:	0.6976  0.6890  0.6871  0.6861  0.6813  0.6812  0.6782  0.6761  0.6727  0.6653  0.6652  0.6634  0.6619  0.6604  0.6602  0.6602
2024-04-29 05:12:28 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 05:12:28 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 05:13:44 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #129: GFLOPs: 627.1714. Time: 369.6168 us. Best GFLOPs: 708.2643
2024-04-29 05:13:44 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #130: GFLOPs: 563.4309. Time: 411.4313 us. Best GFLOPs: 708.2643
2024-04-29 05:13:44 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #131: GFLOPs: 656.5235. Time: 353.0919 us. Best GFLOPs: 708.2643
2024-04-29 05:13:44 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #132: GFLOPs: 436.7843. Time: 530.7267 us. Best GFLOPs: 708.2643
2024-04-29 05:13:44 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #133: GFLOPs: 657.6233. Time: 352.5014 us. Best GFLOPs: 708.2643
2024-04-29 05:13:44 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #134: GFLOPs: 496.9191. Time: 466.5007 us. Best GFLOPs: 708.2643
2024-04-29 05:13:44 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #135: GFLOPs: 673.7986. Time: 344.0392 us. Best GFLOPs: 708.2643
2024-04-29 05:13:44 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #136: GFLOPs: 495.2364. Time: 468.0858 us. Best GFLOPs: 708.2643
2024-04-29 05:13:44 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #137: GFLOPs: 650.4451. Time: 356.3915 us. Best GFLOPs: 708.2643
2024-04-29 05:13:44 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #138: GFLOPs: 631.7131. Time: 366.9595 us. Best GFLOPs: 708.2643
2024-04-29 05:13:44 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #139: GFLOPs: 528.7131. Time: 438.4478 us. Best GFLOPs: 708.2643
2024-04-29 05:13:44 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #140: GFLOPs: 460.6918. Time: 503.1848 us. Best GFLOPs: 708.2643
2024-04-29 05:13:44 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #141: GFLOPs: 683.8084. Time: 339.0030 us. Best GFLOPs: 708.2643
2024-04-29 05:13:44 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #142: GFLOPs: 699.4579. Time: 331.4183 us. Best GFLOPs: 708.2643
2024-04-29 05:13:44 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #143: GFLOPs: 513.0236. Time: 451.8566 us. Best GFLOPs: 708.2643
2024-04-29 05:13:44 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #144: GFLOPs: 312.8388. Time: 740.9986 us. Best GFLOPs: 708.2643
2024-04-29 05:13:44 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #145: GFLOPs: 518.5926. Time: 447.0043 us. Best GFLOPs: 708.2643
2024-04-29 05:13:44 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #146: GFLOPs: 442.8986. Time: 523.4000 us. Best GFLOPs: 708.2643
2024-04-29 05:13:44 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #147: GFLOPs: 466.6193. Time: 496.7928 us. Best GFLOPs: 708.2643
2024-04-29 05:13:44 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #148: GFLOPs: 672.3197. Time: 344.7960 us. Best GFLOPs: 708.2643
2024-04-29 05:13:44 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #149: GFLOPs: 553.8706. Time: 418.5330 us. Best GFLOPs: 708.2643
2024-04-29 05:13:44 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #150: GFLOPs: 519.2568. Time: 446.4326 us. Best GFLOPs: 708.2643
2024-04-29 05:13:44 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #151: GFLOPs: 473.4460. Time: 489.6295 us. Best GFLOPs: 708.2643
2024-04-29 05:13:44 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #152: GFLOPs: 614.0903. Time: 377.4903 us. Best GFLOPs: 708.2643
2024-04-29 05:13:44 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #153: GFLOPs: 391.9391. Time: 591.4518 us. Best GFLOPs: 708.2643
2024-04-29 05:13:44 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #154: GFLOPs: 451.3609. Time: 513.5870 us. Best GFLOPs: 708.2643
2024-04-29 05:13:44 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #155: GFLOPs: 272.9595. Time: 849.2583 us. Best GFLOPs: 708.2643
2024-04-29 05:13:44 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #156: GFLOPs: 413.6938. Time: 560.3495 us. Best GFLOPs: 708.2643
2024-04-29 05:13:44 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #157: GFLOPs: 610.4352. Time: 379.7506 us. Best GFLOPs: 708.2643
2024-04-29 05:13:44 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #158: GFLOPs: 577.0350. Time: 401.7315 us. Best GFLOPs: 708.2643
2024-04-29 05:13:44 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #159: GFLOPs: 401.6060. Time: 577.2152 us. Best GFLOPs: 708.2643
2024-04-29 05:13:44 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #160: GFLOPs: 524.3425. Time: 442.1025 us. Best GFLOPs: 708.2643
2024-04-29 05:13:44 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #161: GFLOPs: 445.4678. Time: 520.3813 us. Best GFLOPs: 708.2643
2024-04-29 05:13:44 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #162: GFLOPs: 286.4908. Time: 809.1470 us. Best GFLOPs: 708.2643
2024-04-29 05:13:44 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #163: GFLOPs: 498.3610. Time: 465.1510 us. Best GFLOPs: 708.2643
2024-04-29 05:13:44 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #164: GFLOPs: 133.3207. Time: 1738.7635 us. Best GFLOPs: 708.2643
2024-04-29 05:13:44 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #165: GFLOPs: 436.8826. Time: 530.6074 us. Best GFLOPs: 708.2643
2024-04-29 05:13:44 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #166: GFLOPs: 322.8330. Time: 718.0590 us. Best GFLOPs: 708.2643
2024-04-29 05:13:44 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #167: GFLOPs: 288.1304. Time: 804.5424 us. Best GFLOPs: 708.2643
2024-04-29 05:13:44 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #168: GFLOPs: 366.4793. Time: 632.5408 us. Best GFLOPs: 708.2643
2024-04-29 05:13:44 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #169: GFLOPs: 454.8451. Time: 509.6529 us. Best GFLOPs: 708.2643
2024-04-29 05:13:44 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #170: GFLOPs: 420.3513. Time: 551.4747 us. Best GFLOPs: 708.2643
2024-04-29 05:13:44 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #171: GFLOPs: 362.8333. Time: 638.8970 us. Best GFLOPs: 708.2643
2024-04-29 05:13:44 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #172: GFLOPs: 290.5716. Time: 797.7832 us. Best GFLOPs: 708.2643
2024-04-29 05:13:44 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #173: GFLOPs: 448.6334. Time: 516.7094 us. Best GFLOPs: 708.2643
2024-04-29 05:13:44 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #174: GFLOPs: 437.8209. Time: 529.4702 us. Best GFLOPs: 708.2643
2024-04-29 05:13:44 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #175: GFLOPs: 668.6830. Time: 346.6712 us. Best GFLOPs: 708.2643
2024-04-29 05:13:44 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #176: GFLOPs: 748.4102. Time: 309.7407 us. Best GFLOPs: 748.4102
2024-04-29 05:13:44 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #177: GFLOPs: 620.4854. Time: 373.5997 us. Best GFLOPs: 748.4102
2024-04-29 05:13:44 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #178: GFLOPs: 626.6806. Time: 369.9063 us. Best GFLOPs: 748.4102
2024-04-29 05:13:44 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #179: GFLOPs: 472.4531. Time: 490.6585 us. Best GFLOPs: 748.4102
2024-04-29 05:13:44 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #180: GFLOPs: 321.7576. Time: 720.4589 us. Best GFLOPs: 748.4102
2024-04-29 05:13:44 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #181: GFLOPs: 745.7201. Time: 310.8581 us. Best GFLOPs: 748.4102
2024-04-29 05:13:44 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #182: GFLOPs: 253.7089. Time: 913.6973 us. Best GFLOPs: 748.4102
2024-04-29 05:13:44 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #183: GFLOPs: 496.6217. Time: 466.7801 us. Best GFLOPs: 748.4102
2024-04-29 05:13:44 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #184: GFLOPs: 103.8328. Time: 2232.5614 us. Best GFLOPs: 748.4102
2024-04-29 05:13:44 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #185: GFLOPs: 297.8871. Time: 778.1912 us. Best GFLOPs: 748.4102
2024-04-29 05:13:44 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #186: GFLOPs: 100.1278. Time: 2315.1720 us. Best GFLOPs: 748.4102
2024-04-29 05:13:44 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #187: GFLOPs: 42.8253. Time: 5412.9929 us. Best GFLOPs: 748.4102
2024-04-29 05:13:44 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #188: GFLOPs: 477.1903. Time: 485.7876 us. Best GFLOPs: 748.4102
2024-04-29 05:13:44 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #189: GFLOPs: 566.8499. Time: 408.9498 us. Best GFLOPs: 748.4102
2024-04-29 05:13:44 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #190: GFLOPs: 4.9556. Time: 46778.3513 us. Best GFLOPs: 748.4102
2024-04-29 05:13:44 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #191: GFLOPs: 19.1509. Time: 12104.5727 us. Best GFLOPs: 748.4102
2024-04-29 05:13:44 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #192: GFLOPs: 24.3579. Time: 9516.9490 us. Best GFLOPs: 748.4102
2024-04-29 05:41:19 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 05:41:20 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-29 05:41:24 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x6d7cf18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3529928)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35fad28)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x42e62b8)]: 0 failure(s)
2024-04-29 05:41:24 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-29 05:41:38 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x6d7cf18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3529928)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35fad28)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x42e62b8)]: 0 failure(s)
2024-04-29 05:41:52 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x6d7cf18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3529928)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35fad28)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x42e62b8)]: 0 failure(s)
2024-04-29 05:42:06 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x6d7cf18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3529928)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35fad28)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x42e62b8)]: 0 failure(s)
2024-04-29 05:42:21 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x6d7cf18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3529928)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35fad28)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x42e62b8)]: 0 failure(s)
2024-04-29 05:42:30 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9614  0.9373  0.9373  0.9373  0.9363  0.9244  0.9244  0.9211  0.9211  0.9211  0.9094  0.9092  0.9020  0.8787  0.8738  0.8738
[17 : 32]:	0.8631  0.8609  0.8609  0.8605  0.8557  0.8557  0.8463  0.8463  0.8434  0.8392  0.8366  0.8287  0.8228  0.8195  0.8190  0.8190
[33 : 48]:	0.8139  0.8139  0.8118  0.8118  0.8085  0.8078  0.8024  0.8009  0.7992  0.7984  0.7971  0.7957  0.7950  0.7915  0.7911  0.7910
[49 : 64]:	0.7904  0.7898  0.7893  0.7888  0.7878  0.7873  0.7865  0.7841  0.7814  0.7813  0.7813  0.7811  0.7799  0.7789  0.7789  0.7770
2024-04-29 05:42:31 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 05:42:31 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 05:44:05 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #193: GFLOPs: 748.9230. Time: 309.5286 us. Best GFLOPs: 748.9230
2024-04-29 05:44:05 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #194: GFLOPs: 490.7981. Time: 472.3187 us. Best GFLOPs: 748.9230
2024-04-29 05:44:05 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #195: GFLOPs: 596.1546. Time: 388.8473 us. Best GFLOPs: 748.9230
2024-04-29 05:44:05 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #196: GFLOPs: 704.7301. Time: 328.9389 us. Best GFLOPs: 748.9230
2024-04-29 05:44:05 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #197: GFLOPs: 756.4891. Time: 306.4329 us. Best GFLOPs: 756.4891
2024-04-29 05:44:05 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #198: GFLOPs: 815.1736. Time: 284.3727 us. Best GFLOPs: 815.1736
2024-04-29 05:44:05 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #199: GFLOPs: 736.8695. Time: 314.5918 us. Best GFLOPs: 815.1736
2024-04-29 05:44:05 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #200: GFLOPs: 687.4650. Time: 337.1999 us. Best GFLOPs: 815.1736
2024-04-29 05:44:05 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #201: GFLOPs: 748.3238. Time: 309.7765 us. Best GFLOPs: 815.1736
2024-04-29 05:44:05 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #202: GFLOPs: 690.2746. Time: 335.8274 us. Best GFLOPs: 815.1736
2024-04-29 05:44:05 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #203: GFLOPs: 695.1709. Time: 333.4621 us. Best GFLOPs: 815.1736
2024-04-29 05:44:05 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #204: GFLOPs: 701.3925. Time: 330.5041 us. Best GFLOPs: 815.1736
2024-04-29 05:44:05 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #205: GFLOPs: 539.8253. Time: 429.4225 us. Best GFLOPs: 815.1736
2024-04-29 05:44:05 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #206: GFLOPs: 677.2162. Time: 342.3030 us. Best GFLOPs: 815.1736
2024-04-29 05:44:05 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #207: GFLOPs: 638.9920. Time: 362.7794 us. Best GFLOPs: 815.1736
2024-04-29 05:44:05 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #208: GFLOPs: 475.7883. Time: 487.2190 us. Best GFLOPs: 815.1736
2024-04-29 05:44:05 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #209: GFLOPs: 599.5291. Time: 386.6587 us. Best GFLOPs: 815.1736
2024-04-29 05:44:05 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #210: GFLOPs: 751.8287. Time: 308.3324 us. Best GFLOPs: 815.1736
2024-04-29 05:44:05 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #211: GFLOPs: 729.8741. Time: 317.6070 us. Best GFLOPs: 815.1736
2024-04-29 05:44:05 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #212: GFLOPs: 673.0266. Time: 344.4338 us. Best GFLOPs: 815.1736
2024-04-29 05:44:05 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #213: GFLOPs: 424.8893. Time: 545.5848 us. Best GFLOPs: 815.1736
2024-04-29 05:44:05 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #214: GFLOPs: 650.9064. Time: 356.1389 us. Best GFLOPs: 815.1736
2024-04-29 05:44:05 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #215: GFLOPs: 657.3398. Time: 352.6534 us. Best GFLOPs: 815.1736
2024-04-29 05:44:05 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #216: GFLOPs: 664.9410. Time: 348.6221 us. Best GFLOPs: 815.1736
2024-04-29 05:44:05 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #217: GFLOPs: 417.9748. Time: 554.6102 us. Best GFLOPs: 815.1736
2024-04-29 05:44:05 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #218: GFLOPs: 659.5646. Time: 351.4639 us. Best GFLOPs: 815.1736
2024-04-29 05:44:05 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #219: GFLOPs: 681.3635. Time: 340.2195 us. Best GFLOPs: 815.1736
2024-04-29 05:44:05 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #220: GFLOPs: 737.4098. Time: 314.3613 us. Best GFLOPs: 815.1736
2024-04-29 05:44:05 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #221: GFLOPs: 562.0833. Time: 412.4178 us. Best GFLOPs: 815.1736
2024-04-29 05:44:05 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #222: GFLOPs: 656.5089. Time: 353.0997 us. Best GFLOPs: 815.1736
2024-04-29 05:44:05 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #223: GFLOPs: 627.4123. Time: 369.4749 us. Best GFLOPs: 815.1736
2024-04-29 05:44:05 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #224: GFLOPs: 631.2581. Time: 367.2240 us. Best GFLOPs: 815.1736
2024-04-29 05:44:05 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #225: GFLOPs: 319.2458. Time: 726.1273 us. Best GFLOPs: 815.1736
2024-04-29 05:44:05 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #226: GFLOPs: 238.6867. Time: 971.2025 us. Best GFLOPs: 815.1736
2024-04-29 05:44:05 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #227: GFLOPs: 389.6811. Time: 594.8791 us. Best GFLOPs: 815.1736
2024-04-29 05:44:05 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #228: GFLOPs: 744.2252. Time: 311.4825 us. Best GFLOPs: 815.1736
2024-04-29 05:44:05 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #229: GFLOPs: 576.3217. Time: 402.2287 us. Best GFLOPs: 815.1736
2024-04-29 05:44:05 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #230: GFLOPs: 695.2639. Time: 333.4175 us. Best GFLOPs: 815.1736
2024-04-29 05:44:05 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #231: GFLOPs: 541.1854. Time: 428.3432 us. Best GFLOPs: 815.1736
2024-04-29 05:44:05 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #232: GFLOPs: 714.6775. Time: 324.3604 us. Best GFLOPs: 815.1736
2024-04-29 05:44:05 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #233: GFLOPs: 494.0967. Time: 469.1654 us. Best GFLOPs: 815.1736
2024-04-29 05:44:05 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #234: GFLOPs: 567.6925. Time: 408.3427 us. Best GFLOPs: 815.1736
2024-04-29 05:44:05 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #235: GFLOPs: 574.6671. Time: 403.3868 us. Best GFLOPs: 815.1736
2024-04-29 05:44:05 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #236: GFLOPs: 634.8112. Time: 365.1686 us. Best GFLOPs: 815.1736
2024-04-29 05:44:05 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #237: GFLOPs: 463.5221. Time: 500.1124 us. Best GFLOPs: 815.1736
2024-04-29 05:44:05 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #238: GFLOPs: 627.0841. Time: 369.6683 us. Best GFLOPs: 815.1736
2024-04-29 05:44:05 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #239: GFLOPs: 563.6361. Time: 411.2815 us. Best GFLOPs: 815.1736
2024-04-29 05:44:05 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #240: GFLOPs: 624.5991. Time: 371.1391 us. Best GFLOPs: 815.1736
2024-04-29 05:44:05 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #241: GFLOPs: 613.6819. Time: 377.7415 us. Best GFLOPs: 815.1736
2024-04-29 05:44:05 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #242: GFLOPs: 606.1313. Time: 382.4471 us. Best GFLOPs: 815.1736
2024-04-29 05:44:05 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #243: GFLOPs: 684.3147. Time: 338.7522 us. Best GFLOPs: 815.1736
2024-04-29 05:44:05 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #244: GFLOPs: 614.6120. Time: 377.1699 us. Best GFLOPs: 815.1736
2024-04-29 05:44:05 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #245: GFLOPs: 670.2929. Time: 345.8385 us. Best GFLOPs: 815.1736
2024-04-29 05:44:05 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #246: GFLOPs: 530.1520. Time: 437.2578 us. Best GFLOPs: 815.1736
2024-04-29 05:44:05 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #247: GFLOPs: 605.4872. Time: 382.8539 us. Best GFLOPs: 815.1736
2024-04-29 05:44:05 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #248: GFLOPs: 685.2388. Time: 338.2954 us. Best GFLOPs: 815.1736
2024-04-29 05:44:05 [INFO] [task_scheduler.cc:121] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #249: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(56), T.int64(56), T.int64(64)), "float32"), p1: T.Buffer((T.int64(2), T.int64(1), T.int64(3), T.int64(3), T.int64(64), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(32)), "float32"), p3: T.Buffer((T.int64(1), T.int64(2), T.int64(56), T.int64(56), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(2), T.int64(56), T.int64(56), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(58), T.int64(58), T.int64(64)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(56), T.int64(56), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused in T.parallel(T.int64(392), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(32), T.int64(1), T.int64(1), T.int64(4), T.int64(1), T.int64(1)):
                with T.block("conv2d_NCHWc_init"):
                    v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                    v_oc_chunk = T.axis.spatial(T.int64(2), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(56) // T.int64(28) + oc_chunk_2_init + oc_chunk_3_init)
                    v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(56) * T.int64(8) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(28) // T.int64(14) * T.int64(4) + oh_2_init * T.int64(4) + oh_3_init)
                    v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(14) * T.int64(4) + ow_2_init + ow_3_init)
                    v_oc_block = T.axis.spatial(T.int64(32), oc_block_2_init + oc_block_3_init)
                    T.reads()
                    T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                    T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                    conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
            for ic_0, kh_0 in T.grid(T.int64(16), T.int64(3)):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(6)):
                    for ax4_fused in T.vectorized(T.int64(4)):
                        with T.block("data_pad"):
                            v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                            v_i2 = T.axis.spatial(T.int64(58), kh_0 + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(56) * T.int64(8) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(28) // T.int64(14) * T.int64(4) + ax2)
                            v_i3 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(14) * T.int64(4) + ax3)
                            v_i4 = T.axis.spatial(T.int64(64), ic_0 * T.int64(4) + ax4_fused)
                            T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                            T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                            data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(57) and T.int64(1) <= v_i3 and v_i3 < T.int64(57), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                for kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(32), T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(2), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(56) // T.int64(28) + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(56) * T.int64(8) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(28) // T.int64(14) * T.int64(4) + oh_2 * T.int64(4) + oh_3)
                        v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(14) * T.int64(4) + ow_2 + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(64), ic_0 * T.int64(4) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(64), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(64)], p1[v_oc_chunk, v_ic // T.int64(64), v_kh, v_kw, v_ic % T.int64(64), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(64), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(64)] * p1[v_oc_chunk, v_ic // T.int64(64), v_kh, v_kw, v_ic % T.int64(64), v_oc_block]
        for ax0_ax1_ax2_ax3_ax4_fused_0 in T.parallel(T.int64(3136)):
            for ax0_ax1_ax2_ax3_ax4_fused_1 in T.vectorized(T.int64(64)):
                with T.block("T_relu"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(2), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) // T.int64(100352))
                    v_ax2 = T.axis.spatial(T.int64(56), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(100352) // T.int64(1792))
                    v_ax3 = T.axis.spatial(T.int64(56), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(1792) // T.int64(32))
                    v_ax4 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(32))
                    T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 2, 1, 1])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[7, 2, 1, 4])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 14, 4, 1])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[1, 1, 32, 1])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[16, 4])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[3, 1])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=11)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87 = sch.get_loops(block=b68)
l88 = sch.fuse(l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, preserve_unit_iters=True)
sch.parallel(loop=l88)
l89 = sch.fuse(l87, preserve_unit_iters=True)
sch.vectorize(loop=l89)
l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106 = sch.get_loops(block=b69)
l107 = sch.fuse(l90, preserve_unit_iters=True)
sch.parallel(loop=l107)
sch.annotate(block_or_loop=l107, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l107, ann_key="pragma_unroll_explicit", ann_val=1)
l108, l109, l110, l111, l112 = sch.get_loops(block=b70)
l113 = sch.fuse(l108, l109, l110, l111, l112, preserve_unit_iters=True)
l114, l115 = sch.split(loop=l113, factors=[None, 64], preserve_unit_iters=True)
sch.parallel(loop=l114)
sch.vectorize(loop=l115)
b116 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133 = sch.get_loops(block=b116)
b134 = sch.decompose_reduction(block=b116, loop=l118)
2024-04-29 05:44:05 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #250: GFLOPs: 621.1646. Time: 373.1912 us. Best GFLOPs: 815.1736
2024-04-29 05:44:05 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #251: GFLOPs: 631.7017. Time: 366.9661 us. Best GFLOPs: 815.1736
2024-04-29 05:44:05 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #252: GFLOPs: 595.3531. Time: 389.3708 us. Best GFLOPs: 815.1736
2024-04-29 05:44:05 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #253: GFLOPs: 546.0259. Time: 424.5460 us. Best GFLOPs: 815.1736
2024-04-29 05:44:05 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #254: GFLOPs: 69.8424. Time: 3319.0882 us. Best GFLOPs: 815.1736
2024-04-29 05:44:05 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #255: GFLOPs: 163.2283. Time: 1420.1775 us. Best GFLOPs: 815.1736
2024-04-29 05:44:05 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #256: GFLOPs: 31.4593. Time: 7368.6607 us. Best GFLOPs: 815.1736
2024-04-29 05:44:05 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 05:44:06 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-29 05:44:10 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x6d7cf18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3529928)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35fad28)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x42e62b8)]: 0 failure(s)
2024-04-29 05:44:10 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-29 05:44:24 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x6d7cf18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3529928)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35fad28)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x42e62b8)]: 0 failure(s)
2024-04-29 05:44:38 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x6d7cf18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3529928)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35fad28)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x42e62b8)]: 0 failure(s)
2024-04-29 05:44:52 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x6d7cf18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3529928)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35fad28)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x42e62b8)]: 0 failure(s)
2024-04-29 05:45:07 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x6d7cf18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3529928)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35fad28)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x42e62b8)]: 0 failure(s)
2024-04-29 05:45:16 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9829  0.9549  0.9280  0.9082  0.8987  0.8983  0.8983  0.8857  0.8763  0.8660  0.8612  0.8612  0.8558  0.8482  0.8477  0.8449
[17 : 32]:	0.8449  0.8441  0.8439  0.8434  0.8349  0.8336  0.8321  0.8286  0.8253  0.8118  0.8102  0.8062  0.8047  0.8047  0.8045  0.8035
[33 : 48]:	0.8013  0.8000  0.7956  0.7876  0.7875  0.7869  0.7825  0.7818  0.7813  0.7802  0.7781  0.7779  0.7774  0.7772  0.7772  0.7768
[49 : 64]:	0.7765  0.7764  0.7745  0.7726  0.7708  0.7698  0.7687  0.7686  0.7686  0.7676  0.7673  0.7662  0.7658  0.7658  0.7651  0.7650
2024-04-29 05:45:16 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 05:45:16 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 05:46:28 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #257: GFLOPs: 416.6239. Time: 556.4086 us. Best GFLOPs: 815.1736
2024-04-29 05:46:28 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #258: GFLOPs: 885.9597. Time: 261.6520 us. Best GFLOPs: 885.9597
2024-04-29 05:46:28 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #259: GFLOPs: 748.4740. Time: 309.7143 us. Best GFLOPs: 885.9597
2024-04-29 05:46:28 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #260: GFLOPs: 507.3697. Time: 456.8919 us. Best GFLOPs: 885.9597
2024-04-29 05:46:28 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #261: GFLOPs: 804.5011. Time: 288.1452 us. Best GFLOPs: 885.9597
2024-04-29 05:46:28 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #262: GFLOPs: 741.5641. Time: 312.6002 us. Best GFLOPs: 885.9597
2024-04-29 05:46:28 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #263: GFLOPs: 739.2681. Time: 313.5711 us. Best GFLOPs: 885.9597
2024-04-29 05:46:28 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #264: GFLOPs: 742.9061. Time: 312.0355 us. Best GFLOPs: 885.9597
2024-04-29 05:46:28 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #265: GFLOPs: 738.7459. Time: 313.7928 us. Best GFLOPs: 885.9597
2024-04-29 05:46:28 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #266: GFLOPs: 787.9656. Time: 294.1919 us. Best GFLOPs: 885.9597
2024-04-29 05:46:28 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #267: GFLOPs: 670.3276. Time: 345.8206 us. Best GFLOPs: 885.9597
2024-04-29 05:46:28 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #268: GFLOPs: 695.2232. Time: 333.4370 us. Best GFLOPs: 885.9597
2024-04-29 05:46:28 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #269: GFLOPs: 733.6003. Time: 315.9938 us. Best GFLOPs: 885.9597
2024-04-29 05:46:28 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #270: GFLOPs: 681.7755. Time: 340.0139 us. Best GFLOPs: 885.9597
2024-04-29 05:46:28 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #271: GFLOPs: 699.0934. Time: 331.5911 us. Best GFLOPs: 885.9597
2024-04-29 05:46:28 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #272: GFLOPs: 839.6224. Time: 276.0921 us. Best GFLOPs: 885.9597
2024-04-29 05:46:28 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #273: GFLOPs: 810.2384. Time: 286.1048 us. Best GFLOPs: 885.9597
2024-04-29 05:46:28 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #274: GFLOPs: 686.9330. Time: 337.4610 us. Best GFLOPs: 885.9597
2024-04-29 05:46:28 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #275: GFLOPs: 612.8963. Time: 378.2257 us. Best GFLOPs: 885.9597
2024-04-29 05:46:28 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #276: GFLOPs: 503.8797. Time: 460.0565 us. Best GFLOPs: 885.9597
2024-04-29 05:46:28 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #277: GFLOPs: 681.0025. Time: 340.3998 us. Best GFLOPs: 885.9597
2024-04-29 05:46:28 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #278: GFLOPs: 883.2489. Time: 262.4550 us. Best GFLOPs: 885.9597
2024-04-29 05:46:28 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #279: GFLOPs: 392.1710. Time: 591.1021 us. Best GFLOPs: 885.9597
2024-04-29 05:46:28 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #280: GFLOPs: 766.0592. Time: 302.6047 us. Best GFLOPs: 885.9597
2024-04-29 05:46:28 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #281: GFLOPs: 586.9829. Time: 394.9231 us. Best GFLOPs: 885.9597
2024-04-29 05:46:28 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #282: GFLOPs: 742.7859. Time: 312.0860 us. Best GFLOPs: 885.9597
2024-04-29 05:46:28 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #283: GFLOPs: 700.0897. Time: 331.1192 us. Best GFLOPs: 885.9597
2024-04-29 05:46:28 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #284: GFLOPs: 682.1896. Time: 339.8075 us. Best GFLOPs: 885.9597
2024-04-29 05:46:28 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #285: GFLOPs: 774.2865. Time: 299.3893 us. Best GFLOPs: 885.9597
2024-04-29 05:46:28 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #286: GFLOPs: 670.9832. Time: 345.4827 us. Best GFLOPs: 885.9597
2024-04-29 05:46:28 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #287: GFLOPs: 661.1047. Time: 350.6451 us. Best GFLOPs: 885.9597
2024-04-29 05:46:28 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #288: GFLOPs: 289.3617. Time: 801.1189 us. Best GFLOPs: 885.9597
2024-04-29 05:46:28 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #289: GFLOPs: 671.9839. Time: 344.9683 us. Best GFLOPs: 885.9597
2024-04-29 05:46:28 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #290: GFLOPs: 709.4698. Time: 326.7413 us. Best GFLOPs: 885.9597
2024-04-29 05:46:28 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #291: GFLOPs: 541.3582. Time: 428.2065 us. Best GFLOPs: 885.9597
2024-04-29 05:46:28 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #292: GFLOPs: 721.9886. Time: 321.0759 us. Best GFLOPs: 885.9597
2024-04-29 05:46:28 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #293: GFLOPs: 1106.1208. Time: 209.5731 us. Best GFLOPs: 1106.1208
2024-04-29 05:46:28 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #294: GFLOPs: 590.8423. Time: 392.3435 us. Best GFLOPs: 1106.1208
2024-04-29 05:46:28 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #295: GFLOPs: 436.3229. Time: 531.2880 us. Best GFLOPs: 1106.1208
2024-04-29 05:46:28 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #296: GFLOPs: 555.0213. Time: 417.6653 us. Best GFLOPs: 1106.1208
2024-04-29 05:46:28 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #297: GFLOPs: 500.2002. Time: 463.4407 us. Best GFLOPs: 1106.1208
2024-04-29 05:46:28 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #298: GFLOPs: 496.5183. Time: 466.8773 us. Best GFLOPs: 1106.1208
2024-04-29 05:46:28 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #299: GFLOPs: 526.0841. Time: 440.6389 us. Best GFLOPs: 1106.1208
2024-04-29 05:46:28 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #300: GFLOPs: 636.8387. Time: 364.0060 us. Best GFLOPs: 1106.1208
2024-04-29 05:46:28 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #301: GFLOPs: 631.8337. Time: 366.8895 us. Best GFLOPs: 1106.1208
2024-04-29 05:46:28 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #302: GFLOPs: 285.3563. Time: 812.3638 us. Best GFLOPs: 1106.1208
2024-04-29 05:46:28 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #303: GFLOPs: 384.4432. Time: 602.9841 us. Best GFLOPs: 1106.1208
2024-04-29 05:46:28 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #304: GFLOPs: 519.2079. Time: 446.4746 us. Best GFLOPs: 1106.1208
2024-04-29 05:46:28 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #305: GFLOPs: 596.0823. Time: 388.8945 us. Best GFLOPs: 1106.1208
2024-04-29 05:46:28 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #306: GFLOPs: 893.9264. Time: 259.3201 us. Best GFLOPs: 1106.1208
2024-04-29 05:46:28 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #307: GFLOPs: 509.4828. Time: 454.9969 us. Best GFLOPs: 1106.1208
2024-04-29 05:46:28 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #308: GFLOPs: 550.2731. Time: 421.2692 us. Best GFLOPs: 1106.1208
2024-04-29 05:46:28 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #309: GFLOPs: 647.1988. Time: 358.1792 us. Best GFLOPs: 1106.1208
2024-04-29 05:46:28 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #310: GFLOPs: 125.3231. Time: 1849.7241 us. Best GFLOPs: 1106.1208
2024-04-29 05:46:28 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #311: GFLOPs: 564.6650. Time: 410.5321 us. Best GFLOPs: 1106.1208
2024-04-29 05:46:28 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #312: GFLOPs: 535.3643. Time: 433.0007 us. Best GFLOPs: 1106.1208
2024-04-29 05:46:28 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #313: GFLOPs: 529.4335. Time: 437.8513 us. Best GFLOPs: 1106.1208
2024-04-29 05:46:28 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #314: GFLOPs: 136.5407. Time: 1697.7581 us. Best GFLOPs: 1106.1208
2024-04-29 05:46:28 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #315: GFLOPs: 425.2883. Time: 545.0729 us. Best GFLOPs: 1106.1208
2024-04-29 05:46:28 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #316: GFLOPs: 695.6550. Time: 333.2300 us. Best GFLOPs: 1106.1208
2024-04-29 05:46:28 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #317: GFLOPs: 533.6497. Time: 434.3919 us. Best GFLOPs: 1106.1208
2024-04-29 05:46:28 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #318: GFLOPs: 4.3203. Time: 53656.6107 us. Best GFLOPs: 1106.1208
2024-04-29 05:46:28 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #319: GFLOPs: 38.4917. Time: 6022.4181 us. Best GFLOPs: 1106.1208
2024-04-29 05:46:28 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #320: GFLOPs: 34.9324. Time: 6636.0409 us. Best GFLOPs: 1106.1208
2024-04-29 06:35:50 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 06:35:51 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-29 06:35:55 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x6d7cf18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3529928)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35fad28)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x42e62b8)]: 0 failure(s)
2024-04-29 06:35:55 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-29 06:36:08 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x6d7cf18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3529928)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35fad28)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x42e62b8)]: 0 failure(s)
2024-04-29 06:36:23 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x6d7cf18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3529928)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35fad28)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x42e62b8)]: 0 failure(s)
2024-04-29 06:36:37 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x6d7cf18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3529928)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35fad28)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x42e62b8)]: 0 failure(s)
2024-04-29 06:36:51 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x6d7cf18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3529928)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35fad28)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x42e62b8)]: 0 failure(s)
2024-04-29 06:37:01 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9222  0.8481  0.8481  0.7866  0.7727  0.7651  0.7651  0.7548  0.7517  0.7491  0.7386  0.7321  0.7218  0.7146  0.7110  0.7075
[17 : 32]:	0.7033  0.7012  0.6986  0.6986  0.6972  0.6959  0.6903  0.6888  0.6818  0.6802  0.6781  0.6760  0.6753  0.6747  0.6703  0.6702
[33 : 48]:	0.6623  0.6592  0.6585  0.6562  0.6553  0.6532  0.6513  0.6503  0.6500  0.6489  0.6431  0.6410  0.6394  0.6378  0.6362  0.6352
[49 : 64]:	0.6352  0.6343  0.6325  0.6322  0.6318  0.6313  0.6283  0.6235  0.6232  0.6230  0.6212  0.6210  0.6209  0.6208  0.6191  0.6189
2024-04-29 06:37:01 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 06:37:01 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 06:38:24 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #321: GFLOPs: 1076.4509. Time: 215.3495 us. Best GFLOPs: 1106.1208
2024-04-29 06:38:24 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #322: GFLOPs: 1048.2091. Time: 221.1516 us. Best GFLOPs: 1106.1208
2024-04-29 06:38:24 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #323: GFLOPs: 1082.7091. Time: 214.1047 us. Best GFLOPs: 1106.1208
2024-04-29 06:38:24 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #324: GFLOPs: 974.7548. Time: 237.8169 us. Best GFLOPs: 1106.1208
2024-04-29 06:38:24 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #325: GFLOPs: 882.6420. Time: 262.6355 us. Best GFLOPs: 1106.1208
2024-04-29 06:38:24 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #326: GFLOPs: 878.8521. Time: 263.7681 us. Best GFLOPs: 1106.1208
2024-04-29 06:38:24 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #327: GFLOPs: 870.4048. Time: 266.3279 us. Best GFLOPs: 1106.1208
2024-04-29 06:38:24 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #328: GFLOPs: 632.1157. Time: 366.7258 us. Best GFLOPs: 1106.1208
2024-04-29 06:38:24 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #329: GFLOPs: 1076.5384. Time: 215.3320 us. Best GFLOPs: 1106.1208
2024-04-29 06:38:24 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #330: GFLOPs: 624.0531. Time: 371.4637 us. Best GFLOPs: 1106.1208
2024-04-29 06:38:24 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #331: GFLOPs: 854.5708. Time: 271.2626 us. Best GFLOPs: 1106.1208
2024-04-29 06:38:24 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #332: GFLOPs: 788.8355. Time: 293.8675 us. Best GFLOPs: 1106.1208
2024-04-29 06:38:24 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #333: GFLOPs: 1007.2467. Time: 230.1453 us. Best GFLOPs: 1106.1208
2024-04-29 06:38:24 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #334: GFLOPs: 888.2824. Time: 260.9678 us. Best GFLOPs: 1106.1208
2024-04-29 06:38:24 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #335: GFLOPs: 157.4008. Time: 1472.7573 us. Best GFLOPs: 1106.1208
2024-04-29 06:38:24 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #336: GFLOPs: 804.9167. Time: 287.9964 us. Best GFLOPs: 1106.1208
2024-04-29 06:38:24 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #337: GFLOPs: 894.4246. Time: 259.1757 us. Best GFLOPs: 1106.1208
2024-04-29 06:38:24 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #338: GFLOPs: 1079.5954. Time: 214.7222 us. Best GFLOPs: 1106.1208
2024-04-29 06:38:24 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #339: GFLOPs: 745.2652. Time: 311.0478 us. Best GFLOPs: 1106.1208
2024-04-29 06:38:24 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #340: GFLOPs: 717.4480. Time: 323.1079 us. Best GFLOPs: 1106.1208
2024-04-29 06:38:24 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #341: GFLOPs: 694.2279. Time: 333.9150 us. Best GFLOPs: 1106.1208
2024-04-29 06:38:24 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #342: GFLOPs: 766.5839. Time: 302.3976 us. Best GFLOPs: 1106.1208
2024-04-29 06:38:24 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #343: GFLOPs: 765.5464. Time: 302.8074 us. Best GFLOPs: 1106.1208
2024-04-29 06:38:24 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #344: GFLOPs: 724.1306. Time: 320.1261 us. Best GFLOPs: 1106.1208
2024-04-29 06:38:24 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #345: GFLOPs: 1032.3270. Time: 224.5540 us. Best GFLOPs: 1106.1208
2024-04-29 06:38:24 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #346: GFLOPs: 1033.6700. Time: 224.2622 us. Best GFLOPs: 1106.1208
2024-04-29 06:38:24 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #347: GFLOPs: 1184.3975. Time: 195.7224 us. Best GFLOPs: 1184.3975
2024-04-29 06:38:24 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #348: GFLOPs: 745.7127. Time: 310.8612 us. Best GFLOPs: 1184.3975
2024-04-29 06:38:24 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #349: GFLOPs: 755.9560. Time: 306.6490 us. Best GFLOPs: 1184.3975
2024-04-29 06:38:24 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #350: GFLOPs: 746.1913. Time: 310.6618 us. Best GFLOPs: 1184.3975
2024-04-29 06:38:24 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #351: GFLOPs: 861.1311. Time: 269.1961 us. Best GFLOPs: 1184.3975
2024-04-29 06:38:24 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #352: GFLOPs: 791.8890. Time: 292.7344 us. Best GFLOPs: 1184.3975
2024-04-29 06:38:24 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #353: GFLOPs: 876.2665. Time: 264.5464 us. Best GFLOPs: 1184.3975
2024-04-29 06:38:24 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #354: GFLOPs: 782.0910. Time: 296.4017 us. Best GFLOPs: 1184.3975
2024-04-29 06:38:24 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #355: GFLOPs: 772.5498. Time: 300.0623 us. Best GFLOPs: 1184.3975
2024-04-29 06:38:24 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #356: GFLOPs: 824.3787. Time: 281.1974 us. Best GFLOPs: 1184.3975
2024-04-29 06:38:24 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #357: GFLOPs: 848.0912. Time: 273.3351 us. Best GFLOPs: 1184.3975
2024-04-29 06:38:24 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #358: GFLOPs: 803.5150. Time: 288.4988 us. Best GFLOPs: 1184.3975
2024-04-29 06:38:24 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #359: GFLOPs: 550.3220. Time: 421.2318 us. Best GFLOPs: 1184.3975
2024-04-29 06:38:24 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #360: GFLOPs: 505.5908. Time: 458.4994 us. Best GFLOPs: 1184.3975
2024-04-29 06:38:24 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #361: GFLOPs: 11.7033. Time: 19807.5342 us. Best GFLOPs: 1184.3975
2024-04-29 06:38:24 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #362: GFLOPs: 637.3057. Time: 363.7393 us. Best GFLOPs: 1184.3975
2024-04-29 06:38:24 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #363: GFLOPs: 756.1807. Time: 306.5579 us. Best GFLOPs: 1184.3975
2024-04-29 06:38:24 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #364: GFLOPs: 746.7233. Time: 310.4404 us. Best GFLOPs: 1184.3975
2024-04-29 06:38:24 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #365: GFLOPs: 760.8601. Time: 304.6725 us. Best GFLOPs: 1184.3975
2024-04-29 06:38:24 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #366: GFLOPs: 776.2629. Time: 298.6271 us. Best GFLOPs: 1184.3975
2024-04-29 06:38:24 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #367: GFLOPs: 703.8309. Time: 329.3591 us. Best GFLOPs: 1184.3975
2024-04-29 06:38:24 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #368: GFLOPs: 495.9954. Time: 467.3695 us. Best GFLOPs: 1184.3975
2024-04-29 06:38:24 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #369: GFLOPs: 714.2233. Time: 324.5668 us. Best GFLOPs: 1184.3975
2024-04-29 06:38:24 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #370: GFLOPs: 651.0880. Time: 356.0396 us. Best GFLOPs: 1184.3975
2024-04-29 06:38:24 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #371: GFLOPs: 612.8038. Time: 378.2828 us. Best GFLOPs: 1184.3975
2024-04-29 06:38:24 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #372: GFLOPs: 612.8007. Time: 378.2847 us. Best GFLOPs: 1184.3975
2024-04-29 06:38:24 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #373: GFLOPs: 687.7621. Time: 337.0542 us. Best GFLOPs: 1184.3975
2024-04-29 06:38:24 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #374: GFLOPs: 418.9910. Time: 553.2652 us. Best GFLOPs: 1184.3975
2024-04-29 06:38:24 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #375: GFLOPs: 737.6775. Time: 314.2472 us. Best GFLOPs: 1184.3975
2024-04-29 06:38:24 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #376: GFLOPs: 707.8921. Time: 327.4696 us. Best GFLOPs: 1184.3975
2024-04-29 06:38:24 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #377: GFLOPs: 723.1577. Time: 320.5568 us. Best GFLOPs: 1184.3975
2024-04-29 06:38:24 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #378: GFLOPs: 633.7733. Time: 365.7666 us. Best GFLOPs: 1184.3975
2024-04-29 06:38:24 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #379: GFLOPs: 737.4818. Time: 314.3306 us. Best GFLOPs: 1184.3975
2024-04-29 06:38:24 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #380: GFLOPs: 709.7692. Time: 326.6035 us. Best GFLOPs: 1184.3975
2024-04-29 06:38:24 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #381: GFLOPs: 682.0540. Time: 339.8750 us. Best GFLOPs: 1184.3975
2024-04-29 06:38:24 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #382: GFLOPs: 2.4124. Time: 96090.8400 us. Best GFLOPs: 1184.3975
2024-04-29 06:38:24 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #383: GFLOPs: 82.4058. Time: 2813.0690 us. Best GFLOPs: 1184.3975
2024-04-29 06:38:24 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #384: GFLOPs: 10.1934. Time: 22741.5674 us. Best GFLOPs: 1184.3975
2024-04-29 06:59:36 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 06:59:37 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-29 06:59:42 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x6d7cf18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3529928)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35fad28)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x42e62b8)]: 0 failure(s)
2024-04-29 06:59:42 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-29 06:59:55 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x6d7cf18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3529928)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35fad28)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x42e62b8)]: 0 failure(s)
2024-04-29 07:00:09 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x6d7cf18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3529928)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35fad28)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x42e62b8)]: 0 failure(s)
2024-04-29 07:00:23 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x6d7cf18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3529928)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35fad28)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x42e62b8)]: 0 failure(s)
2024-04-29 07:00:37 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x6d7cf18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3529928)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35fad28)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x42e62b8)]: 0 failure(s)
2024-04-29 07:00:46 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.8995  0.8960  0.8956  0.8687  0.8687  0.8654  0.8288  0.8019  0.7880  0.7791  0.7742  0.7722  0.7702  0.7672  0.7643  0.7642
[17 : 32]:	0.7622  0.7622  0.7614  0.7600  0.7520  0.7477  0.7455  0.7422  0.7422  0.7393  0.7365  0.7323  0.7320  0.7298  0.7297  0.7289
[33 : 48]:	0.7278  0.7205  0.7203  0.7151  0.7119  0.7094  0.7087  0.7002  0.7002  0.6992  0.6974  0.6966  0.6930  0.6925  0.6902  0.6902
[49 : 64]:	0.6889  0.6877  0.6872  0.6854  0.6832  0.6817  0.6745  0.6675  0.6655  0.6648  0.6640  0.6623  0.6614  0.6612  0.6593  0.6579
2024-04-29 07:00:46 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 07:00:46 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 07:02:22 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #385: GFLOPs: 580.8312. Time: 399.1058 us. Best GFLOPs: 1184.3975
2024-04-29 07:02:22 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #386: GFLOPs: 535.4061. Time: 432.9669 us. Best GFLOPs: 1184.3975
2024-04-29 07:02:22 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #387: GFLOPs: 766.7558. Time: 302.3298 us. Best GFLOPs: 1184.3975
2024-04-29 07:02:22 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #388: GFLOPs: 1102.0075. Time: 210.3553 us. Best GFLOPs: 1184.3975
2024-04-29 07:02:22 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #389: GFLOPs: 1079.5554. Time: 214.7302 us. Best GFLOPs: 1184.3975
2024-04-29 07:02:22 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #390: GFLOPs: 986.7991. Time: 234.9142 us. Best GFLOPs: 1184.3975
2024-04-29 07:02:22 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #391: GFLOPs: 1103.9269. Time: 209.9896 us. Best GFLOPs: 1184.3975
2024-04-29 07:02:22 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #392: GFLOPs: 861.7178. Time: 269.0128 us. Best GFLOPs: 1184.3975
2024-04-29 07:02:22 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #393: GFLOPs: 985.0014. Time: 235.3429 us. Best GFLOPs: 1184.3975
2024-04-29 07:02:22 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #394: GFLOPs: 937.8631. Time: 247.1716 us. Best GFLOPs: 1184.3975
2024-04-29 07:02:22 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #395: GFLOPs: 690.7691. Time: 335.5870 us. Best GFLOPs: 1184.3975
2024-04-29 07:02:22 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #396: GFLOPs: 989.9225. Time: 234.1730 us. Best GFLOPs: 1184.3975
2024-04-29 07:02:22 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #397: GFLOPs: 759.4906. Time: 305.2218 us. Best GFLOPs: 1184.3975
2024-04-29 07:02:22 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #398: GFLOPs: 775.5985. Time: 298.8829 us. Best GFLOPs: 1184.3975
2024-04-29 07:02:22 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #399: GFLOPs: 882.5985. Time: 262.6484 us. Best GFLOPs: 1184.3975
2024-04-29 07:02:22 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #400: GFLOPs: 823.9593. Time: 281.3405 us. Best GFLOPs: 1184.3975
2024-04-29 07:02:22 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #401: GFLOPs: 204.4085. Time: 1134.0681 us. Best GFLOPs: 1184.3975
2024-04-29 07:02:22 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #402: GFLOPs: 204.7170. Time: 1132.3589 us. Best GFLOPs: 1184.3975
2024-04-29 07:02:22 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #403: GFLOPs: 757.4957. Time: 306.0256 us. Best GFLOPs: 1184.3975
2024-04-29 07:02:22 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #404: GFLOPs: 692.9890. Time: 334.5120 us. Best GFLOPs: 1184.3975
2024-04-29 07:02:22 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #405: GFLOPs: 493.4171. Time: 469.8117 us. Best GFLOPs: 1184.3975
2024-04-29 07:02:22 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #406: GFLOPs: 997.5606. Time: 232.3800 us. Best GFLOPs: 1184.3975
2024-04-29 07:02:22 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #407: GFLOPs: 670.7012. Time: 345.6280 us. Best GFLOPs: 1184.3975
2024-04-29 07:02:22 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #408: GFLOPs: 878.8472. Time: 263.7695 us. Best GFLOPs: 1184.3975
2024-04-29 07:02:22 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #409: GFLOPs: 873.0696. Time: 265.5151 us. Best GFLOPs: 1184.3975
2024-04-29 07:02:22 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #410: GFLOPs: 109.4076. Time: 2118.8034 us. Best GFLOPs: 1184.3975
2024-04-29 07:02:22 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #411: GFLOPs: 853.3343. Time: 271.6557 us. Best GFLOPs: 1184.3975
2024-04-29 07:02:22 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #412: GFLOPs: 204.4912. Time: 1133.6094 us. Best GFLOPs: 1184.3975
2024-04-29 07:02:22 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #413: GFLOPs: 859.3645. Time: 269.7495 us. Best GFLOPs: 1184.3975
2024-04-29 07:02:22 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #414: GFLOPs: 682.7967. Time: 339.5053 us. Best GFLOPs: 1184.3975
2024-04-29 07:02:22 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #415: GFLOPs: 718.6561. Time: 322.5647 us. Best GFLOPs: 1184.3975
2024-04-29 07:02:22 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #416: GFLOPs: 1054.1414. Time: 219.9070 us. Best GFLOPs: 1184.3975
2024-04-29 07:02:22 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #417: GFLOPs: 869.7179. Time: 266.5383 us. Best GFLOPs: 1184.3975
2024-04-29 07:02:22 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #418: GFLOPs: 326.1241. Time: 710.8126 us. Best GFLOPs: 1184.3975
2024-04-29 07:02:22 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #419: GFLOPs: 876.9028. Time: 264.3544 us. Best GFLOPs: 1184.3975
2024-04-29 07:02:22 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #420: GFLOPs: 684.0218. Time: 338.8973 us. Best GFLOPs: 1184.3975
2024-04-29 07:02:22 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #421: GFLOPs: 762.0823. Time: 304.1838 us. Best GFLOPs: 1184.3975
2024-04-29 07:02:22 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #422: GFLOPs: 820.9722. Time: 282.3641 us. Best GFLOPs: 1184.3975
2024-04-29 07:02:22 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #423: GFLOPs: 1026.3327. Time: 225.8655 us. Best GFLOPs: 1184.3975
2024-04-29 07:02:22 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #424: GFLOPs: 163.6775. Time: 1416.2800 us. Best GFLOPs: 1184.3975
2024-04-29 07:02:22 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #425: GFLOPs: 164.5951. Time: 1408.3843 us. Best GFLOPs: 1184.3975
2024-04-29 07:02:22 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #426: GFLOPs: 793.4731. Time: 292.1499 us. Best GFLOPs: 1184.3975
2024-04-29 07:02:22 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #427: GFLOPs: 1187.2393. Time: 195.2539 us. Best GFLOPs: 1187.2393
2024-04-29 07:02:22 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #428: GFLOPs: 754.6084. Time: 307.1966 us. Best GFLOPs: 1187.2393
2024-04-29 07:02:22 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #429: GFLOPs: 752.6791. Time: 307.9840 us. Best GFLOPs: 1187.2393
2024-04-29 07:02:22 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #430: GFLOPs: 1037.2041. Time: 223.4981 us. Best GFLOPs: 1187.2393
2024-04-29 07:02:22 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #431: GFLOPs: 699.8624. Time: 331.2267 us. Best GFLOPs: 1187.2393
2024-04-29 07:02:22 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #432: GFLOPs: 780.7125. Time: 296.9251 us. Best GFLOPs: 1187.2393
2024-04-29 07:02:22 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #433: GFLOPs: 972.4190. Time: 238.3881 us. Best GFLOPs: 1187.2393
2024-04-29 07:02:22 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #434: GFLOPs: 934.5813. Time: 248.0395 us. Best GFLOPs: 1187.2393
2024-04-29 07:02:22 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #435: GFLOPs: 712.6647. Time: 325.2766 us. Best GFLOPs: 1187.2393
2024-04-29 07:02:22 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #436: GFLOPs: 552.4218. Time: 419.6307 us. Best GFLOPs: 1187.2393
2024-04-29 07:02:22 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #437: GFLOPs: 742.4311. Time: 312.2352 us. Best GFLOPs: 1187.2393
2024-04-29 07:02:22 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #438: GFLOPs: 872.5369. Time: 265.6772 us. Best GFLOPs: 1187.2393
2024-04-29 07:02:22 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #439: GFLOPs: 162.1176. Time: 1429.9076 us. Best GFLOPs: 1187.2393
2024-04-29 07:02:22 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #440: GFLOPs: 882.3703. Time: 262.7164 us. Best GFLOPs: 1187.2393
2024-04-29 07:02:22 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #441: GFLOPs: 766.2652. Time: 302.5234 us. Best GFLOPs: 1187.2393
2024-04-29 07:02:22 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #442: GFLOPs: 286.3775. Time: 809.4670 us. Best GFLOPs: 1187.2393
2024-04-29 07:02:22 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #443: GFLOPs: 834.3699. Time: 277.8302 us. Best GFLOPs: 1187.2393
2024-04-29 07:02:22 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #444: GFLOPs: 848.9132. Time: 273.0705 us. Best GFLOPs: 1187.2393
2024-04-29 07:02:22 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #445: GFLOPs: 723.7595. Time: 320.2902 us. Best GFLOPs: 1187.2393
2024-04-29 07:02:22 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #446: GFLOPs: 142.8469. Time: 1622.8081 us. Best GFLOPs: 1187.2393
2024-04-29 07:02:22 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #447: GFLOPs: 31.6715. Time: 7319.2883 us. Best GFLOPs: 1187.2393
2024-04-29 07:02:22 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #448: GFLOPs: 22.0731. Time: 10502.0579 us. Best GFLOPs: 1187.2393
2024-04-29 07:28:33 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 07:28:34 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-29 07:28:39 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x6d7cf18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3529928)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35fad28)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x42e62b8)]: 0 failure(s)
2024-04-29 07:28:39 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-29 07:28:52 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x6d7cf18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3529928)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35fad28)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x42e62b8)]: 0 failure(s)
2024-04-29 07:29:06 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x6d7cf18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3529928)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35fad28)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x42e62b8)]: 0 failure(s)
2024-04-29 07:29:19 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x6d7cf18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3529928)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35fad28)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x42e62b8)]: 0 failure(s)
2024-04-29 07:29:33 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x6d7cf18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3529928)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35fad28)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x42e62b8)]: 0 failure(s)
2024-04-29 07:29:42 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9689  0.9212  0.8933  0.8933  0.8933  0.8797  0.8719  0.8719  0.8694  0.8582  0.8310  0.8304  0.8304  0.8304  0.8230  0.7970
[17 : 32]:	0.7960  0.7948  0.7920  0.7872  0.7864  0.7863  0.7857  0.7766  0.7718  0.7718  0.7662  0.7607  0.7520  0.7506  0.7499  0.7446
[33 : 48]:	0.7423  0.7410  0.7410  0.7395  0.7395  0.7383  0.7352  0.7325  0.7305  0.7284  0.7261  0.7247  0.7227  0.7227  0.7218  0.7214
[49 : 64]:	0.7205  0.7200  0.7184  0.7180  0.7174  0.7157  0.7135  0.7128  0.7110  0.7080  0.7058  0.7030  0.7010  0.6989  0.6971  0.6970
2024-04-29 07:29:42 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 07:29:42 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 07:31:21 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #449: GFLOPs: 602.9480. Time: 384.4662 us. Best GFLOPs: 1187.2393
2024-04-29 07:31:21 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #450: GFLOPs: 1063.8868. Time: 217.8927 us. Best GFLOPs: 1187.2393
2024-04-29 07:31:21 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #451: GFLOPs: 1106.6285. Time: 209.4769 us. Best GFLOPs: 1187.2393
2024-04-29 07:31:21 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #452: GFLOPs: 1105.6403. Time: 209.6641 us. Best GFLOPs: 1187.2393
2024-04-29 07:31:21 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #453: GFLOPs: 1070.6308. Time: 216.5201 us. Best GFLOPs: 1187.2393
2024-04-29 07:31:21 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #454: GFLOPs: 1058.6822. Time: 218.9638 us. Best GFLOPs: 1187.2393
2024-04-29 07:31:21 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #455: GFLOPs: 865.8925. Time: 267.7158 us. Best GFLOPs: 1187.2393
2024-04-29 07:31:21 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #456: GFLOPs: 860.6106. Time: 269.3589 us. Best GFLOPs: 1187.2393
2024-04-29 07:31:21 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #457: GFLOPs: 1088.2690. Time: 213.0109 us. Best GFLOPs: 1187.2393
2024-04-29 07:31:21 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #458: GFLOPs: 993.4767. Time: 233.3352 us. Best GFLOPs: 1187.2393
2024-04-29 07:31:21 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #459: GFLOPs: 1136.1308. Time: 204.0374 us. Best GFLOPs: 1187.2393
2024-04-29 07:31:21 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #460: GFLOPs: 1007.1001. Time: 230.1788 us. Best GFLOPs: 1187.2393
2024-04-29 07:31:21 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #461: GFLOPs: 998.3252. Time: 232.2020 us. Best GFLOPs: 1187.2393
2024-04-29 07:31:21 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #462: GFLOPs: 1019.1029. Time: 227.4678 us. Best GFLOPs: 1187.2393
2024-04-29 07:31:21 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #463: GFLOPs: 1010.8973. Time: 229.3142 us. Best GFLOPs: 1187.2393
2024-04-29 07:31:21 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #464: GFLOPs: 891.8930. Time: 259.9114 us. Best GFLOPs: 1187.2393
2024-04-29 07:31:21 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #465: GFLOPs: 795.0007. Time: 291.5886 us. Best GFLOPs: 1187.2393
2024-04-29 07:31:21 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #466: GFLOPs: 1025.6806. Time: 226.0091 us. Best GFLOPs: 1187.2393
2024-04-29 07:31:21 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #467: GFLOPs: 937.8935. Time: 247.1636 us. Best GFLOPs: 1187.2393
2024-04-29 07:31:21 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #468: GFLOPs: 1079.8011. Time: 214.6813 us. Best GFLOPs: 1187.2393
2024-04-29 07:31:21 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #469: GFLOPs: 944.9113. Time: 245.3279 us. Best GFLOPs: 1187.2393
2024-04-29 07:31:21 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #470: GFLOPs: 1059.1142. Time: 218.8745 us. Best GFLOPs: 1187.2393
2024-04-29 07:31:21 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #471: GFLOPs: 754.7301. Time: 307.1471 us. Best GFLOPs: 1187.2393
2024-04-29 07:31:21 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #472: GFLOPs: 1005.1761. Time: 230.6194 us. Best GFLOPs: 1187.2393
2024-04-29 07:31:21 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #473: GFLOPs: 837.8550. Time: 276.6745 us. Best GFLOPs: 1187.2393
2024-04-29 07:31:21 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #474: GFLOPs: 829.9629. Time: 279.3054 us. Best GFLOPs: 1187.2393
2024-04-29 07:31:21 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #475: GFLOPs: 928.8566. Time: 249.5682 us. Best GFLOPs: 1187.2393
2024-04-29 07:31:21 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #476: GFLOPs: 750.8409. Time: 308.7380 us. Best GFLOPs: 1187.2393
2024-04-29 07:31:21 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #477: GFLOPs: 969.2354. Time: 239.1711 us. Best GFLOPs: 1187.2393
2024-04-29 07:31:21 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #478: GFLOPs: 692.4696. Time: 334.7629 us. Best GFLOPs: 1187.2393
2024-04-29 07:31:21 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #479: GFLOPs: 839.1554. Time: 276.2457 us. Best GFLOPs: 1187.2393
2024-04-29 07:31:21 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #480: GFLOPs: 1123.5166. Time: 206.3282 us. Best GFLOPs: 1187.2393
2024-04-29 07:31:21 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #481: GFLOPs: 921.2745. Time: 251.6222 us. Best GFLOPs: 1187.2393
2024-04-29 07:31:21 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #482: GFLOPs: 894.9936. Time: 259.0109 us. Best GFLOPs: 1187.2393
2024-04-29 07:31:21 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #483: GFLOPs: 856.3920. Time: 270.6858 us. Best GFLOPs: 1187.2393
2024-04-29 07:31:21 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #484: GFLOPs: 867.9132. Time: 267.0925 us. Best GFLOPs: 1187.2393
2024-04-29 07:31:21 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #485: GFLOPs: 877.7724. Time: 264.0925 us. Best GFLOPs: 1187.2393
2024-04-29 07:31:21 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #486: GFLOPs: 718.6065. Time: 322.5870 us. Best GFLOPs: 1187.2393
2024-04-29 07:31:21 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #487: GFLOPs: 973.6303. Time: 238.0915 us. Best GFLOPs: 1187.2393
2024-04-29 07:31:21 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #488: GFLOPs: 739.6584. Time: 313.4056 us. Best GFLOPs: 1187.2393
2024-04-29 07:31:21 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #489: GFLOPs: 928.4326. Time: 249.6822 us. Best GFLOPs: 1187.2393
2024-04-29 07:31:21 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #490: GFLOPs: 900.9345. Time: 257.3030 us. Best GFLOPs: 1187.2393
2024-04-29 07:31:21 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #491: GFLOPs: 913.6725. Time: 253.7158 us. Best GFLOPs: 1187.2393
2024-04-29 07:31:21 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #492: GFLOPs: 906.3756. Time: 255.7583 us. Best GFLOPs: 1187.2393
2024-04-29 07:31:21 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #493: GFLOPs: 694.9536. Time: 333.5663 us. Best GFLOPs: 1187.2393
2024-04-29 07:31:21 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #494: GFLOPs: 707.0247. Time: 327.8713 us. Best GFLOPs: 1187.2393
2024-04-29 07:31:21 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #495: GFLOPs: 888.6029. Time: 260.8737 us. Best GFLOPs: 1187.2393
2024-04-29 07:31:21 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #496: GFLOPs: 925.6375. Time: 250.4362 us. Best GFLOPs: 1187.2393
2024-04-29 07:31:21 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #497: GFLOPs: 741.9008. Time: 312.4584 us. Best GFLOPs: 1187.2393
2024-04-29 07:31:21 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #498: GFLOPs: 692.9680. Time: 334.5221 us. Best GFLOPs: 1187.2393
2024-04-29 07:31:21 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #499: GFLOPs: 966.6154. Time: 239.8194 us. Best GFLOPs: 1187.2393
2024-04-29 07:31:21 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #500: GFLOPs: 944.9052. Time: 245.3295 us. Best GFLOPs: 1187.2393
2024-04-29 07:31:21 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #501: GFLOPs: 774.6435. Time: 299.2513 us. Best GFLOPs: 1187.2393
2024-04-29 07:31:21 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #502: GFLOPs: 751.3088. Time: 308.5457 us. Best GFLOPs: 1187.2393
2024-04-29 07:31:21 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #503: GFLOPs: 436.2246. Time: 531.4077 us. Best GFLOPs: 1187.2393
2024-04-29 07:31:21 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #504: GFLOPs: 671.2774. Time: 345.3313 us. Best GFLOPs: 1187.2393
2024-04-29 07:31:21 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #505: GFLOPs: 847.4096. Time: 273.5550 us. Best GFLOPs: 1187.2393
2024-04-29 07:31:21 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #506: GFLOPs: 870.1634. Time: 266.4018 us. Best GFLOPs: 1187.2393
2024-04-29 07:31:21 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #507: GFLOPs: 910.4843. Time: 254.6042 us. Best GFLOPs: 1187.2393
2024-04-29 07:31:21 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #508: GFLOPs: 880.2426. Time: 263.3514 us. Best GFLOPs: 1187.2393
2024-04-29 07:31:21 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #509: GFLOPs: 791.7467. Time: 292.7870 us. Best GFLOPs: 1187.2393
2024-04-29 07:31:21 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #510: GFLOPs: 74.1021. Time: 3128.2928 us. Best GFLOPs: 1187.2393
2024-04-29 07:31:21 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #511: GFLOPs: 44.1588. Time: 5249.5367 us. Best GFLOPs: 1187.2393
2024-04-29 07:31:21 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #512: GFLOPs: 144.4463. Time: 1604.8394 us. Best GFLOPs: 1187.2393
2024-04-29 08:31:05 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 08:31:06 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-29 08:31:11 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x6d7cf18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3529928)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35fad28)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x42e62b8)]: 0 failure(s)
2024-04-29 08:31:11 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-29 08:31:24 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x6d7cf18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3529928)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35fad28)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x42e62b8)]: 0 failure(s)
2024-04-29 08:31:37 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x6d7cf18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3529928)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35fad28)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x42e62b8)]: 0 failure(s)
2024-04-29 08:31:51 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x6d7cf18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3529928)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35fad28)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x42e62b8)]: 0 failure(s)
2024-04-29 08:32:04 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x6d7cf18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3529928)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35fad28)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x42e62b8)]: 0 failure(s)
2024-04-29 08:32:13 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9079  0.9079  0.8907  0.8834  0.8698  0.8622  0.8607  0.8567  0.8545  0.8545  0.8395  0.8394  0.8385  0.8385  0.8385  0.8308
[17 : 32]:	0.8308  0.8281  0.8220  0.8151  0.8145  0.8117  0.8117  0.8025  0.8025  0.8025  0.7964  0.7929  0.7905  0.7888  0.7882  0.7837
[33 : 48]:	0.7802  0.7624  0.7623  0.7622  0.7619  0.7567  0.7545  0.7540  0.7525  0.7495  0.7495  0.7466  0.7463  0.7459  0.7428  0.7428
[49 : 64]:	0.7402  0.7398  0.7391  0.7380  0.7379  0.7373  0.7373  0.7373  0.7363  0.7357  0.7357  0.7352  0.7352  0.7346  0.7346  0.7342
2024-04-29 08:32:13 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 08:32:13 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 08:33:46 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #513: GFLOPs: 1089.1110. Time: 212.8462 us. Best GFLOPs: 1187.2393
2024-04-29 08:33:46 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #514: GFLOPs: 1051.7231. Time: 220.4127 us. Best GFLOPs: 1187.2393
2024-04-29 08:33:46 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #515: GFLOPs: 840.9941. Time: 275.6418 us. Best GFLOPs: 1187.2393
2024-04-29 08:33:46 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #516: GFLOPs: 995.2408. Time: 232.9216 us. Best GFLOPs: 1187.2393
2024-04-29 08:33:46 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #517: GFLOPs: 1073.0883. Time: 216.0243 us. Best GFLOPs: 1187.2393
2024-04-29 08:33:46 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #518: GFLOPs: 977.3609. Time: 237.1827 us. Best GFLOPs: 1187.2393
2024-04-29 08:33:46 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #519: GFLOPs: 1204.3246. Time: 192.4839 us. Best GFLOPs: 1204.3246
2024-04-29 08:33:46 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #520: GFLOPs: 814.9044. Time: 284.4667 us. Best GFLOPs: 1204.3246
2024-04-29 08:33:46 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #521: GFLOPs: 1062.9993. Time: 218.0746 us. Best GFLOPs: 1204.3246
2024-04-29 08:33:46 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #522: GFLOPs: 1068.4981. Time: 216.9523 us. Best GFLOPs: 1204.3246
2024-04-29 08:33:46 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #523: GFLOPs: 1206.7898. Time: 192.0907 us. Best GFLOPs: 1206.7898
2024-04-29 08:33:46 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #524: GFLOPs: 970.8891. Time: 238.7638 us. Best GFLOPs: 1206.7898
2024-04-29 08:33:46 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #525: GFLOPs: 942.2035. Time: 246.0330 us. Best GFLOPs: 1206.7898
2024-04-29 08:33:46 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #526: GFLOPs: 1001.7553. Time: 231.4069 us. Best GFLOPs: 1206.7898
2024-04-29 08:33:46 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #527: GFLOPs: 946.8174. Time: 244.8340 us. Best GFLOPs: 1206.7898
2024-04-29 08:33:46 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #528: GFLOPs: 953.5539. Time: 243.1044 us. Best GFLOPs: 1206.7898
2024-04-29 08:33:46 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #529: GFLOPs: 969.4825. Time: 239.1102 us. Best GFLOPs: 1206.7898
2024-04-29 08:33:46 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #530: GFLOPs: 1008.3940. Time: 229.8835 us. Best GFLOPs: 1206.7898
2024-04-29 08:33:46 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #531: GFLOPs: 665.9478. Time: 348.0950 us. Best GFLOPs: 1206.7898
2024-04-29 08:33:46 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #532: GFLOPs: 928.9806. Time: 249.5349 us. Best GFLOPs: 1206.7898
2024-04-29 08:33:46 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #533: GFLOPs: 990.1605. Time: 234.1167 us. Best GFLOPs: 1206.7898
2024-04-29 08:33:46 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #534: GFLOPs: 1021.4465. Time: 226.9459 us. Best GFLOPs: 1206.7898
2024-04-29 08:33:46 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #535: GFLOPs: 1023.0345. Time: 226.5937 us. Best GFLOPs: 1206.7898
2024-04-29 08:33:46 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #536: GFLOPs: 76.2078. Time: 3041.8560 us. Best GFLOPs: 1206.7898
2024-04-29 08:33:46 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #537: GFLOPs: 769.5547. Time: 301.2302 us. Best GFLOPs: 1206.7898
2024-04-29 08:33:46 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #538: GFLOPs: 987.2460. Time: 234.8079 us. Best GFLOPs: 1206.7898
2024-04-29 08:33:46 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #539: GFLOPs: 1021.6733. Time: 226.8955 us. Best GFLOPs: 1206.7898
2024-04-29 08:33:46 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #540: GFLOPs: 964.9671. Time: 240.2290 us. Best GFLOPs: 1206.7898
2024-04-29 08:33:46 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #541: GFLOPs: 1094.9813. Time: 211.7051 us. Best GFLOPs: 1206.7898
2024-04-29 08:33:46 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #542: GFLOPs: 817.9631. Time: 283.4029 us. Best GFLOPs: 1206.7898
2024-04-29 08:33:46 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #543: GFLOPs: 1021.6672. Time: 226.8969 us. Best GFLOPs: 1206.7898
2024-04-29 08:33:46 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #544: GFLOPs: 763.1974. Time: 303.7394 us. Best GFLOPs: 1206.7898
2024-04-29 08:33:46 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #545: GFLOPs: 903.9511. Time: 256.4443 us. Best GFLOPs: 1206.7898
2024-04-29 08:33:46 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #546: GFLOPs: 911.5932. Time: 254.2945 us. Best GFLOPs: 1206.7898
2024-04-29 08:33:46 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #547: GFLOPs: 898.9852. Time: 257.8609 us. Best GFLOPs: 1206.7898
2024-04-29 08:33:46 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #548: GFLOPs: 970.9348. Time: 238.7525 us. Best GFLOPs: 1206.7898
2024-04-29 08:33:46 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #549: GFLOPs: 1014.5227. Time: 228.4948 us. Best GFLOPs: 1206.7898
2024-04-29 08:33:46 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #550: GFLOPs: 984.5077. Time: 235.4609 us. Best GFLOPs: 1206.7898
2024-04-29 08:33:46 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #551: GFLOPs: 584.9787. Time: 396.2762 us. Best GFLOPs: 1206.7898
2024-04-29 08:33:46 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #552: GFLOPs: 901.2752. Time: 257.2057 us. Best GFLOPs: 1206.7898
2024-04-29 08:33:46 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #553: GFLOPs: 1105.6893. Time: 209.6549 us. Best GFLOPs: 1206.7898
2024-04-29 08:33:46 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #554: GFLOPs: 1125.3148. Time: 205.9985 us. Best GFLOPs: 1206.7898
2024-04-29 08:33:46 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #555: GFLOPs: 58.4843. Time: 3963.6844 us. Best GFLOPs: 1206.7898
2024-04-29 08:33:46 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #556: GFLOPs: 846.7410. Time: 273.7710 us. Best GFLOPs: 1206.7898
2024-04-29 08:33:46 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #557: GFLOPs: 956.1695. Time: 242.4394 us. Best GFLOPs: 1206.7898
2024-04-29 08:33:46 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #558: GFLOPs: 952.3453. Time: 243.4129 us. Best GFLOPs: 1206.7898
2024-04-29 08:33:46 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #559: GFLOPs: 888.6338. Time: 260.8646 us. Best GFLOPs: 1206.7898
2024-04-29 08:33:46 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #560: GFLOPs: 890.2815. Time: 260.3818 us. Best GFLOPs: 1206.7898
2024-04-29 08:33:46 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #561: GFLOPs: 832.8319. Time: 278.3432 us. Best GFLOPs: 1206.7898
2024-04-29 08:33:46 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #562: GFLOPs: 969.3572. Time: 239.1411 us. Best GFLOPs: 1206.7898
2024-04-29 08:33:46 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #563: GFLOPs: 998.7241. Time: 232.1093 us. Best GFLOPs: 1206.7898
2024-04-29 08:33:46 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #564: GFLOPs: 755.2394. Time: 306.9399 us. Best GFLOPs: 1206.7898
2024-04-29 08:33:46 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #565: GFLOPs: 878.2126. Time: 263.9601 us. Best GFLOPs: 1206.7898
2024-04-29 08:33:46 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #566: GFLOPs: 669.6878. Time: 346.1510 us. Best GFLOPs: 1206.7898
2024-04-29 08:33:46 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #567: GFLOPs: 755.6239. Time: 306.7837 us. Best GFLOPs: 1206.7898
2024-04-29 08:33:46 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #568: GFLOPs: 571.3048. Time: 405.7609 us. Best GFLOPs: 1206.7898
2024-04-29 08:33:46 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #569: GFLOPs: 614.7004. Time: 377.1156 us. Best GFLOPs: 1206.7898
2024-04-29 08:33:46 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #570: GFLOPs: 805.4821. Time: 287.7943 us. Best GFLOPs: 1206.7898
2024-04-29 08:33:46 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #571: GFLOPs: 1046.7503. Time: 221.4598 us. Best GFLOPs: 1206.7898
2024-04-29 08:33:46 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #572: GFLOPs: 976.6540. Time: 237.3544 us. Best GFLOPs: 1206.7898
2024-04-29 08:33:46 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #573: GFLOPs: 1013.0600. Time: 228.8247 us. Best GFLOPs: 1206.7898
2024-04-29 08:33:46 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #574: GFLOPs: 4.2774. Time: 54195.4657 us. Best GFLOPs: 1206.7898
2024-04-29 08:33:46 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #575: GFLOPs: 24.6100. Time: 9419.4841 us. Best GFLOPs: 1206.7898
2024-04-29 08:33:46 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #576: GFLOPs: 44.1348. Time: 5252.3835 us. Best GFLOPs: 1206.7898
2024-04-29 09:15:59 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 09:16:01 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-29 09:16:05 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x6d7cf18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3529928)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35fad28)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x42e62b8)]: 0 failure(s)
2024-04-29 09:16:05 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-29 09:16:18 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x6d7cf18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3529928)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35fad28)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x42e62b8)]: 0 failure(s)
2024-04-29 09:16:32 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x6d7cf18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3529928)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35fad28)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x42e62b8)]: 0 failure(s)
2024-04-29 09:16:46 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x6d7cf18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3529928)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35fad28)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x42e62b8)]: 0 failure(s)
2024-04-29 09:17:00 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x6d7cf18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3529928)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35fad28)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x42e62b8)]: 0 failure(s)
2024-04-29 09:17:08 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9825  0.9646  0.9510  0.9510  0.9510  0.8871  0.8836  0.8832  0.8832  0.8488  0.8468  0.8405  0.8380  0.8380  0.8378  0.8378
[17 : 32]:	0.8378  0.8274  0.8265  0.8193  0.8174  0.8170  0.8170  0.8144  0.8139  0.8135  0.8101  0.8011  0.8009  0.7960  0.7943  0.7940
[33 : 48]:	0.7940  0.7936  0.7900  0.7898  0.7887  0.7884  0.7884  0.7872  0.7872  0.7820  0.7754  0.7754  0.7730  0.7704  0.7704  0.7695
[49 : 64]:	0.7690  0.7665  0.7605  0.7522  0.7512  0.7485  0.7485  0.7430  0.7410  0.7390  0.7388  0.7383  0.7352  0.7345  0.7337  0.7328
2024-04-29 09:17:08 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 09:17:09 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 09:18:43 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #577: GFLOPs: 649.0405. Time: 357.1628 us. Best GFLOPs: 1206.7898
2024-04-29 09:18:43 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #578: GFLOPs: 1158.5293. Time: 200.0926 us. Best GFLOPs: 1206.7898
2024-04-29 09:18:43 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #579: GFLOPs: 1191.5724. Time: 194.5439 us. Best GFLOPs: 1206.7898
2024-04-29 09:18:43 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #580: GFLOPs: 1252.2754. Time: 185.1135 us. Best GFLOPs: 1252.2754
2024-04-29 09:18:43 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #581: GFLOPs: 1199.8849. Time: 193.1961 us. Best GFLOPs: 1252.2754
2024-04-29 09:18:43 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #582: GFLOPs: 1125.5149. Time: 205.9618 us. Best GFLOPs: 1252.2754
2024-04-29 09:18:43 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #583: GFLOPs: 1104.2485. Time: 209.9284 us. Best GFLOPs: 1252.2754
2024-04-29 09:18:43 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #584: GFLOPs: 1075.6183. Time: 215.5162 us. Best GFLOPs: 1252.2754
2024-04-29 09:18:43 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #585: GFLOPs: 1097.8158. Time: 211.1585 us. Best GFLOPs: 1252.2754
2024-04-29 09:18:43 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #586: GFLOPs: 1065.7447. Time: 217.5128 us. Best GFLOPs: 1252.2754
2024-04-29 09:18:43 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #587: GFLOPs: 1021.9933. Time: 226.8245 us. Best GFLOPs: 1252.2754
2024-04-29 09:18:43 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #588: GFLOPs: 1054.8023. Time: 219.7693 us. Best GFLOPs: 1252.2754
2024-04-29 09:18:43 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #589: GFLOPs: 1089.0519. Time: 212.8577 us. Best GFLOPs: 1252.2754
2024-04-29 09:18:43 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #590: GFLOPs: 1130.8675. Time: 204.9870 us. Best GFLOPs: 1252.2754
2024-04-29 09:18:43 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #591: GFLOPs: 988.8569. Time: 234.4253 us. Best GFLOPs: 1252.2754
2024-04-29 09:18:43 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #592: GFLOPs: 1095.4222. Time: 211.6199 us. Best GFLOPs: 1252.2754
2024-04-29 09:18:43 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #593: GFLOPs: 1089.9086. Time: 212.6904 us. Best GFLOPs: 1252.2754
2024-04-29 09:18:43 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #594: GFLOPs: 1170.4018. Time: 198.0629 us. Best GFLOPs: 1252.2754
2024-04-29 09:18:43 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #595: GFLOPs: 1011.2929. Time: 229.2245 us. Best GFLOPs: 1252.2754
2024-04-29 09:18:43 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #596: GFLOPs: 1034.2928. Time: 224.1272 us. Best GFLOPs: 1252.2754
2024-04-29 09:18:43 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #597: GFLOPs: 984.4063. Time: 235.4852 us. Best GFLOPs: 1252.2754
2024-04-29 09:18:43 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #598: GFLOPs: 989.0615. Time: 234.3768 us. Best GFLOPs: 1252.2754
2024-04-29 09:18:43 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #599: GFLOPs: 963.9548. Time: 240.4813 us. Best GFLOPs: 1252.2754
2024-04-29 09:18:43 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #600: GFLOPs: 1091.6969. Time: 212.3420 us. Best GFLOPs: 1252.2754
2024-04-29 09:18:43 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #601: GFLOPs: 1025.4931. Time: 226.0504 us. Best GFLOPs: 1252.2754
2024-04-29 09:18:43 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #602: GFLOPs: 1018.0316. Time: 227.7072 us. Best GFLOPs: 1252.2754
2024-04-29 09:18:43 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #603: GFLOPs: 152.3731. Time: 1521.3524 us. Best GFLOPs: 1252.2754
2024-04-29 09:18:43 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #604: GFLOPs: 891.9234. Time: 259.9025 us. Best GFLOPs: 1252.2754
2024-04-29 09:18:43 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #605: GFLOPs: 865.9996. Time: 267.6827 us. Best GFLOPs: 1252.2754
2024-04-29 09:18:43 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #606: GFLOPs: 1152.5557. Time: 201.1296 us. Best GFLOPs: 1252.2754
2024-04-29 09:18:43 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #607: GFLOPs: 1129.2893. Time: 205.2735 us. Best GFLOPs: 1252.2754
2024-04-29 09:18:43 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #608: GFLOPs: 754.3818. Time: 307.2889 us. Best GFLOPs: 1252.2754
2024-04-29 09:18:43 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #609: GFLOPs: 76.2983. Time: 3038.2461 us. Best GFLOPs: 1252.2754
2024-04-29 09:18:43 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #610: GFLOPs: 996.2402. Time: 232.6880 us. Best GFLOPs: 1252.2754
2024-04-29 09:18:43 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #611: GFLOPs: 956.5517. Time: 242.3425 us. Best GFLOPs: 1252.2754
2024-04-29 09:18:43 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #612: GFLOPs: 1038.1764. Time: 223.2888 us. Best GFLOPs: 1252.2754
2024-04-29 09:18:43 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #613: GFLOPs: 896.8394. Time: 258.4779 us. Best GFLOPs: 1252.2754
2024-04-29 09:18:43 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #614: GFLOPs: 1099.5266. Time: 210.8299 us. Best GFLOPs: 1252.2754
2024-04-29 09:18:43 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #615: GFLOPs: 873.2687. Time: 265.4545 us. Best GFLOPs: 1252.2754
2024-04-29 09:18:43 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #616: GFLOPs: 63.1976. Time: 3668.0695 us. Best GFLOPs: 1252.2754
2024-04-29 09:18:43 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #617: GFLOPs: 66.1923. Time: 3502.1162 us. Best GFLOPs: 1252.2754
2024-04-29 09:18:43 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #618: GFLOPs: 849.5906. Time: 272.8527 us. Best GFLOPs: 1252.2754
2024-04-29 09:18:43 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #619: GFLOPs: 416.8741. Time: 556.0746 us. Best GFLOPs: 1252.2754
2024-04-29 09:18:43 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #620: GFLOPs: 855.5155. Time: 270.9631 us. Best GFLOPs: 1252.2754
2024-04-29 09:18:43 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #621: GFLOPs: 1046.1867. Time: 221.5791 us. Best GFLOPs: 1252.2754
2024-04-29 09:18:43 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #622: GFLOPs: 1024.4819. Time: 226.2735 us. Best GFLOPs: 1252.2754
2024-04-29 09:18:43 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #623: GFLOPs: 78.4468. Time: 2955.0345 us. Best GFLOPs: 1252.2754
2024-04-29 09:18:43 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #624: GFLOPs: 874.2677. Time: 265.1512 us. Best GFLOPs: 1252.2754
2024-04-29 09:18:43 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #625: GFLOPs: 891.6144. Time: 259.9926 us. Best GFLOPs: 1252.2754
2024-04-29 09:18:43 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #626: GFLOPs: 1091.7659. Time: 212.3286 us. Best GFLOPs: 1252.2754
2024-04-29 09:18:43 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #627: GFLOPs: 909.0402. Time: 255.0087 us. Best GFLOPs: 1252.2754
2024-04-29 09:18:43 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #628: GFLOPs: 921.8056. Time: 251.4772 us. Best GFLOPs: 1252.2754
2024-04-29 09:18:43 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #629: GFLOPs: 1102.2028. Time: 210.3180 us. Best GFLOPs: 1252.2754
2024-04-29 09:18:43 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #630: GFLOPs: 718.7892. Time: 322.5050 us. Best GFLOPs: 1252.2754
2024-04-29 09:18:43 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #631: GFLOPs: 935.4420. Time: 247.8113 us. Best GFLOPs: 1252.2754
2024-04-29 09:18:43 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #632: GFLOPs: 980.8140. Time: 236.3477 us. Best GFLOPs: 1252.2754
2024-04-29 09:18:43 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #633: GFLOPs: 912.5012. Time: 254.0415 us. Best GFLOPs: 1252.2754
2024-04-29 09:18:43 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #634: GFLOPs: 958.6614. Time: 241.8092 us. Best GFLOPs: 1252.2754
2024-04-29 09:18:43 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #635: GFLOPs: 936.1108. Time: 247.6343 us. Best GFLOPs: 1252.2754
2024-04-29 09:18:43 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #636: GFLOPs: 942.9237. Time: 245.8451 us. Best GFLOPs: 1252.2754
2024-04-29 09:18:43 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #637: GFLOPs: 920.5204. Time: 251.8283 us. Best GFLOPs: 1252.2754
2024-04-29 09:18:43 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #638: GFLOPs: 12.9335. Time: 17923.4873 us. Best GFLOPs: 1252.2754
2024-04-29 09:18:43 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #639: GFLOPs: 3.8179. Time: 60716.9513 us. Best GFLOPs: 1252.2754
2024-04-29 09:18:43 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu] Trial #640: GFLOPs: 70.9254. Time: 3268.4066 us. Best GFLOPs: 1252.2754
