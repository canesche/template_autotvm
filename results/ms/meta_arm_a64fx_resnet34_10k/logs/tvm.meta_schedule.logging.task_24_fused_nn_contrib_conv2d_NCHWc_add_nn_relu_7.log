2024-04-29 03:20:53 [INFO] [task_scheduler.cc:160] Initializing Task #24: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7"
2024-04-29 03:20:53 [INFO] [task_scheduler.cc:35] 
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(7), T.int64(7), T.int64(512)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(9), T.int64(9), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)))
        T_add = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)))
        for i0, i1, i2, i3, i4 in T.grid(T.int64(1), T.int64(1), T.int64(9), T.int64(9), T.int64(512)):
            with T.block("data_pad"):
                v_i0, v_i1, v_i2, v_i3, v_i4 = T.axis.remap("SSSSS", [i0, i1, i2, i3, i4])
                T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(8) and T.int64(1) <= v_i3 and v_i3 < T.int64(8), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
        for n, oc_chunk, oh, ow, oc_block, ic, kh, kw in T.grid(T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32), T.int64(512), T.int64(3), T.int64(3)):
            with T.block("conv2d_NCHWc"):
                v_n, v_oc_chunk, v_oh, v_ow, v_oc_block, v_ic, v_kh, v_kw = T.axis.remap("SSSSSRRR", [n, oc_chunk, oh, ow, oc_block, ic, kh, kw])
                T.reads(data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                with T.init():
                    conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
        for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                T.writes(T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4]
        for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)):
            with T.block("T_relu"):
                v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                T.reads(T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
2024-04-29 03:20:53 [INFO] [task_scheduler.cc:164] Total 3 design space(s) generated
2024-04-29 03:20:53 [INFO] [task_scheduler.cc:170] Design space #0:
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(7), T.int64(7), T.int64(512)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel": 768, "meta_schedule.unroll_explicit": 0, "meta_schedule.vectorize": 64})
            data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(9), T.int64(9), T.int64(512)))
            conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)))
            for n_0, oc_chunk_0, oh_0, ow_0 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(9), T.int64(3), T.int64(512)):
                    with T.block("data_pad"):
                        v_i0, v_i1, v_i2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                        v_i3 = T.axis.spatial(T.int64(9), ow_0 + ax3)
                        v_i4 = T.axis.spatial(T.int64(512), ax4)
                        T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                        T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                        data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(8) and T.int64(1) <= v_i3 and v_i3 < T.int64(8), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                for oc_block_0, n_1, oc_chunk_1, oh_1, ow_1, oc_block_1, ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(8), T.int64(16), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(7), T.int64(1), T.int64(2), T.int64(32), T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2)):
                    with T.block("conv2d_NCHWc"):
                        v_n = T.axis.spatial(T.int64(1), n_0 + n_1 + n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(16), oc_chunk_0 * T.int64(16) + oc_chunk_1 * T.int64(4) + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(7), oh_0 * T.int64(7) + oh_1 * T.int64(7) + oh_2 + oh_3)
                        v_ow = T.axis.spatial(T.int64(7), ow_0 + ow_1 + ow_2 + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_0 * T.int64(32) + oc_block_1 * T.int64(4) + oc_block_2 * T.int64(2) + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(32) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                        T.reads(data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        with T.init():
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)):
                with T.block("T_relu"):
                    v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                    T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                    T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 4, 4, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 7, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[7, 1, 1, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 8, 2, 2])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[16, 32])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
l65 = sch.sample_compute_location(block=b0, decision=3)
sch.compute_at(block=b0, loop=l65, preserve_unit_loops=True, index=-1)
2024-04-29 03:20:53 [INFO] [task_scheduler.cc:170] Design space #1:
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(7), T.int64(7), T.int64(512)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel": 768, "meta_schedule.unroll_explicit": 16, "meta_schedule.vectorize": 64})
            data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(9), T.int64(9), T.int64(512)))
            conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)))
            for n_0, oc_chunk_0, oh_0, ow_0, oc_block_0, n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(8)):
                for ic_0 in range(T.int64(16)):
                    for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(9), T.int64(3), T.int64(32)):
                        with T.block("data_pad"):
                            v_i0, v_i1, v_i2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                            v_i3 = T.axis.spatial(T.int64(9), ow_0 + ax3)
                            v_i4 = T.axis.spatial(T.int64(512), ic_0 * T.int64(32) + ax4)
                            T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                            T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                            data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(8) and T.int64(1) <= v_i3 and v_i3 < T.int64(8), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                    for kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(7), T.int64(1), T.int64(2), T.int64(32), T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2)):
                        with T.block("conv2d_NCHWc"):
                            v_n = T.axis.spatial(T.int64(1), n_0 + n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(16), oc_chunk_0 * T.int64(16) + oc_chunk_1 * T.int64(4) + oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(7), oh_0 * T.int64(7) + oh_1 * T.int64(7) + oh_2 + oh_3)
                            v_ow = T.axis.spatial(T.int64(7), ow_0 + ow_1 + ow_2 + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(32), oc_block_0 * T.int64(32) + oc_block_1 * T.int64(4) + oc_block_2 * T.int64(2) + oc_block_3)
                            v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(32) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                            T.reads(data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            with T.init():
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
                for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(4), T.int64(7), T.int64(1), T.int64(4)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(16), oc_chunk_1 * T.int64(4) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(7), ax2)
                        v_ax3 = T.axis.spatial(T.int64(7), ow_0 + ax3)
                        v_ax4 = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(4) + ax4)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 4, 4, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 7, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[7, 1, 1, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 8, 2, 2])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[16, 32])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=10)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
2024-04-29 03:20:53 [INFO] [task_scheduler.cc:170] Design space #2:
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(7), T.int64(7), T.int64(512)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel": 768, "meta_schedule.unroll_explicit": 0, "meta_schedule.vectorize": 64})
            data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(9), T.int64(9), T.int64(512)))
            conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)))
            for n_0, oc_chunk_0, oh_0, ow_0, oc_block_0 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1)):
                for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1, ic_0 in T.grid(T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(8), T.int64(16)):
                    for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(9), T.int64(3), T.int64(32)):
                        with T.block("data_pad"):
                            v_i0, v_i1, v_i2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                            v_i3 = T.axis.spatial(T.int64(9), ow_0 + ax3)
                            v_i4 = T.axis.spatial(T.int64(512), ic_0 * T.int64(32) + ax4)
                            T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                            T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                            data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(8) and T.int64(1) <= v_i3 and v_i3 < T.int64(8), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                    for kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(7), T.int64(1), T.int64(2), T.int64(32), T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2)):
                        with T.block("conv2d_NCHWc"):
                            v_n = T.axis.spatial(T.int64(1), n_0 + n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(16), oc_chunk_0 * T.int64(16) + oc_chunk_1 * T.int64(4) + oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(7), oh_0 * T.int64(7) + oh_1 * T.int64(7) + oh_2 + oh_3)
                            v_ow = T.axis.spatial(T.int64(7), ow_0 + ow_1 + ow_2 + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(32), oc_block_0 * T.int64(32) + oc_block_1 * T.int64(4) + oc_block_2 * T.int64(2) + oc_block_3)
                            v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(32) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                            T.reads(data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            with T.init():
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
                for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(16), T.int64(7), T.int64(1), T.int64(32)):
                    with T.block("T_relu"):
                        v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                        v_ax3 = T.axis.spatial(T.int64(7), ow_0 + ax3)
                        v_ax4 = T.axis.spatial(T.int64(32), ax4)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 4, 4, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 7, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[7, 1, 1, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 8, 2, 2])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[16, 32])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=10)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
2024-04-29 03:47:54 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 03:47:54 [INFO] [evolutionary_search.cc:715] Picked top 0 candidate(s) from database
2024-04-29 03:47:59 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x5e10dc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x6d79bf8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x5e1f188)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3181528)]: 0 failure(s)
2024-04-29 03:47:59 [INFO] [evolutionary_search.cc:723] Sampled 512 candidate(s)
2024-04-29 03:48:05 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x5e10dc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x6d79bf8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x5e1f188)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3181528)]: 0 failure(s)
2024-04-29 03:48:11 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x5e10dc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x6d79bf8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x5e1f188)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3181528)]: 0 failure(s)
2024-04-29 03:48:16 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x5e10dc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x6d79bf8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x5e1f188)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3181528)]: 0 failure(s)
2024-04-29 03:48:22 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x5e10dc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x6d79bf8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x5e1f188)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3181528)]: 0 failure(s)
2024-04-29 03:48:23 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9996  0.9995  0.9994  0.9984  0.9979  0.9973  0.9961  0.9953  0.9949  0.9928  0.9925  0.9912  0.9909  0.9908  0.9895  0.9895
[17 : 32]:	0.9890  0.9889  0.9886  0.9882  0.9874  0.9870  0.9858  0.9858  0.9843  0.9836  0.9831  0.9830  0.9829  0.9828  0.9826  0.9825
[33 : 48]:	0.9801  0.9801  0.9800  0.9796  0.9794  0.9785  0.9763  0.9759  0.9748  0.9746  0.9745  0.9741  0.9729  0.9723  0.9719  0.9710
[49 : 64]:	0.9692  0.9686  0.9678  0.9678  0.9671  0.9670  0.9657  0.9643  0.9631  0.9626  0.9625  0.9614  0.9614  0.9611  0.9607  0.9603
2024-04-29 03:48:23 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 03:48:23 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 03:57:43 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #1: GFLOPs: 18.1419. Time: 12747.3869 us. Best GFLOPs: 18.1419
2024-04-29 03:57:43 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #2: GFLOPs: 86.8104. Time: 2663.9816 us. Best GFLOPs: 86.8104
2024-04-29 03:57:43 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #3: GFLOPs: 2.0012. Time: 115563.0710 us. Best GFLOPs: 86.8104
2024-04-29 03:57:43 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #4: GFLOPs: 2.3879. Time: 96848.9413 us. Best GFLOPs: 86.8104
2024-04-29 03:57:43 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #5: GFLOPs: 61.6678. Time: 3750.1145 us. Best GFLOPs: 86.8104
2024-04-29 03:57:43 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #6: GFLOPs: 2.2885. Time: 101055.3357 us. Best GFLOPs: 86.8104
2024-04-29 03:57:43 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #7: GFLOPs: 103.1710. Time: 2241.5326 us. Best GFLOPs: 103.1710
2024-04-29 03:57:43 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #8: GFLOPs: 6.3894. Time: 36194.4037 us. Best GFLOPs: 103.1710
2024-04-29 03:57:43 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #9: GFLOPs: 31.3625. Time: 7373.8134 us. Best GFLOPs: 103.1710
2024-04-29 03:57:43 [INFO] [task_scheduler.cc:121] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #10: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(7), T.int64(7), T.int64(512)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(9), T.int64(9), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused in T.parallel(T.int64(7), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(4)):
                for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(3), T.int64(9), T.int64(512)):
                    with T.block("data_pad"):
                        v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                        v_i2 = T.axis.spatial(T.int64(9), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused + ax2)
                        v_i3, v_i4 = T.axis.remap("SS", [ax3, ax4])
                        T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                        T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                        data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(8) and T.int64(1) <= v_i3 and v_i3 < T.int64(8), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(2), T.int64(1), T.int64(7)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(16), oc_chunk_1 * T.int64(4) + oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused + oh_1 + oh_2_init + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(7), ow_1 * T.int64(7) + ow_2_init * T.int64(7) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(8) + oc_block_2_init * T.int64(4) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(8), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(2), T.int64(64), T.int64(3), T.int64(3), T.int64(1), T.int64(2), T.int64(1), T.int64(7)):
                    for oc_block_3_fused in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(16), oc_chunk_1 * T.int64(4) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused + oh_1 + oh_2 + oh_3)
                            v_ow = T.axis.spatial(T.int64(7), ow_1 * T.int64(7) + ow_2 * T.int64(7) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(8) + oc_block_2 * T.int64(4) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(64) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(16), T.int64(1), T.int64(7)):
                for ax4_fused in T.vectorized(T.int64(32)):
                    with T.block("T_relu"):
                        v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                        v_ax2 = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused + ax2)
                        v_ax3, v_ax4 = T.axis.remap("SS", [ax3, ax4_fused])
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 4, 2, 2])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[7, 1, 1, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 1, 7])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 4, 2, 4])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[8, 64])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=9)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85 = sch.get_loops(block=b68)
l86 = sch.fuse(l71, l72, l73, l74, l75, preserve_unit_iters=True)
sch.parallel(loop=l86)
l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107, l108 = sch.get_loops(block=b69)
l109 = sch.fuse(l87, preserve_unit_iters=True)
sch.parallel(loop=l109)
l110 = sch.fuse(l108, preserve_unit_iters=True)
sch.vectorize(loop=l110)
sch.annotate(block_or_loop=l109, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l109, ann_key="pragma_unroll_explicit", ann_val=1)
l111, l112, l113, l114, l115, l116 = sch.get_loops(block=b70)
l117 = sch.fuse(l116, preserve_unit_iters=True)
sch.vectorize(loop=l117)
b118 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140 = sch.get_loops(block=b118)
b141 = sch.decompose_reduction(block=b118, loop=l125)
2024-04-29 03:57:43 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #11: GFLOPs: 26.3166. Time: 8787.6597 us. Best GFLOPs: 103.1710
2024-04-29 03:57:43 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #12: GFLOPs: 40.0960. Time: 5767.6904 us. Best GFLOPs: 103.1710
2024-04-29 03:57:43 [INFO] [task_scheduler.cc:121] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #13: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(7), T.int64(7), T.int64(512)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(9), T.int64(9), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_fused_fused in T.parallel(T.int64(7), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(9), T.int64(3), T.int64(512)):
                with T.block("data_pad"):
                    v_i0, v_i1, v_i2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                    v_i3 = T.axis.spatial(T.int64(9), n_0_oc_chunk_0_oh_0_ow_0_fused_fused + ax3)
                    v_i4 = T.axis.spatial(T.int64(512), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(8) and T.int64(1) <= v_i3 and v_i3 < T.int64(8), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oc_block_0 in range(T.int64(8)):
                for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(8), T.int64(7), T.int64(1), T.int64(1)):
                    for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(16), oc_chunk_1 * T.int64(2) + oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(7), oh_1 + oh_2_init + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_fused_fused + ow_1 + ow_2_init + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(32), oc_block_0 * T.int64(4) + oc_block_1 * T.int64(4) + oc_block_2_init + oc_block_3_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                    for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(8), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(64), T.int64(3), T.int64(3), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(16), oc_chunk_1 * T.int64(2) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(7), oh_1 + oh_2 + oh_3)
                            v_ow = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_fused_fused + ow_1 + ow_2 + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(32), oc_block_0 * T.int64(4) + oc_block_1 * T.int64(4) + oc_block_2 + oc_block_3)
                            v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(64) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(16), T.int64(7), T.int64(1)):
                    for ax4_fused in T.vectorized(T.int64(4)):
                        with T.block("T_relu"):
                            v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                            v_ax3 = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_fused_fused + ax3)
                            v_ax4 = T.axis.spatial(T.int64(32), oc_block_0 * T.int64(4) + ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 8, 1, 2])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 7, 1, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[7, 1, 1, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[8, 1, 4, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[8, 64])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=3)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79 = sch.get_loops(block=b68)
l80 = sch.fuse(l71, l72, l73, l74, preserve_unit_iters=True)
sch.parallel(loop=l80)
l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l81, preserve_unit_iters=True)
sch.parallel(loop=l104)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109, l110, l111 = sch.get_loops(block=b70)
l112 = sch.fuse(l111, preserve_unit_iters=True)
sch.vectorize(loop=l112)
b113 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136 = sch.get_loops(block=b113)
b137 = sch.decompose_reduction(block=b113, loop=l121)
2024-04-29 03:57:43 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #14: GFLOPs: 6.7468. Time: 34276.9767 us. Best GFLOPs: 103.1710
2024-04-29 03:57:43 [INFO] [task_scheduler.cc:121] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #15: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(7), T.int64(7), T.int64(512)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(9), T.int64(9), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_fused_fused in T.parallel(T.int64(7), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(3), T.int64(9), T.int64(512)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(9), n_0_oc_chunk_0_oh_0_fused_fused + ax2)
                    v_i3, v_i4 = T.axis.remap("SS", [ax3, ax4])
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(8) and T.int64(1) <= v_i3 and v_i3 < T.int64(8), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for ow_0, oc_block_0, n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(7), T.int64(2), T.int64(1), T.int64(2), T.int64(1), T.int64(1)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(8)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(16), oc_chunk_1 * T.int64(4) + oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_fused_fused + oh_1 + oh_2_init + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(7), ow_0 * T.int64(7) + ow_1 * T.int64(7) + ow_2_init + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(32), oc_block_0 * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2_init * T.int64(8) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(512), T.int64(1), T.int64(3), T.int64(1), T.int64(2), T.int64(1), T.int64(7), T.int64(2), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1)):
                    for oc_block_3_fused in T.vectorized(T.int64(8)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(16), oc_chunk_1 * T.int64(4) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_fused_fused + oh_1 + oh_2 + oh_3)
                            v_ow = T.axis.spatial(T.int64(7), ow_0 * T.int64(7) + ow_1 * T.int64(7) + ow_2 + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(32), oc_block_0 * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2 * T.int64(8) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(512), ic_0 + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
        for ax0_ax1_ax2_ax3_ax4_fused_0 in T.parallel(T.int64(392)):
            for ax0_ax1_ax2_ax3_ax4_fused_1 in T.vectorized(T.int64(64)):
                with T.block("T_relu"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) // T.int64(1568))
                    v_ax2 = T.axis.spatial(T.int64(7), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(1568) // T.int64(224))
                    v_ax3 = T.axis.spatial(T.int64(7), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(224) // T.int64(32))
                    v_ax4 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(32))
                    T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                    T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 4, 2, 2])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[7, 1, 1, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 7, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[2, 1, 2, 8])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[512, 1])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
l65 = sch.sample_compute_location(block=b0, decision=2)
sch.compute_at(block=b0, loop=l65, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b66 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.unroll_explicit")
b67, b68, b69 = sch.get_child_blocks(b66)
l70, l71, l72, l73, l74, l75, l76, l77 = sch.get_loops(block=b67)
l78 = sch.fuse(l70, l71, l72, preserve_unit_iters=True)
sch.parallel(loop=l78)
l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102 = sch.get_loops(block=b68)
l103 = sch.fuse(l79, preserve_unit_iters=True)
sch.parallel(loop=l103)
l104 = sch.fuse(l102, preserve_unit_iters=True)
sch.vectorize(loop=l104)
sch.annotate(block_or_loop=l103, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l103, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109 = sch.get_loops(block=b69)
l110 = sch.fuse(l105, l106, l107, l108, l109, preserve_unit_iters=True)
l111, l112 = sch.split(loop=l110, factors=[None, 64], preserve_unit_iters=True)
sch.parallel(loop=l111)
sch.vectorize(loop=l112)
b113 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137 = sch.get_loops(block=b113)
b138 = sch.decompose_reduction(block=b113, loop=l122)
2024-04-29 03:57:43 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #16: GFLOPs: 35.9829. Time: 6426.9663 us. Best GFLOPs: 103.1710
2024-04-29 03:57:43 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #17: GFLOPs: 82.9856. Time: 2786.7638 us. Best GFLOPs: 103.1710
2024-04-29 03:57:43 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #18: GFLOPs: 1.6312. Time: 141772.5057 us. Best GFLOPs: 103.1710
2024-04-29 03:57:43 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #19: GFLOPs: 10.9768. Time: 21068.2048 us. Best GFLOPs: 103.1710
2024-04-29 03:57:43 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #20: GFLOPs: 35.7564. Time: 6467.6858 us. Best GFLOPs: 103.1710
2024-04-29 03:57:43 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #21: GFLOPs: 20.9969. Time: 11014.0709 us. Best GFLOPs: 103.1710
2024-04-29 03:57:43 [INFO] [task_scheduler.cc:121] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #22: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(7), T.int64(7), T.int64(512)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(9), T.int64(9), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_fused_fused in T.parallel(T.int64(7), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(9), T.int64(3), T.int64(512)):
                with T.block("data_pad"):
                    v_i0, v_i1, v_i2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                    v_i3 = T.axis.spatial(T.int64(9), n_0_oc_chunk_0_oh_0_ow_0_fused_fused + ax3)
                    v_i4 = T.axis.spatial(T.int64(512), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(8) and T.int64(1) <= v_i3 and v_i3 < T.int64(8), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oc_block_0 in range(T.int64(8)):
                for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(8), T.int64(7), T.int64(1), T.int64(1)):
                    for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                        for oc_block_3_fused_init in T.vectorized(T.int64(4)):
                            with T.block("conv2d_NCHWc_init"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                                v_oc_chunk = T.axis.spatial(T.int64(16), oc_chunk_1 * T.int64(2) + oc_chunk_2_init + oc_chunk_3_init)
                                v_oh = T.axis.spatial(T.int64(7), oh_1 + oh_2_init + oh_3_init)
                                v_ow = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_fused_fused + ow_1 + ow_2_init + ow_3_init)
                                v_oc_block = T.axis.spatial(T.int64(32), oc_block_0 * T.int64(4) + oc_block_1 * T.int64(4) + oc_block_2_init * T.int64(4) + oc_block_3_fused_init)
                                T.reads()
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                    for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(16), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(32), T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                        for oc_block_3_fused in T.vectorized(T.int64(4)):
                            with T.block("conv2d_NCHWc_update"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                                v_oc_chunk = T.axis.spatial(T.int64(16), oc_chunk_1 * T.int64(2) + oc_chunk_2 + oc_chunk_3)
                                v_oh = T.axis.spatial(T.int64(7), oh_1 + oh_2 + oh_3)
                                v_ow = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_fused_fused + ow_1 + ow_2 + ow_3)
                                v_oc_block = T.axis.spatial(T.int64(32), oc_block_0 * T.int64(4) + oc_block_1 * T.int64(4) + oc_block_2 * T.int64(4) + oc_block_3_fused)
                                v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(32) + ic_1)
                                v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                                v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                                T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(16), T.int64(7), T.int64(1)):
                    for ax4_fused in T.vectorized(T.int64(4)):
                        with T.block("T_relu"):
                            v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                            v_ax3 = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_fused_fused + ax3)
                            v_ax4 = T.axis.spatial(T.int64(32), oc_block_0 * T.int64(4) + ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 8, 2, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 7, 1, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[7, 1, 1, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[8, 1, 1, 4])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[16, 32])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=3)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79 = sch.get_loops(block=b68)
l80 = sch.fuse(l71, l72, l73, l74, preserve_unit_iters=True)
sch.parallel(loop=l80)
l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l81, preserve_unit_iters=True)
sch.parallel(loop=l104)
l105 = sch.fuse(l103, preserve_unit_iters=True)
sch.vectorize(loop=l105)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l106, l107, l108, l109, l110, l111, l112 = sch.get_loops(block=b70)
l113 = sch.fuse(l112, preserve_unit_iters=True)
sch.vectorize(loop=l113)
b114 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137 = sch.get_loops(block=b114)
b138 = sch.decompose_reduction(block=b114, loop=l122)
2024-04-29 03:57:43 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #23: GFLOPs: 0.1081. Time: 2139948.3237 us. Best GFLOPs: 103.1710
2024-04-29 03:57:43 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #24: GFLOPs: 0.4112. Time: 562447.9203 us. Best GFLOPs: 103.1710
2024-04-29 03:57:43 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #25: GFLOPs: 14.8619. Time: 15560.6810 us. Best GFLOPs: 103.1710
2024-04-29 03:57:43 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #26: GFLOPs: 1.3511. Time: 171161.6327 us. Best GFLOPs: 103.1710
2024-04-29 03:57:43 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #27: GFLOPs: 8.6965. Time: 26592.5480 us. Best GFLOPs: 103.1710
2024-04-29 03:57:43 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #28: GFLOPs: 25.6256. Time: 9024.6030 us. Best GFLOPs: 103.1710
2024-04-29 03:57:43 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #29: GFLOPs: 15.2095. Time: 15205.0619 us. Best GFLOPs: 103.1710
2024-04-29 03:57:43 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #30: GFLOPs: 25.5368. Time: 9056.0019 us. Best GFLOPs: 103.1710
2024-04-29 03:57:43 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #31: GFLOPs: 30.1761. Time: 7663.7277 us. Best GFLOPs: 103.1710
2024-04-29 03:57:43 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #32: GFLOPs: 19.6351. Time: 11777.9540 us. Best GFLOPs: 103.1710
2024-04-29 03:57:43 [INFO] [task_scheduler.cc:121] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #33: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(7), T.int64(7), T.int64(512)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(9), T.int64(9), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused in T.parallel(T.int64(4), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(2), T.int64(7), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(7), T.int64(8), T.int64(1), T.int64(2), T.int64(1), T.int64(1)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(2)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(2) * T.int64(8) + oc_chunk_1 * T.int64(4) + oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(7), oh_1 + oh_2_init + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(7), ow_1 * T.int64(7) + ow_2_init + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(2) * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2_init * T.int64(2) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0 in T.grid(T.int64(64), T.int64(3)):
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(9)):
                        for ax4_fused in T.vectorized(T.int64(8)):
                            with T.block("data_pad"):
                                v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                                v_i2 = T.axis.spatial(T.int64(9), oh_1 + kh_0 + ax2)
                                v_i3 = T.axis.spatial(T.int64(9), ax3)
                                v_i4 = T.axis.spatial(T.int64(512), ic_0 * T.int64(8) + ax4_fused)
                                T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                                T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                                data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(8) and T.int64(1) <= v_i3 and v_i3 < T.int64(8), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                    for kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(7), T.int64(8), T.int64(8), T.int64(1), T.int64(3), T.int64(1), T.int64(2), T.int64(1), T.int64(1)):
                        for oc_block_3_fused in T.vectorized(T.int64(2)):
                            with T.block("conv2d_NCHWc_update"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                                v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(2) * T.int64(8) + oc_chunk_1 * T.int64(4) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                                v_oh = T.axis.spatial(T.int64(7), oh_1 + oh_2 + oh_3)
                                v_ow = T.axis.spatial(T.int64(7), ow_1 * T.int64(7) + ow_2 + ow_3)
                                v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(2) * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2 * T.int64(2) + oc_block_3_fused)
                                v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(8) + ic_1)
                                v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                                v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                                T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(8), T.int64(7), T.int64(7)):
                for ax4_fused in T.vectorized(T.int64(16)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(2) * T.int64(8) + ax1)
                        v_ax2, v_ax3 = T.axis.remap("SS", [ax2, ax3])
                        v_ax4 = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(2) * T.int64(16) + ax4_fused)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[2, 2, 2, 2])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 7, 1, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 7, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[2, 1, 8, 2])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[64, 8])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=11)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87 = sch.get_loops(block=b68)
l88 = sch.fuse(l71, l72, l73, l74, l75, preserve_unit_iters=True)
sch.parallel(loop=l88)
l89 = sch.fuse(l87, preserve_unit_iters=True)
sch.vectorize(loop=l89)
l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107, l108, l109, l110, l111 = sch.get_loops(block=b69)
l112 = sch.fuse(l90, preserve_unit_iters=True)
sch.parallel(loop=l112)
l113 = sch.fuse(l111, preserve_unit_iters=True)
sch.vectorize(loop=l113)
sch.annotate(block_or_loop=l112, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l112, ann_key="pragma_unroll_explicit", ann_val=1)
l114, l115, l116, l117, l118, l119 = sch.get_loops(block=b70)
l120 = sch.fuse(l119, preserve_unit_iters=True)
sch.vectorize(loop=l120)
b121 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141, l142, l143 = sch.get_loops(block=b121)
b144 = sch.decompose_reduction(block=b121, loop=l128)
2024-04-29 03:57:43 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #34: GFLOPs: 25.2427. Time: 9161.5222 us. Best GFLOPs: 103.1710
2024-04-29 03:57:43 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #35: GFLOPs: 17.1184. Time: 13509.5427 us. Best GFLOPs: 103.1710
2024-04-29 03:57:43 [INFO] [task_scheduler.cc:121] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #36: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(7), T.int64(7), T.int64(512)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(9), T.int64(9), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused in T.parallel(T.int64(2), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(9), T.int64(9), T.int64(512)):
                with T.block("data_pad"):
                    v_i0, v_i1, v_i2, v_i3, v_i4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(8) and T.int64(1) <= v_i3 and v_i3 < T.int64(8), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(2), T.int64(7), T.int64(1), T.int64(1), T.int64(1), T.int64(8), T.int64(1), T.int64(7)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(8)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(16), oc_chunk_1 * T.int64(16) + oc_chunk_2_init * T.int64(8) + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(7), oh_1 * T.int64(7) + oh_2_init + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(7), ow_1 * T.int64(7) + ow_2_init * T.int64(7) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused * T.int64(16) + oc_block_1 * T.int64(8) + oc_block_2_init * T.int64(8) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(32), T.int64(3), T.int64(3), T.int64(1), T.int64(2), T.int64(7), T.int64(1), T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(1), T.int64(8), T.int64(1), T.int64(7)):
                    for oc_block_3_fused in T.vectorized(T.int64(8)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(16), oc_chunk_1 * T.int64(16) + oc_chunk_2 * T.int64(8) + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(7), oh_1 * T.int64(7) + oh_2 + oh_3)
                            v_ow = T.axis.spatial(T.int64(7), ow_1 * T.int64(7) + ow_2 * T.int64(7) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused * T.int64(16) + oc_block_1 * T.int64(8) + oc_block_2 * T.int64(8) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(16) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(16), T.int64(7), T.int64(7)):
                for ax4_fused in T.vectorized(T.int64(16)):
                    with T.block("T_relu"):
                        v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                        v_ax4 = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused * T.int64(16) + ax4_fused)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 2, 8])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 7, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 1, 7])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[2, 2, 1, 8])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[32, 16])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=4)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80 = sch.get_loops(block=b68)
l81 = sch.fuse(l71, l72, l73, l74, l75, preserve_unit_iters=True)
sch.parallel(loop=l81)
l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l82, preserve_unit_iters=True)
sch.parallel(loop=l104)
l105 = sch.fuse(l103, preserve_unit_iters=True)
sch.vectorize(loop=l105)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l106, l107, l108, l109, l110, l111 = sch.get_loops(block=b70)
l112 = sch.fuse(l111, preserve_unit_iters=True)
sch.vectorize(loop=l112)
b113 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135 = sch.get_loops(block=b113)
b136 = sch.decompose_reduction(block=b113, loop=l120)
2024-04-29 03:57:43 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #37: GFLOPs: 5.6830. Time: 40693.1997 us. Best GFLOPs: 103.1710
2024-04-29 03:57:43 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #38: GFLOPs: 2.2872. Time: 101112.4663 us. Best GFLOPs: 103.1710
2024-04-29 03:57:43 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #39: GFLOPs: 18.1107. Time: 12769.3385 us. Best GFLOPs: 103.1710
2024-04-29 03:57:43 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #40: GFLOPs: 42.9543. Time: 5383.8863 us. Best GFLOPs: 103.1710
2024-04-29 03:57:43 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #41: GFLOPs: 22.6498. Time: 10210.3177 us. Best GFLOPs: 103.1710
2024-04-29 03:57:43 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #42: GFLOPs: 3.1850. Time: 72609.2350 us. Best GFLOPs: 103.1710
2024-04-29 03:57:43 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #43: GFLOPs: 45.0379. Time: 5134.8102 us. Best GFLOPs: 103.1710
2024-04-29 03:57:43 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #44: GFLOPs: 79.8730. Time: 2895.3623 us. Best GFLOPs: 103.1710
2024-04-29 03:57:43 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #45: GFLOPs: 2.3745. Time: 97393.6213 us. Best GFLOPs: 103.1710
2024-04-29 03:57:43 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #46: GFLOPs: 53.7004. Time: 4306.5052 us. Best GFLOPs: 103.1710
2024-04-29 03:57:43 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #47: GFLOPs: 1.7719. Time: 130515.5367 us. Best GFLOPs: 103.1710
2024-04-29 03:57:43 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #48: GFLOPs: 1.0776. Time: 214603.9217 us. Best GFLOPs: 103.1710
2024-04-29 03:57:43 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #49: GFLOPs: 2.2023. Time: 105011.2510 us. Best GFLOPs: 103.1710
2024-04-29 03:57:43 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #50: GFLOPs: 19.9188. Time: 11610.1887 us. Best GFLOPs: 103.1710
2024-04-29 03:57:43 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #51: GFLOPs: 12.1928. Time: 18967.0547 us. Best GFLOPs: 103.1710
2024-04-29 03:57:43 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #52: GFLOPs: 8.5075. Time: 27183.3422 us. Best GFLOPs: 103.1710
2024-04-29 03:57:43 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #53: GFLOPs: 0.8436. Time: 274120.8750 us. Best GFLOPs: 103.1710
2024-04-29 03:57:43 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #54: GFLOPs: 80.5305. Time: 2871.7222 us. Best GFLOPs: 103.1710
2024-04-29 03:57:43 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #55: GFLOPs: 33.6703. Time: 6868.4106 us. Best GFLOPs: 103.1710
2024-04-29 03:57:43 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #56: GFLOPs: 44.8265. Time: 5159.0261 us. Best GFLOPs: 103.1710
2024-04-29 03:57:43 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #57: GFLOPs: 14.2983. Time: 16174.0581 us. Best GFLOPs: 103.1710
2024-04-29 03:57:43 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #58: GFLOPs: 65.8279. Time: 3513.1183 us. Best GFLOPs: 103.1710
2024-04-29 03:57:43 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #59: GFLOPs: 8.8096. Time: 26251.0060 us. Best GFLOPs: 103.1710
2024-04-29 03:57:43 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #60: GFLOPs: 31.4915. Time: 7343.6011 us. Best GFLOPs: 103.1710
2024-04-29 03:57:43 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #61: GFLOPs: 9.7829. Time: 23639.3990 us. Best GFLOPs: 103.1710
2024-04-29 03:57:43 [INFO] [task_scheduler.cc:121] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #62: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(7), T.int64(7), T.int64(512)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(9), T.int64(9), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused in T.parallel(T.int64(4), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1 in T.grid(T.int64(1), T.int64(4), T.int64(7)):
                for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(3), T.int64(9), T.int64(512)):
                    with T.block("data_pad"):
                        v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                        v_i2 = T.axis.spatial(T.int64(9), oh_1 + ax2)
                        v_i3, v_i4 = T.axis.remap("SS", [ax3, ax4])
                        T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                        T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                        data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(8) and T.int64(1) <= v_i3 and v_i3 < T.int64(8), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                for ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(2)):
                    for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                        for oc_block_3_fused_init in T.vectorized(T.int64(2)):
                            with T.block("conv2d_NCHWc_init"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                                v_oc_chunk = T.axis.spatial(T.int64(16), oc_chunk_1 * T.int64(4) + oc_chunk_2_init + oc_chunk_3_init)
                                v_oh = T.axis.spatial(T.int64(7), oh_1 + oh_2_init + oh_3_init)
                                v_ow = T.axis.spatial(T.int64(7), ow_1 * T.int64(7) + ow_2_init * T.int64(7) + ow_3_init)
                                v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused * T.int64(8) + oc_block_1 * T.int64(4) + oc_block_2_init * T.int64(2) + oc_block_3_fused_init)
                                T.reads()
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                    for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(16), T.int64(3), T.int64(1), T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(2), T.int64(32), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                        for oc_block_3_fused in T.vectorized(T.int64(2)):
                            with T.block("conv2d_NCHWc_update"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                                v_oc_chunk = T.axis.spatial(T.int64(16), oc_chunk_1 * T.int64(4) + oc_chunk_2 + oc_chunk_3)
                                v_oh = T.axis.spatial(T.int64(7), oh_1 + oh_2 + oh_3)
                                v_ow = T.axis.spatial(T.int64(7), ow_1 * T.int64(7) + ow_2 * T.int64(7) + ow_3)
                                v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused * T.int64(8) + oc_block_1 * T.int64(4) + oc_block_2 * T.int64(2) + oc_block_3_fused)
                                v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(32) + ic_1)
                                v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                                v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                                T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(16), T.int64(7), T.int64(7)):
                for ax4_fused in T.vectorized(T.int64(8)):
                    with T.block("T_relu"):
                        v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                        v_ax4 = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused * T.int64(8) + ax4_fused)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 4, 4, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 7, 1, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 1, 7])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[4, 2, 2, 2])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[16, 32])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=7)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83 = sch.get_loops(block=b68)
l84 = sch.fuse(l71, l72, l73, l74, l75, preserve_unit_iters=True)
sch.parallel(loop=l84)
l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106 = sch.get_loops(block=b69)
l107 = sch.fuse(l85, preserve_unit_iters=True)
sch.parallel(loop=l107)
l108 = sch.fuse(l106, preserve_unit_iters=True)
sch.vectorize(loop=l108)
sch.annotate(block_or_loop=l107, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l107, ann_key="pragma_unroll_explicit", ann_val=1)
l109, l110, l111, l112, l113, l114 = sch.get_loops(block=b70)
l115 = sch.fuse(l114, preserve_unit_iters=True)
sch.vectorize(loop=l115)
b116 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138 = sch.get_loops(block=b116)
b139 = sch.decompose_reduction(block=b116, loop=l123)
2024-04-29 03:57:43 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #63: GFLOPs: 1.9988. Time: 115701.7743 us. Best GFLOPs: 103.1710
2024-04-29 03:57:43 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #64: GFLOPs: 14.4361. Time: 16019.6564 us. Best GFLOPs: 103.1710
2024-04-29 04:03:11 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 04:03:12 [INFO] [evolutionary_search.cc:715] Picked top 57 candidate(s) from database
2024-04-29 04:03:16 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x5e10dc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x6d79bf8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x5e1f188)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3181528)]: 0 failure(s)
2024-04-29 04:03:16 [INFO] [evolutionary_search.cc:723] Sampled 455 candidate(s)
2024-04-29 04:03:27 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x5e10dc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x6d79bf8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x5e1f188)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3181528)]: 0 failure(s)
2024-04-29 04:03:38 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x5e10dc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x6d79bf8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x5e1f188)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3181528)]: 0 failure(s)
2024-04-29 04:03:49 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x5e10dc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x6d79bf8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x5e1f188)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3181528)]: 0 failure(s)
2024-04-29 04:04:01 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x5e10dc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x6d79bf8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x5e1f188)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3181528)]: 0 failure(s)
2024-04-29 04:04:07 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9063  0.8774  0.8661  0.8629  0.8472  0.8314  0.8249  0.8135  0.8092  0.8034  0.8029  0.8028  0.8018  0.7983  0.7954  0.7857
[17 : 32]:	0.7857  0.7857  0.7784  0.7712  0.7694  0.7635  0.7635  0.7628  0.7628  0.7598  0.7598  0.7595  0.7561  0.7526  0.7523  0.7523
[33 : 48]:	0.7500  0.7485  0.7464  0.7438  0.7428  0.7410  0.7393  0.7382  0.7352  0.7337  0.7329  0.7327  0.7311  0.7311  0.7295  0.7289
[49 : 64]:	0.7289  0.7226  0.7196  0.7162  0.7148  0.7135  0.7128  0.7128  0.7128  0.7128  0.7121  0.7114  0.7114  0.7087  0.7069  0.7032
2024-04-29 04:04:07 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 04:04:08 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 04:05:42 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #65: GFLOPs: 76.9296. Time: 3006.1391 us. Best GFLOPs: 103.1710
2024-04-29 04:05:42 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #66: GFLOPs: 142.9458. Time: 1617.8242 us. Best GFLOPs: 142.9458
2024-04-29 04:05:42 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #67: GFLOPs: 121.3974. Time: 1904.9934 us. Best GFLOPs: 142.9458
2024-04-29 04:05:42 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #68: GFLOPs: 125.3301. Time: 1845.2161 us. Best GFLOPs: 142.9458
2024-04-29 04:05:42 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #69: GFLOPs: 161.7217. Time: 1429.9949 us. Best GFLOPs: 161.7217
2024-04-29 04:05:42 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #70: GFLOPs: 162.3392. Time: 1424.5556 us. Best GFLOPs: 162.3392
2024-04-29 04:05:42 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #71: GFLOPs: 136.2854. Time: 1696.8891 us. Best GFLOPs: 162.3392
2024-04-29 04:05:42 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #72: GFLOPs: 165.5704. Time: 1396.7541 us. Best GFLOPs: 165.5704
2024-04-29 04:05:42 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #73: GFLOPs: 126.5129. Time: 1827.9650 us. Best GFLOPs: 165.5704
2024-04-29 04:05:42 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #74: GFLOPs: 177.8966. Time: 1299.9752 us. Best GFLOPs: 177.8966
2024-04-29 04:05:42 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #75: GFLOPs: 235.8156. Time: 980.6866 us. Best GFLOPs: 235.8156
2024-04-29 04:05:42 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #76: GFLOPs: 69.2986. Time: 3337.1695 us. Best GFLOPs: 235.8156
2024-04-29 04:05:42 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #77: GFLOPs: 58.3581. Time: 3962.7960 us. Best GFLOPs: 235.8156
2024-04-29 04:05:42 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #78: GFLOPs: 119.1389. Time: 1941.1056 us. Best GFLOPs: 235.8156
2024-04-29 04:05:42 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #79: GFLOPs: 59.6574. Time: 3876.4879 us. Best GFLOPs: 235.8156
2024-04-29 04:05:42 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #80: GFLOPs: 128.4637. Time: 1800.2060 us. Best GFLOPs: 235.8156
2024-04-29 04:05:42 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #81: GFLOPs: 157.4909. Time: 1468.4099 us. Best GFLOPs: 235.8156
2024-04-29 04:05:42 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #82: GFLOPs: 141.2018. Time: 1637.8066 us. Best GFLOPs: 235.8156
2024-04-29 04:05:42 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #83: GFLOPs: 174.0204. Time: 1328.9317 us. Best GFLOPs: 235.8156
2024-04-29 04:05:42 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #84: GFLOPs: 181.1940. Time: 1276.3178 us. Best GFLOPs: 235.8156
2024-04-29 04:05:42 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #85: GFLOPs: 142.5873. Time: 1621.8918 us. Best GFLOPs: 235.8156
2024-04-29 04:05:42 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #86: GFLOPs: 84.5729. Time: 2734.4595 us. Best GFLOPs: 235.8156
2024-04-29 04:05:42 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #87: GFLOPs: 125.2519. Time: 1846.3683 us. Best GFLOPs: 235.8156
2024-04-29 04:05:42 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #88: GFLOPs: 16.0471. Time: 14411.4038 us. Best GFLOPs: 235.8156
2024-04-29 04:05:42 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #89: GFLOPs: 102.4822. Time: 2256.5975 us. Best GFLOPs: 235.8156
2024-04-29 04:05:42 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #90: GFLOPs: 179.9971. Time: 1284.8051 us. Best GFLOPs: 235.8156
2024-04-29 04:05:42 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #91: GFLOPs: 131.1377. Time: 1763.4990 us. Best GFLOPs: 235.8156
2024-04-29 04:05:42 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #92: GFLOPs: 87.2674. Time: 2650.0296 us. Best GFLOPs: 235.8156
2024-04-29 04:05:42 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #93: GFLOPs: 80.4991. Time: 2872.8412 us. Best GFLOPs: 235.8156
2024-04-29 04:05:42 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #94: GFLOPs: 39.1133. Time: 5912.6031 us. Best GFLOPs: 235.8156
2024-04-29 04:05:42 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #95: GFLOPs: 72.9461. Time: 3170.3002 us. Best GFLOPs: 235.8156
2024-04-29 04:05:42 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #96: GFLOPs: 73.2347. Time: 3157.8103 us. Best GFLOPs: 235.8156
2024-04-29 04:05:42 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #97: GFLOPs: 183.1187. Time: 1262.9035 us. Best GFLOPs: 235.8156
2024-04-29 04:05:42 [INFO] [task_scheduler.cc:121] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #98: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(7), T.int64(7), T.int64(512)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(9), T.int64(9), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused in T.parallel(T.int64(112), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(3), T.int64(9), T.int64(512)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(9), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(7) + ax2)
                    v_i3, v_i4 = T.axis.remap("SS", [ax3, ax4])
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(8) and T.int64(1) <= v_i3 and v_i3 < T.int64(8), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(7), T.int64(16), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(28) * T.int64(4) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(14) // T.int64(7) * T.int64(2) + oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(7) + oh_2_init + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(7), ow_1 * T.int64(7) + ow_2_init + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(28) // T.int64(14) * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(64), T.int64(3), T.int64(3), T.int64(1), T.int64(2), T.int64(1), T.int64(7), T.int64(16), T.int64(8), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(28) * T.int64(4) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(14) // T.int64(7) * T.int64(2) + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(7) + oh_2 + oh_3)
                        v_ow = T.axis.spatial(T.int64(7), ow_1 * T.int64(7) + ow_2 + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(28) // T.int64(14) * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(8) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(7)):
                    for ax4_fused in T.vectorized(T.int64(16)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(28) * T.int64(4) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(14) // T.int64(7) * T.int64(2) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(7) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(7), ax3)
                            v_ax4 = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(28) // T.int64(14) * T.int64(16) + ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[4, 2, 2, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 7, 1, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 7, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[2, 1, 16, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[64, 8])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=7)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83 = sch.get_loops(block=b68)
l84 = sch.fuse(l71, l72, l73, l74, l75, l76, l77, l78, preserve_unit_iters=True)
sch.parallel(loop=l84)
l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l85, preserve_unit_iters=True)
sch.parallel(loop=l104)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109, l110, l111, l112 = sch.get_loops(block=b70)
l113 = sch.fuse(l112, preserve_unit_iters=True)
sch.vectorize(loop=l113)
b114 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133 = sch.get_loops(block=b114)
b134 = sch.decompose_reduction(block=b114, loop=l118)
2024-04-29 04:05:42 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #99: GFLOPs: 87.9197. Time: 2630.3687 us. Best GFLOPs: 235.8156
2024-04-29 04:05:42 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #100: GFLOPs: 272.1450. Time: 849.7721 us. Best GFLOPs: 272.1450
2024-04-29 04:05:42 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #101: GFLOPs: 14.1604. Time: 16331.5259 us. Best GFLOPs: 272.1450
2024-04-29 04:05:42 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #102: GFLOPs: 15.8036. Time: 14633.4693 us. Best GFLOPs: 272.1450
2024-04-29 04:05:42 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #103: GFLOPs: 47.8880. Time: 4829.2141 us. Best GFLOPs: 272.1450
2024-04-29 04:05:42 [INFO] [task_scheduler.cc:121] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #104: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(7), T.int64(7), T.int64(512)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(9), T.int64(9), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused in T.parallel(T.int64(224), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                for oc_block_3_fused_init in T.vectorized(T.int64(4)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(32) // T.int64(4) * T.int64(2) + oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(32) + oh_2_init + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(7), ow_2_init * T.int64(7) + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(4) * T.int64(8) + oc_block_2_init * T.int64(4) + oc_block_3_fused_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
            for ic_0, kh_0 in T.grid(T.int64(16), T.int64(3)):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(9)):
                    for ax4_fused in T.vectorized(T.int64(32)):
                        with T.block("data_pad"):
                            v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                            v_i2 = T.axis.spatial(T.int64(9), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(32) + kh_0 + ax2)
                            v_i3 = T.axis.spatial(T.int64(9), ax3)
                            v_i4 = T.axis.spatial(T.int64(512), ic_0 * T.int64(32) + ax4_fused)
                            T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                            T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                            data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(8) and T.int64(1) <= v_i3 and v_i3 < T.int64(8), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                for kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(3), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(2), T.int64(32), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                    for oc_block_3_fused in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(32) // T.int64(4) * T.int64(2) + oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(32) + oh_2 + oh_3)
                            v_ow = T.axis.spatial(T.int64(7), ow_2 * T.int64(7) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(4) * T.int64(8) + oc_block_2 * T.int64(4) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(32) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(7)):
                for ax4_fused in T.vectorized(T.int64(8)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(32) // T.int64(4) * T.int64(2) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(32) + ax2)
                        v_ax3 = T.axis.spatial(T.int64(7), ax3)
                        v_ax4 = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(4) * T.int64(8) + ax4_fused)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 8, 2, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[7, 1, 1, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 1, 7])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 4, 2, 4])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[16, 32])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=11)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87 = sch.get_loops(block=b68)
l88 = sch.fuse(l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, preserve_unit_iters=True)
sch.parallel(loop=l88)
l89 = sch.fuse(l87, preserve_unit_iters=True)
sch.vectorize(loop=l89)
l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106 = sch.get_loops(block=b69)
l107 = sch.fuse(l90, preserve_unit_iters=True)
sch.parallel(loop=l107)
l108 = sch.fuse(l106, preserve_unit_iters=True)
sch.vectorize(loop=l108)
sch.annotate(block_or_loop=l107, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l107, ann_key="pragma_unroll_explicit", ann_val=1)
l109, l110, l111, l112, l113, l114 = sch.get_loops(block=b70)
l115 = sch.fuse(l114, preserve_unit_iters=True)
sch.vectorize(loop=l115)
b116 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133 = sch.get_loops(block=b116)
b134 = sch.decompose_reduction(block=b116, loop=l118)
2024-04-29 04:05:42 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #105: GFLOPs: 191.0047. Time: 1210.7615 us. Best GFLOPs: 272.1450
2024-04-29 04:05:42 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #106: GFLOPs: 56.3705. Time: 4102.5219 us. Best GFLOPs: 272.1450
2024-04-29 04:05:42 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #107: GFLOPs: 75.3144. Time: 3070.6102 us. Best GFLOPs: 272.1450
2024-04-29 04:05:42 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #108: GFLOPs: 22.6815. Time: 10196.0137 us. Best GFLOPs: 272.1450
2024-04-29 04:05:42 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #109: GFLOPs: 103.8548. Time: 2226.7744 us. Best GFLOPs: 272.1450
2024-04-29 04:05:42 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #110: GFLOPs: 62.7316. Time: 3686.5185 us. Best GFLOPs: 272.1450
2024-04-29 04:05:42 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #111: GFLOPs: 34.9040. Time: 6625.6267 us. Best GFLOPs: 272.1450
2024-04-29 04:05:42 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #112: GFLOPs: 89.3676. Time: 2587.7533 us. Best GFLOPs: 272.1450
2024-04-29 04:05:42 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #113: GFLOPs: 91.0041. Time: 2541.2170 us. Best GFLOPs: 272.1450
2024-04-29 04:05:42 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #114: GFLOPs: 145.6506. Time: 1587.7804 us. Best GFLOPs: 272.1450
2024-04-29 04:05:42 [INFO] [task_scheduler.cc:121] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #115: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(7), T.int64(7), T.int64(512)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(9), T.int64(9), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused in T.parallel(T.int64(56), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(9), T.int64(3), T.int64(512)):
                with T.block("data_pad"):
                    v_i0, v_i1, v_i2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                    v_i3 = T.axis.spatial(T.int64(9), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(14) // T.int64(2) + ax3)
                    v_i4 = T.axis.spatial(T.int64(512), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(8) and T.int64(1) <= v_i3 and v_i3 < T.int64(8), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(16), T.int64(1), T.int64(4), T.int64(7), T.int64(1), T.int64(1)):
                with T.block("conv2d_NCHWc_init"):
                    v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                    v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(14) * T.int64(4) + oc_chunk_2_init * T.int64(4) + oc_chunk_3_init)
                    v_oh = T.axis.spatial(T.int64(7), oh_2_init * T.int64(7) + oh_3_init)
                    v_ow = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(14) // T.int64(2) + ow_2_init + ow_3_init)
                    v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(2) * T.int64(16) + oc_block_2_init + oc_block_3_init)
                    T.reads()
                    T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                    T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                    conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
            for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(64), T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(16), T.int64(8), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(7), T.int64(1), T.int64(1)):
                with T.block("conv2d_NCHWc_update"):
                    v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                    v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(14) * T.int64(4) + oc_chunk_2 * T.int64(4) + oc_chunk_3)
                    v_oh = T.axis.spatial(T.int64(7), oh_2 * T.int64(7) + oh_3)
                    v_ow = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(14) // T.int64(2) + ow_2 + ow_3)
                    v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(2) * T.int64(16) + oc_block_2 + oc_block_3)
                    v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(8) + ic_1)
                    v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                    v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                    T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                    T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                    T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                    conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(4), T.int64(7), T.int64(1)):
                for ax4_fused in T.vectorized(T.int64(16)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(14) * T.int64(4) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(7), ax2)
                        v_ax3 = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(14) // T.int64(2) + ax3)
                        v_ax4 = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(2) * T.int64(16) + ax4_fused)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[2, 2, 1, 4])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 1, 7])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 7, 1, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 2, 16, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[64, 8])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=9)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85 = sch.get_loops(block=b68)
l86 = sch.fuse(l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, preserve_unit_iters=True)
sch.parallel(loop=l86)
l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l87, preserve_unit_iters=True)
sch.parallel(loop=l104)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109, l110 = sch.get_loops(block=b70)
l111 = sch.fuse(l110, preserve_unit_iters=True)
sch.vectorize(loop=l111)
b112 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l113, l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129 = sch.get_loops(block=b112)
b130 = sch.decompose_reduction(block=b112, loop=l114)
2024-04-29 04:05:42 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #116: GFLOPs: 160.3640. Time: 1442.1013 us. Best GFLOPs: 272.1450
2024-04-29 04:05:42 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #117: GFLOPs: 141.0369. Time: 1639.7212 us. Best GFLOPs: 272.1450
2024-04-29 04:05:42 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #118: GFLOPs: 246.7118. Time: 937.3740 us. Best GFLOPs: 272.1450
2024-04-29 04:05:42 [INFO] [task_scheduler.cc:121] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #119: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(7), T.int64(7), T.int64(512)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(9), T.int64(9), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused in T.parallel(T.int64(224), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                for oc_block_3_fused_init in T.vectorized(T.int64(4)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(16) // T.int64(2) * T.int64(2) + oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(32) + oh_2_init + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(7), ow_2_init * T.int64(7) + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(32) // T.int64(16) * T.int64(16) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(2) * T.int64(8) + oc_block_2_init * T.int64(4) + oc_block_3_fused_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
            for ic_0, kh_0 in T.grid(T.int64(16), T.int64(3)):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(9)):
                    for ax4_fused in T.vectorized(T.int64(32)):
                        with T.block("data_pad"):
                            v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                            v_i2 = T.axis.spatial(T.int64(9), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(32) + kh_0 + ax2)
                            v_i3 = T.axis.spatial(T.int64(9), ax3)
                            v_i4 = T.axis.spatial(T.int64(512), ic_0 * T.int64(32) + ax4_fused)
                            T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                            T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                            data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(8) and T.int64(1) <= v_i3 and v_i3 < T.int64(8), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                for kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(3), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(2), T.int64(32), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                    for oc_block_3_fused in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(16) // T.int64(2) * T.int64(2) + oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(32) + oh_2 + oh_3)
                            v_ow = T.axis.spatial(T.int64(7), ow_2 * T.int64(7) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(32) // T.int64(16) * T.int64(16) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(2) * T.int64(8) + oc_block_2 * T.int64(4) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(32) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(7)):
                for ax4_fused in T.vectorized(T.int64(8)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(16) // T.int64(2) * T.int64(2) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(32) + ax2)
                        v_ax3 = T.axis.spatial(T.int64(7), ax3)
                        v_ax4 = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(32) // T.int64(16) * T.int64(16) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(2) * T.int64(8) + ax4_fused)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 8, 2, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[7, 1, 1, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 1, 7])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[2, 2, 2, 4])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[16, 32])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=11)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87 = sch.get_loops(block=b68)
l88 = sch.fuse(l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, preserve_unit_iters=True)
sch.parallel(loop=l88)
l89 = sch.fuse(l87, preserve_unit_iters=True)
sch.vectorize(loop=l89)
l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106 = sch.get_loops(block=b69)
l107 = sch.fuse(l90, preserve_unit_iters=True)
sch.parallel(loop=l107)
l108 = sch.fuse(l106, preserve_unit_iters=True)
sch.vectorize(loop=l108)
sch.annotate(block_or_loop=l107, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l107, ann_key="pragma_unroll_explicit", ann_val=1)
l109, l110, l111, l112, l113, l114 = sch.get_loops(block=b70)
l115 = sch.fuse(l114, preserve_unit_iters=True)
sch.vectorize(loop=l115)
b116 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133 = sch.get_loops(block=b116)
b134 = sch.decompose_reduction(block=b116, loop=l118)
2024-04-29 04:05:42 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #120: GFLOPs: 61.9506. Time: 3732.9910 us. Best GFLOPs: 272.1450
2024-04-29 04:05:42 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #121: GFLOPs: 112.1701. Time: 2061.7000 us. Best GFLOPs: 272.1450
2024-04-29 04:05:42 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #122: GFLOPs: 116.8804. Time: 1978.6133 us. Best GFLOPs: 272.1450
2024-04-29 04:05:42 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #123: GFLOPs: 72.1423. Time: 3205.6246 us. Best GFLOPs: 272.1450
2024-04-29 04:05:42 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #124: GFLOPs: 295.9536. Time: 781.4102 us. Best GFLOPs: 295.9536
2024-04-29 04:05:42 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #125: GFLOPs: 281.4189. Time: 821.7684 us. Best GFLOPs: 295.9536
2024-04-29 04:05:42 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #126: GFLOPs: 54.2917. Time: 4259.6067 us. Best GFLOPs: 295.9536
2024-04-29 04:05:42 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #127: GFLOPs: 21.7626. Time: 10626.5281 us. Best GFLOPs: 295.9536
2024-04-29 04:05:42 [INFO] [task_scheduler.cc:121] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #128: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(7), T.int64(7), T.int64(512)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(9), T.int64(9), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused in T.parallel(T.int64(4), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1, ow_1 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(9), T.int64(3), T.int64(512)):
                    with T.block("data_pad"):
                        v_i0, v_i1, v_i2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                        v_i3 = T.axis.spatial(T.int64(9), ow_1 + ax3)
                        v_i4 = T.axis.spatial(T.int64(512), ax4)
                        T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                        T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                        data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(8) and T.int64(1) <= v_i3 and v_i3 < T.int64(8), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                for oc_block_1 in range(T.int64(4)):
                    for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1)):
                        for oc_block_3_fused_init in T.vectorized(T.int64(8)):
                            with T.block("conv2d_NCHWc_init"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                                v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused * T.int64(4) + oc_chunk_1 * T.int64(4) + oc_chunk_2_init + oc_chunk_3_init)
                                v_oh = T.axis.spatial(T.int64(7), oh_1 * T.int64(7) + oh_2_init * T.int64(7) + oh_3_init)
                                v_ow = T.axis.spatial(T.int64(7), ow_1 + ow_2_init + ow_3_init)
                                v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(8) + oc_block_2_init * T.int64(8) + oc_block_3_fused_init)
                                T.reads()
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                    for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(16), T.int64(3), T.int64(3), T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1)):
                        for oc_block_3_fused in T.vectorized(T.int64(8)):
                            with T.block("conv2d_NCHWc_update"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                                v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused * T.int64(4) + oc_chunk_1 * T.int64(4) + oc_chunk_2 + oc_chunk_3)
                                v_oh = T.axis.spatial(T.int64(7), oh_1 * T.int64(7) + oh_2 * T.int64(7) + oh_3)
                                v_ow = T.axis.spatial(T.int64(7), ow_1 + ow_2 + ow_3)
                                v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(8) + oc_block_2 * T.int64(8) + oc_block_3_fused)
                                v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(32) + ic_1)
                                v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                                v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                                T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(4), T.int64(7), T.int64(7)):
                for ax4_fused in T.vectorized(T.int64(32)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused * T.int64(4) + ax1)
                        v_ax2, v_ax3, v_ax4 = T.axis.remap("SSS", [ax2, ax3, ax4_fused])
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[4, 1, 4, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 1, 7])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 7, 1, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 4, 1, 8])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[16, 32])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=8)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b68)
l85 = sch.fuse(l71, l72, l73, l74, l75, preserve_unit_iters=True)
sch.parallel(loop=l85)
l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107 = sch.get_loops(block=b69)
l108 = sch.fuse(l86, preserve_unit_iters=True)
sch.parallel(loop=l108)
l109 = sch.fuse(l107, preserve_unit_iters=True)
sch.vectorize(loop=l109)
sch.annotate(block_or_loop=l108, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l108, ann_key="pragma_unroll_explicit", ann_val=1)
l110, l111, l112, l113, l114, l115 = sch.get_loops(block=b70)
l116 = sch.fuse(l115, preserve_unit_iters=True)
sch.vectorize(loop=l116)
b117 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139 = sch.get_loops(block=b117)
b140 = sch.decompose_reduction(block=b117, loop=l124)
2024-04-29 04:45:33 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 04:45:34 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-29 04:45:38 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x5e10dc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x6d79bf8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x5e1f188)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3181528)]: 0 failure(s)
2024-04-29 04:45:38 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-29 04:45:49 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x5e10dc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x6d79bf8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x5e1f188)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3181528)]: 0 failure(s)
2024-04-29 04:46:00 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x5e10dc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x6d79bf8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x5e1f188)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3181528)]: 0 failure(s)
2024-04-29 04:46:12 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x5e10dc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x6d79bf8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x5e1f188)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3181528)]: 0 failure(s)
2024-04-29 04:46:23 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x5e10dc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x6d79bf8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x5e1f188)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3181528)]: 0 failure(s)
2024-04-29 04:46:30 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9666  0.9382  0.8583  0.8391  0.8391  0.8391  0.8215  0.7997  0.7980  0.7902  0.7862  0.7821  0.7783  0.7598  0.7504  0.7355
[17 : 32]:	0.7340  0.7337  0.7287  0.7260  0.7197  0.7128  0.7104  0.6975  0.6901  0.6852  0.6842  0.6818  0.6784  0.6704  0.6704  0.6673
[33 : 48]:	0.6532  0.6511  0.6463  0.6428  0.6391  0.6391  0.6372  0.6316  0.6216  0.6214  0.6164  0.6081  0.6057  0.6055  0.6010  0.6001
[49 : 64]:	0.5979  0.5979  0.5963  0.5963  0.5951  0.5947  0.5913  0.5877  0.5876  0.5870  0.5870  0.5862  0.5856  0.5851  0.5851  0.5835
2024-04-29 04:46:30 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 04:46:30 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 04:48:14 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #129: GFLOPs: 28.9809. Time: 7979.7666 us. Best GFLOPs: 295.9536
2024-04-29 04:48:14 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #130: GFLOPs: 295.2808. Time: 783.1909 us. Best GFLOPs: 295.9536
2024-04-29 04:48:14 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #131: GFLOPs: 295.4820. Time: 782.6575 us. Best GFLOPs: 295.9536
2024-04-29 04:48:14 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #132: GFLOPs: 47.3336. Time: 4885.7671 us. Best GFLOPs: 295.9536
2024-04-29 04:48:14 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #133: GFLOPs: 42.8992. Time: 5390.8051 us. Best GFLOPs: 295.9536
2024-04-29 04:48:14 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #134: GFLOPs: 43.8204. Time: 5277.4774 us. Best GFLOPs: 295.9536
2024-04-29 04:48:14 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #135: GFLOPs: 229.1874. Time: 1009.0485 us. Best GFLOPs: 295.9536
2024-04-29 04:48:14 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #136: GFLOPs: 46.4362. Time: 4980.1911 us. Best GFLOPs: 295.9536
2024-04-29 04:48:14 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #137: GFLOPs: 260.1415. Time: 888.9822 us. Best GFLOPs: 295.9536
2024-04-29 04:48:14 [INFO] [task_scheduler.cc:121] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #138: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(7), T.int64(7), T.int64(512)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(9), T.int64(9), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused in T.parallel(T.int64(224), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(8), T.int64(1), T.int64(2), T.int64(1), T.int64(7), T.int64(1)):
                with T.block("conv2d_NCHWc_init"):
                    v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                    v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(16) // T.int64(2) * T.int64(2) + oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                    v_oh = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(32) + oh_2_init + oh_3_init)
                    v_ow = T.axis.spatial(T.int64(7), ow_2_init * T.int64(7) + ow_3_init)
                    v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(32) // T.int64(16) * T.int64(16) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(2) * T.int64(8) + oc_block_2_init + oc_block_3_init)
                    T.reads()
                    T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                    T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                    conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
            for ic_0, kh_0 in T.grid(T.int64(16), T.int64(3)):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(9)):
                    for ax4_fused in T.vectorized(T.int64(32)):
                        with T.block("data_pad"):
                            v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                            v_i2 = T.axis.spatial(T.int64(9), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(32) + kh_0 + ax2)
                            v_i3 = T.axis.spatial(T.int64(9), ax3)
                            v_i4 = T.axis.spatial(T.int64(512), ic_0 * T.int64(32) + ax4_fused)
                            T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                            T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                            data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(8) and T.int64(1) <= v_i3 and v_i3 < T.int64(8), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                for kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(8), T.int64(32), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(7), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(16) // T.int64(2) * T.int64(2) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(32) + oh_2 + oh_3)
                        v_ow = T.axis.spatial(T.int64(7), ow_2 * T.int64(7) + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(32) // T.int64(16) * T.int64(16) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(2) * T.int64(8) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(32) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(7)):
                for ax4_fused in T.vectorized(T.int64(8)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(16) // T.int64(2) * T.int64(2) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(32) + ax2)
                        v_ax3 = T.axis.spatial(T.int64(7), ax3)
                        v_ax4 = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(32) // T.int64(16) * T.int64(16) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(2) * T.int64(8) + ax4_fused)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 8, 1, 2])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[7, 1, 1, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 1, 7])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[2, 2, 8, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[16, 32])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=11)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87 = sch.get_loops(block=b68)
l88 = sch.fuse(l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, preserve_unit_iters=True)
sch.parallel(loop=l88)
l89 = sch.fuse(l87, preserve_unit_iters=True)
sch.vectorize(loop=l89)
l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106 = sch.get_loops(block=b69)
l107 = sch.fuse(l90, preserve_unit_iters=True)
sch.parallel(loop=l107)
sch.annotate(block_or_loop=l107, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l107, ann_key="pragma_unroll_explicit", ann_val=1)
l108, l109, l110, l111, l112, l113 = sch.get_loops(block=b70)
l114 = sch.fuse(l113, preserve_unit_iters=True)
sch.vectorize(loop=l114)
b115 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132 = sch.get_loops(block=b115)
b133 = sch.decompose_reduction(block=b115, loop=l117)
2024-04-29 04:48:14 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #139: GFLOPs: 273.4151. Time: 845.8244 us. Best GFLOPs: 295.9536
2024-04-29 04:48:14 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #140: GFLOPs: 227.1025. Time: 1018.3120 us. Best GFLOPs: 295.9536
2024-04-29 04:48:14 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #141: GFLOPs: 244.5086. Time: 945.8203 us. Best GFLOPs: 295.9536
2024-04-29 04:48:14 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #142: GFLOPs: 240.6777. Time: 960.8751 us. Best GFLOPs: 295.9536
2024-04-29 04:48:14 [INFO] [task_scheduler.cc:121] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #143: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(7), T.int64(7), T.int64(512)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(9), T.int64(9), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused in T.parallel(T.int64(224), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(8), T.int64(1), T.int64(2), T.int64(1), T.int64(7), T.int64(1)):
                with T.block("conv2d_NCHWc_init"):
                    v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                    v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(112) // T.int64(14) * T.int64(2) + oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                    v_oh = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(14) // T.int64(2) + oh_2_init + oh_3_init)
                    v_ow = T.axis.spatial(T.int64(7), ow_2_init * T.int64(7) + ow_3_init)
                    v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(112) * T.int64(16) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(2) * T.int64(8) + oc_block_2_init + oc_block_3_init)
                    T.reads()
                    T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                    T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                    conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
            for ic_0, kh_0 in T.grid(T.int64(16), T.int64(3)):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(9)):
                    for ax4_fused in T.vectorized(T.int64(32)):
                        with T.block("data_pad"):
                            v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                            v_i2 = T.axis.spatial(T.int64(9), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(14) // T.int64(2) + kh_0 + ax2)
                            v_i3 = T.axis.spatial(T.int64(9), ax3)
                            v_i4 = T.axis.spatial(T.int64(512), ic_0 * T.int64(32) + ax4_fused)
                            T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                            T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                            data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(8) and T.int64(1) <= v_i3 and v_i3 < T.int64(8), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                for kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(8), T.int64(32), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(7), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(112) // T.int64(14) * T.int64(2) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(14) // T.int64(2) + oh_2 + oh_3)
                        v_ow = T.axis.spatial(T.int64(7), ow_2 * T.int64(7) + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(112) * T.int64(16) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(2) * T.int64(8) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(32) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(7)):
                for ax4_fused in T.vectorized(T.int64(8)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(112) // T.int64(14) * T.int64(2) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(14) // T.int64(2) + ax2)
                        v_ax3 = T.axis.spatial(T.int64(7), ax3)
                        v_ax4 = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(112) * T.int64(16) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(2) * T.int64(8) + ax4_fused)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 8, 1, 2])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 7, 1, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 1, 7])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[2, 2, 8, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[16, 32])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=11)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87 = sch.get_loops(block=b68)
l88 = sch.fuse(l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, preserve_unit_iters=True)
sch.parallel(loop=l88)
l89 = sch.fuse(l87, preserve_unit_iters=True)
sch.vectorize(loop=l89)
l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106 = sch.get_loops(block=b69)
l107 = sch.fuse(l90, preserve_unit_iters=True)
sch.parallel(loop=l107)
sch.annotate(block_or_loop=l107, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l107, ann_key="pragma_unroll_explicit", ann_val=1)
l108, l109, l110, l111, l112, l113 = sch.get_loops(block=b70)
l114 = sch.fuse(l113, preserve_unit_iters=True)
sch.vectorize(loop=l114)
b115 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132 = sch.get_loops(block=b115)
b133 = sch.decompose_reduction(block=b115, loop=l117)
2024-04-29 04:48:14 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #144: GFLOPs: 132.2813. Time: 1748.2528 us. Best GFLOPs: 295.9536
2024-04-29 04:48:14 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #145: GFLOPs: 122.7861. Time: 1883.4475 us. Best GFLOPs: 295.9536
2024-04-29 04:48:14 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #146: GFLOPs: 54.8270. Time: 4218.0191 us. Best GFLOPs: 295.9536
2024-04-29 04:48:14 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #147: GFLOPs: 64.0243. Time: 3612.0824 us. Best GFLOPs: 295.9536
2024-04-29 04:48:14 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #148: GFLOPs: 122.0717. Time: 1894.4708 us. Best GFLOPs: 295.9536
2024-04-29 04:48:14 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #149: GFLOPs: 23.9114. Time: 9671.5668 us. Best GFLOPs: 295.9536
2024-04-29 04:48:14 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #150: GFLOPs: 43.5289. Time: 5312.8244 us. Best GFLOPs: 295.9536
2024-04-29 04:48:14 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #151: GFLOPs: 18.8798. Time: 12249.1034 us. Best GFLOPs: 295.9536
2024-04-29 04:48:14 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #152: GFLOPs: 176.9314. Time: 1307.0666 us. Best GFLOPs: 295.9536
2024-04-29 04:48:14 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #153: GFLOPs: 134.8117. Time: 1715.4383 us. Best GFLOPs: 295.9536
2024-04-29 04:48:14 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #154: GFLOPs: 308.7826. Time: 748.9450 us. Best GFLOPs: 308.7826
2024-04-29 04:48:14 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #155: GFLOPs: 139.5774. Time: 1656.8675 us. Best GFLOPs: 308.7826
2024-04-29 04:48:14 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #156: GFLOPs: 187.6272. Time: 1232.5566 us. Best GFLOPs: 308.7826
2024-04-29 04:48:14 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #157: GFLOPs: 154.9100. Time: 1492.8743 us. Best GFLOPs: 308.7826
2024-04-29 04:48:14 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #158: GFLOPs: 130.0527. Time: 1778.2118 us. Best GFLOPs: 308.7826
2024-04-29 04:48:14 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #159: GFLOPs: 142.0233. Time: 1628.3332 us. Best GFLOPs: 308.7826
2024-04-29 04:48:14 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #160: GFLOPs: 16.6407. Time: 13897.3471 us. Best GFLOPs: 308.7826
2024-04-29 04:48:14 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #161: GFLOPs: 80.7972. Time: 2862.2426 us. Best GFLOPs: 308.7826
2024-04-29 04:48:14 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #162: GFLOPs: 36.7274. Time: 6296.6943 us. Best GFLOPs: 308.7826
2024-04-29 04:48:14 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #163: GFLOPs: 242.9893. Time: 951.7342 us. Best GFLOPs: 308.7826
2024-04-29 04:48:14 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #164: GFLOPs: 116.8924. Time: 1978.4100 us. Best GFLOPs: 308.7826
2024-04-29 04:48:14 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #165: GFLOPs: 383.5102. Time: 603.0119 us. Best GFLOPs: 383.5102
2024-04-29 04:48:14 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #166: GFLOPs: 333.2438. Time: 693.9700 us. Best GFLOPs: 383.5102
2024-04-29 04:48:14 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #167: GFLOPs: 102.5780. Time: 2254.4918 us. Best GFLOPs: 383.5102
2024-04-29 04:48:14 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #168: GFLOPs: 248.2157. Time: 931.6943 us. Best GFLOPs: 383.5102
2024-04-29 04:48:14 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #169: GFLOPs: 132.3437. Time: 1747.4289 us. Best GFLOPs: 383.5102
2024-04-29 04:48:14 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #170: GFLOPs: 65.5842. Time: 3526.1722 us. Best GFLOPs: 383.5102
2024-04-29 04:48:14 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #171: GFLOPs: 167.8237. Time: 1378.0008 us. Best GFLOPs: 383.5102
2024-04-29 04:48:14 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #172: GFLOPs: 263.1614. Time: 878.7809 us. Best GFLOPs: 383.5102
2024-04-29 04:48:14 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #173: GFLOPs: 166.6347. Time: 1387.8333 us. Best GFLOPs: 383.5102
2024-04-29 04:48:14 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #174: GFLOPs: 132.9463. Time: 1739.5081 us. Best GFLOPs: 383.5102
2024-04-29 04:48:14 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #175: GFLOPs: 100.6365. Time: 2297.9860 us. Best GFLOPs: 383.5102
2024-04-29 04:48:14 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #176: GFLOPs: 169.3893. Time: 1365.2642 us. Best GFLOPs: 383.5102
2024-04-29 04:48:14 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #177: GFLOPs: 89.8896. Time: 2572.7234 us. Best GFLOPs: 383.5102
2024-04-29 04:48:14 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #178: GFLOPs: 53.8981. Time: 4290.7074 us. Best GFLOPs: 383.5102
2024-04-29 04:48:14 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #179: GFLOPs: 343.4810. Time: 673.2867 us. Best GFLOPs: 383.5102
2024-04-29 04:48:14 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #180: GFLOPs: 76.3546. Time: 3028.7802 us. Best GFLOPs: 383.5102
2024-04-29 04:48:14 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #181: GFLOPs: 145.0978. Time: 1593.8297 us. Best GFLOPs: 383.5102
2024-04-29 04:48:14 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #182: GFLOPs: 88.2443. Time: 2620.6932 us. Best GFLOPs: 383.5102
2024-04-29 04:48:14 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #183: GFLOPs: 201.5905. Time: 1147.1831 us. Best GFLOPs: 383.5102
2024-04-29 04:48:14 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #184: GFLOPs: 113.1068. Time: 2044.6271 us. Best GFLOPs: 383.5102
2024-04-29 04:48:14 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #185: GFLOPs: 137.4102. Time: 1682.9991 us. Best GFLOPs: 383.5102
2024-04-29 04:48:14 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #186: GFLOPs: 99.9837. Time: 2312.9879 us. Best GFLOPs: 383.5102
2024-04-29 04:48:14 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #187: GFLOPs: 52.4558. Time: 4408.6887 us. Best GFLOPs: 383.5102
2024-04-29 04:48:14 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #188: GFLOPs: 10.6750. Time: 21663.7536 us. Best GFLOPs: 383.5102
2024-04-29 04:48:14 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #189: GFLOPs: 161.1242. Time: 1435.2981 us. Best GFLOPs: 383.5102
2024-04-29 04:48:14 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #190: GFLOPs: 11.5303. Time: 20056.8842 us. Best GFLOPs: 383.5102
2024-04-29 04:48:14 [INFO] [task_scheduler.cc:121] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #191: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(7), T.int64(7), T.int64(512)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(9), T.int64(9), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)))
        for n_0_oc_chunk_0_fused_fused in T.parallel(T.int64(4), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(9), T.int64(9), T.int64(512)):
                with T.block("data_pad"):
                    v_i0, v_i1, v_i2, v_i3, v_i4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(8) and T.int64(1) <= v_i3 and v_i3 < T.int64(8), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oh_0, ow_0, oc_block_0 in T.grid(T.int64(7), T.int64(1), T.int64(2)):
                for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(4), T.int64(1), T.int64(7), T.int64(1)):
                    for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                        for oc_block_3_fused_init in T.vectorized(T.int64(16)):
                            with T.block("conv2d_NCHWc_init"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                                v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_fused_fused * T.int64(4) + oc_chunk_1 + oc_chunk_2_init + oc_chunk_3_init)
                                v_oh = T.axis.spatial(T.int64(7), oh_0 + oh_1 + oh_2_init + oh_3_init)
                                v_ow = T.axis.spatial(T.int64(7), ow_0 * T.int64(7) + ow_1 + ow_2_init + ow_3_init)
                                v_oc_block = T.axis.spatial(T.int64(32), oc_block_0 * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2_init * T.int64(16) + oc_block_3_fused_init)
                                T.reads()
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                    for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(512), T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                        for oc_block_3_fused in T.vectorized(T.int64(16)):
                            with T.block("conv2d_NCHWc_update"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                                v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_fused_fused * T.int64(4) + oc_chunk_1 + oc_chunk_2 + oc_chunk_3)
                                v_oh = T.axis.spatial(T.int64(7), oh_0 + oh_1 + oh_2 + oh_3)
                                v_ow = T.axis.spatial(T.int64(7), ow_0 * T.int64(7) + ow_1 + ow_2 + ow_3)
                                v_oc_block = T.axis.spatial(T.int64(32), oc_block_0 * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2 * T.int64(16) + oc_block_3_fused)
                                v_ic = T.axis.reduce(T.int64(512), ic_0 + ic_1)
                                v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                                v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                                T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(4), T.int64(1), T.int64(7)):
                    for ax4_fused in T.vectorized(T.int64(16)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_fused_fused * T.int64(4) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(7), oh_0 + ax2)
                            v_ax3 = T.axis.spatial(T.int64(7), ax3)
                            v_ax4 = T.axis.spatial(T.int64(32), oc_block_0 * T.int64(16) + ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[4, 4, 1, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[7, 1, 1, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 7, 1, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[2, 1, 1, 16])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[512, 1])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=1)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77 = sch.get_loops(block=b68)
l78 = sch.fuse(l71, l72, preserve_unit_iters=True)
sch.parallel(loop=l78)
l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l79, preserve_unit_iters=True)
sch.parallel(loop=l104)
l105 = sch.fuse(l103, preserve_unit_iters=True)
sch.vectorize(loop=l105)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l106, l107, l108, l109, l110, l111, l112, l113, l114 = sch.get_loops(block=b70)
l115 = sch.fuse(l114, preserve_unit_iters=True)
sch.vectorize(loop=l115)
b116 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141 = sch.get_loops(block=b116)
b142 = sch.decompose_reduction(block=b116, loop=l126)
2024-04-29 04:48:14 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #192: GFLOPs: 1.7050. Time: 135638.1547 us. Best GFLOPs: 383.5102
2024-04-29 05:28:14 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 05:28:15 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-29 05:28:19 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x5e10dc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x6d79bf8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x5e1f188)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3181528)]: 0 failure(s)
2024-04-29 05:28:19 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-29 05:28:30 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x5e10dc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x6d79bf8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x5e1f188)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3181528)]: 0 failure(s)
2024-04-29 05:28:41 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x5e10dc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x6d79bf8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x5e1f188)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3181528)]: 0 failure(s)
2024-04-29 05:28:52 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x5e10dc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x6d79bf8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x5e1f188)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3181528)]: 0 failure(s)
2024-04-29 05:29:04 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x5e10dc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x6d79bf8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x5e1f188)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3181528)]: 0 failure(s)
2024-04-29 05:29:10 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9329  0.9329  0.9217  0.9217  0.8972  0.8964  0.8844  0.8509  0.8501  0.8167  0.7976  0.7918  0.7918  0.7728  0.7728  0.7709
[17 : 32]:	0.7357  0.7261  0.7134  0.7128  0.7086  0.7030  0.6998  0.6895  0.6895  0.6842  0.6837  0.6837  0.6831  0.6801  0.6793  0.6793
[33 : 48]:	0.6781  0.6728  0.6720  0.6697  0.6606  0.6606  0.6605  0.6605  0.6583  0.6564  0.6551  0.6551  0.6546  0.6522  0.6515  0.6435
[49 : 64]:	0.6432  0.6427  0.6338  0.6298  0.6298  0.6261  0.6246  0.6246  0.6207  0.6207  0.6157  0.6157  0.6148  0.6011  0.6009  0.5994
2024-04-29 05:29:11 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 05:29:11 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 05:30:57 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #193: GFLOPs: 69.8564. Time: 3310.5224 us. Best GFLOPs: 383.5102
2024-04-29 05:30:57 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #194: GFLOPs: 113.6246. Time: 2035.3090 us. Best GFLOPs: 383.5102
2024-04-29 05:30:57 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #195: GFLOPs: 232.3068. Time: 995.4989 us. Best GFLOPs: 383.5102
2024-04-29 05:30:57 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #196: GFLOPs: 241.8102. Time: 956.3749 us. Best GFLOPs: 383.5102
2024-04-29 05:30:57 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #197: GFLOPs: 113.1121. Time: 2044.5312 us. Best GFLOPs: 383.5102
2024-04-29 05:30:57 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #198: GFLOPs: 250.9528. Time: 921.5326 us. Best GFLOPs: 383.5102
2024-04-29 05:30:57 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #199: GFLOPs: 338.4118. Time: 683.3721 us. Best GFLOPs: 383.5102
2024-04-29 05:30:57 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #200: GFLOPs: 379.5321. Time: 609.3324 us. Best GFLOPs: 383.5102
2024-04-29 05:30:57 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #201: GFLOPs: 388.0486. Time: 595.9593 us. Best GFLOPs: 388.0486
2024-04-29 05:30:57 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #202: GFLOPs: 329.7578. Time: 701.3061 us. Best GFLOPs: 388.0486
2024-04-29 05:30:57 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #203: GFLOPs: 135.6069. Time: 1705.3793 us. Best GFLOPs: 388.0486
2024-04-29 05:30:57 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #204: GFLOPs: 222.3640. Time: 1040.0118 us. Best GFLOPs: 388.0486
2024-04-29 05:30:57 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #205: GFLOPs: 281.8220. Time: 820.5932 us. Best GFLOPs: 388.0486
2024-04-29 05:30:57 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #206: GFLOPs: 45.2067. Time: 5115.6429 us. Best GFLOPs: 388.0486
2024-04-29 05:30:57 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #207: GFLOPs: 129.4807. Time: 1786.0670 us. Best GFLOPs: 388.0486
2024-04-29 05:30:57 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #208: GFLOPs: 163.0923. Time: 1417.9776 us. Best GFLOPs: 388.0486
2024-04-29 05:30:57 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #209: GFLOPs: 141.3591. Time: 1635.9842 us. Best GFLOPs: 388.0486
2024-04-29 05:30:57 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #210: GFLOPs: 55.3280. Time: 4179.8242 us. Best GFLOPs: 388.0486
2024-04-29 05:30:57 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #211: GFLOPs: 35.7300. Time: 6472.4604 us. Best GFLOPs: 388.0486
2024-04-29 05:30:57 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #212: GFLOPs: 354.8589. Time: 651.6990 us. Best GFLOPs: 388.0486
2024-04-29 05:30:57 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #213: GFLOPs: 249.0575. Time: 928.5454 us. Best GFLOPs: 388.0486
2024-04-29 05:30:57 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #214: GFLOPs: 310.5810. Time: 744.6083 us. Best GFLOPs: 388.0486
2024-04-29 05:30:57 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #215: GFLOPs: 315.3131. Time: 733.4334 us. Best GFLOPs: 388.0486
2024-04-29 05:30:57 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #216: GFLOPs: 313.6543. Time: 737.3122 us. Best GFLOPs: 388.0486
2024-04-29 05:30:57 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #217: GFLOPs: 307.9004. Time: 751.0910 us. Best GFLOPs: 388.0486
2024-04-29 05:30:57 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #218: GFLOPs: 254.3045. Time: 909.3871 us. Best GFLOPs: 388.0486
2024-04-29 05:30:57 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #219: GFLOPs: 68.8768. Time: 3357.6076 us. Best GFLOPs: 388.0486
2024-04-29 05:30:57 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #220: GFLOPs: 76.1552. Time: 3036.7083 us. Best GFLOPs: 388.0486
2024-04-29 05:30:57 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #221: GFLOPs: 68.2358. Time: 3389.1489 us. Best GFLOPs: 388.0486
2024-04-29 05:30:57 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #222: GFLOPs: 259.9658. Time: 889.5833 us. Best GFLOPs: 388.0486
2024-04-29 05:30:57 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #223: GFLOPs: 259.6243. Time: 890.7533 us. Best GFLOPs: 388.0486
2024-04-29 05:30:57 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #224: GFLOPs: 256.5603. Time: 901.3912 us. Best GFLOPs: 388.0486
2024-04-29 05:30:57 [INFO] [task_scheduler.cc:121] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #225: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(7), T.int64(7), T.int64(512)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(9), T.int64(9), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused in T.parallel(T.int64(112), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(3), T.int64(9), T.int64(512)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(9), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(28) // T.int64(4) + ax2)
                    v_i3, v_i4 = T.axis.remap("SS", [ax3, ax4])
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(8) and T.int64(1) <= v_i3 and v_i3 < T.int64(8), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(32), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(28) * T.int64(4) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(4) + oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(28) // T.int64(4) + oh_1 + oh_2_init + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(7), ow_1 * T.int64(7) + ow_2_init + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(256), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(32), T.int64(2), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(28) * T.int64(4) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(4) + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(28) // T.int64(4) + oh_1 + oh_2 + oh_3)
                        v_ow = T.axis.spatial(T.int64(7), ow_1 * T.int64(7) + ow_2 + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(2) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                    for ax4_fused in T.vectorized(T.int64(32)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(28) * T.int64(4) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(4) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(28) // T.int64(4) + ax2)
                            v_ax3, v_ax4 = T.axis.remap("SS", [ax3, ax4_fused])
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[4, 4, 1, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[7, 1, 1, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 7, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 32, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[256, 2])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=6)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82 = sch.get_loops(block=b68)
l83 = sch.fuse(l71, l72, l73, l74, l75, l76, l77, preserve_unit_iters=True)
sch.parallel(loop=l83)
l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l84, preserve_unit_iters=True)
sch.parallel(loop=l104)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109, l110, l111, l112, l113 = sch.get_loops(block=b70)
l114 = sch.fuse(l113, preserve_unit_iters=True)
sch.vectorize(loop=l114)
b115 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135 = sch.get_loops(block=b115)
b136 = sch.decompose_reduction(block=b115, loop=l120)
2024-04-29 05:30:57 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #226: GFLOPs: 164.4648. Time: 1406.1443 us. Best GFLOPs: 388.0486
2024-04-29 05:30:57 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #227: GFLOPs: 37.1239. Time: 6229.4382 us. Best GFLOPs: 388.0486
2024-04-29 05:30:57 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #228: GFLOPs: 37.8742. Time: 6106.0285 us. Best GFLOPs: 388.0486
2024-04-29 05:30:57 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #229: GFLOPs: 187.7950. Time: 1231.4555 us. Best GFLOPs: 388.0486
2024-04-29 05:30:57 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #230: GFLOPs: 185.6615. Time: 1245.6066 us. Best GFLOPs: 388.0486
2024-04-29 05:30:57 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #231: GFLOPs: 192.3489. Time: 1202.3005 us. Best GFLOPs: 388.0486
2024-04-29 05:30:57 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #232: GFLOPs: 133.9085. Time: 1727.0093 us. Best GFLOPs: 388.0486
2024-04-29 05:30:57 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #233: GFLOPs: 268.4221. Time: 861.5580 us. Best GFLOPs: 388.0486
2024-04-29 05:30:57 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #234: GFLOPs: 79.5394. Time: 2907.5031 us. Best GFLOPs: 388.0486
2024-04-29 05:30:57 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #235: GFLOPs: 90.9364. Time: 2543.1080 us. Best GFLOPs: 388.0486
2024-04-29 05:30:57 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #236: GFLOPs: 38.8095. Time: 5958.8841 us. Best GFLOPs: 388.0486
2024-04-29 05:30:57 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #237: GFLOPs: 256.1974. Time: 902.6678 us. Best GFLOPs: 388.0486
2024-04-29 05:30:57 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #238: GFLOPs: 81.0871. Time: 2852.0104 us. Best GFLOPs: 388.0486
2024-04-29 05:30:57 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #239: GFLOPs: 471.7322. Time: 490.2383 us. Best GFLOPs: 471.7322
2024-04-29 05:30:57 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #240: GFLOPs: 168.3227. Time: 1373.9152 us. Best GFLOPs: 471.7322
2024-04-29 05:30:57 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #241: GFLOPs: 80.4204. Time: 2875.6523 us. Best GFLOPs: 471.7322
2024-04-29 05:30:57 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #242: GFLOPs: 255.9507. Time: 903.5379 us. Best GFLOPs: 471.7322
2024-04-29 05:30:57 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #243: GFLOPs: 186.8996. Time: 1237.3551 us. Best GFLOPs: 471.7322
2024-04-29 05:30:57 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #244: GFLOPs: 262.0448. Time: 882.5252 us. Best GFLOPs: 471.7322
2024-04-29 05:30:57 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #245: GFLOPs: 279.0811. Time: 828.6522 us. Best GFLOPs: 471.7322
2024-04-29 05:30:57 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #246: GFLOPs: 362.5285. Time: 637.9117 us. Best GFLOPs: 471.7322
2024-04-29 05:30:57 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #247: GFLOPs: 256.0750. Time: 903.0994 us. Best GFLOPs: 471.7322
2024-04-29 05:30:57 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #248: GFLOPs: 210.4383. Time: 1098.9500 us. Best GFLOPs: 471.7322
2024-04-29 05:30:57 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #249: GFLOPs: 178.9799. Time: 1292.1071 us. Best GFLOPs: 471.7322
2024-04-29 05:30:57 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #250: GFLOPs: 190.4262. Time: 1214.4397 us. Best GFLOPs: 471.7322
2024-04-29 05:30:57 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #251: GFLOPs: 109.9142. Time: 2104.0149 us. Best GFLOPs: 471.7322
2024-04-29 05:30:57 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #252: GFLOPs: 88.6708. Time: 2608.0871 us. Best GFLOPs: 471.7322
2024-04-29 05:30:57 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #253: GFLOPs: 192.6075. Time: 1200.6866 us. Best GFLOPs: 471.7322
2024-04-29 05:30:57 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #254: GFLOPs: 21.7623. Time: 10626.6697 us. Best GFLOPs: 471.7322
2024-04-29 05:30:57 [INFO] [task_scheduler.cc:121] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #255: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(7), T.int64(7), T.int64(512)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(9), T.int64(9), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused in T.parallel(T.int64(392), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(3), T.int64(3), T.int64(512)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(9), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(14) // T.int64(2) + ax2)
                    v_i3 = T.axis.spatial(T.int64(9), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(98) // T.int64(14) + ax3)
                    v_i4 = T.axis.spatial(T.int64(512), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(8) and T.int64(1) <= v_i3 and v_i3 < T.int64(8), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                for oc_block_3_fused_init in T.vectorized(T.int64(4)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(98) * T.int64(4) + oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(14) // T.int64(2) + oh_2_init + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(98) // T.int64(14) + ow_2_init + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(2) * T.int64(16) + oc_block_2_init * T.int64(4) + oc_block_3_fused_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
            for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(512), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(4), T.int64(1), T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                for oc_block_3_fused in T.vectorized(T.int64(4)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(98) * T.int64(4) + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(14) // T.int64(2) + oh_2 + oh_3)
                        v_ow = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(98) // T.int64(14) + ow_2 + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(2) * T.int64(16) + oc_block_2 * T.int64(4) + oc_block_3_fused)
                        v_ic = T.axis.reduce(T.int64(512), ic_0 + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(4), T.int64(1), T.int64(1)):
                for ax4_fused in T.vectorized(T.int64(16)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(98) * T.int64(4) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(14) // T.int64(2) + ax2)
                        v_ax3 = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(98) // T.int64(14) + ax3)
                        v_ax4 = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(2) * T.int64(16) + ax4_fused)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[4, 1, 4, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 7, 1, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[7, 1, 1, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 2, 4, 4])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[512, 1])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=9)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85 = sch.get_loops(block=b68)
l86 = sch.fuse(l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, preserve_unit_iters=True)
sch.parallel(loop=l86)
l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l87, preserve_unit_iters=True)
sch.parallel(loop=l104)
l105 = sch.fuse(l103, preserve_unit_iters=True)
sch.vectorize(loop=l105)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l106, l107, l108, l109, l110, l111 = sch.get_loops(block=b70)
l112 = sch.fuse(l111, preserve_unit_iters=True)
sch.vectorize(loop=l112)
b113 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130 = sch.get_loops(block=b113)
b131 = sch.decompose_reduction(block=b113, loop=l115)
2024-04-29 05:30:57 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #256: GFLOPs: 12.9570. Time: 17848.3835 us. Best GFLOPs: 471.7322
2024-04-29 05:30:58 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 05:30:59 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-29 05:31:03 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x5e10dc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x6d79bf8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x5e1f188)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3181528)]: 0 failure(s)
2024-04-29 05:31:03 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-29 05:31:14 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x5e10dc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x6d79bf8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x5e1f188)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3181528)]: 0 failure(s)
2024-04-29 05:31:25 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x5e10dc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x6d79bf8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x5e1f188)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3181528)]: 0 failure(s)
2024-04-29 05:31:37 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x5e10dc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x6d79bf8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x5e1f188)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3181528)]: 0 failure(s)
2024-04-29 05:31:48 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x5e10dc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x6d79bf8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x5e1f188)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3181528)]: 0 failure(s)
2024-04-29 05:31:55 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.7821  0.7819  0.7761  0.7731  0.7712  0.7524  0.7438  0.7223  0.7221  0.7074  0.7070  0.6962  0.6962  0.6938  0.6938  0.6863
[17 : 32]:	0.6861  0.6853  0.6778  0.6749  0.6749  0.6749  0.6731  0.6731  0.6703  0.6694  0.6637  0.6637  0.6634  0.6585  0.6582  0.6582
[33 : 48]:	0.6581  0.6545  0.6530  0.6404  0.6291  0.6273  0.6225  0.6174  0.6137  0.6040  0.6040  0.6022  0.6015  0.5910  0.5895  0.5890
[49 : 64]:	0.5890  0.5880  0.5850  0.5807  0.5741  0.5705  0.5702  0.5699  0.5699  0.5685  0.5656  0.5631  0.5629  0.5604  0.5567  0.5542
2024-04-29 05:31:56 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 05:31:56 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 05:33:50 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #257: GFLOPs: 130.4634. Time: 1772.6130 us. Best GFLOPs: 471.7322
2024-04-29 05:33:50 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #258: GFLOPs: 244.6667. Time: 945.2091 us. Best GFLOPs: 471.7322
2024-04-29 05:33:50 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #259: GFLOPs: 185.6625. Time: 1245.5997 us. Best GFLOPs: 471.7322
2024-04-29 05:33:50 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #260: GFLOPs: 379.4138. Time: 609.5224 us. Best GFLOPs: 471.7322
2024-04-29 05:33:50 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #261: GFLOPs: 280.9238. Time: 823.2168 us. Best GFLOPs: 471.7322
2024-04-29 05:33:50 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #262: GFLOPs: 455.4856. Time: 507.7244 us. Best GFLOPs: 471.7322
2024-04-29 05:33:50 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #263: GFLOPs: 351.0385. Time: 658.7915 us. Best GFLOPs: 471.7322
2024-04-29 05:33:50 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #264: GFLOPs: 362.6104. Time: 637.7677 us. Best GFLOPs: 471.7322
2024-04-29 05:33:50 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #265: GFLOPs: 255.2150. Time: 906.1427 us. Best GFLOPs: 471.7322
2024-04-29 05:33:50 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #266: GFLOPs: 312.4272. Time: 740.2083 us. Best GFLOPs: 471.7322
2024-04-29 05:33:50 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #267: GFLOPs: 385.8366. Time: 599.3760 us. Best GFLOPs: 471.7322
2024-04-29 05:33:50 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #268: GFLOPs: 342.0236. Time: 676.1556 us. Best GFLOPs: 471.7322
2024-04-29 05:33:50 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #269: GFLOPs: 340.2958. Time: 679.5887 us. Best GFLOPs: 471.7322
2024-04-29 05:33:50 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #270: GFLOPs: 496.6585. Time: 465.6342 us. Best GFLOPs: 496.6585
2024-04-29 05:33:50 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #271: GFLOPs: 506.1904. Time: 456.8660 us. Best GFLOPs: 506.1904
2024-04-29 05:33:50 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #272: GFLOPs: 348.0060. Time: 664.5321 us. Best GFLOPs: 506.1904
2024-04-29 05:33:50 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #273: GFLOPs: 366.1997. Time: 631.5166 us. Best GFLOPs: 506.1904
2024-04-29 05:33:50 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #274: GFLOPs: 259.0328. Time: 892.7872 us. Best GFLOPs: 506.1904
2024-04-29 05:33:50 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #275: GFLOPs: 655.4694. Time: 352.8177 us. Best GFLOPs: 655.4694
2024-04-29 05:33:50 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #276: GFLOPs: 362.2738. Time: 638.3602 us. Best GFLOPs: 655.4694
2024-04-29 05:33:50 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #277: GFLOPs: 331.9258. Time: 696.7255 us. Best GFLOPs: 655.4694
2024-04-29 05:33:50 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #278: GFLOPs: 168.9133. Time: 1369.1116 us. Best GFLOPs: 655.4694
2024-04-29 05:33:50 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #279: GFLOPs: 211.8099. Time: 1091.8336 us. Best GFLOPs: 655.4694
2024-04-29 05:33:50 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #280: GFLOPs: 202.6712. Time: 1141.0660 us. Best GFLOPs: 655.4694
2024-04-29 05:33:50 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #281: GFLOPs: 394.8729. Time: 585.6599 us. Best GFLOPs: 655.4694
2024-04-29 05:33:50 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #282: GFLOPs: 354.5827. Time: 652.2065 us. Best GFLOPs: 655.4694
2024-04-29 05:33:50 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #283: GFLOPs: 389.5056. Time: 593.7300 us. Best GFLOPs: 655.4694
2024-04-29 05:33:50 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #284: GFLOPs: 374.0165. Time: 618.3182 us. Best GFLOPs: 655.4694
2024-04-29 05:33:50 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #285: GFLOPs: 393.2129. Time: 588.1323 us. Best GFLOPs: 655.4694
2024-04-29 05:33:50 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #286: GFLOPs: 179.2696. Time: 1290.0187 us. Best GFLOPs: 655.4694
2024-04-29 05:33:50 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #287: GFLOPs: 440.1407. Time: 525.4256 us. Best GFLOPs: 655.4694
2024-04-29 05:33:50 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #288: GFLOPs: 444.3407. Time: 520.4592 us. Best GFLOPs: 655.4694
2024-04-29 05:33:50 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #289: GFLOPs: 191.7676. Time: 1205.9449 us. Best GFLOPs: 655.4694
2024-04-29 05:33:50 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #290: GFLOPs: 337.9660. Time: 684.2734 us. Best GFLOPs: 655.4694
2024-04-29 05:33:50 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #291: GFLOPs: 254.2471. Time: 909.5921 us. Best GFLOPs: 655.4694
2024-04-29 05:33:50 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #292: GFLOPs: 226.3967. Time: 1021.4864 us. Best GFLOPs: 655.4694
2024-04-29 05:33:50 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #293: GFLOPs: 283.4088. Time: 815.9987 us. Best GFLOPs: 655.4694
2024-04-29 05:33:50 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #294: GFLOPs: 219.3718. Time: 1054.1974 us. Best GFLOPs: 655.4694
2024-04-29 05:33:50 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #295: GFLOPs: 378.0523. Time: 611.7175 us. Best GFLOPs: 655.4694
2024-04-29 05:33:50 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #296: GFLOPs: 211.8059. Time: 1091.8543 us. Best GFLOPs: 655.4694
2024-04-29 05:33:50 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #297: GFLOPs: 344.2025. Time: 671.8754 us. Best GFLOPs: 655.4694
2024-04-29 05:33:50 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #298: GFLOPs: 240.8005. Time: 960.3852 us. Best GFLOPs: 655.4694
2024-04-29 05:33:50 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #299: GFLOPs: 230.1463. Time: 1004.8443 us. Best GFLOPs: 655.4694
2024-04-29 05:33:50 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #300: GFLOPs: 340.6138. Time: 678.9543 us. Best GFLOPs: 655.4694
2024-04-29 05:33:50 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #301: GFLOPs: 273.7940. Time: 844.6538 us. Best GFLOPs: 655.4694
2024-04-29 05:33:50 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #302: GFLOPs: 321.0766. Time: 720.2678 us. Best GFLOPs: 655.4694
2024-04-29 05:33:50 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #303: GFLOPs: 587.5148. Time: 393.6261 us. Best GFLOPs: 655.4694
2024-04-29 05:33:50 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #304: GFLOPs: 269.7943. Time: 857.1758 us. Best GFLOPs: 655.4694
2024-04-29 05:33:50 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #305: GFLOPs: 272.8842. Time: 847.4701 us. Best GFLOPs: 655.4694
2024-04-29 05:33:50 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #306: GFLOPs: 216.3168. Time: 1069.0856 us. Best GFLOPs: 655.4694
2024-04-29 05:33:50 [INFO] [task_scheduler.cc:121] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #307: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(7), T.int64(7), T.int64(512)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(9), T.int64(9), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused in T.parallel(T.int64(112), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(3), T.int64(9), T.int64(512)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(9), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(14) // T.int64(2) + ax2)
                    v_i3, v_i4 = T.axis.remap("SS", [ax3, ax4])
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(8) and T.int64(1) <= v_i3 and v_i3 < T.int64(8), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(32), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(14) * T.int64(2) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(2) + oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(14) // T.int64(2) + oh_1 + oh_2_init + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(7), ow_1 * T.int64(7) + ow_2_init + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(512), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(32), T.int64(1), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(14) * T.int64(2) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(2) + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(14) // T.int64(2) + oh_1 + oh_2 + oh_3)
                        v_ow = T.axis.spatial(T.int64(7), ow_1 * T.int64(7) + ow_2 + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(512), ic_0 + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                    for ax4_fused in T.vectorized(T.int64(32)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(14) * T.int64(2) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(2) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(14) // T.int64(2) + ax2)
                            v_ax3, v_ax4 = T.axis.remap("SS", [ax3, ax4_fused])
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[8, 2, 1, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[7, 1, 1, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 7, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 32, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[512, 1])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=6)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82 = sch.get_loops(block=b68)
l83 = sch.fuse(l71, l72, l73, l74, l75, l76, l77, preserve_unit_iters=True)
sch.parallel(loop=l83)
l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l84, preserve_unit_iters=True)
sch.parallel(loop=l104)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109, l110, l111, l112, l113 = sch.get_loops(block=b70)
l114 = sch.fuse(l113, preserve_unit_iters=True)
sch.vectorize(loop=l114)
b115 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135 = sch.get_loops(block=b115)
b136 = sch.decompose_reduction(block=b115, loop=l120)
2024-04-29 05:33:50 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #308: GFLOPs: 182.4700. Time: 1267.3929 us. Best GFLOPs: 655.4694
2024-04-29 05:33:50 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #309: GFLOPs: 234.4628. Time: 986.3450 us. Best GFLOPs: 655.4694
2024-04-29 05:33:50 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #310: GFLOPs: 368.3033. Time: 627.9096 us. Best GFLOPs: 655.4694
2024-04-29 05:33:50 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #311: GFLOPs: 190.5652. Time: 1213.5543 us. Best GFLOPs: 655.4694
2024-04-29 05:33:50 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #312: GFLOPs: 325.1191. Time: 711.3121 us. Best GFLOPs: 655.4694
2024-04-29 05:33:50 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #313: GFLOPs: 362.3728. Time: 638.1858 us. Best GFLOPs: 655.4694
2024-04-29 05:33:50 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #314: GFLOPs: 303.6379. Time: 761.6348 us. Best GFLOPs: 655.4694
2024-04-29 05:33:50 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #315: GFLOPs: 175.4689. Time: 1317.9608 us. Best GFLOPs: 655.4694
2024-04-29 05:33:50 [INFO] [task_scheduler.cc:121] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #316: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(7), T.int64(7), T.int64(512)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(9), T.int64(9), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused in T.parallel(T.int64(112), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(3), T.int64(9), T.int64(512)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(9), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(14) // T.int64(2) + ax2)
                    v_i3, v_i4 = T.axis.remap("SS", [ax3, ax4])
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(8) and T.int64(1) <= v_i3 and v_i3 < T.int64(8), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(32), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(14) * T.int64(2) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(2) + oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(14) // T.int64(2) + oh_1 + oh_2_init + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(7), ow_1 * T.int64(7) + ow_2_init + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(256), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(32), T.int64(2), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(14) * T.int64(2) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(2) + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(14) // T.int64(2) + oh_1 + oh_2 + oh_3)
                        v_ow = T.axis.spatial(T.int64(7), ow_1 * T.int64(7) + ow_2 + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(2) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                    for ax4_fused in T.vectorized(T.int64(32)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(14) * T.int64(2) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(2) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(14) // T.int64(2) + ax2)
                            v_ax3, v_ax4 = T.axis.remap("SS", [ax3, ax4_fused])
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[8, 2, 1, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[7, 1, 1, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 7, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 32, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[256, 2])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=6)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82 = sch.get_loops(block=b68)
l83 = sch.fuse(l71, l72, l73, l74, l75, l76, l77, preserve_unit_iters=True)
sch.parallel(loop=l83)
l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l84, preserve_unit_iters=True)
sch.parallel(loop=l104)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109, l110, l111, l112, l113 = sch.get_loops(block=b70)
l114 = sch.fuse(l113, preserve_unit_iters=True)
sch.vectorize(loop=l114)
b115 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135 = sch.get_loops(block=b115)
b136 = sch.decompose_reduction(block=b115, loop=l120)
2024-04-29 05:33:50 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #317: GFLOPs: 140.1253. Time: 1650.3887 us. Best GFLOPs: 655.4694
2024-04-29 05:33:50 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #318: GFLOPs: 19.3869. Time: 11928.7330 us. Best GFLOPs: 655.4694
2024-04-29 05:33:50 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #319: GFLOPs: 0.4957. Time: 466506.7023 us. Best GFLOPs: 655.4694
2024-04-29 05:33:50 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #320: GFLOPs: 9.0789. Time: 25472.5178 us. Best GFLOPs: 655.4694
2024-04-29 06:09:51 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 06:09:52 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-29 06:09:56 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x5e10dc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x6d79bf8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x5e1f188)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3181528)]: 0 failure(s)
2024-04-29 06:09:56 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-29 06:10:07 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x5e10dc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x6d79bf8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x5e1f188)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3181528)]: 0 failure(s)
2024-04-29 06:10:19 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x5e10dc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x6d79bf8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x5e1f188)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3181528)]: 0 failure(s)
2024-04-29 06:10:30 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x5e10dc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x6d79bf8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x5e1f188)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3181528)]: 0 failure(s)
2024-04-29 06:10:41 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x5e10dc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x6d79bf8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x5e1f188)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3181528)]: 0 failure(s)
2024-04-29 06:10:48 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9114  0.9003  0.8652  0.8613  0.8578  0.8540  0.8506  0.8480  0.8409  0.8267  0.8027  0.7758  0.7671  0.7558  0.7558  0.7525
[17 : 32]:	0.7525  0.7381  0.7163  0.7043  0.7043  0.6925  0.6923  0.6896  0.6752  0.6674  0.6621  0.6615  0.6479  0.6438  0.6086  0.5996
[33 : 48]:	0.5996  0.5967  0.5965  0.5965  0.5902  0.5896  0.5896  0.5896  0.5818  0.5765  0.5757  0.5744  0.5708  0.5663  0.5628  0.5628
[49 : 64]:	0.5568  0.5474  0.5448  0.5435  0.5434  0.5429  0.5424  0.5421  0.5420  0.5420  0.5390  0.5364  0.5353  0.5287  0.5271  0.5253
2024-04-29 06:10:48 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 06:10:49 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 06:12:43 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #321: GFLOPs: 628.2390. Time: 368.1102 us. Best GFLOPs: 655.4694
2024-04-29 06:12:43 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #322: GFLOPs: 673.1219. Time: 343.5651 us. Best GFLOPs: 673.1219
2024-04-29 06:12:43 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #323: GFLOPs: 592.8112. Time: 390.1093 us. Best GFLOPs: 673.1219
2024-04-29 06:12:43 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #324: GFLOPs: 594.0659. Time: 389.2854 us. Best GFLOPs: 673.1219
2024-04-29 06:12:43 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #325: GFLOPs: 658.2194. Time: 351.3436 us. Best GFLOPs: 673.1219
2024-04-29 06:12:43 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #326: GFLOPs: 765.9742. Time: 301.9177 us. Best GFLOPs: 765.9742
2024-04-29 06:12:43 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #327: GFLOPs: 640.9091. Time: 360.8331 us. Best GFLOPs: 765.9742
2024-04-29 06:12:43 [INFO] [task_scheduler.cc:121] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #328: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(7), T.int64(7), T.int64(512)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(9), T.int64(9), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused in T.parallel(T.int64(112), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(3), T.int64(9), T.int64(512)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(9), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(28) // T.int64(4) + ax2)
                    v_i3, v_i4 = T.axis.remap("SS", [ax3, ax4])
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(8) and T.int64(1) <= v_i3 and v_i3 < T.int64(8), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(28) * T.int64(4) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(4) + oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(28) // T.int64(4) + oh_1 + oh_2_init + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(7), ow_1 * T.int64(7) + ow_2_init * T.int64(7) + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(512), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(28) * T.int64(4) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(4) + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(28) // T.int64(4) + oh_1 + oh_2 + oh_3)
                        v_ow = T.axis.spatial(T.int64(7), ow_1 * T.int64(7) + ow_2 * T.int64(7) + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(512), ic_0 + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                    for ax4_fused in T.vectorized(T.int64(32)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(28) * T.int64(4) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(4) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(28) // T.int64(4) + ax2)
                            v_ax3, v_ax4 = T.axis.remap("SS", [ax3, ax4_fused])
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[4, 4, 1, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[7, 1, 1, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 1, 7])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 32, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[512, 1])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=112)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=6)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82 = sch.get_loops(block=b68)
l83 = sch.fuse(l71, l72, l73, l74, l75, l76, l77, preserve_unit_iters=True)
sch.parallel(loop=l83)
l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l84, preserve_unit_iters=True)
sch.parallel(loop=l104)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109, l110, l111, l112, l113 = sch.get_loops(block=b70)
l114 = sch.fuse(l113, preserve_unit_iters=True)
sch.vectorize(loop=l114)
b115 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135 = sch.get_loops(block=b115)
b136 = sch.decompose_reduction(block=b115, loop=l120)
2024-04-29 06:12:43 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #329: GFLOPs: 659.6130. Time: 350.6013 us. Best GFLOPs: 765.9742
2024-04-29 06:12:43 [INFO] [task_scheduler.cc:121] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #330: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(7), T.int64(7), T.int64(512)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(9), T.int64(9), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused in T.parallel(T.int64(112), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(3), T.int64(9), T.int64(512)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(9), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(28) // T.int64(4) + ax2)
                    v_i3, v_i4 = T.axis.remap("SS", [ax3, ax4])
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(8) and T.int64(1) <= v_i3 and v_i3 < T.int64(8), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(28) * T.int64(4) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(4) + oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(28) // T.int64(4) + oh_1 + oh_2_init + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(7), ow_1 * T.int64(7) + ow_2_init * T.int64(7) + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(256), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(32), T.int64(2), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(28) * T.int64(4) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(4) + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(28) // T.int64(4) + oh_1 + oh_2 + oh_3)
                        v_ow = T.axis.spatial(T.int64(7), ow_1 * T.int64(7) + ow_2 * T.int64(7) + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(2) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                    for ax4_fused in T.vectorized(T.int64(32)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(28) * T.int64(4) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(4) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(28) // T.int64(4) + ax2)
                            v_ax3, v_ax4 = T.axis.remap("SS", [ax3, ax4_fused])
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[4, 4, 1, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[7, 1, 1, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 1, 7])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 32, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[256, 2])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=6)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82 = sch.get_loops(block=b68)
l83 = sch.fuse(l71, l72, l73, l74, l75, l76, l77, preserve_unit_iters=True)
sch.parallel(loop=l83)
l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l84, preserve_unit_iters=True)
sch.parallel(loop=l104)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109, l110, l111, l112, l113 = sch.get_loops(block=b70)
l114 = sch.fuse(l113, preserve_unit_iters=True)
sch.vectorize(loop=l114)
b115 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135 = sch.get_loops(block=b115)
b136 = sch.decompose_reduction(block=b115, loop=l120)
2024-04-29 06:12:43 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #331: GFLOPs: 341.3473. Time: 677.4953 us. Best GFLOPs: 765.9742
2024-04-29 06:12:43 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #332: GFLOPs: 734.2971. Time: 314.9422 us. Best GFLOPs: 765.9742
2024-04-29 06:12:43 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #333: GFLOPs: 618.6309. Time: 373.8274 us. Best GFLOPs: 765.9742
2024-04-29 06:12:43 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #334: GFLOPs: 594.9444. Time: 388.7106 us. Best GFLOPs: 765.9742
2024-04-29 06:12:43 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #335: GFLOPs: 545.5643. Time: 423.8935 us. Best GFLOPs: 765.9742
2024-04-29 06:12:43 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #336: GFLOPs: 489.8691. Time: 472.0877 us. Best GFLOPs: 765.9742
2024-04-29 06:12:43 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #337: GFLOPs: 478.0508. Time: 483.7586 us. Best GFLOPs: 765.9742
2024-04-29 06:12:43 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #338: GFLOPs: 498.1025. Time: 464.2844 us. Best GFLOPs: 765.9742
2024-04-29 06:12:43 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #339: GFLOPs: 621.3909. Time: 372.1670 us. Best GFLOPs: 765.9742
2024-04-29 06:12:43 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #340: GFLOPs: 443.2216. Time: 521.7733 us. Best GFLOPs: 765.9742
2024-04-29 06:12:43 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #341: GFLOPs: 433.9132. Time: 532.9664 us. Best GFLOPs: 765.9742
2024-04-29 06:12:43 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #342: GFLOPs: 428.8196. Time: 539.2971 us. Best GFLOPs: 765.9742
2024-04-29 06:12:43 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #343: GFLOPs: 390.8935. Time: 591.6220 us. Best GFLOPs: 765.9742
2024-04-29 06:12:43 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #344: GFLOPs: 486.8052. Time: 475.0590 us. Best GFLOPs: 765.9742
2024-04-29 06:12:43 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #345: GFLOPs: 408.9203. Time: 565.5410 us. Best GFLOPs: 765.9742
2024-04-29 06:12:43 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #346: GFLOPs: 448.2904. Time: 515.8736 us. Best GFLOPs: 765.9742
2024-04-29 06:12:43 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #347: GFLOPs: 547.6931. Time: 422.2460 us. Best GFLOPs: 765.9742
2024-04-29 06:12:43 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #348: GFLOPs: 649.2544. Time: 356.1950 us. Best GFLOPs: 765.9742
2024-04-29 06:12:43 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #349: GFLOPs: 457.9255. Time: 505.0193 us. Best GFLOPs: 765.9742
2024-04-29 06:12:43 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #350: GFLOPs: 459.4870. Time: 503.3030 us. Best GFLOPs: 765.9742
2024-04-29 06:12:43 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #351: GFLOPs: 443.0338. Time: 521.9944 us. Best GFLOPs: 765.9742
2024-04-29 06:12:43 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #352: GFLOPs: 633.2981. Time: 365.1696 us. Best GFLOPs: 765.9742
2024-04-29 06:12:43 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #353: GFLOPs: 616.7138. Time: 374.9894 us. Best GFLOPs: 765.9742
2024-04-29 06:12:43 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #354: GFLOPs: 438.0144. Time: 527.9762 us. Best GFLOPs: 765.9742
2024-04-29 06:12:43 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #355: GFLOPs: 225.4308. Time: 1025.8635 us. Best GFLOPs: 765.9742
2024-04-29 06:12:43 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #356: GFLOPs: 432.0421. Time: 535.2746 us. Best GFLOPs: 765.9742
2024-04-29 06:12:43 [INFO] [task_scheduler.cc:121] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #357: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(7), T.int64(7), T.int64(512)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(9), T.int64(9), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused in T.parallel(T.int64(112), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(3), T.int64(9), T.int64(512)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(9), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(28) // T.int64(4) + ax2)
                    v_i3, v_i4 = T.axis.remap("SS", [ax3, ax4])
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(8) and T.int64(1) <= v_i3 and v_i3 < T.int64(8), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(28) * T.int64(4) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(4) + oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(28) // T.int64(4) + oh_1 + oh_2_init + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(7), ow_1 * T.int64(7) + ow_2_init * T.int64(7) + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(256), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(32), T.int64(2), T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(28) * T.int64(4) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(4) + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(28) // T.int64(4) + oh_1 + oh_2 + oh_3)
                        v_ow = T.axis.spatial(T.int64(7), ow_1 * T.int64(7) + ow_2 * T.int64(7) + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(2) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                    for ax4_fused in T.vectorized(T.int64(32)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(28) * T.int64(4) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(4) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(28) // T.int64(4) + ax2)
                            v_ax3, v_ax4 = T.axis.remap("SS", [ax3, ax4_fused])
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[4, 4, 1, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[7, 1, 1, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 1, 7])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 32, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[256, 2])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=112)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=6)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82 = sch.get_loops(block=b68)
l83 = sch.fuse(l71, l72, l73, l74, l75, l76, l77, preserve_unit_iters=True)
sch.parallel(loop=l83)
l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l84, preserve_unit_iters=True)
sch.parallel(loop=l104)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109, l110, l111, l112, l113 = sch.get_loops(block=b70)
l114 = sch.fuse(l113, preserve_unit_iters=True)
sch.vectorize(loop=l114)
b115 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135 = sch.get_loops(block=b115)
b136 = sch.decompose_reduction(block=b115, loop=l120)
2024-04-29 06:12:43 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #358: GFLOPs: 447.6305. Time: 516.6342 us. Best GFLOPs: 765.9742
2024-04-29 06:12:43 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #359: GFLOPs: 428.6309. Time: 539.5346 us. Best GFLOPs: 765.9742
2024-04-29 06:12:43 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #360: GFLOPs: 431.5303. Time: 535.9096 us. Best GFLOPs: 765.9742
2024-04-29 06:12:43 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #361: GFLOPs: 349.6335. Time: 661.4389 us. Best GFLOPs: 765.9742
2024-04-29 06:12:43 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #362: GFLOPs: 357.1480. Time: 647.5219 us. Best GFLOPs: 765.9742
2024-04-29 06:12:43 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #363: GFLOPs: 363.2711. Time: 636.6077 us. Best GFLOPs: 765.9742
2024-04-29 06:12:43 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #364: GFLOPs: 447.0136. Time: 517.3471 us. Best GFLOPs: 765.9742
2024-04-29 06:12:43 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #365: GFLOPs: 378.0059. Time: 611.7926 us. Best GFLOPs: 765.9742
2024-04-29 06:12:43 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #366: GFLOPs: 488.7991. Time: 473.1211 us. Best GFLOPs: 765.9742
2024-04-29 06:12:43 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #367: GFLOPs: 433.0149. Time: 534.0721 us. Best GFLOPs: 765.9742
2024-04-29 06:12:43 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #368: GFLOPs: 413.2801. Time: 559.5749 us. Best GFLOPs: 765.9742
2024-04-29 06:12:43 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #369: GFLOPs: 389.1620. Time: 594.2542 us. Best GFLOPs: 765.9742
2024-04-29 06:12:43 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #370: GFLOPs: 191.3164. Time: 1208.7892 us. Best GFLOPs: 765.9742
2024-04-29 06:12:43 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #371: GFLOPs: 571.7871. Time: 404.4533 us. Best GFLOPs: 765.9742
2024-04-29 06:12:43 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #372: GFLOPs: 158.6916. Time: 1457.2993 us. Best GFLOPs: 765.9742
2024-04-29 06:12:43 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #373: GFLOPs: 386.7049. Time: 598.0301 us. Best GFLOPs: 765.9742
2024-04-29 06:12:43 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #374: GFLOPs: 296.2768. Time: 780.5578 us. Best GFLOPs: 765.9742
2024-04-29 06:12:43 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #375: GFLOPs: 432.0794. Time: 535.2285 us. Best GFLOPs: 765.9742
2024-04-29 06:12:43 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #376: GFLOPs: 330.9250. Time: 698.8326 us. Best GFLOPs: 765.9742
2024-04-29 06:12:43 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #377: GFLOPs: 560.8779. Time: 412.3200 us. Best GFLOPs: 765.9742
2024-04-29 06:12:43 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #378: GFLOPs: 571.2550. Time: 404.8300 us. Best GFLOPs: 765.9742
2024-04-29 06:12:43 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #379: GFLOPs: 309.4569. Time: 747.3132 us. Best GFLOPs: 765.9742
2024-04-29 06:12:43 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #380: GFLOPs: 275.7278. Time: 838.7299 us. Best GFLOPs: 765.9742
2024-04-29 06:12:43 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #381: GFLOPs: 401.8709. Time: 575.4614 us. Best GFLOPs: 765.9742
2024-04-29 06:12:43 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #382: GFLOPs: 96.1497. Time: 2405.2202 us. Best GFLOPs: 765.9742
2024-04-29 06:12:43 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #383: GFLOPs: 0.6510. Time: 355264.7730 us. Best GFLOPs: 765.9742
2024-04-29 06:12:43 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #384: GFLOPs: 7.6121. Time: 30380.8440 us. Best GFLOPs: 765.9742
2024-04-29 06:41:06 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 06:41:07 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-29 06:41:11 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x5e10dc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x6d79bf8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x5e1f188)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3181528)]: 0 failure(s)
2024-04-29 06:41:11 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-29 06:41:22 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x5e10dc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x6d79bf8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x5e1f188)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3181528)]: 0 failure(s)
2024-04-29 06:41:33 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x5e10dc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x6d79bf8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x5e1f188)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3181528)]: 0 failure(s)
2024-04-29 06:41:44 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x5e10dc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x6d79bf8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x5e1f188)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3181528)]: 0 failure(s)
2024-04-29 06:41:54 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x5e10dc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x6d79bf8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x5e1f188)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3181528)]: 0 failure(s)
2024-04-29 06:42:00 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9705  0.9407  0.8801  0.8793  0.8393  0.8392  0.8392  0.8351  0.8344  0.8344  0.8188  0.8143  0.8143  0.8079  0.8057  0.8057
[17 : 32]:	0.8001  0.8001  0.8001  0.7967  0.7964  0.7937  0.7927  0.7927  0.7877  0.7859  0.7820  0.7820  0.7736  0.7643  0.7543  0.7518
[33 : 48]:	0.7458  0.7458  0.7318  0.7318  0.7318  0.7186  0.7163  0.7148  0.7148  0.7143  0.7137  0.7137  0.7126  0.7076  0.6942  0.6932
[49 : 64]:	0.6859  0.6794  0.6737  0.6717  0.6707  0.6440  0.6407  0.6340  0.6299  0.6271  0.6271  0.6246  0.6245  0.6203  0.6193  0.6184
2024-04-29 06:42:01 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 06:42:01 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 06:43:56 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #385: GFLOPs: 771.6425. Time: 299.6999 us. Best GFLOPs: 771.6425
2024-04-29 06:43:56 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #386: GFLOPs: 731.2374. Time: 316.2600 us. Best GFLOPs: 771.6425
2024-04-29 06:43:56 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #387: GFLOPs: 733.8958. Time: 315.1145 us. Best GFLOPs: 771.6425
2024-04-29 06:43:56 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #388: GFLOPs: 615.3351. Time: 375.8296 us. Best GFLOPs: 771.6425
2024-04-29 06:43:56 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #389: GFLOPs: 579.5781. Time: 399.0164 us. Best GFLOPs: 771.6425
2024-04-29 06:43:56 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #390: GFLOPs: 677.7137. Time: 341.2373 us. Best GFLOPs: 771.6425
2024-04-29 06:43:56 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #391: GFLOPs: 675.6829. Time: 342.2629 us. Best GFLOPs: 771.6425
2024-04-29 06:43:56 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #392: GFLOPs: 635.8887. Time: 363.6818 us. Best GFLOPs: 771.6425
2024-04-29 06:43:56 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #393: GFLOPs: 629.1415. Time: 367.5822 us. Best GFLOPs: 771.6425
2024-04-29 06:43:56 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #394: GFLOPs: 601.9342. Time: 384.1968 us. Best GFLOPs: 771.6425
2024-04-29 06:43:56 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #395: GFLOPs: 674.0857. Time: 343.0739 us. Best GFLOPs: 771.6425
2024-04-29 06:43:56 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #396: GFLOPs: 580.8232. Time: 398.1610 us. Best GFLOPs: 771.6425
2024-04-29 06:43:56 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #397: GFLOPs: 675.1671. Time: 342.5244 us. Best GFLOPs: 771.6425
2024-04-29 06:43:56 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #398: GFLOPs: 605.8854. Time: 381.6913 us. Best GFLOPs: 771.6425
2024-04-29 06:43:56 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #399: GFLOPs: 608.1269. Time: 380.2844 us. Best GFLOPs: 771.6425
2024-04-29 06:43:56 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #400: GFLOPs: 621.6895. Time: 371.9882 us. Best GFLOPs: 771.6425
2024-04-29 06:43:56 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #401: GFLOPs: 565.9927. Time: 408.5939 us. Best GFLOPs: 771.6425
2024-04-29 06:43:56 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #402: GFLOPs: 567.9100. Time: 407.2145 us. Best GFLOPs: 771.6425
2024-04-29 06:43:56 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #403: GFLOPs: 563.0512. Time: 410.7285 us. Best GFLOPs: 771.6425
2024-04-29 06:43:56 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #404: GFLOPs: 586.6402. Time: 394.2130 us. Best GFLOPs: 771.6425
2024-04-29 06:43:56 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #405: GFLOPs: 606.4245. Time: 381.3520 us. Best GFLOPs: 771.6425
2024-04-29 06:43:56 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #406: GFLOPs: 683.0204. Time: 338.5860 us. Best GFLOPs: 771.6425
2024-04-29 06:43:56 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #407: GFLOPs: 556.5159. Time: 415.5518 us. Best GFLOPs: 771.6425
2024-04-29 06:43:56 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #408: GFLOPs: 556.2249. Time: 415.7692 us. Best GFLOPs: 771.6425
2024-04-29 06:43:56 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #409: GFLOPs: 659.5629. Time: 350.6280 us. Best GFLOPs: 771.6425
2024-04-29 06:43:56 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #410: GFLOPs: 556.4589. Time: 415.5943 us. Best GFLOPs: 771.6425
2024-04-29 06:43:56 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #411: GFLOPs: 323.3808. Time: 715.1358 us. Best GFLOPs: 771.6425
2024-04-29 06:43:56 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #412: GFLOPs: 555.8620. Time: 416.0407 us. Best GFLOPs: 771.6425
2024-04-29 06:43:56 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #413: GFLOPs: 583.3986. Time: 396.4034 us. Best GFLOPs: 771.6425
2024-04-29 06:43:56 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #414: GFLOPs: 589.1717. Time: 392.5191 us. Best GFLOPs: 771.6425
2024-04-29 06:43:56 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #415: GFLOPs: 567.6208. Time: 407.4220 us. Best GFLOPs: 771.6425
2024-04-29 06:43:56 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #416: GFLOPs: 553.7987. Time: 417.5907 us. Best GFLOPs: 771.6425
2024-04-29 06:43:56 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #417: GFLOPs: 581.9320. Time: 397.4024 us. Best GFLOPs: 771.6425
2024-04-29 06:43:56 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #418: GFLOPs: 569.7997. Time: 405.8640 us. Best GFLOPs: 771.6425
2024-04-29 06:43:56 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #419: GFLOPs: 563.0360. Time: 410.7396 us. Best GFLOPs: 771.6425
2024-04-29 06:43:56 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #420: GFLOPs: 549.5788. Time: 420.7972 us. Best GFLOPs: 771.6425
2024-04-29 06:43:56 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #421: GFLOPs: 550.9415. Time: 419.7563 us. Best GFLOPs: 771.6425
2024-04-29 06:43:56 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #422: GFLOPs: 543.9007. Time: 425.1901 us. Best GFLOPs: 771.6425
2024-04-29 06:43:56 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #423: GFLOPs: 529.1795. Time: 437.0184 us. Best GFLOPs: 771.6425
2024-04-29 06:43:56 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #424: GFLOPs: 538.8528. Time: 429.1732 us. Best GFLOPs: 771.6425
2024-04-29 06:43:56 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #425: GFLOPs: 539.3573. Time: 428.7718 us. Best GFLOPs: 771.6425
2024-04-29 06:43:56 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #426: GFLOPs: 434.6774. Time: 532.0295 us. Best GFLOPs: 771.6425
2024-04-29 06:43:56 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #427: GFLOPs: 550.6890. Time: 419.9488 us. Best GFLOPs: 771.6425
2024-04-29 06:43:56 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #428: GFLOPs: 533.6252. Time: 433.3776 us. Best GFLOPs: 771.6425
2024-04-29 06:43:56 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #429: GFLOPs: 575.0262. Time: 402.1750 us. Best GFLOPs: 771.6425
2024-04-29 06:43:56 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #430: GFLOPs: 599.8580. Time: 385.5266 us. Best GFLOPs: 771.6425
2024-04-29 06:43:56 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #431: GFLOPs: 611.6523. Time: 378.0926 us. Best GFLOPs: 771.6425
2024-04-29 06:43:56 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #432: GFLOPs: 662.9127. Time: 348.8562 us. Best GFLOPs: 771.6425
2024-04-29 06:43:56 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #433: GFLOPs: 652.7842. Time: 354.2690 us. Best GFLOPs: 771.6425
2024-04-29 06:43:56 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #434: GFLOPs: 547.3150. Time: 422.5376 us. Best GFLOPs: 771.6425
2024-04-29 06:43:56 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #435: GFLOPs: 479.8753. Time: 481.9194 us. Best GFLOPs: 771.6425
2024-04-29 06:43:56 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #436: GFLOPs: 522.8688. Time: 442.2929 us. Best GFLOPs: 771.6425
2024-04-29 06:43:56 [INFO] [task_scheduler.cc:121] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #437: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(7), T.int64(7), T.int64(512)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(9), T.int64(9), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused in T.parallel(T.int64(112), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(3), T.int64(9), T.int64(512)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(9), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(14) // T.int64(2) + ax2)
                    v_i3, v_i4 = T.axis.remap("SS", [ax3, ax4])
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(8) and T.int64(1) <= v_i3 and v_i3 < T.int64(8), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(14) * T.int64(2) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(2) + oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(14) // T.int64(2) + oh_1 + oh_2_init + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(7), ow_1 * T.int64(7) + ow_2_init * T.int64(7) + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(256), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(32), T.int64(2), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(14) * T.int64(2) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(2) + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(14) // T.int64(2) + oh_1 + oh_2 + oh_3)
                        v_ow = T.axis.spatial(T.int64(7), ow_1 * T.int64(7) + ow_2 * T.int64(7) + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(2) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                    for ax4_fused in T.vectorized(T.int64(32)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(14) * T.int64(2) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(2) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(14) // T.int64(2) + ax2)
                            v_ax3, v_ax4 = T.axis.remap("SS", [ax3, ax4_fused])
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[8, 2, 1, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[7, 1, 1, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 1, 7])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 32, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[256, 2])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=6)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82 = sch.get_loops(block=b68)
l83 = sch.fuse(l71, l72, l73, l74, l75, l76, l77, preserve_unit_iters=True)
sch.parallel(loop=l83)
l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l84, preserve_unit_iters=True)
sch.parallel(loop=l104)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109, l110, l111, l112, l113 = sch.get_loops(block=b70)
l114 = sch.fuse(l113, preserve_unit_iters=True)
sch.vectorize(loop=l114)
b115 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135 = sch.get_loops(block=b115)
b136 = sch.decompose_reduction(block=b115, loop=l120)
2024-04-29 06:43:56 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #438: GFLOPs: 508.0778. Time: 455.1689 us. Best GFLOPs: 771.6425
2024-04-29 06:43:56 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #439: GFLOPs: 399.8994. Time: 578.2983 us. Best GFLOPs: 771.6425
2024-04-29 06:43:56 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #440: GFLOPs: 382.7725. Time: 604.1740 us. Best GFLOPs: 771.6425
2024-04-29 06:43:56 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #441: GFLOPs: 371.2134. Time: 622.9872 us. Best GFLOPs: 771.6425
2024-04-29 06:43:56 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #442: GFLOPs: 399.6422. Time: 578.6706 us. Best GFLOPs: 771.6425
2024-04-29 06:43:56 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #443: GFLOPs: 400.4728. Time: 577.4703 us. Best GFLOPs: 771.6425
2024-04-29 06:43:56 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #444: GFLOPs: 485.7334. Time: 476.1073 us. Best GFLOPs: 771.6425
2024-04-29 06:43:56 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #445: GFLOPs: 473.8593. Time: 488.0376 us. Best GFLOPs: 771.6425
2024-04-29 06:43:56 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #446: GFLOPs: 22.9206. Time: 10089.6446 us. Best GFLOPs: 771.6425
2024-04-29 06:43:56 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #447: GFLOPs: 46.1737. Time: 5008.5040 us. Best GFLOPs: 771.6425
2024-04-29 06:43:56 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #448: GFLOPs: 38.9698. Time: 5934.3727 us. Best GFLOPs: 771.6425
2024-04-29 07:09:45 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 07:09:46 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-29 07:09:50 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x5e10dc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x6d79bf8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x5e1f188)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3181528)]: 0 failure(s)
2024-04-29 07:09:50 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-29 07:10:01 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x5e10dc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x6d79bf8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x5e1f188)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3181528)]: 0 failure(s)
2024-04-29 07:10:11 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x5e10dc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x6d79bf8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x5e1f188)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3181528)]: 0 failure(s)
2024-04-29 07:10:22 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x5e10dc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x6d79bf8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x5e1f188)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3181528)]: 0 failure(s)
2024-04-29 07:10:32 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x5e10dc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x6d79bf8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x5e1f188)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3181528)]: 0 failure(s)
2024-04-29 07:10:39 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9722  0.9022  0.8898  0.8474  0.8337  0.8265  0.8167  0.8111  0.8057  0.8048  0.8036  0.8026  0.8025  0.8005  0.7916  0.7877
[17 : 32]:	0.7851  0.7813  0.7804  0.7788  0.7768  0.7639  0.7519  0.7493  0.7475  0.7415  0.7404  0.7324  0.7318  0.7299  0.7293  0.7277
[33 : 48]:	0.7269  0.7234  0.7158  0.7158  0.7093  0.6992  0.6918  0.6918  0.6892  0.6878  0.6827  0.6825  0.6768  0.6740  0.6733  0.6727
[49 : 64]:	0.6727  0.6721  0.6706  0.6509  0.6464  0.6399  0.6372  0.6340  0.6335  0.6322  0.6300  0.6290  0.6261  0.6164  0.6158  0.6124
2024-04-29 07:10:39 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 07:10:39 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 07:12:37 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #449: GFLOPs: 753.1012. Time: 307.0785 us. Best GFLOPs: 771.6425
2024-04-29 07:12:37 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #450: GFLOPs: 801.8350. Time: 288.4149 us. Best GFLOPs: 801.8350
2024-04-29 07:12:37 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #451: GFLOPs: 760.0951. Time: 304.2530 us. Best GFLOPs: 801.8350
2024-04-29 07:12:37 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #452: GFLOPs: 693.6686. Time: 333.3886 us. Best GFLOPs: 801.8350
2024-04-29 07:12:37 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #453: GFLOPs: 646.5865. Time: 357.6647 us. Best GFLOPs: 801.8350
2024-04-29 07:12:37 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #454: GFLOPs: 566.8549. Time: 407.9724 us. Best GFLOPs: 801.8350
2024-04-29 07:12:37 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #455: GFLOPs: 651.4142. Time: 355.0141 us. Best GFLOPs: 801.8350
2024-04-29 07:12:37 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #456: GFLOPs: 638.9638. Time: 361.9316 us. Best GFLOPs: 801.8350
2024-04-29 07:12:37 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #457: GFLOPs: 619.9469. Time: 373.0339 us. Best GFLOPs: 801.8350
2024-04-29 07:12:37 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #458: GFLOPs: 697.6471. Time: 331.4874 us. Best GFLOPs: 801.8350
2024-04-29 07:12:37 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #459: GFLOPs: 320.2102. Time: 722.2169 us. Best GFLOPs: 801.8350
2024-04-29 07:12:37 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #460: GFLOPs: 650.7769. Time: 355.3617 us. Best GFLOPs: 801.8350
2024-04-29 07:12:37 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #461: GFLOPs: 643.6528. Time: 359.2949 us. Best GFLOPs: 801.8350
2024-04-29 07:12:37 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #462: GFLOPs: 619.3184. Time: 373.4124 us. Best GFLOPs: 801.8350
2024-04-29 07:12:37 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #463: GFLOPs: 623.4050. Time: 370.9646 us. Best GFLOPs: 801.8350
2024-04-29 07:12:37 [INFO] [task_scheduler.cc:121] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #464: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(7), T.int64(7), T.int64(512)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(9), T.int64(9), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_fused_fused in T.parallel(T.int64(112), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(3), T.int64(9), T.int64(512)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(9), n_0_oc_chunk_0_oh_0_fused_fused % T.int64(7) + ax2)
                    v_i3, v_i4 = T.axis.remap("SS", [ax3, ax4])
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(8) and T.int64(1) <= v_i3 and v_i3 < T.int64(8), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for ow_0, oc_block_0, n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_fused_fused // T.int64(7) + oc_chunk_1 + oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_fused_fused % T.int64(7) + oh_1 + oh_2_init + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(7), ow_0 * T.int64(7) + ow_1 * T.int64(7) + ow_2_init * T.int64(7) + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_0 * T.int64(32) + oc_block_1 * T.int64(32) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(128), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(32), T.int64(4), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_fused_fused // T.int64(7) + oc_chunk_1 + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_fused_fused % T.int64(7) + oh_1 + oh_2 + oh_3)
                        v_ow = T.axis.spatial(T.int64(7), ow_0 * T.int64(7) + ow_1 * T.int64(7) + ow_2 * T.int64(7) + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_0 * T.int64(32) + oc_block_1 * T.int64(32) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(4) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                    for ax4_fused in T.vectorized(T.int64(32)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_fused_fused // T.int64(7) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_fused_fused % T.int64(7) + ax2)
                            v_ax3, v_ax4 = T.axis.remap("SS", [ax3, ax4_fused])
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[16, 1, 1, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[7, 1, 1, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 1, 7])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 32, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[128, 4])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=2)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78 = sch.get_loops(block=b68)
l79 = sch.fuse(l71, l72, l73, preserve_unit_iters=True)
sch.parallel(loop=l79)
l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l80, preserve_unit_iters=True)
sch.parallel(loop=l104)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117 = sch.get_loops(block=b70)
l118 = sch.fuse(l117, preserve_unit_iters=True)
sch.vectorize(loop=l118)
b119 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141, l142, l143 = sch.get_loops(block=b119)
b144 = sch.decompose_reduction(block=b119, loop=l128)
2024-04-29 07:12:37 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #465: GFLOPs: 615.4973. Time: 375.7306 us. Best GFLOPs: 801.8350
2024-04-29 07:12:37 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #466: GFLOPs: 650.2480. Time: 355.6508 us. Best GFLOPs: 801.8350
2024-04-29 07:12:37 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #467: GFLOPs: 609.0951. Time: 379.6799 us. Best GFLOPs: 801.8350
2024-04-29 07:12:37 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #468: GFLOPs: 698.0346. Time: 331.3033 us. Best GFLOPs: 801.8350
2024-04-29 07:12:37 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #469: GFLOPs: 593.3913. Time: 389.7279 us. Best GFLOPs: 801.8350
2024-04-29 07:12:37 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #470: GFLOPs: 590.5155. Time: 391.6259 us. Best GFLOPs: 801.8350
2024-04-29 07:12:37 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #471: GFLOPs: 591.6593. Time: 390.8688 us. Best GFLOPs: 801.8350
2024-04-29 07:12:37 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #472: GFLOPs: 634.2342. Time: 364.6306 us. Best GFLOPs: 801.8350
2024-04-29 07:12:37 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #473: GFLOPs: 564.7385. Time: 409.5014 us. Best GFLOPs: 801.8350
2024-04-29 07:12:37 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #474: GFLOPs: 576.9976. Time: 400.8009 us. Best GFLOPs: 801.8350
2024-04-29 07:12:37 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #475: GFLOPs: 577.7370. Time: 400.2880 us. Best GFLOPs: 801.8350
2024-04-29 07:12:37 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #476: GFLOPs: 576.8108. Time: 400.9308 us. Best GFLOPs: 801.8350
2024-04-29 07:12:37 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #477: GFLOPs: 566.7106. Time: 408.0764 us. Best GFLOPs: 801.8350
2024-04-29 07:12:37 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #478: GFLOPs: 573.5497. Time: 403.2103 us. Best GFLOPs: 801.8350
2024-04-29 07:12:37 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #479: GFLOPs: 559.8765. Time: 413.0575 us. Best GFLOPs: 801.8350
2024-04-29 07:12:37 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #480: GFLOPs: 592.1810. Time: 390.5245 us. Best GFLOPs: 801.8350
2024-04-29 07:12:37 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #481: GFLOPs: 574.3674. Time: 402.6363 us. Best GFLOPs: 801.8350
2024-04-29 07:12:37 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #482: GFLOPs: 555.7126. Time: 416.1525 us. Best GFLOPs: 801.8350
2024-04-29 07:12:37 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #483: GFLOPs: 549.4388. Time: 420.9043 us. Best GFLOPs: 801.8350
2024-04-29 07:12:37 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #484: GFLOPs: 579.7118. Time: 398.9244 us. Best GFLOPs: 801.8350
2024-04-29 07:12:37 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #485: GFLOPs: 586.5192. Time: 394.2943 us. Best GFLOPs: 801.8350
2024-04-29 07:12:37 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #486: GFLOPs: 512.1156. Time: 451.5801 us. Best GFLOPs: 801.8350
2024-04-29 07:12:37 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #487: GFLOPs: 490.3134. Time: 471.6599 us. Best GFLOPs: 801.8350
2024-04-29 07:12:37 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #488: GFLOPs: 555.2875. Time: 416.4711 us. Best GFLOPs: 801.8350
2024-04-29 07:12:37 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #489: GFLOPs: 524.2064. Time: 441.1644 us. Best GFLOPs: 801.8350
2024-04-29 07:12:37 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #490: GFLOPs: 525.4657. Time: 440.1071 us. Best GFLOPs: 801.8350
2024-04-29 07:12:37 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #491: GFLOPs: 498.4511. Time: 463.9596 us. Best GFLOPs: 801.8350
2024-04-29 07:12:37 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #492: GFLOPs: 543.7259. Time: 425.3268 us. Best GFLOPs: 801.8350
2024-04-29 07:12:37 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #493: GFLOPs: 406.2235. Time: 569.2955 us. Best GFLOPs: 801.8350
2024-04-29 07:12:37 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #494: GFLOPs: 526.8226. Time: 438.9736 us. Best GFLOPs: 801.8350
2024-04-29 07:12:37 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #495: GFLOPs: 518.1967. Time: 446.2807 us. Best GFLOPs: 801.8350
2024-04-29 07:12:37 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #496: GFLOPs: 523.7100. Time: 441.5825 us. Best GFLOPs: 801.8350
2024-04-29 07:12:37 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #497: GFLOPs: 512.7574. Time: 451.0148 us. Best GFLOPs: 801.8350
2024-04-29 07:12:37 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #498: GFLOPs: 464.4834. Time: 497.8891 us. Best GFLOPs: 801.8350
2024-04-29 07:12:37 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #499: GFLOPs: 533.6635. Time: 433.3464 us. Best GFLOPs: 801.8350
2024-04-29 07:12:37 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #500: GFLOPs: 584.6379. Time: 395.5631 us. Best GFLOPs: 801.8350
2024-04-29 07:12:37 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #501: GFLOPs: 603.7006. Time: 383.0726 us. Best GFLOPs: 801.8350
2024-04-29 07:12:37 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #502: GFLOPs: 550.3681. Time: 420.1936 us. Best GFLOPs: 801.8350
2024-04-29 07:12:37 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #503: GFLOPs: 493.6851. Time: 468.4387 us. Best GFLOPs: 801.8350
2024-04-29 07:12:37 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #504: GFLOPs: 516.2769. Time: 447.9402 us. Best GFLOPs: 801.8350
2024-04-29 07:12:37 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #505: GFLOPs: 452.4301. Time: 511.1534 us. Best GFLOPs: 801.8350
2024-04-29 07:12:37 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #506: GFLOPs: 522.0199. Time: 443.0122 us. Best GFLOPs: 801.8350
2024-04-29 07:12:37 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #507: GFLOPs: 503.0489. Time: 459.7191 us. Best GFLOPs: 801.8350
2024-04-29 07:12:37 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #508: GFLOPs: 524.8816. Time: 440.5969 us. Best GFLOPs: 801.8350
2024-04-29 07:12:37 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #509: GFLOPs: 551.6659. Time: 419.2051 us. Best GFLOPs: 801.8350
2024-04-29 07:12:37 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #510: GFLOPs: 49.2651. Time: 4694.2198 us. Best GFLOPs: 801.8350
2024-04-29 07:12:37 [INFO] [task_scheduler.cc:121] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #511: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(7), T.int64(7), T.int64(512)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(9), T.int64(9), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused in T.parallel(T.int64(224), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(3), T.int64(9), T.int64(512)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(9), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(7) + ax2)
                    v_i3, v_i4 = T.axis.remap("SS", [ax3, ax4])
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(8) and T.int64(1) <= v_i3 and v_i3 < T.int64(8), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(112) * T.int64(8) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(14) // T.int64(7) * T.int64(4) + oc_chunk_2_init + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(7) + oh_2_init + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(7), ow_1 * T.int64(7) + ow_2_init * T.int64(7) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(112) // T.int64(14) * T.int64(4) + oc_block_1 * T.int64(4) + oc_block_2_init * T.int64(4) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(256), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                    for oc_block_3_fused in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(112) * T.int64(8) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(14) // T.int64(7) * T.int64(4) + oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(7) + oh_2 + oh_3)
                            v_ow = T.axis.spatial(T.int64(7), ow_1 * T.int64(7) + ow_2 * T.int64(7) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(112) // T.int64(14) * T.int64(4) + oc_block_1 * T.int64(4) + oc_block_2 * T.int64(4) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(2) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
        for ax0_ax1_ax2_ax3_ax4_fused_0 in T.parallel(T.int64(392)):
            for ax0_ax1_ax2_ax3_ax4_fused_1 in T.vectorized(T.int64(64)):
                with T.block("T_relu"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) // T.int64(1568))
                    v_ax2 = T.axis.spatial(T.int64(7), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(1568) // T.int64(224))
                    v_ax3 = T.axis.spatial(T.int64(7), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(224) // T.int64(32))
                    v_ax4 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(32))
                    T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                    T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[2, 2, 4, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 7, 1, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 1, 7])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[8, 1, 1, 4])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[256, 2])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
l65 = sch.sample_compute_location(block=b0, decision=7)
sch.compute_at(block=b0, loop=l65, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b66 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.unroll_explicit")
b67, b68, b69 = sch.get_child_blocks(b66)
l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82 = sch.get_loops(block=b67)
l83 = sch.fuse(l70, l71, l72, l73, l74, l75, l76, l77, preserve_unit_iters=True)
sch.parallel(loop=l83)
l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102 = sch.get_loops(block=b68)
l103 = sch.fuse(l84, preserve_unit_iters=True)
sch.parallel(loop=l103)
l104 = sch.fuse(l102, preserve_unit_iters=True)
sch.vectorize(loop=l104)
sch.annotate(block_or_loop=l103, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l103, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109 = sch.get_loops(block=b69)
l110 = sch.fuse(l105, l106, l107, l108, l109, preserve_unit_iters=True)
l111, l112 = sch.split(loop=l110, factors=[None, 64], preserve_unit_iters=True)
sch.parallel(loop=l111)
sch.vectorize(loop=l112)
b113 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132 = sch.get_loops(block=b113)
b133 = sch.decompose_reduction(block=b113, loop=l117)
2024-04-29 07:12:37 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #512: GFLOPs: 48.2376. Time: 4794.2076 us. Best GFLOPs: 801.8350
2024-04-29 08:12:16 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 08:12:17 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-29 08:12:21 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x5e10dc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x6d79bf8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x5e1f188)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3181528)]: 0 failure(s)
2024-04-29 08:12:21 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-29 08:12:32 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x5e10dc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x6d79bf8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x5e1f188)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3181528)]: 0 failure(s)
2024-04-29 08:12:42 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x5e10dc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x6d79bf8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x5e1f188)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3181528)]: 0 failure(s)
2024-04-29 08:12:53 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x5e10dc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x6d79bf8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x5e1f188)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3181528)]: 0 failure(s)
2024-04-29 08:13:03 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x5e10dc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x6d79bf8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x5e1f188)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3181528)]: 0 failure(s)
2024-04-29 08:13:10 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9399  0.9345  0.8715  0.8715  0.8468  0.8421  0.8302  0.8200  0.8001  0.7699  0.7692  0.7676  0.7632  0.7625  0.7417  0.7388
[17 : 32]:	0.7369  0.7353  0.7352  0.7341  0.7332  0.7325  0.7312  0.7220  0.7220  0.7216  0.7199  0.7199  0.7157  0.7142  0.7036  0.7023
[33 : 48]:	0.7017  0.6995  0.6932  0.6929  0.6929  0.6904  0.6885  0.6835  0.6826  0.6807  0.6789  0.6758  0.6758  0.6733  0.6707  0.6661
[49 : 64]:	0.6659  0.6648  0.6641  0.6624  0.6618  0.6612  0.6571  0.6554  0.6526  0.6522  0.6493  0.6436  0.6436  0.6413  0.6413  0.6409
2024-04-29 08:13:10 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 08:13:10 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 08:15:08 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #513: GFLOPs: 774.4559. Time: 298.6112 us. Best GFLOPs: 801.8350
2024-04-29 08:15:08 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #514: GFLOPs: 744.9709. Time: 310.4298 us. Best GFLOPs: 801.8350
2024-04-29 08:15:08 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #515: GFLOPs: 732.5106. Time: 315.7103 us. Best GFLOPs: 801.8350
2024-04-29 08:15:08 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #516: GFLOPs: 758.6629. Time: 304.8273 us. Best GFLOPs: 801.8350
2024-04-29 08:15:08 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #517: GFLOPs: 650.5604. Time: 355.4799 us. Best GFLOPs: 801.8350
2024-04-29 08:15:08 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #518: GFLOPs: 718.5845. Time: 321.8288 us. Best GFLOPs: 801.8350
2024-04-29 08:15:08 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #519: GFLOPs: 668.5652. Time: 345.9067 us. Best GFLOPs: 801.8350
2024-04-29 08:15:08 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #520: GFLOPs: 622.1480. Time: 371.7141 us. Best GFLOPs: 801.8350
2024-04-29 08:15:08 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #521: GFLOPs: 653.9390. Time: 353.6434 us. Best GFLOPs: 801.8350
2024-04-29 08:15:08 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #522: GFLOPs: 639.3662. Time: 361.7038 us. Best GFLOPs: 801.8350
2024-04-29 08:15:08 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #523: GFLOPs: 630.0584. Time: 367.0472 us. Best GFLOPs: 801.8350
2024-04-29 08:15:08 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #524: GFLOPs: 609.6681. Time: 379.3231 us. Best GFLOPs: 801.8350
2024-04-29 08:15:08 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #525: GFLOPs: 661.3604. Time: 349.6750 us. Best GFLOPs: 801.8350
2024-04-29 08:15:08 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #526: GFLOPs: 624.1578. Time: 370.5172 us. Best GFLOPs: 801.8350
2024-04-29 08:15:08 [INFO] [task_scheduler.cc:121] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #527: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(7), T.int64(7), T.int64(512)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(9), T.int64(9), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_fused_fused in T.parallel(T.int64(112), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(3), T.int64(9), T.int64(512)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(9), n_0_oc_chunk_0_oh_0_fused_fused % T.int64(7) + ax2)
                    v_i3, v_i4 = T.axis.remap("SS", [ax3, ax4])
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(8) and T.int64(1) <= v_i3 and v_i3 < T.int64(8), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for ow_0, oc_block_0, n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_fused_fused // T.int64(7) + oc_chunk_1 + oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_fused_fused % T.int64(7) + oh_1 + oh_2_init + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(7), ow_0 * T.int64(7) + ow_1 * T.int64(7) + ow_2_init * T.int64(7) + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_0 * T.int64(32) + oc_block_1 * T.int64(32) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(256), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(32), T.int64(2), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_fused_fused // T.int64(7) + oc_chunk_1 + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_fused_fused % T.int64(7) + oh_1 + oh_2 + oh_3)
                        v_ow = T.axis.spatial(T.int64(7), ow_0 * T.int64(7) + ow_1 * T.int64(7) + ow_2 * T.int64(7) + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_0 * T.int64(32) + oc_block_1 * T.int64(32) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(2) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                    for ax4_fused in T.vectorized(T.int64(32)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_fused_fused // T.int64(7) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_fused_fused % T.int64(7) + ax2)
                            v_ax3, v_ax4 = T.axis.remap("SS", [ax3, ax4_fused])
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[16, 1, 1, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[7, 1, 1, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 1, 7])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 32, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[256, 2])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=2)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78 = sch.get_loops(block=b68)
l79 = sch.fuse(l71, l72, l73, preserve_unit_iters=True)
sch.parallel(loop=l79)
l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l80, preserve_unit_iters=True)
sch.parallel(loop=l104)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117 = sch.get_loops(block=b70)
l118 = sch.fuse(l117, preserve_unit_iters=True)
sch.vectorize(loop=l118)
b119 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141, l142, l143 = sch.get_loops(block=b119)
b144 = sch.decompose_reduction(block=b119, loop=l128)
2024-04-29 08:15:08 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #528: GFLOPs: 306.5165. Time: 754.4819 us. Best GFLOPs: 801.8350
2024-04-29 08:15:08 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #529: GFLOPs: 551.3686. Time: 419.4312 us. Best GFLOPs: 801.8350
2024-04-29 08:15:08 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #530: GFLOPs: 565.0421. Time: 409.2813 us. Best GFLOPs: 801.8350
2024-04-29 08:15:08 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #531: GFLOPs: 564.2379. Time: 409.8647 us. Best GFLOPs: 801.8350
2024-04-29 08:15:08 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #532: GFLOPs: 634.6958. Time: 364.3654 us. Best GFLOPs: 801.8350
2024-04-29 08:15:08 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #533: GFLOPs: 351.8450. Time: 657.2814 us. Best GFLOPs: 801.8350
2024-04-29 08:15:08 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #534: GFLOPs: 553.3585. Time: 417.9229 us. Best GFLOPs: 801.8350
2024-04-29 08:15:08 [INFO] [task_scheduler.cc:121] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #535: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(7), T.int64(7), T.int64(512)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(9), T.int64(9), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused in T.parallel(T.int64(112), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(3), T.int64(9), T.int64(512)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(9), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(28) // T.int64(4) + ax2)
                    v_i3, v_i4 = T.axis.remap("SS", [ax3, ax4])
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(8) and T.int64(1) <= v_i3 and v_i3 < T.int64(8), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(28) * T.int64(4) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(4) + oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(28) // T.int64(4) + oh_1 + oh_2_init + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(7), ow_1 * T.int64(7) + ow_2_init * T.int64(7) + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(128), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(32), T.int64(4), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(28) * T.int64(4) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(4) + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(28) // T.int64(4) + oh_1 + oh_2 + oh_3)
                        v_ow = T.axis.spatial(T.int64(7), ow_1 * T.int64(7) + ow_2 * T.int64(7) + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(4) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                    for ax4_fused in T.vectorized(T.int64(32)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(28) * T.int64(4) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(4) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(28) // T.int64(4) + ax2)
                            v_ax3, v_ax4 = T.axis.remap("SS", [ax3, ax4_fused])
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[4, 4, 1, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[7, 1, 1, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 1, 7])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 32, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[128, 4])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=6)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82 = sch.get_loops(block=b68)
l83 = sch.fuse(l71, l72, l73, l74, l75, l76, l77, preserve_unit_iters=True)
sch.parallel(loop=l83)
l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l84, preserve_unit_iters=True)
sch.parallel(loop=l104)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109, l110, l111, l112, l113 = sch.get_loops(block=b70)
l114 = sch.fuse(l113, preserve_unit_iters=True)
sch.vectorize(loop=l114)
b115 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135 = sch.get_loops(block=b115)
b136 = sch.decompose_reduction(block=b115, loop=l120)
2024-04-29 08:15:08 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #536: GFLOPs: 574.6739. Time: 402.4216 us. Best GFLOPs: 801.8350
2024-04-29 08:15:08 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #537: GFLOPs: 565.5401. Time: 408.9209 us. Best GFLOPs: 801.8350
2024-04-29 08:15:08 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #538: GFLOPs: 564.4872. Time: 409.6836 us. Best GFLOPs: 801.8350
2024-04-29 08:15:08 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #539: GFLOPs: 572.4337. Time: 403.9964 us. Best GFLOPs: 801.8350
2024-04-29 08:15:08 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #540: GFLOPs: 579.0781. Time: 399.3610 us. Best GFLOPs: 801.8350
2024-04-29 08:15:08 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #541: GFLOPs: 566.6713. Time: 408.1046 us. Best GFLOPs: 801.8350
2024-04-29 08:15:08 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #542: GFLOPs: 569.1000. Time: 406.3630 us. Best GFLOPs: 801.8350
2024-04-29 08:15:08 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #543: GFLOPs: 739.3085. Time: 312.8074 us. Best GFLOPs: 801.8350
2024-04-29 08:15:08 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #544: GFLOPs: 543.4978. Time: 425.5053 us. Best GFLOPs: 801.8350
2024-04-29 08:15:08 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #545: GFLOPs: 561.3334. Time: 411.9855 us. Best GFLOPs: 801.8350
2024-04-29 08:15:08 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #546: GFLOPs: 524.5179. Time: 440.9024 us. Best GFLOPs: 801.8350
2024-04-29 08:15:08 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #547: GFLOPs: 546.5193. Time: 423.1528 us. Best GFLOPs: 801.8350
2024-04-29 08:15:08 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #548: GFLOPs: 540.7773. Time: 427.6458 us. Best GFLOPs: 801.8350
2024-04-29 08:15:08 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #549: GFLOPs: 536.9503. Time: 430.6938 us. Best GFLOPs: 801.8350
2024-04-29 08:15:08 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #550: GFLOPs: 543.5327. Time: 425.4780 us. Best GFLOPs: 801.8350
2024-04-29 08:15:08 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #551: GFLOPs: 495.2852. Time: 466.9253 us. Best GFLOPs: 801.8350
2024-04-29 08:15:08 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #552: GFLOPs: 544.1046. Time: 425.0308 us. Best GFLOPs: 801.8350
2024-04-29 08:15:08 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #553: GFLOPs: 556.5394. Time: 415.5342 us. Best GFLOPs: 801.8350
2024-04-29 08:15:08 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #554: GFLOPs: 525.4143. Time: 440.1502 us. Best GFLOPs: 801.8350
2024-04-29 08:15:08 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #555: GFLOPs: 542.4139. Time: 426.3555 us. Best GFLOPs: 801.8350
2024-04-29 08:15:08 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #556: GFLOPs: 559.0137. Time: 413.6950 us. Best GFLOPs: 801.8350
2024-04-29 08:15:08 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #557: GFLOPs: 673.7787. Time: 343.2302 us. Best GFLOPs: 801.8350
2024-04-29 08:15:08 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #558: GFLOPs: 484.6351. Time: 477.1862 us. Best GFLOPs: 801.8350
2024-04-29 08:15:08 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #559: GFLOPs: 558.2322. Time: 414.2742 us. Best GFLOPs: 801.8350
2024-04-29 08:15:08 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #560: GFLOPs: 475.1012. Time: 486.7619 us. Best GFLOPs: 801.8350
2024-04-29 08:15:08 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #561: GFLOPs: 555.2759. Time: 416.4798 us. Best GFLOPs: 801.8350
2024-04-29 08:15:08 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #562: GFLOPs: 398.7601. Time: 579.9506 us. Best GFLOPs: 801.8350
2024-04-29 08:15:08 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #563: GFLOPs: 563.2647. Time: 410.5728 us. Best GFLOPs: 801.8350
2024-04-29 08:15:08 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #564: GFLOPs: 282.9394. Time: 817.3524 us. Best GFLOPs: 801.8350
2024-04-29 08:15:08 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #565: GFLOPs: 555.9037. Time: 416.0094 us. Best GFLOPs: 801.8350
2024-04-29 08:15:08 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #566: GFLOPs: 496.3386. Time: 465.9343 us. Best GFLOPs: 801.8350
2024-04-29 08:15:08 [INFO] [task_scheduler.cc:121] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #567: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(7), T.int64(7), T.int64(512)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(9), T.int64(9), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused in T.parallel(T.int64(112), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(3), T.int64(9), T.int64(512)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(9), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(16) + ax2)
                    v_i3, v_i4 = T.axis.remap("SS", [ax3, ax4])
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(8) and T.int64(1) <= v_i3 and v_i3 < T.int64(8), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(16) + oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(16) + oh_1 + oh_2_init + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(7), ow_1 * T.int64(7) + ow_2_init * T.int64(7) + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(512), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(16) + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(16) + oh_1 + oh_2 + oh_3)
                        v_ow = T.axis.spatial(T.int64(7), ow_1 * T.int64(7) + ow_2 * T.int64(7) + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(512), ic_0 + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                    for ax4_fused in T.vectorized(T.int64(32)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(16) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(16) + ax2)
                            v_ax3, v_ax4 = T.axis.remap("SS", [ax3, ax4_fused])
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 16, 1, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[7, 1, 1, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 1, 7])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 32, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[512, 1])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=6)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82 = sch.get_loops(block=b68)
l83 = sch.fuse(l71, l72, l73, l74, l75, l76, l77, preserve_unit_iters=True)
sch.parallel(loop=l83)
l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l84, preserve_unit_iters=True)
sch.parallel(loop=l104)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109, l110, l111, l112, l113 = sch.get_loops(block=b70)
l114 = sch.fuse(l113, preserve_unit_iters=True)
sch.vectorize(loop=l114)
b115 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135 = sch.get_loops(block=b115)
b136 = sch.decompose_reduction(block=b115, loop=l120)
2024-04-29 08:15:08 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #568: GFLOPs: 599.5346. Time: 385.7345 us. Best GFLOPs: 801.8350
2024-04-29 08:15:08 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #569: GFLOPs: 500.3414. Time: 462.2068 us. Best GFLOPs: 801.8350
2024-04-29 08:15:08 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #570: GFLOPs: 447.3125. Time: 517.0014 us. Best GFLOPs: 801.8350
2024-04-29 08:15:08 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #571: GFLOPs: 398.5554. Time: 580.2486 us. Best GFLOPs: 801.8350
2024-04-29 08:15:08 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #572: GFLOPs: 603.2315. Time: 383.3705 us. Best GFLOPs: 801.8350
2024-04-29 08:15:08 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #573: GFLOPs: 602.9748. Time: 383.5337 us. Best GFLOPs: 801.8350
2024-04-29 08:15:08 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #574: GFLOPs: 20.6780. Time: 11183.9450 us. Best GFLOPs: 801.8350
2024-04-29 08:15:08 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #575: GFLOPs: 23.2859. Time: 9931.3931 us. Best GFLOPs: 801.8350
2024-04-29 08:15:08 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #576: GFLOPs: 16.9152. Time: 13671.7770 us. Best GFLOPs: 801.8350
2024-04-29 09:10:18 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 09:10:19 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-29 09:10:23 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x5e10dc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x6d79bf8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x5e1f188)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3181528)]: 0 failure(s)
2024-04-29 09:10:23 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-29 09:10:34 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x5e10dc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x6d79bf8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x5e1f188)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3181528)]: 0 failure(s)
2024-04-29 09:10:44 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x5e10dc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x6d79bf8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x5e1f188)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3181528)]: 0 failure(s)
2024-04-29 09:10:55 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x5e10dc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x6d79bf8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x5e1f188)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3181528)]: 0 failure(s)
2024-04-29 09:11:05 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x5e10dc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x6d79bf8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x5e1f188)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3181528)]: 0 failure(s)
2024-04-29 09:11:12 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9302  0.9206  0.9138  0.9021  0.8817  0.8757  0.8757  0.8757  0.8757  0.8120  0.8120  0.8085  0.8054  0.8050  0.7995  0.7948
[17 : 32]:	0.7781  0.7781  0.7746  0.7719  0.7681  0.7681  0.7667  0.7667  0.7639  0.7594  0.7519  0.7400  0.7372  0.7368  0.7368  0.7195
[33 : 48]:	0.7168  0.7168  0.7161  0.7161  0.7075  0.7075  0.7013  0.7007  0.6967  0.6920  0.6893  0.6893  0.6864  0.6837  0.6837  0.6770
[49 : 64]:	0.6689  0.6622  0.6543  0.6527  0.6527  0.6482  0.6451  0.6415  0.6403  0.6339  0.6316  0.6297  0.6286  0.6279  0.6255  0.6242
2024-04-29 09:11:12 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 09:11:12 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 09:13:10 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #577: GFLOPs: 797.9231. Time: 289.8289 us. Best GFLOPs: 801.8350
2024-04-29 09:13:10 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #578: GFLOPs: 819.2528. Time: 282.2831 us. Best GFLOPs: 819.2528
2024-04-29 09:13:10 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #579: GFLOPs: 755.0169. Time: 306.2993 us. Best GFLOPs: 819.2528
2024-04-29 09:13:10 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #580: GFLOPs: 771.8558. Time: 299.6171 us. Best GFLOPs: 819.2528
2024-04-29 09:13:10 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #581: GFLOPs: 759.3333. Time: 304.5582 us. Best GFLOPs: 819.2528
2024-04-29 09:13:10 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #582: GFLOPs: 769.1671. Time: 300.6644 us. Best GFLOPs: 819.2528
2024-04-29 09:13:10 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #583: GFLOPs: 728.8460. Time: 317.2977 us. Best GFLOPs: 819.2528
2024-04-29 09:13:10 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #584: GFLOPs: 764.8863. Time: 302.3471 us. Best GFLOPs: 819.2528
2024-04-29 09:13:10 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #585: GFLOPs: 733.1315. Time: 315.4430 us. Best GFLOPs: 819.2528
2024-04-29 09:13:10 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #586: GFLOPs: 707.6827. Time: 326.7865 us. Best GFLOPs: 819.2528
2024-04-29 09:13:10 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #587: GFLOPs: 701.4424. Time: 329.6938 us. Best GFLOPs: 819.2528
2024-04-29 09:13:10 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #588: GFLOPs: 627.6661. Time: 368.4462 us. Best GFLOPs: 819.2528
2024-04-29 09:13:10 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #589: GFLOPs: 482.3565. Time: 479.4404 us. Best GFLOPs: 819.2528
2024-04-29 09:13:10 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #590: GFLOPs: 667.4414. Time: 346.4891 us. Best GFLOPs: 819.2528
2024-04-29 09:13:10 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #591: GFLOPs: 759.5777. Time: 304.4602 us. Best GFLOPs: 819.2528
2024-04-29 09:13:10 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #592: GFLOPs: 659.0890. Time: 350.8801 us. Best GFLOPs: 819.2528
2024-04-29 09:13:10 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #593: GFLOPs: 362.1665. Time: 638.5493 us. Best GFLOPs: 819.2528
2024-04-29 09:13:10 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #594: GFLOPs: 642.3083. Time: 360.0470 us. Best GFLOPs: 819.2528
2024-04-29 09:13:10 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #595: GFLOPs: 664.2369. Time: 348.1607 us. Best GFLOPs: 819.2528
2024-04-29 09:13:10 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #596: GFLOPs: 651.4488. Time: 354.9952 us. Best GFLOPs: 819.2528
2024-04-29 09:13:10 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #597: GFLOPs: 630.0660. Time: 367.0428 us. Best GFLOPs: 819.2528
2024-04-29 09:13:10 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #598: GFLOPs: 614.9242. Time: 376.0808 us. Best GFLOPs: 819.2528
2024-04-29 09:13:10 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #599: GFLOPs: 615.7790. Time: 375.5587 us. Best GFLOPs: 819.2528
2024-04-29 09:13:10 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #600: GFLOPs: 643.6794. Time: 359.2801 us. Best GFLOPs: 819.2528
2024-04-29 09:13:10 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #601: GFLOPs: 619.2117. Time: 373.4768 us. Best GFLOPs: 819.2528
2024-04-29 09:13:10 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #602: GFLOPs: 623.4996. Time: 370.9083 us. Best GFLOPs: 819.2528
2024-04-29 09:13:10 [INFO] [task_scheduler.cc:121] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #603: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(7), T.int64(7), T.int64(512)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(9), T.int64(9), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused in T.parallel(T.int64(112), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(3), T.int64(9), T.int64(512)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(9), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(16) + ax2)
                    v_i3, v_i4 = T.axis.remap("SS", [ax3, ax4])
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(8) and T.int64(1) <= v_i3 and v_i3 < T.int64(8), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(16) + oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(16) + oh_1 + oh_2_init + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(7), ow_1 * T.int64(7) + ow_2_init * T.int64(7) + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(256), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(32), T.int64(2), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(16) + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(16) + oh_1 + oh_2 + oh_3)
                        v_ow = T.axis.spatial(T.int64(7), ow_1 * T.int64(7) + ow_2 * T.int64(7) + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(2) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                    for ax4_fused in T.vectorized(T.int64(32)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(16) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(16) + ax2)
                            v_ax3, v_ax4 = T.axis.remap("SS", [ax3, ax4_fused])
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 16, 1, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[7, 1, 1, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 1, 7])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 32, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[256, 2])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=6)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82 = sch.get_loops(block=b68)
l83 = sch.fuse(l71, l72, l73, l74, l75, l76, l77, preserve_unit_iters=True)
sch.parallel(loop=l83)
l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l84, preserve_unit_iters=True)
sch.parallel(loop=l104)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109, l110, l111, l112, l113 = sch.get_loops(block=b70)
l114 = sch.fuse(l113, preserve_unit_iters=True)
sch.vectorize(loop=l114)
b115 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135 = sch.get_loops(block=b115)
b136 = sch.decompose_reduction(block=b115, loop=l120)
2024-04-29 09:13:10 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #604: GFLOPs: 387.9657. Time: 596.0867 us. Best GFLOPs: 819.2528
2024-04-29 09:13:10 [INFO] [task_scheduler.cc:121] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #605: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(7), T.int64(7), T.int64(512)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(9), T.int64(9), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused in T.parallel(T.int64(112), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(3), T.int64(9), T.int64(512)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(9), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(56) // T.int64(8) + ax2)
                    v_i3, v_i4 = T.axis.remap("SS", [ax3, ax4])
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(8) and T.int64(1) <= v_i3 and v_i3 < T.int64(8), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(56) * T.int64(8) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(8) + oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(56) // T.int64(8) + oh_1 + oh_2_init + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(7), ow_1 * T.int64(7) + ow_2_init * T.int64(7) + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(512), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(56) * T.int64(8) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(8) + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(56) // T.int64(8) + oh_1 + oh_2 + oh_3)
                        v_ow = T.axis.spatial(T.int64(7), ow_1 * T.int64(7) + ow_2 * T.int64(7) + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(512), ic_0 + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                    for ax4_fused in T.vectorized(T.int64(32)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(56) * T.int64(8) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(8) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(56) // T.int64(8) + ax2)
                            v_ax3, v_ax4 = T.axis.remap("SS", [ax3, ax4_fused])
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[2, 8, 1, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[7, 1, 1, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 1, 7])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 32, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[512, 1])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=6)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82 = sch.get_loops(block=b68)
l83 = sch.fuse(l71, l72, l73, l74, l75, l76, l77, preserve_unit_iters=True)
sch.parallel(loop=l83)
l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l84, preserve_unit_iters=True)
sch.parallel(loop=l104)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109, l110, l111, l112, l113 = sch.get_loops(block=b70)
l114 = sch.fuse(l113, preserve_unit_iters=True)
sch.vectorize(loop=l114)
b115 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135 = sch.get_loops(block=b115)
b136 = sch.decompose_reduction(block=b115, loop=l120)
2024-04-29 09:13:10 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #606: GFLOPs: 628.3712. Time: 368.0327 us. Best GFLOPs: 819.2528
2024-04-29 09:13:10 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #607: GFLOPs: 624.8802. Time: 370.0888 us. Best GFLOPs: 819.2528
2024-04-29 09:13:10 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #608: GFLOPs: 549.1605. Time: 421.1177 us. Best GFLOPs: 819.2528
2024-04-29 09:13:10 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #609: GFLOPs: 563.0328. Time: 410.7420 us. Best GFLOPs: 819.2528
2024-04-29 09:13:10 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #610: GFLOPs: 589.2459. Time: 392.4698 us. Best GFLOPs: 819.2528
2024-04-29 09:13:10 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #611: GFLOPs: 551.1485. Time: 419.5987 us. Best GFLOPs: 819.2528
2024-04-29 09:13:10 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #612: GFLOPs: 547.8335. Time: 422.1377 us. Best GFLOPs: 819.2528
2024-04-29 09:13:10 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #613: GFLOPs: 565.4717. Time: 408.9704 us. Best GFLOPs: 819.2528
2024-04-29 09:13:10 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #614: GFLOPs: 582.3442. Time: 397.1211 us. Best GFLOPs: 819.2528
2024-04-29 09:13:10 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #615: GFLOPs: 495.6580. Time: 466.5741 us. Best GFLOPs: 819.2528
2024-04-29 09:13:10 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #616: GFLOPs: 603.4740. Time: 383.2165 us. Best GFLOPs: 819.2528
2024-04-29 09:13:10 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #617: GFLOPs: 575.1470. Time: 402.0906 us. Best GFLOPs: 819.2528
2024-04-29 09:13:10 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #618: GFLOPs: 548.2058. Time: 421.8510 us. Best GFLOPs: 819.2528
2024-04-29 09:13:10 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #619: GFLOPs: 567.7837. Time: 407.3051 us. Best GFLOPs: 819.2528
2024-04-29 09:13:10 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #620: GFLOPs: 558.3090. Time: 414.2172 us. Best GFLOPs: 819.2528
2024-04-29 09:13:10 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #621: GFLOPs: 470.2174. Time: 491.8176 us. Best GFLOPs: 819.2528
2024-04-29 09:13:10 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #622: GFLOPs: 555.2073. Time: 416.5312 us. Best GFLOPs: 819.2528
2024-04-29 09:13:10 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #623: GFLOPs: 573.7798. Time: 403.0487 us. Best GFLOPs: 819.2528
2024-04-29 09:13:10 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #624: GFLOPs: 481.0964. Time: 480.6961 us. Best GFLOPs: 819.2528
2024-04-29 09:13:10 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #625: GFLOPs: 427.4998. Time: 540.9620 us. Best GFLOPs: 819.2528
2024-04-29 09:13:10 [INFO] [task_scheduler.cc:121] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #626: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(7), T.int64(7), T.int64(512)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(9), T.int64(9), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_fused_fused in T.parallel(T.int64(28), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(3), T.int64(9), T.int64(512)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(9), n_0_oc_chunk_0_oh_0_fused_fused % T.int64(7) + ax2)
                    v_i3, v_i4 = T.axis.remap("SS", [ax3, ax4])
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(8) and T.int64(1) <= v_i3 and v_i3 < T.int64(8), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for ow_0, oc_block_0, n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_fused_fused // T.int64(7) * T.int64(4) + oc_chunk_1 + oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_fused_fused % T.int64(7) + oh_1 + oh_2_init + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(7), ow_0 * T.int64(7) + ow_1 * T.int64(7) + ow_2_init * T.int64(7) + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_0 * T.int64(32) + oc_block_1 * T.int64(32) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(512), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_fused_fused // T.int64(7) * T.int64(4) + oc_chunk_1 + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_fused_fused % T.int64(7) + oh_1 + oh_2 + oh_3)
                        v_ow = T.axis.spatial(T.int64(7), ow_0 * T.int64(7) + ow_1 * T.int64(7) + ow_2 * T.int64(7) + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_0 * T.int64(32) + oc_block_1 * T.int64(32) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(512), ic_0 + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                    for ax4_fused in T.vectorized(T.int64(32)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_fused_fused // T.int64(7) * T.int64(4) + oc_chunk_1 + ax1)
                            v_ax2 = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_fused_fused % T.int64(7) + ax2)
                            v_ax3, v_ax4 = T.axis.remap("SS", [ax3, ax4_fused])
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[4, 4, 1, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[7, 1, 1, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 1, 7])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 32, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[512, 1])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=2)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78 = sch.get_loops(block=b68)
l79 = sch.fuse(l71, l72, l73, preserve_unit_iters=True)
sch.parallel(loop=l79)
l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l80, preserve_unit_iters=True)
sch.parallel(loop=l104)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117 = sch.get_loops(block=b70)
l118 = sch.fuse(l117, preserve_unit_iters=True)
sch.vectorize(loop=l118)
b119 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141, l142, l143 = sch.get_loops(block=b119)
b144 = sch.decompose_reduction(block=b119, loop=l128)
2024-04-29 09:13:10 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #627: GFLOPs: 528.1368. Time: 437.8812 us. Best GFLOPs: 819.2528
2024-04-29 09:13:10 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #628: GFLOPs: 576.2300. Time: 401.3349 us. Best GFLOPs: 819.2528
2024-04-29 09:13:10 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #629: GFLOPs: 555.9095. Time: 416.0051 us. Best GFLOPs: 819.2528
2024-04-29 09:13:10 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #630: GFLOPs: 655.7263. Time: 352.6794 us. Best GFLOPs: 819.2528
2024-04-29 09:13:10 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #631: GFLOPs: 504.3940. Time: 458.4931 us. Best GFLOPs: 819.2528
2024-04-29 09:13:10 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #632: GFLOPs: 544.0023. Time: 425.1106 us. Best GFLOPs: 819.2528
2024-04-29 09:13:10 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #633: GFLOPs: 427.0603. Time: 541.5188 us. Best GFLOPs: 819.2528
2024-04-29 09:13:10 [INFO] [task_scheduler.cc:121] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #634: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(7), T.int64(7), T.int64(512)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(9), T.int64(9), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_fused_fused in T.parallel(T.int64(28), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(3), T.int64(9), T.int64(512)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(9), n_0_oc_chunk_0_oh_0_fused_fused % T.int64(7) + ax2)
                    v_i3, v_i4 = T.axis.remap("SS", [ax3, ax4])
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(8) and T.int64(1) <= v_i3 and v_i3 < T.int64(8), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for ow_0, oc_block_0, n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_fused_fused // T.int64(7) * T.int64(4) + oc_chunk_1 + oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_fused_fused % T.int64(7) + oh_1 + oh_2_init + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(7), ow_0 * T.int64(7) + ow_1 * T.int64(7) + ow_2_init * T.int64(7) + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_0 * T.int64(32) + oc_block_1 * T.int64(32) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(256), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(32), T.int64(2), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_fused_fused // T.int64(7) * T.int64(4) + oc_chunk_1 + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_fused_fused % T.int64(7) + oh_1 + oh_2 + oh_3)
                        v_ow = T.axis.spatial(T.int64(7), ow_0 * T.int64(7) + ow_1 * T.int64(7) + ow_2 * T.int64(7) + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_0 * T.int64(32) + oc_block_1 * T.int64(32) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(2) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                    for ax4_fused in T.vectorized(T.int64(32)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_fused_fused // T.int64(7) * T.int64(4) + oc_chunk_1 + ax1)
                            v_ax2 = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_fused_fused % T.int64(7) + ax2)
                            v_ax3, v_ax4 = T.axis.remap("SS", [ax3, ax4_fused])
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[4, 4, 1, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[7, 1, 1, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 1, 7])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 32, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[256, 2])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=2)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78 = sch.get_loops(block=b68)
l79 = sch.fuse(l71, l72, l73, preserve_unit_iters=True)
sch.parallel(loop=l79)
l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l80, preserve_unit_iters=True)
sch.parallel(loop=l104)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117 = sch.get_loops(block=b70)
l118 = sch.fuse(l117, preserve_unit_iters=True)
sch.vectorize(loop=l118)
b119 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141, l142, l143 = sch.get_loops(block=b119)
b144 = sch.decompose_reduction(block=b119, loop=l128)
2024-04-29 09:13:10 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #635: GFLOPs: 172.4719. Time: 1340.8633 us. Best GFLOPs: 819.2528
2024-04-29 09:13:10 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #636: GFLOPs: 479.8887. Time: 481.9059 us. Best GFLOPs: 819.2528
2024-04-29 09:13:10 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #637: GFLOPs: 575.6022. Time: 401.7726 us. Best GFLOPs: 819.2528
2024-04-29 09:13:10 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #638: GFLOPs: 3.7601. Time: 61504.6937 us. Best GFLOPs: 819.2528
2024-04-29 09:13:10 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #639: GFLOPs: 1.6267. Time: 142164.9587 us. Best GFLOPs: 819.2528
2024-04-29 09:13:10 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #640: GFLOPs: 17.5805. Time: 13154.4135 us. Best GFLOPs: 819.2528
2024-04-29 09:48:11 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 09:48:12 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-29 09:48:16 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x5e10dc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x6d79bf8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x5e1f188)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3181528)]: 0 failure(s)
2024-04-29 09:48:16 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-29 09:48:27 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x5e10dc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x6d79bf8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x5e1f188)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3181528)]: 0 failure(s)
2024-04-29 09:48:37 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x5e10dc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x6d79bf8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x5e1f188)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3181528)]: 0 failure(s)
2024-04-29 09:48:48 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x5e10dc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x6d79bf8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x5e1f188)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3181528)]: 0 failure(s)
2024-04-29 09:48:59 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x5e10dc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x6d79bf8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x5e1f188)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3181528)]: 0 failure(s)
2024-04-29 09:49:05 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9516  0.9491  0.9331  0.9331  0.8989  0.8989  0.8912  0.8807  0.8766  0.8766  0.8734  0.8734  0.8312  0.8312  0.7950  0.7831
[17 : 32]:	0.7831  0.7814  0.7771  0.7739  0.7732  0.7713  0.7693  0.7633  0.7623  0.7573  0.7518  0.7464  0.7413  0.7407  0.7389  0.7365
[33 : 48]:	0.7311  0.7149  0.7082  0.7011  0.6988  0.6907  0.6907  0.6799  0.6762  0.6747  0.6727  0.6650  0.6599  0.6595  0.6550  0.6527
[49 : 64]:	0.6523  0.6432  0.6412  0.6412  0.6392  0.6381  0.6320  0.6320  0.6316  0.6302  0.6263  0.6251  0.6251  0.6251  0.6229  0.6211
2024-04-29 09:49:06 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 09:49:06 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 09:51:13 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #641: GFLOPs: 790.6936. Time: 292.4789 us. Best GFLOPs: 819.2528
2024-04-29 09:51:13 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #642: GFLOPs: 810.1311. Time: 285.4614 us. Best GFLOPs: 819.2528
2024-04-29 09:51:13 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #643: GFLOPs: 765.6984. Time: 302.0265 us. Best GFLOPs: 819.2528
2024-04-29 09:51:13 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #644: GFLOPs: 774.8211. Time: 298.4704 us. Best GFLOPs: 819.2528
2024-04-29 09:51:13 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #645: GFLOPs: 749.6470. Time: 308.4934 us. Best GFLOPs: 819.2528
2024-04-29 09:51:13 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #646: GFLOPs: 810.6962. Time: 285.2625 us. Best GFLOPs: 819.2528
2024-04-29 09:51:13 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #647: GFLOPs: 735.1872. Time: 314.5610 us. Best GFLOPs: 819.2528
2024-04-29 09:51:13 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #648: GFLOPs: 767.1263. Time: 301.4643 us. Best GFLOPs: 819.2528
2024-04-29 09:51:13 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #649: GFLOPs: 796.4910. Time: 290.3500 us. Best GFLOPs: 819.2528
2024-04-29 09:51:13 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #650: GFLOPs: 806.5687. Time: 286.7222 us. Best GFLOPs: 819.2528
2024-04-29 09:51:13 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #651: GFLOPs: 786.6795. Time: 293.9713 us. Best GFLOPs: 819.2528
2024-04-29 09:51:13 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #652: GFLOPs: 751.6880. Time: 307.6558 us. Best GFLOPs: 819.2528
2024-04-29 09:51:13 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #653: GFLOPs: 683.2945. Time: 338.4503 us. Best GFLOPs: 819.2528
2024-04-29 09:51:13 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #654: GFLOPs: 694.7347. Time: 332.8770 us. Best GFLOPs: 819.2528
2024-04-29 09:51:13 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #655: GFLOPs: 657.9298. Time: 351.4983 us. Best GFLOPs: 819.2528
2024-04-29 09:51:13 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #656: GFLOPs: 617.5628. Time: 374.4740 us. Best GFLOPs: 819.2528
2024-04-29 09:51:13 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #657: GFLOPs: 572.1139. Time: 404.2223 us. Best GFLOPs: 819.2528
2024-04-29 09:51:13 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #658: GFLOPs: 761.8850. Time: 303.5382 us. Best GFLOPs: 819.2528
2024-04-29 09:51:13 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #659: GFLOPs: 336.9595. Time: 686.3175 us. Best GFLOPs: 819.2528
2024-04-29 09:51:13 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #660: GFLOPs: 623.7048. Time: 370.7863 us. Best GFLOPs: 819.2528
2024-04-29 09:51:13 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #661: GFLOPs: 632.0844. Time: 365.8708 us. Best GFLOPs: 819.2528
2024-04-29 09:51:13 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #662: GFLOPs: 672.2890. Time: 343.9907 us. Best GFLOPs: 819.2528
2024-04-29 09:51:13 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #663: GFLOPs: 622.6903. Time: 371.3904 us. Best GFLOPs: 819.2528
2024-04-29 09:51:13 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #664: GFLOPs: 324.7364. Time: 712.1505 us. Best GFLOPs: 819.2528
2024-04-29 09:51:13 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #665: GFLOPs: 633.5102. Time: 365.0473 us. Best GFLOPs: 819.2528
2024-04-29 09:51:13 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #666: GFLOPs: 622.4523. Time: 371.5324 us. Best GFLOPs: 819.2528
2024-04-29 09:51:13 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #667: GFLOPs: 623.6419. Time: 370.8237 us. Best GFLOPs: 819.2528
2024-04-29 09:51:13 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #668: GFLOPs: 758.0023. Time: 305.0930 us. Best GFLOPs: 819.2528
2024-04-29 09:51:13 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #669: GFLOPs: 637.8535. Time: 362.5616 us. Best GFLOPs: 819.2528
2024-04-29 09:51:13 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #670: GFLOPs: 629.6808. Time: 367.2673 us. Best GFLOPs: 819.2528
2024-04-29 09:51:13 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #671: GFLOPs: 706.4506. Time: 327.3565 us. Best GFLOPs: 819.2528
2024-04-29 09:51:13 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #672: GFLOPs: 638.4172. Time: 362.2414 us. Best GFLOPs: 819.2528
2024-04-29 09:51:13 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #673: GFLOPs: 649.5060. Time: 356.0571 us. Best GFLOPs: 819.2528
2024-04-29 09:51:13 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #674: GFLOPs: 489.4926. Time: 472.4508 us. Best GFLOPs: 819.2528
2024-04-29 09:51:13 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #675: GFLOPs: 351.6071. Time: 657.7261 us. Best GFLOPs: 819.2528
2024-04-29 09:51:13 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #676: GFLOPs: 582.3469. Time: 397.1193 us. Best GFLOPs: 819.2528
2024-04-29 09:51:13 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #677: GFLOPs: 594.1731. Time: 389.2152 us. Best GFLOPs: 819.2528
2024-04-29 09:51:13 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #678: GFLOPs: 555.3056. Time: 416.4575 us. Best GFLOPs: 819.2528
2024-04-29 09:51:13 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #679: GFLOPs: 550.8134. Time: 419.8539 us. Best GFLOPs: 819.2528
2024-04-29 09:51:13 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #680: GFLOPs: 577.8850. Time: 400.1855 us. Best GFLOPs: 819.2528
2024-04-29 09:51:13 [INFO] [task_scheduler.cc:121] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #681: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(7), T.int64(7), T.int64(512)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(3), T.int64(3), T.int64(512), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(9), T.int64(9), T.int64(512)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(7), T.int64(7), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_fused_fused in T.parallel(T.int64(112), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(3), T.int64(9), T.int64(512)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(9), n_0_oc_chunk_0_oh_0_fused_fused % T.int64(7) + ax2)
                    v_i3, v_i4 = T.axis.remap("SS", [ax3, ax4])
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(8) and T.int64(1) <= v_i3 and v_i3 < T.int64(8), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for ow_0, oc_block_0, n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_fused_fused // T.int64(7) + oc_chunk_1 + oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_fused_fused % T.int64(7) + oh_1 + oh_2_init + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(7), ow_0 * T.int64(7) + ow_1 * T.int64(7) + ow_2_init * T.int64(7) + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_0 * T.int64(32) + oc_block_1 * T.int64(32) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(64), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(32), T.int64(8), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_fused_fused // T.int64(7) + oc_chunk_1 + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_fused_fused % T.int64(7) + oh_1 + oh_2 + oh_3)
                        v_ow = T.axis.spatial(T.int64(7), ow_0 * T.int64(7) + ow_1 * T.int64(7) + ow_2 * T.int64(7) + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_0 * T.int64(32) + oc_block_1 * T.int64(32) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(8) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(512), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                    for ax4_fused in T.vectorized(T.int64(32)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_fused_fused // T.int64(7) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(7), n_0_oc_chunk_0_oh_0_fused_fused % T.int64(7) + ax2)
                            v_ax3, v_ax4 = T.axis.remap("SS", [ax3, ax4_fused])
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[16, 1, 1, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[7, 1, 1, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 1, 7])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 32, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[64, 8])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=2)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78 = sch.get_loops(block=b68)
l79 = sch.fuse(l71, l72, l73, preserve_unit_iters=True)
sch.parallel(loop=l79)
l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l80, preserve_unit_iters=True)
sch.parallel(loop=l104)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117 = sch.get_loops(block=b70)
l118 = sch.fuse(l117, preserve_unit_iters=True)
sch.vectorize(loop=l118)
b119 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141, l142, l143 = sch.get_loops(block=b119)
b144 = sch.decompose_reduction(block=b119, loop=l128)
2024-04-29 09:51:13 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #682: GFLOPs: 561.1544. Time: 412.1168 us. Best GFLOPs: 819.2528
2024-04-29 09:51:13 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #683: GFLOPs: 553.6301. Time: 417.7179 us. Best GFLOPs: 819.2528
2024-04-29 09:51:13 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #684: GFLOPs: 542.5637. Time: 426.2378 us. Best GFLOPs: 819.2528
2024-04-29 09:51:13 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #685: GFLOPs: 397.7276. Time: 581.4562 us. Best GFLOPs: 819.2528
2024-04-29 09:51:13 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #686: GFLOPs: 570.4886. Time: 405.3739 us. Best GFLOPs: 819.2528
2024-04-29 09:51:13 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #687: GFLOPs: 469.9072. Time: 492.1423 us. Best GFLOPs: 819.2528
2024-04-29 09:51:13 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #688: GFLOPs: 388.6397. Time: 595.0529 us. Best GFLOPs: 819.2528
2024-04-29 09:51:13 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #689: GFLOPs: 550.5519. Time: 420.0533 us. Best GFLOPs: 819.2528
2024-04-29 09:51:13 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #690: GFLOPs: 495.1190. Time: 467.0820 us. Best GFLOPs: 819.2528
2024-04-29 09:51:13 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #691: GFLOPs: 565.0977. Time: 409.2411 us. Best GFLOPs: 819.2528
2024-04-29 09:51:13 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #692: GFLOPs: 574.8850. Time: 402.2738 us. Best GFLOPs: 819.2528
2024-04-29 09:51:13 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #693: GFLOPs: 580.6019. Time: 398.3128 us. Best GFLOPs: 819.2528
2024-04-29 09:51:13 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #694: GFLOPs: 616.2273. Time: 375.2855 us. Best GFLOPs: 819.2528
2024-04-29 09:51:13 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #695: GFLOPs: 55.5714. Time: 4161.5170 us. Best GFLOPs: 819.2528
2024-04-29 09:51:13 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #696: GFLOPs: 53.4536. Time: 4326.3875 us. Best GFLOPs: 819.2528
2024-04-29 09:51:13 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #697: GFLOPs: 353.9882. Time: 653.3020 us. Best GFLOPs: 819.2528
2024-04-29 09:51:13 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #698: GFLOPs: 471.4216. Time: 490.5613 us. Best GFLOPs: 819.2528
2024-04-29 09:51:13 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #699: GFLOPs: 586.3975. Time: 394.3762 us. Best GFLOPs: 819.2528
2024-04-29 09:51:13 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #700: GFLOPs: 63.6380. Time: 3634.0130 us. Best GFLOPs: 819.2528
2024-04-29 09:51:13 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #701: GFLOPs: 63.3699. Time: 3649.3833 us. Best GFLOPs: 819.2528
2024-04-29 09:51:13 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #702: GFLOPs: 20.8409. Time: 11096.4896 us. Best GFLOPs: 819.2528
2024-04-29 09:51:13 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #703: GFLOPs: 32.4178. Time: 7133.7651 us. Best GFLOPs: 819.2528
2024-04-29 09:51:13 [INFO] [task_scheduler.cc:131] [Task #24: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7] Trial #704: GFLOPs: 46.0596. Time: 5020.9152 us. Best GFLOPs: 819.2528
