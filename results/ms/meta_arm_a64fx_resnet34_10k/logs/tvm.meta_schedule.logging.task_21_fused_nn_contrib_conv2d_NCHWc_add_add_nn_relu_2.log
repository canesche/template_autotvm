2024-04-29 03:20:40 [INFO] [task_scheduler.cc:160] Initializing Task #21: "fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2"
2024-04-29 03:20:40 [INFO] [task_scheduler.cc:35] 
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(14), T.int64(14), T.int64(128)), "float32"), p1: T.Buffer((T.int64(16), T.int64(2), T.int64(3), T.int64(3), T.int64(128), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(16)), "float32"), p3: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(16), T.int64(16), T.int64(128)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)))
        T_add = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)))
        T_add_1 = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)))
        for i0, i1, i2, i3, i4 in T.grid(T.int64(1), T.int64(2), T.int64(16), T.int64(16), T.int64(128)):
            with T.block("data_pad"):
                v_i0, v_i1, v_i2, v_i3, v_i4 = T.axis.remap("SSSSS", [i0, i1, i2, i3, i4])
                T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(15) and T.int64(1) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
        for n, oc_chunk, oh, ow, oc_block, ic, kh, kw in T.grid(T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16), T.int64(256), T.int64(3), T.int64(3)):
            with T.block("conv2d_NCHWc"):
                v_n, v_oc_chunk, v_oh, v_ow, v_oc_block, v_ic, v_kh, v_kw = T.axis.remap("SSSSSRRR", [n, oc_chunk, oh, ow, oc_block, ic, kh, kw])
                T.reads(data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                with T.init():
                    conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
        for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                T.writes(T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4]
        for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)):
            with T.block("T_add_1"):
                v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                T.reads(T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T.writes(T_add_1[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T_add_1[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4]
        for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)):
            with T.block("T_relu"):
                v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                T.reads(T_add_1[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(T_add_1[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
2024-04-29 03:20:40 [INFO] [task_scheduler.cc:164] Total 3 design space(s) generated
2024-04-29 03:20:40 [INFO] [task_scheduler.cc:170] Design space #0:
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(14), T.int64(14), T.int64(128)), "float32"), p1: T.Buffer((T.int64(16), T.int64(2), T.int64(3), T.int64(3), T.int64(128), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(16)), "float32"), p3: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel": 768, "meta_schedule.unroll_explicit": 64, "meta_schedule.vectorize": 64})
            data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(16), T.int64(16), T.int64(128)))
            conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)))
            for i0, i1, i2, i3, i4 in T.grid(T.int64(1), T.int64(2), T.int64(16), T.int64(16), T.int64(128)):
                with T.block("data_pad"):
                    v_i0, v_i1, v_i2, v_i3, v_i4 = T.axis.remap("SSSSS", [i0, i1, i2, i3, i4])
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(15) and T.int64(1) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for n_0, oc_chunk_0, oh_0, ow_0, oc_block_0, n_1, oc_chunk_1, oh_1, ow_1, oc_block_1, ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(1), T.int64(4), T.int64(2), T.int64(7), T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(128), T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(7), T.int64(2), T.int64(1)):
                with T.block("conv2d_NCHWc"):
                    v_n = T.axis.spatial(T.int64(1), n_0 + n_1 + n_2 + n_3)
                    v_oc_chunk = T.axis.spatial(T.int64(16), oc_chunk_0 * T.int64(4) + oc_chunk_1 * T.int64(4) + oc_chunk_2 * T.int64(4) + oc_chunk_3)
                    v_oh = T.axis.spatial(T.int64(14), oh_0 * T.int64(7) + oh_1 * T.int64(7) + oh_2 * T.int64(7) + oh_3)
                    v_ow = T.axis.spatial(T.int64(14), ow_0 * T.int64(2) + ow_1 * T.int64(2) + ow_2 * T.int64(2) + ow_3)
                    v_oc_block = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(4) + oc_block_1 * T.int64(4) + oc_block_2 + oc_block_3)
                    v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(2) + ic_1)
                    v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                    v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                    T.reads(data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                    T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                    T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                    with T.init():
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                    conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)):
                with T.block("T_relu"):
                    v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                    T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[4, 1, 1, 4])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[2, 1, 1, 7])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[7, 1, 1, 2])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[4, 1, 4, 1])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[128, 2])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[3, 1])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=-1)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
2024-04-29 03:20:40 [INFO] [task_scheduler.cc:170] Design space #1:
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(14), T.int64(14), T.int64(128)), "float32"), p1: T.Buffer((T.int64(16), T.int64(2), T.int64(3), T.int64(3), T.int64(128), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(16)), "float32"), p3: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel": 768, "meta_schedule.unroll_explicit": 16, "meta_schedule.vectorize": 64})
            data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(16), T.int64(16), T.int64(128)))
            conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)))
            for n_0, oc_chunk_0, oh_0, ow_0, oc_block_0, n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(4), T.int64(2), T.int64(7), T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                for ic_0 in range(T.int64(128)):
                    for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(9), T.int64(4), T.int64(2)):
                        with T.block("data_pad"):
                            v_i0 = T.axis.spatial(T.int64(1), ax0)
                            v_i1 = T.axis.spatial(T.int64(2), ic_0 // T.int64(64) + ax1)
                            v_i2 = T.axis.spatial(T.int64(16), oh_0 * T.int64(7) + ax2)
                            v_i3 = T.axis.spatial(T.int64(16), ow_0 * T.int64(2) + ax3)
                            v_i4 = T.axis.spatial(T.int64(128), ic_0 % T.int64(64) * T.int64(2) + ax4)
                            T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                            T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                            data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(15) and T.int64(1) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                    for kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(7), T.int64(2), T.int64(1)):
                        with T.block("conv2d_NCHWc"):
                            v_n = T.axis.spatial(T.int64(1), n_0 + n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(16), oc_chunk_0 * T.int64(4) + oc_chunk_1 * T.int64(4) + oc_chunk_2 * T.int64(4) + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(14), oh_0 * T.int64(7) + oh_1 * T.int64(7) + oh_2 * T.int64(7) + oh_3)
                            v_ow = T.axis.spatial(T.int64(14), ow_0 * T.int64(2) + ow_1 * T.int64(2) + ow_2 * T.int64(2) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(4) + oc_block_1 * T.int64(4) + oc_block_2 + oc_block_3)
                            v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(2) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            with T.init():
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
                for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(4), T.int64(7), T.int64(2), T.int64(4)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(16), oc_chunk_0 * T.int64(4) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(14), oh_0 * T.int64(7) + ax2)
                        v_ax3 = T.axis.spatial(T.int64(14), ow_0 * T.int64(2) + ax3)
                        v_ax4 = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(4) + ax4)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[4, 1, 1, 4])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[2, 1, 1, 7])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[7, 1, 1, 2])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[4, 1, 4, 1])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[128, 2])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[3, 1])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l50, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=10)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
2024-04-29 03:20:40 [INFO] [task_scheduler.cc:170] Design space #2:
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(14), T.int64(14), T.int64(128)), "float32"), p1: T.Buffer((T.int64(16), T.int64(2), T.int64(3), T.int64(3), T.int64(128), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(16)), "float32"), p3: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel": 768, "meta_schedule.unroll_explicit": 0, "meta_schedule.vectorize": 64})
            data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(16), T.int64(16), T.int64(128)))
            conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)))
            for n_0, oc_chunk_0, oh_0 in T.grid(T.int64(1), T.int64(4), T.int64(2)):
                for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(2), T.int64(9), T.int64(16), T.int64(128)):
                    with T.block("data_pad"):
                        v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                        v_i2 = T.axis.spatial(T.int64(16), oh_0 * T.int64(7) + ax2)
                        v_i3, v_i4 = T.axis.remap("SS", [ax3, ax4])
                        T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                        T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                        data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(15) and T.int64(1) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                for ow_0, oc_block_0 in T.grid(T.int64(7), T.int64(4)):
                    for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1, ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(128), T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(7), T.int64(2), T.int64(1)):
                        with T.block("conv2d_NCHWc"):
                            v_n = T.axis.spatial(T.int64(1), n_0 + n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(16), oc_chunk_0 * T.int64(4) + oc_chunk_1 * T.int64(4) + oc_chunk_2 * T.int64(4) + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(14), oh_0 * T.int64(7) + oh_1 * T.int64(7) + oh_2 * T.int64(7) + oh_3)
                            v_ow = T.axis.spatial(T.int64(14), ow_0 * T.int64(2) + ow_1 * T.int64(2) + ow_2 * T.int64(2) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(4) + oc_block_1 * T.int64(4) + oc_block_2 + oc_block_3)
                            v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(2) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            with T.init():
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
                    for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(4), T.int64(7), T.int64(2), T.int64(4)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(16), oc_chunk_0 * T.int64(4) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(14), oh_0 * T.int64(7) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(14), ow_0 * T.int64(2) + ax3)
                            v_ax4 = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(4) + ax4)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[4, 1, 1, 4])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[2, 1, 1, 7])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[7, 1, 1, 2])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[4, 1, 4, 1])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[128, 2])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[3, 1])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=2)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
2024-04-29 03:43:55 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 03:43:55 [INFO] [evolutionary_search.cc:715] Picked top 0 candidate(s) from database
2024-04-29 03:44:01 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3639cb8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x419b828)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x312c9f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x425e1d8)]: 0 failure(s)
2024-04-29 03:44:01 [INFO] [evolutionary_search.cc:723] Sampled 512 candidate(s)
2024-04-29 03:44:07 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3639cb8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x419b828)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x312c9f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x425e1d8)]: 0 failure(s)
2024-04-29 03:44:14 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3639cb8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x419b828)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x312c9f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x425e1d8)]: 0 failure(s)
2024-04-29 03:44:20 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3639cb8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x419b828)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x312c9f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x425e1d8)]: 0 failure(s)
2024-04-29 03:44:27 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3639cb8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x419b828)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x312c9f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x425e1d8)]: 0 failure(s)
2024-04-29 03:44:28 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9999  0.9999  0.9995  0.9993  0.9988  0.9984  0.9980  0.9962  0.9954  0.9944  0.9944  0.9943  0.9938  0.9931  0.9921  0.9919
[17 : 32]:	0.9916  0.9913  0.9906  0.9894  0.9891  0.9888  0.9876  0.9875  0.9872  0.9861  0.9852  0.9849  0.9844  0.9841  0.9837  0.9830
[33 : 48]:	0.9830  0.9827  0.9819  0.9817  0.9813  0.9806  0.9804  0.9801  0.9801  0.9800  0.9792  0.9790  0.9784  0.9782  0.9779  0.9766
[49 : 64]:	0.9763  0.9757  0.9754  0.9750  0.9738  0.9737  0.9734  0.9729  0.9727  0.9720  0.9712  0.9711  0.9708  0.9701  0.9698  0.9695
2024-04-29 03:44:28 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 03:44:28 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 03:57:34 [INFO] [task_scheduler.cc:121] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(14), T.int64(14), T.int64(128)), "float32"), p1: T.Buffer((T.int64(16), T.int64(2), T.int64(3), T.int64(3), T.int64(128), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(16)), "float32"), p3: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(16), T.int64(16), T.int64(128)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused in T.parallel(T.int64(16), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(2), T.int64(16), T.int64(9), T.int64(128)):
                with T.block("data_pad"):
                    v_i0, v_i1, v_i2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                    v_i3 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(4) // T.int64(2) * T.int64(7) + ax3)
                    v_i4 = T.axis.spatial(T.int64(128), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(15) and T.int64(1) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(4)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(2), T.int64(7)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(2)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(4) * T.int64(4) + oc_chunk_1 * T.int64(4) + oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(14), oh_1 * T.int64(2) + oh_2_init * T.int64(2) + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(4) // T.int64(2) * T.int64(7) + ow_1 * T.int64(7) + ow_2_init * T.int64(7) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(2) * T.int64(8) + oc_block_1 * T.int64(2) + oc_block_2_init * T.int64(2) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(64), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(3), T.int64(3), T.int64(1), T.int64(2), T.int64(2), T.int64(7)):
                    for oc_block_3_fused in T.vectorized(T.int64(2)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(4) * T.int64(4) + oc_chunk_1 * T.int64(4) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(14), oh_1 * T.int64(2) + oh_2 * T.int64(2) + oh_3)
                            v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(4) // T.int64(2) * T.int64(7) + ow_1 * T.int64(7) + ow_2 * T.int64(7) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(2) * T.int64(8) + oc_block_1 * T.int64(2) + oc_block_2 * T.int64(2) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(4) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(4), T.int64(14), T.int64(7)):
                for ax4_fused in T.vectorized(T.int64(8)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(4) * T.int64(4) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(14), ax2)
                        v_ax3 = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(4) // T.int64(2) * T.int64(7) + ax3)
                        v_ax4 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(2) * T.int64(8) + ax4_fused)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[4, 1, 2, 2])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 7, 1, 2])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[2, 1, 1, 7])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[2, 4, 1, 2])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[64, 4])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[1, 3])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=4)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79, l80, l81 = sch.get_loops(block=b69)
l82 = sch.fuse(l72, l73, l74, l75, l76, preserve_unit_iters=True)
sch.parallel(loop=l82)
l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b70)
l105 = sch.fuse(l83, preserve_unit_iters=True)
sch.parallel(loop=l105)
l106 = sch.fuse(l104, preserve_unit_iters=True)
sch.vectorize(loop=l106)
sch.annotate(block_or_loop=l105, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l105, ann_key="pragma_unroll_explicit", ann_val=1)
l107, l108, l109, l110, l111, l112 = sch.get_loops(block=b71)
l113 = sch.fuse(l112, preserve_unit_iters=True)
sch.vectorize(loop=l113)
b114 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136 = sch.get_loops(block=b114)
b137 = sch.decompose_reduction(block=b114, loop=l121)
2024-04-29 03:57:34 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #2: GFLOPs: 52.5545. Time: 4402.3136 us. Best GFLOPs: 52.5545
2024-04-29 03:57:34 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #3: GFLOPs: 44.7200. Time: 5173.5618 us. Best GFLOPs: 52.5545
2024-04-29 03:57:34 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #4: GFLOPs: 19.0151. Time: 12167.2813 us. Best GFLOPs: 52.5545
2024-04-29 03:57:34 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #5: GFLOPs: 21.4761. Time: 10772.9952 us. Best GFLOPs: 52.5545
2024-04-29 03:57:34 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #6: GFLOPs: 22.5813. Time: 10245.7331 us. Best GFLOPs: 52.5545
2024-04-29 03:57:34 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #7: GFLOPs: 26.0584. Time: 8878.5943 us. Best GFLOPs: 52.5545
2024-04-29 03:57:34 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #8: GFLOPs: 104.7121. Time: 2209.5017 us. Best GFLOPs: 104.7121
2024-04-29 03:57:34 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #9: GFLOPs: 12.5396. Time: 18450.5120 us. Best GFLOPs: 104.7121
2024-04-29 03:57:34 [INFO] [task_scheduler.cc:121] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #10: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(14), T.int64(14), T.int64(128)), "float32"), p1: T.Buffer((T.int64(16), T.int64(2), T.int64(3), T.int64(3), T.int64(128), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(16)), "float32"), p3: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(16), T.int64(16), T.int64(128)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused in T.parallel(T.int64(28), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1 in T.grid(T.int64(1), T.int64(16)):
                for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(2), T.int64(4), T.int64(9), T.int64(128)):
                    with T.block("data_pad"):
                        v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                        v_i2 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(4) * T.int64(2) + ax2)
                        v_i3 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(4) // T.int64(2) * T.int64(7) + ax3)
                        v_i4 = T.axis.spatial(T.int64(128), ax4)
                        T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                        T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                        data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(15) and T.int64(1) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                for oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(7), T.int64(1)):
                    for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(16), oc_chunk_1 + oc_chunk_2_init + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(4) * T.int64(2) + oh_1 * T.int64(2) + oh_2_init * T.int64(2) + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(4) // T.int64(2) * T.int64(7) + ow_1 + ow_2_init + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(2) * T.int64(8) + oc_block_1 * T.int64(8) + oc_block_2_init + oc_block_3_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                    for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(8), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(8), T.int64(32), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(16), oc_chunk_1 + oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(4) * T.int64(2) + oh_1 * T.int64(2) + oh_2 * T.int64(2) + oh_3)
                            v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(4) // T.int64(2) * T.int64(7) + ow_1 + ow_2 + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(2) * T.int64(8) + oc_block_1 * T.int64(8) + oc_block_2 + oc_block_3)
                            v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(32) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(16), T.int64(2), T.int64(7)):
                for ax4_fused in T.vectorized(T.int64(8)):
                    with T.block("T_relu"):
                        v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                        v_ax2 = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(4) * T.int64(2) + ax2)
                        v_ax3 = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(4) // T.int64(2) * T.int64(7) + ax3)
                        v_ax4 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(2) * T.int64(8) + ax4_fused)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 16, 1, 1])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[7, 1, 1, 2])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[2, 7, 1, 1])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[2, 1, 8, 1])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[8, 32])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[1, 3])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=6)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83 = sch.get_loops(block=b69)
l84 = sch.fuse(l72, l73, l74, l75, l76, preserve_unit_iters=True)
sch.parallel(loop=l84)
l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106 = sch.get_loops(block=b70)
l107 = sch.fuse(l85, preserve_unit_iters=True)
sch.parallel(loop=l107)
sch.annotate(block_or_loop=l107, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l107, ann_key="pragma_unroll_explicit", ann_val=1)
l108, l109, l110, l111, l112, l113 = sch.get_loops(block=b71)
l114 = sch.fuse(l113, preserve_unit_iters=True)
sch.vectorize(loop=l114)
b115 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137 = sch.get_loops(block=b115)
b138 = sch.decompose_reduction(block=b115, loop=l122)
2024-04-29 03:57:34 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #11: GFLOPs: 8.2055. Time: 28196.0517 us. Best GFLOPs: 104.7121
2024-04-29 03:57:34 [INFO] [task_scheduler.cc:121] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #12: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(14), T.int64(14), T.int64(128)), "float32"), p1: T.Buffer((T.int64(16), T.int64(2), T.int64(3), T.int64(3), T.int64(128), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(16)), "float32"), p3: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(16), T.int64(16), T.int64(128)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)))
        for n_0 in T.serial(T.int64(1), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for oc_chunk_0, oh_0, ow_0, oc_block_0 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(14), T.int64(1)):
                    for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(2), T.int64(2), T.int64(1), T.int64(4), T.int64(1), T.int64(4), T.int64(7), T.int64(1)):
                        for oc_block_3_fused_init in T.vectorized(T.int64(4)):
                            with T.block("conv2d_NCHWc_init"):
                                v_n = T.axis.spatial(T.int64(1), n_0 + n_1 + n_2_init + n_3_init)
                                v_oc_chunk = T.axis.spatial(T.int64(16), oc_chunk_0 * T.int64(16) + oc_chunk_1 * T.int64(8) + oc_chunk_2_init * T.int64(4) + oc_chunk_3_init)
                                v_oh = T.axis.spatial(T.int64(14), oh_0 * T.int64(14) + oh_1 * T.int64(14) + oh_2_init * T.int64(7) + oh_3_init)
                                v_ow = T.axis.spatial(T.int64(14), ow_0 * T.int64(14) + ow_1 + ow_2_init + ow_3_init)
                                v_oc_block = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2_init * T.int64(4) + oc_block_3_fused_init)
                                T.reads()
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                    for ic_0 in range(T.int64(4)):
                        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(16), T.int64(3)):
                            for ax4_fused in T.vectorized(T.int64(64)):
                                with T.block("data_pad"):
                                    v_i0 = T.axis.spatial(T.int64(1), ax0)
                                    v_i1 = T.axis.spatial(T.int64(2), ic_0 // T.int64(2) + ax1)
                                    v_i2 = T.axis.spatial(T.int64(16), ax2)
                                    v_i3 = T.axis.spatial(T.int64(16), ow_1 + ax3)
                                    v_i4 = T.axis.spatial(T.int64(128), ic_0 % T.int64(2) * T.int64(64) + ax4_fused)
                                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(15) and T.int64(1) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                        for kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(3), T.int64(1), T.int64(1), T.int64(2), T.int64(2), T.int64(1), T.int64(4), T.int64(64), T.int64(1), T.int64(3), T.int64(1), T.int64(4), T.int64(7), T.int64(1)):
                            for oc_block_3_fused in T.vectorized(T.int64(4)):
                                with T.block("conv2d_NCHWc_update"):
                                    v_n = T.axis.spatial(T.int64(1), n_0 + n_1 + n_2 + n_3)
                                    v_oc_chunk = T.axis.spatial(T.int64(16), oc_chunk_0 * T.int64(16) + oc_chunk_1 * T.int64(8) + oc_chunk_2 * T.int64(4) + oc_chunk_3)
                                    v_oh = T.axis.spatial(T.int64(14), oh_0 * T.int64(14) + oh_1 * T.int64(14) + oh_2 * T.int64(7) + oh_3)
                                    v_ow = T.axis.spatial(T.int64(14), ow_0 * T.int64(14) + ow_1 + ow_2 + ow_3)
                                    v_oc_block = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2 * T.int64(4) + oc_block_3_fused)
                                    v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(64) + ic_1)
                                    v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                                    v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                                    T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                                    T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                    T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                    conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(16), T.int64(14), T.int64(14)):
                    for ax4_fused in T.vectorized(T.int64(16)):
                        with T.block("T_relu"):
                            v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4_fused])
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 2, 2, 4])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 2, 7])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 14, 1, 1])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[1, 1, 4, 4])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[4, 64])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[1, 3])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=10)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87 = sch.get_loops(block=b69)
l88 = sch.fuse(l87, preserve_unit_iters=True)
sch.vectorize(loop=l88)
l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107, l108, l109, l110, l111, l112, l113, l114 = sch.get_loops(block=b70)
l115 = sch.fuse(l114, preserve_unit_iters=True)
sch.vectorize(loop=l115)
sch.annotate(block_or_loop=l89, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l89, ann_key="pragma_unroll_explicit", ann_val=1)
l116, l117, l118, l119, l120, l121, l122, l123, l124, l125 = sch.get_loops(block=b71)
l126 = sch.fuse(l125, preserve_unit_iters=True)
sch.vectorize(loop=l126)
b127 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141, l142, l143, l144, l145, l146, l147, l148, l149, l150, l151, l152, l153 = sch.get_loops(block=b127)
b154 = sch.decompose_reduction(block=b127, loop=l138)
2024-04-29 03:57:34 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #13: GFLOPs: 1.1870. Time: 194909.3547 us. Best GFLOPs: 104.7121
2024-04-29 03:57:34 [INFO] [task_scheduler.cc:121] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #14: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(14), T.int64(14), T.int64(128)), "float32"), p1: T.Buffer((T.int64(16), T.int64(2), T.int64(3), T.int64(3), T.int64(128), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(16)), "float32"), p3: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(16), T.int64(16), T.int64(128)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused in T.parallel(T.int64(7), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1 in T.grid(T.int64(1), T.int64(4)):
                for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(2), T.int64(16), T.int64(4), T.int64(128)):
                    with T.block("data_pad"):
                        v_i0, v_i1, v_i2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                        v_i3 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused * T.int64(2) + ax3)
                        v_i4 = T.axis.spatial(T.int64(128), ax4)
                        T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                        T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                        data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(15) and T.int64(1) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                for oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(2)):
                    for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(14), T.int64(2), T.int64(1)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(16), oc_chunk_1 * T.int64(4) + oc_chunk_2_init + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(14), oh_1 * T.int64(14) + oh_2_init * T.int64(14) + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused * T.int64(2) + ow_1 * T.int64(2) + ow_2_init * T.int64(2) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_1 * T.int64(8) + oc_block_2_init + oc_block_3_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                    for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(64), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(8), T.int64(4), T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(14), T.int64(2), T.int64(1)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(16), oc_chunk_1 * T.int64(4) + oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(14), oh_1 * T.int64(14) + oh_2 * T.int64(14) + oh_3)
                            v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused * T.int64(2) + ow_1 * T.int64(2) + ow_2 * T.int64(2) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_1 * T.int64(8) + oc_block_2 + oc_block_3)
                            v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(4) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
            for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(16), T.int64(14)):
                for ax3_ax4_fused in T.vectorized(T.int64(32)):
                    with T.block("T_relu"):
                        v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                        v_ax3 = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused * T.int64(2) + ax3_ax4_fused // T.int64(16))
                        v_ax4 = T.axis.spatial(T.int64(16), ax3_ax4_fused % T.int64(16))
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 4, 4, 1])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 1, 14])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[7, 1, 1, 2])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[1, 2, 8, 1])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[64, 4])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[1, 3])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=6)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83 = sch.get_loops(block=b69)
l84 = sch.fuse(l72, l73, l74, l75, l76, preserve_unit_iters=True)
sch.parallel(loop=l84)
l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106 = sch.get_loops(block=b70)
l107 = sch.fuse(l85, preserve_unit_iters=True)
sch.parallel(loop=l107)
sch.annotate(block_or_loop=l107, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l107, ann_key="pragma_unroll_explicit", ann_val=1)
l108, l109, l110, l111, l112, l113 = sch.get_loops(block=b71)
l114 = sch.fuse(l112, l113, preserve_unit_iters=True)
sch.vectorize(loop=l114)
b115 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137 = sch.get_loops(block=b115)
b138 = sch.decompose_reduction(block=b115, loop=l122)
2024-04-29 03:57:34 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #15: GFLOPs: 44.7111. Time: 5174.5930 us. Best GFLOPs: 104.7121
2024-04-29 03:57:34 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #16: GFLOPs: 5.7232. Time: 40425.3173 us. Best GFLOPs: 104.7121
2024-04-29 03:57:34 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #17: GFLOPs: 37.8787. Time: 6107.9615 us. Best GFLOPs: 104.7121
2024-04-29 03:57:34 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #18: GFLOPs: 9.6427. Time: 23993.3422 us. Best GFLOPs: 104.7121
2024-04-29 03:57:34 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #19: GFLOPs: 3.2648. Time: 70865.8613 us. Best GFLOPs: 104.7121
2024-04-29 03:57:34 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #20: GFLOPs: 15.9767. Time: 14481.2074 us. Best GFLOPs: 104.7121
2024-04-29 03:57:34 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #21: GFLOPs: 47.3092. Time: 4890.4098 us. Best GFLOPs: 104.7121
2024-04-29 03:57:34 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #22: GFLOPs: 2.6435. Time: 87522.3093 us. Best GFLOPs: 104.7121
2024-04-29 03:57:34 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #23: GFLOPs: 4.9964. Time: 46305.2213 us. Best GFLOPs: 104.7121
2024-04-29 03:57:34 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #24: GFLOPs: 54.0518. Time: 4280.3657 us. Best GFLOPs: 104.7121
2024-04-29 03:57:34 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #25: GFLOPs: 44.9234. Time: 5150.1390 us. Best GFLOPs: 104.7121
2024-04-29 03:57:34 [INFO] [task_scheduler.cc:121] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #26: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(14), T.int64(14), T.int64(128)), "float32"), p1: T.Buffer((T.int64(16), T.int64(2), T.int64(3), T.int64(3), T.int64(128), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(16)), "float32"), p3: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(16), T.int64(16), T.int64(128)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused in T.parallel(T.int64(112), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(2), T.int64(14), T.int64(2), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1)):
                for oc_block_3_fused_init in T.vectorized(T.int64(4)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(56) // T.int64(14) * T.int64(4) + oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(14), oh_2_init + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(14) // T.int64(2) * T.int64(2) + ow_2_init + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(56) * T.int64(8) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(2) * T.int64(4) + oc_block_2_init * T.int64(4) + oc_block_3_fused_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
            for ic_0 in range(T.int64(16)):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(16), T.int64(4)):
                    for ax4_fused in T.vectorized(T.int64(16)):
                        with T.block("data_pad"):
                            v_i0 = T.axis.spatial(T.int64(1), ax0)
                            v_i1 = T.axis.spatial(T.int64(2), ic_0 // T.int64(8) + ax1)
                            v_i2 = T.axis.spatial(T.int64(16), ax2)
                            v_i3 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(14) // T.int64(2) * T.int64(2) + ax3)
                            v_i4 = T.axis.spatial(T.int64(128), ic_0 % T.int64(8) * T.int64(16) + ax4_fused)
                            T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                            T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                            data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(15) and T.int64(1) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                for kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(14), T.int64(2), T.int64(1), T.int64(16), T.int64(3), T.int64(3), T.int64(1), T.int64(2), T.int64(1), T.int64(1)):
                    for oc_block_3_fused in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(56) // T.int64(14) * T.int64(4) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(14), oh_2 + oh_3)
                            v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(14) // T.int64(2) * T.int64(2) + ow_2 + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(56) * T.int64(8) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(2) * T.int64(4) + oc_block_2 * T.int64(4) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(16) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(4), T.int64(14), T.int64(2)):
                for ax4_fused in T.vectorized(T.int64(4)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(56) // T.int64(14) * T.int64(4) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(14), ax2)
                        v_ax3 = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(14) // T.int64(2) * T.int64(2) + ax3)
                        v_ax4 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(56) * T.int64(8) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(2) * T.int64(4) + ax4_fused)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 4, 2, 2])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 14, 1])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 7, 2, 1])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[2, 2, 1, 4])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[16, 16])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[1, 3])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l50, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=10)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87 = sch.get_loops(block=b69)
l88 = sch.fuse(l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, preserve_unit_iters=True)
sch.parallel(loop=l88)
l89 = sch.fuse(l87, preserve_unit_iters=True)
sch.vectorize(loop=l89)
l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106 = sch.get_loops(block=b70)
l107 = sch.fuse(l90, preserve_unit_iters=True)
sch.parallel(loop=l107)
l108 = sch.fuse(l106, preserve_unit_iters=True)
sch.vectorize(loop=l108)
sch.annotate(block_or_loop=l107, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l107, ann_key="pragma_unroll_explicit", ann_val=1)
l109, l110, l111, l112, l113, l114 = sch.get_loops(block=b71)
l115 = sch.fuse(l114, preserve_unit_iters=True)
sch.vectorize(loop=l115)
b116 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133 = sch.get_loops(block=b116)
b134 = sch.decompose_reduction(block=b116, loop=l118)
2024-04-29 03:57:34 [INFO] [task_scheduler.cc:121] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #27: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(14), T.int64(14), T.int64(128)), "float32"), p1: T.Buffer((T.int64(16), T.int64(2), T.int64(3), T.int64(3), T.int64(128), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(16)), "float32"), p3: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(16), T.int64(16), T.int64(128)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused in T.parallel(T.int64(4), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(8), T.int64(1), T.int64(14), T.int64(8), T.int64(1), T.int64(1), T.int64(14), T.int64(1), T.int64(1)):
                with T.block("conv2d_NCHWc_init"):
                    v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                    v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(2) * T.int64(8) + oc_chunk_2_init + oc_chunk_3_init)
                    v_oh = T.axis.spatial(T.int64(14), oh_2_init * T.int64(14) + oh_3_init)
                    v_ow = T.axis.spatial(T.int64(14), ow_2_init + ow_3_init)
                    v_oc_block = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(2) * T.int64(8) + oc_block_2_init + oc_block_3_init)
                    T.reads()
                    T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                    T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                    conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
            for ic_0, kh_0 in T.grid(T.int64(16), T.int64(3)):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(14), T.int64(16)):
                    for ax4_fused in T.vectorized(T.int64(16)):
                        with T.block("data_pad"):
                            v_i0 = T.axis.spatial(T.int64(1), ax0)
                            v_i1 = T.axis.spatial(T.int64(2), ic_0 // T.int64(8) + ax1)
                            v_i2 = T.axis.spatial(T.int64(16), kh_0 + ax2)
                            v_i3 = T.axis.spatial(T.int64(16), ax3)
                            v_i4 = T.axis.spatial(T.int64(128), ic_0 % T.int64(8) * T.int64(16) + ax4_fused)
                            T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                            T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                            data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(15) and T.int64(1) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                for kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(3), T.int64(1), T.int64(8), T.int64(1), T.int64(14), T.int64(8), T.int64(16), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(14), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(2) * T.int64(8) + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(14), oh_2 * T.int64(14) + oh_3)
                        v_ow = T.axis.spatial(T.int64(14), ow_2 + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(2) * T.int64(8) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(16) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(8), T.int64(14), T.int64(14)):
                for ax4_fused in T.vectorized(T.int64(8)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(2) * T.int64(8) + ax1)
                        v_ax2, v_ax3 = T.axis.remap("SS", [ax2, ax3])
                        v_ax4 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(2) * T.int64(8) + ax4_fused)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 1, 8, 1])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 1, 14])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 14, 1])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[1, 2, 8, 1])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[16, 16])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[3, 1])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l50, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=11)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88 = sch.get_loops(block=b69)
l89 = sch.fuse(l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, preserve_unit_iters=True)
sch.parallel(loop=l89)
l90 = sch.fuse(l88, preserve_unit_iters=True)
sch.vectorize(loop=l90)
l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107 = sch.get_loops(block=b70)
l108 = sch.fuse(l91, preserve_unit_iters=True)
sch.parallel(loop=l108)
sch.annotate(block_or_loop=l108, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l108, ann_key="pragma_unroll_explicit", ann_val=1)
l109, l110, l111, l112, l113, l114 = sch.get_loops(block=b71)
l115 = sch.fuse(l114, preserve_unit_iters=True)
sch.vectorize(loop=l115)
b116 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133 = sch.get_loops(block=b116)
b134 = sch.decompose_reduction(block=b116, loop=l118)
2024-04-29 03:57:34 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #28: GFLOPs: 34.9308. Time: 6623.4195 us. Best GFLOPs: 104.7121
2024-04-29 03:57:34 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #29: GFLOPs: 8.9898. Time: 25735.8947 us. Best GFLOPs: 104.7121
2024-04-29 03:57:34 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #30: GFLOPs: 124.1510. Time: 1863.5489 us. Best GFLOPs: 124.1510
2024-04-29 03:57:34 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #31: GFLOPs: 33.5184. Time: 6902.5253 us. Best GFLOPs: 124.1510
2024-04-29 03:57:34 [INFO] [task_scheduler.cc:121] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #32: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(14), T.int64(14), T.int64(128)), "float32"), p1: T.Buffer((T.int64(16), T.int64(2), T.int64(3), T.int64(3), T.int64(128), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(16)), "float32"), p3: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(16), T.int64(16), T.int64(128)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused in T.parallel(T.int64(196), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(4), T.int64(2), T.int64(1), T.int64(4), T.int64(1), T.int64(2), T.int64(1), T.int64(1)):
                for oc_block_3_fused_init in T.vectorized(T.int64(4)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(98) * T.int64(8) + oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(98) // T.int64(14) * T.int64(2) + oh_2_init + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(14) + ow_2_init + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(16), oc_block_2_init * T.int64(4) + oc_block_3_fused_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
            for ic_0, kh_0 in T.grid(T.int64(8), T.int64(3)):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(2), T.int64(3)):
                    for ax4_fused in T.vectorized(T.int64(32)):
                        with T.block("data_pad"):
                            v_i0 = T.axis.spatial(T.int64(1), ax0)
                            v_i1 = T.axis.spatial(T.int64(2), ic_0 // T.int64(4) + ax1)
                            v_i2 = T.axis.spatial(T.int64(16), kh_0 + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(98) // T.int64(14) * T.int64(2) + ax2)
                            v_i3 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(14) + ax3)
                            v_i4 = T.axis.spatial(T.int64(128), ic_0 % T.int64(4) * T.int64(32) + ax4_fused)
                            T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                            T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                            data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(15) and T.int64(1) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                for kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(3), T.int64(1), T.int64(4), T.int64(2), T.int64(1), T.int64(4), T.int64(32), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1)):
                    for oc_block_3_fused in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(98) * T.int64(8) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(98) // T.int64(14) * T.int64(2) + oh_2 + oh_3)
                            v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(14) + ow_2 + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_2 * T.int64(4) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(32) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
            for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(8), T.int64(2)):
                for ax3_ax4_fused in T.vectorized(T.int64(16)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(98) * T.int64(8) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(98) // T.int64(14) * T.int64(2) + ax2)
                        v_ax3 = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(14))
                        v_ax4 = T.axis.spatial(T.int64(16), ax3_ax4_fused)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 1, 4, 2])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[7, 1, 2, 1])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[14, 1, 1, 1])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[1, 1, 4, 4])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[8, 32])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[3, 1])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l50, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=11)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88 = sch.get_loops(block=b69)
l89 = sch.fuse(l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, preserve_unit_iters=True)
sch.parallel(loop=l89)
l90 = sch.fuse(l88, preserve_unit_iters=True)
sch.vectorize(loop=l90)
l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107 = sch.get_loops(block=b70)
l108 = sch.fuse(l91, preserve_unit_iters=True)
sch.parallel(loop=l108)
l109 = sch.fuse(l107, preserve_unit_iters=True)
sch.vectorize(loop=l109)
sch.annotate(block_or_loop=l108, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l108, ann_key="pragma_unroll_explicit", ann_val=1)
l110, l111, l112, l113, l114, l115 = sch.get_loops(block=b71)
l116 = sch.fuse(l114, l115, preserve_unit_iters=True)
sch.vectorize(loop=l116)
b117 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134 = sch.get_loops(block=b117)
b135 = sch.decompose_reduction(block=b117, loop=l119)
2024-04-29 03:57:34 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #33: GFLOPs: 4.5845. Time: 50466.3190 us. Best GFLOPs: 124.1510
2024-04-29 03:57:34 [INFO] [task_scheduler.cc:121] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #34: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(14), T.int64(14), T.int64(128)), "float32"), p1: T.Buffer((T.int64(16), T.int64(2), T.int64(3), T.int64(3), T.int64(128), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(16)), "float32"), p3: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(16), T.int64(16), T.int64(128)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused in T.parallel(T.int64(32), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(8), T.int64(2), T.int64(14), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(16) * T.int64(8) + oc_chunk_1 * T.int64(8) + oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(14), oh_1 * T.int64(14) + oh_2_init * T.int64(7) + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(14), ow_1 * T.int64(14) + ow_2_init + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(16) + oc_block_1 + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0 in range(T.int64(8)):
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(16), T.int64(16)):
                        for ax4_fused in T.vectorized(T.int64(32)):
                            with T.block("data_pad"):
                                v_i0 = T.axis.spatial(T.int64(1), ax0)
                                v_i1 = T.axis.spatial(T.int64(2), ic_0 // T.int64(4) + ax1)
                                v_i2, v_i3 = T.axis.remap("SS", [ax2, ax3])
                                v_i4 = T.axis.spatial(T.int64(128), ic_0 % T.int64(4) * T.int64(32) + ax4_fused)
                                T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                                T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                                data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(15) and T.int64(1) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                    for kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(8), T.int64(2), T.int64(14), T.int64(1), T.int64(32), T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(1)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(16) * T.int64(8) + oc_chunk_1 * T.int64(8) + oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(14), oh_1 * T.int64(14) + oh_2 * T.int64(7) + oh_3)
                            v_ow = T.axis.spatial(T.int64(14), ow_1 * T.int64(14) + ow_2 + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(16) + oc_block_1 + oc_block_2 + oc_block_3)
                            v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(32) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(8), T.int64(14), T.int64(14), T.int64(1)):
                with T.block("T_relu"):
                    v_ax0 = T.axis.spatial(T.int64(1), ax0)
                    v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(16) * T.int64(8) + ax1)
                    v_ax2, v_ax3 = T.axis.remap("SS", [ax2, ax3])
                    v_ax4 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(16) + ax4)
                    T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 1, 8, 1])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 2, 7])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 14, 1])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[16, 1, 1, 1])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[8, 32])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[1, 3])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=10)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87 = sch.get_loops(block=b69)
l88 = sch.fuse(l72, l73, l74, l75, l76, preserve_unit_iters=True)
sch.parallel(loop=l88)
l89 = sch.fuse(l87, preserve_unit_iters=True)
sch.vectorize(loop=l89)
l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107, l108, l109, l110, l111 = sch.get_loops(block=b70)
l112 = sch.fuse(l90, preserve_unit_iters=True)
sch.parallel(loop=l112)
sch.annotate(block_or_loop=l112, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l112, ann_key="pragma_unroll_explicit", ann_val=1)
l113, l114, l115, l116, l117, l118 = sch.get_loops(block=b71)
b119 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141 = sch.get_loops(block=b119)
b142 = sch.decompose_reduction(block=b119, loop=l126)
2024-04-29 03:57:34 [INFO] [task_scheduler.cc:121] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #35: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(14), T.int64(14), T.int64(128)), "float32"), p1: T.Buffer((T.int64(16), T.int64(2), T.int64(3), T.int64(3), T.int64(128), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(16)), "float32"), p3: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(16), T.int64(16), T.int64(128)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused in T.parallel(T.int64(32), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(8), T.int64(7), T.int64(14), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(16) * T.int64(8) + oc_chunk_1 * T.int64(8) + oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(14), oh_1 * T.int64(7) + oh_2_init + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(14), ow_1 * T.int64(14) + ow_2_init + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(16) + oc_block_1 + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0 in range(T.int64(4)):
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(9), T.int64(16)):
                        for ax4_fused in T.vectorized(T.int64(64)):
                            with T.block("data_pad"):
                                v_i0 = T.axis.spatial(T.int64(1), ax0)
                                v_i1 = T.axis.spatial(T.int64(2), ic_0 // T.int64(2) + ax1)
                                v_i2 = T.axis.spatial(T.int64(16), oh_1 * T.int64(7) + ax2)
                                v_i3 = T.axis.spatial(T.int64(16), ax3)
                                v_i4 = T.axis.spatial(T.int64(128), ic_0 % T.int64(2) * T.int64(64) + ax4_fused)
                                T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                                T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                                data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(15) and T.int64(1) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                    for kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(8), T.int64(7), T.int64(14), T.int64(1), T.int64(64), T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(16) * T.int64(8) + oc_chunk_1 * T.int64(8) + oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(14), oh_1 * T.int64(7) + oh_2 + oh_3)
                            v_ow = T.axis.spatial(T.int64(14), ow_1 * T.int64(14) + ow_2 + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(16) + oc_block_1 + oc_block_2 + oc_block_3)
                            v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(64) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(8), T.int64(14), T.int64(14), T.int64(1)):
                with T.block("T_relu"):
                    v_ax0 = T.axis.spatial(T.int64(1), ax0)
                    v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(16) * T.int64(8) + ax1)
                    v_ax2, v_ax3 = T.axis.remap("SS", [ax2, ax3])
                    v_ax4 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(16) + ax4)
                    T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 1, 8, 1])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 2, 7, 1])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 14, 1])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[16, 1, 1, 1])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[4, 64])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[1, 3])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=10)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87 = sch.get_loops(block=b69)
l88 = sch.fuse(l72, l73, l74, l75, l76, preserve_unit_iters=True)
sch.parallel(loop=l88)
l89 = sch.fuse(l87, preserve_unit_iters=True)
sch.vectorize(loop=l89)
l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107, l108, l109, l110, l111 = sch.get_loops(block=b70)
l112 = sch.fuse(l90, preserve_unit_iters=True)
sch.parallel(loop=l112)
sch.annotate(block_or_loop=l112, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l112, ann_key="pragma_unroll_explicit", ann_val=1)
l113, l114, l115, l116, l117, l118 = sch.get_loops(block=b71)
b119 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141 = sch.get_loops(block=b119)
b142 = sch.decompose_reduction(block=b119, loop=l126)
2024-04-29 03:57:34 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #36: GFLOPs: 1.2446. Time: 185894.7740 us. Best GFLOPs: 124.1510
2024-04-29 03:57:34 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #37: GFLOPs: 83.3432. Time: 2776.0100 us. Best GFLOPs: 124.1510
2024-04-29 03:57:34 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #38: GFLOPs: 26.3060. Time: 8795.0062 us. Best GFLOPs: 124.1510
2024-04-29 03:57:34 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #39: GFLOPs: 1.8861. Time: 122669.0600 us. Best GFLOPs: 124.1510
2024-04-29 03:57:34 [INFO] [task_scheduler.cc:121] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #40: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(14), T.int64(14), T.int64(128)), "float32"), p1: T.Buffer((T.int64(16), T.int64(2), T.int64(3), T.int64(3), T.int64(128), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(16)), "float32"), p3: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(16), T.int64(16), T.int64(128)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused in T.parallel(T.int64(4), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(2), T.int64(16), T.int64(16), T.int64(128)):
                with T.block("data_pad"):
                    v_i0, v_i1, v_i2, v_i3, v_i4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(15) and T.int64(1) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(7), T.int64(2)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(4), T.int64(1), T.int64(4), T.int64(14), T.int64(2), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(2) * T.int64(8) + oc_chunk_2_init * T.int64(4) + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(14), oh_1 * T.int64(14) + oh_2_init * T.int64(14) + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(14), ow_1 * T.int64(2) + ow_2_init * T.int64(2) + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(2) * T.int64(8) + oc_block_1 * T.int64(4) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(128), T.int64(3), T.int64(3), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(4), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(14), T.int64(2), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(2) * T.int64(8) + oc_chunk_2 * T.int64(4) + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(14), oh_1 * T.int64(14) + oh_2 * T.int64(14) + oh_3)
                        v_ow = T.axis.spatial(T.int64(14), ow_1 * T.int64(2) + ow_2 * T.int64(2) + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(2) * T.int64(8) + oc_block_1 * T.int64(4) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(2) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(8), T.int64(14), T.int64(2)):
                    for ax4_fused in T.vectorized(T.int64(4)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(2) * T.int64(8) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(14), ax2)
                            v_ax3 = T.axis.spatial(T.int64(14), ow_1 * T.int64(2) + ax3)
                            v_ax4 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(2) * T.int64(8) + oc_block_1 * T.int64(4) + ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 2, 2, 4])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 1, 14])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 7, 1, 2])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[2, 2, 4, 1])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[128, 2])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[3, 1])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l50, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=6)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83 = sch.get_loops(block=b69)
l84 = sch.fuse(l72, l73, l74, l75, l76, l77, l78, preserve_unit_iters=True)
sch.parallel(loop=l84)
l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b70)
l105 = sch.fuse(l85, preserve_unit_iters=True)
sch.parallel(loop=l105)
sch.annotate(block_or_loop=l105, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l105, ann_key="pragma_unroll_explicit", ann_val=1)
l106, l107, l108, l109, l110, l111, l112, l113, l114 = sch.get_loops(block=b71)
l115 = sch.fuse(l114, preserve_unit_iters=True)
sch.vectorize(loop=l115)
b116 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136 = sch.get_loops(block=b116)
b137 = sch.decompose_reduction(block=b116, loop=l121)
2024-04-29 03:57:34 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #41: GFLOPs: 9.9229. Time: 23315.8124 us. Best GFLOPs: 124.1510
2024-04-29 03:57:34 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #42: GFLOPs: 0.6360. Time: 363765.8043 us. Best GFLOPs: 124.1510
2024-04-29 03:57:34 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #43: GFLOPs: 1.7983. Time: 128656.5590 us. Best GFLOPs: 124.1510
2024-04-29 03:57:34 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #44: GFLOPs: 86.4558. Time: 2676.0660 us. Best GFLOPs: 124.1510
2024-04-29 03:57:34 [INFO] [task_scheduler.cc:121] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #45: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(14), T.int64(14), T.int64(128)), "float32"), p1: T.Buffer((T.int64(16), T.int64(2), T.int64(3), T.int64(3), T.int64(128), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(16)), "float32"), p3: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(16), T.int64(16), T.int64(128)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)))
        for n_0_oc_chunk_0_fused_fused in T.parallel(T.int64(8), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(2), T.int64(16), T.int64(16), T.int64(128)):
                with T.block("data_pad"):
                    v_i0, v_i1, v_i2, v_i3, v_i4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(15) and T.int64(1) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oh_0, ow_0, oc_block_0 in T.grid(T.int64(1), T.int64(7), T.int64(1)):
                for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(2), T.int64(7), T.int64(2), T.int64(1)):
                    for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1)):
                        for oc_block_3_fused_init in T.vectorized(T.int64(16)):
                            with T.block("conv2d_NCHWc_init"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                                v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_fused_fused * T.int64(2) + oc_chunk_1 + oc_chunk_2_init + oc_chunk_3_init)
                                v_oh = T.axis.spatial(T.int64(14), oh_0 * T.int64(14) + oh_1 * T.int64(2) + oh_2_init * T.int64(2) + oh_3_init)
                                v_ow = T.axis.spatial(T.int64(14), ow_0 * T.int64(2) + ow_1 + ow_2_init + ow_3_init)
                                v_oc_block = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2_init * T.int64(16) + oc_block_3_fused_init)
                                T.reads()
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                    for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(16), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(16), T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(2), T.int64(1)):
                        for oc_block_3_fused in T.vectorized(T.int64(16)):
                            with T.block("conv2d_NCHWc_update"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                                v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_fused_fused * T.int64(2) + oc_chunk_1 + oc_chunk_2 + oc_chunk_3)
                                v_oh = T.axis.spatial(T.int64(14), oh_0 * T.int64(14) + oh_1 * T.int64(2) + oh_2 * T.int64(2) + oh_3)
                                v_ow = T.axis.spatial(T.int64(14), ow_0 * T.int64(2) + ow_1 + ow_2 + ow_3)
                                v_oc_block = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2 * T.int64(16) + oc_block_3_fused)
                                v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(16) + ic_1)
                                v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                                v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                                T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
                for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(2), T.int64(14)):
                    for ax3_ax4_fused in T.vectorized(T.int64(32)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_fused_fused * T.int64(2) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(14), ax2)
                            v_ax3 = T.axis.spatial(T.int64(14), ow_0 * T.int64(2) + ax3_ax4_fused // T.int64(16))
                            v_ax4 = T.axis.spatial(T.int64(16), ax3_ax4_fused % T.int64(16))
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[8, 2, 1, 1])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 7, 1, 2])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[7, 2, 1, 1])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[1, 1, 1, 16])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[16, 16])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[1, 3])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=1)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78 = sch.get_loops(block=b69)
l79 = sch.fuse(l72, l73, preserve_unit_iters=True)
sch.parallel(loop=l79)
l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b70)
l105 = sch.fuse(l80, preserve_unit_iters=True)
sch.parallel(loop=l105)
l106 = sch.fuse(l104, preserve_unit_iters=True)
sch.vectorize(loop=l106)
sch.annotate(block_or_loop=l105, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l105, ann_key="pragma_unroll_explicit", ann_val=1)
l107, l108, l109, l110, l111, l112, l113, l114, l115 = sch.get_loops(block=b71)
l116 = sch.fuse(l114, l115, preserve_unit_iters=True)
sch.vectorize(loop=l116)
b117 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141, l142 = sch.get_loops(block=b117)
b143 = sch.decompose_reduction(block=b117, loop=l127)
2024-04-29 03:57:34 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #46: GFLOPs: 4.4426. Time: 52077.7967 us. Best GFLOPs: 124.1510
2024-04-29 03:57:34 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #47: GFLOPs: 100.5123. Time: 2301.8225 us. Best GFLOPs: 124.1510
2024-04-29 03:57:34 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #48: GFLOPs: 26.6714. Time: 8674.5274 us. Best GFLOPs: 124.1510
2024-04-29 03:57:34 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #49: GFLOPs: 1.2455. Time: 185750.8583 us. Best GFLOPs: 124.1510
2024-04-29 03:57:34 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #50: GFLOPs: 1.3524. Time: 171070.8837 us. Best GFLOPs: 124.1510
2024-04-29 03:57:34 [INFO] [task_scheduler.cc:121] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #51: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(14), T.int64(14), T.int64(128)), "float32"), p1: T.Buffer((T.int64(16), T.int64(2), T.int64(3), T.int64(3), T.int64(128), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(16)), "float32"), p3: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(16), T.int64(16), T.int64(128)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)))
        for n_0_oc_chunk_0_fused_fused in T.parallel(T.int64(8), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(2), T.int64(16), T.int64(16), T.int64(128)):
                with T.block("data_pad"):
                    v_i0, v_i1, v_i2, v_i3, v_i4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(15) and T.int64(1) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oh_0, ow_0, oc_block_0 in T.grid(T.int64(1), T.int64(2), T.int64(1)):
                for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1)):
                    for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(14), T.int64(1)):
                        for oc_block_3_fused_init in T.vectorized(T.int64(4)):
                            with T.block("conv2d_NCHWc_init"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                                v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_fused_fused * T.int64(2) + oc_chunk_1 * T.int64(2) + oc_chunk_2_init + oc_chunk_3_init)
                                v_oh = T.axis.spatial(T.int64(14), oh_0 * T.int64(14) + oh_1 * T.int64(14) + oh_2_init * T.int64(14) + oh_3_init)
                                v_ow = T.axis.spatial(T.int64(14), ow_0 * T.int64(7) + ow_1 + ow_2_init + ow_3_init)
                                v_oc_block = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2_init * T.int64(4) + oc_block_3_fused_init)
                                T.reads()
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                    for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(16), T.int64(3), T.int64(3), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(4), T.int64(16), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(14), T.int64(1)):
                        for oc_block_3_fused in T.vectorized(T.int64(4)):
                            with T.block("conv2d_NCHWc_update"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                                v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_fused_fused * T.int64(2) + oc_chunk_1 * T.int64(2) + oc_chunk_2 + oc_chunk_3)
                                v_oh = T.axis.spatial(T.int64(14), oh_0 * T.int64(14) + oh_1 * T.int64(14) + oh_2 * T.int64(14) + oh_3)
                                v_ow = T.axis.spatial(T.int64(14), ow_0 * T.int64(7) + ow_1 + ow_2 + ow_3)
                                v_oc_block = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2 * T.int64(4) + oc_block_3_fused)
                                v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(16) + ic_1)
                                v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                                v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                                T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(2), T.int64(14), T.int64(7)):
                    for ax4_fused in T.vectorized(T.int64(16)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_fused_fused * T.int64(2) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(14), ax2)
                            v_ax3 = T.axis.spatial(T.int64(14), ow_0 * T.int64(7) + ax3)
                            v_ax4 = T.axis.spatial(T.int64(16), ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[8, 1, 2, 1])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 1, 14])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[2, 7, 1, 1])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[1, 1, 4, 4])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[16, 16])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[3, 1])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=1)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78 = sch.get_loops(block=b69)
l79 = sch.fuse(l72, l73, preserve_unit_iters=True)
sch.parallel(loop=l79)
l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b70)
l105 = sch.fuse(l80, preserve_unit_iters=True)
sch.parallel(loop=l105)
l106 = sch.fuse(l104, preserve_unit_iters=True)
sch.vectorize(loop=l106)
sch.annotate(block_or_loop=l105, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l105, ann_key="pragma_unroll_explicit", ann_val=1)
l107, l108, l109, l110, l111, l112, l113, l114, l115 = sch.get_loops(block=b71)
l116 = sch.fuse(l115, preserve_unit_iters=True)
sch.vectorize(loop=l116)
b117 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141, l142 = sch.get_loops(block=b117)
b143 = sch.decompose_reduction(block=b117, loop=l127)
2024-04-29 03:57:34 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #52: GFLOPs: 27.6612. Time: 8364.1263 us. Best GFLOPs: 124.1510
2024-04-29 03:57:34 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #53: GFLOPs: 50.0467. Time: 4622.9086 us. Best GFLOPs: 124.1510
2024-04-29 03:57:34 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #54: GFLOPs: 14.9080. Time: 15519.3196 us. Best GFLOPs: 124.1510
2024-04-29 03:57:34 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #55: GFLOPs: 5.5554. Time: 41646.4820 us. Best GFLOPs: 124.1510
2024-04-29 03:57:34 [INFO] [task_scheduler.cc:121] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #56: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(14), T.int64(14), T.int64(128)), "float32"), p1: T.Buffer((T.int64(16), T.int64(2), T.int64(3), T.int64(3), T.int64(128), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(16)), "float32"), p3: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(16), T.int64(16), T.int64(128)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)))
        for i0_i1_i2_i3_i4_fused in T.parallel(T.int64(65536)):
            with T.block("data_pad"):
                v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                v_i1 = T.axis.spatial(T.int64(2), i0_i1_i2_i3_i4_fused // T.int64(32768))
                v_i2 = T.axis.spatial(T.int64(16), i0_i1_i2_i3_i4_fused % T.int64(32768) // T.int64(2048))
                v_i3 = T.axis.spatial(T.int64(16), i0_i1_i2_i3_i4_fused % T.int64(2048) // T.int64(128))
                v_i4 = T.axis.spatial(T.int64(128), i0_i1_i2_i3_i4_fused % T.int64(128))
                T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(15) and T.int64(1) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused in T.parallel(T.int64(224), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(4), T.int64(14), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(2), T.int64(1)):
                with T.block("conv2d_NCHWc_init"):
                    v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                    v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(56) // T.int64(28) * T.int64(8) + oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                    v_oh = T.axis.spatial(T.int64(14), oh_2_init + oh_3_init)
                    v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(28) // T.int64(4) * T.int64(2) + ow_2_init * T.int64(2) + ow_3_init)
                    v_oc_block = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused // T.int64(56) * T.int64(4) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(4) + oc_block_2_init + oc_block_3_init)
                    T.reads()
                    T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                    T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                    conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
            for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(256), T.int64(1), T.int64(3), T.int64(1), T.int64(4), T.int64(14), T.int64(1), T.int64(1), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(2), T.int64(1)):
                with T.block("conv2d_NCHWc_update"):
                    v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                    v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(56) // T.int64(28) * T.int64(8) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                    v_oh = T.axis.spatial(T.int64(14), oh_2 + oh_3)
                    v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(28) // T.int64(4) * T.int64(2) + ow_2 * T.int64(2) + ow_3)
                    v_oc_block = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused // T.int64(56) * T.int64(4) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(4) + oc_block_2 + oc_block_3)
                    v_ic = T.axis.reduce(T.int64(256), ic_0 + ic_1)
                    v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                    v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                    T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                    T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                    T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                    conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(8), T.int64(14), T.int64(2), T.int64(1)):
                with T.block("T_relu"):
                    v_ax0 = T.axis.spatial(T.int64(1), ax0)
                    v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(56) // T.int64(28) * T.int64(8) + ax1)
                    v_ax2 = T.axis.spatial(T.int64(14), ax2)
                    v_ax3 = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(28) // T.int64(4) * T.int64(2) + ax3)
                    v_ax4 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused // T.int64(56) * T.int64(4) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(4) + ax4)
                    T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 2, 4, 2])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 14, 1])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 7, 1, 2])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[4, 4, 1, 1])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[256, 1])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[3, 1])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l50, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=-1)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76 = sch.get_loops(block=b69)
l77 = sch.fuse(l72, l73, l74, l75, l76, preserve_unit_iters=True)
sch.parallel(loop=l77)
l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b70)
l104 = sch.fuse(l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, preserve_unit_iters=True)
sch.parallel(loop=l104)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109, l110 = sch.get_loops(block=b71)
b111 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l112, l113, l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128 = sch.get_loops(block=b111)
b129 = sch.decompose_reduction(block=b111, loop=l113)
2024-04-29 03:57:34 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #57: GFLOPs: 5.8209. Time: 39746.4103 us. Best GFLOPs: 124.1510
2024-04-29 03:57:34 [INFO] [task_scheduler.cc:121] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #58: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(14), T.int64(14), T.int64(128)), "float32"), p1: T.Buffer((T.int64(16), T.int64(2), T.int64(3), T.int64(3), T.int64(128), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(16)), "float32"), p3: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(16), T.int64(16), T.int64(128)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused in T.parallel(T.int64(2), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1 in T.grid(T.int64(1), T.int64(4)):
                for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(2), T.int64(16), T.int64(16), T.int64(128)):
                    with T.block("data_pad"):
                        v_i0, v_i1, v_i2, v_i3, v_i4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                        T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                        T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                        data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(15) and T.int64(1) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                for oh_1, ow_1, oc_block_1 in T.grid(T.int64(7), T.int64(1), T.int64(1)):
                    for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(1), T.int64(14)):
                        for oc_block_3_fused_init in T.vectorized(T.int64(8)):
                            with T.block("conv2d_NCHWc_init"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                                v_oc_chunk = T.axis.spatial(T.int64(16), oc_chunk_1 * T.int64(4) + oc_chunk_2_init * T.int64(4) + oc_chunk_3_init)
                                v_oh = T.axis.spatial(T.int64(14), oh_1 * T.int64(2) + oh_2_init + oh_3_init)
                                v_ow = T.axis.spatial(T.int64(14), ow_1 * T.int64(14) + ow_2_init * T.int64(14) + ow_3_init)
                                v_oc_block = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused * T.int64(8) + oc_block_1 * T.int64(8) + oc_block_2_init * T.int64(8) + oc_block_3_fused_init)
                                T.reads()
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                    for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(128), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(2), T.int64(3), T.int64(3), T.int64(1), T.int64(4), T.int64(1), T.int64(14)):
                        for oc_block_3_fused in T.vectorized(T.int64(8)):
                            with T.block("conv2d_NCHWc_update"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                                v_oc_chunk = T.axis.spatial(T.int64(16), oc_chunk_1 * T.int64(4) + oc_chunk_2 * T.int64(4) + oc_chunk_3)
                                v_oh = T.axis.spatial(T.int64(14), oh_1 * T.int64(2) + oh_2 + oh_3)
                                v_ow = T.axis.spatial(T.int64(14), ow_1 * T.int64(14) + ow_2 * T.int64(14) + ow_3)
                                v_oc_block = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused * T.int64(8) + oc_block_1 * T.int64(8) + oc_block_2 * T.int64(8) + oc_block_3_fused)
                                v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(2) + ic_1)
                                v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                                v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                                T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(16), T.int64(14), T.int64(14)):
                for ax4_fused in T.vectorized(T.int64(8)):
                    with T.block("T_relu"):
                        v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                        v_ax4 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused * T.int64(8) + ax4_fused)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 4, 1, 4])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 7, 2, 1])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 1, 14])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[2, 1, 1, 8])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[128, 2])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[1, 3])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=6)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83 = sch.get_loops(block=b69)
l84 = sch.fuse(l72, l73, l74, l75, l76, preserve_unit_iters=True)
sch.parallel(loop=l84)
l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106 = sch.get_loops(block=b70)
l107 = sch.fuse(l85, preserve_unit_iters=True)
sch.parallel(loop=l107)
l108 = sch.fuse(l106, preserve_unit_iters=True)
sch.vectorize(loop=l108)
sch.annotate(block_or_loop=l107, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l107, ann_key="pragma_unroll_explicit", ann_val=1)
l109, l110, l111, l112, l113, l114 = sch.get_loops(block=b71)
l115 = sch.fuse(l114, preserve_unit_iters=True)
sch.vectorize(loop=l115)
b116 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138 = sch.get_loops(block=b116)
b139 = sch.decompose_reduction(block=b116, loop=l123)
2024-04-29 03:57:34 [INFO] [task_scheduler.cc:121] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #59: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(14), T.int64(14), T.int64(128)), "float32"), p1: T.Buffer((T.int64(16), T.int64(2), T.int64(3), T.int64(3), T.int64(128), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(16)), "float32"), p3: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(16), T.int64(16), T.int64(128)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused in T.parallel(T.int64(14), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(8), T.int64(1), T.int64(2), T.int64(8), T.int64(1), T.int64(1), T.int64(14), T.int64(1)):
                for oc_block_3_fused_init in T.vectorized(T.int64(2)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(7) * T.int64(8) + oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(14), oh_2_init * T.int64(14) + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(7) * T.int64(2) + ow_2_init + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(16), oc_block_2_init * T.int64(2) + oc_block_3_fused_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
            for ic_0, kh_0 in T.grid(T.int64(16), T.int64(3)):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(14), T.int64(4)):
                    for ax4_fused in T.vectorized(T.int64(16)):
                        with T.block("data_pad"):
                            v_i0 = T.axis.spatial(T.int64(1), ax0)
                            v_i1 = T.axis.spatial(T.int64(2), ic_0 // T.int64(8) + ax1)
                            v_i2 = T.axis.spatial(T.int64(16), kh_0 + ax2)
                            v_i3 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(7) * T.int64(2) + ax3)
                            v_i4 = T.axis.spatial(T.int64(128), ic_0 % T.int64(8) * T.int64(16) + ax4_fused)
                            T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                            T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                            data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(15) and T.int64(1) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                for kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(3), T.int64(1), T.int64(8), T.int64(1), T.int64(2), T.int64(8), T.int64(16), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(14), T.int64(1)):
                    for oc_block_3_fused in T.vectorized(T.int64(2)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(7) * T.int64(8) + oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(14), oh_2 * T.int64(14) + oh_3)
                            v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(7) * T.int64(2) + ow_2 + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_2 * T.int64(2) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(16) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
            for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(8), T.int64(14)):
                for ax3_ax4_fused in T.vectorized(T.int64(32)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(7) * T.int64(8) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(14), ax2)
                        v_ax3 = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(7) * T.int64(2) + ax3_ax4_fused // T.int64(16))
                        v_ax4 = T.axis.spatial(T.int64(16), ax3_ax4_fused % T.int64(16))
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 1, 8, 1])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 1, 14])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 7, 2, 1])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[1, 1, 8, 2])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[16, 16])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[3, 1])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l50, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=11)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88 = sch.get_loops(block=b69)
l89 = sch.fuse(l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, preserve_unit_iters=True)
sch.parallel(loop=l89)
l90 = sch.fuse(l88, preserve_unit_iters=True)
sch.vectorize(loop=l90)
l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107 = sch.get_loops(block=b70)
l108 = sch.fuse(l91, preserve_unit_iters=True)
sch.parallel(loop=l108)
l109 = sch.fuse(l107, preserve_unit_iters=True)
sch.vectorize(loop=l109)
sch.annotate(block_or_loop=l108, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l108, ann_key="pragma_unroll_explicit", ann_val=1)
l110, l111, l112, l113, l114, l115 = sch.get_loops(block=b71)
l116 = sch.fuse(l114, l115, preserve_unit_iters=True)
sch.vectorize(loop=l116)
b117 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134 = sch.get_loops(block=b117)
b135 = sch.decompose_reduction(block=b117, loop=l119)
2024-04-29 03:57:34 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #60: GFLOPs: 60.8473. Time: 3802.3327 us. Best GFLOPs: 124.1510
2024-04-29 03:57:34 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #61: GFLOPs: 3.7802. Time: 61203.2550 us. Best GFLOPs: 124.1510
2024-04-29 03:57:34 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #62: GFLOPs: 126.9262. Time: 1822.8029 us. Best GFLOPs: 126.9262
2024-04-29 03:57:34 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #63: GFLOPs: 6.7002. Time: 34530.5093 us. Best GFLOPs: 126.9262
2024-04-29 03:57:34 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #64: GFLOPs: 13.1180. Time: 17637.0128 us. Best GFLOPs: 126.9262
2024-04-29 03:58:01 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 03:58:02 [INFO] [evolutionary_search.cc:715] Picked top 49 candidate(s) from database
2024-04-29 03:58:07 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3639cb8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x419b828)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x312c9f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x425e1d8)]: 0 failure(s)
2024-04-29 03:58:07 [INFO] [evolutionary_search.cc:723] Sampled 463 candidate(s)
2024-04-29 03:58:19 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3639cb8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x419b828)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x312c9f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x425e1d8)]: 0 failure(s)
2024-04-29 03:58:32 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3639cb8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x419b828)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x312c9f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x425e1d8)]: 0 failure(s)
2024-04-29 03:58:45 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3639cb8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x419b828)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x312c9f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x425e1d8)]: 0 failure(s)
2024-04-29 03:58:58 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3639cb8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x419b828)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x312c9f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x425e1d8)]: 0 failure(s)
2024-04-29 03:59:05 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	1.0347  0.9924  0.9924  0.9924  0.9924  0.9873  0.9441  0.9384  0.8887  0.8802  0.8792  0.8653  0.8600  0.8600  0.8600  0.8600
[17 : 32]:	0.8595  0.8363  0.8285  0.8238  0.8238  0.8211  0.8198  0.8151  0.8122  0.7967  0.7951  0.7943  0.7937  0.7910  0.7910  0.7910
[33 : 48]:	0.7907  0.7866  0.7863  0.7862  0.7859  0.7851  0.7841  0.7841  0.7821  0.7821  0.7777  0.7749  0.7738  0.7734  0.7721  0.7707
[49 : 64]:	0.7693  0.7693  0.7693  0.7693  0.7693  0.7693  0.7693  0.7693  0.7657  0.7657  0.7636  0.7636  0.7636  0.7635  0.7635  0.7635
2024-04-29 03:59:06 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 03:59:06 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 04:00:20 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #65: GFLOPs: 180.1537. Time: 1284.2449 us. Best GFLOPs: 180.1537
2024-04-29 04:00:20 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #66: GFLOPs: 180.7963. Time: 1279.6806 us. Best GFLOPs: 180.7963
2024-04-29 04:00:20 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #67: GFLOPs: 126.8032. Time: 1824.5716 us. Best GFLOPs: 180.7963
2024-04-29 04:00:20 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #68: GFLOPs: 182.8943. Time: 1265.0017 us. Best GFLOPs: 182.8943
2024-04-29 04:00:20 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #69: GFLOPs: 145.4292. Time: 1590.8877 us. Best GFLOPs: 182.8943
2024-04-29 04:00:20 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #70: GFLOPs: 198.2697. Time: 1166.9031 us. Best GFLOPs: 198.2697
2024-04-29 04:00:20 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #71: GFLOPs: 169.1139. Time: 1368.0807 us. Best GFLOPs: 198.2697
2024-04-29 04:00:20 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #72: GFLOPs: 340.7250. Time: 679.0271 us. Best GFLOPs: 340.7250
2024-04-29 04:00:20 [INFO] [task_scheduler.cc:121] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #73: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(14), T.int64(14), T.int64(128)), "float32"), p1: T.Buffer((T.int64(16), T.int64(2), T.int64(3), T.int64(3), T.int64(128), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(16)), "float32"), p3: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(16), T.int64(16), T.int64(128)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused in T.parallel(T.int64(112), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(2), T.int64(16), T.int64(4), T.int64(128)):
                with T.block("data_pad"):
                    v_i0, v_i1, v_i2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                    v_i3 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(14) // T.int64(2) * T.int64(2) + ax3)
                    v_i4 = T.axis.spatial(T.int64(128), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(15) and T.int64(1) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(2), T.int64(14), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2)):
                for oc_block_3_fused_init in T.vectorized(T.int64(8)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(14) * T.int64(2) + oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(14), oh_2_init + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(14) // T.int64(2) * T.int64(2) + ow_2_init * T.int64(2) + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(2) * T.int64(8) + oc_block_2_init * T.int64(8) + oc_block_3_fused_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
            for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(256), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(14), T.int64(1), T.int64(1), T.int64(1), T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(2)):
                for oc_block_3_fused in T.vectorized(T.int64(8)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(14) * T.int64(2) + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(14), oh_2 + oh_3)
                        v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(14) // T.int64(2) * T.int64(2) + ow_2 * T.int64(2) + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(2) * T.int64(8) + oc_block_2 * T.int64(8) + oc_block_3_fused)
                        v_ic = T.axis.reduce(T.int64(256), ic_0 + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(2), T.int64(14), T.int64(2)):
                for ax4_fused in T.vectorized(T.int64(8)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(14) * T.int64(2) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(14), ax2)
                        v_ax3 = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(14) // T.int64(2) * T.int64(2) + ax3)
                        v_ax4 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(2) * T.int64(8) + ax4_fused)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 4, 2, 1])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 14, 1])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 7, 1, 2])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[1, 2, 1, 8])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[256, 1])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[1, 3])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l50, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=9)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86 = sch.get_loops(block=b69)
l87 = sch.fuse(l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, preserve_unit_iters=True)
sch.parallel(loop=l87)
l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b70)
l105 = sch.fuse(l88, preserve_unit_iters=True)
sch.parallel(loop=l105)
l106 = sch.fuse(l104, preserve_unit_iters=True)
sch.vectorize(loop=l106)
sch.annotate(block_or_loop=l105, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l105, ann_key="pragma_unroll_explicit", ann_val=1)
l107, l108, l109, l110, l111, l112 = sch.get_loops(block=b71)
l113 = sch.fuse(l112, preserve_unit_iters=True)
sch.vectorize(loop=l113)
b114 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131 = sch.get_loops(block=b114)
b132 = sch.decompose_reduction(block=b114, loop=l116)
2024-04-29 04:00:20 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #74: GFLOPs: 93.3297. Time: 2478.9703 us. Best GFLOPs: 340.7250
2024-04-29 04:00:20 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #75: GFLOPs: 139.2139. Time: 1661.9142 us. Best GFLOPs: 340.7250
2024-04-29 04:00:20 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #76: GFLOPs: 100.0280. Time: 2312.9682 us. Best GFLOPs: 340.7250
2024-04-29 04:00:20 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #77: GFLOPs: 166.5755. Time: 1388.9294 us. Best GFLOPs: 340.7250
2024-04-29 04:00:20 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #78: GFLOPs: 191.9847. Time: 1205.1042 us. Best GFLOPs: 340.7250
2024-04-29 04:00:20 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #79: GFLOPs: 189.9120. Time: 1218.2562 us. Best GFLOPs: 340.7250
2024-04-29 04:00:20 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #80: GFLOPs: 123.3128. Time: 1876.2171 us. Best GFLOPs: 340.7250
2024-04-29 04:00:20 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #81: GFLOPs: 153.7117. Time: 1505.1655 us. Best GFLOPs: 340.7250
2024-04-29 04:00:20 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #82: GFLOPs: 110.2635. Time: 2098.2607 us. Best GFLOPs: 340.7250
2024-04-29 04:00:20 [INFO] [task_scheduler.cc:121] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #83: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(14), T.int64(14), T.int64(128)), "float32"), p1: T.Buffer((T.int64(16), T.int64(2), T.int64(3), T.int64(3), T.int64(128), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(16)), "float32"), p3: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(16), T.int64(16), T.int64(128)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused in T.parallel(T.int64(112), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(2), T.int64(9), T.int64(4), T.int64(128)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(56) * T.int64(7) + ax2)
                    v_i3 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(7) * T.int64(2) + ax3)
                    v_i4 = T.axis.spatial(T.int64(128), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(15) and T.int64(1) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oc_block_1 in range(T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(2), T.int64(1), T.int64(4), T.int64(7), T.int64(1)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(28) // T.int64(7) * T.int64(4) + oc_chunk_2_init * T.int64(4) + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(56) * T.int64(7) + oh_2_init * T.int64(7) + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(7) * T.int64(2) + ow_2_init + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(56) // T.int64(28) * T.int64(8) + oc_block_1 * T.int64(8) + oc_block_2_init * T.int64(4) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(2), T.int64(64), T.int64(3), T.int64(3), T.int64(1), T.int64(4), T.int64(7), T.int64(1)):
                    for oc_block_3_fused in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(28) // T.int64(7) * T.int64(4) + oc_chunk_2 * T.int64(4) + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(56) * T.int64(7) + oh_2 * T.int64(7) + oh_3)
                            v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(7) * T.int64(2) + ow_2 + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(56) // T.int64(28) * T.int64(8) + oc_block_1 * T.int64(8) + oc_block_2 * T.int64(4) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(64) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(4), T.int64(7), T.int64(2)):
                    for ax4_fused in T.vectorized(T.int64(8)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(28) // T.int64(7) * T.int64(4) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(56) * T.int64(7) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(7) * T.int64(2) + ax3)
                            v_ax4 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(56) // T.int64(28) * T.int64(8) + ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 4, 1, 4])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[2, 1, 1, 7])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 7, 2, 1])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[2, 1, 2, 4])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[4, 64])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[1, 3])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l50, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=8)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85 = sch.get_loops(block=b69)
l86 = sch.fuse(l72, l73, l74, l75, l76, l77, l78, l79, l80, preserve_unit_iters=True)
sch.parallel(loop=l86)
l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b70)
l105 = sch.fuse(l87, preserve_unit_iters=True)
sch.parallel(loop=l105)
l106 = sch.fuse(l104, preserve_unit_iters=True)
sch.vectorize(loop=l106)
sch.annotate(block_or_loop=l105, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l105, ann_key="pragma_unroll_explicit", ann_val=1)
l107, l108, l109, l110, l111, l112, l113 = sch.get_loops(block=b71)
l114 = sch.fuse(l113, preserve_unit_iters=True)
sch.vectorize(loop=l114)
b115 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133 = sch.get_loops(block=b115)
b134 = sch.decompose_reduction(block=b115, loop=l118)
2024-04-29 04:00:20 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #84: GFLOPs: 107.8115. Time: 2145.9825 us. Best GFLOPs: 340.7250
2024-04-29 04:00:20 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #85: GFLOPs: 95.1475. Time: 2431.6090 us. Best GFLOPs: 340.7250
2024-04-29 04:00:20 [INFO] [task_scheduler.cc:121] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #86: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(14), T.int64(14), T.int64(128)), "float32"), p1: T.Buffer((T.int64(16), T.int64(2), T.int64(3), T.int64(3), T.int64(128), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(16)), "float32"), p3: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(16), T.int64(16), T.int64(128)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused in T.parallel(T.int64(28), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(8), T.int64(1), T.int64(2), T.int64(8), T.int64(1), T.int64(1), T.int64(14), T.int64(1), T.int64(1)):
                with T.block("conv2d_NCHWc_init"):
                    v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                    v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(14) * T.int64(8) + oc_chunk_2_init + oc_chunk_3_init)
                    v_oh = T.axis.spatial(T.int64(14), oh_2_init * T.int64(14) + oh_3_init)
                    v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(14) // T.int64(2) * T.int64(2) + ow_2_init + ow_3_init)
                    v_oc_block = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(2) * T.int64(8) + oc_block_2_init + oc_block_3_init)
                    T.reads()
                    T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                    T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                    conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
            for ic_0, kh_0 in T.grid(T.int64(8), T.int64(3)):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(14), T.int64(4)):
                    for ax4_fused in T.vectorized(T.int64(32)):
                        with T.block("data_pad"):
                            v_i0 = T.axis.spatial(T.int64(1), ax0)
                            v_i1 = T.axis.spatial(T.int64(2), ic_0 // T.int64(4) + ax1)
                            v_i2 = T.axis.spatial(T.int64(16), kh_0 + ax2)
                            v_i3 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(14) // T.int64(2) * T.int64(2) + ax3)
                            v_i4 = T.axis.spatial(T.int64(128), ic_0 % T.int64(4) * T.int64(32) + ax4_fused)
                            T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                            T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                            data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(15) and T.int64(1) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                for kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(1), T.int64(1), T.int64(8), T.int64(1), T.int64(2), T.int64(8), T.int64(32), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(14), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(14) * T.int64(8) + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(14), oh_2 * T.int64(14) + oh_3)
                        v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(14) // T.int64(2) * T.int64(2) + ow_2 + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(2) * T.int64(8) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(32) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(8), T.int64(14), T.int64(2)):
                for ax4_fused in T.vectorized(T.int64(8)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(14) * T.int64(8) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(14), ax2)
                        v_ax3 = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(14) // T.int64(2) * T.int64(2) + ax3)
                        v_ax4 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(2) * T.int64(8) + ax4_fused)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 1, 8, 1])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 1, 14])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 7, 2, 1])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[1, 2, 8, 1])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[8, 32])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[1, 3])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l50, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=11)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88 = sch.get_loops(block=b69)
l89 = sch.fuse(l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, preserve_unit_iters=True)
sch.parallel(loop=l89)
l90 = sch.fuse(l88, preserve_unit_iters=True)
sch.vectorize(loop=l90)
l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107 = sch.get_loops(block=b70)
l108 = sch.fuse(l91, preserve_unit_iters=True)
sch.parallel(loop=l108)
sch.annotate(block_or_loop=l108, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l108, ann_key="pragma_unroll_explicit", ann_val=1)
l109, l110, l111, l112, l113, l114 = sch.get_loops(block=b71)
l115 = sch.fuse(l114, preserve_unit_iters=True)
sch.vectorize(loop=l115)
b116 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133 = sch.get_loops(block=b116)
b134 = sch.decompose_reduction(block=b116, loop=l118)
2024-04-29 04:00:20 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #87: GFLOPs: 94.4856. Time: 2448.6446 us. Best GFLOPs: 340.7250
2024-04-29 04:00:20 [INFO] [task_scheduler.cc:121] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #88: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(14), T.int64(14), T.int64(128)), "float32"), p1: T.Buffer((T.int64(16), T.int64(2), T.int64(3), T.int64(3), T.int64(128), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(16)), "float32"), p3: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(16), T.int64(16), T.int64(128)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused in T.parallel(T.int64(392), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(2), T.int64(4), T.int64(4), T.int64(128)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(56) * T.int64(2) + ax2)
                    v_i3 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(56) // T.int64(8) * T.int64(2) + ax3)
                    v_i4 = T.axis.spatial(T.int64(128), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(15) and T.int64(1) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(8), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2)):
                for oc_block_3_fused_init in T.vectorized(T.int64(4)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(8) // T.int64(4) * T.int64(8) + oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(56) * T.int64(2) + oh_2_init + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(56) // T.int64(8) * T.int64(2) + ow_2_init * T.int64(2) + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(4) * T.int64(4) + oc_block_2_init * T.int64(4) + oc_block_3_fused_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
            for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(16), T.int64(3), T.int64(3), T.int64(1), T.int64(8), T.int64(2), T.int64(1), T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2)):
                for oc_block_3_fused in T.vectorized(T.int64(4)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(8) // T.int64(4) * T.int64(8) + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(56) * T.int64(2) + oh_2 + oh_3)
                        v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(56) // T.int64(8) * T.int64(2) + ow_2 * T.int64(2) + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(4) * T.int64(4) + oc_block_2 * T.int64(4) + oc_block_3_fused)
                        v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(16) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(8), T.int64(2), T.int64(2)):
                for ax4_fused in T.vectorized(T.int64(4)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(8) // T.int64(4) * T.int64(8) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(56) * T.int64(2) + ax2)
                        v_ax3 = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(56) // T.int64(8) * T.int64(2) + ax3)
                        v_ax4 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(4) * T.int64(4) + ax4_fused)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 2, 8, 1])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[7, 1, 2, 1])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[7, 1, 1, 2])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[1, 4, 1, 4])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[16, 16])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[3, 1])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l50, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=9)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86 = sch.get_loops(block=b69)
l87 = sch.fuse(l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, preserve_unit_iters=True)
sch.parallel(loop=l87)
l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b70)
l105 = sch.fuse(l88, preserve_unit_iters=True)
sch.parallel(loop=l105)
l106 = sch.fuse(l104, preserve_unit_iters=True)
sch.vectorize(loop=l106)
sch.annotate(block_or_loop=l105, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l105, ann_key="pragma_unroll_explicit", ann_val=1)
l107, l108, l109, l110, l111, l112 = sch.get_loops(block=b71)
l113 = sch.fuse(l112, preserve_unit_iters=True)
sch.vectorize(loop=l113)
b114 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131 = sch.get_loops(block=b114)
b132 = sch.decompose_reduction(block=b114, loop=l116)
2024-04-29 04:00:20 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #89: GFLOPs: 231.9536. Time: 997.4473 us. Best GFLOPs: 340.7250
2024-04-29 04:00:20 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #90: GFLOPs: 107.5285. Time: 2151.6294 us. Best GFLOPs: 340.7250
2024-04-29 04:00:20 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #91: GFLOPs: 83.1224. Time: 2783.3827 us. Best GFLOPs: 340.7250
2024-04-29 04:00:20 [INFO] [task_scheduler.cc:121] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #92: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(14), T.int64(14), T.int64(128)), "float32"), p1: T.Buffer((T.int64(16), T.int64(2), T.int64(3), T.int64(3), T.int64(128), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(16)), "float32"), p3: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(16), T.int64(16), T.int64(128)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused in T.parallel(T.int64(28), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(8), T.int64(1), T.int64(2), T.int64(8), T.int64(1), T.int64(1), T.int64(14), T.int64(1), T.int64(1)):
                with T.block("conv2d_NCHWc_init"):
                    v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                    v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(14) * T.int64(8) + oc_chunk_2_init + oc_chunk_3_init)
                    v_oh = T.axis.spatial(T.int64(14), oh_2_init * T.int64(14) + oh_3_init)
                    v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(14) // T.int64(2) * T.int64(2) + ow_2_init + ow_3_init)
                    v_oc_block = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(2) * T.int64(8) + oc_block_2_init + oc_block_3_init)
                    T.reads()
                    T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                    T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                    conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
            for ic_0, kh_0 in T.grid(T.int64(32), T.int64(3)):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(14), T.int64(4)):
                    for ax4_fused in T.vectorized(T.int64(8)):
                        with T.block("data_pad"):
                            v_i0 = T.axis.spatial(T.int64(1), ax0)
                            v_i1 = T.axis.spatial(T.int64(2), ic_0 // T.int64(16) + ax1)
                            v_i2 = T.axis.spatial(T.int64(16), kh_0 + ax2)
                            v_i3 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(14) // T.int64(2) * T.int64(2) + ax3)
                            v_i4 = T.axis.spatial(T.int64(128), ic_0 % T.int64(16) * T.int64(8) + ax4_fused)
                            T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                            T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                            data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(15) and T.int64(1) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                for kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(1), T.int64(1), T.int64(8), T.int64(1), T.int64(2), T.int64(8), T.int64(8), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(14), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(14) * T.int64(8) + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(14), oh_2 * T.int64(14) + oh_3)
                        v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(14) // T.int64(2) * T.int64(2) + ow_2 + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(2) * T.int64(8) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(8) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(8), T.int64(14), T.int64(2)):
                for ax4_fused in T.vectorized(T.int64(8)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(14) * T.int64(8) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(14), ax2)
                        v_ax3 = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(14) // T.int64(2) * T.int64(2) + ax3)
                        v_ax4 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(2) * T.int64(8) + ax4_fused)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 1, 8, 1])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 1, 14])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 7, 2, 1])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[1, 2, 8, 1])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[32, 8])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[1, 3])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l50, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=11)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88 = sch.get_loops(block=b69)
l89 = sch.fuse(l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, preserve_unit_iters=True)
sch.parallel(loop=l89)
l90 = sch.fuse(l88, preserve_unit_iters=True)
sch.vectorize(loop=l90)
l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107 = sch.get_loops(block=b70)
l108 = sch.fuse(l91, preserve_unit_iters=True)
sch.parallel(loop=l108)
sch.annotate(block_or_loop=l108, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l108, ann_key="pragma_unroll_explicit", ann_val=1)
l109, l110, l111, l112, l113, l114 = sch.get_loops(block=b71)
l115 = sch.fuse(l114, preserve_unit_iters=True)
sch.vectorize(loop=l115)
b116 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133 = sch.get_loops(block=b116)
b134 = sch.decompose_reduction(block=b116, loop=l118)
2024-04-29 04:00:20 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #93: GFLOPs: 139.3353. Time: 1660.4655 us. Best GFLOPs: 340.7250
2024-04-29 04:00:20 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #94: GFLOPs: 156.4990. Time: 1478.3577 us. Best GFLOPs: 340.7250
2024-04-29 04:00:20 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #95: GFLOPs: 150.7042. Time: 1535.2032 us. Best GFLOPs: 340.7250
2024-04-29 04:00:20 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #96: GFLOPs: 79.6286. Time: 2905.5066 us. Best GFLOPs: 340.7250
2024-04-29 04:00:20 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #97: GFLOPs: 78.0646. Time: 2963.7200 us. Best GFLOPs: 340.7250
2024-04-29 04:00:20 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #98: GFLOPs: 57.6010. Time: 4016.6216 us. Best GFLOPs: 340.7250
2024-04-29 04:00:20 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #99: GFLOPs: 58.5093. Time: 3954.2708 us. Best GFLOPs: 340.7250
2024-04-29 04:00:20 [INFO] [task_scheduler.cc:121] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #100: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(14), T.int64(14), T.int64(128)), "float32"), p1: T.Buffer((T.int64(16), T.int64(2), T.int64(3), T.int64(3), T.int64(128), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(16)), "float32"), p3: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(16), T.int64(16), T.int64(128)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused in T.parallel(T.int64(28), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(14), T.int64(2), T.int64(1)):
                with T.block("conv2d_NCHWc_init"):
                    v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                    v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(14) * T.int64(8) + oc_chunk_2_init + oc_chunk_3_init)
                    v_oh = T.axis.spatial(T.int64(14), oh_2_init * T.int64(14) + oh_3_init)
                    v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(14) // T.int64(2) * T.int64(2) + ow_2_init * T.int64(2) + ow_3_init)
                    v_oc_block = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(2) * T.int64(8) + oc_block_2_init + oc_block_3_init)
                    T.reads()
                    T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                    T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                    conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
            for ic_0, kh_0 in T.grid(T.int64(16), T.int64(3)):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(14), T.int64(4)):
                    for ax4_fused in T.vectorized(T.int64(16)):
                        with T.block("data_pad"):
                            v_i0 = T.axis.spatial(T.int64(1), ax0)
                            v_i1 = T.axis.spatial(T.int64(2), ic_0 // T.int64(8) + ax1)
                            v_i2 = T.axis.spatial(T.int64(16), kh_0 + ax2)
                            v_i3 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(14) // T.int64(2) * T.int64(2) + ax3)
                            v_i4 = T.axis.spatial(T.int64(128), ic_0 % T.int64(8) * T.int64(16) + ax4_fused)
                            T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                            T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                            data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(15) and T.int64(1) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                for kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(1), T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(8), T.int64(16), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(14), T.int64(2), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(14) * T.int64(8) + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(14), oh_2 * T.int64(14) + oh_3)
                        v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(14) // T.int64(2) * T.int64(2) + ow_2 * T.int64(2) + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(2) * T.int64(8) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(16) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(8), T.int64(14), T.int64(2)):
                for ax4_fused in T.vectorized(T.int64(8)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(14) * T.int64(8) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(14), ax2)
                        v_ax3 = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(14) // T.int64(2) * T.int64(2) + ax3)
                        v_ax4 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(2) * T.int64(8) + ax4_fused)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 1, 8, 1])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 1, 14])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 7, 1, 2])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[1, 2, 8, 1])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[16, 16])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[1, 3])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l50, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=11)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88 = sch.get_loops(block=b69)
l89 = sch.fuse(l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, preserve_unit_iters=True)
sch.parallel(loop=l89)
l90 = sch.fuse(l88, preserve_unit_iters=True)
sch.vectorize(loop=l90)
l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107 = sch.get_loops(block=b70)
l108 = sch.fuse(l91, preserve_unit_iters=True)
sch.parallel(loop=l108)
sch.annotate(block_or_loop=l108, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l108, ann_key="pragma_unroll_explicit", ann_val=1)
l109, l110, l111, l112, l113, l114 = sch.get_loops(block=b71)
l115 = sch.fuse(l114, preserve_unit_iters=True)
sch.vectorize(loop=l115)
b116 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133 = sch.get_loops(block=b116)
b134 = sch.decompose_reduction(block=b116, loop=l118)
2024-04-29 04:00:20 [INFO] [task_scheduler.cc:121] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #101: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(14), T.int64(14), T.int64(128)), "float32"), p1: T.Buffer((T.int64(16), T.int64(2), T.int64(3), T.int64(3), T.int64(128), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(16)), "float32"), p3: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(16), T.int64(16), T.int64(128)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused in T.parallel(T.int64(56), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(2), T.int64(16), T.int64(4), T.int64(128)):
                with T.block("data_pad"):
                    v_i0, v_i1, v_i2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                    v_i3 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(14) // T.int64(2) * T.int64(2) + ax3)
                    v_i4 = T.axis.spatial(T.int64(128), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(15) and T.int64(1) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(1), T.int64(14), T.int64(1), T.int64(2), T.int64(1), T.int64(4), T.int64(1), T.int64(2)):
                for oc_block_3_fused_init in T.vectorized(T.int64(4)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(14) * T.int64(4) + oc_chunk_2_init * T.int64(4) + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(14), oh_2_init + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(14) // T.int64(2) * T.int64(2) + ow_2_init * T.int64(2) + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(2) * T.int64(8) + oc_block_2_init * T.int64(4) + oc_block_3_fused_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
            for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(256), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(14), T.int64(1), T.int64(2), T.int64(1), T.int64(3), T.int64(3), T.int64(1), T.int64(4), T.int64(1), T.int64(2)):
                for oc_block_3_fused in T.vectorized(T.int64(4)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(14) * T.int64(4) + oc_chunk_2 * T.int64(4) + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(14), oh_2 + oh_3)
                        v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(14) // T.int64(2) * T.int64(2) + ow_2 * T.int64(2) + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(2) * T.int64(8) + oc_block_2 * T.int64(4) + oc_block_3_fused)
                        v_ic = T.axis.reduce(T.int64(256), ic_0 + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(4), T.int64(14), T.int64(2)):
                for ax4_fused in T.vectorized(T.int64(8)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(14) * T.int64(4) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(14), ax2)
                        v_ax3 = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(14) // T.int64(2) * T.int64(2) + ax3)
                        v_ax4 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(2) * T.int64(8) + ax4_fused)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 4, 1, 4])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 14, 1])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 7, 1, 2])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[1, 2, 2, 4])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[256, 1])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[1, 3])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l50, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=9)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86 = sch.get_loops(block=b69)
l87 = sch.fuse(l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, preserve_unit_iters=True)
sch.parallel(loop=l87)
l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b70)
l105 = sch.fuse(l88, preserve_unit_iters=True)
sch.parallel(loop=l105)
l106 = sch.fuse(l104, preserve_unit_iters=True)
sch.vectorize(loop=l106)
sch.annotate(block_or_loop=l105, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l105, ann_key="pragma_unroll_explicit", ann_val=1)
l107, l108, l109, l110, l111, l112 = sch.get_loops(block=b71)
l113 = sch.fuse(l112, preserve_unit_iters=True)
sch.vectorize(loop=l113)
b114 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131 = sch.get_loops(block=b114)
b132 = sch.decompose_reduction(block=b114, loop=l116)
2024-04-29 04:00:20 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #102: GFLOPs: 91.4259. Time: 2530.5898 us. Best GFLOPs: 340.7250
2024-04-29 04:00:20 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #103: GFLOPs: 110.9605. Time: 2085.0801 us. Best GFLOPs: 340.7250
2024-04-29 04:00:20 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #104: GFLOPs: 188.3718. Time: 1228.2172 us. Best GFLOPs: 340.7250
2024-04-29 04:00:20 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #105: GFLOPs: 97.5256. Time: 2372.3168 us. Best GFLOPs: 340.7250
2024-04-29 04:00:20 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #106: GFLOPs: 205.2078. Time: 1127.4500 us. Best GFLOPs: 340.7250
2024-04-29 04:00:20 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #107: GFLOPs: 155.7368. Time: 1485.5930 us. Best GFLOPs: 340.7250
2024-04-29 04:00:20 [INFO] [task_scheduler.cc:121] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #108: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(14), T.int64(14), T.int64(128)), "float32"), p1: T.Buffer((T.int64(16), T.int64(2), T.int64(3), T.int64(3), T.int64(128), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(16)), "float32"), p3: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(16), T.int64(16), T.int64(128)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused in T.parallel(T.int64(28), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(8), T.int64(1), T.int64(2), T.int64(8), T.int64(1), T.int64(1), T.int64(14), T.int64(1), T.int64(1)):
                with T.block("conv2d_NCHWc_init"):
                    v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                    v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(14) * T.int64(8) + oc_chunk_2_init + oc_chunk_3_init)
                    v_oh = T.axis.spatial(T.int64(14), oh_2_init * T.int64(14) + oh_3_init)
                    v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(14) // T.int64(2) * T.int64(2) + ow_2_init + ow_3_init)
                    v_oc_block = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(2) * T.int64(8) + oc_block_2_init + oc_block_3_init)
                    T.reads()
                    T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                    T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                    conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
            for ic_0 in range(T.int64(8)):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(16), T.int64(4)):
                    for ax4_fused in T.vectorized(T.int64(32)):
                        with T.block("data_pad"):
                            v_i0 = T.axis.spatial(T.int64(1), ax0)
                            v_i1 = T.axis.spatial(T.int64(2), ic_0 // T.int64(4) + ax1)
                            v_i2 = T.axis.spatial(T.int64(16), ax2)
                            v_i3 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(14) // T.int64(2) * T.int64(2) + ax3)
                            v_i4 = T.axis.spatial(T.int64(128), ic_0 % T.int64(4) * T.int64(32) + ax4_fused)
                            T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                            T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                            data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(15) and T.int64(1) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                for kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(8), T.int64(1), T.int64(2), T.int64(8), T.int64(32), T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(14), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(14) * T.int64(8) + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(14), oh_2 * T.int64(14) + oh_3)
                        v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(14) // T.int64(2) * T.int64(2) + ow_2 + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(2) * T.int64(8) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(32) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(8), T.int64(14), T.int64(2)):
                for ax4_fused in T.vectorized(T.int64(8)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(14) * T.int64(8) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(14), ax2)
                        v_ax3 = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(14) // T.int64(2) * T.int64(2) + ax3)
                        v_ax4 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(2) * T.int64(8) + ax4_fused)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 1, 8, 1])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 1, 14])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 7, 2, 1])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[1, 2, 8, 1])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[8, 32])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[1, 3])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l50, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=10)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87 = sch.get_loops(block=b69)
l88 = sch.fuse(l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, preserve_unit_iters=True)
sch.parallel(loop=l88)
l89 = sch.fuse(l87, preserve_unit_iters=True)
sch.vectorize(loop=l89)
l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106 = sch.get_loops(block=b70)
l107 = sch.fuse(l90, preserve_unit_iters=True)
sch.parallel(loop=l107)
sch.annotate(block_or_loop=l107, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l107, ann_key="pragma_unroll_explicit", ann_val=1)
l108, l109, l110, l111, l112, l113 = sch.get_loops(block=b71)
l114 = sch.fuse(l113, preserve_unit_iters=True)
sch.vectorize(loop=l114)
b115 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132 = sch.get_loops(block=b115)
b133 = sch.decompose_reduction(block=b115, loop=l117)
2024-04-29 04:00:20 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #109: GFLOPs: 201.1602. Time: 1150.1359 us. Best GFLOPs: 340.7250
2024-04-29 04:00:20 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #110: GFLOPs: 163.3593. Time: 1416.2737 us. Best GFLOPs: 340.7250
2024-04-29 04:00:20 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #111: GFLOPs: 104.7221. Time: 2209.2902 us. Best GFLOPs: 340.7250
2024-04-29 04:00:20 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #112: GFLOPs: 79.6873. Time: 2903.3686 us. Best GFLOPs: 340.7250
2024-04-29 04:00:20 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #113: GFLOPs: 70.9923. Time: 3258.9677 us. Best GFLOPs: 340.7250
2024-04-29 04:00:20 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #114: GFLOPs: 89.4240. Time: 2587.2419 us. Best GFLOPs: 340.7250
2024-04-29 04:00:20 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #115: GFLOPs: 150.2239. Time: 1540.1111 us. Best GFLOPs: 340.7250
2024-04-29 04:00:20 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #116: GFLOPs: 78.1176. Time: 2961.7070 us. Best GFLOPs: 340.7250
2024-04-29 04:00:20 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #117: GFLOPs: 136.0083. Time: 1701.0834 us. Best GFLOPs: 340.7250
2024-04-29 04:00:20 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #118: GFLOPs: 157.2756. Time: 1471.0584 us. Best GFLOPs: 340.7250
2024-04-29 04:00:20 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #119: GFLOPs: 122.8966. Time: 1882.5706 us. Best GFLOPs: 340.7250
2024-04-29 04:00:20 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #120: GFLOPs: 135.6659. Time: 1705.3777 us. Best GFLOPs: 340.7250
2024-04-29 04:00:20 [INFO] [task_scheduler.cc:121] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #121: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(14), T.int64(14), T.int64(128)), "float32"), p1: T.Buffer((T.int64(16), T.int64(2), T.int64(3), T.int64(3), T.int64(128), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(16)), "float32"), p3: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(16), T.int64(16), T.int64(128)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused in T.parallel(T.int64(112), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(2), T.int64(16), T.int64(4), T.int64(128)):
                with T.block("data_pad"):
                    v_i0, v_i1, v_i2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                    v_i3 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(14) // T.int64(2) * T.int64(2) + ax3)
                    v_i4 = T.axis.spatial(T.int64(128), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(15) and T.int64(1) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(2), T.int64(14), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(2)):
                for oc_block_3_fused_init in T.vectorized(T.int64(4)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(14) * T.int64(2) + oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(14), oh_2_init + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(14) // T.int64(2) * T.int64(2) + ow_2_init * T.int64(2) + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(2) * T.int64(8) + oc_block_2_init * T.int64(4) + oc_block_3_fused_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
            for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(256), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(14), T.int64(1), T.int64(2), T.int64(1), T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(2)):
                for oc_block_3_fused in T.vectorized(T.int64(4)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(14) * T.int64(2) + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(14), oh_2 + oh_3)
                        v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(14) // T.int64(2) * T.int64(2) + ow_2 * T.int64(2) + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(2) * T.int64(8) + oc_block_2 * T.int64(4) + oc_block_3_fused)
                        v_ic = T.axis.reduce(T.int64(256), ic_0 + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(2), T.int64(14), T.int64(2)):
                for ax4_fused in T.vectorized(T.int64(8)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(14) * T.int64(2) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(14), ax2)
                        v_ax3 = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(14) // T.int64(2) * T.int64(2) + ax3)
                        v_ax4 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(2) * T.int64(8) + ax4_fused)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 4, 2, 1])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 14, 1])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 7, 1, 2])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[1, 2, 2, 4])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[256, 1])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[1, 3])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l50, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=9)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86 = sch.get_loops(block=b69)
l87 = sch.fuse(l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, preserve_unit_iters=True)
sch.parallel(loop=l87)
l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b70)
l105 = sch.fuse(l88, preserve_unit_iters=True)
sch.parallel(loop=l105)
l106 = sch.fuse(l104, preserve_unit_iters=True)
sch.vectorize(loop=l106)
sch.annotate(block_or_loop=l105, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l105, ann_key="pragma_unroll_explicit", ann_val=1)
l107, l108, l109, l110, l111, l112 = sch.get_loops(block=b71)
l113 = sch.fuse(l112, preserve_unit_iters=True)
sch.vectorize(loop=l113)
b114 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131 = sch.get_loops(block=b114)
b132 = sch.decompose_reduction(block=b114, loop=l116)
2024-04-29 04:00:20 [INFO] [task_scheduler.cc:121] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #122: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(14), T.int64(14), T.int64(128)), "float32"), p1: T.Buffer((T.int64(16), T.int64(2), T.int64(3), T.int64(3), T.int64(128), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(16)), "float32"), p3: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(16), T.int64(16), T.int64(128)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused in T.parallel(T.int64(112), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(2), T.int64(16), T.int64(4), T.int64(128)):
                with T.block("data_pad"):
                    v_i0, v_i1, v_i2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                    v_i3 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(14) // T.int64(2) * T.int64(2) + ax3)
                    v_i4 = T.axis.spatial(T.int64(128), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(15) and T.int64(1) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(2), T.int64(14), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(2)):
                for oc_block_3_fused_init in T.vectorized(T.int64(4)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(14) * T.int64(2) + oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(14), oh_2_init + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(14) // T.int64(2) * T.int64(2) + ow_2_init * T.int64(2) + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(2) * T.int64(8) + oc_block_2_init * T.int64(4) + oc_block_3_fused_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
            for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(256), T.int64(1), T.int64(3), T.int64(1), T.int64(2), T.int64(14), T.int64(1), T.int64(2), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2)):
                for oc_block_3_fused in T.vectorized(T.int64(4)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(14) * T.int64(2) + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(14), oh_2 + oh_3)
                        v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(14) // T.int64(2) * T.int64(2) + ow_2 * T.int64(2) + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(2) * T.int64(8) + oc_block_2 * T.int64(4) + oc_block_3_fused)
                        v_ic = T.axis.reduce(T.int64(256), ic_0 + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(2), T.int64(14), T.int64(2)):
                for ax4_fused in T.vectorized(T.int64(8)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(14) * T.int64(2) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(14), ax2)
                        v_ax3 = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(14) // T.int64(2) * T.int64(2) + ax3)
                        v_ax4 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(2) * T.int64(8) + ax4_fused)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 4, 2, 1])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 14, 1])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 7, 1, 2])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[1, 2, 2, 4])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[256, 1])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[3, 1])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l50, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=9)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86 = sch.get_loops(block=b69)
l87 = sch.fuse(l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, preserve_unit_iters=True)
sch.parallel(loop=l87)
l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b70)
l105 = sch.fuse(l88, preserve_unit_iters=True)
sch.parallel(loop=l105)
l106 = sch.fuse(l104, preserve_unit_iters=True)
sch.vectorize(loop=l106)
sch.annotate(block_or_loop=l105, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l105, ann_key="pragma_unroll_explicit", ann_val=1)
l107, l108, l109, l110, l111, l112 = sch.get_loops(block=b71)
l113 = sch.fuse(l112, preserve_unit_iters=True)
sch.vectorize(loop=l113)
b114 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131 = sch.get_loops(block=b114)
b132 = sch.decompose_reduction(block=b114, loop=l116)
2024-04-29 04:00:20 [INFO] [task_scheduler.cc:121] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #123: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(14), T.int64(14), T.int64(128)), "float32"), p1: T.Buffer((T.int64(16), T.int64(2), T.int64(3), T.int64(3), T.int64(128), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(16)), "float32"), p3: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(16), T.int64(16), T.int64(128)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused in T.parallel(T.int64(112), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(2), T.int64(16), T.int64(4), T.int64(128)):
                with T.block("data_pad"):
                    v_i0, v_i1, v_i2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                    v_i3 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(14) // T.int64(2) * T.int64(2) + ax3)
                    v_i4 = T.axis.spatial(T.int64(128), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(15) and T.int64(1) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(2), T.int64(14), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(2)):
                for oc_block_3_fused_init in T.vectorized(T.int64(4)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(14) * T.int64(2) + oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(14), oh_2_init + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(14) // T.int64(2) * T.int64(2) + ow_2_init * T.int64(2) + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(2) * T.int64(8) + oc_block_2_init * T.int64(4) + oc_block_3_fused_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
            for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(14), T.int64(1), T.int64(2), T.int64(64), T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(2)):
                for oc_block_3_fused in T.vectorized(T.int64(4)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(14) * T.int64(2) + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(14), oh_2 + oh_3)
                        v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(14) // T.int64(2) * T.int64(2) + ow_2 * T.int64(2) + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(2) * T.int64(8) + oc_block_2 * T.int64(4) + oc_block_3_fused)
                        v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(64) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(2), T.int64(14), T.int64(2)):
                for ax4_fused in T.vectorized(T.int64(8)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(14) * T.int64(2) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(14), ax2)
                        v_ax3 = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(14) // T.int64(2) * T.int64(2) + ax3)
                        v_ax4 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(2) * T.int64(8) + ax4_fused)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 4, 2, 1])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 14, 1])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 7, 1, 2])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[1, 2, 2, 4])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[4, 64])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[1, 3])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l50, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=9)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86 = sch.get_loops(block=b69)
l87 = sch.fuse(l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, preserve_unit_iters=True)
sch.parallel(loop=l87)
l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b70)
l105 = sch.fuse(l88, preserve_unit_iters=True)
sch.parallel(loop=l105)
l106 = sch.fuse(l104, preserve_unit_iters=True)
sch.vectorize(loop=l106)
sch.annotate(block_or_loop=l105, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l105, ann_key="pragma_unroll_explicit", ann_val=1)
l107, l108, l109, l110, l111, l112 = sch.get_loops(block=b71)
l113 = sch.fuse(l112, preserve_unit_iters=True)
sch.vectorize(loop=l113)
b114 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131 = sch.get_loops(block=b114)
b132 = sch.decompose_reduction(block=b114, loop=l116)
2024-04-29 04:00:20 [INFO] [task_scheduler.cc:121] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #124: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(14), T.int64(14), T.int64(128)), "float32"), p1: T.Buffer((T.int64(16), T.int64(2), T.int64(3), T.int64(3), T.int64(128), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(16)), "float32"), p3: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(16), T.int64(16), T.int64(128)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused in T.parallel(T.int64(112), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(2), T.int64(16), T.int64(4), T.int64(128)):
                with T.block("data_pad"):
                    v_i0, v_i1, v_i2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                    v_i3 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(14) // T.int64(2) * T.int64(2) + ax3)
                    v_i4 = T.axis.spatial(T.int64(128), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(15) and T.int64(1) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(2), T.int64(14), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(2)):
                for oc_block_3_fused_init in T.vectorized(T.int64(4)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(14) * T.int64(2) + oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(14), oh_2_init + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(14) // T.int64(2) * T.int64(2) + ow_2_init * T.int64(2) + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(2) * T.int64(8) + oc_block_2_init * T.int64(4) + oc_block_3_fused_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
            for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(4), T.int64(1), T.int64(3), T.int64(1), T.int64(2), T.int64(14), T.int64(1), T.int64(2), T.int64(64), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2)):
                for oc_block_3_fused in T.vectorized(T.int64(4)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(14) * T.int64(2) + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(14), oh_2 + oh_3)
                        v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(14) // T.int64(2) * T.int64(2) + ow_2 * T.int64(2) + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(2) * T.int64(8) + oc_block_2 * T.int64(4) + oc_block_3_fused)
                        v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(64) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(2), T.int64(14), T.int64(2)):
                for ax4_fused in T.vectorized(T.int64(8)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(14) * T.int64(2) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(14), ax2)
                        v_ax3 = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(14) // T.int64(2) * T.int64(2) + ax3)
                        v_ax4 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(2) * T.int64(8) + ax4_fused)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 4, 2, 1])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 14, 1])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 7, 1, 2])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[1, 2, 2, 4])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[4, 64])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[3, 1])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l50, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=9)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86 = sch.get_loops(block=b69)
l87 = sch.fuse(l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, preserve_unit_iters=True)
sch.parallel(loop=l87)
l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b70)
l105 = sch.fuse(l88, preserve_unit_iters=True)
sch.parallel(loop=l105)
l106 = sch.fuse(l104, preserve_unit_iters=True)
sch.vectorize(loop=l106)
sch.annotate(block_or_loop=l105, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l105, ann_key="pragma_unroll_explicit", ann_val=1)
l107, l108, l109, l110, l111, l112 = sch.get_loops(block=b71)
l113 = sch.fuse(l112, preserve_unit_iters=True)
sch.vectorize(loop=l113)
b114 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131 = sch.get_loops(block=b114)
b132 = sch.decompose_reduction(block=b114, loop=l116)
2024-04-29 04:00:20 [INFO] [task_scheduler.cc:121] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #125: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(14), T.int64(14), T.int64(128)), "float32"), p1: T.Buffer((T.int64(16), T.int64(2), T.int64(3), T.int64(3), T.int64(128), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(16)), "float32"), p3: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(16), T.int64(16), T.int64(128)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused in T.parallel(T.int64(112), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(2), T.int64(16), T.int64(4), T.int64(128)):
                with T.block("data_pad"):
                    v_i0, v_i1, v_i2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                    v_i3 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(14) // T.int64(2) * T.int64(2) + ax3)
                    v_i4 = T.axis.spatial(T.int64(128), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(15) and T.int64(1) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(2), T.int64(14), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(2)):
                for oc_block_3_fused_init in T.vectorized(T.int64(4)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(14) * T.int64(2) + oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(14), oh_2_init + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(14) // T.int64(2) * T.int64(2) + ow_2_init * T.int64(2) + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(2) * T.int64(8) + oc_block_2_init * T.int64(4) + oc_block_3_fused_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
            for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(8), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(14), T.int64(1), T.int64(2), T.int64(32), T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(2)):
                for oc_block_3_fused in T.vectorized(T.int64(4)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(14) * T.int64(2) + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(14), oh_2 + oh_3)
                        v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(14) // T.int64(2) * T.int64(2) + ow_2 * T.int64(2) + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(2) * T.int64(8) + oc_block_2 * T.int64(4) + oc_block_3_fused)
                        v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(32) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(2), T.int64(14), T.int64(2)):
                for ax4_fused in T.vectorized(T.int64(8)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(14) * T.int64(2) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(14), ax2)
                        v_ax3 = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(14) // T.int64(2) * T.int64(2) + ax3)
                        v_ax4 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(2) * T.int64(8) + ax4_fused)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 4, 2, 1])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 14, 1])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 7, 1, 2])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[1, 2, 2, 4])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[8, 32])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[1, 3])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l50, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=9)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86 = sch.get_loops(block=b69)
l87 = sch.fuse(l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, preserve_unit_iters=True)
sch.parallel(loop=l87)
l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b70)
l105 = sch.fuse(l88, preserve_unit_iters=True)
sch.parallel(loop=l105)
l106 = sch.fuse(l104, preserve_unit_iters=True)
sch.vectorize(loop=l106)
sch.annotate(block_or_loop=l105, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l105, ann_key="pragma_unroll_explicit", ann_val=1)
l107, l108, l109, l110, l111, l112 = sch.get_loops(block=b71)
l113 = sch.fuse(l112, preserve_unit_iters=True)
sch.vectorize(loop=l113)
b114 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131 = sch.get_loops(block=b114)
b132 = sch.decompose_reduction(block=b114, loop=l116)
2024-04-29 04:00:20 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #126: GFLOPs: 19.6138. Time: 11795.8766 us. Best GFLOPs: 340.7250
2024-04-29 04:00:20 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #127: GFLOPs: 12.4323. Time: 18609.7375 us. Best GFLOPs: 340.7250
2024-04-29 04:00:20 [INFO] [task_scheduler.cc:121] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #128: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(14), T.int64(14), T.int64(128)), "float32"), p1: T.Buffer((T.int64(16), T.int64(2), T.int64(3), T.int64(3), T.int64(128), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(16)), "float32"), p3: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(16), T.int64(16), T.int64(128)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused in T.parallel(T.int64(4), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(2), T.int64(16), T.int64(9), T.int64(128)):
                with T.block("data_pad"):
                    v_i0, v_i1, v_i2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                    v_i3 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(2) * T.int64(7) + ax3)
                    v_i4 = T.axis.spatial(T.int64(128), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(15) and T.int64(1) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(14), T.int64(7)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(8)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(16), oc_chunk_1 * T.int64(2) + oc_chunk_2_init + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(14), oh_1 * T.int64(14) + oh_2_init * T.int64(14) + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(2) * T.int64(7) + ow_1 * T.int64(7) + ow_2_init * T.int64(7) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(2) * T.int64(8) + oc_block_1 * T.int64(8) + oc_block_2_init * T.int64(8) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(32), T.int64(3), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(8), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(14), T.int64(7)):
                    for oc_block_3_fused in T.vectorized(T.int64(8)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(16), oc_chunk_1 * T.int64(2) + oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(14), oh_1 * T.int64(14) + oh_2 * T.int64(14) + oh_3)
                            v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(2) * T.int64(7) + ow_1 * T.int64(7) + ow_2 * T.int64(7) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(2) * T.int64(8) + oc_block_1 * T.int64(8) + oc_block_2 * T.int64(8) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(8) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
        for ax0_ax1_ax2_ax3_ax4_fused_0 in T.parallel(T.int64(784)):
            for ax0_ax1_ax2_ax3_ax4_fused_1 in T.vectorized(T.int64(64)):
                with T.block("T_relu"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) // T.int64(3136))
                    v_ax2 = T.axis.spatial(T.int64(14), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(3136) // T.int64(224))
                    v_ax3 = T.axis.spatial(T.int64(14), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(224) // T.int64(16))
                    v_ax4 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(16))
                    T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 8, 2, 1])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 1, 14])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[2, 1, 1, 7])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[2, 1, 1, 8])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[32, 8])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[1, 3])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=4)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80 = sch.get_loops(block=b68)
l81 = sch.fuse(l71, l72, l73, l74, l75, preserve_unit_iters=True)
sch.parallel(loop=l81)
l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l82, preserve_unit_iters=True)
sch.parallel(loop=l104)
l105 = sch.fuse(l103, preserve_unit_iters=True)
sch.vectorize(loop=l105)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l106, l107, l108, l109, l110 = sch.get_loops(block=b70)
l111 = sch.fuse(l106, l107, l108, l109, l110, preserve_unit_iters=True)
l112, l113 = sch.split(loop=l111, factors=[None, 64], preserve_unit_iters=True)
sch.parallel(loop=l112)
sch.vectorize(loop=l113)
b114 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136 = sch.get_loops(block=b114)
b137 = sch.decompose_reduction(block=b114, loop=l121)
2024-04-29 04:20:31 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 04:20:32 [INFO] [evolutionary_search.cc:715] Picked top 99 candidate(s) from database
2024-04-29 04:20:36 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3639cb8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x419b828)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x312c9f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x425e1d8)]: 0 failure(s)
2024-04-29 04:20:36 [INFO] [evolutionary_search.cc:723] Sampled 413 candidate(s)
2024-04-29 04:20:49 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3639cb8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x419b828)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x312c9f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x425e1d8)]: 0 failure(s)
2024-04-29 04:21:02 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3639cb8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x419b828)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x312c9f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x425e1d8)]: 0 failure(s)
2024-04-29 04:21:14 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3639cb8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x419b828)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x312c9f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x425e1d8)]: 0 failure(s)
2024-04-29 04:21:27 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3639cb8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x419b828)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x312c9f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x425e1d8)]: 0 failure(s)
2024-04-29 04:21:34 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9843  0.9843  0.9843  0.9843  0.9843  0.9843  0.9843  0.9843  0.9843  0.9843  0.9843  0.9796  0.9551  0.9551  0.9551  0.9503
[17 : 32]:	0.9226  0.9196  0.9134  0.9008  0.8968  0.8933  0.8903  0.8903  0.8748  0.8747  0.8741  0.8536  0.8412  0.8361  0.8357  0.8348
[33 : 48]:	0.8144  0.8031  0.8031  0.7930  0.7861  0.7861  0.7853  0.7853  0.7798  0.7769  0.7724  0.7724  0.7708  0.7634  0.7575  0.7575
[49 : 64]:	0.7422  0.7408  0.7380  0.7277  0.7271  0.7262  0.7247  0.7174  0.7109  0.7109  0.7012  0.6939  0.6913  0.6823  0.6815  0.6806
2024-04-29 04:21:34 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 04:21:34 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 04:23:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #129: GFLOPs: 190.7174. Time: 1213.1117 us. Best GFLOPs: 340.7250
2024-04-29 04:23:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #130: GFLOPs: 196.6448. Time: 1176.5455 us. Best GFLOPs: 340.7250
2024-04-29 04:23:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #131: GFLOPs: 216.1499. Time: 1070.3756 us. Best GFLOPs: 340.7250
2024-04-29 04:23:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #132: GFLOPs: 126.3008. Time: 1831.8301 us. Best GFLOPs: 340.7250
2024-04-29 04:23:08 [INFO] [task_scheduler.cc:121] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #133: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(14), T.int64(14), T.int64(128)), "float32"), p1: T.Buffer((T.int64(16), T.int64(2), T.int64(3), T.int64(3), T.int64(128), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(16)), "float32"), p3: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(16), T.int64(16), T.int64(128)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused in T.parallel(T.int64(112), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(2), T.int64(3), T.int64(16), T.int64(128)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(56) * T.int64(7) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(7) + ax2)
                    v_i3, v_i4 = T.axis.remap("SS", [ax3, ax4])
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(15) and T.int64(1) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(7), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(16)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(56) // T.int64(7) * T.int64(2) + oc_chunk_2_init + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(56) * T.int64(7) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(7) + oh_2_init + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(14), ow_1 * T.int64(14) + ow_2_init * T.int64(2) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_1 * T.int64(16) + oc_block_2_init * T.int64(16) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(64), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(7), T.int64(1), T.int64(4), T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(2)):
                    for oc_block_3_fused in T.vectorized(T.int64(16)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(56) // T.int64(7) * T.int64(2) + oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(56) * T.int64(7) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(7) + oh_2 + oh_3)
                            v_ow = T.axis.spatial(T.int64(14), ow_1 * T.int64(14) + ow_2 * T.int64(2) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_1 * T.int64(16) + oc_block_2 * T.int64(16) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(4) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(14)):
                    for ax4_fused in T.vectorized(T.int64(16)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(56) // T.int64(7) * T.int64(2) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(56) * T.int64(7) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(7) + ax2)
                            v_ax3, v_ax4 = T.axis.remap("SS", [ax3, ax4_fused])
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 8, 2, 1])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[2, 7, 1, 1])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 7, 2])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[1, 1, 1, 16])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[64, 4])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[1, 3])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l50, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=7)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b69)
l85 = sch.fuse(l72, l73, l74, l75, l76, l77, l78, l79, preserve_unit_iters=True)
sch.parallel(loop=l85)
l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b70)
l105 = sch.fuse(l86, preserve_unit_iters=True)
sch.parallel(loop=l105)
l106 = sch.fuse(l104, preserve_unit_iters=True)
sch.vectorize(loop=l106)
sch.annotate(block_or_loop=l105, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l105, ann_key="pragma_unroll_explicit", ann_val=1)
l107, l108, l109, l110, l111, l112, l113, l114 = sch.get_loops(block=b71)
l115 = sch.fuse(l114, preserve_unit_iters=True)
sch.vectorize(loop=l115)
b116 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135 = sch.get_loops(block=b116)
b136 = sch.decompose_reduction(block=b116, loop=l120)
2024-04-29 04:23:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #134: GFLOPs: 191.8622. Time: 1205.8733 us. Best GFLOPs: 340.7250
2024-04-29 04:23:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #135: GFLOPs: 152.6729. Time: 1515.4063 us. Best GFLOPs: 340.7250
2024-04-29 04:23:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #136: GFLOPs: 105.0381. Time: 2202.6434 us. Best GFLOPs: 340.7250
2024-04-29 04:23:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #137: GFLOPs: 166.6440. Time: 1388.3584 us. Best GFLOPs: 340.7250
2024-04-29 04:23:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #138: GFLOPs: 194.5539. Time: 1189.1898 us. Best GFLOPs: 340.7250
2024-04-29 04:23:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #139: GFLOPs: 172.8827. Time: 1338.2573 us. Best GFLOPs: 340.7250
2024-04-29 04:23:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #140: GFLOPs: 149.0033. Time: 1552.7271 us. Best GFLOPs: 340.7250
2024-04-29 04:23:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #141: GFLOPs: 346.3255. Time: 668.0464 us. Best GFLOPs: 346.3255
2024-04-29 04:23:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #142: GFLOPs: 196.8054. Time: 1175.5850 us. Best GFLOPs: 346.3255
2024-04-29 04:23:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #143: GFLOPs: 139.4187. Time: 1659.4733 us. Best GFLOPs: 346.3255
2024-04-29 04:23:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #144: GFLOPs: 151.6279. Time: 1525.8508 us. Best GFLOPs: 346.3255
2024-04-29 04:23:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #145: GFLOPs: 156.5309. Time: 1478.0562 us. Best GFLOPs: 346.3255
2024-04-29 04:23:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #146: GFLOPs: 157.1789. Time: 1471.9627 us. Best GFLOPs: 346.3255
2024-04-29 04:23:08 [INFO] [task_scheduler.cc:121] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #147: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(14), T.int64(14), T.int64(128)), "float32"), p1: T.Buffer((T.int64(16), T.int64(2), T.int64(3), T.int64(3), T.int64(128), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(16)), "float32"), p3: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(16), T.int64(16), T.int64(128)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused in T.parallel(T.int64(112), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(2), T.int64(3), T.int64(16), T.int64(128)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(56) * T.int64(7) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(7) + ax2)
                    v_i3, v_i4 = T.axis.remap("SS", [ax3, ax4])
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(15) and T.int64(1) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(7), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(16)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(56) // T.int64(7) * T.int64(2) + oc_chunk_2_init + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(56) * T.int64(7) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(7) + oh_2_init + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(14), ow_1 * T.int64(14) + ow_2_init * T.int64(2) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_1 * T.int64(16) + oc_block_2_init * T.int64(16) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(16), T.int64(3), T.int64(3), T.int64(1), T.int64(2), T.int64(1), T.int64(7), T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2)):
                    for oc_block_3_fused in T.vectorized(T.int64(16)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(56) // T.int64(7) * T.int64(2) + oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(56) * T.int64(7) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(7) + oh_2 + oh_3)
                            v_ow = T.axis.spatial(T.int64(14), ow_1 * T.int64(14) + ow_2 * T.int64(2) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_1 * T.int64(16) + oc_block_2 * T.int64(16) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(16) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(14)):
                    for ax4_fused in T.vectorized(T.int64(16)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(56) // T.int64(7) * T.int64(2) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(56) * T.int64(7) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(7) + ax2)
                            v_ax3, v_ax4 = T.axis.remap("SS", [ax3, ax4_fused])
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 8, 2, 1])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[2, 7, 1, 1])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 7, 2])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[1, 1, 1, 16])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[16, 16])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[3, 1])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l50, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=7)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b69)
l85 = sch.fuse(l72, l73, l74, l75, l76, l77, l78, l79, preserve_unit_iters=True)
sch.parallel(loop=l85)
l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b70)
l105 = sch.fuse(l86, preserve_unit_iters=True)
sch.parallel(loop=l105)
l106 = sch.fuse(l104, preserve_unit_iters=True)
sch.vectorize(loop=l106)
sch.annotate(block_or_loop=l105, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l105, ann_key="pragma_unroll_explicit", ann_val=1)
l107, l108, l109, l110, l111, l112, l113, l114 = sch.get_loops(block=b71)
l115 = sch.fuse(l114, preserve_unit_iters=True)
sch.vectorize(loop=l115)
b116 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135 = sch.get_loops(block=b116)
b136 = sch.decompose_reduction(block=b116, loop=l120)
2024-04-29 04:23:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #148: GFLOPs: 81.4725. Time: 2839.7492 us. Best GFLOPs: 346.3255
2024-04-29 04:23:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #149: GFLOPs: 191.0318. Time: 1211.1154 us. Best GFLOPs: 346.3255
2024-04-29 04:23:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #150: GFLOPs: 140.5132. Time: 1646.5471 us. Best GFLOPs: 346.3255
2024-04-29 04:23:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #151: GFLOPs: 159.1649. Time: 1453.5966 us. Best GFLOPs: 346.3255
2024-04-29 04:23:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #152: GFLOPs: 114.8121. Time: 2015.1325 us. Best GFLOPs: 346.3255
2024-04-29 04:23:08 [INFO] [task_scheduler.cc:121] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #153: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(14), T.int64(14), T.int64(128)), "float32"), p1: T.Buffer((T.int64(16), T.int64(2), T.int64(3), T.int64(3), T.int64(128), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(16)), "float32"), p3: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(16), T.int64(16), T.int64(128)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused in T.parallel(T.int64(112), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(2), T.int64(3), T.int64(16), T.int64(128)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(56) * T.int64(7) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(7) + ax2)
                    v_i3, v_i4 = T.axis.remap("SS", [ax3, ax4])
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(15) and T.int64(1) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(7), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(16)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(56) // T.int64(7) * T.int64(2) + oc_chunk_2_init + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(56) * T.int64(7) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(7) + oh_2_init + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(14), ow_1 * T.int64(14) + ow_2_init * T.int64(2) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_1 * T.int64(16) + oc_block_2_init * T.int64(16) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(8), T.int64(3), T.int64(3), T.int64(1), T.int64(2), T.int64(1), T.int64(7), T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2)):
                    for oc_block_3_fused in T.vectorized(T.int64(16)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(56) // T.int64(7) * T.int64(2) + oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(56) * T.int64(7) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(7) + oh_2 + oh_3)
                            v_ow = T.axis.spatial(T.int64(14), ow_1 * T.int64(14) + ow_2 * T.int64(2) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_1 * T.int64(16) + oc_block_2 * T.int64(16) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(32) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(14)):
                    for ax4_fused in T.vectorized(T.int64(16)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(56) // T.int64(7) * T.int64(2) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(56) * T.int64(7) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(7) + ax2)
                            v_ax3, v_ax4 = T.axis.remap("SS", [ax3, ax4_fused])
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 8, 2, 1])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[2, 7, 1, 1])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 7, 2])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[1, 1, 1, 16])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[8, 32])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[3, 1])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l50, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=7)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b69)
l85 = sch.fuse(l72, l73, l74, l75, l76, l77, l78, l79, preserve_unit_iters=True)
sch.parallel(loop=l85)
l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b70)
l105 = sch.fuse(l86, preserve_unit_iters=True)
sch.parallel(loop=l105)
l106 = sch.fuse(l104, preserve_unit_iters=True)
sch.vectorize(loop=l106)
sch.annotate(block_or_loop=l105, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l105, ann_key="pragma_unroll_explicit", ann_val=1)
l107, l108, l109, l110, l111, l112, l113, l114 = sch.get_loops(block=b71)
l115 = sch.fuse(l114, preserve_unit_iters=True)
sch.vectorize(loop=l115)
b116 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135 = sch.get_loops(block=b116)
b136 = sch.decompose_reduction(block=b116, loop=l120)
2024-04-29 04:23:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #154: GFLOPs: 193.0596. Time: 1198.3943 us. Best GFLOPs: 346.3255
2024-04-29 04:23:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #155: GFLOPs: 152.9087. Time: 1513.0700 us. Best GFLOPs: 346.3255
2024-04-29 04:23:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #156: GFLOPs: 132.2893. Time: 1748.9060 us. Best GFLOPs: 346.3255
2024-04-29 04:23:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #157: GFLOPs: 132.9585. Time: 1740.1029 us. Best GFLOPs: 346.3255
2024-04-29 04:23:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #158: GFLOPs: 137.1627. Time: 1686.7671 us. Best GFLOPs: 346.3255
2024-04-29 04:23:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #159: GFLOPs: 80.5696. Time: 2871.5752 us. Best GFLOPs: 346.3255
2024-04-29 04:23:08 [INFO] [task_scheduler.cc:121] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #160: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(14), T.int64(14), T.int64(128)), "float32"), p1: T.Buffer((T.int64(16), T.int64(2), T.int64(3), T.int64(3), T.int64(128), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(16)), "float32"), p3: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(16), T.int64(16), T.int64(128)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused in T.parallel(T.int64(224), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(2), T.int64(3), T.int64(16), T.int64(128)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(112) // T.int64(56) * T.int64(7) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(7) + ax2)
                    v_i3, v_i4 = T.axis.remap("SS", [ax3, ax4])
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(15) and T.int64(1) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(16)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(112) * T.int64(8) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(56) // T.int64(7) + oc_chunk_2_init + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(112) // T.int64(56) * T.int64(7) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(7) + oh_2_init + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(14), ow_1 * T.int64(14) + ow_2_init * T.int64(2) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_1 * T.int64(16) + oc_block_2_init * T.int64(16) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(64), T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2)):
                    for oc_block_3_fused in T.vectorized(T.int64(16)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(112) * T.int64(8) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(56) // T.int64(7) + oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(112) // T.int64(56) * T.int64(7) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(7) + oh_2 + oh_3)
                            v_ow = T.axis.spatial(T.int64(14), ow_1 * T.int64(14) + ow_2 * T.int64(2) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_1 * T.int64(16) + oc_block_2 * T.int64(16) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(4) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(14)):
                    for ax4_fused in T.vectorized(T.int64(16)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(112) * T.int64(8) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(56) // T.int64(7) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(112) // T.int64(56) * T.int64(7) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(7) + ax2)
                            v_ax3, v_ax4 = T.axis.remap("SS", [ax3, ax4_fused])
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 8, 1, 1])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[2, 7, 1, 1])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 7, 2])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[1, 1, 1, 16])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[64, 4])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[3, 1])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l50, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=7)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b69)
l85 = sch.fuse(l72, l73, l74, l75, l76, l77, l78, l79, preserve_unit_iters=True)
sch.parallel(loop=l85)
l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b70)
l105 = sch.fuse(l86, preserve_unit_iters=True)
sch.parallel(loop=l105)
l106 = sch.fuse(l104, preserve_unit_iters=True)
sch.vectorize(loop=l106)
sch.annotate(block_or_loop=l105, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l105, ann_key="pragma_unroll_explicit", ann_val=1)
l107, l108, l109, l110, l111, l112, l113, l114 = sch.get_loops(block=b71)
l115 = sch.fuse(l114, preserve_unit_iters=True)
sch.vectorize(loop=l115)
b116 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135 = sch.get_loops(block=b116)
b136 = sch.decompose_reduction(block=b116, loop=l120)
2024-04-29 04:23:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #161: GFLOPs: 67.5416. Time: 3425.4650 us. Best GFLOPs: 346.3255
2024-04-29 04:23:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #162: GFLOPs: 191.6792. Time: 1207.0249 us. Best GFLOPs: 346.3255
2024-04-29 04:23:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #163: GFLOPs: 200.8224. Time: 1152.0704 us. Best GFLOPs: 346.3255
2024-04-29 04:23:08 [INFO] [task_scheduler.cc:121] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #164: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(14), T.int64(14), T.int64(128)), "float32"), p1: T.Buffer((T.int64(16), T.int64(2), T.int64(3), T.int64(3), T.int64(128), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(16)), "float32"), p3: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(16), T.int64(16), T.int64(128)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused in T.parallel(T.int64(224), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(2), T.int64(3), T.int64(16), T.int64(128)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(112) // T.int64(56) * T.int64(7) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(7) + ax2)
                    v_i3, v_i4 = T.axis.remap("SS", [ax3, ax4])
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(15) and T.int64(1) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(16)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(112) * T.int64(8) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(56) // T.int64(7) + oc_chunk_2_init + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(112) // T.int64(56) * T.int64(7) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(7) + oh_2_init + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(14), ow_1 * T.int64(14) + ow_2_init * T.int64(2) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_1 * T.int64(16) + oc_block_2_init * T.int64(16) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(64), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(4), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2)):
                    for oc_block_3_fused in T.vectorized(T.int64(16)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(112) * T.int64(8) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(56) // T.int64(7) + oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(112) // T.int64(56) * T.int64(7) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(7) + oh_2 + oh_3)
                            v_ow = T.axis.spatial(T.int64(14), ow_1 * T.int64(14) + ow_2 * T.int64(2) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_1 * T.int64(16) + oc_block_2 * T.int64(16) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(4) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(14)):
                    for ax4_fused in T.vectorized(T.int64(16)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(112) * T.int64(8) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(56) // T.int64(7) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(112) // T.int64(56) * T.int64(7) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(7) + ax2)
                            v_ax3, v_ax4 = T.axis.remap("SS", [ax3, ax4_fused])
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 8, 1, 1])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[2, 7, 1, 1])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 7, 2])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[1, 1, 1, 16])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[64, 4])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[3, 1])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l50, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=7)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b69)
l85 = sch.fuse(l72, l73, l74, l75, l76, l77, l78, l79, preserve_unit_iters=True)
sch.parallel(loop=l85)
l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b70)
l105 = sch.fuse(l86, preserve_unit_iters=True)
sch.parallel(loop=l105)
l106 = sch.fuse(l104, preserve_unit_iters=True)
sch.vectorize(loop=l106)
sch.annotate(block_or_loop=l105, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l105, ann_key="pragma_unroll_explicit", ann_val=1)
l107, l108, l109, l110, l111, l112, l113, l114 = sch.get_loops(block=b71)
l115 = sch.fuse(l114, preserve_unit_iters=True)
sch.vectorize(loop=l115)
b116 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135 = sch.get_loops(block=b116)
b136 = sch.decompose_reduction(block=b116, loop=l120)
2024-04-29 04:23:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #165: GFLOPs: 186.0323. Time: 1243.6629 us. Best GFLOPs: 346.3255
2024-04-29 04:23:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #166: GFLOPs: 214.2526. Time: 1079.8540 us. Best GFLOPs: 346.3255
2024-04-29 04:23:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #167: GFLOPs: 151.1687. Time: 1530.4861 us. Best GFLOPs: 346.3255
2024-04-29 04:23:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #168: GFLOPs: 132.2414. Time: 1749.5387 us. Best GFLOPs: 346.3255
2024-04-29 04:23:08 [INFO] [task_scheduler.cc:121] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #169: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(14), T.int64(14), T.int64(128)), "float32"), p1: T.Buffer((T.int64(16), T.int64(2), T.int64(3), T.int64(3), T.int64(128), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(16)), "float32"), p3: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(16), T.int64(16), T.int64(128)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused in T.parallel(T.int64(224), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(2), T.int64(16), T.int64(3), T.int64(128)):
                with T.block("data_pad"):
                    v_i0, v_i1, v_i2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                    v_i3 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(14) + ax3)
                    v_i4 = T.axis.spatial(T.int64(128), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(15) and T.int64(1) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oc_block_1 in range(T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(16)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(14) + oc_chunk_2_init + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(14), oh_2_init * T.int64(2) + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(14) + ow_2_init + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_1 * T.int64(16) + oc_block_2_init * T.int64(16) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(64), T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1)):
                    for oc_block_3_fused in T.vectorized(T.int64(16)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(14) + oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(14), oh_2 * T.int64(2) + oh_3)
                            v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(14) + ow_2 + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_1 * T.int64(16) + oc_block_2 * T.int64(16) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(4) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
                for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(1), T.int64(14)):
                    for ax3_ax4_fused in T.vectorized(T.int64(16)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(14) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(14), ax2)
                            v_ax3 = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(14))
                            v_ax4 = T.axis.spatial(T.int64(16), ax3_ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[4, 4, 1, 1])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 7, 2])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 14, 1, 1])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[1, 1, 1, 16])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[64, 4])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[3, 1])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l50, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=8)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85 = sch.get_loops(block=b69)
l86 = sch.fuse(l72, l73, l74, l75, l76, l77, l78, l79, l80, preserve_unit_iters=True)
sch.parallel(loop=l86)
l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b70)
l105 = sch.fuse(l87, preserve_unit_iters=True)
sch.parallel(loop=l105)
l106 = sch.fuse(l104, preserve_unit_iters=True)
sch.vectorize(loop=l106)
sch.annotate(block_or_loop=l105, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l105, ann_key="pragma_unroll_explicit", ann_val=1)
l107, l108, l109, l110, l111, l112, l113 = sch.get_loops(block=b71)
l114 = sch.fuse(l112, l113, preserve_unit_iters=True)
sch.vectorize(loop=l114)
b115 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133 = sch.get_loops(block=b115)
b134 = sch.decompose_reduction(block=b115, loop=l118)
2024-04-29 04:23:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #170: GFLOPs: 132.8473. Time: 1741.5598 us. Best GFLOPs: 346.3255
2024-04-29 04:23:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #171: GFLOPs: 122.7328. Time: 1885.0825 us. Best GFLOPs: 346.3255
2024-04-29 04:23:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #172: GFLOPs: 145.1152. Time: 1594.3300 us. Best GFLOPs: 346.3255
2024-04-29 04:23:08 [INFO] [task_scheduler.cc:121] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #173: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(14), T.int64(14), T.int64(128)), "float32"), p1: T.Buffer((T.int64(16), T.int64(2), T.int64(3), T.int64(3), T.int64(128), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(16)), "float32"), p3: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(16), T.int64(16), T.int64(128)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused in T.parallel(T.int64(112), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(2), T.int64(3), T.int64(16), T.int64(128)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(56) * T.int64(7) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(7) + ax2)
                    v_i3, v_i4 = T.axis.remap("SS", [ax3, ax4])
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(15) and T.int64(1) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(7), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(2)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(8)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(56) // T.int64(7) * T.int64(2) + oc_chunk_2_init + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(56) * T.int64(7) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(7) + oh_2_init + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(14), ow_1 * T.int64(14) + ow_2_init * T.int64(2) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_1 * T.int64(16) + oc_block_2_init * T.int64(8) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(4), T.int64(3), T.int64(3), T.int64(1), T.int64(2), T.int64(1), T.int64(7), T.int64(2), T.int64(64), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2)):
                    for oc_block_3_fused in T.vectorized(T.int64(8)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(56) // T.int64(7) * T.int64(2) + oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(56) * T.int64(7) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(7) + oh_2 + oh_3)
                            v_ow = T.axis.spatial(T.int64(14), ow_1 * T.int64(14) + ow_2 * T.int64(2) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_1 * T.int64(16) + oc_block_2 * T.int64(8) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(64) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(14)):
                    for ax4_fused in T.vectorized(T.int64(16)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(56) // T.int64(7) * T.int64(2) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(56) * T.int64(7) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(7) + ax2)
                            v_ax3, v_ax4 = T.axis.remap("SS", [ax3, ax4_fused])
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 8, 2, 1])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[2, 7, 1, 1])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 7, 2])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[1, 1, 2, 8])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[4, 64])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[3, 1])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l50, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=7)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b69)
l85 = sch.fuse(l72, l73, l74, l75, l76, l77, l78, l79, preserve_unit_iters=True)
sch.parallel(loop=l85)
l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b70)
l105 = sch.fuse(l86, preserve_unit_iters=True)
sch.parallel(loop=l105)
l106 = sch.fuse(l104, preserve_unit_iters=True)
sch.vectorize(loop=l106)
sch.annotate(block_or_loop=l105, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l105, ann_key="pragma_unroll_explicit", ann_val=1)
l107, l108, l109, l110, l111, l112, l113, l114 = sch.get_loops(block=b71)
l115 = sch.fuse(l114, preserve_unit_iters=True)
sch.vectorize(loop=l115)
b116 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135 = sch.get_loops(block=b116)
b136 = sch.decompose_reduction(block=b116, loop=l120)
2024-04-29 04:23:08 [INFO] [task_scheduler.cc:121] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #174: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(14), T.int64(14), T.int64(128)), "float32"), p1: T.Buffer((T.int64(16), T.int64(2), T.int64(3), T.int64(3), T.int64(128), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(16)), "float32"), p3: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(16), T.int64(16), T.int64(128)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused in T.parallel(T.int64(112), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(2), T.int64(3), T.int64(16), T.int64(128)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(56) * T.int64(7) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(7) + ax2)
                    v_i3, v_i4 = T.axis.remap("SS", [ax3, ax4])
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(15) and T.int64(1) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(2)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(16)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(56) // T.int64(7) * T.int64(2) + oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(56) * T.int64(7) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(7) + oh_2_init + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(14), ow_1 * T.int64(14) + ow_2_init * T.int64(2) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_1 * T.int64(16) + oc_block_2_init * T.int64(16) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(16), T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(2)):
                    for oc_block_3_fused in T.vectorized(T.int64(16)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(56) // T.int64(7) * T.int64(2) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(56) * T.int64(7) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(7) + oh_2 + oh_3)
                            v_ow = T.axis.spatial(T.int64(14), ow_1 * T.int64(14) + ow_2 * T.int64(2) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_1 * T.int64(16) + oc_block_2 * T.int64(16) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(16) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(14)):
                    for ax4_fused in T.vectorized(T.int64(16)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(56) // T.int64(7) * T.int64(2) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(56) * T.int64(7) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(7) + ax2)
                            v_ax3, v_ax4 = T.axis.remap("SS", [ax3, ax4_fused])
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 8, 1, 2])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[2, 7, 1, 1])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 7, 2])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[1, 1, 1, 16])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[16, 16])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[3, 1])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l50, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=7)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b69)
l85 = sch.fuse(l72, l73, l74, l75, l76, l77, l78, l79, preserve_unit_iters=True)
sch.parallel(loop=l85)
l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b70)
l105 = sch.fuse(l86, preserve_unit_iters=True)
sch.parallel(loop=l105)
l106 = sch.fuse(l104, preserve_unit_iters=True)
sch.vectorize(loop=l106)
sch.annotate(block_or_loop=l105, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l105, ann_key="pragma_unroll_explicit", ann_val=1)
l107, l108, l109, l110, l111, l112, l113, l114 = sch.get_loops(block=b71)
l115 = sch.fuse(l114, preserve_unit_iters=True)
sch.vectorize(loop=l115)
b116 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135 = sch.get_loops(block=b116)
b136 = sch.decompose_reduction(block=b116, loop=l120)
2024-04-29 04:23:08 [INFO] [task_scheduler.cc:121] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #175: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(14), T.int64(14), T.int64(128)), "float32"), p1: T.Buffer((T.int64(16), T.int64(2), T.int64(3), T.int64(3), T.int64(128), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(16)), "float32"), p3: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(16), T.int64(16), T.int64(128)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused in T.parallel(T.int64(112), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(2), T.int64(3), T.int64(16), T.int64(128)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(56) * T.int64(7) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(7) + ax2)
                    v_i3, v_i4 = T.axis.remap("SS", [ax3, ax4])
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(15) and T.int64(1) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(7), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(2)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(8)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(56) // T.int64(7) * T.int64(2) + oc_chunk_2_init + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(56) * T.int64(7) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(7) + oh_2_init + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(14), ow_1 * T.int64(14) + ow_2_init * T.int64(2) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_1 * T.int64(16) + oc_block_2_init * T.int64(8) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(4), T.int64(3), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(7), T.int64(2), T.int64(64), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(2)):
                    for oc_block_3_fused in T.vectorized(T.int64(8)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(56) // T.int64(7) * T.int64(2) + oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(56) * T.int64(7) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(7) + oh_2 + oh_3)
                            v_ow = T.axis.spatial(T.int64(14), ow_1 * T.int64(14) + ow_2 * T.int64(2) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_1 * T.int64(16) + oc_block_2 * T.int64(8) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(64) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(14)):
                    for ax4_fused in T.vectorized(T.int64(16)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(56) // T.int64(7) * T.int64(2) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(56) * T.int64(7) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(7) + ax2)
                            v_ax3, v_ax4 = T.axis.remap("SS", [ax3, ax4_fused])
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 8, 2, 1])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[2, 7, 1, 1])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 7, 2])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[1, 1, 2, 8])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[4, 64])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[1, 3])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l50, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=7)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b69)
l85 = sch.fuse(l72, l73, l74, l75, l76, l77, l78, l79, preserve_unit_iters=True)
sch.parallel(loop=l85)
l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b70)
l105 = sch.fuse(l86, preserve_unit_iters=True)
sch.parallel(loop=l105)
l106 = sch.fuse(l104, preserve_unit_iters=True)
sch.vectorize(loop=l106)
sch.annotate(block_or_loop=l105, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l105, ann_key="pragma_unroll_explicit", ann_val=1)
l107, l108, l109, l110, l111, l112, l113, l114 = sch.get_loops(block=b71)
l115 = sch.fuse(l114, preserve_unit_iters=True)
sch.vectorize(loop=l115)
b116 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135 = sch.get_loops(block=b116)
b136 = sch.decompose_reduction(block=b116, loop=l120)
2024-04-29 04:23:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #176: GFLOPs: 188.9378. Time: 1224.5383 us. Best GFLOPs: 346.3255
2024-04-29 04:23:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #177: GFLOPs: 160.5648. Time: 1440.9231 us. Best GFLOPs: 346.3255
2024-04-29 04:23:08 [INFO] [task_scheduler.cc:121] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #178: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(14), T.int64(14), T.int64(128)), "float32"), p1: T.Buffer((T.int64(16), T.int64(2), T.int64(3), T.int64(3), T.int64(128), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(16)), "float32"), p3: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(16), T.int64(16), T.int64(128)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused in T.parallel(T.int64(112), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(2), T.int64(3), T.int64(16), T.int64(128)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(56) * T.int64(7) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(7) + ax2)
                    v_i3, v_i4 = T.axis.remap("SS", [ax3, ax4])
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(15) and T.int64(1) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(2)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(7), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(8)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(56) // T.int64(7) * T.int64(2) + oc_chunk_2_init + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(56) * T.int64(7) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(7) + oh_2_init + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(14), ow_1 * T.int64(14) + ow_2_init * T.int64(2) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_1 * T.int64(8) + oc_block_2_init * T.int64(8) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(8), T.int64(3), T.int64(3), T.int64(1), T.int64(2), T.int64(1), T.int64(7), T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2)):
                    for oc_block_3_fused in T.vectorized(T.int64(8)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(56) // T.int64(7) * T.int64(2) + oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(56) * T.int64(7) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(7) + oh_2 + oh_3)
                            v_ow = T.axis.spatial(T.int64(14), ow_1 * T.int64(14) + ow_2 * T.int64(2) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_1 * T.int64(8) + oc_block_2 * T.int64(8) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(32) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(14)):
                    for ax4_fused in T.vectorized(T.int64(8)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(56) // T.int64(7) * T.int64(2) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(56) * T.int64(7) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(7) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(14), ax3)
                            v_ax4 = T.axis.spatial(T.int64(16), oc_block_1 * T.int64(8) + ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 8, 2, 1])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[2, 7, 1, 1])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 7, 2])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[1, 2, 1, 8])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[8, 32])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[3, 1])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l50, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=7)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b69)
l85 = sch.fuse(l72, l73, l74, l75, l76, l77, l78, l79, preserve_unit_iters=True)
sch.parallel(loop=l85)
l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b70)
l105 = sch.fuse(l86, preserve_unit_iters=True)
sch.parallel(loop=l105)
l106 = sch.fuse(l104, preserve_unit_iters=True)
sch.vectorize(loop=l106)
sch.annotate(block_or_loop=l105, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l105, ann_key="pragma_unroll_explicit", ann_val=1)
l107, l108, l109, l110, l111, l112, l113, l114 = sch.get_loops(block=b71)
l115 = sch.fuse(l114, preserve_unit_iters=True)
sch.vectorize(loop=l115)
b116 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135 = sch.get_loops(block=b116)
b136 = sch.decompose_reduction(block=b116, loop=l120)
2024-04-29 04:23:08 [INFO] [task_scheduler.cc:121] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #179: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(14), T.int64(14), T.int64(128)), "float32"), p1: T.Buffer((T.int64(16), T.int64(2), T.int64(3), T.int64(3), T.int64(128), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(16)), "float32"), p3: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(16), T.int64(16), T.int64(128)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused in T.parallel(T.int64(224), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(2), T.int64(16), T.int64(3), T.int64(128)):
                with T.block("data_pad"):
                    v_i0, v_i1, v_i2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                    v_i3 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(14) + ax3)
                    v_i4 = T.axis.spatial(T.int64(128), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(15) and T.int64(1) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oc_block_1 in range(T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(16)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(14) + oc_chunk_2_init + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(14), oh_2_init * T.int64(2) + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(14) + ow_2_init + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_1 * T.int64(16) + oc_block_2_init * T.int64(16) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(64), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(1), T.int64(4), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1)):
                    for oc_block_3_fused in T.vectorized(T.int64(16)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(14) + oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(14), oh_2 * T.int64(2) + oh_3)
                            v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(14) + ow_2 + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_1 * T.int64(16) + oc_block_2 * T.int64(16) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(4) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
                for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(1), T.int64(14)):
                    for ax3_ax4_fused in T.vectorized(T.int64(16)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(14) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(14), ax2)
                            v_ax3 = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(14))
                            v_ax4 = T.axis.spatial(T.int64(16), ax3_ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[4, 4, 1, 1])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 7, 2])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 14, 1, 1])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[1, 1, 1, 16])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[64, 4])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[3, 1])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l50, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=8)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85 = sch.get_loops(block=b69)
l86 = sch.fuse(l72, l73, l74, l75, l76, l77, l78, l79, l80, preserve_unit_iters=True)
sch.parallel(loop=l86)
l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b70)
l105 = sch.fuse(l87, preserve_unit_iters=True)
sch.parallel(loop=l105)
l106 = sch.fuse(l104, preserve_unit_iters=True)
sch.vectorize(loop=l106)
sch.annotate(block_or_loop=l105, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l105, ann_key="pragma_unroll_explicit", ann_val=1)
l107, l108, l109, l110, l111, l112, l113 = sch.get_loops(block=b71)
l114 = sch.fuse(l112, l113, preserve_unit_iters=True)
sch.vectorize(loop=l114)
b115 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133 = sch.get_loops(block=b115)
b134 = sch.decompose_reduction(block=b115, loop=l118)
2024-04-29 04:23:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #180: GFLOPs: 116.7698. Time: 1981.3477 us. Best GFLOPs: 346.3255
2024-04-29 04:23:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #181: GFLOPs: 150.1471. Time: 1540.8995 us. Best GFLOPs: 346.3255
2024-04-29 04:23:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #182: GFLOPs: 115.2796. Time: 2006.9593 us. Best GFLOPs: 346.3255
2024-04-29 04:23:08 [INFO] [task_scheduler.cc:121] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #183: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(14), T.int64(14), T.int64(128)), "float32"), p1: T.Buffer((T.int64(16), T.int64(2), T.int64(3), T.int64(3), T.int64(128), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(16)), "float32"), p3: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(16), T.int64(16), T.int64(128)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused in T.parallel(T.int64(112), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(2), T.int64(3), T.int64(16), T.int64(128)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(56) * T.int64(7) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(7) + ax2)
                    v_i3, v_i4 = T.axis.remap("SS", [ax3, ax4])
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(15) and T.int64(1) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(2)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(16)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(56) // T.int64(7) * T.int64(2) + oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(56) * T.int64(7) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(7) + oh_2_init + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(14), ow_1 * T.int64(14) + ow_2_init * T.int64(2) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_1 * T.int64(16) + oc_block_2_init * T.int64(16) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(4), T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(64), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(2)):
                    for oc_block_3_fused in T.vectorized(T.int64(16)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(56) // T.int64(7) * T.int64(2) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(56) * T.int64(7) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(7) + oh_2 + oh_3)
                            v_ow = T.axis.spatial(T.int64(14), ow_1 * T.int64(14) + ow_2 * T.int64(2) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_1 * T.int64(16) + oc_block_2 * T.int64(16) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(64) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(14)):
                    for ax4_fused in T.vectorized(T.int64(16)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(56) // T.int64(7) * T.int64(2) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(56) * T.int64(7) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(7) + ax2)
                            v_ax3, v_ax4 = T.axis.remap("SS", [ax3, ax4_fused])
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 8, 1, 2])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[2, 7, 1, 1])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 7, 2])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[1, 1, 1, 16])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[4, 64])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[3, 1])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l50, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=7)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b69)
l85 = sch.fuse(l72, l73, l74, l75, l76, l77, l78, l79, preserve_unit_iters=True)
sch.parallel(loop=l85)
l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b70)
l105 = sch.fuse(l86, preserve_unit_iters=True)
sch.parallel(loop=l105)
l106 = sch.fuse(l104, preserve_unit_iters=True)
sch.vectorize(loop=l106)
sch.annotate(block_or_loop=l105, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l105, ann_key="pragma_unroll_explicit", ann_val=1)
l107, l108, l109, l110, l111, l112, l113, l114 = sch.get_loops(block=b71)
l115 = sch.fuse(l114, preserve_unit_iters=True)
sch.vectorize(loop=l115)
b116 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135 = sch.get_loops(block=b116)
b136 = sch.decompose_reduction(block=b116, loop=l120)
2024-04-29 04:23:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #184: GFLOPs: 197.1582. Time: 1173.4816 us. Best GFLOPs: 346.3255
2024-04-29 04:23:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #185: GFLOPs: 185.1842. Time: 1249.3591 us. Best GFLOPs: 346.3255
2024-04-29 04:23:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #186: GFLOPs: 97.4894. Time: 2373.1960 us. Best GFLOPs: 346.3255
2024-04-29 04:23:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #187: GFLOPs: 117.9155. Time: 1962.0967 us. Best GFLOPs: 346.3255
2024-04-29 04:23:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #188: GFLOPs: 230.5268. Time: 1003.6211 us. Best GFLOPs: 346.3255
2024-04-29 04:23:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #189: GFLOPs: 170.9685. Time: 1353.2409 us. Best GFLOPs: 346.3255
2024-04-29 04:23:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #190: GFLOPs: 2.6504. Time: 87292.5553 us. Best GFLOPs: 346.3255
2024-04-29 04:23:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #191: GFLOPs: 47.1035. Time: 4911.7680 us. Best GFLOPs: 346.3255
2024-04-29 04:23:08 [INFO] [task_scheduler.cc:121] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #192: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(14), T.int64(14), T.int64(128)), "float32"), p1: T.Buffer((T.int64(16), T.int64(2), T.int64(3), T.int64(3), T.int64(128), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(16)), "float32"), p3: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(16), T.int64(16), T.int64(128)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)))
        for n_0_oc_chunk_0_fused_fused in T.parallel(T.int64(4), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(2), T.int64(16), T.int64(16), T.int64(128)):
                with T.block("data_pad"):
                    v_i0, v_i1, v_i2, v_i3, v_i4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(15) and T.int64(1) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oh_0, ow_0, oc_block_0, n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(8), T.int64(1), T.int64(4), T.int64(14), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(2)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_fused_fused * T.int64(4) + oc_chunk_1 + oc_chunk_2_init + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(14), oh_0 * T.int64(14) + oh_1 + oh_2_init + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(14), ow_0 * T.int64(14) + ow_1 * T.int64(14) + ow_2_init * T.int64(2) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(2) + oc_block_1 * T.int64(2) + oc_block_2_init * T.int64(2) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(64), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(4), T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(2)):
                    for oc_block_3_fused in T.vectorized(T.int64(2)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_fused_fused * T.int64(4) + oc_chunk_1 + oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(14), oh_0 * T.int64(14) + oh_1 + oh_2 + oh_3)
                            v_ow = T.axis.spatial(T.int64(14), ow_0 * T.int64(14) + ow_1 * T.int64(14) + ow_2 * T.int64(2) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(2) + oc_block_1 * T.int64(2) + oc_block_2 * T.int64(2) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(4) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
        for ax0_ax1_ax2_ax3_ax4_fused_0 in T.parallel(T.int64(784)):
            for ax0_ax1_ax2_ax3_ax4_fused_1 in T.vectorized(T.int64(64)):
                with T.block("T_relu"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) // T.int64(3136))
                    v_ax2 = T.axis.spatial(T.int64(14), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(3136) // T.int64(224))
                    v_ax3 = T.axis.spatial(T.int64(14), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(224) // T.int64(16))
                    v_ax4 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(16))
                    T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[4, 4, 1, 1])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 14, 1, 1])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 7, 2])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[8, 1, 1, 2])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[64, 4])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[1, 3])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=1)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77 = sch.get_loops(block=b68)
l78 = sch.fuse(l71, l72, preserve_unit_iters=True)
sch.parallel(loop=l78)
l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l79, preserve_unit_iters=True)
sch.parallel(loop=l104)
l105 = sch.fuse(l103, preserve_unit_iters=True)
sch.vectorize(loop=l105)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l106, l107, l108, l109, l110 = sch.get_loops(block=b70)
l111 = sch.fuse(l106, l107, l108, l109, l110, preserve_unit_iters=True)
l112, l113 = sch.split(loop=l111, factors=[None, 64], preserve_unit_iters=True)
sch.parallel(loop=l112)
sch.vectorize(loop=l113)
b114 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139 = sch.get_loops(block=b114)
b140 = sch.decompose_reduction(block=b114, loop=l124)
2024-04-29 04:28:14 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 04:28:15 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-29 04:28:19 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3639cb8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x419b828)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x312c9f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x425e1d8)]: 0 failure(s)
2024-04-29 04:28:19 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-29 04:28:32 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3639cb8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x419b828)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x312c9f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x425e1d8)]: 0 failure(s)
2024-04-29 04:28:44 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3639cb8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x419b828)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x312c9f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x425e1d8)]: 0 failure(s)
2024-04-29 04:28:56 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3639cb8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x419b828)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x312c9f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x425e1d8)]: 0 failure(s)
2024-04-29 04:29:08 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3639cb8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x419b828)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x312c9f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x425e1d8)]: 0 failure(s)
2024-04-29 04:29:15 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.6829  0.6777  0.6680  0.6655  0.6655  0.6655  0.6655  0.6655  0.6655  0.6655  0.6655  0.6655  0.6655  0.6655  0.6655  0.6655
[17 : 32]:	0.6655  0.6655  0.6655  0.6490  0.6461  0.6442  0.6442  0.6431  0.6402  0.6392  0.6392  0.6392  0.6392  0.6392  0.6378  0.6378
[33 : 48]:	0.6304  0.6194  0.6185  0.6086  0.6081  0.6033  0.6033  0.6026  0.6005  0.6005  0.5962  0.5962  0.5961  0.5961  0.5961  0.5939
[49 : 64]:	0.5919  0.5919  0.5919  0.5891  0.5867  0.5863  0.5863  0.5863  0.5863  0.5863  0.5822  0.5808  0.5795  0.5779  0.5777  0.5777
2024-04-29 04:29:15 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 04:29:15 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 04:30:44 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #193: GFLOPs: 206.4702. Time: 1120.5564 us. Best GFLOPs: 346.3255
2024-04-29 04:30:44 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #194: GFLOPs: 136.9153. Time: 1689.8148 us. Best GFLOPs: 346.3255
2024-04-29 04:30:44 [INFO] [task_scheduler.cc:121] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #195: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(14), T.int64(14), T.int64(128)), "float32"), p1: T.Buffer((T.int64(16), T.int64(2), T.int64(3), T.int64(3), T.int64(128), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(16)), "float32"), p3: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(16), T.int64(16), T.int64(128)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused in T.parallel(T.int64(112), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(2), T.int64(4), T.int64(16), T.int64(128)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(16) * T.int64(2) + ax2)
                    v_i3, v_i4 = T.axis.remap("SS", [ax3, ax4])
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(15) and T.int64(1) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(2), T.int64(1), T.int64(1), T.int64(2), T.int64(2)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(8)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(16) + oc_chunk_2_init + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(16) * T.int64(2) + oh_1 * T.int64(2) + oh_2_init * T.int64(2) + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(14), ow_1 * T.int64(14) + ow_2_init * T.int64(2) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_1 * T.int64(16) + oc_block_2_init * T.int64(8) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(16), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(2), T.int64(16), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(2)):
                    for oc_block_3_fused in T.vectorized(T.int64(8)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(16) + oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(16) * T.int64(2) + oh_1 * T.int64(2) + oh_2 * T.int64(2) + oh_3)
                            v_ow = T.axis.spatial(T.int64(14), ow_1 * T.int64(14) + ow_2 * T.int64(2) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_1 * T.int64(16) + oc_block_2 * T.int64(8) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(16) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(2), T.int64(14)):
                    for ax4_fused in T.vectorized(T.int64(16)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(16) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(16) * T.int64(2) + ax2)
                            v_ax3, v_ax4 = T.axis.remap("SS", [ax3, ax4_fused])
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 16, 1, 1])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[7, 1, 1, 2])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 7, 2])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[1, 1, 2, 8])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[16, 16])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[3, 1])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l50, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=6)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83 = sch.get_loops(block=b69)
l84 = sch.fuse(l72, l73, l74, l75, l76, l77, l78, preserve_unit_iters=True)
sch.parallel(loop=l84)
l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b70)
l105 = sch.fuse(l85, preserve_unit_iters=True)
sch.parallel(loop=l105)
l106 = sch.fuse(l104, preserve_unit_iters=True)
sch.vectorize(loop=l106)
sch.annotate(block_or_loop=l105, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l105, ann_key="pragma_unroll_explicit", ann_val=1)
l107, l108, l109, l110, l111, l112, l113, l114, l115 = sch.get_loops(block=b71)
l116 = sch.fuse(l115, preserve_unit_iters=True)
sch.vectorize(loop=l116)
b117 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137 = sch.get_loops(block=b117)
b138 = sch.decompose_reduction(block=b117, loop=l122)
2024-04-29 04:30:44 [INFO] [task_scheduler.cc:121] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #196: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(14), T.int64(14), T.int64(128)), "float32"), p1: T.Buffer((T.int64(16), T.int64(2), T.int64(3), T.int64(3), T.int64(128), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(16)), "float32"), p3: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(16), T.int64(16), T.int64(128)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused in T.parallel(T.int64(112), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(2), T.int64(3), T.int64(16), T.int64(128)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(8) + ax2)
                    v_i3, v_i4 = T.axis.remap("SS", [ax3, ax4])
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(15) and T.int64(1) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(7), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(16)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(8) * T.int64(2) + oc_chunk_2_init + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(8) + oh_1 + oh_2_init + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(14), ow_1 * T.int64(14) + ow_2_init * T.int64(2) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_1 * T.int64(16) + oc_block_2_init * T.int64(16) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(16), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(7), T.int64(1), T.int64(16), T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(2)):
                    for oc_block_3_fused in T.vectorized(T.int64(16)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(8) * T.int64(2) + oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(8) + oh_1 + oh_2 + oh_3)
                            v_ow = T.axis.spatial(T.int64(14), ow_1 * T.int64(14) + ow_2 * T.int64(2) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_1 * T.int64(16) + oc_block_2 * T.int64(16) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(16) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(14)):
                    for ax4_fused in T.vectorized(T.int64(16)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(8) * T.int64(2) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(8) + ax2)
                            v_ax3, v_ax4 = T.axis.remap("SS", [ax3, ax4_fused])
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 8, 2, 1])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[14, 1, 1, 1])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 7, 2])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[1, 1, 1, 16])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[16, 16])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[1, 3])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l50, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=112)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=6)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83 = sch.get_loops(block=b69)
l84 = sch.fuse(l72, l73, l74, l75, l76, l77, l78, preserve_unit_iters=True)
sch.parallel(loop=l84)
l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b70)
l105 = sch.fuse(l85, preserve_unit_iters=True)
sch.parallel(loop=l105)
l106 = sch.fuse(l104, preserve_unit_iters=True)
sch.vectorize(loop=l106)
sch.annotate(block_or_loop=l105, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l105, ann_key="pragma_unroll_explicit", ann_val=1)
l107, l108, l109, l110, l111, l112, l113, l114, l115 = sch.get_loops(block=b71)
l116 = sch.fuse(l115, preserve_unit_iters=True)
sch.vectorize(loop=l116)
b117 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137 = sch.get_loops(block=b117)
b138 = sch.decompose_reduction(block=b117, loop=l122)
2024-04-29 04:30:44 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #197: GFLOPs: 215.4269. Time: 1073.9677 us. Best GFLOPs: 346.3255
2024-04-29 04:30:44 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #198: GFLOPs: 151.1334. Time: 1530.8431 us. Best GFLOPs: 346.3255
2024-04-29 04:30:44 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #199: GFLOPs: 197.9066. Time: 1169.0438 us. Best GFLOPs: 346.3255
2024-04-29 04:30:44 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #200: GFLOPs: 211.4678. Time: 1094.0744 us. Best GFLOPs: 346.3255
2024-04-29 04:30:44 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #201: GFLOPs: 108.1674. Time: 2138.9218 us. Best GFLOPs: 346.3255
2024-04-29 04:30:44 [INFO] [task_scheduler.cc:121] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #202: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(14), T.int64(14), T.int64(128)), "float32"), p1: T.Buffer((T.int64(16), T.int64(2), T.int64(3), T.int64(3), T.int64(128), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(16)), "float32"), p3: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(16), T.int64(16), T.int64(128)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused in T.parallel(T.int64(112), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(2), T.int64(3), T.int64(16), T.int64(128)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(14) + ax2)
                    v_i3, v_i4 = T.axis.remap("SS", [ax3, ax4])
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(15) and T.int64(1) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(7), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(16)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(14) * T.int64(2) + oc_chunk_2_init + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(14) + oh_2_init + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(14), ow_1 * T.int64(14) + ow_2_init * T.int64(2) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_1 * T.int64(16) + oc_block_2_init * T.int64(16) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(4), T.int64(3), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(7), T.int64(1), T.int64(64), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(2)):
                    for oc_block_3_fused in T.vectorized(T.int64(16)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(14) * T.int64(2) + oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(14) + oh_2 + oh_3)
                            v_ow = T.axis.spatial(T.int64(14), ow_1 * T.int64(14) + ow_2 * T.int64(2) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_1 * T.int64(16) + oc_block_2 * T.int64(16) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(64) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(14)):
                    for ax4_fused in T.vectorized(T.int64(16)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(14) * T.int64(2) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(14) + ax2)
                            v_ax3, v_ax4 = T.axis.remap("SS", [ax3, ax4_fused])
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 8, 2, 1])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 14, 1, 1])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 7, 2])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[1, 1, 1, 16])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[4, 64])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[1, 3])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l50, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=7)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b69)
l85 = sch.fuse(l72, l73, l74, l75, l76, l77, l78, l79, preserve_unit_iters=True)
sch.parallel(loop=l85)
l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b70)
l105 = sch.fuse(l86, preserve_unit_iters=True)
sch.parallel(loop=l105)
l106 = sch.fuse(l104, preserve_unit_iters=True)
sch.vectorize(loop=l106)
sch.annotate(block_or_loop=l105, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l105, ann_key="pragma_unroll_explicit", ann_val=1)
l107, l108, l109, l110, l111, l112, l113, l114 = sch.get_loops(block=b71)
l115 = sch.fuse(l114, preserve_unit_iters=True)
sch.vectorize(loop=l115)
b116 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135 = sch.get_loops(block=b116)
b136 = sch.decompose_reduction(block=b116, loop=l120)
2024-04-29 04:30:44 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #203: GFLOPs: 191.7223. Time: 1206.7535 us. Best GFLOPs: 346.3255
2024-04-29 04:30:44 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #204: GFLOPs: 118.8594. Time: 1946.5139 us. Best GFLOPs: 346.3255
2024-04-29 04:30:44 [INFO] [task_scheduler.cc:121] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #205: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(14), T.int64(14), T.int64(128)), "float32"), p1: T.Buffer((T.int64(16), T.int64(2), T.int64(3), T.int64(3), T.int64(128), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(16)), "float32"), p3: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(16), T.int64(16), T.int64(128)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_fused_fused in T.parallel(T.int64(112), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(2), T.int64(3), T.int64(16), T.int64(128)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_fused_fused % T.int64(14) + ax2)
                    v_i3, v_i4 = T.axis.remap("SS", [ax3, ax4])
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(15) and T.int64(1) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for ow_0, oc_block_0, n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(7), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(16)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_fused_fused // T.int64(14) * T.int64(2) + oc_chunk_1 * T.int64(2) + oc_chunk_2_init + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_fused_fused % T.int64(14) + oh_1 + oh_2_init + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(14), ow_0 * T.int64(14) + ow_1 * T.int64(14) + ow_2_init * T.int64(2) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2_init * T.int64(16) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(16), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(7), T.int64(1), T.int64(16), T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(2)):
                    for oc_block_3_fused in T.vectorized(T.int64(16)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_fused_fused // T.int64(14) * T.int64(2) + oc_chunk_1 * T.int64(2) + oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_fused_fused % T.int64(14) + oh_1 + oh_2 + oh_3)
                            v_ow = T.axis.spatial(T.int64(14), ow_0 * T.int64(14) + ow_1 * T.int64(14) + ow_2 * T.int64(2) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2 * T.int64(16) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(16) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(14)):
                    for ax4_fused in T.vectorized(T.int64(16)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_fused_fused // T.int64(14) * T.int64(2) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_fused_fused % T.int64(14) + ax2)
                            v_ax3, v_ax4 = T.axis.remap("SS", [ax3, ax4_fused])
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[8, 1, 2, 1])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[14, 1, 1, 1])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 7, 2])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[1, 1, 1, 16])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[16, 16])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[1, 3])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l50, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=112)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=2)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79 = sch.get_loops(block=b69)
l80 = sch.fuse(l72, l73, l74, preserve_unit_iters=True)
sch.parallel(loop=l80)
l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b70)
l105 = sch.fuse(l81, preserve_unit_iters=True)
sch.parallel(loop=l105)
l106 = sch.fuse(l104, preserve_unit_iters=True)
sch.vectorize(loop=l106)
sch.annotate(block_or_loop=l105, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l105, ann_key="pragma_unroll_explicit", ann_val=1)
l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117, l118, l119 = sch.get_loops(block=b71)
l120 = sch.fuse(l119, preserve_unit_iters=True)
sch.vectorize(loop=l120)
b121 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141, l142, l143, l144, l145 = sch.get_loops(block=b121)
b146 = sch.decompose_reduction(block=b121, loop=l130)
2024-04-29 04:30:44 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #206: GFLOPs: 126.1998. Time: 1833.2962 us. Best GFLOPs: 346.3255
2024-04-29 04:30:44 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #207: GFLOPs: 178.8492. Time: 1293.6121 us. Best GFLOPs: 346.3255
2024-04-29 04:30:44 [INFO] [task_scheduler.cc:121] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #208: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(14), T.int64(14), T.int64(128)), "float32"), p1: T.Buffer((T.int64(16), T.int64(2), T.int64(3), T.int64(3), T.int64(128), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(16)), "float32"), p3: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(16), T.int64(16), T.int64(128)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused in T.parallel(T.int64(112), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(2), T.int64(3), T.int64(16), T.int64(128)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(14) + ax2)
                    v_i3, v_i4 = T.axis.remap("SS", [ax3, ax4])
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(15) and T.int64(1) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(7), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(16)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(14) * T.int64(2) + oc_chunk_2_init + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(14) + oh_2_init + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(14), ow_1 * T.int64(14) + ow_2_init * T.int64(2) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_1 * T.int64(16) + oc_block_2_init * T.int64(16) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(4), T.int64(1), T.int64(3), T.int64(1), T.int64(2), T.int64(1), T.int64(7), T.int64(1), T.int64(64), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2)):
                    for oc_block_3_fused in T.vectorized(T.int64(16)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(14) * T.int64(2) + oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(14) + oh_2 + oh_3)
                            v_ow = T.axis.spatial(T.int64(14), ow_1 * T.int64(14) + ow_2 * T.int64(2) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_1 * T.int64(16) + oc_block_2 * T.int64(16) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(64) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(14)):
                    for ax4_fused in T.vectorized(T.int64(16)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(14) * T.int64(2) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(14) + ax2)
                            v_ax3, v_ax4 = T.axis.remap("SS", [ax3, ax4_fused])
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 8, 2, 1])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 14, 1, 1])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 7, 2])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[1, 1, 1, 16])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[4, 64])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[3, 1])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l50, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=7)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b69)
l85 = sch.fuse(l72, l73, l74, l75, l76, l77, l78, l79, preserve_unit_iters=True)
sch.parallel(loop=l85)
l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b70)
l105 = sch.fuse(l86, preserve_unit_iters=True)
sch.parallel(loop=l105)
l106 = sch.fuse(l104, preserve_unit_iters=True)
sch.vectorize(loop=l106)
sch.annotate(block_or_loop=l105, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l105, ann_key="pragma_unroll_explicit", ann_val=1)
l107, l108, l109, l110, l111, l112, l113, l114 = sch.get_loops(block=b71)
l115 = sch.fuse(l114, preserve_unit_iters=True)
sch.vectorize(loop=l115)
b116 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135 = sch.get_loops(block=b116)
b136 = sch.decompose_reduction(block=b116, loop=l120)
2024-04-29 04:30:44 [INFO] [task_scheduler.cc:121] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #209: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(14), T.int64(14), T.int64(128)), "float32"), p1: T.Buffer((T.int64(16), T.int64(2), T.int64(3), T.int64(3), T.int64(128), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(16)), "float32"), p3: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(16), T.int64(16), T.int64(128)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused in T.parallel(T.int64(112), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(2), T.int64(3), T.int64(16), T.int64(128)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(8) + ax2)
                    v_i3, v_i4 = T.axis.remap("SS", [ax3, ax4])
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(15) and T.int64(1) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(7), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(16)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(8) * T.int64(2) + oc_chunk_2_init + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(8) + oh_1 + oh_2_init + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(14), ow_1 * T.int64(14) + ow_2_init * T.int64(2) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_1 * T.int64(16) + oc_block_2_init * T.int64(16) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(4), T.int64(3), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(7), T.int64(1), T.int64(64), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(2)):
                    for oc_block_3_fused in T.vectorized(T.int64(16)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(8) * T.int64(2) + oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(8) + oh_1 + oh_2 + oh_3)
                            v_ow = T.axis.spatial(T.int64(14), ow_1 * T.int64(14) + ow_2 * T.int64(2) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_1 * T.int64(16) + oc_block_2 * T.int64(16) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(64) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(14)):
                    for ax4_fused in T.vectorized(T.int64(16)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(8) * T.int64(2) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(8) + ax2)
                            v_ax3, v_ax4 = T.axis.remap("SS", [ax3, ax4_fused])
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 8, 2, 1])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[14, 1, 1, 1])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 7, 2])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[1, 1, 1, 16])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[4, 64])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[1, 3])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l50, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=6)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83 = sch.get_loops(block=b69)
l84 = sch.fuse(l72, l73, l74, l75, l76, l77, l78, preserve_unit_iters=True)
sch.parallel(loop=l84)
l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b70)
l105 = sch.fuse(l85, preserve_unit_iters=True)
sch.parallel(loop=l105)
l106 = sch.fuse(l104, preserve_unit_iters=True)
sch.vectorize(loop=l106)
sch.annotate(block_or_loop=l105, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l105, ann_key="pragma_unroll_explicit", ann_val=1)
l107, l108, l109, l110, l111, l112, l113, l114, l115 = sch.get_loops(block=b71)
l116 = sch.fuse(l115, preserve_unit_iters=True)
sch.vectorize(loop=l116)
b117 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137 = sch.get_loops(block=b117)
b138 = sch.decompose_reduction(block=b117, loop=l122)
2024-04-29 04:30:44 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #210: GFLOPs: 178.7043. Time: 1294.6610 us. Best GFLOPs: 346.3255
2024-04-29 04:30:44 [INFO] [task_scheduler.cc:121] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #211: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(14), T.int64(14), T.int64(128)), "float32"), p1: T.Buffer((T.int64(16), T.int64(2), T.int64(3), T.int64(3), T.int64(128), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(16)), "float32"), p3: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(16), T.int64(16), T.int64(128)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused in T.parallel(T.int64(112), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(2), T.int64(3), T.int64(16), T.int64(128)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(14) + ax2)
                    v_i3, v_i4 = T.axis.remap("SS", [ax3, ax4])
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(15) and T.int64(1) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(7), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(16)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(14) * T.int64(2) + oc_chunk_2_init + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(14) + oh_2_init + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(14), ow_1 * T.int64(14) + ow_2_init * T.int64(2) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_1 * T.int64(16) + oc_block_2_init * T.int64(16) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(64), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(7), T.int64(1), T.int64(4), T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(2)):
                    for oc_block_3_fused in T.vectorized(T.int64(16)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(14) * T.int64(2) + oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(14) + oh_2 + oh_3)
                            v_ow = T.axis.spatial(T.int64(14), ow_1 * T.int64(14) + ow_2 * T.int64(2) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_1 * T.int64(16) + oc_block_2 * T.int64(16) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(4) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(14)):
                    for ax4_fused in T.vectorized(T.int64(16)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(14) * T.int64(2) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(14) + ax2)
                            v_ax3, v_ax4 = T.axis.remap("SS", [ax3, ax4_fused])
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 8, 2, 1])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 14, 1, 1])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 7, 2])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[1, 1, 1, 16])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[64, 4])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[1, 3])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l50, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=7)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b69)
l85 = sch.fuse(l72, l73, l74, l75, l76, l77, l78, l79, preserve_unit_iters=True)
sch.parallel(loop=l85)
l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b70)
l105 = sch.fuse(l86, preserve_unit_iters=True)
sch.parallel(loop=l105)
l106 = sch.fuse(l104, preserve_unit_iters=True)
sch.vectorize(loop=l106)
sch.annotate(block_or_loop=l105, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l105, ann_key="pragma_unroll_explicit", ann_val=1)
l107, l108, l109, l110, l111, l112, l113, l114 = sch.get_loops(block=b71)
l115 = sch.fuse(l114, preserve_unit_iters=True)
sch.vectorize(loop=l115)
b116 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135 = sch.get_loops(block=b116)
b136 = sch.decompose_reduction(block=b116, loop=l120)
2024-04-29 04:30:44 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #212: GFLOPs: 218.3022. Time: 1059.8221 us. Best GFLOPs: 346.3255
2024-04-29 04:30:44 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #213: GFLOPs: 472.2663. Time: 489.8963 us. Best GFLOPs: 472.2663
2024-04-29 04:30:44 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #214: GFLOPs: 143.2417. Time: 1615.1825 us. Best GFLOPs: 472.2663
2024-04-29 04:30:44 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #215: GFLOPs: 155.2540. Time: 1490.2127 us. Best GFLOPs: 472.2663
2024-04-29 04:30:44 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #216: GFLOPs: 152.4043. Time: 1518.0779 us. Best GFLOPs: 472.2663
2024-04-29 04:30:44 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #217: GFLOPs: 217.1892. Time: 1065.2533 us. Best GFLOPs: 472.2663
2024-04-29 04:30:44 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #218: GFLOPs: 223.8779. Time: 1033.4273 us. Best GFLOPs: 472.2663
2024-04-29 04:30:44 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #219: GFLOPs: 188.2759. Time: 1228.8428 us. Best GFLOPs: 472.2663
2024-04-29 04:30:44 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #220: GFLOPs: 197.2288. Time: 1173.0615 us. Best GFLOPs: 472.2663
2024-04-29 04:30:44 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #221: GFLOPs: 159.6398. Time: 1449.2721 us. Best GFLOPs: 472.2663
2024-04-29 04:30:44 [INFO] [task_scheduler.cc:121] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #222: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(14), T.int64(14), T.int64(128)), "float32"), p1: T.Buffer((T.int64(16), T.int64(2), T.int64(3), T.int64(3), T.int64(128), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(16)), "float32"), p3: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(16), T.int64(16), T.int64(128)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused in T.parallel(T.int64(224), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(2), T.int64(3), T.int64(16), T.int64(128)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(112) * T.int64(7) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(7) + ax2)
                    v_i3, v_i4 = T.axis.remap("SS", [ax3, ax4])
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(15) and T.int64(1) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(2)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(8)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(56) // T.int64(7) * T.int64(2) + oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(112) * T.int64(7) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(7) + oh_2_init + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(14), ow_1 * T.int64(14) + ow_2_init * T.int64(2) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(112) // T.int64(56) * T.int64(8) + oc_block_1 * T.int64(8) + oc_block_2_init * T.int64(8) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(32), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(8), T.int64(3), T.int64(3), T.int64(1), T.int64(2), T.int64(1), T.int64(2)):
                    for oc_block_3_fused in T.vectorized(T.int64(8)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(56) // T.int64(7) * T.int64(2) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(112) * T.int64(7) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(7) + oh_2 + oh_3)
                            v_ow = T.axis.spatial(T.int64(14), ow_1 * T.int64(14) + ow_2 * T.int64(2) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(112) // T.int64(56) * T.int64(8) + oc_block_1 * T.int64(8) + oc_block_2 * T.int64(8) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(8) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(14)):
                    for ax4_fused in T.vectorized(T.int64(8)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(56) // T.int64(7) * T.int64(2) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(112) * T.int64(7) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(7) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(14), ax3)
                            v_ax4 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(112) // T.int64(56) * T.int64(8) + ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 8, 1, 2])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[2, 7, 1, 1])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 7, 2])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[2, 1, 1, 8])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[32, 8])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[1, 3])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l50, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=7)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b69)
l85 = sch.fuse(l72, l73, l74, l75, l76, l77, l78, l79, preserve_unit_iters=True)
sch.parallel(loop=l85)
l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b70)
l105 = sch.fuse(l86, preserve_unit_iters=True)
sch.parallel(loop=l105)
l106 = sch.fuse(l104, preserve_unit_iters=True)
sch.vectorize(loop=l106)
sch.annotate(block_or_loop=l105, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l105, ann_key="pragma_unroll_explicit", ann_val=1)
l107, l108, l109, l110, l111, l112, l113, l114 = sch.get_loops(block=b71)
l115 = sch.fuse(l114, preserve_unit_iters=True)
sch.vectorize(loop=l115)
b116 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135 = sch.get_loops(block=b116)
b136 = sch.decompose_reduction(block=b116, loop=l120)
2024-04-29 04:30:44 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #223: GFLOPs: 191.4605. Time: 1208.4033 us. Best GFLOPs: 472.2663
2024-04-29 04:30:44 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #224: GFLOPs: 105.8357. Time: 2186.0447 us. Best GFLOPs: 472.2663
2024-04-29 04:30:44 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #225: GFLOPs: 195.0020. Time: 1186.4573 us. Best GFLOPs: 472.2663
2024-04-29 04:30:44 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #226: GFLOPs: 133.0452. Time: 1738.9699 us. Best GFLOPs: 472.2663
2024-04-29 04:30:44 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #227: GFLOPs: 194.4004. Time: 1190.1291 us. Best GFLOPs: 472.2663
2024-04-29 04:30:44 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #228: GFLOPs: 134.2798. Time: 1722.9815 us. Best GFLOPs: 472.2663
2024-04-29 04:30:44 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #229: GFLOPs: 92.0462. Time: 2513.5384 us. Best GFLOPs: 472.2663
2024-04-29 04:30:44 [INFO] [task_scheduler.cc:121] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #230: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(14), T.int64(14), T.int64(128)), "float32"), p1: T.Buffer((T.int64(16), T.int64(2), T.int64(3), T.int64(3), T.int64(128), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(16)), "float32"), p3: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(16), T.int64(16), T.int64(128)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused in T.parallel(T.int64(112), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(2), T.int64(3), T.int64(16), T.int64(128)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(8) + ax2)
                    v_i3, v_i4 = T.axis.remap("SS", [ax3, ax4])
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(15) and T.int64(1) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(2), T.int64(1), T.int64(2), T.int64(1), T.int64(2)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(8)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(8) * T.int64(2) + oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(8) + oh_1 + oh_2_init + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(14), ow_1 * T.int64(14) + ow_2_init * T.int64(2) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_1 * T.int64(16) + oc_block_2_init * T.int64(8) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(32), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(2), T.int64(8), T.int64(3), T.int64(3), T.int64(1), T.int64(2), T.int64(1), T.int64(2)):
                    for oc_block_3_fused in T.vectorized(T.int64(8)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(8) * T.int64(2) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(8) + oh_1 + oh_2 + oh_3)
                            v_ow = T.axis.spatial(T.int64(14), ow_1 * T.int64(14) + ow_2 * T.int64(2) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_1 * T.int64(16) + oc_block_2 * T.int64(8) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(8) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(14)):
                    for ax4_fused in T.vectorized(T.int64(16)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(8) * T.int64(2) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(8) + ax2)
                            v_ax3, v_ax4 = T.axis.remap("SS", [ax3, ax4_fused])
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 8, 1, 2])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[14, 1, 1, 1])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 7, 2])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[1, 1, 2, 8])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[32, 8])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[1, 3])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l50, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=6)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83 = sch.get_loops(block=b69)
l84 = sch.fuse(l72, l73, l74, l75, l76, l77, l78, preserve_unit_iters=True)
sch.parallel(loop=l84)
l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b70)
l105 = sch.fuse(l85, preserve_unit_iters=True)
sch.parallel(loop=l105)
l106 = sch.fuse(l104, preserve_unit_iters=True)
sch.vectorize(loop=l106)
sch.annotate(block_or_loop=l105, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l105, ann_key="pragma_unroll_explicit", ann_val=1)
l107, l108, l109, l110, l111, l112, l113, l114, l115 = sch.get_loops(block=b71)
l116 = sch.fuse(l115, preserve_unit_iters=True)
sch.vectorize(loop=l116)
b117 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137 = sch.get_loops(block=b117)
b138 = sch.decompose_reduction(block=b117, loop=l122)
2024-04-29 04:30:44 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #231: GFLOPs: 108.4448. Time: 2133.4501 us. Best GFLOPs: 472.2663
2024-04-29 04:30:44 [INFO] [task_scheduler.cc:121] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #232: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(14), T.int64(14), T.int64(128)), "float32"), p1: T.Buffer((T.int64(16), T.int64(2), T.int64(3), T.int64(3), T.int64(128), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(16)), "float32"), p3: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(16), T.int64(16), T.int64(128)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused in T.parallel(T.int64(224), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(2), T.int64(3), T.int64(16), T.int64(128)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(2) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(112) // T.int64(16) * T.int64(2) + ax2)
                    v_i3, v_i4 = T.axis.remap("SS", [ax3, ax4])
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(15) and T.int64(1) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(2)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(8)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(112) * T.int64(8) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(16) // T.int64(2) + oc_chunk_2_init + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(112) // T.int64(16) * T.int64(2) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(2) + oh_2_init + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(14), ow_1 * T.int64(14) + ow_2_init * T.int64(2) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_1 * T.int64(16) + oc_block_2_init * T.int64(8) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(16), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(2), T.int64(16), T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(2)):
                    for oc_block_3_fused in T.vectorized(T.int64(8)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(112) * T.int64(8) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(16) // T.int64(2) + oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(112) // T.int64(16) * T.int64(2) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(2) + oh_2 + oh_3)
                            v_ow = T.axis.spatial(T.int64(14), ow_1 * T.int64(14) + ow_2 * T.int64(2) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_1 * T.int64(16) + oc_block_2 * T.int64(8) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(16) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(14)):
                    for ax4_fused in T.vectorized(T.int64(16)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(112) * T.int64(8) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(16) // T.int64(2) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(112) // T.int64(16) * T.int64(2) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(2) + ax2)
                            v_ax3, v_ax4 = T.axis.remap("SS", [ax3, ax4_fused])
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 8, 1, 1])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[7, 2, 1, 1])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 7, 2])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[1, 1, 2, 8])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[16, 16])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[1, 3])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l50, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=7)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b69)
l85 = sch.fuse(l72, l73, l74, l75, l76, l77, l78, l79, preserve_unit_iters=True)
sch.parallel(loop=l85)
l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b70)
l105 = sch.fuse(l86, preserve_unit_iters=True)
sch.parallel(loop=l105)
l106 = sch.fuse(l104, preserve_unit_iters=True)
sch.vectorize(loop=l106)
sch.annotate(block_or_loop=l105, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l105, ann_key="pragma_unroll_explicit", ann_val=1)
l107, l108, l109, l110, l111, l112, l113, l114 = sch.get_loops(block=b71)
l115 = sch.fuse(l114, preserve_unit_iters=True)
sch.vectorize(loop=l115)
b116 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135 = sch.get_loops(block=b116)
b136 = sch.decompose_reduction(block=b116, loop=l120)
2024-04-29 04:30:44 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #233: GFLOPs: 197.0104. Time: 1174.3623 us. Best GFLOPs: 472.2663
2024-04-29 04:30:44 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #234: GFLOPs: 102.2958. Time: 2261.6910 us. Best GFLOPs: 472.2663
2024-04-29 04:30:44 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #235: GFLOPs: 155.6155. Time: 1486.7516 us. Best GFLOPs: 472.2663
2024-04-29 04:30:44 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #236: GFLOPs: 196.6007. Time: 1176.8095 us. Best GFLOPs: 472.2663
2024-04-29 04:30:44 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #237: GFLOPs: 134.0662. Time: 1725.7267 us. Best GFLOPs: 472.2663
2024-04-29 04:30:44 [INFO] [task_scheduler.cc:121] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #238: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(14), T.int64(14), T.int64(128)), "float32"), p1: T.Buffer((T.int64(16), T.int64(2), T.int64(3), T.int64(3), T.int64(128), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(16)), "float32"), p3: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(16), T.int64(16), T.int64(128)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused in T.parallel(T.int64(56), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(2), T.int64(4), T.int64(16), T.int64(128)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(8) * T.int64(2) + ax2)
                    v_i3, v_i4 = T.axis.remap("SS", [ax3, ax4])
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(15) and T.int64(1) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oh_1, ow_1, oc_block_1 in T.grid(T.int64(2), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(7), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(16)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(8) * T.int64(2) + oc_chunk_2_init + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(8) * T.int64(2) + oh_1 + oh_2_init + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(14), ow_1 * T.int64(14) + ow_2_init * T.int64(2) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_1 * T.int64(16) + oc_block_2_init * T.int64(16) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(16), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(7), T.int64(1), T.int64(16), T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(2)):
                    for oc_block_3_fused in T.vectorized(T.int64(16)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(8) * T.int64(2) + oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(8) * T.int64(2) + oh_1 + oh_2 + oh_3)
                            v_ow = T.axis.spatial(T.int64(14), ow_1 * T.int64(14) + ow_2 * T.int64(2) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_1 * T.int64(16) + oc_block_2 * T.int64(16) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(16) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(14)):
                    for ax4_fused in T.vectorized(T.int64(16)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(8) * T.int64(2) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(8) * T.int64(2) + oh_1 + ax2)
                            v_ax3, v_ax4 = T.axis.remap("SS", [ax3, ax4_fused])
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 8, 2, 1])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[7, 2, 1, 1])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 7, 2])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[1, 1, 1, 16])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[16, 16])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[1, 3])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l50, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=112)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=6)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83 = sch.get_loops(block=b69)
l84 = sch.fuse(l72, l73, l74, l75, l76, l77, l78, preserve_unit_iters=True)
sch.parallel(loop=l84)
l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b70)
l105 = sch.fuse(l85, preserve_unit_iters=True)
sch.parallel(loop=l105)
l106 = sch.fuse(l104, preserve_unit_iters=True)
sch.vectorize(loop=l106)
sch.annotate(block_or_loop=l105, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l105, ann_key="pragma_unroll_explicit", ann_val=1)
l107, l108, l109, l110, l111, l112, l113, l114, l115 = sch.get_loops(block=b71)
l116 = sch.fuse(l115, preserve_unit_iters=True)
sch.vectorize(loop=l116)
b117 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137 = sch.get_loops(block=b117)
b138 = sch.decompose_reduction(block=b117, loop=l122)
2024-04-29 04:30:44 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #239: GFLOPs: 118.4221. Time: 1953.7017 us. Best GFLOPs: 472.2663
2024-04-29 04:30:44 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #240: GFLOPs: 104.5220. Time: 2213.5205 us. Best GFLOPs: 472.2663
2024-04-29 04:30:44 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #241: GFLOPs: 185.8227. Time: 1245.0660 us. Best GFLOPs: 472.2663
2024-04-29 04:30:44 [INFO] [task_scheduler.cc:121] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #242: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(14), T.int64(14), T.int64(128)), "float32"), p1: T.Buffer((T.int64(16), T.int64(2), T.int64(3), T.int64(3), T.int64(128), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(16)), "float32"), p3: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(16), T.int64(16), T.int64(128)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused in T.parallel(T.int64(112), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(2), T.int64(3), T.int64(16), T.int64(128)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(56) * T.int64(7) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(7) + ax2)
                    v_i3, v_i4 = T.axis.remap("SS", [ax3, ax4])
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(15) and T.int64(1) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(2), T.int64(1), T.int64(2), T.int64(1), T.int64(2)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(8)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(56) // T.int64(7) * T.int64(2) + oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(56) * T.int64(7) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(7) + oh_2_init + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(14), ow_1 * T.int64(14) + ow_2_init * T.int64(2) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_1 * T.int64(16) + oc_block_2_init * T.int64(8) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(32), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(2), T.int64(8), T.int64(3), T.int64(3), T.int64(1), T.int64(2), T.int64(1), T.int64(2)):
                    for oc_block_3_fused in T.vectorized(T.int64(8)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(56) // T.int64(7) * T.int64(2) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(56) * T.int64(7) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(7) + oh_2 + oh_3)
                            v_ow = T.axis.spatial(T.int64(14), ow_1 * T.int64(14) + ow_2 * T.int64(2) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_1 * T.int64(16) + oc_block_2 * T.int64(8) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(8) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(14)):
                    for ax4_fused in T.vectorized(T.int64(16)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(56) // T.int64(7) * T.int64(2) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(56) * T.int64(7) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(7) + ax2)
                            v_ax3, v_ax4 = T.axis.remap("SS", [ax3, ax4_fused])
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 8, 1, 2])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[2, 7, 1, 1])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 7, 2])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[1, 1, 2, 8])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[32, 8])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[1, 3])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l50, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=7)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b69)
l85 = sch.fuse(l72, l73, l74, l75, l76, l77, l78, l79, preserve_unit_iters=True)
sch.parallel(loop=l85)
l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b70)
l105 = sch.fuse(l86, preserve_unit_iters=True)
sch.parallel(loop=l105)
l106 = sch.fuse(l104, preserve_unit_iters=True)
sch.vectorize(loop=l106)
sch.annotate(block_or_loop=l105, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l105, ann_key="pragma_unroll_explicit", ann_val=1)
l107, l108, l109, l110, l111, l112, l113, l114 = sch.get_loops(block=b71)
l115 = sch.fuse(l114, preserve_unit_iters=True)
sch.vectorize(loop=l115)
b116 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135 = sch.get_loops(block=b116)
b136 = sch.decompose_reduction(block=b116, loop=l120)
2024-04-29 04:30:44 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #243: GFLOPs: 172.1397. Time: 1344.0332 us. Best GFLOPs: 472.2663
2024-04-29 04:30:44 [INFO] [task_scheduler.cc:121] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #244: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(14), T.int64(14), T.int64(128)), "float32"), p1: T.Buffer((T.int64(16), T.int64(2), T.int64(3), T.int64(3), T.int64(128), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(16)), "float32"), p3: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(16), T.int64(16), T.int64(128)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused in T.parallel(T.int64(224), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(2), T.int64(3), T.int64(16), T.int64(128)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(112) // T.int64(8) + ax2)
                    v_i3, v_i4 = T.axis.remap("SS", [ax3, ax4])
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(15) and T.int64(1) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(2), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(16)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(112) * T.int64(8) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(8) + oc_chunk_2_init + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(112) // T.int64(8) + oh_1 + oh_2_init + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(14), ow_1 * T.int64(7) + ow_2_init + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_1 * T.int64(16) + oc_block_2_init * T.int64(16) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(32), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(8), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                    for oc_block_3_fused in T.vectorized(T.int64(16)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(112) * T.int64(8) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(8) + oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(112) // T.int64(8) + oh_1 + oh_2 + oh_3)
                            v_ow = T.axis.spatial(T.int64(14), ow_1 * T.int64(7) + ow_2 + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_1 * T.int64(16) + oc_block_2 * T.int64(16) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(8) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                    for ax4_fused in T.vectorized(T.int64(16)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(112) * T.int64(8) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(8) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(112) // T.int64(8) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(14), ow_1 * T.int64(7) + ax3)
                            v_ax4 = T.axis.spatial(T.int64(16), ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 8, 1, 1])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[14, 1, 1, 1])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 2, 7, 1])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[1, 1, 1, 16])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[32, 8])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[3, 1])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l50, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=6)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83 = sch.get_loops(block=b69)
l84 = sch.fuse(l72, l73, l74, l75, l76, l77, l78, preserve_unit_iters=True)
sch.parallel(loop=l84)
l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b70)
l105 = sch.fuse(l85, preserve_unit_iters=True)
sch.parallel(loop=l105)
l106 = sch.fuse(l104, preserve_unit_iters=True)
sch.vectorize(loop=l106)
sch.annotate(block_or_loop=l105, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l105, ann_key="pragma_unroll_explicit", ann_val=1)
l107, l108, l109, l110, l111, l112, l113, l114, l115 = sch.get_loops(block=b71)
l116 = sch.fuse(l115, preserve_unit_iters=True)
sch.vectorize(loop=l116)
b117 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137 = sch.get_loops(block=b117)
b138 = sch.decompose_reduction(block=b117, loop=l122)
2024-04-29 04:30:44 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #245: GFLOPs: 131.6001. Time: 1758.0656 us. Best GFLOPs: 472.2663
2024-04-29 04:30:44 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #246: GFLOPs: 119.6334. Time: 1933.9206 us. Best GFLOPs: 472.2663
2024-04-29 04:30:44 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #247: GFLOPs: 167.5617. Time: 1380.7542 us. Best GFLOPs: 472.2663
2024-04-29 04:30:44 [INFO] [task_scheduler.cc:121] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #248: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(14), T.int64(14), T.int64(128)), "float32"), p1: T.Buffer((T.int64(16), T.int64(2), T.int64(3), T.int64(3), T.int64(128), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(16)), "float32"), p3: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(16), T.int64(16), T.int64(128)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused in T.parallel(T.int64(112), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(2), T.int64(3), T.int64(16), T.int64(128)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(56) * T.int64(7) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(7) + ax2)
                    v_i3, v_i4 = T.axis.remap("SS", [ax3, ax4])
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(15) and T.int64(1) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(7), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(16)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(56) // T.int64(7) * T.int64(2) + oc_chunk_2_init + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(56) * T.int64(7) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(7) + oh_2_init + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(14), ow_1 * T.int64(14) + ow_2_init * T.int64(2) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_1 * T.int64(16) + oc_block_2_init * T.int64(16) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(16), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(7), T.int64(1), T.int64(16), T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(2)):
                    for oc_block_3_fused in T.vectorized(T.int64(16)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(56) // T.int64(7) * T.int64(2) + oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(56) * T.int64(7) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(7) + oh_2 + oh_3)
                            v_ow = T.axis.spatial(T.int64(14), ow_1 * T.int64(14) + ow_2 * T.int64(2) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_1 * T.int64(16) + oc_block_2 * T.int64(16) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(16) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(14)):
                    for ax4_fused in T.vectorized(T.int64(16)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(56) // T.int64(7) * T.int64(2) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(56) * T.int64(7) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(7) + ax2)
                            v_ax3, v_ax4 = T.axis.remap("SS", [ax3, ax4_fused])
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 8, 2, 1])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[2, 7, 1, 1])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 7, 2])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[1, 1, 1, 16])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[16, 16])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[1, 3])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l50, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=7)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b69)
l85 = sch.fuse(l72, l73, l74, l75, l76, l77, l78, l79, preserve_unit_iters=True)
sch.parallel(loop=l85)
l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b70)
l105 = sch.fuse(l86, preserve_unit_iters=True)
sch.parallel(loop=l105)
l106 = sch.fuse(l104, preserve_unit_iters=True)
sch.vectorize(loop=l106)
sch.annotate(block_or_loop=l105, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l105, ann_key="pragma_unroll_explicit", ann_val=1)
l107, l108, l109, l110, l111, l112, l113, l114 = sch.get_loops(block=b71)
l115 = sch.fuse(l114, preserve_unit_iters=True)
sch.vectorize(loop=l115)
b116 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135 = sch.get_loops(block=b116)
b136 = sch.decompose_reduction(block=b116, loop=l120)
2024-04-29 04:30:44 [INFO] [task_scheduler.cc:121] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #249: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(14), T.int64(14), T.int64(128)), "float32"), p1: T.Buffer((T.int64(16), T.int64(2), T.int64(3), T.int64(3), T.int64(128), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(16)), "float32"), p3: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(16), T.int64(16), T.int64(128)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused in T.parallel(T.int64(112), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(2), T.int64(3), T.int64(16), T.int64(128)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(56) * T.int64(7) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(7) + ax2)
                    v_i3, v_i4 = T.axis.remap("SS", [ax3, ax4])
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(15) and T.int64(1) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(7), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(16)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(56) // T.int64(7) * T.int64(2) + oc_chunk_2_init + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(56) * T.int64(7) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(7) + oh_2_init + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(14), ow_1 * T.int64(14) + ow_2_init * T.int64(2) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_1 * T.int64(16) + oc_block_2_init * T.int64(16) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(4), T.int64(1), T.int64(3), T.int64(1), T.int64(2), T.int64(1), T.int64(7), T.int64(1), T.int64(64), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2)):
                    for oc_block_3_fused in T.vectorized(T.int64(16)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(56) // T.int64(7) * T.int64(2) + oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(56) * T.int64(7) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(7) + oh_2 + oh_3)
                            v_ow = T.axis.spatial(T.int64(14), ow_1 * T.int64(14) + ow_2 * T.int64(2) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_1 * T.int64(16) + oc_block_2 * T.int64(16) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(64) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(14)):
                    for ax4_fused in T.vectorized(T.int64(16)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(56) // T.int64(7) * T.int64(2) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(56) * T.int64(7) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(7) + ax2)
                            v_ax3, v_ax4 = T.axis.remap("SS", [ax3, ax4_fused])
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 8, 2, 1])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[2, 7, 1, 1])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 7, 2])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[1, 1, 1, 16])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[4, 64])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[3, 1])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l50, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=7)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b69)
l85 = sch.fuse(l72, l73, l74, l75, l76, l77, l78, l79, preserve_unit_iters=True)
sch.parallel(loop=l85)
l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b70)
l105 = sch.fuse(l86, preserve_unit_iters=True)
sch.parallel(loop=l105)
l106 = sch.fuse(l104, preserve_unit_iters=True)
sch.vectorize(loop=l106)
sch.annotate(block_or_loop=l105, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l105, ann_key="pragma_unroll_explicit", ann_val=1)
l107, l108, l109, l110, l111, l112, l113, l114 = sch.get_loops(block=b71)
l115 = sch.fuse(l114, preserve_unit_iters=True)
sch.vectorize(loop=l115)
b116 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135 = sch.get_loops(block=b116)
b136 = sch.decompose_reduction(block=b116, loop=l120)
2024-04-29 04:30:44 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #250: GFLOPs: 119.2921. Time: 1939.4536 us. Best GFLOPs: 472.2663
2024-04-29 04:30:44 [INFO] [task_scheduler.cc:121] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #251: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(14), T.int64(14), T.int64(128)), "float32"), p1: T.Buffer((T.int64(16), T.int64(2), T.int64(3), T.int64(3), T.int64(128), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(16)), "float32"), p3: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(16), T.int64(16), T.int64(128)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused in T.parallel(T.int64(224), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(2), T.int64(3), T.int64(16), T.int64(128)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(112) // T.int64(56) * T.int64(7) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(7) + ax2)
                    v_i3, v_i4 = T.axis.remap("SS", [ax3, ax4])
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(15) and T.int64(1) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for ow_1, oc_block_1 in T.grid(T.int64(7), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(8)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(112) * T.int64(8) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(28) // T.int64(7) * T.int64(2) + oc_chunk_2_init + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(112) // T.int64(56) * T.int64(7) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(7) + oh_2_init + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(14), ow_1 * T.int64(2) + ow_2_init * T.int64(2) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(56) // T.int64(28) * T.int64(8) + oc_block_1 * T.int64(8) + oc_block_2_init * T.int64(8) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(32), T.int64(3), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(8), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(2)):
                    for oc_block_3_fused in T.vectorized(T.int64(8)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(112) * T.int64(8) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(28) // T.int64(7) * T.int64(2) + oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(112) // T.int64(56) * T.int64(7) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(7) + oh_2 + oh_3)
                            v_ow = T.axis.spatial(T.int64(14), ow_1 * T.int64(2) + ow_2 * T.int64(2) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(56) // T.int64(28) * T.int64(8) + oc_block_1 * T.int64(8) + oc_block_2 * T.int64(8) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(8) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(2)):
                    for ax4_fused in T.vectorized(T.int64(8)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(112) * T.int64(8) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(28) // T.int64(7) * T.int64(2) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(112) // T.int64(56) * T.int64(7) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(7) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(14), ow_1 * T.int64(2) + ax3)
                            v_ax4 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(56) // T.int64(28) * T.int64(8) + ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 4, 2, 1])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[2, 7, 1, 1])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 7, 1, 2])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[2, 1, 1, 8])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[32, 8])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[1, 3])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l50, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=7)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b69)
l85 = sch.fuse(l72, l73, l74, l75, l76, l77, l78, l79, preserve_unit_iters=True)
sch.parallel(loop=l85)
l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b70)
l105 = sch.fuse(l86, preserve_unit_iters=True)
sch.parallel(loop=l105)
l106 = sch.fuse(l104, preserve_unit_iters=True)
sch.vectorize(loop=l106)
sch.annotate(block_or_loop=l105, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l105, ann_key="pragma_unroll_explicit", ann_val=1)
l107, l108, l109, l110, l111, l112, l113, l114 = sch.get_loops(block=b71)
l115 = sch.fuse(l114, preserve_unit_iters=True)
sch.vectorize(loop=l115)
b116 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135 = sch.get_loops(block=b116)
b136 = sch.decompose_reduction(block=b116, loop=l120)
2024-04-29 04:30:44 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #252: GFLOPs: 190.2069. Time: 1216.3680 us. Best GFLOPs: 472.2663
2024-04-29 04:30:44 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #253: GFLOPs: 67.0873. Time: 3448.6654 us. Best GFLOPs: 472.2663
2024-04-29 04:30:44 [INFO] [task_scheduler.cc:121] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #254: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(14), T.int64(14), T.int64(128)), "float32"), p1: T.Buffer((T.int64(16), T.int64(2), T.int64(3), T.int64(3), T.int64(128), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(16)), "float32"), p3: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused in T.parallel(T.int64(392), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(2), T.int64(2), T.int64(1), T.int64(2)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused // T.int64(98) * T.int64(4) + oc_chunk_1 * T.int64(2) + oc_chunk_2_init + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused % T.int64(98) // T.int64(14) * T.int64(2) + oh_1 + oh_2_init + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused % T.int64(14) // T.int64(2) * T.int64(2) + ow_1 * T.int64(2) + ow_2_init * T.int64(2) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused % T.int64(2) * T.int64(8) + oc_block_1 * T.int64(4) + oc_block_2_init * T.int64(4) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(8), T.int64(3), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(32), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(2)):
                    for oc_block_3_fused in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused // T.int64(98) * T.int64(4) + oc_chunk_1 * T.int64(2) + oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused % T.int64(98) // T.int64(14) * T.int64(2) + oh_1 + oh_2 + oh_3)
                            v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused % T.int64(14) // T.int64(2) * T.int64(2) + ow_1 * T.int64(2) + ow_2 * T.int64(2) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused % T.int64(2) * T.int64(8) + oc_block_1 * T.int64(4) + oc_block_2 * T.int64(4) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(32) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], p0[v_n, v_ic // T.int64(128), v_oh + v_kh - T.int64(1), v_ow + v_kw - T.int64(1), v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + T.if_then_else(T.int64(1) <= v_oh + v_kh and v_oh + v_kh < T.int64(15) and T.int64(1) <= v_ow + v_kw and v_ow + v_kw < T.int64(15), p0[v_n, v_ic // T.int64(128), v_oh + v_kh - T.int64(1), v_ow + v_kw - T.int64(1), v_ic % T.int64(128)], T.float32(0)) * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(4), T.int64(2), T.int64(2)):
                for ax4_fused in T.vectorized(T.int64(8)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused // T.int64(98) * T.int64(4) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused % T.int64(98) // T.int64(14) * T.int64(2) + ax2)
                        v_ax3 = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused % T.int64(14) // T.int64(2) * T.int64(2) + ax3)
                        v_ax4 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused % T.int64(2) * T.int64(8) + ax4_fused)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[4, 2, 2, 1])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[7, 2, 1, 1])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[7, 1, 1, 2])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[2, 2, 1, 4])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[8, 32])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[1, 3])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=-2)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70 = sch.get_child_blocks(b68)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96 = sch.get_loops(block=b69)
l97 = sch.fuse(l71, l72, l73, l74, l75, preserve_unit_iters=True)
sch.parallel(loop=l97)
l98 = sch.fuse(l96, preserve_unit_iters=True)
sch.vectorize(loop=l98)
sch.annotate(block_or_loop=l97, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l97, ann_key="pragma_unroll_explicit", ann_val=1)
l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b70)
l105 = sch.fuse(l104, preserve_unit_iters=True)
sch.vectorize(loop=l105)
b106 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128 = sch.get_loops(block=b106)
b129 = sch.decompose_reduction(block=b106, loop=l113)
2024-04-29 04:30:44 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #255: GFLOPs: 45.2226. Time: 5116.0546 us. Best GFLOPs: 472.2663
2024-04-29 04:30:44 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #256: GFLOPs: 51.3299. Time: 4507.3413 us. Best GFLOPs: 472.2663
2024-04-29 04:30:44 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 04:30:45 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-29 04:30:50 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3639cb8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x419b828)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x312c9f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x425e1d8)]: 0 failure(s)
2024-04-29 04:30:50 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-29 04:31:02 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3639cb8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x419b828)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x312c9f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x425e1d8)]: 0 failure(s)
2024-04-29 04:31:15 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3639cb8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x419b828)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x312c9f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x425e1d8)]: 0 failure(s)
2024-04-29 04:31:27 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3639cb8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x419b828)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x312c9f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x425e1d8)]: 0 failure(s)
2024-04-29 04:31:40 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3639cb8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x419b828)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x312c9f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x425e1d8)]: 0 failure(s)
2024-04-29 04:31:47 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.8150  0.8150  0.7662  0.7374  0.7374  0.6691  0.6675  0.6675  0.6675  0.6635  0.6588  0.6588  0.6371  0.6032  0.6032  0.5981
[17 : 32]:	0.5969  0.5894  0.5751  0.5751  0.5538  0.5538  0.5401  0.5308  0.5241  0.5178  0.5157  0.5156  0.5156  0.5071  0.5049  0.5004
[33 : 48]:	0.4936  0.4928  0.4856  0.4785  0.4673  0.4671  0.4671  0.4651  0.4651  0.4613  0.4562  0.4540  0.4527  0.4511  0.4498  0.4482
[49 : 64]:	0.4460  0.4455  0.4455  0.4455  0.4418  0.4416  0.4416  0.4396  0.4394  0.4371  0.4359  0.4359  0.4359  0.4341  0.4317  0.4317
2024-04-29 04:31:48 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 04:31:48 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 04:33:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #257: GFLOPs: 470.2904. Time: 491.9546 us. Best GFLOPs: 472.2663
2024-04-29 04:33:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #258: GFLOPs: 368.1302. Time: 628.4775 us. Best GFLOPs: 472.2663
2024-04-29 04:33:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #259: GFLOPs: 179.3211. Time: 1290.2080 us. Best GFLOPs: 472.2663
2024-04-29 04:33:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #260: GFLOPs: 162.9949. Time: 1419.4401 us. Best GFLOPs: 472.2663
2024-04-29 04:33:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #261: GFLOPs: 270.2348. Time: 856.1499 us. Best GFLOPs: 472.2663
2024-04-29 04:33:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #262: GFLOPs: 142.7455. Time: 1620.7973 us. Best GFLOPs: 472.2663
2024-04-29 04:33:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #263: GFLOPs: 471.8890. Time: 490.2881 us. Best GFLOPs: 472.2663
2024-04-29 04:33:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #264: GFLOPs: 238.3964. Time: 970.4911 us. Best GFLOPs: 472.2663
2024-04-29 04:33:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #265: GFLOPs: 372.3832. Time: 621.2997 us. Best GFLOPs: 472.2663
2024-04-29 04:33:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #266: GFLOPs: 148.4323. Time: 1558.7008 us. Best GFLOPs: 472.2663
2024-04-29 04:33:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #267: GFLOPs: 238.1598. Time: 971.4549 us. Best GFLOPs: 472.2663
2024-04-29 04:33:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #268: GFLOPs: 468.8594. Time: 493.4561 us. Best GFLOPs: 472.2663
2024-04-29 04:33:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #269: GFLOPs: 121.3751. Time: 1906.1701 us. Best GFLOPs: 472.2663
2024-04-29 04:33:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #270: GFLOPs: 276.2644. Time: 837.4642 us. Best GFLOPs: 472.2663
2024-04-29 04:33:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #271: GFLOPs: 182.4181. Time: 1268.3034 us. Best GFLOPs: 472.2663
2024-04-29 04:33:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #272: GFLOPs: 215.4193. Time: 1074.0056 us. Best GFLOPs: 472.2663
2024-04-29 04:33:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #273: GFLOPs: 217.3242. Time: 1064.5919 us. Best GFLOPs: 472.2663
2024-04-29 04:33:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #274: GFLOPs: 131.2141. Time: 1763.2368 us. Best GFLOPs: 472.2663
2024-04-29 04:33:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #275: GFLOPs: 105.5539. Time: 2191.8800 us. Best GFLOPs: 472.2663
2024-04-29 04:33:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #276: GFLOPs: 184.4660. Time: 1254.2230 us. Best GFLOPs: 472.2663
2024-04-29 04:33:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #277: GFLOPs: 101.9143. Time: 2270.1570 us. Best GFLOPs: 472.2663
2024-04-29 04:33:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #278: GFLOPs: 380.6326. Time: 607.8342 us. Best GFLOPs: 472.2663
2024-04-29 04:33:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #279: GFLOPs: 512.6678. Time: 451.2894 us. Best GFLOPs: 512.6678
2024-04-29 04:33:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #280: GFLOPs: 175.7061. Time: 1316.7527 us. Best GFLOPs: 512.6678
2024-04-29 04:33:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #281: GFLOPs: 427.4668. Time: 541.2387 us. Best GFLOPs: 512.6678
2024-04-29 04:33:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #282: GFLOPs: 121.5935. Time: 1902.7454 us. Best GFLOPs: 512.6678
2024-04-29 04:33:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #283: GFLOPs: 93.9916. Time: 2461.5118 us. Best GFLOPs: 512.6678
2024-04-29 04:33:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #284: GFLOPs: 213.0253. Time: 1086.0752 us. Best GFLOPs: 512.6678
2024-04-29 04:33:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #285: GFLOPs: 327.7383. Time: 705.9339 us. Best GFLOPs: 512.6678
2024-04-29 04:33:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #286: GFLOPs: 363.5883. Time: 636.3283 us. Best GFLOPs: 512.6678
2024-04-29 04:33:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #287: GFLOPs: 229.7277. Time: 1007.1120 us. Best GFLOPs: 512.6678
2024-04-29 04:33:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #288: GFLOPs: 155.9728. Time: 1483.3450 us. Best GFLOPs: 512.6678
2024-04-29 04:33:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #289: GFLOPs: 132.8403. Time: 1741.6521 us. Best GFLOPs: 512.6678
2024-04-29 04:33:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #290: GFLOPs: 101.1135. Time: 2288.1365 us. Best GFLOPs: 512.6678
2024-04-29 04:33:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #291: GFLOPs: 139.0210. Time: 1664.2204 us. Best GFLOPs: 512.6678
2024-04-29 04:33:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #292: GFLOPs: 285.8273. Time: 809.4453 us. Best GFLOPs: 512.6678
2024-04-29 04:33:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #293: GFLOPs: 159.1691. Time: 1453.5578 us. Best GFLOPs: 512.6678
2024-04-29 04:33:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #294: GFLOPs: 143.4743. Time: 1612.5638 us. Best GFLOPs: 512.6678
2024-04-29 04:33:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #295: GFLOPs: 154.9796. Time: 1492.8520 us. Best GFLOPs: 512.6678
2024-04-29 04:33:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #296: GFLOPs: 556.9973. Time: 415.3728 us. Best GFLOPs: 556.9973
2024-04-29 04:33:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #297: GFLOPs: 239.3203. Time: 966.7442 us. Best GFLOPs: 556.9973
2024-04-29 04:33:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #298: GFLOPs: 134.3345. Time: 1722.2789 us. Best GFLOPs: 556.9973
2024-04-29 04:33:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #299: GFLOPs: 178.2393. Time: 1298.0391 us. Best GFLOPs: 556.9973
2024-04-29 04:33:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #300: GFLOPs: 159.7232. Time: 1448.5151 us. Best GFLOPs: 556.9973
2024-04-29 04:33:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #301: GFLOPs: 78.2045. Time: 2958.4161 us. Best GFLOPs: 556.9973
2024-04-29 04:33:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #302: GFLOPs: 171.4169. Time: 1349.7010 us. Best GFLOPs: 556.9973
2024-04-29 04:33:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #303: GFLOPs: 157.1367. Time: 1472.3588 us. Best GFLOPs: 556.9973
2024-04-29 04:33:15 [INFO] [task_scheduler.cc:121] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #304: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(14), T.int64(14), T.int64(128)), "float32"), p1: T.Buffer((T.int64(16), T.int64(2), T.int64(3), T.int64(3), T.int64(128), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(16)), "float32"), p3: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(16), T.int64(16), T.int64(128)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused in T.parallel(T.int64(28), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(8), T.int64(2), T.int64(1), T.int64(2), T.int64(1), T.int64(2), T.int64(7), T.int64(1)):
                for oc_block_3_fused_init in T.vectorized(T.int64(4)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(16), oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(14), oh_2_init * T.int64(7) + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(14) * T.int64(7) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(7) + ow_2_init + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(14) // T.int64(7) * T.int64(8) + oc_block_2_init * T.int64(4) + oc_block_3_fused_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
            for ic_0 in range(T.int64(64)):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(16), T.int64(3)):
                    for ax4_fused in T.vectorized(T.int64(4)):
                        with T.block("data_pad"):
                            v_i0 = T.axis.spatial(T.int64(1), ax0)
                            v_i1 = T.axis.spatial(T.int64(2), ic_0 // T.int64(32) + ax1)
                            v_i2 = T.axis.spatial(T.int64(16), ax2)
                            v_i3 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(14) * T.int64(7) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(7) + ax3)
                            v_i4 = T.axis.spatial(T.int64(128), ic_0 % T.int64(32) * T.int64(4) + ax4_fused)
                            T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                            T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                            data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(15) and T.int64(1) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                for kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(8), T.int64(2), T.int64(1), T.int64(2), T.int64(4), T.int64(3), T.int64(3), T.int64(1), T.int64(2), T.int64(7), T.int64(1)):
                    for oc_block_3_fused in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(16), oc_chunk_2 * T.int64(2) + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(14), oh_2 * T.int64(7) + oh_3)
                            v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(14) * T.int64(7) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(7) + ow_2 + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(14) // T.int64(7) * T.int64(8) + oc_block_2 * T.int64(4) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(4) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(16), T.int64(14), T.int64(1)):
                for ax4_fused in T.vectorized(T.int64(8)):
                    with T.block("T_relu"):
                        v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                        v_ax3 = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(14) * T.int64(7) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(7) + ax3)
                        v_ax4 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(14) // T.int64(7) * T.int64(8) + ax4_fused)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 8, 2])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 2, 7])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[2, 7, 1, 1])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[2, 1, 2, 4])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[64, 4])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[1, 3])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l50, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=10)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87 = sch.get_loops(block=b69)
l88 = sch.fuse(l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, preserve_unit_iters=True)
sch.parallel(loop=l88)
l89 = sch.fuse(l87, preserve_unit_iters=True)
sch.vectorize(loop=l89)
l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106 = sch.get_loops(block=b70)
l107 = sch.fuse(l90, preserve_unit_iters=True)
sch.parallel(loop=l107)
l108 = sch.fuse(l106, preserve_unit_iters=True)
sch.vectorize(loop=l108)
sch.annotate(block_or_loop=l107, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l107, ann_key="pragma_unroll_explicit", ann_val=1)
l109, l110, l111, l112, l113, l114 = sch.get_loops(block=b71)
l115 = sch.fuse(l114, preserve_unit_iters=True)
sch.vectorize(loop=l115)
b116 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133 = sch.get_loops(block=b116)
b134 = sch.decompose_reduction(block=b116, loop=l118)
2024-04-29 04:33:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #305: GFLOPs: 244.7331. Time: 945.3628 us. Best GFLOPs: 556.9973
2024-04-29 04:33:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #306: GFLOPs: 451.5991. Time: 512.3162 us. Best GFLOPs: 556.9973
2024-04-29 04:33:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #307: GFLOPs: 293.4527. Time: 788.4118 us. Best GFLOPs: 556.9973
2024-04-29 04:33:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #308: GFLOPs: 366.9869. Time: 630.4353 us. Best GFLOPs: 556.9973
2024-04-29 04:33:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #309: GFLOPs: 182.4964. Time: 1267.7592 us. Best GFLOPs: 556.9973
2024-04-29 04:33:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #310: GFLOPs: 73.7008. Time: 3139.2008 us. Best GFLOPs: 556.9973
2024-04-29 04:33:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #311: GFLOPs: 73.6011. Time: 3143.4512 us. Best GFLOPs: 556.9973
2024-04-29 04:33:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #312: GFLOPs: 99.6430. Time: 2321.9049 us. Best GFLOPs: 556.9973
2024-04-29 04:33:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #313: GFLOPs: 184.9838. Time: 1250.7125 us. Best GFLOPs: 556.9973
2024-04-29 04:33:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #314: GFLOPs: 107.3847. Time: 2154.5111 us. Best GFLOPs: 556.9973
2024-04-29 04:33:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #315: GFLOPs: 145.9305. Time: 1585.4227 us. Best GFLOPs: 556.9973
2024-04-29 04:33:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #316: GFLOPs: 188.7257. Time: 1225.9141 us. Best GFLOPs: 556.9973
2024-04-29 04:33:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #317: GFLOPs: 144.0354. Time: 1606.2822 us. Best GFLOPs: 556.9973
2024-04-29 04:33:15 [INFO] [task_scheduler.cc:121] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #318: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(14), T.int64(14), T.int64(128)), "float32"), p1: T.Buffer((T.int64(16), T.int64(2), T.int64(3), T.int64(3), T.int64(128), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(16)), "float32"), p3: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(16), T.int64(16), T.int64(128)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)))
        for i0_i1_i2_i3_i4_fused in T.parallel(T.int64(65536)):
            with T.block("data_pad"):
                v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                v_i1 = T.axis.spatial(T.int64(2), i0_i1_i2_i3_i4_fused // T.int64(32768))
                v_i2 = T.axis.spatial(T.int64(16), i0_i1_i2_i3_i4_fused % T.int64(32768) // T.int64(2048))
                v_i3 = T.axis.spatial(T.int64(16), i0_i1_i2_i3_i4_fused % T.int64(2048) // T.int64(128))
                v_i4 = T.axis.spatial(T.int64(128), i0_i1_i2_i3_i4_fused % T.int64(128))
                T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(15) and T.int64(1) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused in T.parallel(T.int64(32), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(7), T.int64(14), T.int64(1)):
                with T.block("conv2d_NCHWc_init"):
                    v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                    v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused // T.int64(4) * T.int64(2) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(2) + oc_chunk_2_init + oc_chunk_3_init)
                    v_oh = T.axis.spatial(T.int64(14), oh_2_init * T.int64(7) + oh_3_init)
                    v_ow = T.axis.spatial(T.int64(14), ow_2_init * T.int64(14) + ow_3_init)
                    v_oc_block = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(4) // T.int64(2) * T.int64(8) + oc_block_2_init + oc_block_3_init)
                    T.reads()
                    T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                    T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                    conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
            for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(8), T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(8), T.int64(32), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(14), T.int64(1)):
                with T.block("conv2d_NCHWc_update"):
                    v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                    v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused // T.int64(4) * T.int64(2) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(2) + oc_chunk_2 + oc_chunk_3)
                    v_oh = T.axis.spatial(T.int64(14), oh_2 * T.int64(7) + oh_3)
                    v_ow = T.axis.spatial(T.int64(14), ow_2 * T.int64(14) + ow_3)
                    v_oc_block = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(4) // T.int64(2) * T.int64(8) + oc_block_2 + oc_block_3)
                    v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(32) + ic_1)
                    v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                    v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                    T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                    T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                    T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                    conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(14), T.int64(14)):
                for ax4_fused in T.vectorized(T.int64(8)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused // T.int64(4) * T.int64(2) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(2) + ax1)
                        v_ax2, v_ax3 = T.axis.remap("SS", [ax2, ax3])
                        v_ax4 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(4) // T.int64(2) * T.int64(8) + ax4_fused)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[8, 2, 1, 1])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 2, 7])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 1, 14])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[2, 1, 8, 1])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[8, 32])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[3, 1])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l50, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=-1)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76 = sch.get_loops(block=b69)
l77 = sch.fuse(l72, l73, l74, l75, l76, preserve_unit_iters=True)
sch.parallel(loop=l77)
l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b70)
l104 = sch.fuse(l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, preserve_unit_iters=True)
sch.parallel(loop=l104)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109, l110 = sch.get_loops(block=b71)
l111 = sch.fuse(l110, preserve_unit_iters=True)
sch.vectorize(loop=l111)
b112 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l113, l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129 = sch.get_loops(block=b112)
b130 = sch.decompose_reduction(block=b112, loop=l114)
2024-04-29 04:33:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #319: GFLOPs: 16.9173. Time: 13675.9975 us. Best GFLOPs: 556.9973
2024-04-29 04:33:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #320: GFLOPs: 3.8044. Time: 60813.7627 us. Best GFLOPs: 556.9973
2024-04-29 04:53:36 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 04:53:37 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-29 04:53:42 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3639cb8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x419b828)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x312c9f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x425e1d8)]: 0 failure(s)
2024-04-29 04:53:42 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-29 04:53:54 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3639cb8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x419b828)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x312c9f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x425e1d8)]: 0 failure(s)
2024-04-29 04:54:07 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3639cb8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x419b828)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x312c9f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x425e1d8)]: 0 failure(s)
2024-04-29 04:54:21 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3639cb8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x419b828)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x312c9f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x425e1d8)]: 0 failure(s)
2024-04-29 04:54:35 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3639cb8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x419b828)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x312c9f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x425e1d8)]: 0 failure(s)
2024-04-29 04:54:43 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.8440  0.8440  0.8440  0.8440  0.8242  0.8242  0.8242  0.8242  0.8242  0.8211  0.8209  0.8202  0.8202  0.8202  0.8202  0.8202
[17 : 32]:	0.8202  0.8202  0.8175  0.8162  0.7195  0.7195  0.7170  0.7093  0.6889  0.6889  0.6853  0.6853  0.6761  0.6761  0.6761  0.6699
[33 : 48]:	0.6692  0.6494  0.6494  0.6466  0.6466  0.6466  0.6466  0.6437  0.6437  0.6403  0.6390  0.6390  0.6390  0.6356  0.6356  0.6356
[49 : 64]:	0.6351  0.6351  0.6343  0.6343  0.6323  0.6323  0.6323  0.6281  0.6281  0.6281  0.6281  0.6281  0.6211  0.6211  0.6149  0.6149
2024-04-29 04:54:43 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 04:54:44 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 04:56:12 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #321: GFLOPs: 352.3860. Time: 656.5571 us. Best GFLOPs: 556.9973
2024-04-29 04:56:12 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #322: GFLOPs: 520.0402. Time: 444.8916 us. Best GFLOPs: 556.9973
2024-04-29 04:56:12 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #323: GFLOPs: 419.8498. Time: 551.0579 us. Best GFLOPs: 556.9973
2024-04-29 04:56:12 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #324: GFLOPs: 350.3196. Time: 660.4299 us. Best GFLOPs: 556.9973
2024-04-29 04:56:12 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #325: GFLOPs: 289.7610. Time: 798.4565 us. Best GFLOPs: 556.9973
2024-04-29 04:56:12 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #326: GFLOPs: 563.7854. Time: 410.3716 us. Best GFLOPs: 563.7854
2024-04-29 04:56:12 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #327: GFLOPs: 276.2681. Time: 837.4528 us. Best GFLOPs: 563.7854
2024-04-29 04:56:12 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #328: GFLOPs: 230.5491. Time: 1003.5240 us. Best GFLOPs: 563.7854
2024-04-29 04:56:12 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #329: GFLOPs: 159.7215. Time: 1448.5312 us. Best GFLOPs: 563.7854
2024-04-29 04:56:12 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #330: GFLOPs: 229.5611. Time: 1007.8428 us. Best GFLOPs: 563.7854
2024-04-29 04:56:12 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #331: GFLOPs: 290.5704. Time: 796.2323 us. Best GFLOPs: 563.7854
2024-04-29 04:56:12 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #332: GFLOPs: 290.4179. Time: 796.6504 us. Best GFLOPs: 563.7854
2024-04-29 04:56:12 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #333: GFLOPs: 563.5583. Time: 410.5370 us. Best GFLOPs: 563.7854
2024-04-29 04:56:12 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #334: GFLOPs: 289.8115. Time: 798.3172 us. Best GFLOPs: 563.7854
2024-04-29 04:56:12 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #335: GFLOPs: 451.7538. Time: 512.1408 us. Best GFLOPs: 563.7854
2024-04-29 04:56:12 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #336: GFLOPs: 289.8654. Time: 798.1688 us. Best GFLOPs: 563.7854
2024-04-29 04:56:12 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #337: GFLOPs: 565.0273. Time: 409.4697 us. Best GFLOPs: 565.0273
2024-04-29 04:56:12 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #338: GFLOPs: 564.0865. Time: 410.1526 us. Best GFLOPs: 565.0273
2024-04-29 04:56:12 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #339: GFLOPs: 561.9469. Time: 411.7142 us. Best GFLOPs: 565.0273
2024-04-29 04:56:12 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #340: GFLOPs: 453.0429. Time: 510.6835 us. Best GFLOPs: 565.0273
2024-04-29 04:56:12 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #341: GFLOPs: 461.0427. Time: 501.8224 us. Best GFLOPs: 565.0273
2024-04-29 04:56:12 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #342: GFLOPs: 121.3127. Time: 1907.1508 us. Best GFLOPs: 565.0273
2024-04-29 04:56:12 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #343: GFLOPs: 462.2101. Time: 500.5549 us. Best GFLOPs: 565.0273
2024-04-29 04:56:12 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #344: GFLOPs: 239.6409. Time: 965.4508 us. Best GFLOPs: 565.0273
2024-04-29 04:56:12 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #345: GFLOPs: 471.6509. Time: 490.5355 us. Best GFLOPs: 565.0273
2024-04-29 04:56:12 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #346: GFLOPs: 241.2194. Time: 959.1332 us. Best GFLOPs: 565.0273
2024-04-29 04:56:12 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #347: GFLOPs: 363.4909. Time: 636.4989 us. Best GFLOPs: 565.0273
2024-04-29 04:56:12 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #348: GFLOPs: 486.4520. Time: 475.6102 us. Best GFLOPs: 565.0273
2024-04-29 04:56:12 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #349: GFLOPs: 238.9891. Time: 968.0842 us. Best GFLOPs: 565.0273
2024-04-29 04:56:12 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #350: GFLOPs: 475.2530. Time: 486.8177 us. Best GFLOPs: 565.0273
2024-04-29 04:56:12 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #351: GFLOPs: 368.3148. Time: 628.1624 us. Best GFLOPs: 565.0273
2024-04-29 04:56:12 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #352: GFLOPs: 408.6771. Time: 566.1230 us. Best GFLOPs: 565.0273
2024-04-29 04:56:12 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #353: GFLOPs: 489.3974. Time: 472.7478 us. Best GFLOPs: 565.0273
2024-04-29 04:56:12 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #354: GFLOPs: 201.0756. Time: 1150.6197 us. Best GFLOPs: 565.0273
2024-04-29 04:56:12 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #355: GFLOPs: 266.5498. Time: 867.9861 us. Best GFLOPs: 565.0273
2024-04-29 04:56:12 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #356: GFLOPs: 138.8160. Time: 1666.6783 us. Best GFLOPs: 565.0273
2024-04-29 04:56:12 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #357: GFLOPs: 250.3537. Time: 924.1386 us. Best GFLOPs: 565.0273
2024-04-29 04:56:12 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #358: GFLOPs: 192.1789. Time: 1203.8860 us. Best GFLOPs: 565.0273
2024-04-29 04:56:12 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #359: GFLOPs: 179.6702. Time: 1287.7013 us. Best GFLOPs: 565.0273
2024-04-29 04:56:12 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #360: GFLOPs: 183.7443. Time: 1259.1493 us. Best GFLOPs: 565.0273
2024-04-29 04:56:12 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #361: GFLOPs: 289.1061. Time: 800.2651 us. Best GFLOPs: 565.0273
2024-04-29 04:56:12 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #362: GFLOPs: 502.8233. Time: 460.1249 us. Best GFLOPs: 565.0273
2024-04-29 04:56:12 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #363: GFLOPs: 503.4604. Time: 459.5426 us. Best GFLOPs: 565.0273
2024-04-29 04:56:12 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #364: GFLOPs: 239.6594. Time: 965.3763 us. Best GFLOPs: 565.0273
2024-04-29 04:56:12 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #365: GFLOPs: 370.3478. Time: 624.7142 us. Best GFLOPs: 565.0273
2024-04-29 04:56:12 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #366: GFLOPs: 438.4767. Time: 527.6485 us. Best GFLOPs: 565.0273
2024-04-29 04:56:12 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #367: GFLOPs: 499.4709. Time: 463.2133 us. Best GFLOPs: 565.0273
2024-04-29 04:56:12 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #368: GFLOPs: 248.8911. Time: 929.5693 us. Best GFLOPs: 565.0273
2024-04-29 04:56:12 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #369: GFLOPs: 182.4944. Time: 1267.7732 us. Best GFLOPs: 565.0273
2024-04-29 04:56:12 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #370: GFLOPs: 362.9611. Time: 637.4279 us. Best GFLOPs: 565.0273
2024-04-29 04:56:12 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #371: GFLOPs: 249.1005. Time: 928.7881 us. Best GFLOPs: 565.0273
2024-04-29 04:56:12 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #372: GFLOPs: 437.6548. Time: 528.6394 us. Best GFLOPs: 565.0273
2024-04-29 04:56:12 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #373: GFLOPs: 499.8619. Time: 462.8509 us. Best GFLOPs: 565.0273
2024-04-29 04:56:12 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #374: GFLOPs: 440.1390. Time: 525.6556 us. Best GFLOPs: 565.0273
2024-04-29 04:56:12 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #375: GFLOPs: 250.5880. Time: 923.2748 us. Best GFLOPs: 565.0273
2024-04-29 04:56:12 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #376: GFLOPs: 250.2949. Time: 924.3559 us. Best GFLOPs: 565.0273
2024-04-29 04:56:12 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #377: GFLOPs: 249.9908. Time: 925.4800 us. Best GFLOPs: 565.0273
2024-04-29 04:56:12 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #378: GFLOPs: 263.9228. Time: 876.6259 us. Best GFLOPs: 565.0273
2024-04-29 04:56:12 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #379: GFLOPs: 499.0877. Time: 463.5689 us. Best GFLOPs: 565.0273
2024-04-29 04:56:12 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #380: GFLOPs: 316.8482. Time: 730.1968 us. Best GFLOPs: 565.0273
2024-04-29 04:56:12 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #381: GFLOPs: 130.2326. Time: 1776.5260 us. Best GFLOPs: 565.0273
2024-04-29 04:56:12 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #382: GFLOPs: 72.1284. Time: 3207.6365 us. Best GFLOPs: 565.0273
2024-04-29 04:56:12 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #383: GFLOPs: 3.2615. Time: 70936.3503 us. Best GFLOPs: 565.0273
2024-04-29 04:56:12 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #384: GFLOPs: 18.1425. Time: 12752.4358 us. Best GFLOPs: 565.0273
2024-04-29 05:06:15 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 05:06:17 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-29 05:06:21 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3639cb8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x419b828)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x312c9f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x425e1d8)]: 0 failure(s)
2024-04-29 05:06:21 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-29 05:06:34 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3639cb8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x419b828)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x312c9f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x425e1d8)]: 0 failure(s)
2024-04-29 05:06:48 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3639cb8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x419b828)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x312c9f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x425e1d8)]: 0 failure(s)
2024-04-29 05:07:02 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3639cb8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x419b828)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x312c9f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x425e1d8)]: 0 failure(s)
2024-04-29 05:07:17 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3639cb8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x419b828)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x312c9f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x425e1d8)]: 0 failure(s)
2024-04-29 05:07:26 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9305  0.9305  0.9305  0.9305  0.8384  0.8384  0.8384  0.8384  0.8384  0.8384  0.8245  0.8117  0.8117  0.8117  0.8117  0.8117
[17 : 32]:	0.8117  0.8117  0.8117  0.8117  0.8082  0.8042  0.8042  0.7988  0.7988  0.7988  0.7988  0.7988  0.7896  0.7896  0.7778  0.7778
[33 : 48]:	0.7685  0.7685  0.7683  0.7683  0.7676  0.7676  0.7676  0.7676  0.7676  0.7668  0.7668  0.7668  0.7532  0.7446  0.7446  0.7446
[49 : 64]:	0.7335  0.7325  0.7320  0.7318  0.7296  0.7296  0.7283  0.7201  0.7200  0.7184  0.7184  0.7181  0.7133  0.7115  0.7093  0.7093
2024-04-29 05:07:26 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 05:07:26 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 05:08:53 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #385: GFLOPs: 152.8499. Time: 1513.6515 us. Best GFLOPs: 565.0273
2024-04-29 05:08:53 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #386: GFLOPs: 232.8899. Time: 993.4375 us. Best GFLOPs: 565.0273
2024-04-29 05:08:53 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #387: GFLOPs: 152.5319. Time: 1516.8076 us. Best GFLOPs: 565.0273
2024-04-29 05:08:53 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #388: GFLOPs: 228.6581. Time: 1011.8231 us. Best GFLOPs: 565.0273
2024-04-29 05:08:53 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #389: GFLOPs: 141.0178. Time: 1640.6550 us. Best GFLOPs: 565.0273
2024-04-29 05:08:53 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #390: GFLOPs: 244.6267. Time: 945.7740 us. Best GFLOPs: 565.0273
2024-04-29 05:08:53 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #391: GFLOPs: 371.5369. Time: 622.7148 us. Best GFLOPs: 565.0273
2024-04-29 05:08:53 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #392: GFLOPs: 241.2913. Time: 958.8473 us. Best GFLOPs: 565.0273
2024-04-29 05:08:53 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #393: GFLOPs: 502.0166. Time: 460.8643 us. Best GFLOPs: 565.0273
2024-04-29 05:08:53 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #394: GFLOPs: 371.3513. Time: 623.0261 us. Best GFLOPs: 565.0273
2024-04-29 05:08:53 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #395: GFLOPs: 565.9137. Time: 408.8283 us. Best GFLOPs: 565.9137
2024-04-29 05:08:53 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #396: GFLOPs: 290.9190. Time: 795.2782 us. Best GFLOPs: 565.9137
2024-04-29 05:08:53 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #397: GFLOPs: 452.1543. Time: 511.6871 us. Best GFLOPs: 565.9137
2024-04-29 05:08:53 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #398: GFLOPs: 563.4721. Time: 410.5998 us. Best GFLOPs: 565.9137
2024-04-29 05:08:53 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #399: GFLOPs: 451.5671. Time: 512.3525 us. Best GFLOPs: 565.9137
2024-04-29 05:08:53 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #400: GFLOPs: 563.7670. Time: 410.3850 us. Best GFLOPs: 565.9137
2024-04-29 05:08:53 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #401: GFLOPs: 563.8883. Time: 410.2968 us. Best GFLOPs: 565.9137
2024-04-29 05:08:53 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #402: GFLOPs: 291.1394. Time: 794.6762 us. Best GFLOPs: 565.9137
2024-04-29 05:08:53 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #403: GFLOPs: 452.2697. Time: 511.5566 us. Best GFLOPs: 565.9137
2024-04-29 05:08:53 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #404: GFLOPs: 247.2151. Time: 935.8713 us. Best GFLOPs: 565.9137
2024-04-29 05:08:53 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #405: GFLOPs: 361.4546. Time: 640.0847 us. Best GFLOPs: 565.9137
2024-04-29 05:08:53 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #406: GFLOPs: 457.2684. Time: 505.9644 us. Best GFLOPs: 565.9137
2024-04-29 05:08:53 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #407: GFLOPs: 135.0647. Time: 1712.9686 us. Best GFLOPs: 565.9137
2024-04-29 05:08:53 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #408: GFLOPs: 565.3487. Time: 409.2369 us. Best GFLOPs: 565.9137
2024-04-29 05:08:53 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #409: GFLOPs: 564.4214. Time: 409.9092 us. Best GFLOPs: 565.9137
2024-04-29 05:08:53 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #410: GFLOPs: 453.4033. Time: 510.2776 us. Best GFLOPs: 565.9137
2024-04-29 05:08:53 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #411: GFLOPs: 291.9677. Time: 792.4217 us. Best GFLOPs: 565.9137
2024-04-29 05:08:53 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #412: GFLOPs: 291.8635. Time: 792.7047 us. Best GFLOPs: 565.9137
2024-04-29 05:08:53 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #413: GFLOPs: 357.2291. Time: 647.6559 us. Best GFLOPs: 565.9137
2024-04-29 05:08:53 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #414: GFLOPs: 527.0712. Time: 438.9569 us. Best GFLOPs: 565.9137
2024-04-29 05:08:53 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #415: GFLOPs: 253.0197. Time: 914.4014 us. Best GFLOPs: 565.9137
2024-04-29 05:08:53 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #416: GFLOPs: 501.3403. Time: 461.4861 us. Best GFLOPs: 565.9137
2024-04-29 05:08:53 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #417: GFLOPs: 367.1785. Time: 630.1064 us. Best GFLOPs: 565.9137
2024-04-29 05:08:53 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #418: GFLOPs: 133.6331. Time: 1731.3196 us. Best GFLOPs: 565.9137
2024-04-29 05:08:53 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #419: GFLOPs: 589.7669. Time: 392.2932 us. Best GFLOPs: 589.7669
2024-04-29 05:08:53 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #420: GFLOPs: 134.3049. Time: 1722.6590 us. Best GFLOPs: 589.7669
2024-04-29 05:08:53 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #421: GFLOPs: 362.7587. Time: 637.7835 us. Best GFLOPs: 589.7669
2024-04-29 05:08:53 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #422: GFLOPs: 485.4065. Time: 476.6346 us. Best GFLOPs: 589.7669
2024-04-29 05:08:53 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #423: GFLOPs: 368.8073. Time: 627.3237 us. Best GFLOPs: 589.7669
2024-04-29 05:08:53 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #424: GFLOPs: 486.3813. Time: 475.6793 us. Best GFLOPs: 589.7669
2024-04-29 05:08:53 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #425: GFLOPs: 363.5810. Time: 636.3410 us. Best GFLOPs: 589.7669
2024-04-29 05:08:53 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #426: GFLOPs: 418.0758. Time: 553.3962 us. Best GFLOPs: 589.7669
2024-04-29 05:08:53 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #427: GFLOPs: 519.2653. Time: 445.5555 us. Best GFLOPs: 589.7669
2024-04-29 05:08:53 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #428: GFLOPs: 326.2993. Time: 709.0470 us. Best GFLOPs: 589.7669
2024-04-29 05:08:53 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #429: GFLOPs: 367.3645. Time: 629.7874 us. Best GFLOPs: 589.7669
2024-04-29 05:08:53 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #430: GFLOPs: 438.9792. Time: 527.0444 us. Best GFLOPs: 589.7669
2024-04-29 05:08:53 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #431: GFLOPs: 500.7806. Time: 462.0018 us. Best GFLOPs: 589.7669
2024-04-29 05:08:53 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #432: GFLOPs: 250.2697. Time: 924.4487 us. Best GFLOPs: 589.7669
2024-04-29 05:08:53 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #433: GFLOPs: 503.3609. Time: 459.6335 us. Best GFLOPs: 589.7669
2024-04-29 05:08:53 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #434: GFLOPs: 172.9604. Time: 1337.6558 us. Best GFLOPs: 589.7669
2024-04-29 05:08:53 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #435: GFLOPs: 241.9051. Time: 956.4146 us. Best GFLOPs: 589.7669
2024-04-29 05:08:53 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #436: GFLOPs: 497.0153. Time: 465.5018 us. Best GFLOPs: 589.7669
2024-04-29 05:08:53 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #437: GFLOPs: 218.0289. Time: 1061.1508 us. Best GFLOPs: 589.7669
2024-04-29 05:08:53 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #438: GFLOPs: 327.0909. Time: 707.3310 us. Best GFLOPs: 589.7669
2024-04-29 05:08:53 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #439: GFLOPs: 452.9272. Time: 510.8139 us. Best GFLOPs: 589.7669
2024-04-29 05:08:53 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #440: GFLOPs: 457.6881. Time: 505.5004 us. Best GFLOPs: 589.7669
2024-04-29 05:08:53 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #441: GFLOPs: 376.3755. Time: 614.7093 us. Best GFLOPs: 589.7669
2024-04-29 05:08:53 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #442: GFLOPs: 170.6336. Time: 1355.8970 us. Best GFLOPs: 589.7669
2024-04-29 05:08:53 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #443: GFLOPs: 554.8453. Time: 416.9838 us. Best GFLOPs: 589.7669
2024-04-29 05:08:53 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #444: GFLOPs: 285.3257. Time: 810.8682 us. Best GFLOPs: 589.7669
2024-04-29 05:08:53 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #445: GFLOPs: 172.2334. Time: 1343.3025 us. Best GFLOPs: 589.7669
2024-04-29 05:08:53 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #446: GFLOPs: 10.3957. Time: 22255.4394 us. Best GFLOPs: 589.7669
2024-04-29 05:08:53 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #447: GFLOPs: 45.2623. Time: 5111.5717 us. Best GFLOPs: 589.7669
2024-04-29 05:08:53 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #448: GFLOPs: 20.5090. Time: 11280.9631 us. Best GFLOPs: 589.7669
2024-04-29 05:33:50 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 05:33:51 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-29 05:33:56 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3639cb8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x419b828)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x312c9f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x425e1d8)]: 0 failure(s)
2024-04-29 05:33:56 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-29 05:34:09 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3639cb8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x419b828)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x312c9f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x425e1d8)]: 0 failure(s)
2024-04-29 05:34:23 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3639cb8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x419b828)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x312c9f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x425e1d8)]: 0 failure(s)
2024-04-29 05:34:37 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3639cb8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x419b828)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x312c9f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x425e1d8)]: 0 failure(s)
2024-04-29 05:34:52 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3639cb8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x419b828)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x312c9f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x425e1d8)]: 0 failure(s)
2024-04-29 05:35:01 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.8275  0.8275  0.8275  0.8275  0.7815  0.7815  0.7815  0.7732  0.7700  0.7700  0.7684  0.7684  0.7679  0.7679  0.7679  0.7650
[17 : 32]:	0.7650  0.7650  0.7486  0.7469  0.7467  0.7411  0.7411  0.7363  0.7363  0.7269  0.7269  0.7234  0.7234  0.7234  0.7234  0.7226
[33 : 48]:	0.7183  0.7183  0.7173  0.7143  0.7125  0.7099  0.7099  0.7099  0.7045  0.7045  0.7045  0.7045  0.7045  0.6841  0.6819  0.6819
[49 : 64]:	0.6819  0.6818  0.6787  0.6787  0.6787  0.6761  0.6761  0.6761  0.6739  0.6723  0.6723  0.6711  0.6699  0.6679  0.6659  0.6659
2024-04-29 05:35:01 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 05:35:02 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 05:36:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #449: GFLOPs: 291.2506. Time: 794.3728 us. Best GFLOPs: 589.7669
2024-04-29 05:36:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #450: GFLOPs: 452.2826. Time: 511.5419 us. Best GFLOPs: 589.7669
2024-04-29 05:36:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #451: GFLOPs: 452.4522. Time: 511.3502 us. Best GFLOPs: 589.7669
2024-04-29 05:36:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #452: GFLOPs: 290.6233. Time: 796.0874 us. Best GFLOPs: 589.7669
2024-04-29 05:36:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #453: GFLOPs: 291.2063. Time: 794.4937 us. Best GFLOPs: 589.7669
2024-04-29 05:36:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #454: GFLOPs: 452.4287. Time: 511.3768 us. Best GFLOPs: 589.7669
2024-04-29 05:36:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #455: GFLOPs: 453.8889. Time: 509.7316 us. Best GFLOPs: 589.7669
2024-04-29 05:36:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #456: GFLOPs: 109.6883. Time: 2109.2627 us. Best GFLOPs: 589.7669
2024-04-29 05:36:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #457: GFLOPs: 552.6757. Time: 418.6208 us. Best GFLOPs: 589.7669
2024-04-29 05:36:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #458: GFLOPs: 202.1478. Time: 1144.5169 us. Best GFLOPs: 589.7669
2024-04-29 05:36:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #459: GFLOPs: 525.4936. Time: 440.2747 us. Best GFLOPs: 589.7669
2024-04-29 05:36:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #460: GFLOPs: 420.0191. Time: 550.8358 us. Best GFLOPs: 589.7669
2024-04-29 05:36:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #461: GFLOPs: 496.0005. Time: 466.4542 us. Best GFLOPs: 589.7669
2024-04-29 05:36:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #462: GFLOPs: 189.7996. Time: 1218.9780 us. Best GFLOPs: 589.7669
2024-04-29 05:36:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #463: GFLOPs: 100.1694. Time: 2309.7019 us. Best GFLOPs: 589.7669
2024-04-29 05:36:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #464: GFLOPs: 420.3591. Time: 550.3902 us. Best GFLOPs: 589.7669
2024-04-29 05:36:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #465: GFLOPs: 525.9911. Time: 439.8582 us. Best GFLOPs: 589.7669
2024-04-29 05:36:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #466: GFLOPs: 519.4960. Time: 445.3576 us. Best GFLOPs: 589.7669
2024-04-29 05:36:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #467: GFLOPs: 684.3800. Time: 338.0601 us. Best GFLOPs: 684.3800
2024-04-29 05:36:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #468: GFLOPs: 671.7106. Time: 344.4363 us. Best GFLOPs: 684.3800
2024-04-29 05:36:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #469: GFLOPs: 421.0294. Time: 549.5139 us. Best GFLOPs: 684.3800
2024-04-29 05:36:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #470: GFLOPs: 254.1209. Time: 910.4388 us. Best GFLOPs: 684.3800
2024-04-29 05:36:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #471: GFLOPs: 519.7380. Time: 445.1504 us. Best GFLOPs: 684.3800
2024-04-29 05:36:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #472: GFLOPs: 563.4272. Time: 410.6325 us. Best GFLOPs: 684.3800
2024-04-29 05:36:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #473: GFLOPs: 290.8975. Time: 795.3369 us. Best GFLOPs: 684.3800
2024-04-29 05:36:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #474: GFLOPs: 368.1775. Time: 628.3967 us. Best GFLOPs: 684.3800
2024-04-29 05:36:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #475: GFLOPs: 487.6229. Time: 474.4682 us. Best GFLOPs: 684.3800
2024-04-29 05:36:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #476: GFLOPs: 249.8722. Time: 925.9195 us. Best GFLOPs: 684.3800
2024-04-29 05:36:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #477: GFLOPs: 437.9235. Time: 528.3149 us. Best GFLOPs: 684.3800
2024-04-29 05:36:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #478: GFLOPs: 499.2408. Time: 463.4267 us. Best GFLOPs: 684.3800
2024-04-29 05:36:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #479: GFLOPs: 129.1345. Time: 1791.6323 us. Best GFLOPs: 684.3800
2024-04-29 05:36:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #480: GFLOPs: 237.9832. Time: 972.1758 us. Best GFLOPs: 684.3800
2024-04-29 05:36:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #481: GFLOPs: 302.0322. Time: 766.0160 us. Best GFLOPs: 684.3800
2024-04-29 05:36:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #482: GFLOPs: 299.6890. Time: 772.0055 us. Best GFLOPs: 684.3800
2024-04-29 05:36:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #483: GFLOPs: 227.0861. Time: 1018.8275 us. Best GFLOPs: 684.3800
2024-04-29 05:36:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #484: GFLOPs: 363.1276. Time: 637.1356 us. Best GFLOPs: 684.3800
2024-04-29 05:36:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #485: GFLOPs: 110.4104. Time: 2095.4689 us. Best GFLOPs: 684.3800
2024-04-29 05:36:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #486: GFLOPs: 190.5724. Time: 1214.0352 us. Best GFLOPs: 684.3800
2024-04-29 05:36:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #487: GFLOPs: 146.3368. Time: 1581.0209 us. Best GFLOPs: 684.3800
2024-04-29 05:36:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #488: GFLOPs: 111.0454. Time: 2083.4864 us. Best GFLOPs: 684.3800
2024-04-29 05:36:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #489: GFLOPs: 486.2105. Time: 475.8464 us. Best GFLOPs: 684.3800
2024-04-29 05:36:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #490: GFLOPs: 362.6619. Time: 637.9538 us. Best GFLOPs: 684.3800
2024-04-29 05:36:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #491: GFLOPs: 363.5889. Time: 636.3273 us. Best GFLOPs: 684.3800
2024-04-29 05:36:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #492: GFLOPs: 486.1118. Time: 475.9431 us. Best GFLOPs: 684.3800
2024-04-29 05:36:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #493: GFLOPs: 329.7883. Time: 701.5456 us. Best GFLOPs: 684.3800
2024-04-29 05:36:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #494: GFLOPs: 186.4898. Time: 1240.6121 us. Best GFLOPs: 684.3800
2024-04-29 05:36:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #495: GFLOPs: 252.4468. Time: 916.4764 us. Best GFLOPs: 684.3800
2024-04-29 05:36:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #496: GFLOPs: 440.6171. Time: 525.0852 us. Best GFLOPs: 684.3800
2024-04-29 05:36:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #497: GFLOPs: 501.5947. Time: 461.2519 us. Best GFLOPs: 684.3800
2024-04-29 05:36:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #498: GFLOPs: 510.2042. Time: 453.4685 us. Best GFLOPs: 684.3800
2024-04-29 05:36:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #499: GFLOPs: 452.9536. Time: 510.7842 us. Best GFLOPs: 684.3800
2024-04-29 05:36:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #500: GFLOPs: 453.2265. Time: 510.4766 us. Best GFLOPs: 684.3800
2024-04-29 05:36:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #501: GFLOPs: 564.8748. Time: 409.5802 us. Best GFLOPs: 684.3800
2024-04-29 05:36:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #502: GFLOPs: 224.8825. Time: 1028.8109 us. Best GFLOPs: 684.3800
2024-04-29 05:36:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #503: GFLOPs: 108.7831. Time: 2126.8149 us. Best GFLOPs: 684.3800
2024-04-29 05:36:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #504: GFLOPs: 131.7565. Time: 1755.9786 us. Best GFLOPs: 684.3800
2024-04-29 05:36:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #505: GFLOPs: 107.2007. Time: 2158.2090 us. Best GFLOPs: 684.3800
2024-04-29 05:36:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #506: GFLOPs: 368.1088. Time: 628.5140 us. Best GFLOPs: 684.3800
2024-04-29 05:36:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #507: GFLOPs: 429.4880. Time: 538.6915 us. Best GFLOPs: 684.3800
2024-04-29 05:36:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #508: GFLOPs: 502.6574. Time: 460.2768 us. Best GFLOPs: 684.3800
2024-04-29 05:36:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #509: GFLOPs: 492.6736. Time: 469.6040 us. Best GFLOPs: 684.3800
2024-04-29 05:36:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #510: GFLOPs: 37.5155. Time: 6167.0946 us. Best GFLOPs: 684.3800
2024-04-29 05:36:36 [INFO] [task_scheduler.cc:121] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #511: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(14), T.int64(14), T.int64(128)), "float32"), p1: T.Buffer((T.int64(16), T.int64(2), T.int64(3), T.int64(3), T.int64(128), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(16)), "float32"), p3: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(16), T.int64(16), T.int64(128)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused in T.parallel(T.int64(16), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(14), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(8), T.int64(1), T.int64(14), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(16), oc_chunk_1 * T.int64(16) + oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(14), oh_1 + oh_2_init + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(14), ow_1 * T.int64(14) + ow_2_init + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused + oc_block_1 + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0 in range(T.int64(16)):
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(3), T.int64(16)):
                        for ax4_fused in T.vectorized(T.int64(16)):
                            with T.block("data_pad"):
                                v_i0 = T.axis.spatial(T.int64(1), ax0)
                                v_i1 = T.axis.spatial(T.int64(2), ic_0 // T.int64(8) + ax1)
                                v_i2 = T.axis.spatial(T.int64(16), oh_1 + ax2)
                                v_i3 = T.axis.spatial(T.int64(16), ax3)
                                v_i4 = T.axis.spatial(T.int64(128), ic_0 % T.int64(8) * T.int64(16) + ax4_fused)
                                T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                                T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                                data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(15) and T.int64(1) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                    for kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(3), T.int64(1), T.int64(1), T.int64(8), T.int64(1), T.int64(14), T.int64(1), T.int64(16), T.int64(1), T.int64(3), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(16), oc_chunk_1 * T.int64(16) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(14), oh_1 + oh_2 + oh_3)
                            v_ow = T.axis.spatial(T.int64(14), ow_1 * T.int64(14) + ow_2 + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused + oc_block_1 + oc_block_2 + oc_block_3)
                            v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(16) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(1)):
                with T.block("T_relu"):
                    v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                    v_ax4 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused + ax4)
                    T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 8, 2])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 14, 1, 1])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 14, 1])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[16, 1, 1, 1])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[16, 16])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[1, 3])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=10)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87 = sch.get_loops(block=b69)
l88 = sch.fuse(l72, l73, l74, l75, l76, preserve_unit_iters=True)
sch.parallel(loop=l88)
l89 = sch.fuse(l87, preserve_unit_iters=True)
sch.vectorize(loop=l89)
l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107, l108, l109, l110, l111 = sch.get_loops(block=b70)
l112 = sch.fuse(l90, preserve_unit_iters=True)
sch.parallel(loop=l112)
sch.annotate(block_or_loop=l112, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l112, ann_key="pragma_unroll_explicit", ann_val=1)
l113, l114, l115, l116, l117, l118 = sch.get_loops(block=b71)
b119 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141 = sch.get_loops(block=b119)
b142 = sch.decompose_reduction(block=b119, loop=l126)
2024-04-29 05:36:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #512: GFLOPs: 49.7922. Time: 4646.5402 us. Best GFLOPs: 684.3800
2024-04-29 05:51:32 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 05:51:33 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-29 05:51:38 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3639cb8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x419b828)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x312c9f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x425e1d8)]: 0 failure(s)
2024-04-29 05:51:38 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-29 05:51:51 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3639cb8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x419b828)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x312c9f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x425e1d8)]: 0 failure(s)
2024-04-29 05:52:05 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3639cb8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x419b828)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x312c9f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x425e1d8)]: 0 failure(s)
2024-04-29 05:52:20 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3639cb8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x419b828)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x312c9f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x425e1d8)]: 0 failure(s)
2024-04-29 05:52:35 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3639cb8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x419b828)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x312c9f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x425e1d8)]: 0 failure(s)
2024-04-29 05:52:44 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9968  0.9574  0.8801  0.8801  0.8573  0.8475  0.8473  0.8383  0.8073  0.8073  0.7770  0.7770  0.7270  0.7267  0.7177  0.7022
[17 : 32]:	0.7022  0.6791  0.6769  0.6736  0.6726  0.6692  0.6581  0.6420  0.6416  0.6416  0.6416  0.6416  0.6398  0.6398  0.6396  0.6302
[33 : 48]:	0.6227  0.6227  0.6227  0.6205  0.6200  0.6193  0.6193  0.6193  0.6176  0.6176  0.6176  0.6161  0.6109  0.6094  0.6087  0.6087
[49 : 64]:	0.6058  0.6058  0.5966  0.5966  0.5966  0.5900  0.5900  0.5840  0.5840  0.5836  0.5836  0.5836  0.5836  0.5836  0.5836  0.5836
2024-04-29 05:52:44 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 05:52:44 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 05:54:11 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #513: GFLOPs: 544.4818. Time: 424.9206 us. Best GFLOPs: 684.3800
2024-04-29 05:54:11 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #514: GFLOPs: 675.8679. Time: 342.3177 us. Best GFLOPs: 684.3800
2024-04-29 05:54:11 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #515: GFLOPs: 810.5544. Time: 285.4361 us. Best GFLOPs: 810.5544
2024-04-29 05:54:11 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #516: GFLOPs: 619.4496. Time: 373.4953 us. Best GFLOPs: 810.5544
2024-04-29 05:54:11 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #517: GFLOPs: 794.6124. Time: 291.1627 us. Best GFLOPs: 810.5544
2024-04-29 05:54:11 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #518: GFLOPs: 685.2267. Time: 337.6423 us. Best GFLOPs: 810.5544
2024-04-29 05:54:11 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #519: GFLOPs: 404.5791. Time: 571.8573 us. Best GFLOPs: 810.5544
2024-04-29 05:54:11 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #520: GFLOPs: 615.6697. Time: 375.7884 us. Best GFLOPs: 810.5544
2024-04-29 05:54:11 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #521: GFLOPs: 566.2188. Time: 408.6080 us. Best GFLOPs: 810.5544
2024-04-29 05:54:11 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #522: GFLOPs: 583.9609. Time: 396.1936 us. Best GFLOPs: 810.5544
2024-04-29 05:54:11 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #523: GFLOPs: 566.2756. Time: 408.5670 us. Best GFLOPs: 810.5544
2024-04-29 05:54:11 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #524: GFLOPs: 578.8711. Time: 399.6771 us. Best GFLOPs: 810.5544
2024-04-29 05:54:11 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #525: GFLOPs: 344.0550. Time: 672.4551 us. Best GFLOPs: 810.5544
2024-04-29 05:54:11 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #526: GFLOPs: 370.4707. Time: 624.5070 us. Best GFLOPs: 810.5544
2024-04-29 05:54:11 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #527: GFLOPs: 349.0824. Time: 662.7705 us. Best GFLOPs: 810.5544
2024-04-29 05:54:11 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #528: GFLOPs: 447.4586. Time: 517.0568 us. Best GFLOPs: 810.5544
2024-04-29 05:54:11 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #529: GFLOPs: 113.2988. Time: 2042.0479 us. Best GFLOPs: 810.5544
2024-04-29 05:54:11 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #530: GFLOPs: 529.6535. Time: 436.8168 us. Best GFLOPs: 810.5544
2024-04-29 05:54:11 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #531: GFLOPs: 185.2698. Time: 1248.7818 us. Best GFLOPs: 810.5544
2024-04-29 05:54:11 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #532: GFLOPs: 600.8413. Time: 385.0626 us. Best GFLOPs: 810.5544
2024-04-29 05:54:11 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #533: GFLOPs: 468.0160. Time: 494.3454 us. Best GFLOPs: 810.5544
2024-04-29 05:54:11 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #534: GFLOPs: 367.0310. Time: 630.3597 us. Best GFLOPs: 810.5544
2024-04-29 05:54:11 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #535: GFLOPs: 389.1702. Time: 594.4996 us. Best GFLOPs: 810.5544
2024-04-29 05:54:11 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #536: GFLOPs: 563.2620. Time: 410.7530 us. Best GFLOPs: 810.5544
2024-04-29 05:54:11 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #537: GFLOPs: 133.3974. Time: 1734.3780 us. Best GFLOPs: 810.5544
2024-04-29 05:54:11 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #538: GFLOPs: 551.9705. Time: 419.1556 us. Best GFLOPs: 810.5544
2024-04-29 05:54:11 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #539: GFLOPs: 202.4214. Time: 1142.9697 us. Best GFLOPs: 810.5544
2024-04-29 05:54:11 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #540: GFLOPs: 552.2510. Time: 418.9427 us. Best GFLOPs: 810.5544
2024-04-29 05:54:11 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #541: GFLOPs: 500.3099. Time: 462.4364 us. Best GFLOPs: 810.5544
2024-04-29 05:54:11 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #542: GFLOPs: 369.6404. Time: 625.9098 us. Best GFLOPs: 810.5544
2024-04-29 05:54:11 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #543: GFLOPs: 558.9575. Time: 413.9162 us. Best GFLOPs: 810.5544
2024-04-29 05:54:11 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #544: GFLOPs: 709.9003. Time: 325.9071 us. Best GFLOPs: 810.5544
2024-04-29 05:54:11 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #545: GFLOPs: 350.3966. Time: 660.2848 us. Best GFLOPs: 810.5544
2024-04-29 05:54:11 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #546: GFLOPs: 516.7241. Time: 447.7468 us. Best GFLOPs: 810.5544
2024-04-29 05:54:11 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #547: GFLOPs: 350.3213. Time: 660.4267 us. Best GFLOPs: 810.5544
2024-04-29 05:54:11 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #548: GFLOPs: 500.3026. Time: 462.4432 us. Best GFLOPs: 810.5544
2024-04-29 05:54:11 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #549: GFLOPs: 349.1240. Time: 662.6916 us. Best GFLOPs: 810.5544
2024-04-29 05:54:11 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #550: GFLOPs: 455.1702. Time: 508.2968 us. Best GFLOPs: 810.5544
2024-04-29 05:54:11 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #551: GFLOPs: 563.4468. Time: 410.6182 us. Best GFLOPs: 810.5544
2024-04-29 05:54:11 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #552: GFLOPs: 240.9670. Time: 960.1379 us. Best GFLOPs: 810.5544
2024-04-29 05:54:11 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #553: GFLOPs: 440.0901. Time: 525.7140 us. Best GFLOPs: 810.5544
2024-04-29 05:54:11 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #554: GFLOPs: 499.7947. Time: 462.9131 us. Best GFLOPs: 810.5544
2024-04-29 05:54:11 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #555: GFLOPs: 438.5553. Time: 527.5538 us. Best GFLOPs: 810.5544
2024-04-29 05:54:11 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #556: GFLOPs: 99.1047. Time: 2334.5173 us. Best GFLOPs: 810.5544
2024-04-29 05:54:11 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #557: GFLOPs: 441.0342. Time: 524.5886 us. Best GFLOPs: 810.5544
2024-04-29 05:54:11 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #558: GFLOPs: 592.0763. Time: 390.7630 us. Best GFLOPs: 810.5544
2024-04-29 05:54:11 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #559: GFLOPs: 501.1050. Time: 461.7027 us. Best GFLOPs: 810.5544
2024-04-29 05:54:11 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #560: GFLOPs: 499.9490. Time: 462.7702 us. Best GFLOPs: 810.5544
2024-04-29 05:54:11 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #561: GFLOPs: 249.2627. Time: 928.1836 us. Best GFLOPs: 810.5544
2024-04-29 05:54:11 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #562: GFLOPs: 498.5537. Time: 464.0655 us. Best GFLOPs: 810.5544
2024-04-29 05:54:11 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #563: GFLOPs: 585.8768. Time: 394.8979 us. Best GFLOPs: 810.5544
2024-04-29 05:54:11 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #564: GFLOPs: 458.7275. Time: 504.3551 us. Best GFLOPs: 810.5544
2024-04-29 05:54:11 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #565: GFLOPs: 578.9310. Time: 399.6358 us. Best GFLOPs: 810.5544
2024-04-29 05:54:11 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #566: GFLOPs: 362.7611. Time: 637.7793 us. Best GFLOPs: 810.5544
2024-04-29 05:54:11 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #567: GFLOPs: 483.9703. Time: 478.0491 us. Best GFLOPs: 810.5544
2024-04-29 05:54:11 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #568: GFLOPs: 376.7635. Time: 614.0763 us. Best GFLOPs: 810.5544
2024-04-29 05:54:11 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #569: GFLOPs: 500.8091. Time: 461.9755 us. Best GFLOPs: 810.5544
2024-04-29 05:54:11 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #570: GFLOPs: 135.1467. Time: 1711.9289 us. Best GFLOPs: 810.5544
2024-04-29 05:54:11 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #571: GFLOPs: 134.7832. Time: 1716.5461 us. Best GFLOPs: 810.5544
2024-04-29 05:54:11 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #572: GFLOPs: 458.9779. Time: 504.0799 us. Best GFLOPs: 810.5544
2024-04-29 05:54:11 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #573: GFLOPs: 585.7074. Time: 395.0122 us. Best GFLOPs: 810.5544
2024-04-29 05:54:11 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #574: GFLOPs: 91.3483. Time: 2532.7406 us. Best GFLOPs: 810.5544
2024-04-29 05:54:11 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #575: GFLOPs: 2.3689. Time: 97666.1347 us. Best GFLOPs: 810.5544
2024-04-29 05:54:11 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #576: GFLOPs: 85.1885. Time: 2715.8768 us. Best GFLOPs: 810.5544
2024-04-29 05:59:28 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 05:59:29 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-29 05:59:34 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3639cb8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x419b828)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x312c9f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x425e1d8)]: 0 failure(s)
2024-04-29 05:59:34 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-29 05:59:46 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3639cb8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x419b828)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x312c9f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x425e1d8)]: 0 failure(s)
2024-04-29 06:00:01 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3639cb8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x419b828)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x312c9f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x425e1d8)]: 0 failure(s)
2024-04-29 06:00:15 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3639cb8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x419b828)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x312c9f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x425e1d8)]: 0 failure(s)
2024-04-29 06:00:29 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3639cb8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x419b828)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x312c9f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x425e1d8)]: 0 failure(s)
2024-04-29 06:00:37 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9420  0.8640  0.8628  0.8412  0.8412  0.8203  0.7941  0.7881  0.7881  0.7783  0.7623  0.7608  0.7568  0.7439  0.7417  0.7330
[17 : 32]:	0.7330  0.7309  0.7149  0.7149  0.7093  0.7093  0.7034  0.7007  0.6998  0.6995  0.6897  0.6894  0.6858  0.6842  0.6821  0.6809
[33 : 48]:	0.6702  0.6702  0.6700  0.6691  0.6581  0.6562  0.6555  0.6543  0.6543  0.6534  0.6513  0.6406  0.6394  0.6394  0.6372  0.6325
[49 : 64]:	0.6321  0.6304  0.6285  0.6272  0.6254  0.6215  0.6190  0.6090  0.6064  0.6064  0.6062  0.6052  0.6052  0.6038  0.6003  0.6003
2024-04-29 06:00:38 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 06:00:38 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 06:02:18 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #577: GFLOPs: 430.8726. Time: 536.9605 us. Best GFLOPs: 810.5544
2024-04-29 06:02:18 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #578: GFLOPs: 578.5449. Time: 399.9025 us. Best GFLOPs: 810.5544
2024-04-29 06:02:18 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #579: GFLOPs: 642.4640. Time: 360.1160 us. Best GFLOPs: 810.5544
2024-04-29 06:02:18 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #580: GFLOPs: 595.5796. Time: 388.4645 us. Best GFLOPs: 810.5544
2024-04-29 06:02:18 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #581: GFLOPs: 698.1950. Time: 331.3710 us. Best GFLOPs: 810.5544
2024-04-29 06:02:18 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #582: GFLOPs: 646.2828. Time: 357.9881 us. Best GFLOPs: 810.5544
2024-04-29 06:02:18 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #583: GFLOPs: 710.0747. Time: 325.8270 us. Best GFLOPs: 810.5544
2024-04-29 06:02:18 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #584: GFLOPs: 625.2017. Time: 370.0591 us. Best GFLOPs: 810.5544
2024-04-29 06:02:18 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #585: GFLOPs: 641.6948. Time: 360.5476 us. Best GFLOPs: 810.5544
2024-04-29 06:02:18 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #586: GFLOPs: 618.2380. Time: 374.2273 us. Best GFLOPs: 810.5544
2024-04-29 06:02:18 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #587: GFLOPs: 540.6276. Time: 427.9499 us. Best GFLOPs: 810.5544
2024-04-29 06:02:18 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #588: GFLOPs: 526.8914. Time: 439.1067 us. Best GFLOPs: 810.5544
2024-04-29 06:02:18 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #589: GFLOPs: 481.4094. Time: 480.5921 us. Best GFLOPs: 810.5544
2024-04-29 06:02:18 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #590: GFLOPs: 176.4069. Time: 1311.5217 us. Best GFLOPs: 810.5544
2024-04-29 06:02:18 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #591: GFLOPs: 513.1203. Time: 450.8914 us. Best GFLOPs: 810.5544
2024-04-29 06:02:18 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #592: GFLOPs: 609.4696. Time: 379.6113 us. Best GFLOPs: 810.5544
2024-04-29 06:02:18 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #593: GFLOPs: 603.6524. Time: 383.2695 us. Best GFLOPs: 810.5544
2024-04-29 06:02:18 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #594: GFLOPs: 531.4069. Time: 435.3755 us. Best GFLOPs: 810.5544
2024-04-29 06:02:18 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #595: GFLOPs: 582.9957. Time: 396.8495 us. Best GFLOPs: 810.5544
2024-04-29 06:02:18 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #596: GFLOPs: 492.0303. Time: 470.2181 us. Best GFLOPs: 810.5544
2024-04-29 06:02:18 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #597: GFLOPs: 106.6029. Time: 2170.3114 us. Best GFLOPs: 810.5544
2024-04-29 06:02:18 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #598: GFLOPs: 106.6360. Time: 2169.6391 us. Best GFLOPs: 810.5544
2024-04-29 06:02:18 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #599: GFLOPs: 678.6819. Time: 340.8983 us. Best GFLOPs: 810.5544
2024-04-29 06:02:18 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #600: GFLOPs: 622.0532. Time: 371.9321 us. Best GFLOPs: 810.5544
2024-04-29 06:02:18 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #601: GFLOPs: 644.5431. Time: 358.9544 us. Best GFLOPs: 810.5544
2024-04-29 06:02:18 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #602: GFLOPs: 154.9737. Time: 1492.9089 us. Best GFLOPs: 810.5544
2024-04-29 06:02:18 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #603: GFLOPs: 475.7088. Time: 486.3512 us. Best GFLOPs: 810.5544
2024-04-29 06:02:18 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #604: GFLOPs: 205.7382. Time: 1124.5435 us. Best GFLOPs: 810.5544
2024-04-29 06:02:18 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #605: GFLOPs: 409.8499. Time: 564.5030 us. Best GFLOPs: 810.5544
2024-04-29 06:02:18 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #606: GFLOPs: 662.1285. Time: 349.4209 us. Best GFLOPs: 810.5544
2024-04-29 06:02:18 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #607: GFLOPs: 353.8731. Time: 653.7981 us. Best GFLOPs: 810.5544
2024-04-29 06:02:18 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #608: GFLOPs: 196.3400. Time: 1178.3719 us. Best GFLOPs: 810.5544
2024-04-29 06:02:18 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #609: GFLOPs: 336.5576. Time: 687.4351 us. Best GFLOPs: 810.5544
2024-04-29 06:02:18 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #610: GFLOPs: 166.3736. Time: 1390.6145 us. Best GFLOPs: 810.5544
2024-04-29 06:02:18 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #611: GFLOPs: 594.6243. Time: 389.0886 us. Best GFLOPs: 810.5544
2024-04-29 06:02:18 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #612: GFLOPs: 719.6919. Time: 321.4730 us. Best GFLOPs: 810.5544
2024-04-29 06:02:18 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #613: GFLOPs: 723.7970. Time: 319.6498 us. Best GFLOPs: 810.5544
2024-04-29 06:02:18 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #614: GFLOPs: 526.0136. Time: 439.8395 us. Best GFLOPs: 810.5544
2024-04-29 06:02:18 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #615: GFLOPs: 636.9197. Time: 363.2507 us. Best GFLOPs: 810.5544
2024-04-29 06:02:18 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #616: GFLOPs: 316.6287. Time: 730.7030 us. Best GFLOPs: 810.5544
2024-04-29 06:02:18 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #617: GFLOPs: 345.2380. Time: 670.1508 us. Best GFLOPs: 810.5544
2024-04-29 06:02:18 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #618: GFLOPs: 578.7971. Time: 399.7282 us. Best GFLOPs: 810.5544
2024-04-29 06:02:18 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #619: GFLOPs: 517.6706. Time: 446.9281 us. Best GFLOPs: 810.5544
2024-04-29 06:02:18 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #620: GFLOPs: 489.3916. Time: 472.7534 us. Best GFLOPs: 810.5544
2024-04-29 06:02:18 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #621: GFLOPs: 109.3084. Time: 2116.5942 us. Best GFLOPs: 810.5544
2024-04-29 06:02:18 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #622: GFLOPs: 109.9046. Time: 2105.1115 us. Best GFLOPs: 810.5544
2024-04-29 06:02:18 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #623: GFLOPs: 628.4842. Time: 368.1262 us. Best GFLOPs: 810.5544
2024-04-29 06:02:18 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #624: GFLOPs: 378.0328. Time: 612.0144 us. Best GFLOPs: 810.5544
2024-04-29 06:02:18 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #625: GFLOPs: 549.6249. Time: 420.9444 us. Best GFLOPs: 810.5544
2024-04-29 06:02:18 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #626: GFLOPs: 340.6446. Time: 679.1874 us. Best GFLOPs: 810.5544
2024-04-29 06:02:18 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #627: GFLOPs: 591.4240. Time: 391.1940 us. Best GFLOPs: 810.5544
2024-04-29 06:02:18 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #628: GFLOPs: 274.2572. Time: 843.5932 us. Best GFLOPs: 810.5544
2024-04-29 06:02:18 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #629: GFLOPs: 597.6301. Time: 387.1317 us. Best GFLOPs: 810.5544
2024-04-29 06:02:18 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #630: GFLOPs: 548.7836. Time: 421.5897 us. Best GFLOPs: 810.5544
2024-04-29 06:02:18 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #631: GFLOPs: 323.3878. Time: 715.4307 us. Best GFLOPs: 810.5544
2024-04-29 06:02:18 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #632: GFLOPs: 348.3152. Time: 664.2304 us. Best GFLOPs: 810.5544
2024-04-29 06:02:18 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #633: GFLOPs: 477.7561. Time: 484.2670 us. Best GFLOPs: 810.5544
2024-04-29 06:02:18 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #634: GFLOPs: 468.9584. Time: 493.3519 us. Best GFLOPs: 810.5544
2024-04-29 06:02:18 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #635: GFLOPs: 324.4299. Time: 713.1325 us. Best GFLOPs: 810.5544
2024-04-29 06:02:18 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #636: GFLOPs: 369.7409. Time: 625.7397 us. Best GFLOPs: 810.5544
2024-04-29 06:02:18 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #637: GFLOPs: 202.0112. Time: 1145.2904 us. Best GFLOPs: 810.5544
2024-04-29 06:02:18 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #638: GFLOPs: 15.7888. Time: 14653.5340 us. Best GFLOPs: 810.5544
2024-04-29 06:02:18 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #639: GFLOPs: 18.2659. Time: 12666.3057 us. Best GFLOPs: 810.5544
2024-04-29 06:02:18 [INFO] [task_scheduler.cc:121] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #640: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(14), T.int64(14), T.int64(128)), "float32"), p1: T.Buffer((T.int64(16), T.int64(2), T.int64(3), T.int64(3), T.int64(128), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(16)), "float32"), p3: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(16), T.int64(16), T.int64(128)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused in T.parallel(T.int64(14), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(14), T.int64(1), T.int64(16)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(16), oc_chunk_1 * T.int64(16) + oc_chunk_2_init * T.int64(8) + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(14), oh_1 + oh_2_init + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused + ow_1 + ow_2_init + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(16), oc_block_1 + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0 in range(T.int64(64)):
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(3), T.int64(3)):
                        for ax4_fused in T.vectorized(T.int64(4)):
                            with T.block("data_pad"):
                                v_i0 = T.axis.spatial(T.int64(1), ax0)
                                v_i1 = T.axis.spatial(T.int64(2), ic_0 // T.int64(32) + ax1)
                                v_i2 = T.axis.spatial(T.int64(16), oh_1 + ax2)
                                v_i3 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused + ax3)
                                v_i4 = T.axis.spatial(T.int64(128), ic_0 % T.int64(32) * T.int64(4) + ax4_fused)
                                T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                                T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                                data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(15) and T.int64(1) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                    for kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(3), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(1), T.int64(3), T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(1)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(16), oc_chunk_1 * T.int64(16) + oc_chunk_2 * T.int64(8) + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(14), oh_1 + oh_2 + oh_3)
                            v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused + ow_1 + ow_2 + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_1 + oc_block_2 + oc_block_3)
                            v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(4) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
            for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(16), T.int64(14)):
                for ax3_ax4_fused in T.vectorized(T.int64(16)):
                    with T.block("T_relu"):
                        v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused, ax3_ax4_fused])
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 2, 8])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 14, 1, 1])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[14, 1, 1, 1])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[1, 16, 1, 1])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[64, 4])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[1, 3])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=10)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87 = sch.get_loops(block=b69)
l88 = sch.fuse(l72, l73, l74, l75, l76, preserve_unit_iters=True)
sch.parallel(loop=l88)
l89 = sch.fuse(l87, preserve_unit_iters=True)
sch.vectorize(loop=l89)
l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107, l108, l109, l110, l111 = sch.get_loops(block=b70)
l112 = sch.fuse(l90, preserve_unit_iters=True)
sch.parallel(loop=l112)
sch.annotate(block_or_loop=l112, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l112, ann_key="pragma_unroll_explicit", ann_val=1)
l113, l114, l115, l116, l117, l118 = sch.get_loops(block=b71)
l119 = sch.fuse(l117, l118, preserve_unit_iters=True)
sch.vectorize(loop=l119)
b120 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141, l142 = sch.get_loops(block=b120)
b143 = sch.decompose_reduction(block=b120, loop=l127)
2024-04-29 06:02:24 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 06:02:25 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-29 06:02:30 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3639cb8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x419b828)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x312c9f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x425e1d8)]: 0 failure(s)
2024-04-29 06:02:30 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-29 06:02:43 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3639cb8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x419b828)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x312c9f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x425e1d8)]: 0 failure(s)
2024-04-29 06:02:57 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3639cb8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x419b828)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x312c9f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x425e1d8)]: 0 failure(s)
2024-04-29 06:03:10 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3639cb8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x419b828)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x312c9f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x425e1d8)]: 0 failure(s)
2024-04-29 06:03:23 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3639cb8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x419b828)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x312c9f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x425e1d8)]: 0 failure(s)
2024-04-29 06:03:32 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.8475  0.8475  0.8338  0.8232  0.8131  0.7931  0.7707  0.7695  0.7695  0.7597  0.7596  0.7596  0.7553  0.7553  0.7551  0.7551
[17 : 32]:	0.7538  0.7384  0.7302  0.7276  0.7241  0.7122  0.7083  0.7074  0.7074  0.7073  0.7004  0.6990  0.6943  0.6943  0.6937  0.6931
[33 : 48]:	0.6851  0.6841  0.6813  0.6810  0.6787  0.6782  0.6777  0.6771  0.6771  0.6761  0.6733  0.6733  0.6729  0.6685  0.6636  0.6636
[49 : 64]:	0.6627  0.6627  0.6626  0.6625  0.6611  0.6589  0.6570  0.6527  0.6520  0.6515  0.6499  0.6499  0.6486  0.6468  0.6464  0.6461
2024-04-29 06:03:32 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 06:03:32 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 06:04:55 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #641: GFLOPs: 701.4562. Time: 329.8303 us. Best GFLOPs: 810.5544
2024-04-29 06:04:55 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #642: GFLOPs: 698.4724. Time: 331.2393 us. Best GFLOPs: 810.5544
2024-04-29 06:04:55 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #643: GFLOPs: 814.7971. Time: 283.9499 us. Best GFLOPs: 814.7971
2024-04-29 06:04:55 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #644: GFLOPs: 629.7428. Time: 367.3905 us. Best GFLOPs: 814.7971
2024-04-29 06:04:55 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #645: GFLOPs: 678.2441. Time: 341.1184 us. Best GFLOPs: 814.7971
2024-04-29 06:04:55 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #646: GFLOPs: 674.4951. Time: 343.0144 us. Best GFLOPs: 814.7971
2024-04-29 06:04:55 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #647: GFLOPs: 624.5553. Time: 370.4420 us. Best GFLOPs: 814.7971
2024-04-29 06:04:55 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #648: GFLOPs: 682.6885. Time: 338.8977 us. Best GFLOPs: 814.7971
2024-04-29 06:04:55 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #649: GFLOPs: 678.4910. Time: 340.9943 us. Best GFLOPs: 814.7971
2024-04-29 06:04:55 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #650: GFLOPs: 537.5203. Time: 430.4238 us. Best GFLOPs: 814.7971
2024-04-29 06:04:55 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #651: GFLOPs: 621.7109. Time: 372.1368 us. Best GFLOPs: 814.7971
2024-04-29 06:04:55 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #652: GFLOPs: 298.4677. Time: 775.1645 us. Best GFLOPs: 814.7971
2024-04-29 06:04:55 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #653: GFLOPs: 616.5675. Time: 375.2412 us. Best GFLOPs: 814.7971
2024-04-29 06:04:55 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #654: GFLOPs: 621.8537. Time: 372.0514 us. Best GFLOPs: 814.7971
2024-04-29 06:04:55 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #655: GFLOPs: 682.9766. Time: 338.7547 us. Best GFLOPs: 814.7971
2024-04-29 06:04:55 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #656: GFLOPs: 599.6034. Time: 385.8576 us. Best GFLOPs: 814.7971
2024-04-29 06:04:55 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #657: GFLOPs: 684.6625. Time: 337.9206 us. Best GFLOPs: 814.7971
2024-04-29 06:04:55 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #658: GFLOPs: 716.1929. Time: 323.0436 us. Best GFLOPs: 814.7971
2024-04-29 06:04:55 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #659: GFLOPs: 637.3050. Time: 363.0311 us. Best GFLOPs: 814.7971
2024-04-29 06:04:55 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #660: GFLOPs: 691.4854. Time: 334.5863 us. Best GFLOPs: 814.7971
2024-04-29 06:04:55 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #661: GFLOPs: 629.8052. Time: 367.3541 us. Best GFLOPs: 814.7971
2024-04-29 06:04:55 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #662: GFLOPs: 547.6120. Time: 422.4917 us. Best GFLOPs: 814.7971
2024-04-29 06:04:55 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #663: GFLOPs: 646.3057. Time: 357.9754 us. Best GFLOPs: 814.7971
2024-04-29 06:04:55 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #664: GFLOPs: 608.3340. Time: 380.3199 us. Best GFLOPs: 814.7971
2024-04-29 06:04:55 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #665: GFLOPs: 610.1333. Time: 379.1983 us. Best GFLOPs: 814.7971
2024-04-29 06:04:55 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #666: GFLOPs: 608.7855. Time: 380.0378 us. Best GFLOPs: 814.7971
2024-04-29 06:04:55 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #667: GFLOPs: 142.6748. Time: 1621.6001 us. Best GFLOPs: 814.7971
2024-04-29 06:04:55 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #668: GFLOPs: 612.1093. Time: 377.9742 us. Best GFLOPs: 814.7971
2024-04-29 06:04:55 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #669: GFLOPs: 516.6381. Time: 447.8213 us. Best GFLOPs: 814.7971
2024-04-29 06:04:55 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #670: GFLOPs: 513.1093. Time: 450.9011 us. Best GFLOPs: 814.7971
2024-04-29 06:04:55 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #671: GFLOPs: 584.5377. Time: 395.8026 us. Best GFLOPs: 814.7971
2024-04-29 06:04:55 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #672: GFLOPs: 129.3490. Time: 1788.6618 us. Best GFLOPs: 814.7971
2024-04-29 06:04:55 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #673: GFLOPs: 610.5004. Time: 378.9703 us. Best GFLOPs: 814.7971
2024-04-29 06:04:55 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #674: GFLOPs: 545.3653. Time: 424.2322 us. Best GFLOPs: 814.7971
2024-04-29 06:04:55 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #675: GFLOPs: 598.9708. Time: 386.2652 us. Best GFLOPs: 814.7971
2024-04-29 06:04:55 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #676: GFLOPs: 705.4444. Time: 327.9657 us. Best GFLOPs: 814.7971
2024-04-29 06:04:55 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #677: GFLOPs: 641.7268. Time: 360.5296 us. Best GFLOPs: 814.7971
2024-04-29 06:04:55 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #678: GFLOPs: 640.7784. Time: 361.0632 us. Best GFLOPs: 814.7971
2024-04-29 06:04:55 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #679: GFLOPs: 594.8036. Time: 388.9713 us. Best GFLOPs: 814.7971
2024-04-29 06:04:55 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #680: GFLOPs: 638.4485. Time: 362.3809 us. Best GFLOPs: 814.7971
2024-04-29 06:04:55 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #681: GFLOPs: 634.0464. Time: 364.8969 us. Best GFLOPs: 814.7971
2024-04-29 06:04:55 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #682: GFLOPs: 689.1629. Time: 335.7139 us. Best GFLOPs: 814.7971
2024-04-29 06:04:55 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #683: GFLOPs: 803.0690. Time: 288.0967 us. Best GFLOPs: 814.7971
2024-04-29 06:04:55 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #684: GFLOPs: 799.2297. Time: 289.4807 us. Best GFLOPs: 814.7971
2024-04-29 06:04:55 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #685: GFLOPs: 152.9824. Time: 1512.3410 us. Best GFLOPs: 814.7971
2024-04-29 06:04:55 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #686: GFLOPs: 531.8653. Time: 435.0003 us. Best GFLOPs: 814.7971
2024-04-29 06:04:55 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #687: GFLOPs: 580.4648. Time: 398.5798 us. Best GFLOPs: 814.7971
2024-04-29 06:04:55 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #688: GFLOPs: 570.6695. Time: 405.4213 us. Best GFLOPs: 814.7971
2024-04-29 06:04:55 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #689: GFLOPs: 636.1491. Time: 363.6907 us. Best GFLOPs: 814.7971
2024-04-29 06:04:55 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #690: GFLOPs: 633.5687. Time: 365.1720 us. Best GFLOPs: 814.7971
2024-04-29 06:04:55 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #691: GFLOPs: 870.2440. Time: 265.8582 us. Best GFLOPs: 870.2440
2024-04-29 06:04:55 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #692: GFLOPs: 605.3670. Time: 382.1839 us. Best GFLOPs: 870.2440
2024-04-29 06:04:55 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #693: GFLOPs: 518.0171. Time: 446.6292 us. Best GFLOPs: 870.2440
2024-04-29 06:04:55 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #694: GFLOPs: 689.1615. Time: 335.7145 us. Best GFLOPs: 870.2440
2024-04-29 06:04:55 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #695: GFLOPs: 524.9305. Time: 440.7470 us. Best GFLOPs: 870.2440
2024-04-29 06:04:55 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #696: GFLOPs: 481.2153. Time: 480.7859 us. Best GFLOPs: 870.2440
2024-04-29 06:04:55 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #697: GFLOPs: 549.8550. Time: 420.7683 us. Best GFLOPs: 870.2440
2024-04-29 06:04:55 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #698: GFLOPs: 695.2159. Time: 332.7909 us. Best GFLOPs: 870.2440
2024-04-29 06:04:55 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #699: GFLOPs: 556.9610. Time: 415.3999 us. Best GFLOPs: 870.2440
2024-04-29 06:04:55 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #700: GFLOPs: 555.6706. Time: 416.3645 us. Best GFLOPs: 870.2440
2024-04-29 06:04:55 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #701: GFLOPs: 719.6165. Time: 321.5067 us. Best GFLOPs: 870.2440
2024-04-29 06:04:55 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #702: GFLOPs: 10.4227. Time: 22197.9134 us. Best GFLOPs: 870.2440
2024-04-29 06:04:55 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #703: GFLOPs: 6.9222. Time: 33423.1270 us. Best GFLOPs: 870.2440
2024-04-29 06:04:55 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #704: GFLOPs: 63.7400. Time: 3629.7727 us. Best GFLOPs: 870.2440
2024-04-29 06:22:46 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 06:22:48 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-29 06:22:52 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3639cb8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x419b828)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x312c9f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x425e1d8)]: 0 failure(s)
2024-04-29 06:22:52 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-29 06:23:05 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3639cb8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x419b828)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x312c9f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x425e1d8)]: 0 failure(s)
2024-04-29 06:23:18 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3639cb8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x419b828)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x312c9f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x425e1d8)]: 0 failure(s)
2024-04-29 06:23:31 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3639cb8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x419b828)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x312c9f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x425e1d8)]: 0 failure(s)
2024-04-29 06:23:45 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3639cb8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x419b828)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x312c9f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x425e1d8)]: 0 failure(s)
2024-04-29 06:23:53 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.8980  0.8090  0.8016  0.8014  0.8014  0.7882  0.7724  0.7644  0.7626  0.7626  0.7604  0.7484  0.7423  0.7414  0.7361  0.7348
[17 : 32]:	0.7323  0.7323  0.7310  0.7232  0.7226  0.7195  0.7195  0.7190  0.7188  0.7177  0.7177  0.7164  0.7164  0.7144  0.7141  0.7080
[33 : 48]:	0.7048  0.7048  0.7000  0.6984  0.6981  0.6979  0.6977  0.6929  0.6929  0.6918  0.6886  0.6864  0.6850  0.6849  0.6773  0.6773
[49 : 64]:	0.6761  0.6742  0.6703  0.6703  0.6657  0.6626  0.6611  0.6592  0.6592  0.6540  0.6537  0.6515  0.6515  0.6491  0.6474  0.6474
2024-04-29 06:23:54 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 06:23:54 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 06:25:32 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #705: GFLOPs: 836.0801. Time: 276.7217 us. Best GFLOPs: 870.2440
2024-04-29 06:25:32 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #706: GFLOPs: 836.7025. Time: 276.5159 us. Best GFLOPs: 870.2440
2024-04-29 06:25:32 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #707: GFLOPs: 830.1528. Time: 278.6975 us. Best GFLOPs: 870.2440
2024-04-29 06:25:32 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #708: GFLOPs: 720.4896. Time: 321.1171 us. Best GFLOPs: 870.2440
2024-04-29 06:25:32 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #709: GFLOPs: 720.5404. Time: 321.0945 us. Best GFLOPs: 870.2440
2024-04-29 06:25:32 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #710: GFLOPs: 706.7538. Time: 327.3580 us. Best GFLOPs: 870.2440
2024-04-29 06:25:32 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #711: GFLOPs: 794.2941. Time: 291.2794 us. Best GFLOPs: 870.2440
2024-04-29 06:25:32 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #712: GFLOPs: 776.9775. Time: 297.7712 us. Best GFLOPs: 870.2440
2024-04-29 06:25:32 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #713: GFLOPs: 586.4486. Time: 394.5129 us. Best GFLOPs: 870.2440
2024-04-29 06:25:32 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #714: GFLOPs: 698.8062. Time: 331.0811 us. Best GFLOPs: 870.2440
2024-04-29 06:25:32 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #715: GFLOPs: 751.8322. Time: 307.7303 us. Best GFLOPs: 870.2440
2024-04-29 06:25:32 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #716: GFLOPs: 617.5410. Time: 374.6497 us. Best GFLOPs: 870.2440
2024-04-29 06:25:32 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #717: GFLOPs: 674.0897. Time: 343.2207 us. Best GFLOPs: 870.2440
2024-04-29 06:25:32 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #718: GFLOPs: 698.3496. Time: 331.2976 us. Best GFLOPs: 870.2440
2024-04-29 06:25:32 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #719: GFLOPs: 718.4289. Time: 322.0382 us. Best GFLOPs: 870.2440
2024-04-29 06:25:32 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #720: GFLOPs: 660.0804. Time: 350.5051 us. Best GFLOPs: 870.2440
2024-04-29 06:25:32 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #721: GFLOPs: 650.2144. Time: 355.8235 us. Best GFLOPs: 870.2440
2024-04-29 06:25:32 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #722: GFLOPs: 661.8427. Time: 349.5718 us. Best GFLOPs: 870.2440
2024-04-29 06:25:32 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #723: GFLOPs: 480.1021. Time: 481.9007 us. Best GFLOPs: 870.2440
2024-04-29 06:25:32 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #724: GFLOPs: 690.2327. Time: 335.1935 us. Best GFLOPs: 870.2440
2024-04-29 06:25:32 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #725: GFLOPs: 603.2424. Time: 383.5300 us. Best GFLOPs: 870.2440
2024-04-29 06:25:32 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #726: GFLOPs: 690.1905. Time: 335.2140 us. Best GFLOPs: 870.2440
2024-04-29 06:25:32 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #727: GFLOPs: 595.9689. Time: 388.2108 us. Best GFLOPs: 870.2440
2024-04-29 06:25:32 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #728: GFLOPs: 629.7692. Time: 367.3751 us. Best GFLOPs: 870.2440
2024-04-29 06:25:32 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #729: GFLOPs: 696.6674. Time: 332.0975 us. Best GFLOPs: 870.2440
2024-04-29 06:25:32 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #730: GFLOPs: 165.1878. Time: 1400.5968 us. Best GFLOPs: 870.2440
2024-04-29 06:25:32 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #731: GFLOPs: 168.8762. Time: 1370.0070 us. Best GFLOPs: 870.2440
2024-04-29 06:25:32 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #732: GFLOPs: 640.4864. Time: 361.2278 us. Best GFLOPs: 870.2440
2024-04-29 06:25:32 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #733: GFLOPs: 646.9079. Time: 357.6422 us. Best GFLOPs: 870.2440
2024-04-29 06:25:32 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #734: GFLOPs: 601.8831. Time: 384.3961 us. Best GFLOPs: 870.2440
2024-04-29 06:25:32 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #735: GFLOPs: 486.2352. Time: 475.8223 us. Best GFLOPs: 870.2440
2024-04-29 06:25:32 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #736: GFLOPs: 631.0551. Time: 366.6265 us. Best GFLOPs: 870.2440
2024-04-29 06:25:32 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #737: GFLOPs: 505.8709. Time: 457.3529 us. Best GFLOPs: 870.2440
2024-04-29 06:25:32 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #738: GFLOPs: 506.6530. Time: 456.6470 us. Best GFLOPs: 870.2440
2024-04-29 06:25:32 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #739: GFLOPs: 582.1909. Time: 397.3980 us. Best GFLOPs: 870.2440
2024-04-29 06:25:32 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #740: GFLOPs: 613.6306. Time: 377.0372 us. Best GFLOPs: 870.2440
2024-04-29 06:25:32 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #741: GFLOPs: 569.6231. Time: 406.1660 us. Best GFLOPs: 870.2440
2024-04-29 06:25:32 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #742: GFLOPs: 156.8134. Time: 1475.3940 us. Best GFLOPs: 870.2440
2024-04-29 06:25:32 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #743: GFLOPs: 756.1416. Time: 305.9765 us. Best GFLOPs: 870.2440
2024-04-29 06:25:32 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #744: GFLOPs: 536.0408. Time: 431.6118 us. Best GFLOPs: 870.2440
2024-04-29 06:25:32 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #745: GFLOPs: 533.8963. Time: 433.3455 us. Best GFLOPs: 870.2440
2024-04-29 06:25:32 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #746: GFLOPs: 647.5274. Time: 357.3000 us. Best GFLOPs: 870.2440
2024-04-29 06:25:32 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #747: GFLOPs: 645.1570. Time: 358.6127 us. Best GFLOPs: 870.2440
2024-04-29 06:25:32 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #748: GFLOPs: 584.4301. Time: 395.8755 us. Best GFLOPs: 870.2440
2024-04-29 06:25:32 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #749: GFLOPs: 528.7107. Time: 437.5958 us. Best GFLOPs: 870.2440
2024-04-29 06:25:32 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #750: GFLOPs: 700.3622. Time: 330.3456 us. Best GFLOPs: 870.2440
2024-04-29 06:25:32 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #751: GFLOPs: 484.9349. Time: 477.0981 us. Best GFLOPs: 870.2440
2024-04-29 06:25:32 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #752: GFLOPs: 600.2870. Time: 385.4182 us. Best GFLOPs: 870.2440
2024-04-29 06:25:32 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #753: GFLOPs: 626.7068. Time: 369.1703 us. Best GFLOPs: 870.2440
2024-04-29 06:25:32 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #754: GFLOPs: 617.3650. Time: 374.7565 us. Best GFLOPs: 870.2440
2024-04-29 06:25:32 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #755: GFLOPs: 584.0635. Time: 396.1240 us. Best GFLOPs: 870.2440
2024-04-29 06:25:32 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #756: GFLOPs: 509.5531. Time: 454.0479 us. Best GFLOPs: 870.2440
2024-04-29 06:25:32 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #757: GFLOPs: 623.5900. Time: 371.0155 us. Best GFLOPs: 870.2440
2024-04-29 06:25:32 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #758: GFLOPs: 619.0351. Time: 373.7454 us. Best GFLOPs: 870.2440
2024-04-29 06:25:32 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #759: GFLOPs: 346.3784. Time: 667.9445 us. Best GFLOPs: 870.2440
2024-04-29 06:25:32 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #760: GFLOPs: 355.4715. Time: 650.8582 us. Best GFLOPs: 870.2440
2024-04-29 06:25:32 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #761: GFLOPs: 347.7734. Time: 665.2652 us. Best GFLOPs: 870.2440
2024-04-29 06:25:32 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #762: GFLOPs: 349.3970. Time: 662.1737 us. Best GFLOPs: 870.2440
2024-04-29 06:25:32 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #763: GFLOPs: 275.2703. Time: 840.4886 us. Best GFLOPs: 870.2440
2024-04-29 06:25:32 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #764: GFLOPs: 509.6773. Time: 453.9373 us. Best GFLOPs: 870.2440
2024-04-29 06:25:32 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #765: GFLOPs: 509.9856. Time: 453.6629 us. Best GFLOPs: 870.2440
2024-04-29 06:25:32 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #766: GFLOPs: 35.6460. Time: 6490.5319 us. Best GFLOPs: 870.2440
2024-04-29 06:25:32 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #767: GFLOPs: 3.5594. Time: 64999.6563 us. Best GFLOPs: 870.2440
2024-04-29 06:25:32 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #768: GFLOPs: 1.2948. Time: 178680.2730 us. Best GFLOPs: 870.2440
2024-04-29 06:49:18 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 06:49:19 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-29 06:49:24 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3639cb8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x419b828)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x312c9f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x425e1d8)]: 0 failure(s)
2024-04-29 06:49:24 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-29 06:49:37 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3639cb8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x419b828)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x312c9f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x425e1d8)]: 0 failure(s)
2024-04-29 06:49:50 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3639cb8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x419b828)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x312c9f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x425e1d8)]: 0 failure(s)
2024-04-29 06:50:03 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3639cb8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x419b828)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x312c9f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x425e1d8)]: 0 failure(s)
2024-04-29 06:50:16 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3639cb8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x419b828)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x312c9f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x425e1d8)]: 0 failure(s)
2024-04-29 06:50:25 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9739  0.9208  0.8728  0.8208  0.8205  0.8205  0.8205  0.8175  0.8109  0.7990  0.7949  0.7945  0.7929  0.7903  0.7866  0.7855
[17 : 32]:	0.7825  0.7717  0.7708  0.7594  0.7497  0.7427  0.7419  0.7401  0.7385  0.7330  0.7330  0.7316  0.7301  0.7279  0.7276  0.7264
[33 : 48]:	0.7245  0.7215  0.7140  0.7117  0.7115  0.7104  0.7104  0.7098  0.7093  0.7093  0.7093  0.7065  0.7044  0.7018  0.7007  0.7007
[49 : 64]:	0.7007  0.6976  0.6955  0.6955  0.6951  0.6909  0.6884  0.6884  0.6857  0.6855  0.6837  0.6828  0.6748  0.6740  0.6723  0.6704
2024-04-29 06:50:25 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 06:50:25 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 06:52:07 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #769: GFLOPs: 478.4796. Time: 483.5347 us. Best GFLOPs: 870.2440
2024-04-29 06:52:07 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #770: GFLOPs: 793.8479. Time: 291.4432 us. Best GFLOPs: 870.2440
2024-04-29 06:52:07 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #771: GFLOPs: 888.2246. Time: 260.4764 us. Best GFLOPs: 888.2246
2024-04-29 06:52:07 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #772: GFLOPs: 717.0509. Time: 322.6571 us. Best GFLOPs: 888.2246
2024-04-29 06:52:07 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #773: GFLOPs: 731.1831. Time: 316.4208 us. Best GFLOPs: 888.2246
2024-04-29 06:52:07 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #774: GFLOPs: 737.7370. Time: 313.6098 us. Best GFLOPs: 888.2246
2024-04-29 06:52:07 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #775: GFLOPs: 735.9205. Time: 314.3839 us. Best GFLOPs: 888.2246
2024-04-29 06:52:07 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #776: GFLOPs: 823.3852. Time: 280.9882 us. Best GFLOPs: 888.2246
2024-04-29 06:52:07 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #777: GFLOPs: 806.7277. Time: 286.7901 us. Best GFLOPs: 888.2246
2024-04-29 06:52:07 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #778: GFLOPs: 783.6795. Time: 295.2247 us. Best GFLOPs: 888.2246
2024-04-29 06:52:07 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #779: GFLOPs: 721.3756. Time: 320.7227 us. Best GFLOPs: 888.2246
2024-04-29 06:52:07 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #780: GFLOPs: 837.8306. Time: 276.1436 us. Best GFLOPs: 888.2246
2024-04-29 06:52:07 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #781: GFLOPs: 678.9586. Time: 340.7594 us. Best GFLOPs: 888.2246
2024-04-29 06:52:07 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #782: GFLOPs: 652.2938. Time: 354.6892 us. Best GFLOPs: 888.2246
2024-04-29 06:52:07 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #783: GFLOPs: 675.3753. Time: 342.5674 us. Best GFLOPs: 888.2246
2024-04-29 06:52:07 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #784: GFLOPs: 835.9756. Time: 276.7563 us. Best GFLOPs: 888.2246
2024-04-29 06:52:07 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #785: GFLOPs: 933.2391. Time: 247.9124 us. Best GFLOPs: 933.2391
2024-04-29 06:52:07 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #786: GFLOPs: 669.7258. Time: 345.4571 us. Best GFLOPs: 933.2391
2024-04-29 06:52:07 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #787: GFLOPs: 824.8517. Time: 280.4886 us. Best GFLOPs: 933.2391
2024-04-29 06:52:07 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #788: GFLOPs: 712.4674. Time: 324.7328 us. Best GFLOPs: 933.2391
2024-04-29 06:52:07 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #789: GFLOPs: 669.4951. Time: 345.5761 us. Best GFLOPs: 933.2391
2024-04-29 06:52:07 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #790: GFLOPs: 576.2475. Time: 401.4968 us. Best GFLOPs: 933.2391
2024-04-29 06:52:07 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #791: GFLOPs: 762.5254. Time: 303.4149 us. Best GFLOPs: 933.2391
2024-04-29 06:52:07 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #792: GFLOPs: 663.2587. Time: 348.8255 us. Best GFLOPs: 933.2391
2024-04-29 06:52:07 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #793: GFLOPs: 747.5026. Time: 309.5127 us. Best GFLOPs: 933.2391
2024-04-29 06:52:07 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #794: GFLOPs: 685.8031. Time: 337.3585 us. Best GFLOPs: 933.2391
2024-04-29 06:52:07 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #795: GFLOPs: 789.7471. Time: 292.9565 us. Best GFLOPs: 933.2391
2024-04-29 06:52:07 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #796: GFLOPs: 680.8595. Time: 339.8080 us. Best GFLOPs: 933.2391
2024-04-29 06:52:07 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #797: GFLOPs: 581.5822. Time: 397.8140 us. Best GFLOPs: 933.2391
2024-04-29 06:52:07 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #798: GFLOPs: 707.0878. Time: 327.2034 us. Best GFLOPs: 933.2391
2024-04-29 06:52:07 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #799: GFLOPs: 712.4213. Time: 324.7538 us. Best GFLOPs: 933.2391
2024-04-29 06:52:07 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #800: GFLOPs: 862.6675. Time: 268.1932 us. Best GFLOPs: 933.2391
2024-04-29 06:52:07 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #801: GFLOPs: 642.8116. Time: 359.9212 us. Best GFLOPs: 933.2391
2024-04-29 06:52:07 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #802: GFLOPs: 657.3645. Time: 351.9532 us. Best GFLOPs: 933.2391
2024-04-29 06:52:07 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #803: GFLOPs: 553.7780. Time: 417.7875 us. Best GFLOPs: 933.2391
2024-04-29 06:52:07 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #804: GFLOPs: 656.7424. Time: 352.2866 us. Best GFLOPs: 933.2391
2024-04-29 06:52:07 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #805: GFLOPs: 612.1675. Time: 377.9383 us. Best GFLOPs: 933.2391
2024-04-29 06:52:07 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #806: GFLOPs: 527.1755. Time: 438.8700 us. Best GFLOPs: 933.2391
2024-04-29 06:52:07 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #807: GFLOPs: 525.9893. Time: 439.8598 us. Best GFLOPs: 933.2391
2024-04-29 06:52:07 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #808: GFLOPs: 851.2284. Time: 271.7973 us. Best GFLOPs: 933.2391
2024-04-29 06:52:07 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #809: GFLOPs: 665.6351. Time: 347.5801 us. Best GFLOPs: 933.2391
2024-04-29 06:52:07 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #810: GFLOPs: 666.0067. Time: 347.3862 us. Best GFLOPs: 933.2391
2024-04-29 06:52:07 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #811: GFLOPs: 666.8926. Time: 346.9247 us. Best GFLOPs: 933.2391
2024-04-29 06:52:07 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #812: GFLOPs: 686.9921. Time: 336.7746 us. Best GFLOPs: 933.2391
2024-04-29 06:52:07 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #813: GFLOPs: 631.9140. Time: 366.1282 us. Best GFLOPs: 933.2391
2024-04-29 06:52:07 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #814: GFLOPs: 561.2616. Time: 412.2169 us. Best GFLOPs: 933.2391
2024-04-29 06:52:07 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #815: GFLOPs: 715.3286. Time: 323.4339 us. Best GFLOPs: 933.2391
2024-04-29 06:52:07 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #816: GFLOPs: 517.8908. Time: 446.7380 us. Best GFLOPs: 933.2391
2024-04-29 06:52:07 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #817: GFLOPs: 407.8474. Time: 567.2748 us. Best GFLOPs: 933.2391
2024-04-29 06:52:07 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #818: GFLOPs: 678.5590. Time: 340.9601 us. Best GFLOPs: 933.2391
2024-04-29 06:52:07 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #819: GFLOPs: 651.4719. Time: 355.1366 us. Best GFLOPs: 933.2391
2024-04-29 06:52:07 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #820: GFLOPs: 546.2808. Time: 423.5212 us. Best GFLOPs: 933.2391
2024-04-29 06:52:07 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #821: GFLOPs: 687.6658. Time: 336.4447 us. Best GFLOPs: 933.2391
2024-04-29 06:52:07 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #822: GFLOPs: 658.6921. Time: 351.2438 us. Best GFLOPs: 933.2391
2024-04-29 06:52:07 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #823: GFLOPs: 673.4767. Time: 343.5331 us. Best GFLOPs: 933.2391
2024-04-29 06:52:07 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #824: GFLOPs: 546.1857. Time: 423.5950 us. Best GFLOPs: 933.2391
2024-04-29 06:52:07 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #825: GFLOPs: 690.3343. Time: 335.1442 us. Best GFLOPs: 933.2391
2024-04-29 06:52:07 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #826: GFLOPs: 644.5136. Time: 358.9707 us. Best GFLOPs: 933.2391
2024-04-29 06:52:07 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #827: GFLOPs: 613.3917. Time: 377.1840 us. Best GFLOPs: 933.2391
2024-04-29 06:52:07 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #828: GFLOPs: 590.3948. Time: 391.8760 us. Best GFLOPs: 933.2391
2024-04-29 06:52:07 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #829: GFLOPs: 658.9587. Time: 351.1017 us. Best GFLOPs: 933.2391
2024-04-29 06:52:07 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #830: GFLOPs: 7.2487. Time: 31917.8673 us. Best GFLOPs: 933.2391
2024-04-29 06:52:07 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #831: GFLOPs: 41.5508. Time: 5568.1573 us. Best GFLOPs: 933.2391
2024-04-29 06:52:07 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #832: GFLOPs: 56.2011. Time: 4116.6693 us. Best GFLOPs: 933.2391
2024-04-29 06:56:53 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 06:56:55 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-29 06:56:59 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3639cb8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x419b828)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x312c9f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x425e1d8)]: 0 failure(s)
2024-04-29 06:56:59 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-29 06:57:12 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3639cb8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x419b828)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x312c9f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x425e1d8)]: 0 failure(s)
2024-04-29 06:57:26 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3639cb8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x419b828)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x312c9f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x425e1d8)]: 0 failure(s)
2024-04-29 06:57:39 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3639cb8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x419b828)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x312c9f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x425e1d8)]: 0 failure(s)
2024-04-29 06:57:53 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3639cb8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x419b828)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x312c9f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x425e1d8)]: 0 failure(s)
2024-04-29 06:58:02 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9938  0.8840  0.8840  0.8796  0.8730  0.8446  0.8407  0.8380  0.8332  0.8332  0.8314  0.8314  0.8314  0.8314  0.8252  0.8233
[17 : 32]:	0.8201  0.8201  0.8191  0.8186  0.8135  0.8070  0.8070  0.8053  0.8049  0.8045  0.7956  0.7858  0.7791  0.7785  0.7685  0.7558
[33 : 48]:	0.7481  0.7481  0.7481  0.7455  0.7426  0.7408  0.7378  0.7365  0.7365  0.7361  0.7322  0.7319  0.7311  0.7270  0.7200  0.7200
[49 : 64]:	0.7199  0.7183  0.7140  0.7137  0.7137  0.7131  0.7126  0.7095  0.7070  0.7039  0.7032  0.7032  0.7031  0.7031  0.7011  0.6992
2024-04-29 06:58:02 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 06:58:02 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 06:59:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #833: GFLOPs: 938.9573. Time: 246.4026 us. Best GFLOPs: 938.9573
2024-04-29 06:59:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #834: GFLOPs: 946.3400. Time: 244.4803 us. Best GFLOPs: 946.3400
2024-04-29 06:59:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #835: GFLOPs: 647.2469. Time: 357.4549 us. Best GFLOPs: 946.3400
2024-04-29 06:59:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #836: GFLOPs: 875.5911. Time: 264.2347 us. Best GFLOPs: 946.3400
2024-04-29 06:59:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #837: GFLOPs: 667.0296. Time: 346.8535 us. Best GFLOPs: 946.3400
2024-04-29 06:59:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #838: GFLOPs: 884.1640. Time: 261.6726 us. Best GFLOPs: 946.3400
2024-04-29 06:59:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #839: GFLOPs: 617.6282. Time: 374.5968 us. Best GFLOPs: 946.3400
2024-04-29 06:59:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #840: GFLOPs: 856.1510. Time: 270.2345 us. Best GFLOPs: 946.3400
2024-04-29 06:59:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #841: GFLOPs: 797.3384. Time: 290.1673 us. Best GFLOPs: 946.3400
2024-04-29 06:59:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #842: GFLOPs: 798.5464. Time: 289.7283 us. Best GFLOPs: 946.3400
2024-04-29 06:59:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #843: GFLOPs: 824.9130. Time: 280.4678 us. Best GFLOPs: 946.3400
2024-04-29 06:59:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #844: GFLOPs: 829.8808. Time: 278.7889 us. Best GFLOPs: 946.3400
2024-04-29 06:59:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #845: GFLOPs: 828.5640. Time: 279.2319 us. Best GFLOPs: 946.3400
2024-04-29 06:59:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #846: GFLOPs: 831.5578. Time: 278.2266 us. Best GFLOPs: 946.3400
2024-04-29 06:59:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #847: GFLOPs: 815.1028. Time: 283.8434 us. Best GFLOPs: 946.3400
2024-04-29 06:59:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #848: GFLOPs: 810.8061. Time: 285.3475 us. Best GFLOPs: 946.3400
2024-04-29 06:59:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #849: GFLOPs: 765.1125. Time: 302.3889 us. Best GFLOPs: 946.3400
2024-04-29 06:59:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #850: GFLOPs: 767.6650. Time: 301.3835 us. Best GFLOPs: 946.3400
2024-04-29 06:59:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #851: GFLOPs: 670.2108. Time: 345.2071 us. Best GFLOPs: 946.3400
2024-04-29 06:59:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #852: GFLOPs: 814.6039. Time: 284.0172 us. Best GFLOPs: 946.3400
2024-04-29 06:59:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #853: GFLOPs: 889.1447. Time: 260.2068 us. Best GFLOPs: 946.3400
2024-04-29 06:59:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #854: GFLOPs: 798.3750. Time: 289.7906 us. Best GFLOPs: 946.3400
2024-04-29 06:59:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #855: GFLOPs: 798.4683. Time: 289.7567 us. Best GFLOPs: 946.3400
2024-04-29 06:59:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #856: GFLOPs: 674.4182. Time: 343.0535 us. Best GFLOPs: 946.3400
2024-04-29 06:59:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #857: GFLOPs: 836.3745. Time: 276.6243 us. Best GFLOPs: 946.3400
2024-04-29 06:59:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #858: GFLOPs: 789.4385. Time: 293.0710 us. Best GFLOPs: 946.3400
2024-04-29 06:59:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #859: GFLOPs: 813.8463. Time: 284.2816 us. Best GFLOPs: 946.3400
2024-04-29 06:59:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #860: GFLOPs: 659.2487. Time: 350.9473 us. Best GFLOPs: 946.3400
2024-04-29 06:59:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #861: GFLOPs: 570.2238. Time: 405.7381 us. Best GFLOPs: 946.3400
2024-04-29 06:59:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #862: GFLOPs: 757.3733. Time: 305.4789 us. Best GFLOPs: 946.3400
2024-04-29 06:59:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #863: GFLOPs: 678.7070. Time: 340.8857 us. Best GFLOPs: 946.3400
2024-04-29 06:59:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #864: GFLOPs: 758.6559. Time: 304.9624 us. Best GFLOPs: 946.3400
2024-04-29 06:59:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #865: GFLOPs: 346.6138. Time: 667.4909 us. Best GFLOPs: 946.3400
2024-04-29 06:59:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #866: GFLOPs: 653.6296. Time: 353.9643 us. Best GFLOPs: 946.3400
2024-04-29 06:59:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #867: GFLOPs: 659.7030. Time: 350.7056 us. Best GFLOPs: 946.3400
2024-04-29 06:59:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #868: GFLOPs: 784.2557. Time: 295.0078 us. Best GFLOPs: 946.3400
2024-04-29 06:59:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #869: GFLOPs: 618.8541. Time: 373.8547 us. Best GFLOPs: 946.3400
2024-04-29 06:59:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #870: GFLOPs: 590.8550. Time: 391.5708 us. Best GFLOPs: 946.3400
2024-04-29 06:59:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #871: GFLOPs: 769.0583. Time: 300.8374 us. Best GFLOPs: 946.3400
2024-04-29 06:59:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #872: GFLOPs: 725.5294. Time: 318.8865 us. Best GFLOPs: 946.3400
2024-04-29 06:59:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #873: GFLOPs: 732.9429. Time: 315.6611 us. Best GFLOPs: 946.3400
2024-04-29 06:59:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #874: GFLOPs: 762.8334. Time: 303.2924 us. Best GFLOPs: 946.3400
2024-04-29 06:59:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #875: GFLOPs: 690.2747. Time: 335.1731 us. Best GFLOPs: 946.3400
2024-04-29 06:59:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #876: GFLOPs: 662.9050. Time: 349.0116 us. Best GFLOPs: 946.3400
2024-04-29 06:59:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #877: GFLOPs: 730.6111. Time: 316.6685 us. Best GFLOPs: 946.3400
2024-04-29 06:59:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #878: GFLOPs: 611.9290. Time: 378.0856 us. Best GFLOPs: 946.3400
2024-04-29 06:59:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #879: GFLOPs: 742.4620. Time: 311.6140 us. Best GFLOPs: 946.3400
2024-04-29 06:59:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #880: GFLOPs: 647.5266. Time: 357.3004 us. Best GFLOPs: 946.3400
2024-04-29 06:59:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #881: GFLOPs: 836.9213. Time: 276.4436 us. Best GFLOPs: 946.3400
2024-04-29 06:59:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #882: GFLOPs: 695.8517. Time: 332.4868 us. Best GFLOPs: 946.3400
2024-04-29 06:59:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #883: GFLOPs: 684.6826. Time: 337.9107 us. Best GFLOPs: 946.3400
2024-04-29 06:59:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #884: GFLOPs: 453.8977. Time: 509.7218 us. Best GFLOPs: 946.3400
2024-04-29 06:59:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #885: GFLOPs: 664.2298. Time: 348.3155 us. Best GFLOPs: 946.3400
2024-04-29 06:59:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #886: GFLOPs: 695.0812. Time: 332.8554 us. Best GFLOPs: 946.3400
2024-04-29 06:59:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #887: GFLOPs: 668.6653. Time: 346.0050 us. Best GFLOPs: 946.3400
2024-04-29 06:59:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #888: GFLOPs: 712.2556. Time: 324.8294 us. Best GFLOPs: 946.3400
2024-04-29 06:59:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #889: GFLOPs: 589.7129. Time: 392.3291 us. Best GFLOPs: 946.3400
2024-04-29 06:59:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #890: GFLOPs: 724.7907. Time: 319.2115 us. Best GFLOPs: 946.3400
2024-04-29 06:59:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #891: GFLOPs: 665.1981. Time: 347.8085 us. Best GFLOPs: 946.3400
2024-04-29 06:59:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #892: GFLOPs: 664.2365. Time: 348.3120 us. Best GFLOPs: 946.3400
2024-04-29 06:59:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #893: GFLOPs: 616.5109. Time: 375.2757 us. Best GFLOPs: 946.3400
2024-04-29 06:59:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #894: GFLOPs: 13.5477. Time: 17077.5915 us. Best GFLOPs: 946.3400
2024-04-29 06:59:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #895: GFLOPs: 23.7984. Time: 9721.7061 us. Best GFLOPs: 946.3400
2024-04-29 06:59:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #896: GFLOPs: 11.5411. Time: 20046.7480 us. Best GFLOPs: 946.3400
2024-04-29 07:14:58 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 07:15:00 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-29 07:15:04 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3639cb8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x419b828)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x312c9f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x425e1d8)]: 0 failure(s)
2024-04-29 07:15:04 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-29 07:15:17 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3639cb8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x419b828)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x312c9f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x425e1d8)]: 0 failure(s)
2024-04-29 07:15:31 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3639cb8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x419b828)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x312c9f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x425e1d8)]: 0 failure(s)
2024-04-29 07:15:45 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3639cb8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x419b828)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x312c9f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x425e1d8)]: 0 failure(s)
2024-04-29 07:16:00 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3639cb8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x419b828)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x312c9f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x425e1d8)]: 0 failure(s)
2024-04-29 07:16:08 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9262  0.9191  0.9191  0.9005  0.8886  0.8841  0.8793  0.8727  0.8694  0.8694  0.8691  0.8680  0.8680  0.8641  0.8641  0.8535
[17 : 32]:	0.8535  0.8479  0.8428  0.8405  0.8378  0.8307  0.8297  0.8232  0.8126  0.8126  0.8125  0.8125  0.8002  0.7958  0.7958  0.7836
[33 : 48]:	0.7753  0.7730  0.7728  0.7707  0.7702  0.7702  0.7685  0.7663  0.7663  0.7663  0.7605  0.7530  0.7530  0.7524  0.7508  0.7508
[49 : 64]:	0.7505  0.7503  0.7502  0.7500  0.7500  0.7490  0.7450  0.7389  0.7292  0.7283  0.7226  0.7226  0.7189  0.7187  0.7187  0.7111
2024-04-29 07:16:09 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 07:16:09 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 07:17:45 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #897: GFLOPs: 876.0733. Time: 264.0892 us. Best GFLOPs: 946.3400
2024-04-29 07:17:45 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #898: GFLOPs: 908.4646. Time: 254.6731 us. Best GFLOPs: 946.3400
2024-04-29 07:17:45 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #899: GFLOPs: 905.5844. Time: 255.4831 us. Best GFLOPs: 946.3400
2024-04-29 07:17:45 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #900: GFLOPs: 595.0446. Time: 388.8138 us. Best GFLOPs: 946.3400
2024-04-29 07:17:45 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #901: GFLOPs: 812.6972. Time: 284.6836 us. Best GFLOPs: 946.3400
2024-04-29 07:17:45 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #902: GFLOPs: 847.6510. Time: 272.9443 us. Best GFLOPs: 946.3400
2024-04-29 07:17:45 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #903: GFLOPs: 819.2372. Time: 282.4109 us. Best GFLOPs: 946.3400
2024-04-29 07:17:45 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #904: GFLOPs: 828.3288. Time: 279.3112 us. Best GFLOPs: 946.3400
2024-04-29 07:17:45 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #905: GFLOPs: 815.8948. Time: 283.5679 us. Best GFLOPs: 946.3400
2024-04-29 07:17:45 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #906: GFLOPs: 809.5577. Time: 285.7876 us. Best GFLOPs: 946.3400
2024-04-29 07:17:45 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #907: GFLOPs: 868.9214. Time: 266.2629 us. Best GFLOPs: 946.3400
2024-04-29 07:17:45 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #908: GFLOPs: 825.7674. Time: 280.1776 us. Best GFLOPs: 946.3400
2024-04-29 07:17:45 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #909: GFLOPs: 824.5391. Time: 280.5950 us. Best GFLOPs: 946.3400
2024-04-29 07:17:45 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #910: GFLOPs: 825.1022. Time: 280.4035 us. Best GFLOPs: 946.3400
2024-04-29 07:17:45 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #911: GFLOPs: 829.3314. Time: 278.9736 us. Best GFLOPs: 946.3400
2024-04-29 07:17:45 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #912: GFLOPs: 518.8989. Time: 445.8702 us. Best GFLOPs: 946.3400
2024-04-29 07:17:45 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #913: GFLOPs: 818.7873. Time: 282.5661 us. Best GFLOPs: 946.3400
2024-04-29 07:17:45 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #914: GFLOPs: 817.4106. Time: 283.0420 us. Best GFLOPs: 946.3400
2024-04-29 07:17:45 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #915: GFLOPs: 819.8018. Time: 282.2164 us. Best GFLOPs: 946.3400
2024-04-29 07:17:45 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #916: GFLOPs: 802.1312. Time: 288.4335 us. Best GFLOPs: 946.3400
2024-04-29 07:17:45 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #917: GFLOPs: 816.5586. Time: 283.3373 us. Best GFLOPs: 946.3400
2024-04-29 07:17:45 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #918: GFLOPs: 822.9894. Time: 281.1233 us. Best GFLOPs: 946.3400
2024-04-29 07:17:45 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #919: GFLOPs: 823.9858. Time: 280.7834 us. Best GFLOPs: 946.3400
2024-04-29 07:17:45 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #920: GFLOPs: 809.5412. Time: 285.7934 us. Best GFLOPs: 946.3400
2024-04-29 07:17:45 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #921: GFLOPs: 821.5238. Time: 281.6249 us. Best GFLOPs: 946.3400
2024-04-29 07:17:45 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #922: GFLOPs: 825.3500. Time: 280.3193 us. Best GFLOPs: 946.3400
2024-04-29 07:17:45 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #923: GFLOPs: 766.4008. Time: 301.8806 us. Best GFLOPs: 946.3400
2024-04-29 07:17:45 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #924: GFLOPs: 763.3512. Time: 303.0866 us. Best GFLOPs: 946.3400
2024-04-29 07:17:45 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #925: GFLOPs: 793.5645. Time: 291.5472 us. Best GFLOPs: 946.3400
2024-04-29 07:17:45 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #926: GFLOPs: 778.1238. Time: 297.3325 us. Best GFLOPs: 946.3400
2024-04-29 07:17:45 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #927: GFLOPs: 779.3211. Time: 296.8757 us. Best GFLOPs: 946.3400
2024-04-29 07:17:45 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #928: GFLOPs: 680.3090. Time: 340.0830 us. Best GFLOPs: 946.3400
2024-04-29 07:17:45 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #929: GFLOPs: 659.8640. Time: 350.6200 us. Best GFLOPs: 946.3400
2024-04-29 07:17:45 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #930: GFLOPs: 795.9068. Time: 290.6892 us. Best GFLOPs: 946.3400
2024-04-29 07:17:45 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #931: GFLOPs: 823.9653. Time: 280.7904 us. Best GFLOPs: 946.3400
2024-04-29 07:17:45 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #932: GFLOPs: 703.9372. Time: 328.6679 us. Best GFLOPs: 946.3400
2024-04-29 07:17:45 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #933: GFLOPs: 752.2925. Time: 307.5420 us. Best GFLOPs: 946.3400
2024-04-29 07:17:45 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #934: GFLOPs: 747.3056. Time: 309.5943 us. Best GFLOPs: 946.3400
2024-04-29 07:17:45 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #935: GFLOPs: 747.0712. Time: 309.6914 us. Best GFLOPs: 946.3400
2024-04-29 07:17:45 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #936: GFLOPs: 750.9022. Time: 308.1114 us. Best GFLOPs: 946.3400
2024-04-29 07:17:45 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #937: GFLOPs: 751.2496. Time: 307.9690 us. Best GFLOPs: 946.3400
2024-04-29 07:17:45 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #938: GFLOPs: 750.9614. Time: 308.0871 us. Best GFLOPs: 946.3400
2024-04-29 07:17:45 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #939: GFLOPs: 772.8387. Time: 299.3659 us. Best GFLOPs: 946.3400
2024-04-29 07:17:45 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #940: GFLOPs: 745.3597. Time: 310.4025 us. Best GFLOPs: 946.3400
2024-04-29 07:17:45 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #941: GFLOPs: 738.4363. Time: 313.3128 us. Best GFLOPs: 946.3400
2024-04-29 07:17:45 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #942: GFLOPs: 724.8985. Time: 319.1640 us. Best GFLOPs: 946.3400
2024-04-29 07:17:45 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #943: GFLOPs: 700.2228. Time: 330.4113 us. Best GFLOPs: 946.3400
2024-04-29 07:17:45 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #944: GFLOPs: 697.4899. Time: 331.7060 us. Best GFLOPs: 946.3400
2024-04-29 07:17:45 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #945: GFLOPs: 746.9988. Time: 309.7214 us. Best GFLOPs: 946.3400
2024-04-29 07:17:45 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #946: GFLOPs: 723.3001. Time: 319.8694 us. Best GFLOPs: 946.3400
2024-04-29 07:17:45 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #947: GFLOPs: 791.1606. Time: 292.4331 us. Best GFLOPs: 946.3400
2024-04-29 07:17:45 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #948: GFLOPs: 630.8989. Time: 366.7173 us. Best GFLOPs: 946.3400
2024-04-29 07:17:45 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #949: GFLOPs: 648.4836. Time: 356.7732 us. Best GFLOPs: 946.3400
2024-04-29 07:17:45 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #950: GFLOPs: 683.1046. Time: 338.6912 us. Best GFLOPs: 946.3400
2024-04-29 07:17:45 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #951: GFLOPs: 840.3966. Time: 275.3004 us. Best GFLOPs: 946.3400
2024-04-29 07:17:45 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #952: GFLOPs: 527.8861. Time: 438.2793 us. Best GFLOPs: 946.3400
2024-04-29 07:17:45 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #953: GFLOPs: 735.4928. Time: 314.5667 us. Best GFLOPs: 946.3400
2024-04-29 07:17:45 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #954: GFLOPs: 726.1190. Time: 318.6276 us. Best GFLOPs: 946.3400
2024-04-29 07:17:45 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #955: GFLOPs: 857.7294. Time: 269.7372 us. Best GFLOPs: 946.3400
2024-04-29 07:17:45 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #956: GFLOPs: 693.0258. Time: 333.8426 us. Best GFLOPs: 946.3400
2024-04-29 07:17:45 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #957: GFLOPs: 724.5357. Time: 319.3238 us. Best GFLOPs: 946.3400
2024-04-29 07:17:45 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #958: GFLOPs: 46.2248. Time: 5005.1404 us. Best GFLOPs: 946.3400
2024-04-29 07:17:45 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #959: GFLOPs: 47.5050. Time: 4870.2602 us. Best GFLOPs: 946.3400
2024-04-29 07:17:45 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #960: GFLOPs: 40.6092. Time: 5697.2655 us. Best GFLOPs: 946.3400
2024-04-29 07:25:48 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 07:25:49 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-29 07:25:54 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3639cb8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x419b828)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x312c9f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x425e1d8)]: 0 failure(s)
2024-04-29 07:25:54 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-29 07:26:07 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3639cb8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x419b828)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x312c9f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x425e1d8)]: 0 failure(s)
2024-04-29 07:26:21 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3639cb8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x419b828)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x312c9f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x425e1d8)]: 0 failure(s)
2024-04-29 07:26:36 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3639cb8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x419b828)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x312c9f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x425e1d8)]: 0 failure(s)
2024-04-29 07:26:50 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3639cb8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x419b828)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x312c9f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x425e1d8)]: 0 failure(s)
2024-04-29 07:26:59 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9498  0.9498  0.8936  0.8936  0.8672  0.8599  0.8412  0.8388  0.8382  0.8380  0.8380  0.8380  0.8358  0.8358  0.8347  0.8347
[17 : 32]:	0.8305  0.8290  0.8290  0.8250  0.8247  0.8206  0.8206  0.8184  0.8046  0.7949  0.7943  0.7932  0.7917  0.7917  0.7908  0.7894
[33 : 48]:	0.7894  0.7879  0.7843  0.7827  0.7827  0.7827  0.7821  0.7754  0.7737  0.7709  0.7635  0.7623  0.7608  0.7608  0.7608  0.7606
[49 : 64]:	0.7568  0.7550  0.7537  0.7514  0.7473  0.7446  0.7376  0.7344  0.7341  0.7337  0.7337  0.7337  0.7336  0.7324  0.7292  0.7291
2024-04-29 07:26:59 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 07:27:00 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 07:28:33 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #961: GFLOPs: 469.2521. Time: 493.0432 us. Best GFLOPs: 946.3400
2024-04-29 07:28:33 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #962: GFLOPs: 907.4444. Time: 254.9595 us. Best GFLOPs: 946.3400
2024-04-29 07:28:33 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #963: GFLOPs: 870.4882. Time: 265.7837 us. Best GFLOPs: 946.3400
2024-04-29 07:28:33 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #964: GFLOPs: 864.3627. Time: 267.6672 us. Best GFLOPs: 946.3400
2024-04-29 07:28:33 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #965: GFLOPs: 815.9085. Time: 283.5631 us. Best GFLOPs: 946.3400
2024-04-29 07:28:33 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #966: GFLOPs: 836.3207. Time: 276.6421 us. Best GFLOPs: 946.3400
2024-04-29 07:28:33 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #967: GFLOPs: 791.3568. Time: 292.3606 us. Best GFLOPs: 946.3400
2024-04-29 07:28:33 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #968: GFLOPs: 789.4772. Time: 293.0566 us. Best GFLOPs: 946.3400
2024-04-29 07:28:33 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #969: GFLOPs: 814.2453. Time: 284.1423 us. Best GFLOPs: 946.3400
2024-04-29 07:28:33 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #970: GFLOPs: 405.8532. Time: 570.0621 us. Best GFLOPs: 946.3400
2024-04-29 07:28:33 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #971: GFLOPs: 800.4614. Time: 289.0352 us. Best GFLOPs: 946.3400
2024-04-29 07:28:33 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #972: GFLOPs: 805.5900. Time: 287.1952 us. Best GFLOPs: 946.3400
2024-04-29 07:28:33 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #973: GFLOPs: 788.4676. Time: 293.4319 us. Best GFLOPs: 946.3400
2024-04-29 07:28:33 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #974: GFLOPs: 792.7126. Time: 291.8605 us. Best GFLOPs: 946.3400
2024-04-29 07:28:33 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #975: GFLOPs: 812.3979. Time: 284.7884 us. Best GFLOPs: 946.3400
2024-04-29 07:28:33 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #976: GFLOPs: 813.4601. Time: 284.4166 us. Best GFLOPs: 946.3400
2024-04-29 07:28:33 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #977: GFLOPs: 788.8408. Time: 293.2931 us. Best GFLOPs: 946.3400
2024-04-29 07:28:33 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #978: GFLOPs: 812.8302. Time: 284.6370 us. Best GFLOPs: 946.3400
2024-04-29 07:28:33 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #979: GFLOPs: 817.7719. Time: 282.9169 us. Best GFLOPs: 946.3400
2024-04-29 07:28:33 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #980: GFLOPs: 793.0795. Time: 291.7255 us. Best GFLOPs: 946.3400
2024-04-29 07:28:33 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #981: GFLOPs: 800.3413. Time: 289.0786 us. Best GFLOPs: 946.3400
2024-04-29 07:28:33 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #982: GFLOPs: 781.4143. Time: 296.0805 us. Best GFLOPs: 946.3400
2024-04-29 07:28:33 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #983: GFLOPs: 786.1981. Time: 294.2789 us. Best GFLOPs: 946.3400
2024-04-29 07:28:33 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #984: GFLOPs: 844.0138. Time: 274.1205 us. Best GFLOPs: 946.3400
2024-04-29 07:28:33 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #985: GFLOPs: 561.3261. Time: 412.1695 us. Best GFLOPs: 946.3400
2024-04-29 07:28:33 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #986: GFLOPs: 764.0815. Time: 302.7969 us. Best GFLOPs: 946.3400
2024-04-29 07:28:33 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #987: GFLOPs: 900.8865. Time: 256.8154 us. Best GFLOPs: 946.3400
2024-04-29 07:28:33 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #988: GFLOPs: 800.1881. Time: 289.1339 us. Best GFLOPs: 946.3400
2024-04-29 07:28:33 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #989: GFLOPs: 755.1745. Time: 306.3683 us. Best GFLOPs: 946.3400
2024-04-29 07:28:33 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #990: GFLOPs: 756.2538. Time: 305.9311 us. Best GFLOPs: 946.3400
2024-04-29 07:28:33 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #991: GFLOPs: 680.5049. Time: 339.9851 us. Best GFLOPs: 946.3400
2024-04-29 07:28:33 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #992: GFLOPs: 757.1733. Time: 305.5595 us. Best GFLOPs: 946.3400
2024-04-29 07:28:33 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #993: GFLOPs: 757.5714. Time: 305.3990 us. Best GFLOPs: 946.3400
2024-04-29 07:28:33 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #994: GFLOPs: 777.8205. Time: 297.4485 us. Best GFLOPs: 946.3400
2024-04-29 07:28:33 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #995: GFLOPs: 713.9398. Time: 324.0631 us. Best GFLOPs: 946.3400
2024-04-29 07:28:33 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #996: GFLOPs: 761.5446. Time: 303.8056 us. Best GFLOPs: 946.3400
2024-04-29 07:28:33 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #997: GFLOPs: 762.2203. Time: 303.5363 us. Best GFLOPs: 946.3400
2024-04-29 07:28:33 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #998: GFLOPs: 386.1606. Time: 599.1330 us. Best GFLOPs: 946.3400
2024-04-29 07:28:33 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #999: GFLOPs: 685.2588. Time: 337.6265 us. Best GFLOPs: 946.3400
2024-04-29 07:28:33 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1000: GFLOPs: 740.2583. Time: 312.5416 us. Best GFLOPs: 946.3400
2024-04-29 07:28:33 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1001: GFLOPs: 827.1209. Time: 279.7191 us. Best GFLOPs: 946.3400
2024-04-29 07:28:33 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1002: GFLOPs: 746.4857. Time: 309.9343 us. Best GFLOPs: 946.3400
2024-04-29 07:28:33 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1003: GFLOPs: 801.3004. Time: 288.7326 us. Best GFLOPs: 946.3400
2024-04-29 07:28:33 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1004: GFLOPs: 332.2694. Time: 696.3072 us. Best GFLOPs: 946.3400
2024-04-29 07:28:33 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1005: GFLOPs: 671.8814. Time: 344.3488 us. Best GFLOPs: 946.3400
2024-04-29 07:28:33 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1006: GFLOPs: 448.9101. Time: 515.3851 us. Best GFLOPs: 946.3400
2024-04-29 07:28:33 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1007: GFLOPs: 667.4741. Time: 346.6225 us. Best GFLOPs: 946.3400
2024-04-29 07:28:33 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1008: GFLOPs: 728.0977. Time: 317.7617 us. Best GFLOPs: 946.3400
2024-04-29 07:28:33 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1009: GFLOPs: 696.6042. Time: 332.1277 us. Best GFLOPs: 946.3400
2024-04-29 07:28:33 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1010: GFLOPs: 459.0517. Time: 503.9989 us. Best GFLOPs: 946.3400
2024-04-29 07:28:33 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1011: GFLOPs: 682.8611. Time: 338.8120 us. Best GFLOPs: 946.3400
2024-04-29 07:28:33 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1012: GFLOPs: 797.3043. Time: 290.1797 us. Best GFLOPs: 946.3400
2024-04-29 07:28:33 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1013: GFLOPs: 740.0838. Time: 312.6153 us. Best GFLOPs: 946.3400
2024-04-29 07:28:33 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1014: GFLOPs: 769.7044. Time: 300.5849 us. Best GFLOPs: 946.3400
2024-04-29 07:28:33 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1015: GFLOPs: 670.0906. Time: 345.2691 us. Best GFLOPs: 946.3400
2024-04-29 07:28:33 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1016: GFLOPs: 756.6897. Time: 305.7549 us. Best GFLOPs: 946.3400
2024-04-29 07:28:33 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1017: GFLOPs: 659.5941. Time: 350.7635 us. Best GFLOPs: 946.3400
2024-04-29 07:28:33 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1018: GFLOPs: 737.2932. Time: 313.7986 us. Best GFLOPs: 946.3400
2024-04-29 07:28:33 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1019: GFLOPs: 737.0440. Time: 313.9046 us. Best GFLOPs: 946.3400
2024-04-29 07:28:33 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1020: GFLOPs: 737.7466. Time: 313.6057 us. Best GFLOPs: 946.3400
2024-04-29 07:28:33 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1021: GFLOPs: 748.3034. Time: 309.1815 us. Best GFLOPs: 946.3400
2024-04-29 07:28:33 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1022: GFLOPs: 52.8590. Time: 4376.9553 us. Best GFLOPs: 946.3400
2024-04-29 07:28:33 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1023: GFLOPs: 4.1117. Time: 56268.9273 us. Best GFLOPs: 946.3400
2024-04-29 07:28:33 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1024: GFLOPs: 64.4200. Time: 3591.4529 us. Best GFLOPs: 946.3400
2024-04-29 07:55:15 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 07:55:16 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-29 07:55:21 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3639cb8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x419b828)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x312c9f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x425e1d8)]: 0 failure(s)
2024-04-29 07:55:21 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-29 07:55:34 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3639cb8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x419b828)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x312c9f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x425e1d8)]: 0 failure(s)
2024-04-29 07:55:48 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3639cb8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x419b828)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x312c9f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x425e1d8)]: 0 failure(s)
2024-04-29 07:56:03 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3639cb8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x419b828)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x312c9f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x425e1d8)]: 0 failure(s)
2024-04-29 07:56:17 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3639cb8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x419b828)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x312c9f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x425e1d8)]: 0 failure(s)
2024-04-29 07:56:27 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9036  0.9035  0.8810  0.8667  0.8636  0.8548  0.8548  0.8435  0.8428  0.8384  0.8380  0.8380  0.8375  0.8365  0.8317  0.8317
[17 : 32]:	0.8302  0.8283  0.8283  0.8276  0.8276  0.8246  0.8173  0.8145  0.8145  0.8097  0.8097  0.8059  0.7952  0.7859  0.7850  0.7827
[33 : 48]:	0.7826  0.7773  0.7763  0.7763  0.7758  0.7709  0.7700  0.7633  0.7626  0.7616  0.7531  0.7520  0.7517  0.7460  0.7443  0.7403
[49 : 64]:	0.7385  0.7361  0.7349  0.7348  0.7330  0.7326  0.7326  0.7282  0.7279  0.7271  0.7269  0.7234  0.7231  0.7229  0.7197  0.7190
2024-04-29 07:56:27 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 07:56:27 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 07:58:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1025: GFLOPs: 870.1845. Time: 265.8764 us. Best GFLOPs: 946.3400
2024-04-29 07:58:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1026: GFLOPs: 885.5937. Time: 261.2502 us. Best GFLOPs: 946.3400
2024-04-29 07:58:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1027: GFLOPs: 808.1783. Time: 286.2753 us. Best GFLOPs: 946.3400
2024-04-29 07:58:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1028: GFLOPs: 802.0083. Time: 288.4777 us. Best GFLOPs: 946.3400
2024-04-29 07:58:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1029: GFLOPs: 882.2934. Time: 262.2274 us. Best GFLOPs: 946.3400
2024-04-29 07:58:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1030: GFLOPs: 792.9240. Time: 291.7828 us. Best GFLOPs: 946.3400
2024-04-29 07:58:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1031: GFLOPs: 789.8678. Time: 292.9117 us. Best GFLOPs: 946.3400
2024-04-29 07:58:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1032: GFLOPs: 788.7391. Time: 293.3309 us. Best GFLOPs: 946.3400
2024-04-29 07:58:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1033: GFLOPs: 785.7764. Time: 294.4369 us. Best GFLOPs: 946.3400
2024-04-29 07:58:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1034: GFLOPs: 772.6066. Time: 299.4558 us. Best GFLOPs: 946.3400
2024-04-29 07:58:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1035: GFLOPs: 767.9785. Time: 301.2604 us. Best GFLOPs: 946.3400
2024-04-29 07:58:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1036: GFLOPs: 786.3070. Time: 294.2382 us. Best GFLOPs: 946.3400
2024-04-29 07:58:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1037: GFLOPs: 769.6839. Time: 300.5929 us. Best GFLOPs: 946.3400
2024-04-29 07:58:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1038: GFLOPs: 795.5288. Time: 290.8273 us. Best GFLOPs: 946.3400
2024-04-29 07:58:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1039: GFLOPs: 799.7459. Time: 289.2938 us. Best GFLOPs: 946.3400
2024-04-29 07:58:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1040: GFLOPs: 799.9711. Time: 289.2124 us. Best GFLOPs: 946.3400
2024-04-29 07:58:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1041: GFLOPs: 789.3379. Time: 293.1083 us. Best GFLOPs: 946.3400
2024-04-29 07:58:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1042: GFLOPs: 806.0457. Time: 287.0328 us. Best GFLOPs: 946.3400
2024-04-29 07:58:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1043: GFLOPs: 803.5824. Time: 287.9126 us. Best GFLOPs: 946.3400
2024-04-29 07:58:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1044: GFLOPs: 784.1263. Time: 295.0565 us. Best GFLOPs: 946.3400
2024-04-29 07:58:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1045: GFLOPs: 784.2147. Time: 295.0232 us. Best GFLOPs: 946.3400
2024-04-29 07:58:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1046: GFLOPs: 770.4541. Time: 300.2924 us. Best GFLOPs: 946.3400
2024-04-29 07:58:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1047: GFLOPs: 774.6435. Time: 298.6684 us. Best GFLOPs: 946.3400
2024-04-29 07:58:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1048: GFLOPs: 799.4366. Time: 289.4058 us. Best GFLOPs: 946.3400
2024-04-29 07:58:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1049: GFLOPs: 800.8291. Time: 288.9025 us. Best GFLOPs: 946.3400
2024-04-29 07:58:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1050: GFLOPs: 777.0012. Time: 297.7621 us. Best GFLOPs: 946.3400
2024-04-29 07:58:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1051: GFLOPs: 776.5000. Time: 297.9543 us. Best GFLOPs: 946.3400
2024-04-29 07:58:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1052: GFLOPs: 772.9908. Time: 299.3070 us. Best GFLOPs: 946.3400
2024-04-29 07:58:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1053: GFLOPs: 757.3150. Time: 305.5024 us. Best GFLOPs: 946.3400
2024-04-29 07:58:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1054: GFLOPs: 798.0354. Time: 289.9139 us. Best GFLOPs: 946.3400
2024-04-29 07:58:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1055: GFLOPs: 595.6009. Time: 388.4506 us. Best GFLOPs: 946.3400
2024-04-29 07:58:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1056: GFLOPs: 762.1813. Time: 303.5518 us. Best GFLOPs: 946.3400
2024-04-29 07:58:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1057: GFLOPs: 807.3368. Time: 286.5738 us. Best GFLOPs: 946.3400
2024-04-29 07:58:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1058: GFLOPs: 779.4277. Time: 296.8352 us. Best GFLOPs: 946.3400
2024-04-29 07:58:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1059: GFLOPs: 807.8552. Time: 286.3899 us. Best GFLOPs: 946.3400
2024-04-29 07:58:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1060: GFLOPs: 809.5159. Time: 285.8023 us. Best GFLOPs: 946.3400
2024-04-29 07:58:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1061: GFLOPs: 773.1709. Time: 299.2372 us. Best GFLOPs: 946.3400
2024-04-29 07:58:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1062: GFLOPs: 731.5369. Time: 316.2677 us. Best GFLOPs: 946.3400
2024-04-29 07:58:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1063: GFLOPs: 726.2843. Time: 318.5550 us. Best GFLOPs: 946.3400
2024-04-29 07:58:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1064: GFLOPs: 693.8045. Time: 333.4679 us. Best GFLOPs: 946.3400
2024-04-29 07:58:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1065: GFLOPs: 748.9498. Time: 308.9146 us. Best GFLOPs: 946.3400
2024-04-29 07:58:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1066: GFLOPs: 780.5907. Time: 296.3929 us. Best GFLOPs: 946.3400
2024-04-29 07:58:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1067: GFLOPs: 740.3361. Time: 312.5088 us. Best GFLOPs: 946.3400
2024-04-29 07:58:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1068: GFLOPs: 575.1640. Time: 402.2531 us. Best GFLOPs: 946.3400
2024-04-29 07:58:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1069: GFLOPs: 664.9865. Time: 347.9191 us. Best GFLOPs: 946.3400
2024-04-29 07:58:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1070: GFLOPs: 651.3439. Time: 355.2064 us. Best GFLOPs: 946.3400
2024-04-29 07:58:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1071: GFLOPs: 691.0125. Time: 334.8153 us. Best GFLOPs: 946.3400
2024-04-29 07:58:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1072: GFLOPs: 695.1344. Time: 332.8300 us. Best GFLOPs: 946.3400
2024-04-29 07:58:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1073: GFLOPs: 688.3740. Time: 336.0986 us. Best GFLOPs: 946.3400
2024-04-29 07:58:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1074: GFLOPs: 652.1632. Time: 354.7602 us. Best GFLOPs: 946.3400
2024-04-29 07:58:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1075: GFLOPs: 790.3236. Time: 292.7428 us. Best GFLOPs: 946.3400
2024-04-29 07:58:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1076: GFLOPs: 680.0358. Time: 340.2196 us. Best GFLOPs: 946.3400
2024-04-29 07:58:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1077: GFLOPs: 695.1483. Time: 332.8233 us. Best GFLOPs: 946.3400
2024-04-29 07:58:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1078: GFLOPs: 671.4930. Time: 344.5480 us. Best GFLOPs: 946.3400
2024-04-29 07:58:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1079: GFLOPs: 660.3469. Time: 350.3636 us. Best GFLOPs: 946.3400
2024-04-29 07:58:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1080: GFLOPs: 674.5052. Time: 343.0093 us. Best GFLOPs: 946.3400
2024-04-29 07:58:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1081: GFLOPs: 692.4302. Time: 334.1297 us. Best GFLOPs: 946.3400
2024-04-29 07:58:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1082: GFLOPs: 634.4461. Time: 364.6670 us. Best GFLOPs: 946.3400
2024-04-29 07:58:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1083: GFLOPs: 677.9165. Time: 341.2832 us. Best GFLOPs: 946.3400
2024-04-29 07:58:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1084: GFLOPs: 664.7691. Time: 348.0330 us. Best GFLOPs: 946.3400
2024-04-29 07:58:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1085: GFLOPs: 791.5354. Time: 292.2946 us. Best GFLOPs: 946.3400
2024-04-29 07:58:15 [INFO] [task_scheduler.cc:121] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1086: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(14), T.int64(14), T.int64(128)), "float32"), p1: T.Buffer((T.int64(16), T.int64(2), T.int64(3), T.int64(3), T.int64(128), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(16)), "float32"), p3: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(16), T.int64(16), T.int64(128)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused in T.parallel(T.int64(224), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(2), T.int64(7), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(2), T.int64(2), T.int64(1)):
                with T.block("conv2d_NCHWc_init"):
                    v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                    v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(2) * T.int64(8) + oc_chunk_2_init * T.int64(4) + oc_chunk_3_init)
                    v_oh = T.axis.spatial(T.int64(14), oh_2_init * T.int64(2) + oh_3_init)
                    v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(32) * T.int64(2) + ow_2_init * T.int64(2) + ow_3_init)
                    v_oc_block = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(32) // T.int64(2) + oc_block_2_init + oc_block_3_init)
                    T.reads()
                    T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                    T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                    conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
            for ic_0 in range(T.int64(8)):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(16), T.int64(4)):
                    for ax4_fused in T.vectorized(T.int64(32)):
                        with T.block("data_pad"):
                            v_i0 = T.axis.spatial(T.int64(1), ax0)
                            v_i1 = T.axis.spatial(T.int64(2), ic_0 // T.int64(4) + ax1)
                            v_i2 = T.axis.spatial(T.int64(16), ax2)
                            v_i3 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(32) * T.int64(2) + ax3)
                            v_i4 = T.axis.spatial(T.int64(128), ic_0 % T.int64(4) * T.int64(32) + ax4_fused)
                            T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                            T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                            data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(15) and T.int64(1) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                for kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(7), T.int64(1), T.int64(1), T.int64(32), T.int64(3), T.int64(3), T.int64(1), T.int64(4), T.int64(2), T.int64(2), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(2) * T.int64(8) + oc_chunk_2 * T.int64(4) + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(14), oh_2 * T.int64(2) + oh_3)
                        v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(32) * T.int64(2) + ow_2 * T.int64(2) + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(32) // T.int64(2) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(32) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(8), T.int64(14), T.int64(2), T.int64(1)):
                with T.block("T_relu"):
                    v_ax0 = T.axis.spatial(T.int64(1), ax0)
                    v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(2) * T.int64(8) + ax1)
                    v_ax2 = T.axis.spatial(T.int64(14), ax2)
                    v_ax3 = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(32) * T.int64(2) + ax3)
                    v_ax4 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(32) // T.int64(2) + ax4)
                    T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 2, 2, 4])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 7, 2])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[7, 1, 1, 2])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[16, 1, 1, 1])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[8, 32])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[1, 3])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l50, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=10)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87 = sch.get_loops(block=b69)
l88 = sch.fuse(l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, preserve_unit_iters=True)
sch.parallel(loop=l88)
l89 = sch.fuse(l87, preserve_unit_iters=True)
sch.vectorize(loop=l89)
l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106 = sch.get_loops(block=b70)
l107 = sch.fuse(l90, preserve_unit_iters=True)
sch.parallel(loop=l107)
sch.annotate(block_or_loop=l107, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l107, ann_key="pragma_unroll_explicit", ann_val=1)
l108, l109, l110, l111, l112, l113 = sch.get_loops(block=b71)
b114 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131 = sch.get_loops(block=b114)
b132 = sch.decompose_reduction(block=b114, loop=l116)
2024-04-29 07:58:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1087: GFLOPs: 1.6259. Time: 142293.3063 us. Best GFLOPs: 946.3400
2024-04-29 07:58:15 [INFO] [task_scheduler.cc:121] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1088: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(14), T.int64(14), T.int64(128)), "float32"), p1: T.Buffer((T.int64(16), T.int64(2), T.int64(3), T.int64(3), T.int64(128), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(16)), "float32"), p3: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(16), T.int64(16), T.int64(128)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused in T.parallel(T.int64(112), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(2), T.int64(16), T.int64(3), T.int64(128)):
                with T.block("data_pad"):
                    v_i0, v_i1, v_i2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                    v_i3 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(14) + ax3)
                    v_i4 = T.axis.spatial(T.int64(128), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(15) and T.int64(1) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oc_block_1 in range(T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(1), T.int64(14), T.int64(1), T.int64(1), T.int64(1), T.int64(16), T.int64(1), T.int64(1)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(2)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(16), oc_chunk_2_init * T.int64(16) + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(14), oh_2_init + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(14) + ow_2_init + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(14) * T.int64(2) + oc_block_1 * T.int64(2) + oc_block_2_init * T.int64(2) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(4), T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(14), T.int64(1), T.int64(1), T.int64(64), T.int64(1), T.int64(1), T.int64(1), T.int64(16), T.int64(1), T.int64(1)):
                    for oc_block_3_fused in T.vectorized(T.int64(2)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(16), oc_chunk_2 * T.int64(16) + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(14), oh_2 + oh_3)
                            v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(14) + ow_2 + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(14) * T.int64(2) + oc_block_1 * T.int64(2) + oc_block_2 * T.int64(2) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(64) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(16), T.int64(14), T.int64(1)):
                    for ax4_fused in T.vectorized(T.int64(2)):
                        with T.block("T_relu"):
                            v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                            v_ax3 = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(14) + ax3)
                            v_ax4 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(14) * T.int64(2) + ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 1, 16])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 14, 1])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 14, 1, 1])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[8, 1, 1, 2])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[4, 64])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[3, 1])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l50, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=8)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85 = sch.get_loops(block=b69)
l86 = sch.fuse(l72, l73, l74, l75, l76, l77, l78, l79, l80, preserve_unit_iters=True)
sch.parallel(loop=l86)
l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b70)
l105 = sch.fuse(l87, preserve_unit_iters=True)
sch.parallel(loop=l105)
l106 = sch.fuse(l104, preserve_unit_iters=True)
sch.vectorize(loop=l106)
sch.annotate(block_or_loop=l105, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l105, ann_key="pragma_unroll_explicit", ann_val=1)
l107, l108, l109, l110, l111, l112, l113 = sch.get_loops(block=b71)
l114 = sch.fuse(l113, preserve_unit_iters=True)
sch.vectorize(loop=l114)
b115 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133 = sch.get_loops(block=b115)
b134 = sch.decompose_reduction(block=b115, loop=l118)
2024-04-29 08:00:59 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 08:01:00 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-29 08:01:05 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3639cb8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x419b828)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x312c9f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x425e1d8)]: 0 failure(s)
2024-04-29 08:01:05 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-29 08:01:18 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3639cb8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x419b828)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x312c9f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x425e1d8)]: 0 failure(s)
2024-04-29 08:01:32 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3639cb8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x419b828)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x312c9f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x425e1d8)]: 0 failure(s)
2024-04-29 08:01:47 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3639cb8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x419b828)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x312c9f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x425e1d8)]: 0 failure(s)
2024-04-29 08:02:01 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3639cb8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x419b828)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x312c9f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x425e1d8)]: 0 failure(s)
2024-04-29 08:02:10 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.8867  0.8742  0.8623  0.8613  0.8592  0.8592  0.8550  0.8489  0.8480  0.8448  0.8445  0.8410  0.8390  0.8385  0.8379  0.8379
[17 : 32]:	0.8369  0.8345  0.8315  0.8299  0.8299  0.8285  0.8281  0.8248  0.8241  0.8234  0.8211  0.8211  0.8210  0.8182  0.8182  0.8135
[33 : 48]:	0.8115  0.8102  0.8057  0.7946  0.7946  0.7943  0.7943  0.7859  0.7842  0.7842  0.7749  0.7688  0.7655  0.7655  0.7539  0.7524
[49 : 64]:	0.7520  0.7443  0.7438  0.7413  0.7411  0.7402  0.7363  0.7361  0.7361  0.7361  0.7343  0.7342  0.7313  0.7313  0.7313  0.7313
2024-04-29 08:02:11 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 08:02:11 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 08:04:01 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1089: GFLOPs: 869.2130. Time: 266.1736 us. Best GFLOPs: 946.3400
2024-04-29 08:04:01 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1090: GFLOPs: 847.7537. Time: 272.9113 us. Best GFLOPs: 946.3400
2024-04-29 08:04:01 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1091: GFLOPs: 823.7942. Time: 280.8487 us. Best GFLOPs: 946.3400
2024-04-29 08:04:01 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1092: GFLOPs: 849.8286. Time: 272.2449 us. Best GFLOPs: 946.3400
2024-04-29 08:04:01 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1093: GFLOPs: 834.0686. Time: 277.3891 us. Best GFLOPs: 946.3400
2024-04-29 08:04:01 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1094: GFLOPs: 834.3266. Time: 277.3033 us. Best GFLOPs: 946.3400
2024-04-29 08:04:01 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1095: GFLOPs: 826.8931. Time: 279.7962 us. Best GFLOPs: 946.3400
2024-04-29 08:04:01 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1096: GFLOPs: 391.1494. Time: 591.4915 us. Best GFLOPs: 946.3400
2024-04-29 08:04:01 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1097: GFLOPs: 451.4978. Time: 512.4311 us. Best GFLOPs: 946.3400
2024-04-29 08:04:01 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1098: GFLOPs: 781.0976. Time: 296.2005 us. Best GFLOPs: 946.3400
2024-04-29 08:04:01 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1099: GFLOPs: 804.7615. Time: 287.4908 us. Best GFLOPs: 946.3400
2024-04-29 08:04:01 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1100: GFLOPs: 861.9991. Time: 268.4011 us. Best GFLOPs: 946.3400
2024-04-29 08:04:01 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1101: GFLOPs: 791.9064. Time: 292.1577 us. Best GFLOPs: 946.3400
2024-04-29 08:04:01 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1102: GFLOPs: 787.3542. Time: 293.8468 us. Best GFLOPs: 946.3400
2024-04-29 08:04:01 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1103: GFLOPs: 796.0125. Time: 290.6506 us. Best GFLOPs: 946.3400
2024-04-29 08:04:01 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1104: GFLOPs: 798.0513. Time: 289.9081 us. Best GFLOPs: 946.3400
2024-04-29 08:04:01 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1105: GFLOPs: 784.2238. Time: 295.0198 us. Best GFLOPs: 946.3400
2024-04-29 08:04:01 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1106: GFLOPs: 795.3127. Time: 290.9064 us. Best GFLOPs: 946.3400
2024-04-29 08:04:01 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1107: GFLOPs: 781.4005. Time: 296.0857 us. Best GFLOPs: 946.3400
2024-04-29 08:04:01 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1108: GFLOPs: 763.3149. Time: 303.1010 us. Best GFLOPs: 946.3400
2024-04-29 08:04:01 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1109: GFLOPs: 766.1089. Time: 301.9956 us. Best GFLOPs: 946.3400
2024-04-29 08:04:01 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1110: GFLOPs: 810.6326. Time: 285.4086 us. Best GFLOPs: 946.3400
2024-04-29 08:04:01 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1111: GFLOPs: 762.0559. Time: 303.6018 us. Best GFLOPs: 946.3400
2024-04-29 08:04:01 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1112: GFLOPs: 795.2969. Time: 290.9122 us. Best GFLOPs: 946.3400
2024-04-29 08:04:01 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1113: GFLOPs: 766.7524. Time: 301.7422 us. Best GFLOPs: 946.3400
2024-04-29 08:04:01 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1114: GFLOPs: 779.9898. Time: 296.6212 us. Best GFLOPs: 946.3400
2024-04-29 08:04:01 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1115: GFLOPs: 778.4574. Time: 297.2051 us. Best GFLOPs: 946.3400
2024-04-29 08:04:01 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1116: GFLOPs: 772.5524. Time: 299.4768 us. Best GFLOPs: 946.3400
2024-04-29 08:04:01 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1117: GFLOPs: 807.4667. Time: 286.5277 us. Best GFLOPs: 946.3400
2024-04-29 08:04:01 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1118: GFLOPs: 787.2644. Time: 293.8804 us. Best GFLOPs: 946.3400
2024-04-29 08:04:01 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1119: GFLOPs: 786.2890. Time: 294.2449 us. Best GFLOPs: 946.3400
2024-04-29 08:04:01 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1120: GFLOPs: 814.6817. Time: 283.9901 us. Best GFLOPs: 946.3400
2024-04-29 08:04:01 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1121: GFLOPs: 801.4284. Time: 288.6865 us. Best GFLOPs: 946.3400
2024-04-29 08:04:01 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1122: GFLOPs: 801.3725. Time: 288.7066 us. Best GFLOPs: 946.3400
2024-04-29 08:04:01 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1123: GFLOPs: 811.6248. Time: 285.0597 us. Best GFLOPs: 946.3400
2024-04-29 08:04:01 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1124: GFLOPs: 789.7489. Time: 292.9558 us. Best GFLOPs: 946.3400
2024-04-29 08:04:01 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1125: GFLOPs: 787.7662. Time: 293.6932 us. Best GFLOPs: 946.3400
2024-04-29 08:04:01 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1126: GFLOPs: 796.8411. Time: 290.3484 us. Best GFLOPs: 946.3400
2024-04-29 08:04:01 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1127: GFLOPs: 786.0870. Time: 294.3205 us. Best GFLOPs: 946.3400
2024-04-29 08:04:01 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1128: GFLOPs: 764.9827. Time: 302.4402 us. Best GFLOPs: 946.3400
2024-04-29 08:04:01 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1129: GFLOPs: 780.2022. Time: 296.5405 us. Best GFLOPs: 946.3400
2024-04-29 08:04:01 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1130: GFLOPs: 779.0708. Time: 296.9711 us. Best GFLOPs: 946.3400
2024-04-29 08:04:01 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1131: GFLOPs: 653.9319. Time: 353.8007 us. Best GFLOPs: 946.3400
2024-04-29 08:04:01 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1132: GFLOPs: 716.2079. Time: 323.0368 us. Best GFLOPs: 946.3400
2024-04-29 08:04:01 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1133: GFLOPs: 795.4832. Time: 290.8440 us. Best GFLOPs: 946.3400
2024-04-29 08:04:01 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1134: GFLOPs: 790.0003. Time: 292.8626 us. Best GFLOPs: 946.3400
2024-04-29 08:04:01 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1135: GFLOPs: 732.4668. Time: 315.8662 us. Best GFLOPs: 946.3400
2024-04-29 08:04:01 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1136: GFLOPs: 718.5688. Time: 321.9755 us. Best GFLOPs: 946.3400
2024-04-29 08:04:01 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1137: GFLOPs: 724.9203. Time: 319.1545 us. Best GFLOPs: 946.3400
2024-04-29 08:04:01 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1138: GFLOPs: 789.3088. Time: 293.1192 us. Best GFLOPs: 946.3400
2024-04-29 08:04:01 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1139: GFLOPs: 722.0992. Time: 320.4013 us. Best GFLOPs: 946.3400
2024-04-29 08:04:01 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1140: GFLOPs: 800.2252. Time: 289.1205 us. Best GFLOPs: 946.3400
2024-04-29 08:04:01 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1141: GFLOPs: 786.8292. Time: 294.0429 us. Best GFLOPs: 946.3400
2024-04-29 08:04:01 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1142: GFLOPs: 831.0281. Time: 278.4040 us. Best GFLOPs: 946.3400
2024-04-29 08:04:01 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1143: GFLOPs: 712.6391. Time: 324.6545 us. Best GFLOPs: 946.3400
2024-04-29 08:04:01 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1144: GFLOPs: 788.8996. Time: 293.2712 us. Best GFLOPs: 946.3400
2024-04-29 08:04:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1145: GFLOPs: 700.7269. Time: 330.1736 us. Best GFLOPs: 946.3400
2024-04-29 08:04:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1146: GFLOPs: 785.9941. Time: 294.3553 us. Best GFLOPs: 946.3400
2024-04-29 08:04:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1147: GFLOPs: 853.4599. Time: 271.0866 us. Best GFLOPs: 946.3400
2024-04-29 08:04:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1148: GFLOPs: 686.5977. Time: 336.9681 us. Best GFLOPs: 946.3400
2024-04-29 08:04:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1149: GFLOPs: 846.0852. Time: 273.4494 us. Best GFLOPs: 946.3400
2024-04-29 08:04:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1150: GFLOPs: 116.2957. Time: 1989.4253 us. Best GFLOPs: 946.3400
2024-04-29 08:04:02 [INFO] [task_scheduler.cc:121] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1151: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(14), T.int64(14), T.int64(128)), "float32"), p1: T.Buffer((T.int64(16), T.int64(2), T.int64(3), T.int64(3), T.int64(128), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(16)), "float32"), p3: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(16), T.int64(16), T.int64(128)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused in T.parallel(T.int64(8), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(4), T.int64(2), T.int64(1), T.int64(2)):
                for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(2), T.int64(9), T.int64(16), T.int64(128)):
                    with T.block("data_pad"):
                        v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                        v_i2 = T.axis.spatial(T.int64(16), oh_1 * T.int64(7) + ax2)
                        v_i3, v_i4 = T.axis.remap("SS", [ax3, ax4])
                        T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                        T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                        data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(15) and T.int64(1) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(14), T.int64(1), T.int64(1), T.int64(2), T.int64(7), T.int64(1)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(2)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(4) * T.int64(8) + oc_chunk_1 * T.int64(2) + oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(14), oh_1 * T.int64(7) + oh_2_init * T.int64(7) + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(14), ow_1 * T.int64(14) + ow_2_init + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(4) * T.int64(4) + oc_block_1 * T.int64(2) + oc_block_2_init * T.int64(2) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(64), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(14), T.int64(1), T.int64(4), T.int64(3), T.int64(3), T.int64(1), T.int64(2), T.int64(7), T.int64(1)):
                    for oc_block_3_fused in T.vectorized(T.int64(2)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(4) * T.int64(8) + oc_chunk_1 * T.int64(2) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(14), oh_1 * T.int64(7) + oh_2 * T.int64(7) + oh_3)
                            v_ow = T.axis.spatial(T.int64(14), ow_1 * T.int64(14) + ow_2 + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(4) * T.int64(4) + oc_block_1 * T.int64(2) + oc_block_2 * T.int64(2) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(4) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(8), T.int64(14), T.int64(14)):
                for ax4_fused in T.vectorized(T.int64(4)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(4) * T.int64(8) + ax1)
                        v_ax2, v_ax3 = T.axis.remap("SS", [ax2, ax3])
                        v_ax4 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(4) * T.int64(4) + ax4_fused)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 4, 1, 2])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 2, 1, 7])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 14, 1])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[4, 2, 1, 2])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[64, 4])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[1, 3])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=9)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86 = sch.get_loops(block=b69)
l87 = sch.fuse(l72, l73, l74, l75, l76, preserve_unit_iters=True)
sch.parallel(loop=l87)
l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107, l108, l109 = sch.get_loops(block=b70)
l110 = sch.fuse(l88, preserve_unit_iters=True)
sch.parallel(loop=l110)
l111 = sch.fuse(l109, preserve_unit_iters=True)
sch.vectorize(loop=l111)
sch.annotate(block_or_loop=l110, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l110, ann_key="pragma_unroll_explicit", ann_val=1)
l112, l113, l114, l115, l116, l117 = sch.get_loops(block=b71)
l118 = sch.fuse(l117, preserve_unit_iters=True)
sch.vectorize(loop=l118)
b119 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141 = sch.get_loops(block=b119)
b142 = sch.decompose_reduction(block=b119, loop=l126)
2024-04-29 08:04:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1152: GFLOPs: 10.4383. Time: 22164.6126 us. Best GFLOPs: 946.3400
2024-04-29 08:17:28 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 08:17:29 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-29 08:17:34 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3639cb8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x419b828)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x312c9f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x425e1d8)]: 0 failure(s)
2024-04-29 08:17:34 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-29 08:17:47 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3639cb8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x419b828)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x312c9f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x425e1d8)]: 0 failure(s)
2024-04-29 08:18:01 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3639cb8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x419b828)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x312c9f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x425e1d8)]: 0 failure(s)
2024-04-29 08:18:16 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3639cb8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x419b828)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x312c9f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x425e1d8)]: 0 failure(s)
2024-04-29 08:18:30 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3639cb8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x419b828)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x312c9f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x425e1d8)]: 0 failure(s)
2024-04-29 08:18:39 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9226  0.9037  0.8589  0.8515  0.8498  0.8496  0.8450  0.8395  0.8384  0.8384  0.8384  0.8384  0.8381  0.8378  0.8368  0.8368
[17 : 32]:	0.8368  0.8368  0.8362  0.8355  0.8323  0.8276  0.8265  0.8252  0.8251  0.8218  0.8205  0.8154  0.8083  0.8022  0.8013  0.7994
[33 : 48]:	0.7988  0.7988  0.7971  0.7949  0.7841  0.7818  0.7791  0.7763  0.7733  0.7701  0.7617  0.7573  0.7534  0.7534  0.7510  0.7509
[49 : 64]:	0.7508  0.7499  0.7499  0.7497  0.7496  0.7489  0.7487  0.7487  0.7446  0.7446  0.7434  0.7433  0.7409  0.7395  0.7395  0.7381
2024-04-29 08:18:39 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 08:18:39 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 08:20:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1153: GFLOPs: 476.5999. Time: 485.4418 us. Best GFLOPs: 946.3400
2024-04-29 08:20:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1154: GFLOPs: 450.8573. Time: 513.1591 us. Best GFLOPs: 946.3400
2024-04-29 08:20:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1155: GFLOPs: 871.7417. Time: 265.4015 us. Best GFLOPs: 946.3400
2024-04-29 08:20:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1156: GFLOPs: 819.0469. Time: 282.4766 us. Best GFLOPs: 946.3400
2024-04-29 08:20:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1157: GFLOPs: 833.5376. Time: 277.5658 us. Best GFLOPs: 946.3400
2024-04-29 08:20:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1158: GFLOPs: 811.0874. Time: 285.2486 us. Best GFLOPs: 946.3400
2024-04-29 08:20:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1159: GFLOPs: 791.1379. Time: 292.4415 us. Best GFLOPs: 946.3400
2024-04-29 08:20:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1160: GFLOPs: 804.6933. Time: 287.5152 us. Best GFLOPs: 946.3400
2024-04-29 08:20:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1161: GFLOPs: 682.2626. Time: 339.1092 us. Best GFLOPs: 946.3400
2024-04-29 08:20:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1162: GFLOPs: 537.0617. Time: 430.7914 us. Best GFLOPs: 946.3400
2024-04-29 08:20:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1163: GFLOPs: 679.7169. Time: 340.3792 us. Best GFLOPs: 946.3400
2024-04-29 08:20:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1164: GFLOPs: 824.9506. Time: 280.4550 us. Best GFLOPs: 946.3400
2024-04-29 08:20:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1165: GFLOPs: 791.7680. Time: 292.2087 us. Best GFLOPs: 946.3400
2024-04-29 08:20:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1166: GFLOPs: 810.2573. Time: 285.5408 us. Best GFLOPs: 946.3400
2024-04-29 08:20:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1167: GFLOPs: 820.6663. Time: 281.9191 us. Best GFLOPs: 946.3400
2024-04-29 08:20:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1168: GFLOPs: 677.7492. Time: 341.3675 us. Best GFLOPs: 946.3400
2024-04-29 08:20:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1169: GFLOPs: 671.6269. Time: 344.4792 us. Best GFLOPs: 946.3400
2024-04-29 08:20:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1170: GFLOPs: 829.2440. Time: 279.0030 us. Best GFLOPs: 946.3400
2024-04-29 08:20:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1171: GFLOPs: 803.2182. Time: 288.0432 us. Best GFLOPs: 946.3400
2024-04-29 08:20:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1172: GFLOPs: 797.3085. Time: 290.1782 us. Best GFLOPs: 946.3400
2024-04-29 08:20:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1173: GFLOPs: 804.9024. Time: 287.4405 us. Best GFLOPs: 946.3400
2024-04-29 08:20:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1174: GFLOPs: 805.2442. Time: 287.3185 us. Best GFLOPs: 946.3400
2024-04-29 08:20:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1175: GFLOPs: 812.4862. Time: 284.7575 us. Best GFLOPs: 946.3400
2024-04-29 08:20:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1176: GFLOPs: 786.1333. Time: 294.3032 us. Best GFLOPs: 946.3400
2024-04-29 08:20:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1177: GFLOPs: 799.1028. Time: 289.5266 us. Best GFLOPs: 946.3400
2024-04-29 08:20:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1178: GFLOPs: 788.7229. Time: 293.3369 us. Best GFLOPs: 946.3400
2024-04-29 08:20:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1179: GFLOPs: 830.0983. Time: 278.7158 us. Best GFLOPs: 946.3400
2024-04-29 08:20:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1180: GFLOPs: 774.7795. Time: 298.6160 us. Best GFLOPs: 946.3400
2024-04-29 08:20:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1181: GFLOPs: 785.7584. Time: 294.4436 us. Best GFLOPs: 946.3400
2024-04-29 08:20:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1182: GFLOPs: 746.7487. Time: 309.8252 us. Best GFLOPs: 946.3400
2024-04-29 08:20:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1183: GFLOPs: 705.7813. Time: 327.8091 us. Best GFLOPs: 946.3400
2024-04-29 08:20:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1184: GFLOPs: 766.7929. Time: 301.7262 us. Best GFLOPs: 946.3400
2024-04-29 08:20:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1185: GFLOPs: 745.5447. Time: 310.3255 us. Best GFLOPs: 946.3400
2024-04-29 08:20:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1186: GFLOPs: 743.8337. Time: 311.0393 us. Best GFLOPs: 946.3400
2024-04-29 08:20:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1187: GFLOPs: 360.3860. Time: 641.9827 us. Best GFLOPs: 946.3400
2024-04-29 08:20:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1188: GFLOPs: 530.7830. Time: 435.8872 us. Best GFLOPs: 946.3400
2024-04-29 08:20:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1189: GFLOPs: 760.4996. Time: 304.2231 us. Best GFLOPs: 946.3400
2024-04-29 08:20:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1190: GFLOPs: 818.2143. Time: 282.7640 us. Best GFLOPs: 946.3400
2024-04-29 08:20:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1191: GFLOPs: 753.3250. Time: 307.1205 us. Best GFLOPs: 946.3400
2024-04-29 08:20:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1192: GFLOPs: 705.1807. Time: 328.0883 us. Best GFLOPs: 946.3400
2024-04-29 08:20:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1193: GFLOPs: 702.1355. Time: 329.5112 us. Best GFLOPs: 946.3400
2024-04-29 08:20:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1194: GFLOPs: 739.1705. Time: 313.0016 us. Best GFLOPs: 946.3400
2024-04-29 08:20:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1195: GFLOPs: 812.2239. Time: 284.8495 us. Best GFLOPs: 946.3400
2024-04-29 08:20:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1196: GFLOPs: 732.3473. Time: 315.9178 us. Best GFLOPs: 946.3400
2024-04-29 08:20:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1197: GFLOPs: 852.5379. Time: 271.3798 us. Best GFLOPs: 946.3400
2024-04-29 08:20:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1198: GFLOPs: 637.2118. Time: 363.0842 us. Best GFLOPs: 946.3400
2024-04-29 08:20:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1199: GFLOPs: 663.5812. Time: 348.6559 us. Best GFLOPs: 946.3400
2024-04-29 08:20:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1200: GFLOPs: 672.3170. Time: 344.1256 us. Best GFLOPs: 946.3400
2024-04-29 08:20:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1201: GFLOPs: 567.9900. Time: 407.3338 us. Best GFLOPs: 946.3400
2024-04-29 08:20:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1202: GFLOPs: 682.1784. Time: 339.1511 us. Best GFLOPs: 946.3400
2024-04-29 08:20:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1203: GFLOPs: 686.1552. Time: 337.1854 us. Best GFLOPs: 946.3400
2024-04-29 08:20:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1204: GFLOPs: 357.9965. Time: 646.2676 us. Best GFLOPs: 946.3400
2024-04-29 08:20:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1205: GFLOPs: 820.6180. Time: 281.9357 us. Best GFLOPs: 946.3400
2024-04-29 08:20:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1206: GFLOPs: 845.8862. Time: 273.5138 us. Best GFLOPs: 946.3400
2024-04-29 08:20:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1207: GFLOPs: 599.0788. Time: 386.1955 us. Best GFLOPs: 946.3400
2024-04-29 08:20:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1208: GFLOPs: 768.9671. Time: 300.8731 us. Best GFLOPs: 946.3400
2024-04-29 08:20:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1209: GFLOPs: 515.8503. Time: 448.5052 us. Best GFLOPs: 946.3400
2024-04-29 08:20:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1210: GFLOPs: 515.6554. Time: 448.6747 us. Best GFLOPs: 946.3400
2024-04-29 08:20:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1211: GFLOPs: 820.6635. Time: 281.9201 us. Best GFLOPs: 946.3400
2024-04-29 08:20:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1212: GFLOPs: 793.7788. Time: 291.4685 us. Best GFLOPs: 946.3400
2024-04-29 08:20:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1213: GFLOPs: 669.4015. Time: 345.6245 us. Best GFLOPs: 946.3400
2024-04-29 08:20:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1214: GFLOPs: 121.1674. Time: 1909.4378 us. Best GFLOPs: 946.3400
2024-04-29 08:20:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1215: GFLOPs: 55.9359. Time: 4136.1921 us. Best GFLOPs: 946.3400
2024-04-29 08:20:15 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1216: GFLOPs: 73.5554. Time: 3145.4049 us. Best GFLOPs: 946.3400
2024-04-29 08:28:19 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 08:28:20 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-29 08:28:24 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3639cb8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x419b828)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x312c9f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x425e1d8)]: 0 failure(s)
2024-04-29 08:28:24 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-29 08:28:37 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3639cb8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x419b828)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x312c9f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x425e1d8)]: 0 failure(s)
2024-04-29 08:28:52 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3639cb8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x419b828)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x312c9f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x425e1d8)]: 0 failure(s)
2024-04-29 08:29:06 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3639cb8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x419b828)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x312c9f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x425e1d8)]: 0 failure(s)
2024-04-29 08:29:20 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3639cb8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x419b828)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x312c9f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x425e1d8)]: 0 failure(s)
2024-04-29 08:29:29 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9048  0.8971  0.8727  0.8727  0.8710  0.8710  0.8582  0.8582  0.8582  0.8571  0.8522  0.8476  0.8453  0.8453  0.8432  0.8423
[17 : 32]:	0.8418  0.8398  0.8327  0.8327  0.8301  0.8284  0.8252  0.8250  0.8245  0.8144  0.8125  0.8092  0.8092  0.8043  0.7989  0.7989
[33 : 48]:	0.7989  0.7966  0.7925  0.7925  0.7925  0.7922  0.7911  0.7911  0.7875  0.7875  0.7875  0.7860  0.7858  0.7847  0.7819  0.7819
[49 : 64]:	0.7785  0.7751  0.7751  0.7751  0.7685  0.7654  0.7543  0.7541  0.7541  0.7429  0.7396  0.7392  0.7378  0.7378  0.7361  0.7310
2024-04-29 08:29:29 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 08:29:29 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 08:31:05 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1217: GFLOPs: 881.7670. Time: 262.3840 us. Best GFLOPs: 946.3400
2024-04-29 08:31:05 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1218: GFLOPs: 879.8095. Time: 262.9678 us. Best GFLOPs: 946.3400
2024-04-29 08:31:05 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1219: GFLOPs: 620.7857. Time: 372.6915 us. Best GFLOPs: 946.3400
2024-04-29 08:31:05 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1220: GFLOPs: 808.6205. Time: 286.1188 us. Best GFLOPs: 946.3400
2024-04-29 08:31:05 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1221: GFLOPs: 623.9862. Time: 370.7799 us. Best GFLOPs: 946.3400
2024-04-29 08:31:05 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1222: GFLOPs: 572.7826. Time: 403.9256 us. Best GFLOPs: 946.3400
2024-04-29 08:31:05 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1223: GFLOPs: 777.3182. Time: 297.6407 us. Best GFLOPs: 946.3400
2024-04-29 08:31:05 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1224: GFLOPs: 324.4719. Time: 713.0402 us. Best GFLOPs: 946.3400
2024-04-29 08:31:05 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1225: GFLOPs: 333.1437. Time: 694.4797 us. Best GFLOPs: 946.3400
2024-04-29 08:31:05 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1226: GFLOPs: 826.3413. Time: 279.9830 us. Best GFLOPs: 946.3400
2024-04-29 08:31:05 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1227: GFLOPs: 820.5830. Time: 281.9478 us. Best GFLOPs: 946.3400
2024-04-29 08:31:05 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1228: GFLOPs: 820.4071. Time: 282.0082 us. Best GFLOPs: 946.3400
2024-04-29 08:31:05 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1229: GFLOPs: 306.6315. Time: 754.5264 us. Best GFLOPs: 946.3400
2024-04-29 08:31:05 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1230: GFLOPs: 807.8085. Time: 286.4064 us. Best GFLOPs: 946.3400
2024-04-29 08:31:05 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1231: GFLOPs: 811.3016. Time: 285.1733 us. Best GFLOPs: 946.3400
2024-04-29 08:31:05 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1232: GFLOPs: 815.3671. Time: 283.7514 us. Best GFLOPs: 946.3400
2024-04-29 08:31:05 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1233: GFLOPs: 843.3527. Time: 274.3355 us. Best GFLOPs: 946.3400
2024-04-29 08:31:05 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1234: GFLOPs: 81.7677. Time: 2829.4968 us. Best GFLOPs: 946.3400
2024-04-29 08:31:05 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1235: GFLOPs: 753.6356. Time: 306.9939 us. Best GFLOPs: 946.3400
2024-04-29 08:31:05 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1236: GFLOPs: 794.0993. Time: 291.3509 us. Best GFLOPs: 946.3400
2024-04-29 08:31:05 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1237: GFLOPs: 807.0129. Time: 286.6888 us. Best GFLOPs: 946.3400
2024-04-29 08:31:05 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1238: GFLOPs: 787.8015. Time: 293.6800 us. Best GFLOPs: 946.3400
2024-04-29 08:31:05 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1239: GFLOPs: 799.3900. Time: 289.4226 us. Best GFLOPs: 946.3400
2024-04-29 08:31:05 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1240: GFLOPs: 688.6403. Time: 335.9686 us. Best GFLOPs: 946.3400
2024-04-29 08:31:05 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1241: GFLOPs: 768.5395. Time: 301.0405 us. Best GFLOPs: 946.3400
2024-04-29 08:31:05 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1242: GFLOPs: 770.7871. Time: 300.1627 us. Best GFLOPs: 946.3400
2024-04-29 08:31:05 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1243: GFLOPs: 811.9190. Time: 284.9564 us. Best GFLOPs: 946.3400
2024-04-29 08:31:05 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1244: GFLOPs: 775.7308. Time: 298.2498 us. Best GFLOPs: 946.3400
2024-04-29 08:31:05 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1245: GFLOPs: 787.0108. Time: 293.9750 us. Best GFLOPs: 946.3400
2024-04-29 08:31:05 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1246: GFLOPs: 545.9073. Time: 423.8110 us. Best GFLOPs: 946.3400
2024-04-29 08:31:05 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1247: GFLOPs: 81.7288. Time: 2830.8460 us. Best GFLOPs: 946.3400
2024-04-29 08:31:05 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1248: GFLOPs: 812.0629. Time: 284.9059 us. Best GFLOPs: 946.3400
2024-04-29 08:31:05 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1249: GFLOPs: 818.9977. Time: 282.4935 us. Best GFLOPs: 946.3400
2024-04-29 08:31:05 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1250: GFLOPs: 760.6594. Time: 304.1592 us. Best GFLOPs: 946.3400
2024-04-29 08:31:05 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1251: GFLOPs: 663.1594. Time: 348.8777 us. Best GFLOPs: 946.3400
2024-04-29 08:31:05 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1252: GFLOPs: 663.4853. Time: 348.7064 us. Best GFLOPs: 946.3400
2024-04-29 08:31:05 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1253: GFLOPs: 829.1069. Time: 279.0491 us. Best GFLOPs: 946.3400
2024-04-29 08:31:05 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1254: GFLOPs: 581.6555. Time: 397.7638 us. Best GFLOPs: 946.3400
2024-04-29 08:31:05 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1255: GFLOPs: 808.4969. Time: 286.1626 us. Best GFLOPs: 946.3400
2024-04-29 08:31:05 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1256: GFLOPs: 812.4019. Time: 284.7871 us. Best GFLOPs: 946.3400
2024-04-29 08:31:05 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1257: GFLOPs: 831.1219. Time: 278.3726 us. Best GFLOPs: 946.3400
2024-04-29 08:31:05 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1258: GFLOPs: 81.6272. Time: 2834.3688 us. Best GFLOPs: 946.3400
2024-04-29 08:31:05 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1259: GFLOPs: 833.4440. Time: 277.5970 us. Best GFLOPs: 946.3400
2024-04-29 08:31:05 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1260: GFLOPs: 682.1419. Time: 339.1692 us. Best GFLOPs: 946.3400
2024-04-29 08:31:05 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1261: GFLOPs: 775.8773. Time: 298.1935 us. Best GFLOPs: 946.3400
2024-04-29 08:31:05 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1262: GFLOPs: 799.9999. Time: 289.2019 us. Best GFLOPs: 946.3400
2024-04-29 08:31:05 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1263: GFLOPs: 730.4466. Time: 316.7398 us. Best GFLOPs: 946.3400
2024-04-29 08:31:05 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1264: GFLOPs: 685.4152. Time: 337.5495 us. Best GFLOPs: 946.3400
2024-04-29 08:31:05 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1265: GFLOPs: 544.4351. Time: 424.9570 us. Best GFLOPs: 946.3400
2024-04-29 08:31:05 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1266: GFLOPs: 68.8184. Time: 3361.9137 us. Best GFLOPs: 946.3400
2024-04-29 08:31:05 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1267: GFLOPs: 778.8309. Time: 297.0626 us. Best GFLOPs: 946.3400
2024-04-29 08:31:05 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1268: GFLOPs: 555.9959. Time: 416.1209 us. Best GFLOPs: 946.3400
2024-04-29 08:31:05 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1269: GFLOPs: 724.1467. Time: 319.4954 us. Best GFLOPs: 946.3400
2024-04-29 08:31:05 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1270: GFLOPs: 465.1557. Time: 497.3852 us. Best GFLOPs: 946.3400
2024-04-29 08:31:05 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1271: GFLOPs: 682.1743. Time: 339.1531 us. Best GFLOPs: 946.3400
2024-04-29 08:31:05 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1272: GFLOPs: 83.4036. Time: 2774.0005 us. Best GFLOPs: 946.3400
2024-04-29 08:31:05 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1273: GFLOPs: 82.2182. Time: 2813.9932 us. Best GFLOPs: 946.3400
2024-04-29 08:31:05 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1274: GFLOPs: 361.3046. Time: 640.3504 us. Best GFLOPs: 946.3400
2024-04-29 08:31:05 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1275: GFLOPs: 678.9005. Time: 340.7886 us. Best GFLOPs: 946.3400
2024-04-29 08:31:05 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1276: GFLOPs: 692.7153. Time: 333.9923 us. Best GFLOPs: 946.3400
2024-04-29 08:31:05 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1277: GFLOPs: 627.0991. Time: 368.9394 us. Best GFLOPs: 946.3400
2024-04-29 08:31:05 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1278: GFLOPs: 9.8139. Time: 23574.8964 us. Best GFLOPs: 946.3400
2024-04-29 08:31:05 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1279: GFLOPs: 10.7211. Time: 21579.9940 us. Best GFLOPs: 946.3400
2024-04-29 08:31:05 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1280: GFLOPs: 27.7582. Time: 8334.9044 us. Best GFLOPs: 946.3400
2024-04-29 08:39:00 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 08:39:01 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-29 08:39:06 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3639cb8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x419b828)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x312c9f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x425e1d8)]: 0 failure(s)
2024-04-29 08:39:06 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-29 08:39:19 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3639cb8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x419b828)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x312c9f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x425e1d8)]: 0 failure(s)
2024-04-29 08:39:33 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3639cb8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x419b828)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x312c9f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x425e1d8)]: 0 failure(s)
2024-04-29 08:39:48 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3639cb8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x419b828)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x312c9f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x425e1d8)]: 0 failure(s)
2024-04-29 08:40:02 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3639cb8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x419b828)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x312c9f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x425e1d8)]: 0 failure(s)
2024-04-29 08:40:11 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9197  0.9056  0.8751  0.8649  0.8649  0.8477  0.8456  0.8417  0.8396  0.8396  0.8389  0.8389  0.8389  0.8389  0.8343  0.8337
[17 : 32]:	0.8320  0.8313  0.8274  0.8200  0.8162  0.8162  0.8162  0.8158  0.7996  0.7979  0.7970  0.7949  0.7949  0.7949  0.7949  0.7949
[33 : 48]:	0.7866  0.7852  0.7852  0.7830  0.7772  0.7729  0.7727  0.7683  0.7680  0.7660  0.7659  0.7651  0.7637  0.7633  0.7551  0.7486
[49 : 64]:	0.7437  0.7368  0.7353  0.7318  0.7294  0.7294  0.7273  0.7232  0.7222  0.7215  0.7208  0.7203  0.7193  0.7193  0.7193  0.7189
2024-04-29 08:40:11 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 08:40:12 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 08:41:46 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1281: GFLOPs: 904.5844. Time: 255.7656 us. Best GFLOPs: 946.3400
2024-04-29 08:41:46 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1282: GFLOPs: 905.3210. Time: 255.5575 us. Best GFLOPs: 946.3400
2024-04-29 08:41:46 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1283: GFLOPs: 847.0314. Time: 273.1440 us. Best GFLOPs: 946.3400
2024-04-29 08:41:46 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1284: GFLOPs: 870.4561. Time: 265.7935 us. Best GFLOPs: 946.3400
2024-04-29 08:41:46 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1285: GFLOPs: 864.3328. Time: 267.6765 us. Best GFLOPs: 946.3400
2024-04-29 08:41:46 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1286: GFLOPs: 791.3961. Time: 292.3461 us. Best GFLOPs: 946.3400
2024-04-29 08:41:46 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1287: GFLOPs: 825.2537. Time: 280.3520 us. Best GFLOPs: 946.3400
2024-04-29 08:41:46 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1288: GFLOPs: 819.2260. Time: 282.4148 us. Best GFLOPs: 946.3400
2024-04-29 08:41:46 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1289: GFLOPs: 810.3046. Time: 285.5242 us. Best GFLOPs: 946.3400
2024-04-29 08:41:46 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1290: GFLOPs: 807.2252. Time: 286.6134 us. Best GFLOPs: 946.3400
2024-04-29 08:41:46 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1291: GFLOPs: 809.7814. Time: 285.7086 us. Best GFLOPs: 946.3400
2024-04-29 08:41:46 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1292: GFLOPs: 810.4880. Time: 285.4595 us. Best GFLOPs: 946.3400
2024-04-29 08:41:46 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1293: GFLOPs: 806.5043. Time: 286.8696 us. Best GFLOPs: 946.3400
2024-04-29 08:41:46 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1294: GFLOPs: 800.0166. Time: 289.1959 us. Best GFLOPs: 946.3400
2024-04-29 08:41:46 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1295: GFLOPs: 813.1234. Time: 284.5343 us. Best GFLOPs: 946.3400
2024-04-29 08:41:46 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1296: GFLOPs: 806.1747. Time: 286.9868 us. Best GFLOPs: 946.3400
2024-04-29 08:41:46 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1297: GFLOPs: 807.1529. Time: 286.6390 us. Best GFLOPs: 946.3400
2024-04-29 08:41:46 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1298: GFLOPs: 789.6777. Time: 292.9822 us. Best GFLOPs: 946.3400
2024-04-29 08:41:46 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1299: GFLOPs: 668.0142. Time: 346.3423 us. Best GFLOPs: 946.3400
2024-04-29 08:41:46 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1300: GFLOPs: 792.0688. Time: 292.0978 us. Best GFLOPs: 946.3400
2024-04-29 08:41:46 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1301: GFLOPs: 81.1652. Time: 2850.5032 us. Best GFLOPs: 946.3400
2024-04-29 08:41:46 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1302: GFLOPs: 538.7248. Time: 429.4614 us. Best GFLOPs: 946.3400
2024-04-29 08:41:46 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1303: GFLOPs: 840.3580. Time: 275.3131 us. Best GFLOPs: 946.3400
2024-04-29 08:41:46 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1304: GFLOPs: 81.4465. Time: 2840.6578 us. Best GFLOPs: 946.3400
2024-04-29 08:41:46 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1305: GFLOPs: 70.2680. Time: 3292.5572 us. Best GFLOPs: 946.3400
2024-04-29 08:41:46 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1306: GFLOPs: 591.2150. Time: 391.3323 us. Best GFLOPs: 946.3400
2024-04-29 08:41:46 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1307: GFLOPs: 764.8935. Time: 302.4755 us. Best GFLOPs: 946.3400
2024-04-29 08:41:46 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1308: GFLOPs: 806.0399. Time: 287.0348 us. Best GFLOPs: 946.3400
2024-04-29 08:41:46 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1309: GFLOPs: 819.6918. Time: 282.2543 us. Best GFLOPs: 946.3400
2024-04-29 08:41:46 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1310: GFLOPs: 604.5607. Time: 382.6937 us. Best GFLOPs: 946.3400
2024-04-29 08:41:46 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1311: GFLOPs: 68.4219. Time: 3381.3983 us. Best GFLOPs: 946.3400
2024-04-29 08:41:46 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1312: GFLOPs: 68.4432. Time: 3380.3432 us. Best GFLOPs: 946.3400
2024-04-29 08:41:46 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1313: GFLOPs: 645.4446. Time: 358.4530 us. Best GFLOPs: 946.3400
2024-04-29 08:41:46 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1314: GFLOPs: 540.7092. Time: 427.8853 us. Best GFLOPs: 946.3400
2024-04-29 08:41:46 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1315: GFLOPs: 542.8772. Time: 426.1766 us. Best GFLOPs: 946.3400
2024-04-29 08:41:46 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1316: GFLOPs: 872.4723. Time: 265.1792 us. Best GFLOPs: 946.3400
2024-04-29 08:41:46 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1317: GFLOPs: 542.9470. Time: 426.1218 us. Best GFLOPs: 946.3400
2024-04-29 08:41:46 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1318: GFLOPs: 797.3403. Time: 290.1666 us. Best GFLOPs: 946.3400
2024-04-29 08:41:46 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1319: GFLOPs: 743.7426. Time: 311.0774 us. Best GFLOPs: 946.3400
2024-04-29 08:41:46 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1320: GFLOPs: 69.3223. Time: 3337.4778 us. Best GFLOPs: 946.3400
2024-04-29 08:41:46 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1321: GFLOPs: 82.0955. Time: 2818.1991 us. Best GFLOPs: 946.3400
2024-04-29 08:41:46 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1322: GFLOPs: 783.5372. Time: 295.2783 us. Best GFLOPs: 946.3400
2024-04-29 08:41:46 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1323: GFLOPs: 747.1755. Time: 309.6482 us. Best GFLOPs: 946.3400
2024-04-29 08:41:46 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1324: GFLOPs: 730.3694. Time: 316.7733 us. Best GFLOPs: 946.3400
2024-04-29 08:41:46 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1325: GFLOPs: 784.6580. Time: 294.8565 us. Best GFLOPs: 946.3400
2024-04-29 08:41:46 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1326: GFLOPs: 777.5204. Time: 297.5633 us. Best GFLOPs: 946.3400
2024-04-29 08:41:46 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1327: GFLOPs: 750.0844. Time: 308.4473 us. Best GFLOPs: 946.3400
2024-04-29 08:41:46 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1328: GFLOPs: 520.0488. Time: 444.8842 us. Best GFLOPs: 946.3400
2024-04-29 08:41:46 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1329: GFLOPs: 76.8931. Time: 3008.8710 us. Best GFLOPs: 946.3400
2024-04-29 08:41:46 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1330: GFLOPs: 857.3912. Time: 269.8436 us. Best GFLOPs: 946.3400
2024-04-29 08:41:46 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1331: GFLOPs: 684.4432. Time: 338.0288 us. Best GFLOPs: 946.3400
2024-04-29 08:41:46 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1332: GFLOPs: 505.2261. Time: 457.9367 us. Best GFLOPs: 946.3400
2024-04-29 08:41:46 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1333: GFLOPs: 701.9959. Time: 329.5768 us. Best GFLOPs: 946.3400
2024-04-29 08:41:46 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1334: GFLOPs: 700.0213. Time: 330.5064 us. Best GFLOPs: 946.3400
2024-04-29 08:41:46 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1335: GFLOPs: 782.2219. Time: 295.7748 us. Best GFLOPs: 946.3400
2024-04-29 08:41:46 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1336: GFLOPs: 660.5257. Time: 350.2688 us. Best GFLOPs: 946.3400
2024-04-29 08:41:46 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1337: GFLOPs: 687.5045. Time: 336.5237 us. Best GFLOPs: 946.3400
2024-04-29 08:41:46 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1338: GFLOPs: 792.6533. Time: 291.8824 us. Best GFLOPs: 946.3400
2024-04-29 08:41:46 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1339: GFLOPs: 524.6399. Time: 440.9911 us. Best GFLOPs: 946.3400
2024-04-29 08:41:46 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1340: GFLOPs: 607.2452. Time: 381.0018 us. Best GFLOPs: 946.3400
2024-04-29 08:41:46 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1341: GFLOPs: 659.7828. Time: 350.6632 us. Best GFLOPs: 946.3400
2024-04-29 08:41:46 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1342: GFLOPs: 49.4977. Time: 4674.1887 us. Best GFLOPs: 946.3400
2024-04-29 08:41:46 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1343: GFLOPs: 110.7168. Time: 2089.6688 us. Best GFLOPs: 946.3400
2024-04-29 08:41:46 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1344: GFLOPs: 13.4710. Time: 17174.7575 us. Best GFLOPs: 946.3400
2024-04-29 08:51:25 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 08:51:26 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-29 08:51:30 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3639cb8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x419b828)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x312c9f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x425e1d8)]: 0 failure(s)
2024-04-29 08:51:30 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-29 08:51:44 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3639cb8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x419b828)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x312c9f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x425e1d8)]: 0 failure(s)
2024-04-29 08:51:58 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3639cb8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x419b828)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x312c9f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x425e1d8)]: 0 failure(s)
2024-04-29 08:52:12 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3639cb8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x419b828)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x312c9f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x425e1d8)]: 0 failure(s)
2024-04-29 08:52:27 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3639cb8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x419b828)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x312c9f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x425e1d8)]: 0 failure(s)
2024-04-29 08:52:35 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9881  0.9096  0.8793  0.8679  0.8679  0.8679  0.8671  0.8646  0.8645  0.8618  0.8565  0.8382  0.8358  0.8352  0.8352  0.8330
[17 : 32]:	0.8295  0.8277  0.8277  0.8274  0.8213  0.8199  0.8199  0.8198  0.8132  0.8112  0.8111  0.8075  0.8075  0.8045  0.8024  0.8008
[33 : 48]:	0.7991  0.7966  0.7962  0.7945  0.7940  0.7895  0.7881  0.7850  0.7843  0.7836  0.7715  0.7715  0.7690  0.7655  0.7626  0.7604
[49 : 64]:	0.7532  0.7517  0.7493  0.7431  0.7306  0.7278  0.7269  0.7269  0.7265  0.7235  0.7235  0.7234  0.7219  0.7219  0.7212  0.7210
2024-04-29 08:52:36 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 08:52:36 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 08:54:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1345: GFLOPs: 921.4174. Time: 251.0931 us. Best GFLOPs: 946.3400
2024-04-29 08:54:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1346: GFLOPs: 868.3332. Time: 266.4433 us. Best GFLOPs: 946.3400
2024-04-29 08:54:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1347: GFLOPs: 836.7735. Time: 276.4924 us. Best GFLOPs: 946.3400
2024-04-29 08:54:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1348: GFLOPs: 69.8667. Time: 3311.4698 us. Best GFLOPs: 946.3400
2024-04-29 08:54:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1349: GFLOPs: 68.4488. Time: 3380.0681 us. Best GFLOPs: 946.3400
2024-04-29 08:54:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1350: GFLOPs: 603.0209. Time: 383.6709 us. Best GFLOPs: 946.3400
2024-04-29 08:54:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1351: GFLOPs: 796.8605. Time: 290.3413 us. Best GFLOPs: 946.3400
2024-04-29 08:54:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1352: GFLOPs: 794.8818. Time: 291.0641 us. Best GFLOPs: 946.3400
2024-04-29 08:54:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1353: GFLOPs: 799.3941. Time: 289.4211 us. Best GFLOPs: 946.3400
2024-04-29 08:54:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1354: GFLOPs: 819.0919. Time: 282.4610 us. Best GFLOPs: 946.3400
2024-04-29 08:54:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1355: GFLOPs: 806.8079. Time: 286.7616 us. Best GFLOPs: 946.3400
2024-04-29 08:54:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1356: GFLOPs: 772.1896. Time: 299.6175 us. Best GFLOPs: 946.3400
2024-04-29 08:54:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1357: GFLOPs: 791.5304. Time: 292.2965 us. Best GFLOPs: 946.3400
2024-04-29 08:54:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1358: GFLOPs: 808.9529. Time: 286.0012 us. Best GFLOPs: 946.3400
2024-04-29 08:54:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1359: GFLOPs: 756.6181. Time: 305.7838 us. Best GFLOPs: 946.3400
2024-04-29 08:54:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1360: GFLOPs: 795.3952. Time: 290.8762 us. Best GFLOPs: 946.3400
2024-04-29 08:54:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1361: GFLOPs: 767.2179. Time: 301.5591 us. Best GFLOPs: 946.3400
2024-04-29 08:54:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1362: GFLOPs: 797.9761. Time: 289.9354 us. Best GFLOPs: 946.3400
2024-04-29 08:54:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1363: GFLOPs: 776.4371. Time: 297.9785 us. Best GFLOPs: 946.3400
2024-04-29 08:54:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1364: GFLOPs: 558.5817. Time: 414.1946 us. Best GFLOPs: 946.3400
2024-04-29 08:54:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1365: GFLOPs: 791.0372. Time: 292.4787 us. Best GFLOPs: 946.3400
2024-04-29 08:54:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1366: GFLOPs: 527.8867. Time: 438.2788 us. Best GFLOPs: 946.3400
2024-04-29 08:54:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1367: GFLOPs: 781.2045. Time: 296.1600 us. Best GFLOPs: 946.3400
2024-04-29 08:54:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1368: GFLOPs: 782.4548. Time: 295.6868 us. Best GFLOPs: 946.3400
2024-04-29 08:54:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1369: GFLOPs: 815.4405. Time: 283.7258 us. Best GFLOPs: 946.3400
2024-04-29 08:54:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1370: GFLOPs: 751.8381. Time: 307.7279 us. Best GFLOPs: 946.3400
2024-04-29 08:54:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1371: GFLOPs: 798.8038. Time: 289.6350 us. Best GFLOPs: 946.3400
2024-04-29 08:54:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1372: GFLOPs: 199.3395. Time: 1160.6408 us. Best GFLOPs: 946.3400
2024-04-29 08:54:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1373: GFLOPs: 197.8403. Time: 1169.4358 us. Best GFLOPs: 946.3400
2024-04-29 08:54:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1374: GFLOPs: 761.2302. Time: 303.9311 us. Best GFLOPs: 946.3400
2024-04-29 08:54:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1375: GFLOPs: 724.9270. Time: 319.1515 us. Best GFLOPs: 946.3400
2024-04-29 08:54:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1376: GFLOPs: 730.5733. Time: 316.6849 us. Best GFLOPs: 946.3400
2024-04-29 08:54:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1377: GFLOPs: 729.5633. Time: 317.1233 us. Best GFLOPs: 946.3400
2024-04-29 08:54:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1378: GFLOPs: 694.3404. Time: 333.2105 us. Best GFLOPs: 946.3400
2024-04-29 08:54:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1379: GFLOPs: 777.1328. Time: 297.7117 us. Best GFLOPs: 946.3400
2024-04-29 08:54:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1380: GFLOPs: 752.8838. Time: 307.3005 us. Best GFLOPs: 946.3400
2024-04-29 08:54:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1381: GFLOPs: 163.2183. Time: 1417.4975 us. Best GFLOPs: 946.3400
2024-04-29 08:54:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1382: GFLOPs: 757.1711. Time: 305.5604 us. Best GFLOPs: 946.3400
2024-04-29 08:54:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1383: GFLOPs: 524.6503. Time: 440.9824 us. Best GFLOPs: 946.3400
2024-04-29 08:54:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1384: GFLOPs: 81.7402. Time: 2830.4489 us. Best GFLOPs: 946.3400
2024-04-29 08:54:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1385: GFLOPs: 732.9710. Time: 315.6490 us. Best GFLOPs: 946.3400
2024-04-29 08:54:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1386: GFLOPs: 812.9792. Time: 284.5848 us. Best GFLOPs: 946.3400
2024-04-29 08:54:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1387: GFLOPs: 69.8521. Time: 3312.1618 us. Best GFLOPs: 946.3400
2024-04-29 08:54:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1388: GFLOPs: 601.9853. Time: 384.3309 us. Best GFLOPs: 946.3400
2024-04-29 08:54:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1389: GFLOPs: 705.4820. Time: 327.9482 us. Best GFLOPs: 946.3400
2024-04-29 08:54:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1390: GFLOPs: 816.2404. Time: 283.4478 us. Best GFLOPs: 946.3400
2024-04-29 08:54:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1391: GFLOPs: 741.0143. Time: 312.2228 us. Best GFLOPs: 946.3400
2024-04-29 08:54:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1392: GFLOPs: 725.8143. Time: 318.7613 us. Best GFLOPs: 946.3400
2024-04-29 08:54:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1393: GFLOPs: 776.9134. Time: 297.7958 us. Best GFLOPs: 946.3400
2024-04-29 08:54:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1394: GFLOPs: 647.5643. Time: 357.2796 us. Best GFLOPs: 946.3400
2024-04-29 08:54:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1395: GFLOPs: 776.4848. Time: 297.9602 us. Best GFLOPs: 946.3400
2024-04-29 08:54:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1396: GFLOPs: 753.4259. Time: 307.0794 us. Best GFLOPs: 946.3400
2024-04-29 08:54:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1397: GFLOPs: 714.2208. Time: 323.9356 us. Best GFLOPs: 946.3400
2024-04-29 08:54:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1398: GFLOPs: 557.6625. Time: 414.8773 us. Best GFLOPs: 946.3400
2024-04-29 08:54:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1399: GFLOPs: 556.4814. Time: 415.7579 us. Best GFLOPs: 946.3400
2024-04-29 08:54:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1400: GFLOPs: 546.9544. Time: 422.9997 us. Best GFLOPs: 946.3400
2024-04-29 08:54:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1401: GFLOPs: 167.9675. Time: 1377.4183 us. Best GFLOPs: 946.3400
2024-04-29 08:54:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1402: GFLOPs: 93.8770. Time: 2464.5190 us. Best GFLOPs: 946.3400
2024-04-29 08:54:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1403: GFLOPs: 94.1044. Time: 2458.5622 us. Best GFLOPs: 946.3400
2024-04-29 08:54:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1404: GFLOPs: 707.0490. Time: 327.2214 us. Best GFLOPs: 946.3400
2024-04-29 08:54:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1405: GFLOPs: 112.3769. Time: 2058.8001 us. Best GFLOPs: 946.3400
2024-04-29 08:54:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1406: GFLOPs: 41.5930. Time: 5562.5139 us. Best GFLOPs: 946.3400
2024-04-29 08:54:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1407: GFLOPs: 1.5042. Time: 153810.3513 us. Best GFLOPs: 946.3400
2024-04-29 08:54:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1408: GFLOPs: 18.7444. Time: 12342.9612 us. Best GFLOPs: 946.3400
2024-04-29 09:07:18 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 09:07:19 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-29 09:07:24 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3639cb8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x419b828)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x312c9f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x425e1d8)]: 0 failure(s)
2024-04-29 09:07:24 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-29 09:07:37 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3639cb8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x419b828)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x312c9f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x425e1d8)]: 0 failure(s)
2024-04-29 09:07:51 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3639cb8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x419b828)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x312c9f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x425e1d8)]: 0 failure(s)
2024-04-29 09:08:05 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3639cb8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x419b828)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x312c9f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x425e1d8)]: 0 failure(s)
2024-04-29 09:08:20 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3639cb8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x419b828)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x312c9f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x425e1d8)]: 0 failure(s)
2024-04-29 09:08:29 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9073  0.9062  0.9012  0.8874  0.8805  0.8735  0.8697  0.8671  0.8565  0.8525  0.8408  0.8334  0.8314  0.8290  0.8232  0.8231
[17 : 32]:	0.8206  0.8192  0.8146  0.8100  0.8095  0.8057  0.8011  0.7984  0.7901  0.7884  0.7884  0.7884  0.7884  0.7884  0.7849  0.7789
[33 : 48]:	0.7774  0.7774  0.7774  0.7774  0.7774  0.7774  0.7766  0.7706  0.7699  0.7614  0.7609  0.7609  0.7584  0.7584  0.7570  0.7559
[49 : 64]:	0.7546  0.7509  0.7506  0.7506  0.7499  0.7456  0.7456  0.7449  0.7400  0.7343  0.7227  0.7224  0.7211  0.7206  0.7189  0.7162
2024-04-29 09:08:29 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 09:08:29 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 09:10:18 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1409: GFLOPs: 464.3517. Time: 498.2463 us. Best GFLOPs: 946.3400
2024-04-29 09:10:18 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1410: GFLOPs: 704.3137. Time: 328.4922 us. Best GFLOPs: 946.3400
2024-04-29 09:10:18 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1411: GFLOPs: 863.1851. Time: 268.0324 us. Best GFLOPs: 946.3400
2024-04-29 09:10:18 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1412: GFLOPs: 875.1991. Time: 264.3530 us. Best GFLOPs: 946.3400
2024-04-29 09:10:18 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1413: GFLOPs: 861.6146. Time: 268.5209 us. Best GFLOPs: 946.3400
2024-04-29 09:10:18 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1414: GFLOPs: 814.5885. Time: 284.0226 us. Best GFLOPs: 946.3400
2024-04-29 09:10:18 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1415: GFLOPs: 801.2525. Time: 288.7499 us. Best GFLOPs: 946.3400
2024-04-29 09:10:18 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1416: GFLOPs: 828.7864. Time: 279.1570 us. Best GFLOPs: 946.3400
2024-04-29 09:10:18 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1417: GFLOPs: 812.1640. Time: 284.8705 us. Best GFLOPs: 946.3400
2024-04-29 09:10:18 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1418: GFLOPs: 797.0103. Time: 290.2868 us. Best GFLOPs: 946.3400
2024-04-29 09:10:18 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1419: GFLOPs: 792.2397. Time: 292.0348 us. Best GFLOPs: 946.3400
2024-04-29 09:10:18 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1420: GFLOPs: 774.3252. Time: 298.7912 us. Best GFLOPs: 946.3400
2024-04-29 09:10:18 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1421: GFLOPs: 771.0205. Time: 300.0718 us. Best GFLOPs: 946.3400
2024-04-29 09:10:18 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1422: GFLOPs: 793.7022. Time: 291.4967 us. Best GFLOPs: 946.3400
2024-04-29 09:10:18 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1423: GFLOPs: 754.8711. Time: 306.4914 us. Best GFLOPs: 946.3400
2024-04-29 09:10:18 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1424: GFLOPs: 804.2775. Time: 287.6638 us. Best GFLOPs: 946.3400
2024-04-29 09:10:18 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1425: GFLOPs: 764.5147. Time: 302.6254 us. Best GFLOPs: 946.3400
2024-04-29 09:10:18 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1426: GFLOPs: 750.5144. Time: 308.2706 us. Best GFLOPs: 946.3400
2024-04-29 09:10:18 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1427: GFLOPs: 797.2173. Time: 290.2114 us. Best GFLOPs: 946.3400
2024-04-29 09:10:18 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1428: GFLOPs: 587.4439. Time: 393.8445 us. Best GFLOPs: 946.3400
2024-04-29 09:10:18 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1429: GFLOPs: 751.2634. Time: 307.9633 us. Best GFLOPs: 946.3400
2024-04-29 09:10:18 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1430: GFLOPs: 765.5697. Time: 302.2083 us. Best GFLOPs: 946.3400
2024-04-29 09:10:18 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1431: GFLOPs: 767.8639. Time: 301.3054 us. Best GFLOPs: 946.3400
2024-04-29 09:10:18 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1432: GFLOPs: 748.8619. Time: 308.9509 us. Best GFLOPs: 946.3400
2024-04-29 09:10:18 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1433: GFLOPs: 719.1872. Time: 321.6986 us. Best GFLOPs: 946.3400
2024-04-29 09:10:18 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1434: GFLOPs: 751.9460. Time: 307.6837 us. Best GFLOPs: 946.3400
2024-04-29 09:10:18 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1435: GFLOPs: 661.2363. Time: 349.8923 us. Best GFLOPs: 946.3400
2024-04-29 09:10:18 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1436: GFLOPs: 488.7012. Time: 473.4213 us. Best GFLOPs: 946.3400
2024-04-29 09:10:18 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1437: GFLOPs: 661.6618. Time: 349.6674 us. Best GFLOPs: 946.3400
2024-04-29 09:10:18 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1438: GFLOPs: 752.1519. Time: 307.5995 us. Best GFLOPs: 946.3400
2024-04-29 09:10:18 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1439: GFLOPs: 784.4950. Time: 294.9178 us. Best GFLOPs: 946.3400
2024-04-29 09:10:18 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1440: GFLOPs: 363.0291. Time: 637.3086 us. Best GFLOPs: 946.3400
2024-04-29 09:10:18 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1441: GFLOPs: 544.3932. Time: 424.9897 us. Best GFLOPs: 946.3400
2024-04-29 09:10:18 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1442: GFLOPs: 544.0844. Time: 425.2310 us. Best GFLOPs: 946.3400
2024-04-29 09:10:18 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1443: GFLOPs: 83.8675. Time: 2758.6543 us. Best GFLOPs: 946.3400
2024-04-29 09:10:18 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1444: GFLOPs: 542.7140. Time: 426.3047 us. Best GFLOPs: 946.3400
2024-04-29 09:10:18 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1445: GFLOPs: 82.9423. Time: 2789.4286 us. Best GFLOPs: 946.3400
2024-04-29 09:10:18 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1446: GFLOPs: 852.5278. Time: 271.3830 us. Best GFLOPs: 946.3400
2024-04-29 09:10:18 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1447: GFLOPs: 840.1825. Time: 275.3706 us. Best GFLOPs: 946.3400
2024-04-29 09:10:18 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1448: GFLOPs: 857.9544. Time: 269.6665 us. Best GFLOPs: 946.3400
2024-04-29 09:10:18 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1449: GFLOPs: 844.8615. Time: 273.8455 us. Best GFLOPs: 946.3400
2024-04-29 09:10:18 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1450: GFLOPs: 816.2160. Time: 283.4563 us. Best GFLOPs: 946.3400
2024-04-29 09:10:18 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1451: GFLOPs: 81.7522. Time: 2830.0360 us. Best GFLOPs: 946.3400
2024-04-29 09:10:18 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1452: GFLOPs: 844.6096. Time: 273.9272 us. Best GFLOPs: 946.3400
2024-04-29 09:10:18 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1453: GFLOPs: 540.8161. Time: 427.8007 us. Best GFLOPs: 946.3400
2024-04-29 09:10:18 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1454: GFLOPs: 542.2090. Time: 426.7017 us. Best GFLOPs: 946.3400
2024-04-29 09:10:18 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1455: GFLOPs: 688.7733. Time: 335.9037 us. Best GFLOPs: 946.3400
2024-04-29 09:10:18 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1456: GFLOPs: 841.5512. Time: 274.9227 us. Best GFLOPs: 946.3400
2024-04-29 09:10:18 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1457: GFLOPs: 678.7967. Time: 340.8407 us. Best GFLOPs: 946.3400
2024-04-29 09:10:18 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1458: GFLOPs: 746.7358. Time: 309.8305 us. Best GFLOPs: 946.3400
2024-04-29 09:10:18 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1459: GFLOPs: 773.3911. Time: 299.1520 us. Best GFLOPs: 946.3400
2024-04-29 09:10:18 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1460: GFLOPs: 768.5708. Time: 301.0283 us. Best GFLOPs: 946.3400
2024-04-29 09:10:18 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1461: GFLOPs: 592.0503. Time: 390.7802 us. Best GFLOPs: 946.3400
2024-04-29 09:10:18 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1462: GFLOPs: 582.2479. Time: 397.3592 us. Best GFLOPs: 946.3400
2024-04-29 09:10:18 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1463: GFLOPs: 637.6683. Time: 362.8243 us. Best GFLOPs: 946.3400
2024-04-29 09:10:18 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1464: GFLOPs: 668.0819. Time: 346.3071 us. Best GFLOPs: 946.3400
2024-04-29 09:10:18 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1465: GFLOPs: 673.6900. Time: 343.4243 us. Best GFLOPs: 946.3400
2024-04-29 09:10:18 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1466: GFLOPs: 699.2750. Time: 330.8592 us. Best GFLOPs: 946.3400
2024-04-29 09:10:18 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1467: GFLOPs: 702.4685. Time: 329.3550 us. Best GFLOPs: 946.3400
2024-04-29 09:10:18 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1468: GFLOPs: 709.3237. Time: 326.1720 us. Best GFLOPs: 946.3400
2024-04-29 09:10:18 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1469: GFLOPs: 69.9790. Time: 3306.1557 us. Best GFLOPs: 946.3400
2024-04-29 09:10:18 [INFO] [task_scheduler.cc:121] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1470: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(14), T.int64(14), T.int64(128)), "float32"), p1: T.Buffer((T.int64(16), T.int64(2), T.int64(3), T.int64(3), T.int64(128), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(16)), "float32"), p3: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(16), T.int64(16), T.int64(128)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_fused_fused in T.parallel(T.int64(7), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(2), T.int64(16), T.int64(4), T.int64(128)):
                with T.block("data_pad"):
                    v_i0, v_i1, v_i2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                    v_i3 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_fused_fused * T.int64(2) + ax3)
                    v_i4 = T.axis.spatial(T.int64(128), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(15) and T.int64(1) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oc_block_0 in range(T.int64(2)):
                for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(2)):
                    for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(4), T.int64(14), T.int64(1)):
                        for oc_block_3_fused_init in T.vectorized(T.int64(2)):
                            with T.block("conv2d_NCHWc_init"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                                v_oc_chunk = T.axis.spatial(T.int64(16), oc_chunk_1 * T.int64(16) + oc_chunk_2_init * T.int64(4) + oc_chunk_3_init)
                                v_oh = T.axis.spatial(T.int64(14), oh_1 * T.int64(14) + oh_2_init * T.int64(14) + oh_3_init)
                                v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_fused_fused * T.int64(2) + ow_1 + ow_2_init + ow_3_init)
                                v_oc_block = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(8) + oc_block_1 * T.int64(4) + oc_block_2_init * T.int64(2) + oc_block_3_fused_init)
                                T.reads()
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                    for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(16), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(2), T.int64(16), T.int64(3), T.int64(3), T.int64(1), T.int64(4), T.int64(14), T.int64(1)):
                        for oc_block_3_fused in T.vectorized(T.int64(2)):
                            with T.block("conv2d_NCHWc_update"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                                v_oc_chunk = T.axis.spatial(T.int64(16), oc_chunk_1 * T.int64(16) + oc_chunk_2 * T.int64(4) + oc_chunk_3)
                                v_oh = T.axis.spatial(T.int64(14), oh_1 * T.int64(14) + oh_2 * T.int64(14) + oh_3)
                                v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_fused_fused * T.int64(2) + ow_1 + ow_2 + ow_3)
                                v_oc_block = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(8) + oc_block_1 * T.int64(4) + oc_block_2 * T.int64(2) + oc_block_3_fused)
                                v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(16) + ic_1)
                                v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                                v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                                T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(16), T.int64(14), T.int64(2)):
                    for ax4_fused in T.vectorized(T.int64(8)):
                        with T.block("T_relu"):
                            v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                            v_ax3 = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_fused_fused * T.int64(2) + ax3)
                            v_ax4 = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(8) + ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 4, 4])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 1, 14])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[7, 2, 1, 1])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[2, 2, 2, 2])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[16, 16])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[1, 3])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=3)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79, l80 = sch.get_loops(block=b69)
l81 = sch.fuse(l72, l73, l74, l75, preserve_unit_iters=True)
sch.parallel(loop=l81)
l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b70)
l105 = sch.fuse(l82, preserve_unit_iters=True)
sch.parallel(loop=l105)
l106 = sch.fuse(l104, preserve_unit_iters=True)
sch.vectorize(loop=l106)
sch.annotate(block_or_loop=l105, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l105, ann_key="pragma_unroll_explicit", ann_val=1)
l107, l108, l109, l110, l111, l112, l113 = sch.get_loops(block=b71)
l114 = sch.fuse(l113, preserve_unit_iters=True)
sch.vectorize(loop=l114)
b115 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138 = sch.get_loops(block=b115)
b139 = sch.decompose_reduction(block=b115, loop=l123)
2024-04-29 09:10:18 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1471: GFLOPs: 14.8374. Time: 15593.1065 us. Best GFLOPs: 946.3400
2024-04-29 09:10:18 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1472: GFLOPs: 24.5031. Time: 9442.1420 us. Best GFLOPs: 946.3400
2024-04-29 09:26:22 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 09:26:23 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-29 09:26:28 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3639cb8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x419b828)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x312c9f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x425e1d8)]: 0 failure(s)
2024-04-29 09:26:28 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-29 09:26:41 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3639cb8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x419b828)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x312c9f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x425e1d8)]: 0 failure(s)
2024-04-29 09:26:55 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3639cb8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x419b828)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x312c9f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x425e1d8)]: 0 failure(s)
2024-04-29 09:27:09 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3639cb8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x419b828)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x312c9f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x425e1d8)]: 0 failure(s)
2024-04-29 09:27:24 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3639cb8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x419b828)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x312c9f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x425e1d8)]: 0 failure(s)
2024-04-29 09:27:33 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9214  0.9145  0.9112  0.8809  0.8750  0.8750  0.8716  0.8618  0.8512  0.8512  0.8491  0.8395  0.8342  0.8342  0.8232  0.8201
[17 : 32]:	0.8178  0.8126  0.8113  0.8042  0.7997  0.7975  0.7907  0.7883  0.7883  0.7815  0.7815  0.7716  0.7716  0.7707  0.7666  0.7591
[33 : 48]:	0.7586  0.7586  0.7586  0.7565  0.7519  0.7504  0.7433  0.7385  0.7337  0.7324  0.7319  0.7256  0.7229  0.7223  0.7219  0.7203
[49 : 64]:	0.7203  0.7203  0.7150  0.7147  0.7133  0.7133  0.7130  0.7114  0.7111  0.7099  0.7093  0.7075  0.7075  0.7075  0.7062  0.7059
2024-04-29 09:27:33 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 09:27:33 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 09:29:09 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1473: GFLOPs: 428.2983. Time: 540.1879 us. Best GFLOPs: 946.3400
2024-04-29 09:29:09 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1474: GFLOPs: 433.5045. Time: 533.7004 us. Best GFLOPs: 946.3400
2024-04-29 09:29:09 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1475: GFLOPs: 495.4406. Time: 466.9814 us. Best GFLOPs: 946.3400
2024-04-29 09:29:09 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1476: GFLOPs: 438.3628. Time: 527.7855 us. Best GFLOPs: 946.3400
2024-04-29 09:29:09 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1477: GFLOPs: 451.6887. Time: 512.2146 us. Best GFLOPs: 946.3400
2024-04-29 09:29:09 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1478: GFLOPs: 403.8077. Time: 572.9497 us. Best GFLOPs: 946.3400
2024-04-29 09:29:09 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1479: GFLOPs: 885.5119. Time: 261.2743 us. Best GFLOPs: 946.3400
2024-04-29 09:29:09 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1480: GFLOPs: 829.8192. Time: 278.8096 us. Best GFLOPs: 946.3400
2024-04-29 09:29:09 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1481: GFLOPs: 874.3852. Time: 264.5991 us. Best GFLOPs: 946.3400
2024-04-29 09:29:09 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1482: GFLOPs: 833.0246. Time: 277.7367 us. Best GFLOPs: 946.3400
2024-04-29 09:29:09 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1483: GFLOPs: 817.7210. Time: 282.9346 us. Best GFLOPs: 946.3400
2024-04-29 09:29:09 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1484: GFLOPs: 817.9864. Time: 282.8428 us. Best GFLOPs: 946.3400
2024-04-29 09:29:09 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1485: GFLOPs: 936.6784. Time: 247.0021 us. Best GFLOPs: 946.3400
2024-04-29 09:29:09 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1486: GFLOPs: 645.9765. Time: 358.1578 us. Best GFLOPs: 946.3400
2024-04-29 09:29:09 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1487: GFLOPs: 845.4669. Time: 273.6494 us. Best GFLOPs: 946.3400
2024-04-29 09:29:09 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1488: GFLOPs: 870.6018. Time: 265.7490 us. Best GFLOPs: 946.3400
2024-04-29 09:29:09 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1489: GFLOPs: 831.3405. Time: 278.2994 us. Best GFLOPs: 946.3400
2024-04-29 09:29:09 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1490: GFLOPs: 802.1087. Time: 288.4416 us. Best GFLOPs: 946.3400
2024-04-29 09:29:09 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1491: GFLOPs: 700.0766. Time: 330.4803 us. Best GFLOPs: 946.3400
2024-04-29 09:29:09 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1492: GFLOPs: 623.8574. Time: 370.8565 us. Best GFLOPs: 946.3400
2024-04-29 09:29:09 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1493: GFLOPs: 788.5564. Time: 293.3988 us. Best GFLOPs: 946.3400
2024-04-29 09:29:09 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1494: GFLOPs: 814.1854. Time: 284.1632 us. Best GFLOPs: 946.3400
2024-04-29 09:29:09 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1495: GFLOPs: 564.5609. Time: 409.8079 us. Best GFLOPs: 946.3400
2024-04-29 09:29:09 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1496: GFLOPs: 69.6437. Time: 3322.0757 us. Best GFLOPs: 946.3400
2024-04-29 09:29:09 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1497: GFLOPs: 824.6598. Time: 280.5539 us. Best GFLOPs: 946.3400
2024-04-29 09:29:09 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1498: GFLOPs: 545.0949. Time: 424.4427 us. Best GFLOPs: 946.3400
2024-04-29 09:29:09 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1499: GFLOPs: 697.0766. Time: 331.9026 us. Best GFLOPs: 946.3400
2024-04-29 09:29:09 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1500: GFLOPs: 706.5281. Time: 327.4626 us. Best GFLOPs: 946.3400
2024-04-29 09:29:09 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1501: GFLOPs: 545.2832. Time: 424.2961 us. Best GFLOPs: 946.3400
2024-04-29 09:29:09 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1502: GFLOPs: 705.3465. Time: 328.0112 us. Best GFLOPs: 946.3400
2024-04-29 09:29:09 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1503: GFLOPs: 383.1433. Time: 603.8512 us. Best GFLOPs: 946.3400
2024-04-29 09:29:09 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1504: GFLOPs: 732.9038. Time: 315.6779 us. Best GFLOPs: 946.3400
2024-04-29 09:29:09 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1505: GFLOPs: 607.0563. Time: 381.1204 us. Best GFLOPs: 946.3400
2024-04-29 09:29:09 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1506: GFLOPs: 334.1260. Time: 692.4380 us. Best GFLOPs: 946.3400
2024-04-29 09:29:09 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1507: GFLOPs: 607.8272. Time: 380.6370 us. Best GFLOPs: 946.3400
2024-04-29 09:29:09 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1508: GFLOPs: 795.9423. Time: 290.6763 us. Best GFLOPs: 946.3400
2024-04-29 09:29:09 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1509: GFLOPs: 697.1103. Time: 331.8866 us. Best GFLOPs: 946.3400
2024-04-29 09:29:09 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1510: GFLOPs: 814.8654. Time: 283.9261 us. Best GFLOPs: 946.3400
2024-04-29 09:29:09 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1511: GFLOPs: 695.0884. Time: 332.8520 us. Best GFLOPs: 946.3400
2024-04-29 09:29:09 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1512: GFLOPs: 566.5985. Time: 408.3342 us. Best GFLOPs: 946.3400
2024-04-29 09:29:09 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1513: GFLOPs: 695.6200. Time: 332.5976 us. Best GFLOPs: 946.3400
2024-04-29 09:29:09 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1514: GFLOPs: 162.8461. Time: 1420.7371 us. Best GFLOPs: 946.3400
2024-04-29 09:29:09 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1515: GFLOPs: 680.6892. Time: 339.8931 us. Best GFLOPs: 946.3400
2024-04-29 09:29:09 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1516: GFLOPs: 667.3782. Time: 346.6723 us. Best GFLOPs: 946.3400
2024-04-29 09:29:09 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1517: GFLOPs: 809.9499. Time: 285.6492 us. Best GFLOPs: 946.3400
2024-04-29 09:29:09 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1518: GFLOPs: 577.0143. Time: 400.9632 us. Best GFLOPs: 946.3400
2024-04-29 09:29:09 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1519: GFLOPs: 297.7826. Time: 776.9477 us. Best GFLOPs: 946.3400
2024-04-29 09:29:09 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1520: GFLOPs: 579.1230. Time: 399.5033 us. Best GFLOPs: 946.3400
2024-04-29 09:29:09 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1521: GFLOPs: 616.3442. Time: 375.3771 us. Best GFLOPs: 946.3400
2024-04-29 09:29:09 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1522: GFLOPs: 781.4194. Time: 296.0785 us. Best GFLOPs: 946.3400
2024-04-29 09:29:09 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1523: GFLOPs: 673.6261. Time: 343.4569 us. Best GFLOPs: 946.3400
2024-04-29 09:29:09 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1524: GFLOPs: 665.2528. Time: 347.7799 us. Best GFLOPs: 946.3400
2024-04-29 09:29:09 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1525: GFLOPs: 808.5849. Time: 286.1314 us. Best GFLOPs: 946.3400
2024-04-29 09:29:09 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1526: GFLOPs: 802.5390. Time: 288.2870 us. Best GFLOPs: 946.3400
2024-04-29 09:29:09 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1527: GFLOPs: 774.5674. Time: 298.6978 us. Best GFLOPs: 946.3400
2024-04-29 09:29:09 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1528: GFLOPs: 680.6421. Time: 339.9166 us. Best GFLOPs: 946.3400
2024-04-29 09:29:09 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1529: GFLOPs: 665.7431. Time: 347.5238 us. Best GFLOPs: 946.3400
2024-04-29 09:29:09 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1530: GFLOPs: 69.3091. Time: 3338.1140 us. Best GFLOPs: 946.3400
2024-04-29 09:29:09 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1531: GFLOPs: 659.4566. Time: 350.8367 us. Best GFLOPs: 946.3400
2024-04-29 09:29:09 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1532: GFLOPs: 789.5563. Time: 293.0273 us. Best GFLOPs: 946.3400
2024-04-29 09:29:09 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1533: GFLOPs: 791.5100. Time: 292.3040 us. Best GFLOPs: 946.3400
2024-04-29 09:29:09 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1534: GFLOPs: 46.2064. Time: 5007.1356 us. Best GFLOPs: 946.3400
2024-04-29 09:29:09 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1535: GFLOPs: 6.9185. Time: 33440.9847 us. Best GFLOPs: 946.3400
2024-04-29 09:29:09 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1536: GFLOPs: 30.1231. Time: 7680.5393 us. Best GFLOPs: 946.3400
2024-04-29 09:42:36 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 09:42:37 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-29 09:42:42 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3639cb8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x419b828)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x312c9f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x425e1d8)]: 0 failure(s)
2024-04-29 09:42:42 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-29 09:42:55 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3639cb8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x419b828)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x312c9f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x425e1d8)]: 0 failure(s)
2024-04-29 09:43:09 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3639cb8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x419b828)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x312c9f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x425e1d8)]: 0 failure(s)
2024-04-29 09:43:23 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3639cb8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x419b828)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x312c9f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x425e1d8)]: 0 failure(s)
2024-04-29 09:43:38 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3639cb8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x419b828)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x312c9f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x425e1d8)]: 0 failure(s)
2024-04-29 09:43:47 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.8792  0.8702  0.8634  0.8593  0.8450  0.8450  0.8419  0.8372  0.8351  0.8127  0.7953  0.7919  0.7882  0.7831  0.7792  0.7751
[17 : 32]:	0.7647  0.7609  0.7596  0.7585  0.7524  0.7449  0.7410  0.7407  0.7374  0.7374  0.7325  0.7277  0.7140  0.7112  0.7093  0.7049
[33 : 48]:	0.7049  0.7029  0.6999  0.6993  0.6970  0.6902  0.6891  0.6871  0.6867  0.6860  0.6860  0.6848  0.6840  0.6740  0.6740  0.6740
[49 : 64]:	0.6731  0.6661  0.6647  0.6646  0.6636  0.6589  0.6559  0.6525  0.6505  0.6502  0.6497  0.6494  0.6469  0.6460  0.6460  0.6448
2024-04-29 09:43:47 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 09:43:47 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 09:45:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1537: GFLOPs: 869.5351. Time: 266.0750 us. Best GFLOPs: 946.3400
2024-04-29 09:45:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1538: GFLOPs: 842.8401. Time: 274.5023 us. Best GFLOPs: 946.3400
2024-04-29 09:45:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1539: GFLOPs: 836.4155. Time: 276.6108 us. Best GFLOPs: 946.3400
2024-04-29 09:45:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1540: GFLOPs: 844.4337. Time: 273.9842 us. Best GFLOPs: 946.3400
2024-04-29 09:45:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1541: GFLOPs: 827.2865. Time: 279.6631 us. Best GFLOPs: 946.3400
2024-04-29 09:45:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1542: GFLOPs: 827.3936. Time: 279.6269 us. Best GFLOPs: 946.3400
2024-04-29 09:45:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1543: GFLOPs: 835.5642. Time: 276.8926 us. Best GFLOPs: 946.3400
2024-04-29 09:45:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1544: GFLOPs: 813.2096. Time: 284.5042 us. Best GFLOPs: 946.3400
2024-04-29 09:45:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1545: GFLOPs: 791.2817. Time: 292.3883 us. Best GFLOPs: 946.3400
2024-04-29 09:45:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1546: GFLOPs: 785.1253. Time: 294.6810 us. Best GFLOPs: 946.3400
2024-04-29 09:45:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1547: GFLOPs: 760.6583. Time: 304.1596 us. Best GFLOPs: 946.3400
2024-04-29 09:45:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1548: GFLOPs: 614.5216. Time: 376.4905 us. Best GFLOPs: 946.3400
2024-04-29 09:45:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1549: GFLOPs: 841.2312. Time: 275.0273 us. Best GFLOPs: 946.3400
2024-04-29 09:45:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1550: GFLOPs: 766.6920. Time: 301.7659 us. Best GFLOPs: 946.3400
2024-04-29 09:45:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1551: GFLOPs: 614.5556. Time: 376.4697 us. Best GFLOPs: 946.3400
2024-04-29 09:45:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1552: GFLOPs: 777.6686. Time: 297.5066 us. Best GFLOPs: 946.3400
2024-04-29 09:45:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1553: GFLOPs: 727.7179. Time: 317.9275 us. Best GFLOPs: 946.3400
2024-04-29 09:45:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1554: GFLOPs: 878.1658. Time: 263.4600 us. Best GFLOPs: 946.3400
2024-04-29 09:45:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1555: GFLOPs: 746.6725. Time: 309.8568 us. Best GFLOPs: 946.3400
2024-04-29 09:45:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1556: GFLOPs: 644.4350. Time: 359.0146 us. Best GFLOPs: 946.3400
2024-04-29 09:45:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1557: GFLOPs: 644.0418. Time: 359.2337 us. Best GFLOPs: 946.3400
2024-04-29 09:45:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1558: GFLOPs: 807.4845. Time: 286.5213 us. Best GFLOPs: 946.3400
2024-04-29 09:45:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1559: GFLOPs: 749.5718. Time: 308.6583 us. Best GFLOPs: 946.3400
2024-04-29 09:45:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1560: GFLOPs: 630.9049. Time: 366.7138 us. Best GFLOPs: 946.3400
2024-04-29 09:45:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1561: GFLOPs: 764.5691. Time: 302.6038 us. Best GFLOPs: 946.3400
2024-04-29 09:45:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1562: GFLOPs: 562.0627. Time: 411.6294 us. Best GFLOPs: 946.3400
2024-04-29 09:45:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1563: GFLOPs: 717.9081. Time: 322.2718 us. Best GFLOPs: 946.3400
2024-04-29 09:45:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1564: GFLOPs: 694.4577. Time: 333.1542 us. Best GFLOPs: 946.3400
2024-04-29 09:45:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1565: GFLOPs: 156.9015. Time: 1474.5656 us. Best GFLOPs: 946.3400
2024-04-29 09:45:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1566: GFLOPs: 661.6642. Time: 349.6661 us. Best GFLOPs: 946.3400
2024-04-29 09:45:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1567: GFLOPs: 884.7882. Time: 261.4880 us. Best GFLOPs: 946.3400
2024-04-29 09:45:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1568: GFLOPs: 378.4473. Time: 611.3441 us. Best GFLOPs: 946.3400
2024-04-29 09:45:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1569: GFLOPs: 8.4444. Time: 27398.1065 us. Best GFLOPs: 946.3400
2024-04-29 09:45:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1570: GFLOPs: 649.1554. Time: 356.4039 us. Best GFLOPs: 946.3400
2024-04-29 09:45:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1571: GFLOPs: 565.3309. Time: 409.2497 us. Best GFLOPs: 946.3400
2024-04-29 09:45:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1572: GFLOPs: 810.9824. Time: 285.2855 us. Best GFLOPs: 946.3400
2024-04-29 09:45:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1573: GFLOPs: 715.0627. Time: 323.5542 us. Best GFLOPs: 946.3400
2024-04-29 09:45:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1574: GFLOPs: 582.5220. Time: 397.1722 us. Best GFLOPs: 946.3400
2024-04-29 09:45:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1575: GFLOPs: 649.1174. Time: 356.4248 us. Best GFLOPs: 946.3400
2024-04-29 09:45:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1576: GFLOPs: 590.2940. Time: 391.9429 us. Best GFLOPs: 946.3400
2024-04-29 09:45:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1577: GFLOPs: 661.1715. Time: 349.9266 us. Best GFLOPs: 946.3400
2024-04-29 09:45:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1578: GFLOPs: 468.0210. Time: 494.3401 us. Best GFLOPs: 946.3400
2024-04-29 09:45:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1579: GFLOPs: 464.7041. Time: 497.8685 us. Best GFLOPs: 946.3400
2024-04-29 09:45:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1580: GFLOPs: 705.0106. Time: 328.1675 us. Best GFLOPs: 946.3400
2024-04-29 09:45:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1581: GFLOPs: 649.5007. Time: 356.2144 us. Best GFLOPs: 946.3400
2024-04-29 09:45:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1582: GFLOPs: 50.1386. Time: 4614.4364 us. Best GFLOPs: 946.3400
2024-04-29 09:45:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1583: GFLOPs: 152.3520. Time: 1518.5986 us. Best GFLOPs: 946.3400
2024-04-29 09:45:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1584: GFLOPs: 156.8706. Time: 1474.8562 us. Best GFLOPs: 946.3400
2024-04-29 09:45:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1585: GFLOPs: 617.3049. Time: 374.7929 us. Best GFLOPs: 946.3400
2024-04-29 09:45:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1586: GFLOPs: 64.7180. Time: 3574.9197 us. Best GFLOPs: 946.3400
2024-04-29 09:45:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1587: GFLOPs: 508.2009. Time: 455.2561 us. Best GFLOPs: 946.3400
2024-04-29 09:45:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1588: GFLOPs: 662.8236. Time: 349.0545 us. Best GFLOPs: 946.3400
2024-04-29 09:45:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1589: GFLOPs: 531.6967. Time: 435.1382 us. Best GFLOPs: 946.3400
2024-04-29 09:45:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1590: GFLOPs: 540.9269. Time: 427.7131 us. Best GFLOPs: 946.3400
2024-04-29 09:45:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1591: GFLOPs: 623.7473. Time: 370.9219 us. Best GFLOPs: 946.3400
2024-04-29 09:45:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1592: GFLOPs: 144.4731. Time: 1601.4156 us. Best GFLOPs: 946.3400
2024-04-29 09:45:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1593: GFLOPs: 36.7335. Time: 6298.3852 us. Best GFLOPs: 946.3400
2024-04-29 09:45:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1594: GFLOPs: 525.1737. Time: 440.5429 us. Best GFLOPs: 946.3400
2024-04-29 09:45:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1595: GFLOPs: 587.2999. Time: 393.9410 us. Best GFLOPs: 946.3400
2024-04-29 09:45:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1596: GFLOPs: 684.3699. Time: 338.0651 us. Best GFLOPs: 946.3400
2024-04-29 09:45:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1597: GFLOPs: 634.3020. Time: 364.7498 us. Best GFLOPs: 946.3400
2024-04-29 09:45:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1598: GFLOPs: 30.7070. Time: 7534.4917 us. Best GFLOPs: 946.3400
2024-04-29 09:45:36 [INFO] [task_scheduler.cc:121] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1599: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(14), T.int64(14), T.int64(128)), "float32"), p1: T.Buffer((T.int64(16), T.int64(2), T.int64(3), T.int64(3), T.int64(128), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(16)), "float32"), p3: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(16), T.int64(16), T.int64(128)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused in T.parallel(T.int64(14), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(16), T.int64(7), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(2)):
                for oc_block_3_fused_init in T.vectorized(T.int64(8)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(16), oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(14), oh_2_init * T.int64(2) + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(2) * T.int64(2) + ow_2_init * T.int64(2) + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(2) * T.int64(8) + oc_block_2_init * T.int64(8) + oc_block_3_fused_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
            for ic_0 in range(T.int64(8)):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(16), T.int64(4)):
                    for ax4_fused in T.vectorized(T.int64(32)):
                        with T.block("data_pad"):
                            v_i0 = T.axis.spatial(T.int64(1), ax0)
                            v_i1 = T.axis.spatial(T.int64(2), ic_0 // T.int64(4) + ax1)
                            v_i2 = T.axis.spatial(T.int64(16), ax2)
                            v_i3 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(2) * T.int64(2) + ax3)
                            v_i4 = T.axis.spatial(T.int64(128), ic_0 % T.int64(4) * T.int64(32) + ax4_fused)
                            T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                            T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                            data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(15) and T.int64(1) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                for kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(3), T.int64(1), T.int64(1), T.int64(16), T.int64(7), T.int64(1), T.int64(1), T.int64(32), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(2), T.int64(2)):
                    for oc_block_3_fused in T.vectorized(T.int64(8)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(16), oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(14), oh_2 * T.int64(2) + oh_3)
                            v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(2) * T.int64(2) + ow_2 * T.int64(2) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(2) * T.int64(8) + oc_block_2 * T.int64(8) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(32) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
        for ax0_ax1_ax2_ax3_ax4_fused_0 in T.parallel(T.int64(784)):
            for ax0_ax1_ax2_ax3_ax4_fused_1 in T.vectorized(T.int64(64)):
                with T.block("T_relu"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) // T.int64(3136))
                    v_ax2 = T.axis.spatial(T.int64(14), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(3136) // T.int64(224))
                    v_ax3 = T.axis.spatial(T.int64(14), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(224) // T.int64(16))
                    v_ax4 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(16))
                    T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 16, 1])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 7, 2])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 7, 1, 2])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[1, 2, 1, 8])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[8, 32])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[1, 3])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=10)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86 = sch.get_loops(block=b68)
l87 = sch.fuse(l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, preserve_unit_iters=True)
sch.parallel(loop=l87)
l88 = sch.fuse(l86, preserve_unit_iters=True)
sch.vectorize(loop=l88)
l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105 = sch.get_loops(block=b69)
l106 = sch.fuse(l89, preserve_unit_iters=True)
sch.parallel(loop=l106)
l107 = sch.fuse(l105, preserve_unit_iters=True)
sch.vectorize(loop=l107)
sch.annotate(block_or_loop=l106, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l106, ann_key="pragma_unroll_explicit", ann_val=1)
l108, l109, l110, l111, l112 = sch.get_loops(block=b70)
l113 = sch.fuse(l108, l109, l110, l111, l112, preserve_unit_iters=True)
l114, l115 = sch.split(loop=l113, factors=[None, 64], preserve_unit_iters=True)
sch.parallel(loop=l114)
sch.vectorize(loop=l115)
b116 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133 = sch.get_loops(block=b116)
b134 = sch.decompose_reduction(block=b116, loop=l118)
2024-04-29 09:45:36 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1600: GFLOPs: 16.6110. Time: 13928.1760 us. Best GFLOPs: 946.3400
2024-04-29 09:53:54 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 09:53:56 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-29 09:54:00 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3639cb8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x419b828)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x312c9f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x425e1d8)]: 0 failure(s)
2024-04-29 09:54:00 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-29 09:54:13 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3639cb8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x419b828)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x312c9f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x425e1d8)]: 0 failure(s)
2024-04-29 09:54:27 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3639cb8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x419b828)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x312c9f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x425e1d8)]: 0 failure(s)
2024-04-29 09:54:42 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3639cb8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x419b828)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x312c9f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x425e1d8)]: 0 failure(s)
2024-04-29 09:54:57 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3639cb8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x419b828)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x312c9f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x425e1d8)]: 0 failure(s)
2024-04-29 09:55:06 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.8825  0.8780  0.8737  0.8552  0.8524  0.8524  0.8496  0.8457  0.8379  0.8377  0.8309  0.8235  0.8184  0.8160  0.8093  0.8085
[17 : 32]:	0.7997  0.7984  0.7917  0.7917  0.7834  0.7807  0.7782  0.7725  0.7683  0.7682  0.7665  0.7616  0.7597  0.7597  0.7579  0.7565
[33 : 48]:	0.7452  0.7398  0.7379  0.7268  0.7241  0.7229  0.7228  0.7128  0.7110  0.7093  0.7081  0.7067  0.7030  0.7025  0.6986  0.6940
[49 : 64]:	0.6930  0.6928  0.6926  0.6922  0.6916  0.6916  0.6892  0.6873  0.6873  0.6873  0.6863  0.6860  0.6849  0.6849  0.6842  0.6820
2024-04-29 09:55:06 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 09:55:06 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 09:56:41 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1601: GFLOPs: 274.6683. Time: 842.3306 us. Best GFLOPs: 946.3400
2024-04-29 09:56:41 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1602: GFLOPs: 842.2183. Time: 274.7050 us. Best GFLOPs: 946.3400
2024-04-29 09:56:41 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1603: GFLOPs: 801.7453. Time: 288.5724 us. Best GFLOPs: 946.3400
2024-04-29 09:56:41 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1604: GFLOPs: 803.7470. Time: 287.8537 us. Best GFLOPs: 946.3400
2024-04-29 09:56:41 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1605: GFLOPs: 658.2963. Time: 351.4550 us. Best GFLOPs: 946.3400
2024-04-29 09:56:41 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1606: GFLOPs: 815.4184. Time: 283.7335 us. Best GFLOPs: 946.3400
2024-04-29 09:56:41 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1607: GFLOPs: 876.2687. Time: 264.0303 us. Best GFLOPs: 946.3400
2024-04-29 09:56:41 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1608: GFLOPs: 817.1106. Time: 283.1459 us. Best GFLOPs: 946.3400
2024-04-29 09:56:41 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1609: GFLOPs: 791.0501. Time: 292.4739 us. Best GFLOPs: 946.3400
2024-04-29 09:56:41 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1610: GFLOPs: 802.2524. Time: 288.3900 us. Best GFLOPs: 946.3400
2024-04-29 09:56:41 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1611: GFLOPs: 801.5704. Time: 288.6353 us. Best GFLOPs: 946.3400
2024-04-29 09:56:41 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1612: GFLOPs: 818.8053. Time: 282.5599 us. Best GFLOPs: 946.3400
2024-04-29 09:56:41 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1613: GFLOPs: 776.7734. Time: 297.8495 us. Best GFLOPs: 946.3400
2024-04-29 09:56:41 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1614: GFLOPs: 813.3717. Time: 284.4475 us. Best GFLOPs: 946.3400
2024-04-29 09:56:41 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1615: GFLOPs: 892.1720. Time: 259.3239 us. Best GFLOPs: 946.3400
2024-04-29 09:56:41 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1616: GFLOPs: 775.8108. Time: 298.2190 us. Best GFLOPs: 946.3400
2024-04-29 09:56:41 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1617: GFLOPs: 563.2231. Time: 410.7813 us. Best GFLOPs: 946.3400
2024-04-29 09:56:41 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1618: GFLOPs: 791.0626. Time: 292.4693 us. Best GFLOPs: 946.3400
2024-04-29 09:56:41 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1619: GFLOPs: 689.4200. Time: 335.5887 us. Best GFLOPs: 946.3400
2024-04-29 09:56:41 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1620: GFLOPs: 683.9371. Time: 338.2790 us. Best GFLOPs: 946.3400
2024-04-29 09:56:41 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1621: GFLOPs: 756.1130. Time: 305.9880 us. Best GFLOPs: 946.3400
2024-04-29 09:56:41 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1622: GFLOPs: 603.7735. Time: 383.1926 us. Best GFLOPs: 946.3400
2024-04-29 09:56:41 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1623: GFLOPs: 755.9266. Time: 306.0635 us. Best GFLOPs: 946.3400
2024-04-29 09:56:41 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1624: GFLOPs: 529.1854. Time: 437.2032 us. Best GFLOPs: 946.3400
2024-04-29 09:56:41 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1625: GFLOPs: 667.4670. Time: 346.6262 us. Best GFLOPs: 946.3400
2024-04-29 09:56:41 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1626: GFLOPs: 728.0212. Time: 317.7950 us. Best GFLOPs: 946.3400
2024-04-29 09:56:41 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1627: GFLOPs: 664.8459. Time: 347.9927 us. Best GFLOPs: 946.3400
2024-04-29 09:56:41 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1628: GFLOPs: 750.5784. Time: 308.2443 us. Best GFLOPs: 946.3400
2024-04-29 09:56:41 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1629: GFLOPs: 710.0767. Time: 325.8261 us. Best GFLOPs: 946.3400
2024-04-29 09:56:41 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1630: GFLOPs: 711.1010. Time: 325.3568 us. Best GFLOPs: 946.3400
2024-04-29 09:56:41 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1631: GFLOPs: 693.7791. Time: 333.4801 us. Best GFLOPs: 946.3400
2024-04-29 09:56:41 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1632: GFLOPs: 665.4660. Time: 347.6685 us. Best GFLOPs: 946.3400
2024-04-29 09:56:41 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1633: GFLOPs: 680.7293. Time: 339.8730 us. Best GFLOPs: 946.3400
2024-04-29 09:56:41 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1634: GFLOPs: 707.6986. Time: 326.9210 us. Best GFLOPs: 946.3400
2024-04-29 09:56:41 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1635: GFLOPs: 730.3235. Time: 316.7932 us. Best GFLOPs: 946.3400
2024-04-29 09:56:41 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1636: GFLOPs: 580.1070. Time: 398.8256 us. Best GFLOPs: 946.3400
2024-04-29 09:56:41 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1637: GFLOPs: 349.6418. Time: 661.7103 us. Best GFLOPs: 946.3400
2024-04-29 09:56:41 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1638: GFLOPs: 665.2942. Time: 347.7582 us. Best GFLOPs: 946.3400
2024-04-29 09:56:41 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1639: GFLOPs: 172.9776. Time: 1337.5230 us. Best GFLOPs: 946.3400
2024-04-29 09:56:41 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1640: GFLOPs: 687.2580. Time: 336.6444 us. Best GFLOPs: 946.3400
2024-04-29 09:56:41 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1641: GFLOPs: 686.8405. Time: 336.8490 us. Best GFLOPs: 946.3400
2024-04-29 09:56:41 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1642: GFLOPs: 769.3435. Time: 300.7259 us. Best GFLOPs: 946.3400
2024-04-29 09:56:41 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1643: GFLOPs: 737.5483. Time: 313.6900 us. Best GFLOPs: 946.3400
2024-04-29 09:56:41 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1644: GFLOPs: 40.5036. Time: 5712.1296 us. Best GFLOPs: 946.3400
2024-04-29 09:56:41 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1645: GFLOPs: 696.1569. Time: 332.3411 us. Best GFLOPs: 946.3400
2024-04-29 09:56:41 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1646: GFLOPs: 646.0122. Time: 358.1380 us. Best GFLOPs: 946.3400
2024-04-29 09:56:41 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1647: GFLOPs: 648.0181. Time: 357.0295 us. Best GFLOPs: 946.3400
2024-04-29 09:56:41 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1648: GFLOPs: 630.5698. Time: 366.9087 us. Best GFLOPs: 946.3400
2024-04-29 09:56:41 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1649: GFLOPs: 629.8938. Time: 367.3024 us. Best GFLOPs: 946.3400
2024-04-29 09:56:41 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1650: GFLOPs: 572.6296. Time: 404.0335 us. Best GFLOPs: 946.3400
2024-04-29 09:56:41 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1651: GFLOPs: 674.8905. Time: 342.8135 us. Best GFLOPs: 946.3400
2024-04-29 09:56:41 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1652: GFLOPs: 721.8778. Time: 320.4996 us. Best GFLOPs: 946.3400
2024-04-29 09:56:41 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1653: GFLOPs: 740.8050. Time: 312.3110 us. Best GFLOPs: 946.3400
2024-04-29 09:56:41 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1654: GFLOPs: 742.5805. Time: 311.5642 us. Best GFLOPs: 946.3400
2024-04-29 09:56:41 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1655: GFLOPs: 693.9021. Time: 333.4210 us. Best GFLOPs: 946.3400
2024-04-29 09:56:41 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1656: GFLOPs: 639.6777. Time: 361.6845 us. Best GFLOPs: 946.3400
2024-04-29 09:56:41 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1657: GFLOPs: 607.9042. Time: 380.5888 us. Best GFLOPs: 946.3400
2024-04-29 09:56:41 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1658: GFLOPs: 634.8169. Time: 364.4540 us. Best GFLOPs: 946.3400
2024-04-29 09:56:41 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1659: GFLOPs: 646.5024. Time: 357.8665 us. Best GFLOPs: 946.3400
2024-04-29 09:56:41 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1660: GFLOPs: 672.3853. Time: 344.0907 us. Best GFLOPs: 946.3400
2024-04-29 09:56:41 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1661: GFLOPs: 619.5552. Time: 373.4317 us. Best GFLOPs: 946.3400
2024-04-29 09:56:41 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1662: GFLOPs: 7.9218. Time: 29205.5917 us. Best GFLOPs: 946.3400
2024-04-29 09:56:41 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1663: GFLOPs: 42.3146. Time: 5467.6543 us. Best GFLOPs: 946.3400
2024-04-29 09:56:41 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1664: GFLOPs: 68.1149. Time: 3396.6372 us. Best GFLOPs: 946.3400
