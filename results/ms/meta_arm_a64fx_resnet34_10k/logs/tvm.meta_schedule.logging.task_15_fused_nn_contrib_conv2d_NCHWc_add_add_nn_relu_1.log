2024-04-29 03:20:19 [INFO] [task_scheduler.cc:160] Initializing Task #15: "fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1"
2024-04-29 03:20:19 [INFO] [task_scheduler.cc:35] 
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(128)), "float32"), p1: T.Buffer((T.int64(4), T.int64(1), T.int64(3), T.int64(3), T.int64(128), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(32)), "float32"), p3: T.Buffer((T.int64(1), T.int64(4), T.int64(28), T.int64(28), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(4), T.int64(28), T.int64(28), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(128)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(4), T.int64(28), T.int64(28), T.int64(32)))
        T_add = T.alloc_buffer((T.int64(1), T.int64(4), T.int64(28), T.int64(28), T.int64(32)))
        T_add_1 = T.alloc_buffer((T.int64(1), T.int64(4), T.int64(28), T.int64(28), T.int64(32)))
        for i0, i1, i2, i3, i4 in T.grid(T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(128)):
            with T.block("data_pad"):
                v_i0, v_i1, v_i2, v_i3, v_i4 = T.axis.remap("SSSSS", [i0, i1, i2, i3, i4])
                T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
        for n, oc_chunk, oh, ow, oc_block, ic, kh, kw in T.grid(T.int64(1), T.int64(4), T.int64(28), T.int64(28), T.int64(32), T.int64(128), T.int64(3), T.int64(3)):
            with T.block("conv2d_NCHWc"):
                v_n, v_oc_chunk, v_oh, v_ow, v_oc_block, v_ic, v_kh, v_kw = T.axis.remap("SSSSSRRR", [n, oc_chunk, oh, ow, oc_block, ic, kh, kw])
                T.reads(data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                with T.init():
                    conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
        for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(4), T.int64(28), T.int64(28), T.int64(32)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                T.writes(T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4]
        for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(4), T.int64(28), T.int64(28), T.int64(32)):
            with T.block("T_add_1"):
                v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                T.reads(T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T.writes(T_add_1[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T_add_1[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4]
        for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(4), T.int64(28), T.int64(28), T.int64(32)):
            with T.block("T_relu"):
                v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                T.reads(T_add_1[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(T_add_1[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
2024-04-29 03:20:19 [INFO] [task_scheduler.cc:164] Total 3 design space(s) generated
2024-04-29 03:20:19 [INFO] [task_scheduler.cc:170] Design space #0:
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(128)), "float32"), p1: T.Buffer((T.int64(4), T.int64(1), T.int64(3), T.int64(3), T.int64(128), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(32)), "float32"), p3: T.Buffer((T.int64(1), T.int64(4), T.int64(28), T.int64(28), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(4), T.int64(28), T.int64(28), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel": 768, "meta_schedule.unroll_explicit": 16, "meta_schedule.vectorize": 64})
            data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(128)))
            conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(4), T.int64(28), T.int64(28), T.int64(32)))
            for n_0, oc_chunk_0 in T.grid(T.int64(1), T.int64(4)):
                for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(128)):
                    with T.block("data_pad"):
                        v_i0, v_i1, v_i2, v_i3, v_i4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                        T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                        T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                        data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                for oh_0, ow_0, oc_block_0, n_1, oc_chunk_1, oh_1, ow_1, oc_block_1, ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(28), T.int64(2), T.int64(32), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(4), T.int64(4), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(1), T.int64(2)):
                    with T.block("conv2d_NCHWc"):
                        v_n = T.axis.spatial(T.int64(1), n_0 + n_1 + n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(4), oc_chunk_0 + oc_chunk_1 + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(28), oh_0 * T.int64(28) + oh_1 * T.int64(28) + oh_2 * T.int64(4) + oh_3)
                        v_ow = T.axis.spatial(T.int64(28), ow_0 * T.int64(28) + ow_1 + ow_2 + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_0 * T.int64(16) + oc_block_1 * T.int64(8) + oc_block_2 * T.int64(2) + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(128), ic_0 * T.int64(4) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                        T.reads(data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        with T.init():
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(4), T.int64(28), T.int64(28), T.int64(32)):
                with T.block("T_relu"):
                    v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                    T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[4, 1, 1, 1])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 7, 4])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 28, 1, 1])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[2, 2, 4, 2])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[32, 4])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[3, 1])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=1)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
2024-04-29 03:20:19 [INFO] [task_scheduler.cc:170] Design space #1:
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(128)), "float32"), p1: T.Buffer((T.int64(4), T.int64(1), T.int64(3), T.int64(3), T.int64(128), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(32)), "float32"), p3: T.Buffer((T.int64(1), T.int64(4), T.int64(28), T.int64(28), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(4), T.int64(28), T.int64(28), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel": 768, "meta_schedule.unroll_explicit": 512, "meta_schedule.vectorize": 64})
            data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(128)))
            conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(4), T.int64(28), T.int64(28), T.int64(32)))
            for n_0, oc_chunk_0, oh_0, ow_0, oc_block_0, n_1, oc_chunk_1, oh_1, ow_1 in T.grid(T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(28)):
                for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(30), T.int64(3), T.int64(128)):
                    with T.block("data_pad"):
                        v_i0, v_i1, v_i2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                        v_i3 = T.axis.spatial(T.int64(30), ow_1 + ax3)
                        v_i4 = T.axis.spatial(T.int64(128), ax4)
                        T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                        T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                        data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                for oc_block_1 in range(T.int64(2)):
                    for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(32), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(4), T.int64(4), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(1), T.int64(2)):
                        with T.block("conv2d_NCHWc"):
                            v_n = T.axis.spatial(T.int64(1), n_0 + n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(4), oc_chunk_0 + oc_chunk_1 + oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(28), oh_0 * T.int64(28) + oh_1 * T.int64(28) + oh_2 * T.int64(4) + oh_3)
                            v_ow = T.axis.spatial(T.int64(28), ow_0 * T.int64(28) + ow_1 + ow_2 + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(32), oc_block_0 * T.int64(16) + oc_block_1 * T.int64(8) + oc_block_2 * T.int64(2) + oc_block_3)
                            v_ic = T.axis.reduce(T.int64(128), ic_0 * T.int64(4) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            with T.init():
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
                    for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(28), T.int64(1), T.int64(8)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(4), oc_chunk_0 + ax1)
                            v_ax2 = T.axis.spatial(T.int64(28), ax2)
                            v_ax3 = T.axis.spatial(T.int64(28), ow_1 + ax3)
                            v_ax4 = T.axis.spatial(T.int64(32), oc_block_0 * T.int64(16) + oc_block_1 * T.int64(8) + ax4)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[4, 1, 1, 1])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 7, 4])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 28, 1, 1])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[2, 2, 4, 2])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[32, 4])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[3, 1])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l50, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=8)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
2024-04-29 03:20:19 [INFO] [task_scheduler.cc:170] Design space #2:
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(128)), "float32"), p1: T.Buffer((T.int64(4), T.int64(1), T.int64(3), T.int64(3), T.int64(128), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(32)), "float32"), p3: T.Buffer((T.int64(1), T.int64(4), T.int64(28), T.int64(28), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(4), T.int64(28), T.int64(28), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel": 768, "meta_schedule.unroll_explicit": 64, "meta_schedule.vectorize": 64})
            data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(128)))
            conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(4), T.int64(28), T.int64(28), T.int64(32)))
            for n_0, oc_chunk_0, oh_0, ow_0, oc_block_0 in T.grid(T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(2)):
                for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(128)):
                    with T.block("data_pad"):
                        v_i0, v_i1, v_i2, v_i3, v_i4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                        T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                        T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                        data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1, ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(28), T.int64(2), T.int64(32), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(4), T.int64(4), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(1), T.int64(2)):
                    with T.block("conv2d_NCHWc"):
                        v_n = T.axis.spatial(T.int64(1), n_0 + n_1 + n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(4), oc_chunk_0 + oc_chunk_1 + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(28), oh_0 * T.int64(28) + oh_1 * T.int64(28) + oh_2 * T.int64(4) + oh_3)
                        v_ow = T.axis.spatial(T.int64(28), ow_0 * T.int64(28) + ow_1 + ow_2 + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_0 * T.int64(16) + oc_block_1 * T.int64(8) + oc_block_2 * T.int64(2) + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(128), ic_0 * T.int64(4) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                        T.reads(data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        with T.init():
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
                for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(16)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(4), oc_chunk_0 + ax1)
                        v_ax2, v_ax3 = T.axis.remap("SS", [ax2, ax3])
                        v_ax4 = T.axis.spatial(T.int64(32), oc_block_0 * T.int64(16) + ax4)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[4, 1, 1, 1])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 7, 4])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 28, 1, 1])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[2, 2, 4, 2])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[32, 4])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[3, 1])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=4)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
2024-04-29 03:37:52 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 03:37:52 [INFO] [evolutionary_search.cc:715] Picked top 0 candidate(s) from database
2024-04-29 03:37:58 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4391338)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x38dd208)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x4182678)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x6ddeb88)]: 0 failure(s)
2024-04-29 03:37:58 [INFO] [evolutionary_search.cc:723] Sampled 512 candidate(s)
2024-04-29 03:38:04 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4391338)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x38dd208)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x4182678)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x6ddeb88)]: 0 failure(s)
2024-04-29 03:38:10 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4391338)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x38dd208)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x4182678)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x6ddeb88)]: 0 failure(s)
2024-04-29 03:38:16 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4391338)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x38dd208)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x4182678)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x6ddeb88)]: 0 failure(s)
2024-04-29 03:38:22 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4391338)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x38dd208)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x4182678)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x6ddeb88)]: 0 failure(s)
2024-04-29 03:38:23 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	1.0000  0.9998  0.9997  0.9993  0.9989  0.9980  0.9979  0.9976  0.9973  0.9972  0.9966  0.9961  0.9958  0.9955  0.9950  0.9948
[17 : 32]:	0.9939  0.9936  0.9932  0.9931  0.9930  0.9921  0.9919  0.9917  0.9915  0.9914  0.9913  0.9908  0.9907  0.9899  0.9897  0.9895
[33 : 48]:	0.9894  0.9893  0.9878  0.9868  0.9863  0.9863  0.9854  0.9851  0.9850  0.9842  0.9840  0.9835  0.9830  0.9828  0.9827  0.9816
[49 : 64]:	0.9812  0.9811  0.9804  0.9790  0.9789  0.9783  0.9782  0.9779  0.9777  0.9776  0.9774  0.9768  0.9758  0.9757  0.9753  0.9750
2024-04-29 03:38:24 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 03:38:24 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 03:57:19 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #1: GFLOPs: 23.6256. Time: 9799.2193 us. Best GFLOPs: 23.6256
2024-04-29 03:57:20 [INFO] [task_scheduler.cc:121] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #2: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(128)), "float32"), p1: T.Buffer((T.int64(4), T.int64(1), T.int64(3), T.int64(3), T.int64(128), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(32)), "float32"), p3: T.Buffer((T.int64(1), T.int64(4), T.int64(28), T.int64(28), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(4), T.int64(28), T.int64(28), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(128)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(4), T.int64(28), T.int64(28), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused in T.parallel(T.int64(16), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(2), T.int64(7), T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(28)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(2)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(4), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(8) * T.int64(2) + oc_chunk_1 * T.int64(2) + oc_chunk_2_init + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(8) // T.int64(4) * T.int64(14) + oh_1 * T.int64(7) + oh_2_init + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(28), ow_1 * T.int64(28) + ow_2_init * T.int64(28) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(4) * T.int64(8) + oc_block_1 * T.int64(8) + oc_block_2_init * T.int64(2) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0 in range(T.int64(8)):
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(9), T.int64(30)):
                        for ax4_fused in T.vectorized(T.int64(16)):
                            with T.block("data_pad"):
                                v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                                v_i2 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(8) // T.int64(4) * T.int64(14) + oh_1 * T.int64(7) + ax2)
                                v_i3 = T.axis.spatial(T.int64(30), ax3)
                                v_i4 = T.axis.spatial(T.int64(128), ic_0 * T.int64(16) + ax4_fused)
                                T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                                T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                                data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                    for kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(1), T.int64(3), T.int64(1), T.int64(2), T.int64(7), T.int64(1), T.int64(4), T.int64(16), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(28)):
                        for oc_block_3_fused in T.vectorized(T.int64(2)):
                            with T.block("conv2d_NCHWc_update"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                                v_oc_chunk = T.axis.spatial(T.int64(4), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(8) * T.int64(2) + oc_chunk_1 * T.int64(2) + oc_chunk_2 + oc_chunk_3)
                                v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(8) // T.int64(4) * T.int64(14) + oh_1 * T.int64(7) + oh_2 + oh_3)
                                v_ow = T.axis.spatial(T.int64(28), ow_1 * T.int64(28) + ow_2 * T.int64(28) + ow_3)
                                v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(4) * T.int64(8) + oc_block_1 * T.int64(8) + oc_block_2 * T.int64(2) + oc_block_3_fused)
                                v_ic = T.axis.reduce(T.int64(128), ic_0 * T.int64(16) + ic_1)
                                v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                                v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                                T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(2), T.int64(14), T.int64(28)):
                for ax4_fused in T.vectorized(T.int64(8)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(4), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(8) * T.int64(2) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(8) // T.int64(4) * T.int64(14) + ax2)
                        v_ax3 = T.axis.spatial(T.int64(28), ax3)
                        v_ax4 = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(4) * T.int64(8) + ax4_fused)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 1, 2, 1])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[2, 2, 7, 1])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 1, 28])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[4, 1, 4, 2])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[8, 16])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[3, 1])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=10)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87 = sch.get_loops(block=b69)
l88 = sch.fuse(l72, l73, l74, l75, l76, preserve_unit_iters=True)
sch.parallel(loop=l88)
l89 = sch.fuse(l87, preserve_unit_iters=True)
sch.vectorize(loop=l89)
l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107, l108, l109, l110, l111 = sch.get_loops(block=b70)
l112 = sch.fuse(l90, preserve_unit_iters=True)
sch.parallel(loop=l112)
l113 = sch.fuse(l111, preserve_unit_iters=True)
sch.vectorize(loop=l113)
sch.annotate(block_or_loop=l112, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l112, ann_key="pragma_unroll_explicit", ann_val=1)
l114, l115, l116, l117, l118, l119 = sch.get_loops(block=b71)
l120 = sch.fuse(l119, preserve_unit_iters=True)
sch.vectorize(loop=l120)
b121 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141, l142, l143 = sch.get_loops(block=b121)
b144 = sch.decompose_reduction(block=b121, loop=l128)
2024-04-29 03:57:20 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #3: GFLOPs: 1.2611. Time: 183578.1077 us. Best GFLOPs: 23.6256
2024-04-29 03:57:20 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #4: GFLOPs: 2.6209. Time: 88331.8553 us. Best GFLOPs: 23.6256
2024-04-29 03:57:20 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #5: GFLOPs: 12.9161. Time: 17924.3295 us. Best GFLOPs: 23.6256
2024-04-29 03:57:20 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #6: GFLOPs: 17.8975. Time: 12935.4109 us. Best GFLOPs: 23.6256
2024-04-29 03:57:20 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #7: GFLOPs: 7.0524. Time: 32827.3080 us. Best GFLOPs: 23.6256
2024-04-29 03:57:20 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #8: GFLOPs: 198.2422. Time: 1167.8242 us. Best GFLOPs: 198.2422
2024-04-29 03:57:20 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #9: GFLOPs: 84.1914. Time: 2749.8294 us. Best GFLOPs: 198.2422
2024-04-29 03:57:20 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #10: GFLOPs: 36.5669. Time: 6331.1986 us. Best GFLOPs: 198.2422
2024-04-29 03:57:20 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #11: GFLOPs: 91.8155. Time: 2521.4920 us. Best GFLOPs: 198.2422
2024-04-29 03:57:20 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #12: GFLOPs: 106.2053. Time: 2179.8544 us. Best GFLOPs: 198.2422
2024-04-29 03:57:20 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #13: GFLOPs: 3.5162. Time: 65842.2727 us. Best GFLOPs: 198.2422
2024-04-29 03:57:20 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #14: GFLOPs: 66.8329. Time: 3464.0446 us. Best GFLOPs: 198.2422
2024-04-29 03:57:20 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #15: GFLOPs: 105.0667. Time: 2203.4763 us. Best GFLOPs: 198.2422
2024-04-29 03:57:20 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #16: GFLOPs: 57.4429. Time: 4030.2996 us. Best GFLOPs: 198.2422
2024-04-29 03:57:20 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #17: GFLOPs: 132.4413. Time: 1748.0350 us. Best GFLOPs: 198.2422
2024-04-29 03:57:20 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #18: GFLOPs: 61.0726. Time: 3790.7706 us. Best GFLOPs: 198.2422
2024-04-29 03:57:20 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #19: GFLOPs: 87.6194. Time: 2642.2469 us. Best GFLOPs: 198.2422
2024-04-29 03:57:20 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #20: GFLOPs: 68.8816. Time: 3361.0163 us. Best GFLOPs: 198.2422
2024-04-29 03:57:20 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #21: GFLOPs: 16.9173. Time: 13684.9601 us. Best GFLOPs: 198.2422
2024-04-29 03:57:20 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #22: GFLOPs: 5.1390. Time: 45049.9563 us. Best GFLOPs: 198.2422
2024-04-29 03:57:20 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #23: GFLOPs: 27.3218. Time: 8473.5371 us. Best GFLOPs: 198.2422
2024-04-29 03:57:20 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #24: GFLOPs: 50.2031. Time: 4611.5076 us. Best GFLOPs: 198.2422
2024-04-29 03:57:20 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #25: GFLOPs: 80.8132. Time: 2864.7792 us. Best GFLOPs: 198.2422
2024-04-29 03:57:20 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #26: GFLOPs: 74.1280. Time: 3123.1391 us. Best GFLOPs: 198.2422
2024-04-29 03:57:20 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #27: GFLOPs: 89.3313. Time: 2591.6114 us. Best GFLOPs: 198.2422
2024-04-29 03:57:20 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #28: GFLOPs: 9.1029. Time: 25432.7165 us. Best GFLOPs: 198.2422
2024-04-29 03:57:20 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #29: GFLOPs: 99.0590. Time: 2337.1122 us. Best GFLOPs: 198.2422
2024-04-29 03:57:20 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #30: GFLOPs: 241.2331. Time: 959.7027 us. Best GFLOPs: 241.2331
2024-04-29 03:57:20 [INFO] [task_scheduler.cc:121] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #31: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(128)), "float32"), p1: T.Buffer((T.int64(4), T.int64(1), T.int64(3), T.int64(3), T.int64(128), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(32)), "float32"), p3: T.Buffer((T.int64(1), T.int64(4), T.int64(28), T.int64(28), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(4), T.int64(28), T.int64(28), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(4), T.int64(28), T.int64(28), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused in T.parallel(T.int64(16), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(4), T.int64(7), T.int64(7), T.int64(4), T.int64(1), T.int64(1), T.int64(2), T.int64(2)):
                for oc_block_3_fused_init in T.vectorized(T.int64(2)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(4), oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(4) // T.int64(2) * T.int64(14) + oh_2_init * T.int64(2) + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(2) * T.int64(14) + ow_2_init * T.int64(2) + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused // T.int64(4) * T.int64(8) + oc_block_2_init * T.int64(2) + oc_block_3_fused_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
            for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(16), T.int64(3), T.int64(3), T.int64(1), T.int64(4), T.int64(7), T.int64(7), T.int64(4), T.int64(8), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(2)):
                for oc_block_3_fused in T.vectorized(T.int64(2)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(4), oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(4) // T.int64(2) * T.int64(14) + oh_2 * T.int64(2) + oh_3)
                        v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(2) * T.int64(14) + ow_2 * T.int64(2) + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused // T.int64(4) * T.int64(8) + oc_block_2 * T.int64(2) + oc_block_3_fused)
                        v_ic = T.axis.reduce(T.int64(128), ic_0 * T.int64(8) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], p0[v_n, v_ic // T.int64(128), v_oh + v_kh - T.int64(1), v_ow + v_kw - T.int64(1), v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + T.if_then_else(T.int64(1) <= v_oh + v_kh and v_oh + v_kh < T.int64(29) and T.int64(1) <= v_ow + v_kw and v_ow + v_kw < T.int64(29), p0[v_n, v_ic // T.int64(128), v_oh + v_kh - T.int64(1), v_ow + v_kw - T.int64(1), v_ic % T.int64(128)], T.float32(0)) * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(4), T.int64(14), T.int64(14)):
                for ax4_fused in T.vectorized(T.int64(8)):
                    with T.block("T_relu"):
                        v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                        v_ax2 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(4) // T.int64(2) * T.int64(14) + ax2)
                        v_ax3 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(2) * T.int64(14) + ax3)
                        v_ax4 = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused // T.int64(4) * T.int64(8) + ax4_fused)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 4, 1])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 2, 7, 2])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 2, 7, 2])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[4, 1, 4, 2])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[16, 8])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[3, 1])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l50, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=-2)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70 = sch.get_child_blocks(b68)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96 = sch.get_loops(block=b69)
l97 = sch.fuse(l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, preserve_unit_iters=True)
sch.parallel(loop=l97)
l98 = sch.fuse(l96, preserve_unit_iters=True)
sch.vectorize(loop=l98)
sch.annotate(block_or_loop=l97, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l97, ann_key="pragma_unroll_explicit", ann_val=1)
l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b70)
l105 = sch.fuse(l104, preserve_unit_iters=True)
sch.vectorize(loop=l105)
b106 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117, l118, l119, l120, l121, l122, l123 = sch.get_loops(block=b106)
b124 = sch.decompose_reduction(block=b106, loop=l108)
2024-04-29 03:57:20 [INFO] [task_scheduler.cc:121] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #32: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(128)), "float32"), p1: T.Buffer((T.int64(4), T.int64(1), T.int64(3), T.int64(3), T.int64(128), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(32)), "float32"), p3: T.Buffer((T.int64(1), T.int64(4), T.int64(28), T.int64(28), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(4), T.int64(28), T.int64(28), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(128)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(4), T.int64(28), T.int64(28), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused in T.parallel(T.int64(4), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1 in T.grid(T.int64(1), T.int64(2), T.int64(2)):
                for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(9), T.int64(16), T.int64(128)):
                    with T.block("data_pad"):
                        v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                        v_i2 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(2) * T.int64(14) + oh_1 * T.int64(7) + ax2)
                        v_i3 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(2) * T.int64(14) + ax3)
                        v_i4 = T.axis.spatial(T.int64(128), ax4)
                        T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                        T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                        data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                for ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(2)):
                    for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(1), T.int64(7), T.int64(7), T.int64(8), T.int64(1), T.int64(2), T.int64(1), T.int64(2)):
                        for oc_block_3_fused_init in T.vectorized(T.int64(2)):
                            with T.block("conv2d_NCHWc_init"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                                v_oc_chunk = T.axis.spatial(T.int64(4), oc_chunk_1 * T.int64(2) + oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                                v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(2) * T.int64(14) + oh_1 * T.int64(7) + oh_2_init + oh_3_init)
                                v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(2) * T.int64(14) + ow_1 * T.int64(14) + ow_2_init * T.int64(2) + ow_3_init)
                                v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(16) + oc_block_2_init * T.int64(2) + oc_block_3_fused_init)
                                T.reads()
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                    for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(32), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(7), T.int64(8), T.int64(4), T.int64(3), T.int64(3), T.int64(1), T.int64(2), T.int64(1), T.int64(2)):
                        for oc_block_3_fused in T.vectorized(T.int64(2)):
                            with T.block("conv2d_NCHWc_update"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                                v_oc_chunk = T.axis.spatial(T.int64(4), oc_chunk_1 * T.int64(2) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                                v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(2) * T.int64(14) + oh_1 * T.int64(7) + oh_2 + oh_3)
                                v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(2) * T.int64(14) + ow_1 * T.int64(14) + ow_2 * T.int64(2) + ow_3)
                                v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(16) + oc_block_2 * T.int64(2) + oc_block_3_fused)
                                v_ic = T.axis.reduce(T.int64(128), ic_0 * T.int64(4) + ic_1)
                                v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                                v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                                T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(4), T.int64(14), T.int64(14)):
                for ax4_fused in T.vectorized(T.int64(32)):
                    with T.block("T_relu"):
                        v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                        v_ax2 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(2) * T.int64(14) + ax2)
                        v_ax3 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(2) * T.int64(14) + ax3)
                        v_ax4 = T.axis.spatial(T.int64(32), ax4_fused)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 2, 1, 2])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[2, 2, 7, 1])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[2, 1, 7, 2])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[1, 2, 8, 2])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[32, 4])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[1, 3])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=7)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b69)
l85 = sch.fuse(l72, l73, l74, l75, l76, preserve_unit_iters=True)
sch.parallel(loop=l85)
l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107 = sch.get_loops(block=b70)
l108 = sch.fuse(l86, preserve_unit_iters=True)
sch.parallel(loop=l108)
l109 = sch.fuse(l107, preserve_unit_iters=True)
sch.vectorize(loop=l109)
sch.annotate(block_or_loop=l108, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l108, ann_key="pragma_unroll_explicit", ann_val=1)
l110, l111, l112, l113, l114, l115 = sch.get_loops(block=b71)
l116 = sch.fuse(l115, preserve_unit_iters=True)
sch.vectorize(loop=l116)
b117 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139 = sch.get_loops(block=b117)
b140 = sch.decompose_reduction(block=b117, loop=l124)
2024-04-29 03:57:20 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #33: GFLOPs: 0.8957. Time: 258464.8407 us. Best GFLOPs: 241.2331
2024-04-29 03:57:20 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #34: GFLOPs: 68.4021. Time: 3384.5745 us. Best GFLOPs: 241.2331
2024-04-29 03:57:20 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #35: GFLOPs: 1.8357. Time: 126116.2867 us. Best GFLOPs: 241.2331
2024-04-29 03:57:20 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #36: GFLOPs: 22.1797. Time: 10438.0131 us. Best GFLOPs: 241.2331
2024-04-29 03:57:20 [INFO] [task_scheduler.cc:121] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #37: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(128)), "float32"), p1: T.Buffer((T.int64(4), T.int64(1), T.int64(3), T.int64(3), T.int64(128), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(32)), "float32"), p3: T.Buffer((T.int64(1), T.int64(4), T.int64(28), T.int64(28), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(4), T.int64(28), T.int64(28), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(128)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(4), T.int64(28), T.int64(28), T.int64(32)))
        for i0_i1_i2_i3_fused in T.parallel(T.int64(900)):
            for i4 in range(T.int64(128)):
                with T.block("data_pad"):
                    v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_i1 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_i2 = T.axis.spatial(T.int64(30), i0_i1_i2_i3_fused // T.int64(30))
                    v_i3 = T.axis.spatial(T.int64(30), i0_i1_i2_i3_fused % T.int64(30))
                    v_i4 = T.axis.spatial(T.int64(128), i4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused in T.parallel(T.int64(4), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(1), T.int64(28), T.int64(1), T.int64(2), T.int64(1), T.int64(4), T.int64(1), T.int64(14)):
                for oc_block_3_fused_init in T.vectorized(T.int64(8)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(4), oc_chunk_2_init * T.int64(4) + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(28), oh_2_init + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused // T.int64(2) * T.int64(14) + ow_2_init * T.int64(14) + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(2) * T.int64(16) + oc_block_2_init * T.int64(8) + oc_block_3_fused_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
            for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(64), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(28), T.int64(1), T.int64(2), T.int64(2), T.int64(1), T.int64(3), T.int64(1), T.int64(4), T.int64(1), T.int64(14)):
                for oc_block_3_fused in T.vectorized(T.int64(8)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(4), oc_chunk_2 * T.int64(4) + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(28), oh_2 + oh_3)
                        v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused // T.int64(2) * T.int64(14) + ow_2 * T.int64(14) + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(2) * T.int64(16) + oc_block_2 * T.int64(8) + oc_block_3_fused)
                        v_ic = T.axis.reduce(T.int64(128), ic_0 * T.int64(2) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(4), T.int64(28), T.int64(14)):
                for ax4_fused in T.vectorized(T.int64(16)):
                    with T.block("T_relu"):
                        v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                        v_ax3 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused // T.int64(2) * T.int64(14) + ax3)
                        v_ax4 = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(2) * T.int64(16) + ax4_fused)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 1, 4])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 28, 1])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 2, 1, 14])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[1, 2, 2, 8])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[64, 2])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[1, 3])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l50, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=-1)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76 = sch.get_loops(block=b69)
l77 = sch.fuse(l72, l73, l74, l75, preserve_unit_iters=True)
sch.parallel(loop=l77)
l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b70)
l104 = sch.fuse(l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, preserve_unit_iters=True)
sch.parallel(loop=l104)
l105 = sch.fuse(l103, preserve_unit_iters=True)
sch.vectorize(loop=l105)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l106, l107, l108, l109, l110, l111 = sch.get_loops(block=b71)
l112 = sch.fuse(l111, preserve_unit_iters=True)
sch.vectorize(loop=l112)
b113 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130 = sch.get_loops(block=b113)
b131 = sch.decompose_reduction(block=b113, loop=l115)
2024-04-29 03:57:20 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #38: GFLOPs: 26.4408. Time: 8755.8619 us. Best GFLOPs: 241.2331
2024-04-29 03:57:20 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #39: GFLOPs: 2.2677. Time: 102092.1620 us. Best GFLOPs: 241.2331
2024-04-29 03:57:20 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #40: GFLOPs: 180.9104. Time: 1279.7060 us. Best GFLOPs: 241.2331
2024-04-29 03:57:20 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #41: GFLOPs: 60.2371. Time: 3843.3437 us. Best GFLOPs: 241.2331
2024-04-29 03:57:20 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #42: GFLOPs: 131.0089. Time: 1767.1477 us. Best GFLOPs: 241.2331
2024-04-29 03:57:20 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #43: GFLOPs: 3.0638. Time: 75563.1577 us. Best GFLOPs: 241.2331
2024-04-29 03:57:20 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #44: GFLOPs: 31.2165. Time: 7416.3351 us. Best GFLOPs: 241.2331
2024-04-29 03:57:20 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #45: GFLOPs: 32.5273. Time: 7117.4774 us. Best GFLOPs: 241.2331
2024-04-29 03:57:20 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #46: GFLOPs: 5.5860. Time: 41445.0753 us. Best GFLOPs: 241.2331
2024-04-29 03:57:20 [INFO] [task_scheduler.cc:121] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #47: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(128)), "float32"), p1: T.Buffer((T.int64(4), T.int64(1), T.int64(3), T.int64(3), T.int64(128), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(32)), "float32"), p3: T.Buffer((T.int64(1), T.int64(4), T.int64(28), T.int64(28), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(4), T.int64(28), T.int64(28), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(128)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(4), T.int64(28), T.int64(28), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused in T.parallel(T.int64(2), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(2), T.int64(2), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(2), T.int64(2), T.int64(7), T.int64(16), T.int64(1), T.int64(1), T.int64(7), T.int64(4), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(4), oc_chunk_1 * T.int64(2) + oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(28), oh_1 * T.int64(14) + oh_2_init * T.int64(7) + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(28), ow_1 * T.int64(28) + ow_2_init * T.int64(4) + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0 in T.grid(T.int64(8), T.int64(3), T.int64(3)):
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(14), T.int64(28)):
                        for ax4_fused in T.vectorized(T.int64(16)):
                            with T.block("data_pad"):
                                v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                                v_i2 = T.axis.spatial(T.int64(30), kh_0 + oh_1 * T.int64(14) + ax2)
                                v_i3 = T.axis.spatial(T.int64(30), kw_0 + ax3)
                                v_i4 = T.axis.spatial(T.int64(128), ic_0 * T.int64(16) + ax4_fused)
                                T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                                T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                                data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                    for n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(1), T.int64(2), T.int64(2), T.int64(7), T.int64(16), T.int64(16), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(4), T.int64(1)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(4), oc_chunk_1 * T.int64(2) + oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(28), oh_1 * T.int64(14) + oh_2 * T.int64(7) + oh_3)
                            v_ow = T.axis.spatial(T.int64(28), ow_1 * T.int64(28) + ow_2 * T.int64(4) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2 + oc_block_3)
                            v_ic = T.axis.reduce(T.int64(128), ic_0 * T.int64(16) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(4), T.int64(28), T.int64(28)):
                for ax4_fused in T.vectorized(T.int64(16)):
                    with T.block("T_relu"):
                        v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                        v_ax4 = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused * T.int64(16) + ax4_fused)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 2, 2, 1])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 2, 2, 7])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 7, 4])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[2, 1, 16, 1])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[8, 16])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[3, 1])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=12)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89 = sch.get_loops(block=b69)
l90 = sch.fuse(l72, l73, l74, l75, l76, preserve_unit_iters=True)
sch.parallel(loop=l90)
l91 = sch.fuse(l89, preserve_unit_iters=True)
sch.vectorize(loop=l91)
l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107, l108, l109, l110, l111, l112, l113 = sch.get_loops(block=b70)
l114 = sch.fuse(l92, preserve_unit_iters=True)
sch.parallel(loop=l114)
sch.annotate(block_or_loop=l114, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l114, ann_key="pragma_unroll_explicit", ann_val=1)
l115, l116, l117, l118, l119, l120 = sch.get_loops(block=b71)
l121 = sch.fuse(l120, preserve_unit_iters=True)
sch.vectorize(loop=l121)
b122 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141, l142, l143, l144 = sch.get_loops(block=b122)
b145 = sch.decompose_reduction(block=b122, loop=l129)
2024-04-29 03:57:20 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #48: GFLOPs: 25.2708. Time: 9161.2317 us. Best GFLOPs: 241.2331
2024-04-29 03:57:20 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #49: GFLOPs: 13.0520. Time: 17737.6562 us. Best GFLOPs: 241.2331
2024-04-29 03:57:20 [INFO] [task_scheduler.cc:121] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #50: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(128)), "float32"), p1: T.Buffer((T.int64(4), T.int64(1), T.int64(3), T.int64(3), T.int64(128), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(32)), "float32"), p3: T.Buffer((T.int64(1), T.int64(4), T.int64(28), T.int64(28), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(4), T.int64(28), T.int64(28), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(4), T.int64(28), T.int64(28), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused in T.parallel(T.int64(32), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(4), T.int64(7), T.int64(7), T.int64(4), T.int64(1), T.int64(1), T.int64(2), T.int64(2), T.int64(1)):
                with T.block("conv2d_NCHWc_init"):
                    v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                    v_oc_chunk = T.axis.spatial(T.int64(4), oc_chunk_2_init + oc_chunk_3_init)
                    v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused // T.int64(16) * T.int64(14) + oh_2_init * T.int64(2) + oh_3_init)
                    v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(16) // T.int64(8) * T.int64(14) + ow_2_init * T.int64(2) + ow_3_init)
                    v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(8) * T.int64(4) + oc_block_2_init + oc_block_3_init)
                    T.reads()
                    T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                    T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                    conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
            for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(16), T.int64(3), T.int64(3), T.int64(1), T.int64(4), T.int64(7), T.int64(7), T.int64(4), T.int64(8), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(2), T.int64(1)):
                with T.block("conv2d_NCHWc_update"):
                    v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                    v_oc_chunk = T.axis.spatial(T.int64(4), oc_chunk_2 + oc_chunk_3)
                    v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused // T.int64(16) * T.int64(14) + oh_2 * T.int64(2) + oh_3)
                    v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(16) // T.int64(8) * T.int64(14) + ow_2 * T.int64(2) + ow_3)
                    v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(8) * T.int64(4) + oc_block_2 + oc_block_3)
                    v_ic = T.axis.reduce(T.int64(128), ic_0 * T.int64(8) + ic_1)
                    v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                    v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                    T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], p0[v_n, v_ic // T.int64(128), v_oh + v_kh - T.int64(1), v_ow + v_kw - T.int64(1), v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                    T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                    T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                    conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + T.if_then_else(T.int64(1) <= v_oh + v_kh and v_oh + v_kh < T.int64(29) and T.int64(1) <= v_ow + v_kw and v_ow + v_kw < T.int64(29), p0[v_n, v_ic // T.int64(128), v_oh + v_kh - T.int64(1), v_ow + v_kw - T.int64(1), v_ic % T.int64(128)], T.float32(0)) * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(4), T.int64(14), T.int64(14)):
                for ax4_fused in T.vectorized(T.int64(4)):
                    with T.block("T_relu"):
                        v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                        v_ax2 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused // T.int64(16) * T.int64(14) + ax2)
                        v_ax3 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(16) // T.int64(8) * T.int64(14) + ax3)
                        v_ax4 = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(8) * T.int64(4) + ax4_fused)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 4, 1])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 2, 7, 2])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 2, 7, 2])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[1, 8, 4, 1])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[16, 8])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[3, 1])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l50, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=-2)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70 = sch.get_child_blocks(b68)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96 = sch.get_loops(block=b69)
l97 = sch.fuse(l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, preserve_unit_iters=True)
sch.parallel(loop=l97)
sch.annotate(block_or_loop=l97, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l97, ann_key="pragma_unroll_explicit", ann_val=1)
l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b70)
l104 = sch.fuse(l103, preserve_unit_iters=True)
sch.vectorize(loop=l104)
b105 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l106, l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117, l118, l119, l120, l121, l122 = sch.get_loops(block=b105)
b123 = sch.decompose_reduction(block=b105, loop=l107)
2024-04-29 03:57:20 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #51: GFLOPs: 66.9573. Time: 3457.6083 us. Best GFLOPs: 241.2331
2024-04-29 03:57:20 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #52: GFLOPs: 4.5827. Time: 50518.7787 us. Best GFLOPs: 241.2331
2024-04-29 03:57:20 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #53: GFLOPs: 17.5373. Time: 13201.1054 us. Best GFLOPs: 241.2331
2024-04-29 03:57:20 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #54: GFLOPs: 12.5358. Time: 18468.0555 us. Best GFLOPs: 241.2331
2024-04-29 03:57:20 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #55: GFLOPs: 99.7529. Time: 2320.8566 us. Best GFLOPs: 241.2331
2024-04-29 03:57:20 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #56: GFLOPs: 166.1976. Time: 1392.9931 us. Best GFLOPs: 241.2331
2024-04-29 03:57:20 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #57: GFLOPs: 12.7555. Time: 18149.9748 us. Best GFLOPs: 241.2331
2024-04-29 03:57:20 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #58: GFLOPs: 39.9988. Time: 5787.9762 us. Best GFLOPs: 241.2331
2024-04-29 03:57:20 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #59: GFLOPs: 1.9921. Time: 116216.7190 us. Best GFLOPs: 241.2331
2024-04-29 03:57:20 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #60: GFLOPs: 25.2818. Time: 9157.2598 us. Best GFLOPs: 241.2331
2024-04-29 03:57:20 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #61: GFLOPs: 26.5798. Time: 8710.0795 us. Best GFLOPs: 241.2331
2024-04-29 03:57:20 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #62: GFLOPs: 90.1515. Time: 2568.0328 us. Best GFLOPs: 241.2331
2024-04-29 03:57:20 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #63: GFLOPs: 18.9272. Time: 12231.7089 us. Best GFLOPs: 241.2331
2024-04-29 03:57:20 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #64: GFLOPs: 16.8869. Time: 13709.5691 us. Best GFLOPs: 241.2331
2024-04-29 04:05:42 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 04:05:43 [INFO] [evolutionary_search.cc:715] Picked top 58 candidate(s) from database
2024-04-29 04:05:48 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4391338)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x38dd208)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x4182678)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x6ddeb88)]: 0 failure(s)
2024-04-29 04:05:48 [INFO] [evolutionary_search.cc:723] Sampled 454 candidate(s)
2024-04-29 04:06:00 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4391338)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x38dd208)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x4182678)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x6ddeb88)]: 0 failure(s)
2024-04-29 04:06:13 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4391338)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x38dd208)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x4182678)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x6ddeb88)]: 0 failure(s)
2024-04-29 04:06:26 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4391338)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x38dd208)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x4182678)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x6ddeb88)]: 0 failure(s)
2024-04-29 04:06:39 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4391338)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x38dd208)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x4182678)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x6ddeb88)]: 0 failure(s)
2024-04-29 04:06:47 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9988  0.8508  0.8407  0.8250  0.7841  0.7486  0.7306  0.7285  0.7169  0.7099  0.7011  0.6968  0.6903  0.6894  0.6842  0.6824
[17 : 32]:	0.6824  0.6820  0.6783  0.6766  0.6747  0.6732  0.6732  0.6725  0.6718  0.6718  0.6714  0.6703  0.6658  0.6642  0.6638  0.6638
[33 : 48]:	0.6631  0.6587  0.6551  0.6539  0.6496  0.6496  0.6295  0.6283  0.6273  0.6242  0.6206  0.6199  0.6199  0.6189  0.6189  0.6169
[49 : 64]:	0.6165  0.6164  0.6163  0.6141  0.6140  0.6124  0.6091  0.6091  0.6090  0.6082  0.6081  0.6033  0.6014  0.6005  0.5992  0.5988
2024-04-29 04:06:48 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 04:06:48 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 04:07:55 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #65: GFLOPs: 169.2561. Time: 1367.8207 us. Best GFLOPs: 241.2331
2024-04-29 04:07:55 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #66: GFLOPs: 41.0225. Time: 5643.5328 us. Best GFLOPs: 241.2331
2024-04-29 04:07:55 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #67: GFLOPs: 63.8658. Time: 3624.9749 us. Best GFLOPs: 241.2331
2024-04-29 04:07:55 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #68: GFLOPs: 206.8416. Time: 1119.2725 us. Best GFLOPs: 241.2331
2024-04-29 04:07:55 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #69: GFLOPs: 133.8617. Time: 1729.4874 us. Best GFLOPs: 241.2331
2024-04-29 04:07:55 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #70: GFLOPs: 140.1583. Time: 1651.7902 us. Best GFLOPs: 241.2331
2024-04-29 04:07:55 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #71: GFLOPs: 133.0825. Time: 1739.6137 us. Best GFLOPs: 241.2331
2024-04-29 04:07:55 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #72: GFLOPs: 204.6602. Time: 1131.2022 us. Best GFLOPs: 241.2331
2024-04-29 04:07:55 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #73: GFLOPs: 138.2043. Time: 1675.1437 us. Best GFLOPs: 241.2331
2024-04-29 04:07:55 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #74: GFLOPs: 120.1237. Time: 1927.2799 us. Best GFLOPs: 241.2331
2024-04-29 04:07:55 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #75: GFLOPs: 142.3443. Time: 1626.4230 us. Best GFLOPs: 241.2331
2024-04-29 04:07:55 [INFO] [task_scheduler.cc:121] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #76: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(128)), "float32"), p1: T.Buffer((T.int64(4), T.int64(1), T.int64(3), T.int64(3), T.int64(128), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(32)), "float32"), p3: T.Buffer((T.int64(1), T.int64(4), T.int64(28), T.int64(28), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(4), T.int64(28), T.int64(28), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(128)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(4), T.int64(28), T.int64(28), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused in T.parallel(T.int64(224), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(7), T.int64(2), T.int64(1), T.int64(2), T.int64(2), T.int64(1)):
                for oc_block_3_fused_init in T.vectorized(T.int64(4)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(4), oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(112) // T.int64(8) * T.int64(2) + oh_2_init * T.int64(2) + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(8) // T.int64(2) * T.int64(7) + ow_2_init + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(112) * T.int64(16) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(2) * T.int64(8) + oc_block_2_init * T.int64(4) + oc_block_3_fused_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
            for ic_0, kh_0, kw_0 in T.grid(T.int64(4), T.int64(1), T.int64(3)):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(7)):
                    for ax4_fused in T.vectorized(T.int64(32)):
                        with T.block("data_pad"):
                            v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                            v_i2 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(112) // T.int64(8) * T.int64(2) + ax2)
                            v_i3 = T.axis.spatial(T.int64(30), kw_0 + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(8) // T.int64(2) * T.int64(7) + ax3)
                            v_i4 = T.axis.spatial(T.int64(128), ic_0 * T.int64(32) + ax4_fused)
                            T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                            T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                            data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                for n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(7), T.int64(2), T.int64(32), T.int64(3), T.int64(1), T.int64(1), T.int64(2), T.int64(2), T.int64(1)):
                    for oc_block_3_fused in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(4), oc_chunk_2 * T.int64(2) + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(112) // T.int64(8) * T.int64(2) + oh_2 * T.int64(2) + oh_3)
                            v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(8) // T.int64(2) * T.int64(7) + ow_2 + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(112) * T.int64(16) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(2) * T.int64(8) + oc_block_2 * T.int64(4) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(128), ic_0 * T.int64(32) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(4), T.int64(2), T.int64(7)):
                for ax4_fused in T.vectorized(T.int64(8)):
                    with T.block("T_relu"):
                        v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                        v_ax2 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(112) // T.int64(8) * T.int64(2) + ax2)
                        v_ax3 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(8) // T.int64(2) * T.int64(7) + ax3)
                        v_ax4 = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(112) * T.int64(16) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(2) * T.int64(8) + ax4_fused)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 2, 2])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 14, 1, 2])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 4, 7, 1])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[2, 2, 2, 4])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[4, 32])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[3, 1])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l50, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=12)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89 = sch.get_loops(block=b69)
l90 = sch.fuse(l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, preserve_unit_iters=True)
sch.parallel(loop=l90)
l91 = sch.fuse(l89, preserve_unit_iters=True)
sch.vectorize(loop=l91)
l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107, l108 = sch.get_loops(block=b70)
l109 = sch.fuse(l92, preserve_unit_iters=True)
sch.parallel(loop=l109)
l110 = sch.fuse(l108, preserve_unit_iters=True)
sch.vectorize(loop=l110)
sch.annotate(block_or_loop=l109, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l109, ann_key="pragma_unroll_explicit", ann_val=1)
l111, l112, l113, l114, l115, l116 = sch.get_loops(block=b71)
l117 = sch.fuse(l116, preserve_unit_iters=True)
sch.vectorize(loop=l117)
b118 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135 = sch.get_loops(block=b118)
b136 = sch.decompose_reduction(block=b118, loop=l120)
2024-04-29 04:07:55 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #77: GFLOPs: 107.1213. Time: 2161.2143 us. Best GFLOPs: 241.2331
2024-04-29 04:07:55 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #78: GFLOPs: 237.8773. Time: 973.2414 us. Best GFLOPs: 241.2331
2024-04-29 04:07:55 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #79: GFLOPs: 211.7911. Time: 1093.1153 us. Best GFLOPs: 241.2331
2024-04-29 04:07:55 [INFO] [task_scheduler.cc:121] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #80: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(128)), "float32"), p1: T.Buffer((T.int64(4), T.int64(1), T.int64(3), T.int64(3), T.int64(128), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(32)), "float32"), p3: T.Buffer((T.int64(1), T.int64(4), T.int64(28), T.int64(28), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(4), T.int64(28), T.int64(28), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(128)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(4), T.int64(28), T.int64(28), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused in T.parallel(T.int64(28), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(7), T.int64(2)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(2)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(8)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(4), oc_chunk_1 * T.int64(4) + oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(4) * T.int64(4) + oh_1 + oh_2_init + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(4) // T.int64(2) * T.int64(14) + ow_1 * T.int64(2) + ow_2_init * T.int64(2) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(2) * T.int64(16) + oc_block_1 * T.int64(8) + oc_block_2_init * T.int64(8) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0 in range(T.int64(8)):
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(3), T.int64(4)):
                        for ax4_fused in T.vectorized(T.int64(16)):
                            with T.block("data_pad"):
                                v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                                v_i2 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(4) * T.int64(4) + oh_1 + ax2)
                                v_i3 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(4) // T.int64(2) * T.int64(14) + ow_1 * T.int64(2) + ax3)
                                v_i4 = T.axis.spatial(T.int64(128), ic_0 * T.int64(16) + ax4_fused)
                                T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                                T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                                data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                    for kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(1), T.int64(3), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(16), T.int64(3), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(2)):
                        for oc_block_3_fused in T.vectorized(T.int64(8)):
                            with T.block("conv2d_NCHWc_update"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                                v_oc_chunk = T.axis.spatial(T.int64(4), oc_chunk_1 * T.int64(4) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                                v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(4) * T.int64(4) + oh_1 + oh_2 + oh_3)
                                v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(4) // T.int64(2) * T.int64(14) + ow_1 * T.int64(2) + ow_2 * T.int64(2) + ow_3)
                                v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(2) * T.int64(16) + oc_block_1 * T.int64(8) + oc_block_2 * T.int64(8) + oc_block_3_fused)
                                v_ic = T.axis.reduce(T.int64(128), ic_0 * T.int64(16) + ic_1)
                                v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                                v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                                T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(4), T.int64(4), T.int64(14)):
                for ax4_fused in T.vectorized(T.int64(16)):
                    with T.block("T_relu"):
                        v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                        v_ax2 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(4) * T.int64(4) + ax2)
                        v_ax3 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(4) // T.int64(2) * T.int64(14) + ax3)
                        v_ax4 = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(2) * T.int64(16) + ax4_fused)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 2, 2])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[7, 4, 1, 1])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[2, 7, 1, 2])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[2, 2, 1, 8])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[8, 16])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[3, 1])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=10)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87 = sch.get_loops(block=b69)
l88 = sch.fuse(l72, l73, l74, l75, l76, preserve_unit_iters=True)
sch.parallel(loop=l88)
l89 = sch.fuse(l87, preserve_unit_iters=True)
sch.vectorize(loop=l89)
l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107, l108, l109, l110, l111 = sch.get_loops(block=b70)
l112 = sch.fuse(l90, preserve_unit_iters=True)
sch.parallel(loop=l112)
l113 = sch.fuse(l111, preserve_unit_iters=True)
sch.vectorize(loop=l113)
sch.annotate(block_or_loop=l112, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l112, ann_key="pragma_unroll_explicit", ann_val=1)
l114, l115, l116, l117, l118, l119 = sch.get_loops(block=b71)
l120 = sch.fuse(l119, preserve_unit_iters=True)
sch.vectorize(loop=l120)
b121 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141, l142, l143 = sch.get_loops(block=b121)
b144 = sch.decompose_reduction(block=b121, loop=l128)
2024-04-29 04:07:55 [INFO] [task_scheduler.cc:121] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #81: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(128)), "float32"), p1: T.Buffer((T.int64(4), T.int64(1), T.int64(3), T.int64(3), T.int64(128), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(32)), "float32"), p3: T.Buffer((T.int64(1), T.int64(4), T.int64(28), T.int64(28), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(4), T.int64(28), T.int64(28), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(128)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(4), T.int64(28), T.int64(28), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused in T.parallel(T.int64(28), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(7), T.int64(2)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(2)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(8)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(4), oc_chunk_1 * T.int64(4) + oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(4) * T.int64(4) + oh_1 + oh_2_init + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(4) // T.int64(2) * T.int64(14) + ow_1 * T.int64(2) + ow_2_init * T.int64(2) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(2) * T.int64(16) + oc_block_1 * T.int64(8) + oc_block_2_init * T.int64(8) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0 in range(T.int64(8)):
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(3), T.int64(4)):
                        for ax4_fused in T.vectorized(T.int64(16)):
                            with T.block("data_pad"):
                                v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                                v_i2 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(4) * T.int64(4) + oh_1 + ax2)
                                v_i3 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(4) // T.int64(2) * T.int64(14) + ow_1 * T.int64(2) + ax3)
                                v_i4 = T.axis.spatial(T.int64(128), ic_0 * T.int64(16) + ax4_fused)
                                T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                                T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                                data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                    for kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(16), T.int64(3), T.int64(3), T.int64(1), T.int64(2), T.int64(1), T.int64(2)):
                        for oc_block_3_fused in T.vectorized(T.int64(8)):
                            with T.block("conv2d_NCHWc_update"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                                v_oc_chunk = T.axis.spatial(T.int64(4), oc_chunk_1 * T.int64(4) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                                v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(4) * T.int64(4) + oh_1 + oh_2 + oh_3)
                                v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(4) // T.int64(2) * T.int64(14) + ow_1 * T.int64(2) + ow_2 * T.int64(2) + ow_3)
                                v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(2) * T.int64(16) + oc_block_1 * T.int64(8) + oc_block_2 * T.int64(8) + oc_block_3_fused)
                                v_ic = T.axis.reduce(T.int64(128), ic_0 * T.int64(16) + ic_1)
                                v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                                v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                                T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(4), T.int64(4), T.int64(14)):
                for ax4_fused in T.vectorized(T.int64(16)):
                    with T.block("T_relu"):
                        v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                        v_ax2 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(4) * T.int64(4) + ax2)
                        v_ax3 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(4) // T.int64(2) * T.int64(14) + ax3)
                        v_ax4 = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(2) * T.int64(16) + ax4_fused)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 2, 2])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[7, 4, 1, 1])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[2, 7, 1, 2])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[2, 2, 1, 8])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[8, 16])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[1, 3])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=10)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87 = sch.get_loops(block=b69)
l88 = sch.fuse(l72, l73, l74, l75, l76, preserve_unit_iters=True)
sch.parallel(loop=l88)
l89 = sch.fuse(l87, preserve_unit_iters=True)
sch.vectorize(loop=l89)
l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107, l108, l109, l110, l111 = sch.get_loops(block=b70)
l112 = sch.fuse(l90, preserve_unit_iters=True)
sch.parallel(loop=l112)
l113 = sch.fuse(l111, preserve_unit_iters=True)
sch.vectorize(loop=l113)
sch.annotate(block_or_loop=l112, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l112, ann_key="pragma_unroll_explicit", ann_val=1)
l114, l115, l116, l117, l118, l119 = sch.get_loops(block=b71)
l120 = sch.fuse(l119, preserve_unit_iters=True)
sch.vectorize(loop=l120)
b121 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141, l142, l143 = sch.get_loops(block=b121)
b144 = sch.decompose_reduction(block=b121, loop=l128)
2024-04-29 04:07:55 [INFO] [task_scheduler.cc:121] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #82: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(128)), "float32"), p1: T.Buffer((T.int64(4), T.int64(1), T.int64(3), T.int64(3), T.int64(128), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(32)), "float32"), p3: T.Buffer((T.int64(1), T.int64(4), T.int64(28), T.int64(28), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(4), T.int64(28), T.int64(28), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(128)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(4), T.int64(28), T.int64(28), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused in T.parallel(T.int64(196), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(6), T.int64(4), T.int64(128)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(98) // T.int64(14) * T.int64(4) + ax2)
                    v_i3 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(14) * T.int64(2) + ax3)
                    v_i4 = T.axis.spatial(T.int64(128), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oc_block_1 in range(T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(2), T.int64(2), T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(2), T.int64(2)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(8)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(4), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(98) * T.int64(2) + oc_chunk_2_init + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(98) // T.int64(14) * T.int64(4) + oh_2_init * T.int64(2) + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(14) * T.int64(2) + ow_2_init * T.int64(2) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2_init * T.int64(8) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(2), T.int64(1), T.int64(3), T.int64(1), T.int64(2), T.int64(2), T.int64(1), T.int64(4), T.int64(64), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(2)):
                    for oc_block_3_fused in T.vectorized(T.int64(8)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(4), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(98) * T.int64(2) + oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(98) // T.int64(14) * T.int64(4) + oh_2 * T.int64(2) + oh_3)
                            v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(14) * T.int64(2) + ow_2 * T.int64(2) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2 * T.int64(8) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(128), ic_0 * T.int64(64) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
                for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(2), T.int64(4)):
                    for ax3_ax4_fused in T.vectorized(T.int64(64)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(4), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(98) * T.int64(2) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(98) // T.int64(14) * T.int64(4) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(14) * T.int64(2) + ax3_ax4_fused // T.int64(32))
                            v_ax4 = T.axis.spatial(T.int64(32), ax3_ax4_fused % T.int64(32))
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 1, 2, 1])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[7, 1, 2, 2])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[2, 7, 1, 2])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[1, 1, 4, 8])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[2, 64])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[3, 1])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l50, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=8)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85 = sch.get_loops(block=b69)
l86 = sch.fuse(l72, l73, l74, l75, l76, l77, l78, l79, l80, preserve_unit_iters=True)
sch.parallel(loop=l86)
l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b70)
l105 = sch.fuse(l87, preserve_unit_iters=True)
sch.parallel(loop=l105)
l106 = sch.fuse(l104, preserve_unit_iters=True)
sch.vectorize(loop=l106)
sch.annotate(block_or_loop=l105, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l105, ann_key="pragma_unroll_explicit", ann_val=1)
l107, l108, l109, l110, l111, l112, l113 = sch.get_loops(block=b71)
l114 = sch.fuse(l112, l113, preserve_unit_iters=True)
sch.vectorize(loop=l114)
b115 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133 = sch.get_loops(block=b115)
b134 = sch.decompose_reduction(block=b115, loop=l118)
2024-04-29 04:07:55 [INFO] [task_scheduler.cc:121] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #83: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(128)), "float32"), p1: T.Buffer((T.int64(4), T.int64(1), T.int64(3), T.int64(3), T.int64(128), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(32)), "float32"), p3: T.Buffer((T.int64(1), T.int64(4), T.int64(28), T.int64(28), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(4), T.int64(28), T.int64(28), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(128)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(4), T.int64(28), T.int64(28), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused in T.parallel(T.int64(28), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(7), T.int64(2)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(2)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(8)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(4), oc_chunk_1 * T.int64(4) + oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(4) * T.int64(4) + oh_1 + oh_2_init + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(4) // T.int64(2) * T.int64(14) + ow_1 * T.int64(2) + ow_2_init * T.int64(2) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(2) * T.int64(16) + oc_block_1 * T.int64(8) + oc_block_2_init * T.int64(8) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0 in range(T.int64(8)):
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(3), T.int64(4)):
                        for ax4_fused in T.vectorized(T.int64(16)):
                            with T.block("data_pad"):
                                v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                                v_i2 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(4) * T.int64(4) + oh_1 + ax2)
                                v_i3 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(4) // T.int64(2) * T.int64(14) + ow_1 * T.int64(2) + ax3)
                                v_i4 = T.axis.spatial(T.int64(128), ic_0 * T.int64(16) + ax4_fused)
                                T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                                T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                                data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                    for kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(3), T.int64(3), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(2)):
                        for oc_block_3_fused in T.vectorized(T.int64(8)):
                            with T.block("conv2d_NCHWc_update"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                                v_oc_chunk = T.axis.spatial(T.int64(4), oc_chunk_1 * T.int64(4) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                                v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(4) * T.int64(4) + oh_1 + oh_2 + oh_3)
                                v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(4) // T.int64(2) * T.int64(14) + ow_1 * T.int64(2) + ow_2 * T.int64(2) + ow_3)
                                v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(2) * T.int64(16) + oc_block_1 * T.int64(8) + oc_block_2 * T.int64(8) + oc_block_3_fused)
                                v_ic = T.axis.reduce(T.int64(128), ic_0 * T.int64(16) + ic_1)
                                v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                                v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                                T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(4), T.int64(4), T.int64(14)):
                for ax4_fused in T.vectorized(T.int64(16)):
                    with T.block("T_relu"):
                        v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                        v_ax2 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(4) * T.int64(4) + ax2)
                        v_ax3 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(4) // T.int64(2) * T.int64(14) + ax3)
                        v_ax4 = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(2) * T.int64(16) + ax4_fused)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 2, 2])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[7, 4, 1, 1])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[2, 7, 1, 2])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[2, 2, 1, 8])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[8, 16])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[3, 1])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=10)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87 = sch.get_loops(block=b69)
l88 = sch.fuse(l72, l73, l74, l75, l76, preserve_unit_iters=True)
sch.parallel(loop=l88)
l89 = sch.fuse(l87, preserve_unit_iters=True)
sch.vectorize(loop=l89)
l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107, l108, l109, l110, l111 = sch.get_loops(block=b70)
l112 = sch.fuse(l90, preserve_unit_iters=True)
sch.parallel(loop=l112)
l113 = sch.fuse(l111, preserve_unit_iters=True)
sch.vectorize(loop=l113)
sch.annotate(block_or_loop=l112, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l112, ann_key="pragma_unroll_explicit", ann_val=1)
l114, l115, l116, l117, l118, l119 = sch.get_loops(block=b71)
l120 = sch.fuse(l119, preserve_unit_iters=True)
sch.vectorize(loop=l120)
b121 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141, l142, l143 = sch.get_loops(block=b121)
b144 = sch.decompose_reduction(block=b121, loop=l128)
2024-04-29 04:07:55 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #84: GFLOPs: 49.4206. Time: 4684.5258 us. Best GFLOPs: 241.2331
2024-04-29 04:07:55 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #85: GFLOPs: 144.7704. Time: 1599.1667 us. Best GFLOPs: 241.2331
2024-04-29 04:07:55 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #86: GFLOPs: 271.7494. Time: 851.9321 us. Best GFLOPs: 271.7494
2024-04-29 04:07:55 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #87: GFLOPs: 271.9515. Time: 851.2991 us. Best GFLOPs: 271.9515
2024-04-29 04:07:55 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #88: GFLOPs: 198.3920. Time: 1166.9427 us. Best GFLOPs: 271.9515
2024-04-29 04:07:55 [INFO] [task_scheduler.cc:121] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #89: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(128)), "float32"), p1: T.Buffer((T.int64(4), T.int64(1), T.int64(3), T.int64(3), T.int64(128), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(32)), "float32"), p3: T.Buffer((T.int64(1), T.int64(4), T.int64(28), T.int64(28), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(4), T.int64(28), T.int64(28), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(128)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(4), T.int64(28), T.int64(28), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused in T.parallel(T.int64(196), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(6), T.int64(4), T.int64(128)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(28) * T.int64(4) + ax2)
                    v_i3 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(28) // T.int64(14) * T.int64(14) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(7) * T.int64(2) + ax3)
                    v_i4 = T.axis.spatial(T.int64(128), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oc_block_1 in range(T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(4), T.int64(1), T.int64(2), T.int64(2), T.int64(2)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(8)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(4), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(14) // T.int64(7) * T.int64(2) + oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(28) * T.int64(4) + oh_2_init * T.int64(2) + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(28) // T.int64(14) * T.int64(14) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(7) * T.int64(2) + ow_2_init * T.int64(2) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2_init * T.int64(8) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(4), T.int64(64), T.int64(3), T.int64(3), T.int64(1), T.int64(2), T.int64(2), T.int64(2)):
                    for oc_block_3_fused in T.vectorized(T.int64(8)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(4), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(14) // T.int64(7) * T.int64(2) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(28) * T.int64(4) + oh_2 * T.int64(2) + oh_3)
                            v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(28) // T.int64(14) * T.int64(14) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(7) * T.int64(2) + ow_2 * T.int64(2) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2 * T.int64(8) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(128), ic_0 * T.int64(64) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
                for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(2), T.int64(4)):
                    for ax3_ax4_fused in T.vectorized(T.int64(64)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(4), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(14) // T.int64(7) * T.int64(2) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(28) * T.int64(4) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(28) // T.int64(14) * T.int64(14) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(7) * T.int64(2) + ax3_ax4_fused // T.int64(32))
                            v_ax4 = T.axis.spatial(T.int64(32), ax3_ax4_fused % T.int64(32))
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 2, 1, 2])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[7, 1, 2, 2])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[2, 7, 1, 2])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[1, 1, 4, 8])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[2, 64])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[1, 3])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l50, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=8)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85 = sch.get_loops(block=b69)
l86 = sch.fuse(l72, l73, l74, l75, l76, l77, l78, l79, l80, preserve_unit_iters=True)
sch.parallel(loop=l86)
l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b70)
l105 = sch.fuse(l87, preserve_unit_iters=True)
sch.parallel(loop=l105)
l106 = sch.fuse(l104, preserve_unit_iters=True)
sch.vectorize(loop=l106)
sch.annotate(block_or_loop=l105, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l105, ann_key="pragma_unroll_explicit", ann_val=1)
l107, l108, l109, l110, l111, l112, l113 = sch.get_loops(block=b71)
l114 = sch.fuse(l112, l113, preserve_unit_iters=True)
sch.vectorize(loop=l114)
b115 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133 = sch.get_loops(block=b115)
b134 = sch.decompose_reduction(block=b115, loop=l118)
2024-04-29 04:07:55 [INFO] [task_scheduler.cc:121] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #90: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(128)), "float32"), p1: T.Buffer((T.int64(4), T.int64(1), T.int64(3), T.int64(3), T.int64(128), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(32)), "float32"), p3: T.Buffer((T.int64(1), T.int64(4), T.int64(28), T.int64(28), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(4), T.int64(28), T.int64(28), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(128)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(4), T.int64(28), T.int64(28), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused in T.parallel(T.int64(196), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(6), T.int64(4), T.int64(128)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(28) * T.int64(4) + ax2)
                    v_i3 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(28) // T.int64(14) * T.int64(14) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(7) * T.int64(2) + ax3)
                    v_i4 = T.axis.spatial(T.int64(128), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oc_block_1 in range(T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(4), T.int64(1), T.int64(2), T.int64(2), T.int64(2)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(8)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(4), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(14) // T.int64(7) * T.int64(2) + oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(28) * T.int64(4) + oh_2_init * T.int64(2) + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(28) // T.int64(14) * T.int64(14) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(7) * T.int64(2) + ow_2_init * T.int64(2) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2_init * T.int64(8) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(2), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(4), T.int64(64), T.int64(3), T.int64(1), T.int64(1), T.int64(2), T.int64(2), T.int64(2)):
                    for oc_block_3_fused in T.vectorized(T.int64(8)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(4), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(14) // T.int64(7) * T.int64(2) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(28) * T.int64(4) + oh_2 * T.int64(2) + oh_3)
                            v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(28) // T.int64(14) * T.int64(14) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(7) * T.int64(2) + ow_2 * T.int64(2) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2 * T.int64(8) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(128), ic_0 * T.int64(64) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
                for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(2), T.int64(4)):
                    for ax3_ax4_fused in T.vectorized(T.int64(64)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(4), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(14) // T.int64(7) * T.int64(2) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(28) * T.int64(4) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(28) // T.int64(14) * T.int64(14) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(7) * T.int64(2) + ax3_ax4_fused // T.int64(32))
                            v_ax4 = T.axis.spatial(T.int64(32), ax3_ax4_fused % T.int64(32))
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 2, 1, 2])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[7, 1, 2, 2])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[2, 7, 1, 2])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[1, 1, 4, 8])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[2, 64])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[3, 1])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l50, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=8)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85 = sch.get_loops(block=b69)
l86 = sch.fuse(l72, l73, l74, l75, l76, l77, l78, l79, l80, preserve_unit_iters=True)
sch.parallel(loop=l86)
l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b70)
l105 = sch.fuse(l87, preserve_unit_iters=True)
sch.parallel(loop=l105)
l106 = sch.fuse(l104, preserve_unit_iters=True)
sch.vectorize(loop=l106)
sch.annotate(block_or_loop=l105, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l105, ann_key="pragma_unroll_explicit", ann_val=1)
l107, l108, l109, l110, l111, l112, l113 = sch.get_loops(block=b71)
l114 = sch.fuse(l112, l113, preserve_unit_iters=True)
sch.vectorize(loop=l114)
b115 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133 = sch.get_loops(block=b115)
b134 = sch.decompose_reduction(block=b115, loop=l118)
2024-04-29 04:07:55 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #91: GFLOPs: 66.0733. Time: 3503.8659 us. Best GFLOPs: 271.9515
2024-04-29 04:07:55 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #92: GFLOPs: 134.1129. Time: 1726.2470 us. Best GFLOPs: 271.9515
2024-04-29 04:07:56 [INFO] [task_scheduler.cc:121] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #93: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(128)), "float32"), p1: T.Buffer((T.int64(4), T.int64(1), T.int64(3), T.int64(3), T.int64(128), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(32)), "float32"), p3: T.Buffer((T.int64(1), T.int64(4), T.int64(28), T.int64(28), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(4), T.int64(28), T.int64(28), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(128)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(4), T.int64(28), T.int64(28), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused in T.parallel(T.int64(28), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(2), T.int64(4), T.int64(7), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(2), T.int64(1), T.int64(2)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(8)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(4), oc_chunk_1 * T.int64(2) + oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(4) * T.int64(4) + oh_1 + oh_2_init + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(4) // T.int64(2) * T.int64(14) + ow_1 * T.int64(2) + ow_2_init * T.int64(2) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(2) * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2_init * T.int64(8) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0 in range(T.int64(8)):
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(3), T.int64(4)):
                        for ax4_fused in T.vectorized(T.int64(16)):
                            with T.block("data_pad"):
                                v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                                v_i2 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(4) * T.int64(4) + oh_1 + ax2)
                                v_i3 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(4) // T.int64(2) * T.int64(14) + ow_1 * T.int64(2) + ax3)
                                v_i4 = T.axis.spatial(T.int64(128), ic_0 * T.int64(16) + ax4_fused)
                                T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                                T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                                data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                    for kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(16), T.int64(3), T.int64(3), T.int64(1), T.int64(2), T.int64(1), T.int64(2)):
                        for oc_block_3_fused in T.vectorized(T.int64(8)):
                            with T.block("conv2d_NCHWc_update"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                                v_oc_chunk = T.axis.spatial(T.int64(4), oc_chunk_1 * T.int64(2) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                                v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(4) * T.int64(4) + oh_1 + oh_2 + oh_3)
                                v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(4) // T.int64(2) * T.int64(14) + ow_1 * T.int64(2) + ow_2 * T.int64(2) + ow_3)
                                v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(2) * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2 * T.int64(8) + oc_block_3_fused)
                                v_ic = T.axis.reduce(T.int64(128), ic_0 * T.int64(16) + ic_1)
                                v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                                v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                                T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(4), T.int64(4), T.int64(14)):
                for ax4_fused in T.vectorized(T.int64(16)):
                    with T.block("T_relu"):
                        v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                        v_ax2 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(4) * T.int64(4) + ax2)
                        v_ax3 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(4) // T.int64(2) * T.int64(14) + ax3)
                        v_ax4 = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(2) * T.int64(16) + ax4_fused)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 2, 1, 2])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[7, 4, 1, 1])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[2, 7, 1, 2])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[2, 1, 2, 8])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[8, 16])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[1, 3])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=10)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87 = sch.get_loops(block=b69)
l88 = sch.fuse(l72, l73, l74, l75, l76, preserve_unit_iters=True)
sch.parallel(loop=l88)
l89 = sch.fuse(l87, preserve_unit_iters=True)
sch.vectorize(loop=l89)
l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107, l108, l109, l110, l111 = sch.get_loops(block=b70)
l112 = sch.fuse(l90, preserve_unit_iters=True)
sch.parallel(loop=l112)
l113 = sch.fuse(l111, preserve_unit_iters=True)
sch.vectorize(loop=l113)
sch.annotate(block_or_loop=l112, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l112, ann_key="pragma_unroll_explicit", ann_val=1)
l114, l115, l116, l117, l118, l119 = sch.get_loops(block=b71)
l120 = sch.fuse(l119, preserve_unit_iters=True)
sch.vectorize(loop=l120)
b121 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141, l142, l143 = sch.get_loops(block=b121)
b144 = sch.decompose_reduction(block=b121, loop=l128)
2024-04-29 04:07:56 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #94: GFLOPs: 186.1269. Time: 1243.8397 us. Best GFLOPs: 271.9515
2024-04-29 04:07:56 [INFO] [task_scheduler.cc:121] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #95: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(128)), "float32"), p1: T.Buffer((T.int64(4), T.int64(1), T.int64(3), T.int64(3), T.int64(128), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(32)), "float32"), p3: T.Buffer((T.int64(1), T.int64(4), T.int64(28), T.int64(28), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(4), T.int64(28), T.int64(28), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(128)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(4), T.int64(28), T.int64(28), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused in T.parallel(T.int64(196), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(6), T.int64(4), T.int64(128)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(28) * T.int64(4) + ax2)
                    v_i3 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(28) // T.int64(14) * T.int64(14) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(7) * T.int64(2) + ax3)
                    v_i4 = T.axis.spatial(T.int64(128), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oc_block_1 in range(T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(4), T.int64(1), T.int64(2), T.int64(2), T.int64(2)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(8)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(4), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(14) // T.int64(7) * T.int64(2) + oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(28) * T.int64(4) + oh_2_init * T.int64(2) + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(28) // T.int64(14) * T.int64(14) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(7) * T.int64(2) + ow_2_init * T.int64(2) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2_init * T.int64(8) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(2), T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(4), T.int64(64), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(2), T.int64(2)):
                    for oc_block_3_fused in T.vectorized(T.int64(8)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(4), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(14) // T.int64(7) * T.int64(2) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(28) * T.int64(4) + oh_2 * T.int64(2) + oh_3)
                            v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(28) // T.int64(14) * T.int64(14) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(7) * T.int64(2) + ow_2 * T.int64(2) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2 * T.int64(8) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(128), ic_0 * T.int64(64) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
                for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(2), T.int64(4)):
                    for ax3_ax4_fused in T.vectorized(T.int64(64)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(4), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(14) // T.int64(7) * T.int64(2) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(28) * T.int64(4) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(28) // T.int64(14) * T.int64(14) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(7) * T.int64(2) + ax3_ax4_fused // T.int64(32))
                            v_ax4 = T.axis.spatial(T.int64(32), ax3_ax4_fused % T.int64(32))
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 2, 1, 2])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[7, 1, 2, 2])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[2, 7, 1, 2])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[1, 1, 4, 8])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[2, 64])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[3, 1])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l50, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=8)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85 = sch.get_loops(block=b69)
l86 = sch.fuse(l72, l73, l74, l75, l76, l77, l78, l79, l80, preserve_unit_iters=True)
sch.parallel(loop=l86)
l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b70)
l105 = sch.fuse(l87, preserve_unit_iters=True)
sch.parallel(loop=l105)
l106 = sch.fuse(l104, preserve_unit_iters=True)
sch.vectorize(loop=l106)
sch.annotate(block_or_loop=l105, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l105, ann_key="pragma_unroll_explicit", ann_val=1)
l107, l108, l109, l110, l111, l112, l113 = sch.get_loops(block=b71)
l114 = sch.fuse(l112, l113, preserve_unit_iters=True)
sch.vectorize(loop=l114)
b115 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133 = sch.get_loops(block=b115)
b134 = sch.decompose_reduction(block=b115, loop=l118)
2024-04-29 04:07:56 [INFO] [task_scheduler.cc:121] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #96: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(128)), "float32"), p1: T.Buffer((T.int64(4), T.int64(1), T.int64(3), T.int64(3), T.int64(128), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(32)), "float32"), p3: T.Buffer((T.int64(1), T.int64(4), T.int64(28), T.int64(28), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(4), T.int64(28), T.int64(28), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(128)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(4), T.int64(28), T.int64(28), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused in T.parallel(T.int64(196), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(6), T.int64(4), T.int64(128)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(49) // T.int64(7) * T.int64(4) + ax2)
                    v_i3 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(98) * T.int64(14) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(7) * T.int64(2) + ax3)
                    v_i4 = T.axis.spatial(T.int64(128), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oc_block_1 in range(T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(4), T.int64(1), T.int64(2), T.int64(2), T.int64(2)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(8)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(4), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(98) // T.int64(49) * T.int64(2) + oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(49) // T.int64(7) * T.int64(4) + oh_2_init * T.int64(2) + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(98) * T.int64(14) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(7) * T.int64(2) + ow_2_init * T.int64(2) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2_init * T.int64(8) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(2), T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(4), T.int64(64), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(2), T.int64(2)):
                    for oc_block_3_fused in T.vectorized(T.int64(8)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(4), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(98) // T.int64(49) * T.int64(2) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(49) // T.int64(7) * T.int64(4) + oh_2 * T.int64(2) + oh_3)
                            v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(98) * T.int64(14) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(7) * T.int64(2) + ow_2 * T.int64(2) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2 * T.int64(8) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(128), ic_0 * T.int64(64) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
                for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(2), T.int64(4)):
                    for ax3_ax4_fused in T.vectorized(T.int64(64)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(4), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(98) // T.int64(49) * T.int64(2) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(49) // T.int64(7) * T.int64(4) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(98) * T.int64(14) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(7) * T.int64(2) + ax3_ax4_fused // T.int64(32))
                            v_ax4 = T.axis.spatial(T.int64(32), ax3_ax4_fused % T.int64(32))
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 2, 1, 2])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 7, 2, 2])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[2, 7, 1, 2])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[1, 1, 4, 8])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[2, 64])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[3, 1])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l50, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=8)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85 = sch.get_loops(block=b69)
l86 = sch.fuse(l72, l73, l74, l75, l76, l77, l78, l79, l80, preserve_unit_iters=True)
sch.parallel(loop=l86)
l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b70)
l105 = sch.fuse(l87, preserve_unit_iters=True)
sch.parallel(loop=l105)
l106 = sch.fuse(l104, preserve_unit_iters=True)
sch.vectorize(loop=l106)
sch.annotate(block_or_loop=l105, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l105, ann_key="pragma_unroll_explicit", ann_val=1)
l107, l108, l109, l110, l111, l112, l113 = sch.get_loops(block=b71)
l114 = sch.fuse(l112, l113, preserve_unit_iters=True)
sch.vectorize(loop=l114)
b115 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133 = sch.get_loops(block=b115)
b134 = sch.decompose_reduction(block=b115, loop=l118)
2024-04-29 04:07:56 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #97: GFLOPs: 120.7642. Time: 1917.0595 us. Best GFLOPs: 271.9515
2024-04-29 04:07:56 [INFO] [task_scheduler.cc:121] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #98: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(128)), "float32"), p1: T.Buffer((T.int64(4), T.int64(1), T.int64(3), T.int64(3), T.int64(128), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(32)), "float32"), p3: T.Buffer((T.int64(1), T.int64(4), T.int64(28), T.int64(28), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(4), T.int64(28), T.int64(28), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(128)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(4), T.int64(28), T.int64(28), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused in T.parallel(T.int64(392), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(6), T.int64(4), T.int64(128)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(196) // T.int64(28) * T.int64(4) + ax2)
                    v_i3 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(28) // T.int64(14) * T.int64(14) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(7) * T.int64(2) + ax3)
                    v_i4 = T.axis.spatial(T.int64(128), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oc_block_1 in range(T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(2), T.int64(2)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(8)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(4), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(196) * T.int64(2) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(14) // T.int64(7) + oc_chunk_2_init + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(196) // T.int64(28) * T.int64(4) + oh_2_init * T.int64(2) + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(28) // T.int64(14) * T.int64(14) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(7) * T.int64(2) + ow_2_init * T.int64(2) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2_init * T.int64(8) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(2), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(4), T.int64(64), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(2)):
                    for oc_block_3_fused in T.vectorized(T.int64(8)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(4), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(196) * T.int64(2) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(14) // T.int64(7) + oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(196) // T.int64(28) * T.int64(4) + oh_2 * T.int64(2) + oh_3)
                            v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(28) // T.int64(14) * T.int64(14) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(7) * T.int64(2) + ow_2 * T.int64(2) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2 * T.int64(8) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(128), ic_0 * T.int64(64) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
                for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(1), T.int64(4)):
                    for ax3_ax4_fused in T.vectorized(T.int64(64)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(4), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(196) * T.int64(2) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(14) // T.int64(7) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(196) // T.int64(28) * T.int64(4) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(28) // T.int64(14) * T.int64(14) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(7) * T.int64(2) + ax3_ax4_fused // T.int64(32))
                            v_ax4 = T.axis.spatial(T.int64(32), ax3_ax4_fused % T.int64(32))
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 2, 1, 1])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[7, 1, 2, 2])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[2, 7, 1, 2])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[1, 1, 4, 8])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[2, 64])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[3, 1])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l50, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=8)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85 = sch.get_loops(block=b69)
l86 = sch.fuse(l72, l73, l74, l75, l76, l77, l78, l79, l80, preserve_unit_iters=True)
sch.parallel(loop=l86)
l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b70)
l105 = sch.fuse(l87, preserve_unit_iters=True)
sch.parallel(loop=l105)
l106 = sch.fuse(l104, preserve_unit_iters=True)
sch.vectorize(loop=l106)
sch.annotate(block_or_loop=l105, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l105, ann_key="pragma_unroll_explicit", ann_val=1)
l107, l108, l109, l110, l111, l112, l113 = sch.get_loops(block=b71)
l114 = sch.fuse(l112, l113, preserve_unit_iters=True)
sch.vectorize(loop=l114)
b115 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133 = sch.get_loops(block=b115)
b134 = sch.decompose_reduction(block=b115, loop=l118)
2024-04-29 04:07:56 [INFO] [task_scheduler.cc:121] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #99: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(128)), "float32"), p1: T.Buffer((T.int64(4), T.int64(1), T.int64(3), T.int64(3), T.int64(128), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(32)), "float32"), p3: T.Buffer((T.int64(1), T.int64(4), T.int64(28), T.int64(28), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(4), T.int64(28), T.int64(28), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(128)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(4), T.int64(28), T.int64(28), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused in T.parallel(T.int64(224), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(7), T.int64(2), T.int64(1), T.int64(2), T.int64(2), T.int64(1)):
                for oc_block_3_fused_init in T.vectorized(T.int64(4)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(4), oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(56) // T.int64(4) * T.int64(2) + oh_2_init * T.int64(2) + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(112) * T.int64(14) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(4) // T.int64(2) * T.int64(7) + ow_2_init + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(112) // T.int64(56) * T.int64(16) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(2) * T.int64(8) + oc_block_2_init * T.int64(4) + oc_block_3_fused_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
            for ic_0, kh_0, kw_0 in T.grid(T.int64(4), T.int64(1), T.int64(3)):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(7)):
                    for ax4_fused in T.vectorized(T.int64(32)):
                        with T.block("data_pad"):
                            v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                            v_i2 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(56) // T.int64(4) * T.int64(2) + ax2)
                            v_i3 = T.axis.spatial(T.int64(30), kw_0 + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(112) * T.int64(14) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(4) // T.int64(2) * T.int64(7) + ax3)
                            v_i4 = T.axis.spatial(T.int64(128), ic_0 * T.int64(32) + ax4_fused)
                            T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                            T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                            data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                for n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(7), T.int64(2), T.int64(32), T.int64(3), T.int64(1), T.int64(1), T.int64(2), T.int64(2), T.int64(1)):
                    for oc_block_3_fused in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(4), oc_chunk_2 * T.int64(2) + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(56) // T.int64(4) * T.int64(2) + oh_2 * T.int64(2) + oh_3)
                            v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(112) * T.int64(14) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(4) // T.int64(2) * T.int64(7) + ow_2 + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(112) // T.int64(56) * T.int64(16) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(2) * T.int64(8) + oc_block_2 * T.int64(4) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(128), ic_0 * T.int64(32) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(4), T.int64(2), T.int64(7)):
                for ax4_fused in T.vectorized(T.int64(8)):
                    with T.block("T_relu"):
                        v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                        v_ax2 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(56) // T.int64(4) * T.int64(2) + ax2)
                        v_ax3 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(112) * T.int64(14) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(4) // T.int64(2) * T.int64(7) + ax3)
                        v_ax4 = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(112) // T.int64(56) * T.int64(16) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(2) * T.int64(8) + ax4_fused)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 2, 2])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 14, 1, 2])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[2, 2, 7, 1])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[2, 2, 2, 4])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[4, 32])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[3, 1])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l50, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=12)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89 = sch.get_loops(block=b69)
l90 = sch.fuse(l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, preserve_unit_iters=True)
sch.parallel(loop=l90)
l91 = sch.fuse(l89, preserve_unit_iters=True)
sch.vectorize(loop=l91)
l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107, l108 = sch.get_loops(block=b70)
l109 = sch.fuse(l92, preserve_unit_iters=True)
sch.parallel(loop=l109)
l110 = sch.fuse(l108, preserve_unit_iters=True)
sch.vectorize(loop=l110)
sch.annotate(block_or_loop=l109, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l109, ann_key="pragma_unroll_explicit", ann_val=1)
l111, l112, l113, l114, l115, l116 = sch.get_loops(block=b71)
l117 = sch.fuse(l116, preserve_unit_iters=True)
sch.vectorize(loop=l117)
b118 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135 = sch.get_loops(block=b118)
b136 = sch.decompose_reduction(block=b118, loop=l120)
2024-04-29 04:07:56 [INFO] [task_scheduler.cc:121] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #100: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(128)), "float32"), p1: T.Buffer((T.int64(4), T.int64(1), T.int64(3), T.int64(3), T.int64(128), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(32)), "float32"), p3: T.Buffer((T.int64(1), T.int64(4), T.int64(28), T.int64(28), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(4), T.int64(28), T.int64(28), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(128)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(4), T.int64(28), T.int64(28), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused in T.parallel(T.int64(196), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(6), T.int64(4), T.int64(128)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(28) * T.int64(4) + ax2)
                    v_i3 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(28) // T.int64(14) * T.int64(14) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(7) * T.int64(2) + ax3)
                    v_i4 = T.axis.spatial(T.int64(128), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oc_block_1 in range(T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(1), T.int64(2), T.int64(4), T.int64(2)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(8)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(4), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(14) // T.int64(7) * T.int64(2) + oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(28) * T.int64(4) + oh_2_init * T.int64(4) + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(28) // T.int64(14) * T.int64(14) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(7) * T.int64(2) + ow_2_init * T.int64(2) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2_init * T.int64(8) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(2), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(64), T.int64(3), T.int64(1), T.int64(1), T.int64(2), T.int64(4), T.int64(2)):
                    for oc_block_3_fused in T.vectorized(T.int64(8)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(4), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(14) // T.int64(7) * T.int64(2) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(28) * T.int64(4) + oh_2 * T.int64(4) + oh_3)
                            v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(28) // T.int64(14) * T.int64(14) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(7) * T.int64(2) + ow_2 * T.int64(2) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2 * T.int64(8) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(128), ic_0 * T.int64(64) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
                for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(2), T.int64(4)):
                    for ax3_ax4_fused in T.vectorized(T.int64(64)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(4), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(14) // T.int64(7) * T.int64(2) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(28) * T.int64(4) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(28) // T.int64(14) * T.int64(14) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(7) * T.int64(2) + ax3_ax4_fused // T.int64(32))
                            v_ax4 = T.axis.spatial(T.int64(32), ax3_ax4_fused % T.int64(32))
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 2, 1, 2])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[7, 1, 1, 4])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[2, 7, 1, 2])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[1, 1, 4, 8])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[2, 64])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[3, 1])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l50, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=8)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85 = sch.get_loops(block=b69)
l86 = sch.fuse(l72, l73, l74, l75, l76, l77, l78, l79, l80, preserve_unit_iters=True)
sch.parallel(loop=l86)
l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b70)
l105 = sch.fuse(l87, preserve_unit_iters=True)
sch.parallel(loop=l105)
l106 = sch.fuse(l104, preserve_unit_iters=True)
sch.vectorize(loop=l106)
sch.annotate(block_or_loop=l105, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l105, ann_key="pragma_unroll_explicit", ann_val=1)
l107, l108, l109, l110, l111, l112, l113 = sch.get_loops(block=b71)
l114 = sch.fuse(l112, l113, preserve_unit_iters=True)
sch.vectorize(loop=l114)
b115 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133 = sch.get_loops(block=b115)
b134 = sch.decompose_reduction(block=b115, loop=l118)
2024-04-29 04:07:56 [INFO] [task_scheduler.cc:121] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #101: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(128)), "float32"), p1: T.Buffer((T.int64(4), T.int64(1), T.int64(3), T.int64(3), T.int64(128), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(32)), "float32"), p3: T.Buffer((T.int64(1), T.int64(4), T.int64(28), T.int64(28), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(4), T.int64(28), T.int64(28), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(128)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(4), T.int64(28), T.int64(28), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused in T.parallel(T.int64(196), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(6), T.int64(4), T.int64(128)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(49) // T.int64(7) * T.int64(4) + ax2)
                    v_i3 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(98) * T.int64(14) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(7) * T.int64(2) + ax3)
                    v_i4 = T.axis.spatial(T.int64(128), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oc_block_1 in range(T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(1), T.int64(2), T.int64(4), T.int64(2)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(8)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(4), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(98) // T.int64(49) * T.int64(2) + oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(49) // T.int64(7) * T.int64(4) + oh_2_init * T.int64(4) + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(98) * T.int64(14) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(7) * T.int64(2) + ow_2_init * T.int64(2) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2_init * T.int64(8) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(2), T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(64), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(4), T.int64(2)):
                    for oc_block_3_fused in T.vectorized(T.int64(8)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(4), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(98) // T.int64(49) * T.int64(2) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(49) // T.int64(7) * T.int64(4) + oh_2 * T.int64(4) + oh_3)
                            v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(98) * T.int64(14) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(7) * T.int64(2) + ow_2 * T.int64(2) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2 * T.int64(8) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(128), ic_0 * T.int64(64) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
                for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(2), T.int64(4)):
                    for ax3_ax4_fused in T.vectorized(T.int64(64)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(4), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(98) // T.int64(49) * T.int64(2) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(49) // T.int64(7) * T.int64(4) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(98) * T.int64(14) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(7) * T.int64(2) + ax3_ax4_fused // T.int64(32))
                            v_ax4 = T.axis.spatial(T.int64(32), ax3_ax4_fused % T.int64(32))
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 2, 1, 2])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 7, 1, 4])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[2, 7, 1, 2])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[1, 1, 4, 8])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[2, 64])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[3, 1])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l50, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=8)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85 = sch.get_loops(block=b69)
l86 = sch.fuse(l72, l73, l74, l75, l76, l77, l78, l79, l80, preserve_unit_iters=True)
sch.parallel(loop=l86)
l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b70)
l105 = sch.fuse(l87, preserve_unit_iters=True)
sch.parallel(loop=l105)
l106 = sch.fuse(l104, preserve_unit_iters=True)
sch.vectorize(loop=l106)
sch.annotate(block_or_loop=l105, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l105, ann_key="pragma_unroll_explicit", ann_val=1)
l107, l108, l109, l110, l111, l112, l113 = sch.get_loops(block=b71)
l114 = sch.fuse(l112, l113, preserve_unit_iters=True)
sch.vectorize(loop=l114)
b115 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133 = sch.get_loops(block=b115)
b134 = sch.decompose_reduction(block=b115, loop=l118)
2024-04-29 04:07:56 [INFO] [task_scheduler.cc:121] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #102: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(128)), "float32"), p1: T.Buffer((T.int64(4), T.int64(1), T.int64(3), T.int64(3), T.int64(128), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(32)), "float32"), p3: T.Buffer((T.int64(1), T.int64(4), T.int64(28), T.int64(28), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(4), T.int64(28), T.int64(28), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(128)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(4), T.int64(28), T.int64(28), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused in T.parallel(T.int64(196), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(6), T.int64(4), T.int64(128)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(28) * T.int64(4) + ax2)
                    v_i3 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(28) // T.int64(14) * T.int64(14) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(7) * T.int64(2) + ax3)
                    v_i4 = T.axis.spatial(T.int64(128), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oc_block_1 in range(T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(1), T.int64(2), T.int64(4), T.int64(2)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(8)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(4), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(14) // T.int64(7) * T.int64(2) + oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(28) * T.int64(4) + oh_2_init * T.int64(4) + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(28) // T.int64(14) * T.int64(14) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(7) * T.int64(2) + ow_2_init * T.int64(2) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2_init * T.int64(8) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(2), T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(64), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(4), T.int64(2)):
                    for oc_block_3_fused in T.vectorized(T.int64(8)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(4), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(14) // T.int64(7) * T.int64(2) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(28) * T.int64(4) + oh_2 * T.int64(4) + oh_3)
                            v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(28) // T.int64(14) * T.int64(14) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(7) * T.int64(2) + ow_2 * T.int64(2) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2 * T.int64(8) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(128), ic_0 * T.int64(64) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
                for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(2), T.int64(4)):
                    for ax3_ax4_fused in T.vectorized(T.int64(64)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(4), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(14) // T.int64(7) * T.int64(2) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(28) * T.int64(4) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(28) // T.int64(14) * T.int64(14) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(7) * T.int64(2) + ax3_ax4_fused // T.int64(32))
                            v_ax4 = T.axis.spatial(T.int64(32), ax3_ax4_fused % T.int64(32))
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 2, 1, 2])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[7, 1, 1, 4])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[2, 7, 1, 2])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[1, 1, 4, 8])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[2, 64])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[3, 1])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l50, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=8)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85 = sch.get_loops(block=b69)
l86 = sch.fuse(l72, l73, l74, l75, l76, l77, l78, l79, l80, preserve_unit_iters=True)
sch.parallel(loop=l86)
l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b70)
l105 = sch.fuse(l87, preserve_unit_iters=True)
sch.parallel(loop=l105)
l106 = sch.fuse(l104, preserve_unit_iters=True)
sch.vectorize(loop=l106)
sch.annotate(block_or_loop=l105, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l105, ann_key="pragma_unroll_explicit", ann_val=1)
l107, l108, l109, l110, l111, l112, l113 = sch.get_loops(block=b71)
l114 = sch.fuse(l112, l113, preserve_unit_iters=True)
sch.vectorize(loop=l114)
b115 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133 = sch.get_loops(block=b115)
b134 = sch.decompose_reduction(block=b115, loop=l118)
2024-04-29 04:07:56 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #103: GFLOPs: 191.7152. Time: 1207.5834 us. Best GFLOPs: 271.9515
2024-04-29 04:07:56 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #104: GFLOPs: 104.4181. Time: 2217.1645 us. Best GFLOPs: 271.9515
2024-04-29 04:07:56 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #105: GFLOPs: 129.5298. Time: 1787.3272 us. Best GFLOPs: 271.9515
2024-04-29 04:07:56 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #106: GFLOPs: 109.7765. Time: 2108.9405 us. Best GFLOPs: 271.9515
2024-04-29 04:07:56 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #107: GFLOPs: 113.3669. Time: 2042.1495 us. Best GFLOPs: 271.9515
2024-04-29 04:07:56 [INFO] [task_scheduler.cc:121] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #108: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(128)), "float32"), p1: T.Buffer((T.int64(4), T.int64(1), T.int64(3), T.int64(3), T.int64(128), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(32)), "float32"), p3: T.Buffer((T.int64(1), T.int64(4), T.int64(28), T.int64(28), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(4), T.int64(28), T.int64(28), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(128)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(4), T.int64(28), T.int64(28), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused in T.parallel(T.int64(28), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(2), T.int64(4), T.int64(7), T.int64(2)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(2)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(8)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(4), oc_chunk_1 * T.int64(2) + oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(4) * T.int64(4) + oh_1 + oh_2_init + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(4) // T.int64(2) * T.int64(14) + ow_1 * T.int64(2) + ow_2_init * T.int64(2) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(2) * T.int64(16) + oc_block_1 * T.int64(8) + oc_block_2_init * T.int64(8) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0 in range(T.int64(8)):
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(3), T.int64(4)):
                        for ax4_fused in T.vectorized(T.int64(16)):
                            with T.block("data_pad"):
                                v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                                v_i2 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(4) * T.int64(4) + oh_1 + ax2)
                                v_i3 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(4) // T.int64(2) * T.int64(14) + ow_1 * T.int64(2) + ax3)
                                v_i4 = T.axis.spatial(T.int64(128), ic_0 * T.int64(16) + ax4_fused)
                                T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                                T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                                data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                    for kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(16), T.int64(3), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(2)):
                        for oc_block_3_fused in T.vectorized(T.int64(8)):
                            with T.block("conv2d_NCHWc_update"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                                v_oc_chunk = T.axis.spatial(T.int64(4), oc_chunk_1 * T.int64(2) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                                v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(4) * T.int64(4) + oh_1 + oh_2 + oh_3)
                                v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(4) // T.int64(2) * T.int64(14) + ow_1 * T.int64(2) + ow_2 * T.int64(2) + ow_3)
                                v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(2) * T.int64(16) + oc_block_1 * T.int64(8) + oc_block_2 * T.int64(8) + oc_block_3_fused)
                                v_ic = T.axis.reduce(T.int64(128), ic_0 * T.int64(16) + ic_1)
                                v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                                v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                                T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(4), T.int64(4), T.int64(14)):
                for ax4_fused in T.vectorized(T.int64(16)):
                    with T.block("T_relu"):
                        v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                        v_ax2 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(4) * T.int64(4) + ax2)
                        v_ax3 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(4) // T.int64(2) * T.int64(14) + ax3)
                        v_ax4 = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(2) * T.int64(16) + ax4_fused)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 2, 1, 2])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[7, 4, 1, 1])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[2, 7, 1, 2])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[2, 2, 1, 8])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[8, 16])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[3, 1])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=10)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87 = sch.get_loops(block=b69)
l88 = sch.fuse(l72, l73, l74, l75, l76, preserve_unit_iters=True)
sch.parallel(loop=l88)
l89 = sch.fuse(l87, preserve_unit_iters=True)
sch.vectorize(loop=l89)
l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107, l108, l109, l110, l111 = sch.get_loops(block=b70)
l112 = sch.fuse(l90, preserve_unit_iters=True)
sch.parallel(loop=l112)
l113 = sch.fuse(l111, preserve_unit_iters=True)
sch.vectorize(loop=l113)
sch.annotate(block_or_loop=l112, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l112, ann_key="pragma_unroll_explicit", ann_val=1)
l114, l115, l116, l117, l118, l119 = sch.get_loops(block=b71)
l120 = sch.fuse(l119, preserve_unit_iters=True)
sch.vectorize(loop=l120)
b121 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141, l142, l143 = sch.get_loops(block=b121)
b144 = sch.decompose_reduction(block=b121, loop=l128)
2024-04-29 04:07:56 [INFO] [task_scheduler.cc:121] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #109: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(128)), "float32"), p1: T.Buffer((T.int64(4), T.int64(1), T.int64(3), T.int64(3), T.int64(128), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(32)), "float32"), p3: T.Buffer((T.int64(1), T.int64(4), T.int64(28), T.int64(28), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(4), T.int64(28), T.int64(28), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(128)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(4), T.int64(28), T.int64(28), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused in T.parallel(T.int64(28), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(2), T.int64(4), T.int64(7), T.int64(2)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(2)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(8)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(4), oc_chunk_1 * T.int64(2) + oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(4) * T.int64(4) + oh_1 + oh_2_init + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(4) // T.int64(2) * T.int64(14) + ow_1 * T.int64(2) + ow_2_init * T.int64(2) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(2) * T.int64(16) + oc_block_1 * T.int64(8) + oc_block_2_init * T.int64(8) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0 in range(T.int64(8)):
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(3), T.int64(4)):
                        for ax4_fused in T.vectorized(T.int64(16)):
                            with T.block("data_pad"):
                                v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                                v_i2 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(4) * T.int64(4) + oh_1 + ax2)
                                v_i3 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(4) // T.int64(2) * T.int64(14) + ow_1 * T.int64(2) + ax3)
                                v_i4 = T.axis.spatial(T.int64(128), ic_0 * T.int64(16) + ax4_fused)
                                T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                                T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                                data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                    for kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(16), T.int64(3), T.int64(3), T.int64(1), T.int64(2), T.int64(1), T.int64(2)):
                        for oc_block_3_fused in T.vectorized(T.int64(8)):
                            with T.block("conv2d_NCHWc_update"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                                v_oc_chunk = T.axis.spatial(T.int64(4), oc_chunk_1 * T.int64(2) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                                v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(4) * T.int64(4) + oh_1 + oh_2 + oh_3)
                                v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(4) // T.int64(2) * T.int64(14) + ow_1 * T.int64(2) + ow_2 * T.int64(2) + ow_3)
                                v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(2) * T.int64(16) + oc_block_1 * T.int64(8) + oc_block_2 * T.int64(8) + oc_block_3_fused)
                                v_ic = T.axis.reduce(T.int64(128), ic_0 * T.int64(16) + ic_1)
                                v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                                v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                                T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(4), T.int64(4), T.int64(14)):
                for ax4_fused in T.vectorized(T.int64(16)):
                    with T.block("T_relu"):
                        v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                        v_ax2 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(4) * T.int64(4) + ax2)
                        v_ax3 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(4) // T.int64(2) * T.int64(14) + ax3)
                        v_ax4 = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(2) * T.int64(16) + ax4_fused)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 2, 1, 2])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[7, 4, 1, 1])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[2, 7, 1, 2])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[2, 2, 1, 8])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[8, 16])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[1, 3])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=10)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87 = sch.get_loops(block=b69)
l88 = sch.fuse(l72, l73, l74, l75, l76, preserve_unit_iters=True)
sch.parallel(loop=l88)
l89 = sch.fuse(l87, preserve_unit_iters=True)
sch.vectorize(loop=l89)
l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107, l108, l109, l110, l111 = sch.get_loops(block=b70)
l112 = sch.fuse(l90, preserve_unit_iters=True)
sch.parallel(loop=l112)
l113 = sch.fuse(l111, preserve_unit_iters=True)
sch.vectorize(loop=l113)
sch.annotate(block_or_loop=l112, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l112, ann_key="pragma_unroll_explicit", ann_val=1)
l114, l115, l116, l117, l118, l119 = sch.get_loops(block=b71)
l120 = sch.fuse(l119, preserve_unit_iters=True)
sch.vectorize(loop=l120)
b121 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141, l142, l143 = sch.get_loops(block=b121)
b144 = sch.decompose_reduction(block=b121, loop=l128)
2024-04-29 04:07:56 [INFO] [task_scheduler.cc:121] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #110: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(128)), "float32"), p1: T.Buffer((T.int64(4), T.int64(1), T.int64(3), T.int64(3), T.int64(128), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(32)), "float32"), p3: T.Buffer((T.int64(1), T.int64(4), T.int64(28), T.int64(28), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(4), T.int64(28), T.int64(28), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(128)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(4), T.int64(28), T.int64(28), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused in T.parallel(T.int64(392), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4), T.int64(128)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(28) * T.int64(2) + ax2)
                    v_i3 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(28) // T.int64(14) * T.int64(14) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(7) * T.int64(2) + ax3)
                    v_i4 = T.axis.spatial(T.int64(128), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oc_block_1 in range(T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(4), T.int64(1), T.int64(2), T.int64(1), T.int64(2)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(8)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(4), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(14) // T.int64(7) * T.int64(2) + oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(28) * T.int64(2) + oh_2_init + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(28) // T.int64(14) * T.int64(14) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(7) * T.int64(2) + ow_2_init * T.int64(2) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2_init * T.int64(8) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(2), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(4), T.int64(64), T.int64(3), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(2)):
                    for oc_block_3_fused in T.vectorized(T.int64(8)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(4), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(14) // T.int64(7) * T.int64(2) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(28) * T.int64(2) + oh_2 + oh_3)
                            v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(28) // T.int64(14) * T.int64(14) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(7) * T.int64(2) + ow_2 * T.int64(2) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2 * T.int64(8) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(128), ic_0 * T.int64(64) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
                for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(2), T.int64(2)):
                    for ax3_ax4_fused in T.vectorized(T.int64(64)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(4), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(14) // T.int64(7) * T.int64(2) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(28) * T.int64(2) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(28) // T.int64(14) * T.int64(14) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(7) * T.int64(2) + ax3_ax4_fused // T.int64(32))
                            v_ax4 = T.axis.spatial(T.int64(32), ax3_ax4_fused % T.int64(32))
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 2, 1, 2])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[14, 1, 2, 1])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[2, 7, 1, 2])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[1, 1, 4, 8])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[2, 64])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[3, 1])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l50, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=8)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85 = sch.get_loops(block=b69)
l86 = sch.fuse(l72, l73, l74, l75, l76, l77, l78, l79, l80, preserve_unit_iters=True)
sch.parallel(loop=l86)
l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b70)
l105 = sch.fuse(l87, preserve_unit_iters=True)
sch.parallel(loop=l105)
l106 = sch.fuse(l104, preserve_unit_iters=True)
sch.vectorize(loop=l106)
sch.annotate(block_or_loop=l105, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l105, ann_key="pragma_unroll_explicit", ann_val=1)
l107, l108, l109, l110, l111, l112, l113 = sch.get_loops(block=b71)
l114 = sch.fuse(l112, l113, preserve_unit_iters=True)
sch.vectorize(loop=l114)
b115 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133 = sch.get_loops(block=b115)
b134 = sch.decompose_reduction(block=b115, loop=l118)
2024-04-29 04:07:56 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #111: GFLOPs: 77.1943. Time: 2999.0825 us. Best GFLOPs: 271.9515
2024-04-29 04:07:56 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #112: GFLOPs: 123.9808. Time: 1867.3219 us. Best GFLOPs: 271.9515
2024-04-29 04:07:56 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #113: GFLOPs: 89.7761. Time: 2578.7708 us. Best GFLOPs: 271.9515
2024-04-29 04:07:56 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #114: GFLOPs: 142.9727. Time: 1619.2742 us. Best GFLOPs: 271.9515
2024-04-29 04:07:56 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #115: GFLOPs: 219.5125. Time: 1054.6644 us. Best GFLOPs: 271.9515
2024-04-29 04:07:56 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #116: GFLOPs: 99.5919. Time: 2324.6085 us. Best GFLOPs: 271.9515
2024-04-29 04:07:56 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #117: GFLOPs: 74.7842. Time: 3095.7355 us. Best GFLOPs: 271.9515
2024-04-29 04:07:56 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #118: GFLOPs: 110.9637. Time: 2086.3766 us. Best GFLOPs: 271.9515
2024-04-29 04:07:56 [INFO] [task_scheduler.cc:121] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #119: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(128)), "float32"), p1: T.Buffer((T.int64(4), T.int64(1), T.int64(3), T.int64(3), T.int64(128), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(32)), "float32"), p3: T.Buffer((T.int64(1), T.int64(4), T.int64(28), T.int64(28), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(4), T.int64(28), T.int64(28), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(128)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(4), T.int64(28), T.int64(28), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused in T.parallel(T.int64(392), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4), T.int64(128)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(196) // T.int64(14) * T.int64(2) + ax2)
                    v_i3 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(14) * T.int64(2) + ax3)
                    v_i4 = T.axis.spatial(T.int64(128), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oc_block_1 in range(T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(2), T.int64(2)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(16)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(4), oc_chunk_2_init * T.int64(4) + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(196) // T.int64(14) * T.int64(2) + oh_2_init * T.int64(2) + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(14) * T.int64(2) + ow_2_init * T.int64(2) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(196) * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2_init * T.int64(16) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(128), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(4), T.int64(2), T.int64(2)):
                    for oc_block_3_fused in T.vectorized(T.int64(16)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(4), oc_chunk_2 * T.int64(4) + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(196) // T.int64(14) * T.int64(2) + oh_2 * T.int64(2) + oh_3)
                            v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(14) * T.int64(2) + ow_2 * T.int64(2) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(196) * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2 * T.int64(16) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(128), ic_0 + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(4), T.int64(2), T.int64(2)):
                    for ax4_fused in T.vectorized(T.int64(16)):
                        with T.block("T_relu"):
                            v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                            v_ax2 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(196) // T.int64(14) * T.int64(2) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(14) * T.int64(2) + ax3)
                            v_ax4 = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(196) * T.int64(16) + ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 1, 4])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 14, 1, 2])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 14, 1, 2])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[2, 1, 1, 16])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[128, 1])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[3, 1])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l50, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=8)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85 = sch.get_loops(block=b69)
l86 = sch.fuse(l72, l73, l74, l75, l76, l77, l78, l79, l80, preserve_unit_iters=True)
sch.parallel(loop=l86)
l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b70)
l105 = sch.fuse(l87, preserve_unit_iters=True)
sch.parallel(loop=l105)
l106 = sch.fuse(l104, preserve_unit_iters=True)
sch.vectorize(loop=l106)
sch.annotate(block_or_loop=l105, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l105, ann_key="pragma_unroll_explicit", ann_val=1)
l107, l108, l109, l110, l111, l112, l113 = sch.get_loops(block=b71)
l114 = sch.fuse(l113, preserve_unit_iters=True)
sch.vectorize(loop=l114)
b115 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133 = sch.get_loops(block=b115)
b134 = sch.decompose_reduction(block=b115, loop=l118)
2024-04-29 04:07:56 [INFO] [task_scheduler.cc:121] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #120: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(128)), "float32"), p1: T.Buffer((T.int64(4), T.int64(1), T.int64(3), T.int64(3), T.int64(128), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(32)), "float32"), p3: T.Buffer((T.int64(1), T.int64(4), T.int64(28), T.int64(28), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(4), T.int64(28), T.int64(28), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(128)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(4), T.int64(28), T.int64(28), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused in T.parallel(T.int64(392), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4), T.int64(128)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(196) // T.int64(14) * T.int64(2) + ax2)
                    v_i3 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(14) * T.int64(2) + ax3)
                    v_i4 = T.axis.spatial(T.int64(128), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oc_block_1 in range(T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(2), T.int64(2)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(16)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(4), oc_chunk_2_init * T.int64(4) + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(196) // T.int64(14) * T.int64(2) + oh_2_init * T.int64(2) + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(14) * T.int64(2) + ow_2_init * T.int64(2) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(196) * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2_init * T.int64(16) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(128), T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(2), T.int64(2)):
                    for oc_block_3_fused in T.vectorized(T.int64(16)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(4), oc_chunk_2 * T.int64(4) + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(196) // T.int64(14) * T.int64(2) + oh_2 * T.int64(2) + oh_3)
                            v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(14) * T.int64(2) + ow_2 * T.int64(2) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(196) * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2 * T.int64(16) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(128), ic_0 + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(4), T.int64(2), T.int64(2)):
                    for ax4_fused in T.vectorized(T.int64(16)):
                        with T.block("T_relu"):
                            v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                            v_ax2 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(196) // T.int64(14) * T.int64(2) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(14) * T.int64(2) + ax3)
                            v_ax4 = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(196) * T.int64(16) + ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 1, 4])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 14, 1, 2])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 14, 1, 2])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[2, 1, 1, 16])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[128, 1])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[3, 1])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l50, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=8)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85 = sch.get_loops(block=b69)
l86 = sch.fuse(l72, l73, l74, l75, l76, l77, l78, l79, l80, preserve_unit_iters=True)
sch.parallel(loop=l86)
l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b70)
l105 = sch.fuse(l87, preserve_unit_iters=True)
sch.parallel(loop=l105)
l106 = sch.fuse(l104, preserve_unit_iters=True)
sch.vectorize(loop=l106)
sch.annotate(block_or_loop=l105, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l105, ann_key="pragma_unroll_explicit", ann_val=1)
l107, l108, l109, l110, l111, l112, l113 = sch.get_loops(block=b71)
l114 = sch.fuse(l113, preserve_unit_iters=True)
sch.vectorize(loop=l114)
b115 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133 = sch.get_loops(block=b115)
b134 = sch.decompose_reduction(block=b115, loop=l118)
2024-04-29 04:07:56 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #121: GFLOPs: 89.1859. Time: 2595.8360 us. Best GFLOPs: 271.9515
2024-04-29 04:07:56 [INFO] [task_scheduler.cc:121] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #122: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(128)), "float32"), p1: T.Buffer((T.int64(4), T.int64(1), T.int64(3), T.int64(3), T.int64(128), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(32)), "float32"), p3: T.Buffer((T.int64(1), T.int64(4), T.int64(28), T.int64(28), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(4), T.int64(28), T.int64(28), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(128)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(4), T.int64(28), T.int64(28), T.int64(32)))
        for i0_i1_i2_i3_fused in T.parallel(T.int64(900)):
            for i4 in range(T.int64(128)):
                with T.block("data_pad"):
                    v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_i1 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_i2 = T.axis.spatial(T.int64(30), i0_i1_i2_i3_fused // T.int64(30))
                    v_i3 = T.axis.spatial(T.int64(30), i0_i1_i2_i3_fused % T.int64(30))
                    v_i4 = T.axis.spatial(T.int64(128), i4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused in T.parallel(T.int64(56), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(2), T.int64(28), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(4)):
                for oc_block_3_fused_init in T.vectorized(T.int64(4)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(4), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(2) * T.int64(2) + oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(28), oh_2_init + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused // T.int64(8) * T.int64(4) + ow_2_init * T.int64(4) + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(8) // T.int64(2) * T.int64(8) + oc_block_2_init * T.int64(4) + oc_block_3_fused_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
            for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(64), T.int64(3), T.int64(3), T.int64(1), T.int64(2), T.int64(28), T.int64(1), T.int64(2), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(4)):
                for oc_block_3_fused in T.vectorized(T.int64(4)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(4), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(2) * T.int64(2) + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(28), oh_2 + oh_3)
                        v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused // T.int64(8) * T.int64(4) + ow_2 * T.int64(4) + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(8) // T.int64(2) * T.int64(8) + oc_block_2 * T.int64(4) + oc_block_3_fused)
                        v_ic = T.axis.reduce(T.int64(128), ic_0 * T.int64(2) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(2), T.int64(28), T.int64(4)):
                for ax4_fused in T.vectorized(T.int64(8)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(4), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(2) * T.int64(2) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(28), ax2)
                        v_ax3 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused // T.int64(8) * T.int64(4) + ax3)
                        v_ax4 = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(8) // T.int64(2) * T.int64(8) + ax4_fused)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 2, 2, 1])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 28, 1])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[7, 1, 1, 4])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[4, 1, 2, 4])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[64, 2])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[3, 1])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l50, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=-1)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76 = sch.get_loops(block=b69)
l77 = sch.fuse(l72, l73, l74, l75, preserve_unit_iters=True)
sch.parallel(loop=l77)
l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b70)
l104 = sch.fuse(l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, preserve_unit_iters=True)
sch.parallel(loop=l104)
l105 = sch.fuse(l103, preserve_unit_iters=True)
sch.vectorize(loop=l105)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l106, l107, l108, l109, l110, l111 = sch.get_loops(block=b71)
l112 = sch.fuse(l111, preserve_unit_iters=True)
sch.vectorize(loop=l112)
b113 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130 = sch.get_loops(block=b113)
b131 = sch.decompose_reduction(block=b113, loop=l115)
2024-04-29 04:07:56 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #123: GFLOPs: 206.3547. Time: 1121.9131 us. Best GFLOPs: 271.9515
2024-04-29 04:07:56 [INFO] [task_scheduler.cc:121] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #124: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(128)), "float32"), p1: T.Buffer((T.int64(4), T.int64(1), T.int64(3), T.int64(3), T.int64(128), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(32)), "float32"), p3: T.Buffer((T.int64(1), T.int64(4), T.int64(28), T.int64(28), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(4), T.int64(28), T.int64(28), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(4), T.int64(28), T.int64(28), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused in T.parallel(T.int64(784), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(4), T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                for oc_block_3_fused_init in T.vectorized(T.int64(4)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(4), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(8) // T.int64(4) * T.int64(2) + oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused // T.int64(56) * T.int64(2) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(4) // T.int64(2) + oh_2_init + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(56) // T.int64(8) * T.int64(4) + ow_2_init + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(2) * T.int64(16) + oc_block_2_init * T.int64(4) + oc_block_3_fused_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
            for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(2), T.int64(3), T.int64(3), T.int64(1), T.int64(2), T.int64(1), T.int64(4), T.int64(4), T.int64(64), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                for oc_block_3_fused in T.vectorized(T.int64(4)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(4), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(8) // T.int64(4) * T.int64(2) + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused // T.int64(56) * T.int64(2) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(4) // T.int64(2) + oh_2 + oh_3)
                        v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(56) // T.int64(8) * T.int64(4) + ow_2 + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(2) * T.int64(16) + oc_block_2 * T.int64(4) + oc_block_3_fused)
                        v_ic = T.axis.reduce(T.int64(128), ic_0 * T.int64(64) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], p0[v_n, v_ic // T.int64(128), v_oh + v_kh - T.int64(1), v_ow + v_kw - T.int64(1), v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + T.if_then_else(T.int64(1) <= v_oh + v_kh and v_oh + v_kh < T.int64(29) and T.int64(1) <= v_ow + v_kw and v_ow + v_kw < T.int64(29), p0[v_n, v_ic // T.int64(128), v_oh + v_kh - T.int64(1), v_ow + v_kw - T.int64(1), v_ic % T.int64(128)], T.float32(0)) * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(4)):
                for ax4_fused in T.vectorized(T.int64(16)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(4), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(8) // T.int64(4) * T.int64(2) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused // T.int64(56) * T.int64(2) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(4) // T.int64(2) + ax2)
                        v_ax3 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(56) // T.int64(8) * T.int64(4) + ax3)
                        v_ax4 = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(2) * T.int64(16) + ax4_fused)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 2, 2, 1])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[14, 2, 1, 1])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[7, 1, 4, 1])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[1, 2, 4, 4])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[2, 64])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[3, 1])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l50, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=-2)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70 = sch.get_child_blocks(b68)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96 = sch.get_loops(block=b69)
l97 = sch.fuse(l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, preserve_unit_iters=True)
sch.parallel(loop=l97)
l98 = sch.fuse(l96, preserve_unit_iters=True)
sch.vectorize(loop=l98)
sch.annotate(block_or_loop=l97, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l97, ann_key="pragma_unroll_explicit", ann_val=1)
l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b70)
l105 = sch.fuse(l104, preserve_unit_iters=True)
sch.vectorize(loop=l105)
b106 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117, l118, l119, l120, l121, l122, l123 = sch.get_loops(block=b106)
b124 = sch.decompose_reduction(block=b106, loop=l108)
2024-04-29 04:07:56 [INFO] [task_scheduler.cc:121] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #125: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(128)), "float32"), p1: T.Buffer((T.int64(4), T.int64(1), T.int64(3), T.int64(3), T.int64(128), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(32)), "float32"), p3: T.Buffer((T.int64(1), T.int64(4), T.int64(28), T.int64(28), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(4), T.int64(28), T.int64(28), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(128)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(4), T.int64(28), T.int64(28), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused in T.parallel(T.int64(392), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4), T.int64(128)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(196) * T.int64(14) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(98) // T.int64(14) * T.int64(2) + ax2)
                    v_i3 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(14) * T.int64(2) + ax3)
                    v_i4 = T.axis.spatial(T.int64(128), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oc_block_1 in range(T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(2), T.int64(2)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(16)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(4), oc_chunk_2_init * T.int64(4) + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(196) * T.int64(14) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(98) // T.int64(14) * T.int64(2) + oh_2_init * T.int64(2) + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(14) * T.int64(2) + ow_2_init * T.int64(2) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(196) // T.int64(98) * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2_init * T.int64(16) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(128), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(4), T.int64(2), T.int64(2)):
                    for oc_block_3_fused in T.vectorized(T.int64(16)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(4), oc_chunk_2 * T.int64(4) + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(196) * T.int64(14) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(98) // T.int64(14) * T.int64(2) + oh_2 * T.int64(2) + oh_3)
                            v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(14) * T.int64(2) + ow_2 * T.int64(2) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(196) // T.int64(98) * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2 * T.int64(16) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(128), ic_0 + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(4), T.int64(2), T.int64(2)):
                    for ax4_fused in T.vectorized(T.int64(16)):
                        with T.block("T_relu"):
                            v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                            v_ax2 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(196) * T.int64(14) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(98) // T.int64(14) * T.int64(2) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(14) * T.int64(2) + ax3)
                            v_ax4 = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(196) // T.int64(98) * T.int64(16) + ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 1, 4])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[2, 7, 1, 2])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 14, 1, 2])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[2, 1, 1, 16])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[128, 1])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[3, 1])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l50, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=8)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85 = sch.get_loops(block=b69)
l86 = sch.fuse(l72, l73, l74, l75, l76, l77, l78, l79, l80, preserve_unit_iters=True)
sch.parallel(loop=l86)
l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b70)
l105 = sch.fuse(l87, preserve_unit_iters=True)
sch.parallel(loop=l105)
l106 = sch.fuse(l104, preserve_unit_iters=True)
sch.vectorize(loop=l106)
sch.annotate(block_or_loop=l105, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l105, ann_key="pragma_unroll_explicit", ann_val=1)
l107, l108, l109, l110, l111, l112, l113 = sch.get_loops(block=b71)
l114 = sch.fuse(l113, preserve_unit_iters=True)
sch.vectorize(loop=l114)
b115 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133 = sch.get_loops(block=b115)
b134 = sch.decompose_reduction(block=b115, loop=l118)
2024-04-29 04:07:56 [INFO] [task_scheduler.cc:121] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #126: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(128)), "float32"), p1: T.Buffer((T.int64(4), T.int64(1), T.int64(3), T.int64(3), T.int64(128), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(32)), "float32"), p3: T.Buffer((T.int64(1), T.int64(4), T.int64(28), T.int64(28), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(4), T.int64(28), T.int64(28), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(128)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(4), T.int64(28), T.int64(28), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused in T.parallel(T.int64(56), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1 in T.grid(T.int64(1), T.int64(2)):
                for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(6), T.int64(30), T.int64(128)):
                    with T.block("data_pad"):
                        v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                        v_i2 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(8) * T.int64(4) + ax2)
                        v_i3, v_i4 = T.axis.remap("SS", [ax3, ax4])
                        T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                        T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                        data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                for oh_1, ow_1, oc_block_1 in T.grid(T.int64(2), T.int64(2), T.int64(1)):
                    for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(2), T.int64(14)):
                        for oc_block_3_fused_init in T.vectorized(T.int64(2)):
                            with T.block("conv2d_NCHWc_init"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                                v_oc_chunk = T.axis.spatial(T.int64(4), oc_chunk_1 * T.int64(2) + oc_chunk_2_init + oc_chunk_3_init)
                                v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(8) * T.int64(4) + oh_1 * T.int64(2) + oh_2_init * T.int64(2) + oh_3_init)
                                v_ow = T.axis.spatial(T.int64(28), ow_1 * T.int64(14) + ow_2_init * T.int64(14) + ow_3_init)
                                v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(8) * T.int64(4) + oc_block_1 * T.int64(4) + oc_block_2_init * T.int64(2) + oc_block_3_fused_init)
                                T.reads()
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                    for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(8), T.int64(1), T.int64(3), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(2), T.int64(16), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(14)):
                        for oc_block_3_fused in T.vectorized(T.int64(2)):
                            with T.block("conv2d_NCHWc_update"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                                v_oc_chunk = T.axis.spatial(T.int64(4), oc_chunk_1 * T.int64(2) + oc_chunk_2 + oc_chunk_3)
                                v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(8) * T.int64(4) + oh_1 * T.int64(2) + oh_2 * T.int64(2) + oh_3)
                                v_ow = T.axis.spatial(T.int64(28), ow_1 * T.int64(14) + ow_2 * T.int64(14) + ow_3)
                                v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(8) * T.int64(4) + oc_block_1 * T.int64(4) + oc_block_2 * T.int64(2) + oc_block_3_fused)
                                v_ic = T.axis.reduce(T.int64(128), ic_0 * T.int64(16) + ic_1)
                                v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                                v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                                T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(4), T.int64(4), T.int64(28)):
                for ax4_fused in T.vectorized(T.int64(4)):
                    with T.block("T_relu"):
                        v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                        v_ax2 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(8) * T.int64(4) + ax2)
                        v_ax3 = T.axis.spatial(T.int64(28), ax3)
                        v_ax4 = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(8) * T.int64(4) + ax4_fused)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 2, 2, 1])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[7, 2, 1, 2])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 2, 1, 14])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[8, 1, 2, 2])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[8, 16])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[3, 1])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=6)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83 = sch.get_loops(block=b69)
l84 = sch.fuse(l72, l73, l74, l75, l76, preserve_unit_iters=True)
sch.parallel(loop=l84)
l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106 = sch.get_loops(block=b70)
l107 = sch.fuse(l85, preserve_unit_iters=True)
sch.parallel(loop=l107)
l108 = sch.fuse(l106, preserve_unit_iters=True)
sch.vectorize(loop=l108)
sch.annotate(block_or_loop=l107, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l107, ann_key="pragma_unroll_explicit", ann_val=1)
l109, l110, l111, l112, l113, l114 = sch.get_loops(block=b71)
l115 = sch.fuse(l114, preserve_unit_iters=True)
sch.vectorize(loop=l115)
b116 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138 = sch.get_loops(block=b116)
b139 = sch.decompose_reduction(block=b116, loop=l123)
2024-04-29 04:07:56 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #127: GFLOPs: 79.8187. Time: 2900.4757 us. Best GFLOPs: 271.9515
2024-04-29 04:07:56 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #128: GFLOPs: 81.1309. Time: 2853.5617 us. Best GFLOPs: 271.9515
2024-04-29 04:23:08 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 04:23:09 [INFO] [evolutionary_search.cc:715] Picked top 98 candidate(s) from database
2024-04-29 04:23:14 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4391338)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x38dd208)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x4182678)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x6ddeb88)]: 0 failure(s)
2024-04-29 04:23:14 [INFO] [evolutionary_search.cc:723] Sampled 414 candidate(s)
2024-04-29 04:23:26 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4391338)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x38dd208)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x4182678)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x6ddeb88)]: 0 failure(s)
2024-04-29 04:23:39 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4391338)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x38dd208)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x4182678)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x6ddeb88)]: 0 failure(s)
2024-04-29 04:23:53 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4391338)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x38dd208)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x4182678)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x6ddeb88)]: 0 failure(s)
2024-04-29 04:24:06 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4391338)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x38dd208)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x4182678)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x6ddeb88)]: 0 failure(s)
2024-04-29 04:24:14 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	1.0158  0.9836  0.9827  0.9476  0.9240  0.9098  0.9098  0.9098  0.8931  0.8815  0.8550  0.8533  0.8533  0.8533  0.8533  0.8511
[17 : 32]:	0.8409  0.8402  0.8381  0.8338  0.8308  0.8109  0.8109  0.8091  0.8088  0.8032  0.7990  0.7922  0.7921  0.7921  0.7893  0.7764
[33 : 48]:	0.7702  0.7654  0.7605  0.7589  0.7589  0.7512  0.7454  0.7446  0.7440  0.7423  0.7390  0.7269  0.7180  0.7169  0.7168  0.7039
[49 : 64]:	0.6895  0.6877  0.6877  0.6856  0.6847  0.6845  0.6825  0.6825  0.6795  0.6751  0.6730  0.6730  0.6672  0.6669  0.6669  0.6665
2024-04-29 04:24:14 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 04:24:14 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 04:25:39 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #129: GFLOPs: 228.8200. Time: 1011.7651 us. Best GFLOPs: 271.9515
2024-04-29 04:25:39 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #130: GFLOPs: 200.9640. Time: 1152.0075 us. Best GFLOPs: 271.9515
2024-04-29 04:25:39 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #131: GFLOPs: 157.9759. Time: 1465.4895 us. Best GFLOPs: 271.9515
2024-04-29 04:25:39 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #132: GFLOPs: 187.0412. Time: 1237.7600 us. Best GFLOPs: 271.9515
2024-04-29 04:25:39 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #133: GFLOPs: 244.2601. Time: 947.8098 us. Best GFLOPs: 271.9515
2024-04-29 04:25:39 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #134: GFLOPs: 185.2343. Time: 1249.8339 us. Best GFLOPs: 271.9515
2024-04-29 04:25:39 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #135: GFLOPs: 215.1371. Time: 1076.1139 us. Best GFLOPs: 271.9515
2024-04-29 04:25:39 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #136: GFLOPs: 200.6619. Time: 1153.7419 us. Best GFLOPs: 271.9515
2024-04-29 04:25:39 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #137: GFLOPs: 170.5837. Time: 1357.1755 us. Best GFLOPs: 271.9515
2024-04-29 04:25:39 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #138: GFLOPs: 176.6476. Time: 1310.5869 us. Best GFLOPs: 271.9515
2024-04-29 04:25:39 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #139: GFLOPs: 339.3495. Time: 682.2231 us. Best GFLOPs: 339.3495
2024-04-29 04:25:39 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #140: GFLOPs: 97.5984. Time: 2372.0882 us. Best GFLOPs: 339.3495
2024-04-29 04:25:39 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #141: GFLOPs: 244.3357. Time: 947.5164 us. Best GFLOPs: 339.3495
2024-04-29 04:25:39 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #142: GFLOPs: 177.3101. Time: 1305.6899 us. Best GFLOPs: 339.3495
2024-04-29 04:25:39 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #143: GFLOPs: 111.7263. Time: 2072.1351 us. Best GFLOPs: 339.3495
2024-04-29 04:25:39 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #144: GFLOPs: 77.7808. Time: 2976.4693 us. Best GFLOPs: 339.3495
2024-04-29 04:25:39 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #145: GFLOPs: 151.9935. Time: 1523.1713 us. Best GFLOPs: 339.3495
2024-04-29 04:25:39 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #146: GFLOPs: 179.9077. Time: 1286.8382 us. Best GFLOPs: 339.3495
2024-04-29 04:25:39 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #147: GFLOPs: 72.0346. Time: 3213.9021 us. Best GFLOPs: 339.3495
2024-04-29 04:25:39 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #148: GFLOPs: 113.1314. Time: 2046.3998 us. Best GFLOPs: 339.3495
2024-04-29 04:25:39 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #149: GFLOPs: 76.3210. Time: 3033.4003 us. Best GFLOPs: 339.3495
2024-04-29 04:25:39 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #150: GFLOPs: 149.9795. Time: 1543.6251 us. Best GFLOPs: 339.3495
2024-04-29 04:25:39 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #151: GFLOPs: 175.7046. Time: 1317.6208 us. Best GFLOPs: 339.3495
2024-04-29 04:25:39 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #152: GFLOPs: 106.1372. Time: 2181.2531 us. Best GFLOPs: 339.3495
2024-04-29 04:25:39 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #153: GFLOPs: 235.3924. Time: 983.5156 us. Best GFLOPs: 339.3495
2024-04-29 04:25:39 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #154: GFLOPs: 215.4356. Time: 1074.6230 us. Best GFLOPs: 339.3495
2024-04-29 04:25:39 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #155: GFLOPs: 147.3933. Time: 1570.7095 us. Best GFLOPs: 339.3495
2024-04-29 04:25:39 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #156: GFLOPs: 226.9195. Time: 1020.2386 us. Best GFLOPs: 339.3495
2024-04-29 04:25:39 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #157: GFLOPs: 210.5052. Time: 1099.7926 us. Best GFLOPs: 339.3495
2024-04-29 04:25:39 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #158: GFLOPs: 210.5301. Time: 1099.6625 us. Best GFLOPs: 339.3495
2024-04-29 04:25:39 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #159: GFLOPs: 231.8624. Time: 998.4890 us. Best GFLOPs: 339.3495
2024-04-29 04:25:39 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #160: GFLOPs: 171.7092. Time: 1348.2801 us. Best GFLOPs: 339.3495
2024-04-29 04:25:39 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #161: GFLOPs: 188.7351. Time: 1226.6508 us. Best GFLOPs: 339.3495
2024-04-29 04:25:39 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #162: GFLOPs: 122.0710. Time: 1896.5355 us. Best GFLOPs: 339.3495
2024-04-29 04:25:39 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #163: GFLOPs: 13.5774. Time: 17051.3195 us. Best GFLOPs: 339.3495
2024-04-29 04:25:39 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #164: GFLOPs: 149.7961. Time: 1545.5147 us. Best GFLOPs: 339.3495
2024-04-29 04:25:39 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #165: GFLOPs: 149.4676. Time: 1548.9111 us. Best GFLOPs: 339.3495
2024-04-29 04:25:39 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #166: GFLOPs: 149.5439. Time: 1548.1209 us. Best GFLOPs: 339.3495
2024-04-29 04:25:39 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #167: GFLOPs: 78.4436. Time: 2951.3203 us. Best GFLOPs: 339.3495
2024-04-29 04:25:39 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #168: GFLOPs: 197.7052. Time: 1170.9966 us. Best GFLOPs: 339.3495
2024-04-29 04:25:39 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #169: GFLOPs: 86.7723. Time: 2668.0400 us. Best GFLOPs: 339.3495
2024-04-29 04:25:39 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #170: GFLOPs: 152.1158. Time: 1521.9464 us. Best GFLOPs: 339.3495
2024-04-29 04:25:39 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #171: GFLOPs: 194.6539. Time: 1189.3521 us. Best GFLOPs: 339.3495
2024-04-29 04:25:39 [INFO] [task_scheduler.cc:121] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #172: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(128)), "float32"), p1: T.Buffer((T.int64(4), T.int64(1), T.int64(3), T.int64(3), T.int64(128), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(32)), "float32"), p3: T.Buffer((T.int64(1), T.int64(4), T.int64(28), T.int64(28), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(4), T.int64(28), T.int64(28), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(4), T.int64(28), T.int64(28), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused in T.parallel(T.int64(784), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(4)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(2), T.int64(2), T.int64(8), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(4), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused % T.int64(4) + oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused // T.int64(56) * T.int64(2) + oh_1 * T.int64(2) + oh_2_init + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused % T.int64(56) // T.int64(4) * T.int64(2) + ow_1 * T.int64(2) + ow_2_init + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(8) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(2), T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(2), T.int64(2), T.int64(8), T.int64(64), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(4), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused % T.int64(4) + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused // T.int64(56) * T.int64(2) + oh_1 * T.int64(2) + oh_2 + oh_3)
                        v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused % T.int64(56) // T.int64(4) * T.int64(2) + ow_1 * T.int64(2) + ow_2 + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(8) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(128), ic_0 * T.int64(64) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], p0[v_n, v_ic // T.int64(128), v_oh + v_kh - T.int64(1), v_ow + v_kw - T.int64(1), v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + T.if_then_else(T.int64(1) <= v_oh + v_kh and v_oh + v_kh < T.int64(29) and T.int64(1) <= v_ow + v_kw and v_ow + v_kw < T.int64(29), p0[v_n, v_ic // T.int64(128), v_oh + v_kh - T.int64(1), v_ow + v_kw - T.int64(1), v_ic % T.int64(128)], T.float32(0)) * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(2), T.int64(2)):
                    for ax4_fused in T.vectorized(T.int64(8)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(4), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused % T.int64(4) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused // T.int64(56) * T.int64(2) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused % T.int64(56) // T.int64(4) * T.int64(2) + ax3)
                            v_ax4 = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(8) + ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 4, 1, 1])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[14, 1, 2, 1])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[14, 1, 2, 1])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[1, 4, 8, 1])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[2, 64])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[3, 1])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l50, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=-2)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70 = sch.get_child_blocks(b68)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96 = sch.get_loops(block=b69)
l97 = sch.fuse(l71, l72, l73, l74, l75, l76, l77, preserve_unit_iters=True)
sch.parallel(loop=l97)
sch.annotate(block_or_loop=l97, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l97, ann_key="pragma_unroll_explicit", ann_val=1)
l98, l99, l100, l101, l102, l103, l104, l105, l106 = sch.get_loops(block=b70)
l107 = sch.fuse(l106, preserve_unit_iters=True)
sch.vectorize(loop=l107)
b108 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l109, l110, l111, l112, l113, l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128 = sch.get_loops(block=b108)
b129 = sch.decompose_reduction(block=b108, loop=l113)
2024-04-29 04:25:39 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #173: GFLOPs: 207.6524. Time: 1114.9019 us. Best GFLOPs: 339.3495
2024-04-29 04:25:39 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #174: GFLOPs: 189.4045. Time: 1222.3157 us. Best GFLOPs: 339.3495
2024-04-29 04:25:39 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #175: GFLOPs: 320.6130. Time: 722.0919 us. Best GFLOPs: 339.3495
2024-04-29 04:25:39 [INFO] [task_scheduler.cc:121] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #176: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(128)), "float32"), p1: T.Buffer((T.int64(4), T.int64(1), T.int64(3), T.int64(3), T.int64(128), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(32)), "float32"), p3: T.Buffer((T.int64(1), T.int64(4), T.int64(28), T.int64(28), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(4), T.int64(28), T.int64(28), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(4), T.int64(28), T.int64(28), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused in T.parallel(T.int64(784), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for oc_block_1 in range(T.int64(2)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(16), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(4), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused % T.int64(56) // T.int64(14) + oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused // T.int64(56) * T.int64(2) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused % T.int64(14) // T.int64(7) + oh_2_init + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused % T.int64(7) * T.int64(4) + ow_2_init + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(16) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(4), T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(16), T.int64(32), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(4), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused % T.int64(56) // T.int64(14) + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused // T.int64(56) * T.int64(2) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused % T.int64(14) // T.int64(7) + oh_2 + oh_3)
                        v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused % T.int64(7) * T.int64(4) + ow_2 + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(16) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(128), ic_0 * T.int64(32) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], p0[v_n, v_ic // T.int64(128), v_oh + v_kh - T.int64(1), v_ow + v_kw - T.int64(1), v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + T.if_then_else(T.int64(1) <= v_oh + v_kh and v_oh + v_kh < T.int64(29) and T.int64(1) <= v_ow + v_kw and v_ow + v_kw < T.int64(29), p0[v_n, v_ic // T.int64(128), v_oh + v_kh - T.int64(1), v_ow + v_kw - T.int64(1), v_ic % T.int64(128)], T.float32(0)) * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(4)):
                    for ax4_fused in T.vectorized(T.int64(16)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(4), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused % T.int64(56) // T.int64(14) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused // T.int64(56) * T.int64(2) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused % T.int64(14) // T.int64(7) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused % T.int64(7) * T.int64(4) + ax3)
                            v_ax4 = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(16) + ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 4, 1, 1])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[14, 2, 1, 1])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 7, 4, 1])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[1, 2, 16, 1])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[4, 32])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[3, 1])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l50, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=-2)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70 = sch.get_child_blocks(b68)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96 = sch.get_loops(block=b69)
l97 = sch.fuse(l71, l72, l73, l74, l75, l76, l77, l78, l79, preserve_unit_iters=True)
sch.parallel(loop=l97)
sch.annotate(block_or_loop=l97, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l97, ann_key="pragma_unroll_explicit", ann_val=1)
l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b70)
l105 = sch.fuse(l104, preserve_unit_iters=True)
sch.vectorize(loop=l105)
b106 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124 = sch.get_loops(block=b106)
b125 = sch.decompose_reduction(block=b106, loop=l109)
2024-04-29 04:25:39 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #177: GFLOPs: 357.7064. Time: 647.2126 us. Best GFLOPs: 357.7064
2024-04-29 04:25:39 [INFO] [task_scheduler.cc:121] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #178: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(128)), "float32"), p1: T.Buffer((T.int64(4), T.int64(1), T.int64(3), T.int64(3), T.int64(128), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(32)), "float32"), p3: T.Buffer((T.int64(1), T.int64(4), T.int64(28), T.int64(28), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(4), T.int64(28), T.int64(28), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(4), T.int64(28), T.int64(28), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused in T.parallel(T.int64(784), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(2), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2)):
                for oc_block_3_fused_init in T.vectorized(T.int64(16)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(4), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused // T.int64(392) * T.int64(2) + oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(196) // T.int64(14) * T.int64(2) + oh_2_init + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(392) // T.int64(196) * T.int64(14) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(14) // T.int64(2) * T.int64(2) + ow_2_init * T.int64(2) + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(2) * T.int64(16) + oc_block_2_init * T.int64(16) + oc_block_3_fused_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
            for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(8), T.int64(3), T.int64(1), T.int64(1), T.int64(2), T.int64(2), T.int64(1), T.int64(1), T.int64(16), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(2)):
                for oc_block_3_fused in T.vectorized(T.int64(16)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(4), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused // T.int64(392) * T.int64(2) + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(196) // T.int64(14) * T.int64(2) + oh_2 + oh_3)
                        v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(392) // T.int64(196) * T.int64(14) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(14) // T.int64(2) * T.int64(2) + ow_2 * T.int64(2) + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(2) * T.int64(16) + oc_block_2 * T.int64(16) + oc_block_3_fused)
                        v_ic = T.axis.reduce(T.int64(128), ic_0 * T.int64(16) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], p0[v_n, v_ic // T.int64(128), v_oh + v_kh - T.int64(1), v_ow + v_kw - T.int64(1), v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + T.if_then_else(T.int64(1) <= v_oh + v_kh and v_oh + v_kh < T.int64(29) and T.int64(1) <= v_ow + v_kw and v_ow + v_kw < T.int64(29), p0[v_n, v_ic // T.int64(128), v_oh + v_kh - T.int64(1), v_ow + v_kw - T.int64(1), v_ic % T.int64(128)], T.float32(0)) * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(2), T.int64(2), T.int64(2)):
                for ax4_fused in T.vectorized(T.int64(16)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(4), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused // T.int64(392) * T.int64(2) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(196) // T.int64(14) * T.int64(2) + ax2)
                        v_ax3 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(392) // T.int64(196) * T.int64(14) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(14) // T.int64(2) * T.int64(2) + ax3)
                        v_ax4 = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(2) * T.int64(16) + ax4_fused)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 1, 2, 1])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 14, 2, 1])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[2, 7, 1, 2])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[1, 2, 1, 16])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[8, 16])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[1, 3])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l50, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=-2)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70 = sch.get_child_blocks(b68)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96 = sch.get_loops(block=b69)
l97 = sch.fuse(l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, preserve_unit_iters=True)
sch.parallel(loop=l97)
l98 = sch.fuse(l96, preserve_unit_iters=True)
sch.vectorize(loop=l98)
sch.annotate(block_or_loop=l97, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l97, ann_key="pragma_unroll_explicit", ann_val=1)
l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b70)
l105 = sch.fuse(l104, preserve_unit_iters=True)
sch.vectorize(loop=l105)
b106 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117, l118, l119, l120, l121, l122, l123 = sch.get_loops(block=b106)
b124 = sch.decompose_reduction(block=b106, loop=l108)
2024-04-29 04:25:39 [INFO] [task_scheduler.cc:121] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #179: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(128)), "float32"), p1: T.Buffer((T.int64(4), T.int64(1), T.int64(3), T.int64(3), T.int64(128), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(32)), "float32"), p3: T.Buffer((T.int64(1), T.int64(4), T.int64(28), T.int64(28), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(4), T.int64(28), T.int64(28), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(4), T.int64(28), T.int64(28), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused in T.parallel(T.int64(784), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(2), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2)):
                for oc_block_3_fused_init in T.vectorized(T.int64(16)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(4), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused // T.int64(392) * T.int64(2) + oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(196) // T.int64(14) * T.int64(2) + oh_2_init + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(392) // T.int64(196) * T.int64(14) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(14) // T.int64(2) * T.int64(2) + ow_2_init * T.int64(2) + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(2) * T.int64(16) + oc_block_2_init * T.int64(16) + oc_block_3_fused_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
            for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(4), T.int64(3), T.int64(1), T.int64(1), T.int64(2), T.int64(2), T.int64(1), T.int64(1), T.int64(32), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(2)):
                for oc_block_3_fused in T.vectorized(T.int64(16)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(4), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused // T.int64(392) * T.int64(2) + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(196) // T.int64(14) * T.int64(2) + oh_2 + oh_3)
                        v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(392) // T.int64(196) * T.int64(14) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(14) // T.int64(2) * T.int64(2) + ow_2 * T.int64(2) + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(2) * T.int64(16) + oc_block_2 * T.int64(16) + oc_block_3_fused)
                        v_ic = T.axis.reduce(T.int64(128), ic_0 * T.int64(32) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], p0[v_n, v_ic // T.int64(128), v_oh + v_kh - T.int64(1), v_ow + v_kw - T.int64(1), v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + T.if_then_else(T.int64(1) <= v_oh + v_kh and v_oh + v_kh < T.int64(29) and T.int64(1) <= v_ow + v_kw and v_ow + v_kw < T.int64(29), p0[v_n, v_ic // T.int64(128), v_oh + v_kh - T.int64(1), v_ow + v_kw - T.int64(1), v_ic % T.int64(128)], T.float32(0)) * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(2), T.int64(2), T.int64(2)):
                for ax4_fused in T.vectorized(T.int64(16)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(4), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused // T.int64(392) * T.int64(2) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(196) // T.int64(14) * T.int64(2) + ax2)
                        v_ax3 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(392) // T.int64(196) * T.int64(14) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(14) // T.int64(2) * T.int64(2) + ax3)
                        v_ax4 = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(2) * T.int64(16) + ax4_fused)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 1, 2, 1])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 14, 2, 1])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[2, 7, 1, 2])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[1, 2, 1, 16])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[4, 32])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[1, 3])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l50, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=-2)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70 = sch.get_child_blocks(b68)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96 = sch.get_loops(block=b69)
l97 = sch.fuse(l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, preserve_unit_iters=True)
sch.parallel(loop=l97)
l98 = sch.fuse(l96, preserve_unit_iters=True)
sch.vectorize(loop=l98)
sch.annotate(block_or_loop=l97, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l97, ann_key="pragma_unroll_explicit", ann_val=1)
l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b70)
l105 = sch.fuse(l104, preserve_unit_iters=True)
sch.vectorize(loop=l105)
b106 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117, l118, l119, l120, l121, l122, l123 = sch.get_loops(block=b106)
b124 = sch.decompose_reduction(block=b106, loop=l108)
2024-04-29 04:25:39 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #180: GFLOPs: 120.7575. Time: 1917.1647 us. Best GFLOPs: 357.7064
2024-04-29 04:25:39 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #181: GFLOPs: 130.9235. Time: 1768.3004 us. Best GFLOPs: 357.7064
2024-04-29 04:25:39 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #182: GFLOPs: 193.0354. Time: 1199.3243 us. Best GFLOPs: 357.7064
2024-04-29 04:25:39 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #183: GFLOPs: 107.2589. Time: 2158.4411 us. Best GFLOPs: 357.7064
2024-04-29 04:25:39 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #184: GFLOPs: 66.1669. Time: 3498.9107 us. Best GFLOPs: 357.7064
2024-04-29 04:25:39 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #185: GFLOPs: 134.9182. Time: 1715.9444 us. Best GFLOPs: 357.7064
2024-04-29 04:25:39 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #186: GFLOPs: 207.7648. Time: 1114.2990 us. Best GFLOPs: 357.7064
2024-04-29 04:25:39 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #187: GFLOPs: 179.0976. Time: 1292.6583 us. Best GFLOPs: 357.7064
2024-04-29 04:25:39 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #188: GFLOPs: 154.7144. Time: 1496.3831 us. Best GFLOPs: 357.7064
2024-04-29 04:25:39 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #189: GFLOPs: 181.4964. Time: 1275.5736 us. Best GFLOPs: 357.7064
2024-04-29 04:25:39 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #190: GFLOPs: 8.6949. Time: 26626.2025 us. Best GFLOPs: 357.7064
2024-04-29 04:25:39 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #191: GFLOPs: 122.4021. Time: 1891.4056 us. Best GFLOPs: 357.7064
2024-04-29 04:25:39 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #192: GFLOPs: 5.4455. Time: 42514.1973 us. Best GFLOPs: 357.7064
2024-04-29 04:38:10 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 04:38:12 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-29 04:38:16 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4391338)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x38dd208)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x4182678)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x6ddeb88)]: 0 failure(s)
2024-04-29 04:38:16 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-29 04:38:29 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4391338)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x38dd208)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x4182678)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x6ddeb88)]: 0 failure(s)
2024-04-29 04:38:43 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4391338)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x38dd208)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x4182678)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x6ddeb88)]: 0 failure(s)
2024-04-29 04:38:57 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4391338)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x38dd208)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x4182678)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x6ddeb88)]: 0 failure(s)
2024-04-29 04:39:11 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4391338)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x38dd208)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x4182678)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x6ddeb88)]: 0 failure(s)
2024-04-29 04:39:19 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.8656  0.8216  0.8128  0.7737  0.7713  0.7626  0.7189  0.7169  0.7130  0.7085  0.7085  0.7085  0.6963  0.6958  0.6958  0.6948
[17 : 32]:	0.6914  0.6914  0.6910  0.6902  0.6874  0.6792  0.6760  0.6690  0.6580  0.6420  0.6398  0.6363  0.6363  0.6346  0.6288  0.6286
[33 : 48]:	0.6278  0.6278  0.6249  0.6215  0.6174  0.6167  0.6147  0.6147  0.6083  0.6078  0.6044  0.6041  0.6032  0.5990  0.5990  0.5976
[49 : 64]:	0.5951  0.5933  0.5933  0.5933  0.5928  0.5927  0.5923  0.5923  0.5923  0.5890  0.5890  0.5869  0.5863  0.5822  0.5821  0.5791
2024-04-29 04:39:20 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 04:39:20 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 04:40:44 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #193: GFLOPs: 167.4898. Time: 1382.2457 us. Best GFLOPs: 357.7064
2024-04-29 04:40:44 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #194: GFLOPs: 260.4328. Time: 888.9513 us. Best GFLOPs: 357.7064
2024-04-29 04:40:44 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #195: GFLOPs: 243.7486. Time: 949.7986 us. Best GFLOPs: 357.7064
2024-04-29 04:40:44 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #196: GFLOPs: 322.6742. Time: 717.4792 us. Best GFLOPs: 357.7064
2024-04-29 04:40:44 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #197: GFLOPs: 324.9800. Time: 712.3885 us. Best GFLOPs: 357.7064
2024-04-29 04:40:44 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #198: GFLOPs: 127.3627. Time: 1817.7378 us. Best GFLOPs: 357.7064
2024-04-29 04:40:44 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #199: GFLOPs: 176.6678. Time: 1310.4374 us. Best GFLOPs: 357.7064
2024-04-29 04:40:44 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #200: GFLOPs: 195.2153. Time: 1185.9318 us. Best GFLOPs: 357.7064
2024-04-29 04:40:44 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #201: GFLOPs: 271.3719. Time: 853.1173 us. Best GFLOPs: 357.7064
2024-04-29 04:40:44 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #202: GFLOPs: 312.1097. Time: 741.7651 us. Best GFLOPs: 357.7064
2024-04-29 04:40:44 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #203: GFLOPs: 73.7169. Time: 3140.5541 us. Best GFLOPs: 357.7064
2024-04-29 04:40:44 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #204: GFLOPs: 187.0024. Time: 1238.0163 us. Best GFLOPs: 357.7064
2024-04-29 04:40:44 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #205: GFLOPs: 265.6838. Time: 871.3820 us. Best GFLOPs: 357.7064
2024-04-29 04:40:44 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #206: GFLOPs: 369.7703. Time: 626.0970 us. Best GFLOPs: 369.7703
2024-04-29 04:40:44 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #207: GFLOPs: 329.1379. Time: 703.3893 us. Best GFLOPs: 369.7703
2024-04-29 04:40:44 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #208: GFLOPs: 62.0769. Time: 3729.4404 us. Best GFLOPs: 369.7703
2024-04-29 04:40:44 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #209: GFLOPs: 108.6877. Time: 2130.0668 us. Best GFLOPs: 369.7703
2024-04-29 04:40:44 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #210: GFLOPs: 110.5358. Time: 2094.4541 us. Best GFLOPs: 369.7703
2024-04-29 04:40:44 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #211: GFLOPs: 267.7171. Time: 864.7640 us. Best GFLOPs: 369.7703
2024-04-29 04:40:44 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #212: GFLOPs: 267.5794. Time: 865.2088 us. Best GFLOPs: 369.7703
2024-04-29 04:40:44 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #213: GFLOPs: 491.5247. Time: 471.0080 us. Best GFLOPs: 491.5247
2024-04-29 04:40:44 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #214: GFLOPs: 316.1645. Time: 732.2518 us. Best GFLOPs: 491.5247
2024-04-29 04:40:44 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #215: GFLOPs: 317.9274. Time: 728.1916 us. Best GFLOPs: 491.5247
2024-04-29 04:40:44 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #216: GFLOPs: 162.1260. Time: 1427.9765 us. Best GFLOPs: 491.5247
2024-04-29 04:40:44 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #217: GFLOPs: 206.8559. Time: 1119.1947 us. Best GFLOPs: 491.5247
2024-04-29 04:40:44 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #218: GFLOPs: 115.3473. Time: 2007.0874 us. Best GFLOPs: 491.5247
2024-04-29 04:40:44 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #219: GFLOPs: 260.2610. Time: 889.5379 us. Best GFLOPs: 491.5247
2024-04-29 04:40:44 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #220: GFLOPs: 350.2154. Time: 661.0562 us. Best GFLOPs: 491.5247
2024-04-29 04:40:44 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #221: GFLOPs: 355.4880. Time: 651.2515 us. Best GFLOPs: 491.5247
2024-04-29 04:40:44 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #222: GFLOPs: 357.6872. Time: 647.2472 us. Best GFLOPs: 491.5247
2024-04-29 04:40:44 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #223: GFLOPs: 148.0962. Time: 1563.2542 us. Best GFLOPs: 491.5247
2024-04-29 04:40:44 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #224: GFLOPs: 251.7722. Time: 919.5299 us. Best GFLOPs: 491.5247
2024-04-29 04:40:44 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #225: GFLOPs: 165.3581. Time: 1400.0649 us. Best GFLOPs: 491.5247
2024-04-29 04:40:44 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #226: GFLOPs: 56.2641. Time: 4114.7382 us. Best GFLOPs: 491.5247
2024-04-29 04:40:44 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #227: GFLOPs: 241.7696. Time: 957.5729 us. Best GFLOPs: 491.5247
2024-04-29 04:40:44 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #228: GFLOPs: 211.9789. Time: 1092.1467 us. Best GFLOPs: 491.5247
2024-04-29 04:40:44 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #229: GFLOPs: 63.1302. Time: 3667.2173 us. Best GFLOPs: 491.5247
2024-04-29 04:40:44 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #230: GFLOPs: 257.7363. Time: 898.2518 us. Best GFLOPs: 491.5247
2024-04-29 04:40:44 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #231: GFLOPs: 198.9315. Time: 1163.7777 us. Best GFLOPs: 491.5247
2024-04-29 04:40:44 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #232: GFLOPs: 198.5618. Time: 1165.9447 us. Best GFLOPs: 491.5247
2024-04-29 04:40:44 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #233: GFLOPs: 150.2292. Time: 1541.0588 us. Best GFLOPs: 491.5247
2024-04-29 04:40:44 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #234: GFLOPs: 229.2157. Time: 1010.0183 us. Best GFLOPs: 491.5247
2024-04-29 04:40:44 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #235: GFLOPs: 179.0111. Time: 1293.2831 us. Best GFLOPs: 491.5247
2024-04-29 04:40:44 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #236: GFLOPs: 206.0634. Time: 1123.4994 us. Best GFLOPs: 491.5247
2024-04-29 04:40:44 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #237: GFLOPs: 113.0694. Time: 2047.5225 us. Best GFLOPs: 491.5247
2024-04-29 04:40:44 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #238: GFLOPs: 148.1230. Time: 1562.9712 us. Best GFLOPs: 491.5247
2024-04-29 04:40:44 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #239: GFLOPs: 170.8729. Time: 1354.8787 us. Best GFLOPs: 491.5247
2024-04-29 04:40:44 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #240: GFLOPs: 178.0436. Time: 1300.3112 us. Best GFLOPs: 491.5247
2024-04-29 04:40:44 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #241: GFLOPs: 231.0708. Time: 1001.9098 us. Best GFLOPs: 491.5247
2024-04-29 04:40:44 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #242: GFLOPs: 181.9010. Time: 1272.7365 us. Best GFLOPs: 491.5247
2024-04-29 04:40:44 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #243: GFLOPs: 193.6527. Time: 1195.5014 us. Best GFLOPs: 491.5247
2024-04-29 04:40:44 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #244: GFLOPs: 193.1493. Time: 1198.6169 us. Best GFLOPs: 491.5247
2024-04-29 04:40:44 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #245: GFLOPs: 406.9249. Time: 568.9307 us. Best GFLOPs: 491.5247
2024-04-29 04:40:44 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #246: GFLOPs: 208.3249. Time: 1111.3030 us. Best GFLOPs: 491.5247
2024-04-29 04:40:44 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #247: GFLOPs: 136.8875. Time: 1691.2578 us. Best GFLOPs: 491.5247
2024-04-29 04:40:44 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #248: GFLOPs: 150.5930. Time: 1537.3365 us. Best GFLOPs: 491.5247
2024-04-29 04:40:44 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #249: GFLOPs: 116.2881. Time: 1990.8486 us. Best GFLOPs: 491.5247
2024-04-29 04:40:44 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #250: GFLOPs: 85.2447. Time: 2715.8542 us. Best GFLOPs: 491.5247
2024-04-29 04:40:44 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #251: GFLOPs: 101.9716. Time: 2270.3583 us. Best GFLOPs: 491.5247
2024-04-29 04:40:44 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #252: GFLOPs: 223.3951. Time: 1036.3344 us. Best GFLOPs: 491.5247
2024-04-29 04:40:44 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #253: GFLOPs: 152.0774. Time: 1522.3304 us. Best GFLOPs: 491.5247
2024-04-29 04:40:44 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #254: GFLOPs: 119.3084. Time: 1940.4506 us. Best GFLOPs: 491.5247
2024-04-29 04:40:44 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #255: GFLOPs: 4.4414. Time: 52126.2283 us. Best GFLOPs: 491.5247
2024-04-29 04:40:44 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #256: GFLOPs: 118.5035. Time: 1953.6301 us. Best GFLOPs: 491.5247
2024-04-29 04:48:14 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 04:48:16 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-29 04:48:20 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4391338)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x38dd208)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x4182678)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x6ddeb88)]: 0 failure(s)
2024-04-29 04:48:20 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-29 04:48:33 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4391338)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x38dd208)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x4182678)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x6ddeb88)]: 0 failure(s)
2024-04-29 04:48:47 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4391338)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x38dd208)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x4182678)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x6ddeb88)]: 0 failure(s)
2024-04-29 04:49:01 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4391338)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x38dd208)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x4182678)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x6ddeb88)]: 0 failure(s)
2024-04-29 04:49:15 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4391338)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x38dd208)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x4182678)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x6ddeb88)]: 0 failure(s)
2024-04-29 04:49:24 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.7905  0.7783  0.7608  0.7552  0.7549  0.7521  0.7271  0.7246  0.7094  0.6922  0.6866  0.6795  0.6693  0.6591  0.6471  0.6471
[17 : 32]:	0.6311  0.6278  0.6261  0.6240  0.6235  0.6132  0.6064  0.6058  0.5998  0.5998  0.5918  0.5799  0.5763  0.5755  0.5755  0.5714
[33 : 48]:	0.5696  0.5685  0.5620  0.5608  0.5608  0.5467  0.5440  0.5417  0.5414  0.5346  0.5299  0.5299  0.5299  0.5287  0.5284  0.5284
[49 : 64]:	0.5283  0.5278  0.5263  0.5263  0.5218  0.5214  0.5205  0.5204  0.5180  0.5155  0.5118  0.5099  0.5099  0.5089  0.5082  0.5082
2024-04-29 04:49:24 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 04:49:24 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 04:50:54 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #257: GFLOPs: 167.1436. Time: 1385.1084 us. Best GFLOPs: 491.5247
2024-04-29 04:50:54 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #258: GFLOPs: 411.5145. Time: 562.5854 us. Best GFLOPs: 491.5247
2024-04-29 04:50:54 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #259: GFLOPs: 199.6738. Time: 1159.4514 us. Best GFLOPs: 491.5247
2024-04-29 04:50:54 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #260: GFLOPs: 591.2489. Time: 391.5645 us. Best GFLOPs: 591.2489
2024-04-29 04:50:54 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #261: GFLOPs: 387.4590. Time: 597.5137 us. Best GFLOPs: 591.2489
2024-04-29 04:50:54 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #262: GFLOPs: 413.0839. Time: 560.4481 us. Best GFLOPs: 591.2489
2024-04-29 04:50:54 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #263: GFLOPs: 150.1372. Time: 1542.0038 us. Best GFLOPs: 591.2489
2024-04-29 04:50:54 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #264: GFLOPs: 404.0420. Time: 572.9901 us. Best GFLOPs: 591.2489
2024-04-29 04:50:54 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #265: GFLOPs: 403.5841. Time: 573.6403 us. Best GFLOPs: 591.2489
2024-04-29 04:50:54 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #266: GFLOPs: 391.8205. Time: 590.8626 us. Best GFLOPs: 591.2489
2024-04-29 04:50:54 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #267: GFLOPs: 174.7451. Time: 1324.8556 us. Best GFLOPs: 591.2489
2024-04-29 04:50:54 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #268: GFLOPs: 403.8012. Time: 573.3317 us. Best GFLOPs: 591.2489
2024-04-29 04:50:54 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #269: GFLOPs: 378.9463. Time: 610.9364 us. Best GFLOPs: 591.2489
2024-04-29 04:50:54 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #270: GFLOPs: 363.1467. Time: 637.5167 us. Best GFLOPs: 591.2489
2024-04-29 04:50:54 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #271: GFLOPs: 295.0215. Time: 784.7293 us. Best GFLOPs: 591.2489
2024-04-29 04:50:54 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #272: GFLOPs: 325.8083. Time: 710.5775 us. Best GFLOPs: 591.2489
2024-04-29 04:50:54 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #273: GFLOPs: 353.5511. Time: 654.8192 us. Best GFLOPs: 591.2489
2024-04-29 04:50:54 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #274: GFLOPs: 268.8800. Time: 861.0236 us. Best GFLOPs: 591.2489
2024-04-29 04:50:54 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #275: GFLOPs: 465.1552. Time: 497.7093 us. Best GFLOPs: 591.2489
2024-04-29 04:50:54 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #276: GFLOPs: 136.7171. Time: 1693.3655 us. Best GFLOPs: 591.2489
2024-04-29 04:50:54 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #277: GFLOPs: 72.7886. Time: 3180.6090 us. Best GFLOPs: 591.2489
2024-04-29 04:50:54 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #278: GFLOPs: 318.1131. Time: 727.7666 us. Best GFLOPs: 591.2489
2024-04-29 04:50:54 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #279: GFLOPs: 318.6437. Time: 726.5548 us. Best GFLOPs: 591.2489
2024-04-29 04:50:54 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #280: GFLOPs: 504.9938. Time: 458.4454 us. Best GFLOPs: 591.2489
2024-04-29 04:50:54 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #281: GFLOPs: 99.4953. Time: 2326.8646 us. Best GFLOPs: 591.2489
2024-04-29 04:50:54 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #282: GFLOPs: 73.6042. Time: 3145.3662 us. Best GFLOPs: 591.2489
2024-04-29 04:50:54 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #283: GFLOPs: 391.7231. Time: 591.0094 us. Best GFLOPs: 591.2489
2024-04-29 04:50:54 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #284: GFLOPs: 49.9665. Time: 4633.3487 us. Best GFLOPs: 591.2489
2024-04-29 04:50:54 [INFO] [task_scheduler.cc:121] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #285: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(128)), "float32"), p1: T.Buffer((T.int64(4), T.int64(1), T.int64(3), T.int64(3), T.int64(128), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(32)), "float32"), p3: T.Buffer((T.int64(1), T.int64(4), T.int64(28), T.int64(28), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(4), T.int64(28), T.int64(28), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(128)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(4), T.int64(28), T.int64(28), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused in T.parallel(T.int64(1568), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for oc_block_1 in range(T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(2)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(8)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(4), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(392) + oc_chunk_2_init + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(196) // T.int64(7) + oh_2_init + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(7) * T.int64(4) + ow_2_init * T.int64(2) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(392) // T.int64(196) * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2_init * T.int64(8) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0 in T.grid(T.int64(4), T.int64(3)):
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(6)):
                        for ax4_fused in T.vectorized(T.int64(32)):
                            with T.block("data_pad"):
                                v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                                v_i2 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(196) // T.int64(7) + kh_0 + ax2)
                                v_i3 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(7) * T.int64(4) + ax3)
                                v_i4 = T.axis.spatial(T.int64(128), ic_0 * T.int64(32) + ax4_fused)
                                T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                                T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                                data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                    for kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(2), T.int64(32), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(2)):
                        for oc_block_3_fused in T.vectorized(T.int64(8)):
                            with T.block("conv2d_NCHWc_update"):
                                v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                                v_oc_chunk = T.axis.spatial(T.int64(4), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(392) + oc_chunk_2 + oc_chunk_3)
                                v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(196) // T.int64(7) + oh_2 + oh_3)
                                v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(7) * T.int64(4) + ow_2 * T.int64(2) + ow_3)
                                v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(392) // T.int64(196) * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2 * T.int64(8) + oc_block_3_fused)
                                v_ic = T.axis.reduce(T.int64(128), ic_0 * T.int64(32) + ic_1)
                                v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                                v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                                T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(4)):
                    for ax4_fused in T.vectorized(T.int64(16)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(4), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(392) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(196) // T.int64(7) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(7) * T.int64(4) + ax3)
                            v_ax4 = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(392) // T.int64(196) * T.int64(16) + ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[4, 1, 1, 1])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 28, 1, 1])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 7, 2, 2])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[2, 1, 2, 8])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[4, 32])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[1, 3])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l50, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=11)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88 = sch.get_loops(block=b69)
l89 = sch.fuse(l72, l73, l74, l75, l76, l77, l78, l79, l80, preserve_unit_iters=True)
sch.parallel(loop=l89)
l90 = sch.fuse(l88, preserve_unit_iters=True)
sch.vectorize(loop=l90)
l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107, l108 = sch.get_loops(block=b70)
l109 = sch.fuse(l91, preserve_unit_iters=True)
sch.parallel(loop=l109)
l110 = sch.fuse(l108, preserve_unit_iters=True)
sch.vectorize(loop=l110)
sch.annotate(block_or_loop=l109, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l109, ann_key="pragma_unroll_explicit", ann_val=1)
l111, l112, l113, l114, l115, l116, l117 = sch.get_loops(block=b71)
l118 = sch.fuse(l117, preserve_unit_iters=True)
sch.vectorize(loop=l118)
b119 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137 = sch.get_loops(block=b119)
b138 = sch.decompose_reduction(block=b119, loop=l122)
2024-04-29 04:50:54 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #286: GFLOPs: 156.2379. Time: 1481.7915 us. Best GFLOPs: 591.2489
2024-04-29 04:50:54 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #287: GFLOPs: 244.5215. Time: 946.7962 us. Best GFLOPs: 591.2489
2024-04-29 04:50:54 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #288: GFLOPs: 200.5586. Time: 1154.3360 us. Best GFLOPs: 591.2489
2024-04-29 04:50:54 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #289: GFLOPs: 214.3880. Time: 1079.8742 us. Best GFLOPs: 591.2489
2024-04-29 04:50:54 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #290: GFLOPs: 201.1091. Time: 1151.1767 us. Best GFLOPs: 591.2489
2024-04-29 04:50:54 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #291: GFLOPs: 184.4439. Time: 1255.1893 us. Best GFLOPs: 591.2489
2024-04-29 04:50:54 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #292: GFLOPs: 100.3084. Time: 2308.0026 us. Best GFLOPs: 591.2489
2024-04-29 04:50:54 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #293: GFLOPs: 100.3756. Time: 2306.4571 us. Best GFLOPs: 591.2489
2024-04-29 04:50:54 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #294: GFLOPs: 299.2427. Time: 773.6598 us. Best GFLOPs: 591.2489
2024-04-29 04:50:54 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #295: GFLOPs: 508.2977. Time: 455.4655 us. Best GFLOPs: 591.2489
2024-04-29 04:50:54 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #296: GFLOPs: 498.5848. Time: 464.3383 us. Best GFLOPs: 591.2489
2024-04-29 04:50:54 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #297: GFLOPs: 137.1934. Time: 1687.4870 us. Best GFLOPs: 591.2489
2024-04-29 04:50:54 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #298: GFLOPs: 360.5330. Time: 642.1383 us. Best GFLOPs: 591.2489
2024-04-29 04:50:54 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #299: GFLOPs: 271.5716. Time: 852.4900 us. Best GFLOPs: 591.2489
2024-04-29 04:50:54 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #300: GFLOPs: 273.2943. Time: 847.1164 us. Best GFLOPs: 591.2489
2024-04-29 04:50:54 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #301: GFLOPs: 271.9512. Time: 851.3000 us. Best GFLOPs: 591.2489
2024-04-29 04:50:54 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #302: GFLOPs: 160.6210. Time: 1441.3565 us. Best GFLOPs: 591.2489
2024-04-29 04:50:54 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #303: GFLOPs: 244.1710. Time: 948.1555 us. Best GFLOPs: 591.2489
2024-04-29 04:50:54 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #304: GFLOPs: 292.7197. Time: 790.9003 us. Best GFLOPs: 591.2489
2024-04-29 04:50:54 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #305: GFLOPs: 136.9562. Time: 1690.4099 us. Best GFLOPs: 591.2489
2024-04-29 04:50:54 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #306: GFLOPs: 200.1269. Time: 1156.8263 us. Best GFLOPs: 591.2489
2024-04-29 04:50:54 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #307: GFLOPs: 341.0979. Time: 678.7262 us. Best GFLOPs: 591.2489
2024-04-29 04:50:54 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #308: GFLOPs: 359.7926. Time: 643.4598 us. Best GFLOPs: 591.2489
2024-04-29 04:50:54 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #309: GFLOPs: 413.6308. Time: 559.7071 us. Best GFLOPs: 591.2489
2024-04-29 04:50:54 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #310: GFLOPs: 190.7562. Time: 1213.6540 us. Best GFLOPs: 591.2489
2024-04-29 04:50:54 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #311: GFLOPs: 154.1020. Time: 1502.3297 us. Best GFLOPs: 591.2489
2024-04-29 04:50:54 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #312: GFLOPs: 400.6509. Time: 577.8399 us. Best GFLOPs: 591.2489
2024-04-29 04:50:54 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #313: GFLOPs: 271.0783. Time: 854.0413 us. Best GFLOPs: 591.2489
2024-04-29 04:50:54 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #314: GFLOPs: 248.8115. Time: 930.4718 us. Best GFLOPs: 591.2489
2024-04-29 04:50:54 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #315: GFLOPs: 147.5362. Time: 1569.1884 us. Best GFLOPs: 591.2489
2024-04-29 04:50:54 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #316: GFLOPs: 356.2611. Time: 649.8383 us. Best GFLOPs: 591.2489
2024-04-29 04:50:54 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #317: GFLOPs: 520.6926. Time: 444.6233 us. Best GFLOPs: 591.2489
2024-04-29 04:50:54 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #318: GFLOPs: 16.8025. Time: 13778.4604 us. Best GFLOPs: 591.2489
2024-04-29 04:50:54 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #319: GFLOPs: 38.7875. Time: 5968.7272 us. Best GFLOPs: 591.2489
2024-04-29 04:50:54 [INFO] [task_scheduler.cc:121] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #320: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(128)), "float32"), p1: T.Buffer((T.int64(4), T.int64(1), T.int64(3), T.int64(3), T.int64(128), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(32)), "float32"), p3: T.Buffer((T.int64(1), T.int64(4), T.int64(28), T.int64(28), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(4), T.int64(28), T.int64(28), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(128)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(4), T.int64(28), T.int64(28), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_fused_fused in T.parallel(T.int64(2), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(16), T.int64(30), T.int64(128)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_fused_fused * T.int64(14) + ax2)
                    v_i3, v_i4 = T.axis.remap("SS", [ax3, ax4])
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for ow_0, oc_block_0, n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(2)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(4), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(28)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(8)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(4), oc_chunk_1 * T.int64(4) + oc_chunk_2_init + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_fused_fused * T.int64(14) + oh_1 * T.int64(2) + oh_2_init + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(28), ow_0 * T.int64(28) + ow_1 * T.int64(28) + ow_2_init * T.int64(28) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(32), oc_block_0 * T.int64(16) + oc_block_1 * T.int64(8) + oc_block_2_init * T.int64(8) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(64), T.int64(1), T.int64(3), T.int64(1), T.int64(4), T.int64(2), T.int64(1), T.int64(1), T.int64(2), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(28)):
                    for oc_block_3_fused in T.vectorized(T.int64(8)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(4), oc_chunk_1 * T.int64(4) + oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_fused_fused * T.int64(14) + oh_1 * T.int64(2) + oh_2 + oh_3)
                            v_ow = T.axis.spatial(T.int64(28), ow_0 * T.int64(28) + ow_1 * T.int64(28) + ow_2 * T.int64(28) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(32), oc_block_0 * T.int64(16) + oc_block_1 * T.int64(8) + oc_block_2 * T.int64(8) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(128), ic_0 * T.int64(2) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
        for ax0_ax1_ax2_ax3_ax4_fused_0 in T.parallel(T.int64(1568)):
            for ax0_ax1_ax2_ax3_ax4_fused_1 in T.vectorized(T.int64(64)):
                with T.block("T_relu"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) // T.int64(25088))
                    v_ax2 = T.axis.spatial(T.int64(28), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(25088) // T.int64(896))
                    v_ax3 = T.axis.spatial(T.int64(28), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(896) // T.int64(32))
                    v_ax4 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(32))
                    T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 4, 1])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[2, 7, 2, 1])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 1, 28])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[2, 2, 1, 8])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[64, 2])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[3, 1])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=2)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78 = sch.get_loops(block=b68)
l79 = sch.fuse(l71, l72, l73, preserve_unit_iters=True)
sch.parallel(loop=l79)
l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l80, preserve_unit_iters=True)
sch.parallel(loop=l104)
l105 = sch.fuse(l103, preserve_unit_iters=True)
sch.vectorize(loop=l105)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l106, l107, l108, l109, l110 = sch.get_loops(block=b70)
l111 = sch.fuse(l106, l107, l108, l109, l110, preserve_unit_iters=True)
l112, l113 = sch.split(loop=l111, factors=[None, 64], preserve_unit_iters=True)
sch.parallel(loop=l112)
sch.vectorize(loop=l113)
b114 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138 = sch.get_loops(block=b114)
b139 = sch.decompose_reduction(block=b114, loop=l123)
2024-04-29 05:13:44 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 05:13:45 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-29 05:13:50 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4391338)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x38dd208)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x4182678)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x6ddeb88)]: 0 failure(s)
2024-04-29 05:13:50 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-29 05:14:03 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4391338)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x38dd208)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x4182678)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x6ddeb88)]: 0 failure(s)
2024-04-29 05:14:16 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4391338)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x38dd208)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x4182678)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x6ddeb88)]: 0 failure(s)
2024-04-29 05:14:30 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4391338)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x38dd208)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x4182678)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x6ddeb88)]: 0 failure(s)
2024-04-29 05:14:44 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4391338)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x38dd208)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x4182678)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x6ddeb88)]: 0 failure(s)
2024-04-29 05:14:52 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.8372  0.7998  0.7949  0.7949  0.7708  0.7541  0.7318  0.7299  0.7202  0.7093  0.7062  0.6939  0.6881  0.6751  0.6751  0.6698
[17 : 32]:	0.6696  0.6678  0.6662  0.6647  0.6612  0.6465  0.6463  0.6432  0.6432  0.6430  0.6405  0.6240  0.6216  0.6180  0.6069  0.6034
[33 : 48]:	0.5953  0.5951  0.5887  0.5886  0.5844  0.5844  0.5843  0.5843  0.5834  0.5834  0.5771  0.5746  0.5726  0.5720  0.5720  0.5709
[49 : 64]:	0.5674  0.5623  0.5623  0.5611  0.5544  0.5544  0.5522  0.5510  0.5479  0.5477  0.5477  0.5477  0.5457  0.5437  0.5418  0.5400
2024-04-29 05:14:53 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 05:14:53 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 05:16:11 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #321: GFLOPs: 460.1614. Time: 503.1106 us. Best GFLOPs: 591.2489
2024-04-29 05:16:11 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #322: GFLOPs: 454.9014. Time: 508.9280 us. Best GFLOPs: 591.2489
2024-04-29 05:16:11 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #323: GFLOPs: 281.5165. Time: 822.3749 us. Best GFLOPs: 591.2489
2024-04-29 05:16:11 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #324: GFLOPs: 380.7370. Time: 608.0630 us. Best GFLOPs: 591.2489
2024-04-29 05:16:11 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #325: GFLOPs: 183.4129. Time: 1262.2455 us. Best GFLOPs: 591.2489
2024-04-29 05:16:11 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #326: GFLOPs: 425.8200. Time: 543.6853 us. Best GFLOPs: 591.2489
2024-04-29 05:16:11 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #327: GFLOPs: 82.7710. Time: 2797.0184 us. Best GFLOPs: 591.2489
2024-04-29 05:16:11 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #328: GFLOPs: 415.9261. Time: 556.6182 us. Best GFLOPs: 591.2489
2024-04-29 05:16:11 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #329: GFLOPs: 142.7103. Time: 1622.2522 us. Best GFLOPs: 591.2489
2024-04-29 05:16:11 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #330: GFLOPs: 476.7554. Time: 485.5992 us. Best GFLOPs: 591.2489
2024-04-29 05:16:11 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #331: GFLOPs: 337.8513. Time: 685.2485 us. Best GFLOPs: 591.2489
2024-04-29 05:16:11 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #332: GFLOPs: 115.8790. Time: 1997.8777 us. Best GFLOPs: 591.2489
2024-04-29 05:16:11 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #333: GFLOPs: 75.2501. Time: 3076.5678 us. Best GFLOPs: 591.2489
2024-04-29 05:16:11 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #334: GFLOPs: 357.6200. Time: 647.3689 us. Best GFLOPs: 591.2489
2024-04-29 05:16:11 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #335: GFLOPs: 518.9865. Time: 446.0849 us. Best GFLOPs: 591.2489
2024-04-29 05:16:11 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #336: GFLOPs: 269.0321. Time: 860.5369 us. Best GFLOPs: 591.2489
2024-04-29 05:16:11 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #337: GFLOPs: 500.1197. Time: 462.9133 us. Best GFLOPs: 591.2489
2024-04-29 05:16:11 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #338: GFLOPs: 509.2718. Time: 454.5943 us. Best GFLOPs: 591.2489
2024-04-29 05:16:11 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #339: GFLOPs: 401.5553. Time: 576.5384 us. Best GFLOPs: 591.2489
2024-04-29 05:16:11 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #340: GFLOPs: 416.8539. Time: 555.3793 us. Best GFLOPs: 591.2489
2024-04-29 05:16:11 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #341: GFLOPs: 72.4547. Time: 3195.2668 us. Best GFLOPs: 591.2489
2024-04-29 05:16:11 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #342: GFLOPs: 393.4655. Time: 588.3923 us. Best GFLOPs: 591.2489
2024-04-29 05:16:11 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #343: GFLOPs: 214.6234. Time: 1078.6899 us. Best GFLOPs: 591.2489
2024-04-29 05:16:11 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #344: GFLOPs: 432.9142. Time: 534.7759 us. Best GFLOPs: 591.2489
2024-04-29 05:16:11 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #345: GFLOPs: 398.4493. Time: 581.0326 us. Best GFLOPs: 591.2489
2024-04-29 05:16:11 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #346: GFLOPs: 443.3856. Time: 522.1461 us. Best GFLOPs: 591.2489
2024-04-29 05:16:11 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #347: GFLOPs: 320.0077. Time: 723.4578 us. Best GFLOPs: 591.2489
2024-04-29 05:16:11 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #348: GFLOPs: 370.0607. Time: 625.6057 us. Best GFLOPs: 591.2489
2024-04-29 05:16:11 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #349: GFLOPs: 430.7506. Time: 537.4619 us. Best GFLOPs: 591.2489
2024-04-29 05:16:11 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #350: GFLOPs: 334.7601. Time: 691.5761 us. Best GFLOPs: 591.2489
2024-04-29 05:16:11 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #351: GFLOPs: 565.8724. Time: 409.1242 us. Best GFLOPs: 591.2489
2024-04-29 05:16:11 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #352: GFLOPs: 385.4673. Time: 600.6011 us. Best GFLOPs: 591.2489
2024-04-29 05:16:11 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #353: GFLOPs: 322.7478. Time: 717.3158 us. Best GFLOPs: 591.2489
2024-04-29 05:16:11 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #354: GFLOPs: 490.2632. Time: 472.2200 us. Best GFLOPs: 591.2489
2024-04-29 05:16:11 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #355: GFLOPs: 980.1472. Time: 236.2013 us. Best GFLOPs: 980.1472
2024-04-29 05:16:11 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #356: GFLOPs: 297.5567. Time: 778.0436 us. Best GFLOPs: 980.1472
2024-04-29 05:16:11 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #357: GFLOPs: 418.4702. Time: 553.2342 us. Best GFLOPs: 980.1472
2024-04-29 05:16:11 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #358: GFLOPs: 458.1923. Time: 505.2727 us. Best GFLOPs: 980.1472
2024-04-29 05:16:11 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #359: GFLOPs: 214.6073. Time: 1078.7706 us. Best GFLOPs: 980.1472
2024-04-29 05:16:11 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #360: GFLOPs: 289.8914. Time: 798.6167 us. Best GFLOPs: 980.1472
2024-04-29 05:16:11 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #361: GFLOPs: 164.1964. Time: 1409.9702 us. Best GFLOPs: 980.1472
2024-04-29 05:16:11 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #362: GFLOPs: 215.5695. Time: 1073.9558 us. Best GFLOPs: 980.1472
2024-04-29 05:16:11 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #363: GFLOPs: 359.7950. Time: 643.4554 us. Best GFLOPs: 980.1472
2024-04-29 05:16:11 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #364: GFLOPs: 524.4692. Time: 441.4217 us. Best GFLOPs: 980.1472
2024-04-29 05:16:11 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #365: GFLOPs: 351.2615. Time: 659.0875 us. Best GFLOPs: 980.1472
2024-04-29 05:16:11 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #366: GFLOPs: 282.1055. Time: 820.6579 us. Best GFLOPs: 980.1472
2024-04-29 05:16:11 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #367: GFLOPs: 456.1373. Time: 507.5491 us. Best GFLOPs: 980.1472
2024-04-29 05:16:11 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #368: GFLOPs: 338.4354. Time: 684.0658 us. Best GFLOPs: 980.1472
2024-04-29 05:16:11 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #369: GFLOPs: 331.2413. Time: 698.9226 us. Best GFLOPs: 980.1472
2024-04-29 05:16:11 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #370: GFLOPs: 410.6766. Time: 563.7332 us. Best GFLOPs: 980.1472
2024-04-29 05:16:11 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #371: GFLOPs: 404.9291. Time: 571.7349 us. Best GFLOPs: 980.1472
2024-04-29 05:16:11 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #372: GFLOPs: 421.2640. Time: 549.5652 us. Best GFLOPs: 980.1472
2024-04-29 05:16:11 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #373: GFLOPs: 423.0779. Time: 547.2090 us. Best GFLOPs: 980.1472
2024-04-29 05:16:11 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #374: GFLOPs: 178.1592. Time: 1299.4672 us. Best GFLOPs: 980.1472
2024-04-29 05:16:11 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #375: GFLOPs: 383.9141. Time: 603.0309 us. Best GFLOPs: 980.1472
2024-04-29 05:16:11 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #376: GFLOPs: 330.5349. Time: 700.4163 us. Best GFLOPs: 980.1472
2024-04-29 05:16:11 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #377: GFLOPs: 174.9606. Time: 1323.2242 us. Best GFLOPs: 980.1472
2024-04-29 05:16:11 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #378: GFLOPs: 382.5738. Time: 605.1436 us. Best GFLOPs: 980.1472
2024-04-29 05:16:11 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #379: GFLOPs: 183.0053. Time: 1265.0565 us. Best GFLOPs: 980.1472
2024-04-29 05:16:11 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #380: GFLOPs: 427.8370. Time: 541.1222 us. Best GFLOPs: 980.1472
2024-04-29 05:16:11 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #381: GFLOPs: 88.4505. Time: 2617.4194 us. Best GFLOPs: 980.1472
2024-04-29 05:16:11 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #382: GFLOPs: 111.7779. Time: 2071.1797 us. Best GFLOPs: 980.1472
2024-04-29 05:16:11 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #383: GFLOPs: 36.1831. Time: 6398.3432 us. Best GFLOPs: 980.1472
2024-04-29 05:16:11 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #384: GFLOPs: 65.8460. Time: 3515.9639 us. Best GFLOPs: 980.1472
2024-04-29 05:46:28 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 05:46:29 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-29 05:46:34 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4391338)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x38dd208)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x4182678)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x6ddeb88)]: 0 failure(s)
2024-04-29 05:46:34 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-29 05:46:47 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4391338)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x38dd208)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x4182678)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x6ddeb88)]: 0 failure(s)
2024-04-29 05:47:00 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4391338)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x38dd208)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x4182678)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x6ddeb88)]: 0 failure(s)
2024-04-29 05:47:14 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4391338)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x38dd208)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x4182678)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x6ddeb88)]: 0 failure(s)
2024-04-29 05:47:27 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4391338)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x38dd208)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x4182678)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x6ddeb88)]: 0 failure(s)
2024-04-29 05:47:36 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9708  0.9696  0.8924  0.8637  0.8040  0.7318  0.6353  0.6320  0.6023  0.5693  0.5549  0.5531  0.5531  0.5517  0.5334  0.5224
[17 : 32]:	0.5191  0.5098  0.5098  0.4941  0.4894  0.4854  0.4826  0.4816  0.4798  0.4791  0.4780  0.4750  0.4743  0.4728  0.4716  0.4710
[33 : 48]:	0.4709  0.4688  0.4643  0.4643  0.4623  0.4610  0.4572  0.4563  0.4547  0.4528  0.4515  0.4515  0.4473  0.4422  0.4422  0.4409
[49 : 64]:	0.4386  0.4332  0.4332  0.4310  0.4300  0.4284  0.4284  0.4279  0.4279  0.4279  0.4262  0.4248  0.4248  0.4242  0.4220  0.4218
2024-04-29 05:47:36 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 05:47:36 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 05:48:44 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #385: GFLOPs: 886.3337. Time: 261.2019 us. Best GFLOPs: 980.1472
2024-04-29 05:48:44 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #386: GFLOPs: 785.7631. Time: 294.6334 us. Best GFLOPs: 980.1472
2024-04-29 05:48:44 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #387: GFLOPs: 332.8974. Time: 695.4456 us. Best GFLOPs: 980.1472
2024-04-29 05:48:44 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #388: GFLOPs: 338.3614. Time: 684.2154 us. Best GFLOPs: 980.1472
2024-04-29 05:48:44 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #389: GFLOPs: 138.6718. Time: 1669.4959 us. Best GFLOPs: 980.1472
2024-04-29 05:48:44 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #390: GFLOPs: 740.8196. Time: 312.5080 us. Best GFLOPs: 980.1472
2024-04-29 05:48:44 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #391: GFLOPs: 609.3207. Time: 379.9511 us. Best GFLOPs: 980.1472
2024-04-29 05:48:44 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #392: GFLOPs: 966.6222. Time: 239.5063 us. Best GFLOPs: 980.1472
2024-04-29 05:48:44 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #393: GFLOPs: 344.8285. Time: 671.3833 us. Best GFLOPs: 980.1472
2024-04-29 05:48:44 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #394: GFLOPs: 677.1074. Time: 341.9134 us. Best GFLOPs: 980.1472
2024-04-29 05:48:44 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #395: GFLOPs: 595.4578. Time: 388.7967 us. Best GFLOPs: 980.1472
2024-04-29 05:48:44 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #396: GFLOPs: 632.4682. Time: 366.0454 us. Best GFLOPs: 980.1472
2024-04-29 05:48:44 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #397: GFLOPs: 596.2564. Time: 388.2760 us. Best GFLOPs: 980.1472
2024-04-29 05:48:44 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #398: GFLOPs: 650.2037. Time: 356.0608 us. Best GFLOPs: 980.1472
2024-04-29 05:48:44 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #399: GFLOPs: 597.8768. Time: 387.2237 us. Best GFLOPs: 980.1472
2024-04-29 05:48:44 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #400: GFLOPs: 39.4495. Time: 5868.5671 us. Best GFLOPs: 980.1472
2024-04-29 05:48:44 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #401: GFLOPs: 124.9842. Time: 1852.3311 us. Best GFLOPs: 980.1472
2024-04-29 05:48:44 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #402: GFLOPs: 35.7651. Time: 6473.1317 us. Best GFLOPs: 980.1472
2024-04-29 05:48:44 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #403: GFLOPs: 39.7644. Time: 5822.0956 us. Best GFLOPs: 980.1472
2024-04-29 05:48:44 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #404: GFLOPs: 279.1129. Time: 829.4566 us. Best GFLOPs: 980.1472
2024-04-29 05:48:44 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #405: GFLOPs: 368.5170. Time: 628.2264 us. Best GFLOPs: 980.1472
2024-04-29 05:48:44 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #406: GFLOPs: 297.2969. Time: 778.7235 us. Best GFLOPs: 980.1472
2024-04-29 05:48:44 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #407: GFLOPs: 368.0923. Time: 628.9511 us. Best GFLOPs: 980.1472
2024-04-29 05:48:44 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #408: GFLOPs: 164.3216. Time: 1408.8960 us. Best GFLOPs: 980.1472
2024-04-29 05:48:44 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #409: GFLOPs: 74.2927. Time: 3116.2148 us. Best GFLOPs: 980.1472
2024-04-29 05:48:44 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #410: GFLOPs: 47.0876. Time: 4916.6241 us. Best GFLOPs: 980.1472
2024-04-29 05:48:44 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #411: GFLOPs: 82.2806. Time: 2813.6906 us. Best GFLOPs: 980.1472
2024-04-29 05:48:44 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #412: GFLOPs: 434.9803. Time: 532.2357 us. Best GFLOPs: 980.1472
2024-04-29 05:48:44 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #413: GFLOPs: 481.8863. Time: 480.4288 us. Best GFLOPs: 980.1472
2024-04-29 05:48:44 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #414: GFLOPs: 336.8202. Time: 687.3461 us. Best GFLOPs: 980.1472
2024-04-29 05:48:44 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #415: GFLOPs: 304.5347. Time: 760.2156 us. Best GFLOPs: 980.1472
2024-04-29 05:48:44 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #416: GFLOPs: 404.3610. Time: 572.5380 us. Best GFLOPs: 980.1472
2024-04-29 05:48:44 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #417: GFLOPs: 194.1776. Time: 1192.2697 us. Best GFLOPs: 980.1472
2024-04-29 05:48:44 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #418: GFLOPs: 357.2284. Time: 648.0785 us. Best GFLOPs: 980.1472
2024-04-29 05:48:44 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #419: GFLOPs: 434.1631. Time: 533.2375 us. Best GFLOPs: 980.1472
2024-04-29 05:48:44 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #420: GFLOPs: 535.1751. Time: 432.5913 us. Best GFLOPs: 980.1472
2024-04-29 05:48:44 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #421: GFLOPs: 483.4655. Time: 478.8595 us. Best GFLOPs: 980.1472
2024-04-29 05:48:44 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #422: GFLOPs: 351.5712. Time: 658.5069 us. Best GFLOPs: 980.1472
2024-04-29 05:48:44 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #423: GFLOPs: 79.4249. Time: 2914.8533 us. Best GFLOPs: 980.1472
2024-04-29 05:48:44 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #424: GFLOPs: 397.3352. Time: 582.6618 us. Best GFLOPs: 980.1472
2024-04-29 05:48:44 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #425: GFLOPs: 468.4702. Time: 494.1874 us. Best GFLOPs: 980.1472
2024-04-29 05:48:44 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #426: GFLOPs: 404.4981. Time: 572.3441 us. Best GFLOPs: 980.1472
2024-04-29 05:48:44 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #427: GFLOPs: 409.4821. Time: 565.3777 us. Best GFLOPs: 980.1472
2024-04-29 05:48:44 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #428: GFLOPs: 519.2998. Time: 445.8158 us. Best GFLOPs: 980.1472
2024-04-29 05:48:44 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #429: GFLOPs: 61.5536. Time: 3761.1429 us. Best GFLOPs: 980.1472
2024-04-29 05:48:44 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #430: GFLOPs: 47.7281. Time: 4850.6444 us. Best GFLOPs: 980.1472
2024-04-29 05:48:44 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #431: GFLOPs: 388.3444. Time: 596.1515 us. Best GFLOPs: 980.1472
2024-04-29 05:48:44 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #432: GFLOPs: 296.6322. Time: 780.4684 us. Best GFLOPs: 980.1472
2024-04-29 05:48:44 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #433: GFLOPs: 417.0656. Time: 555.0975 us. Best GFLOPs: 980.1472
2024-04-29 05:48:44 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #434: GFLOPs: 409.0475. Time: 565.9785 us. Best GFLOPs: 980.1472
2024-04-29 05:48:44 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #435: GFLOPs: 283.3954. Time: 816.9225 us. Best GFLOPs: 980.1472
2024-04-29 05:48:44 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #436: GFLOPs: 546.2042. Time: 423.8562 us. Best GFLOPs: 980.1472
2024-04-29 05:48:44 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #437: GFLOPs: 530.6482. Time: 436.2816 us. Best GFLOPs: 980.1472
2024-04-29 05:48:44 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #438: GFLOPs: 648.2315. Time: 357.1441 us. Best GFLOPs: 980.1472
2024-04-29 05:48:44 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #439: GFLOPs: 647.4632. Time: 357.5679 us. Best GFLOPs: 980.1472
2024-04-29 05:48:44 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #440: GFLOPs: 57.8201. Time: 4004.0045 us. Best GFLOPs: 980.1472
2024-04-29 05:48:44 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #441: GFLOPs: 360.3942. Time: 642.3856 us. Best GFLOPs: 980.1472
2024-04-29 05:48:44 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #442: GFLOPs: 361.4987. Time: 640.4230 us. Best GFLOPs: 980.1472
2024-04-29 05:48:44 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #443: GFLOPs: 506.6610. Time: 456.9369 us. Best GFLOPs: 980.1472
2024-04-29 05:48:44 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #444: GFLOPs: 400.2273. Time: 578.4514 us. Best GFLOPs: 980.1472
2024-04-29 05:48:44 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #445: GFLOPs: 407.9183. Time: 567.5451 us. Best GFLOPs: 980.1472
2024-04-29 05:48:44 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #446: GFLOPs: 89.7647. Time: 2579.0995 us. Best GFLOPs: 980.1472
2024-04-29 05:48:44 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #447: GFLOPs: 19.3489. Time: 11965.0993 us. Best GFLOPs: 980.1472
2024-04-29 05:48:44 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #448: GFLOPs: 24.1548. Time: 9584.5323 us. Best GFLOPs: 980.1472
2024-04-29 06:07:31 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 06:07:32 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-29 06:07:37 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4391338)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x38dd208)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x4182678)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x6ddeb88)]: 0 failure(s)
2024-04-29 06:07:37 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-29 06:07:49 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4391338)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x38dd208)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x4182678)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x6ddeb88)]: 0 failure(s)
2024-04-29 06:08:03 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4391338)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x38dd208)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x4182678)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x6ddeb88)]: 0 failure(s)
2024-04-29 06:08:17 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4391338)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x38dd208)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x4182678)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x6ddeb88)]: 0 failure(s)
2024-04-29 06:08:31 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4391338)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x38dd208)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x4182678)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x6ddeb88)]: 0 failure(s)
2024-04-29 06:08:40 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.8886  0.7957  0.7956  0.7712  0.7692  0.7578  0.7422  0.7387  0.7241  0.7216  0.7028  0.6961  0.6792  0.6790  0.6756  0.6754
[17 : 32]:	0.6752  0.6733  0.6731  0.6653  0.6631  0.6618  0.6593  0.6562  0.6546  0.6444  0.6420  0.6389  0.6367  0.6362  0.6345  0.6183
[33 : 48]:	0.6183  0.6134  0.6102  0.6102  0.6086  0.6070  0.6050  0.6031  0.6028  0.6028  0.6011  0.5924  0.5852  0.5820  0.5784  0.5725
[49 : 64]:	0.5725  0.5694  0.5668  0.5613  0.5576  0.5503  0.5492  0.5469  0.5463  0.5463  0.5396  0.5392  0.5285  0.5285  0.5283  0.5269
2024-04-29 06:08:40 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 06:08:40 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 06:09:51 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #449: GFLOPs: 790.9259. Time: 292.7102 us. Best GFLOPs: 980.1472
2024-04-29 06:09:51 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #450: GFLOPs: 844.5922. Time: 274.1111 us. Best GFLOPs: 980.1472
2024-04-29 06:09:51 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #451: GFLOPs: 858.6991. Time: 269.6079 us. Best GFLOPs: 980.1472
2024-04-29 06:09:51 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #452: GFLOPs: 847.4168. Time: 273.1974 us. Best GFLOPs: 980.1472
2024-04-29 06:09:51 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #453: GFLOPs: 837.9821. Time: 276.2733 us. Best GFLOPs: 980.1472
2024-04-29 06:09:51 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #454: GFLOPs: 853.4895. Time: 271.2536 us. Best GFLOPs: 980.1472
2024-04-29 06:09:51 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #455: GFLOPs: 775.2801. Time: 298.6173 us. Best GFLOPs: 980.1472
2024-04-29 06:09:51 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #456: GFLOPs: 497.8946. Time: 464.9821 us. Best GFLOPs: 980.1472
2024-04-29 06:09:51 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #457: GFLOPs: 598.3443. Time: 386.9211 us. Best GFLOPs: 980.1472
2024-04-29 06:09:51 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #458: GFLOPs: 686.7141. Time: 337.1302 us. Best GFLOPs: 980.1472
2024-04-29 06:09:51 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #459: GFLOPs: 646.5796. Time: 358.0566 us. Best GFLOPs: 980.1472
2024-04-29 06:09:51 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #460: GFLOPs: 882.6378. Time: 262.2957 us. Best GFLOPs: 980.1472
2024-04-29 06:09:51 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #461: GFLOPs: 738.4990. Time: 313.4900 us. Best GFLOPs: 980.1472
2024-04-29 06:09:51 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #462: GFLOPs: 662.3810. Time: 349.5149 us. Best GFLOPs: 980.1472
2024-04-29 06:09:51 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #463: GFLOPs: 358.5333. Time: 645.7199 us. Best GFLOPs: 980.1472
2024-04-29 06:09:51 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #464: GFLOPs: 753.3164. Time: 307.3238 us. Best GFLOPs: 980.1472
2024-04-29 06:09:51 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #465: GFLOPs: 645.9013. Time: 358.4326 us. Best GFLOPs: 980.1472
2024-04-29 06:09:51 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #466: GFLOPs: 685.4023. Time: 337.7754 us. Best GFLOPs: 980.1472
2024-04-29 06:09:51 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #467: GFLOPs: 647.3907. Time: 357.6079 us. Best GFLOPs: 980.1472
2024-04-29 06:09:51 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #468: GFLOPs: 671.2846. Time: 344.8792 us. Best GFLOPs: 980.1472
2024-04-29 06:09:51 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #469: GFLOPs: 654.0069. Time: 353.9903 us. Best GFLOPs: 980.1472
2024-04-29 06:09:51 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #470: GFLOPs: 651.1141. Time: 355.5630 us. Best GFLOPs: 980.1472
2024-04-29 06:09:51 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #471: GFLOPs: 693.2523. Time: 333.9507 us. Best GFLOPs: 980.1472
2024-04-29 06:09:51 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #472: GFLOPs: 872.3962. Time: 265.3749 us. Best GFLOPs: 980.1472
2024-04-29 06:09:51 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #473: GFLOPs: 553.0425. Time: 418.6153 us. Best GFLOPs: 980.1472
2024-04-29 06:09:51 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #474: GFLOPs: 107.1609. Time: 2160.4159 us. Best GFLOPs: 980.1472
2024-04-29 06:09:51 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #475: GFLOPs: 738.4648. Time: 313.5045 us. Best GFLOPs: 980.1472
2024-04-29 06:09:51 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #476: GFLOPs: 718.3558. Time: 322.2805 us. Best GFLOPs: 980.1472
2024-04-29 06:09:51 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #477: GFLOPs: 789.0118. Time: 293.4203 us. Best GFLOPs: 980.1472
2024-04-29 06:09:51 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #478: GFLOPs: 425.9238. Time: 543.5528 us. Best GFLOPs: 980.1472
2024-04-29 06:09:51 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #479: GFLOPs: 562.1727. Time: 411.8166 us. Best GFLOPs: 980.1472
2024-04-29 06:09:51 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #480: GFLOPs: 535.3702. Time: 432.4336 us. Best GFLOPs: 980.1472
2024-04-29 06:09:51 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #481: GFLOPs: 521.9694. Time: 443.5357 us. Best GFLOPs: 980.1472
2024-04-29 06:09:51 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #482: GFLOPs: 663.4761. Time: 348.9381 us. Best GFLOPs: 980.1472
2024-04-29 06:09:51 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #483: GFLOPs: 617.2247. Time: 375.0855 us. Best GFLOPs: 980.1472
2024-04-29 06:09:51 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #484: GFLOPs: 129.9132. Time: 1782.0517 us. Best GFLOPs: 980.1472
2024-04-29 06:09:51 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #485: GFLOPs: 576.2895. Time: 401.7287 us. Best GFLOPs: 980.1472
2024-04-29 06:09:51 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #486: GFLOPs: 655.2450. Time: 353.3214 us. Best GFLOPs: 980.1472
2024-04-29 06:09:51 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #487: GFLOPs: 656.3643. Time: 352.7188 us. Best GFLOPs: 980.1472
2024-04-29 06:09:51 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #488: GFLOPs: 76.4526. Time: 3028.1759 us. Best GFLOPs: 980.1472
2024-04-29 06:09:51 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #489: GFLOPs: 572.2896. Time: 404.5366 us. Best GFLOPs: 980.1472
2024-04-29 06:09:51 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #490: GFLOPs: 485.8397. Time: 476.5194 us. Best GFLOPs: 980.1472
2024-04-29 06:09:51 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #491: GFLOPs: 93.1396. Time: 2485.6446 us. Best GFLOPs: 980.1472
2024-04-29 06:09:51 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #492: GFLOPs: 427.3953. Time: 541.6814 us. Best GFLOPs: 980.1472
2024-04-29 06:09:51 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #493: GFLOPs: 525.0187. Time: 440.9596 us. Best GFLOPs: 980.1472
2024-04-29 06:09:51 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #494: GFLOPs: 149.8903. Time: 1544.5433 us. Best GFLOPs: 980.1472
2024-04-29 06:09:51 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #495: GFLOPs: 783.3114. Time: 295.5556 us. Best GFLOPs: 980.1472
2024-04-29 06:09:51 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #496: GFLOPs: 661.9301. Time: 349.7530 us. Best GFLOPs: 980.1472
2024-04-29 06:09:51 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #497: GFLOPs: 639.2121. Time: 362.1835 us. Best GFLOPs: 980.1472
2024-04-29 06:09:51 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #498: GFLOPs: 475.5060. Time: 486.8752 us. Best GFLOPs: 980.1472
2024-04-29 06:09:51 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #499: GFLOPs: 810.6930. Time: 285.5730 us. Best GFLOPs: 980.1472
2024-04-29 06:09:51 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #500: GFLOPs: 356.9023. Time: 648.6708 us. Best GFLOPs: 980.1472
2024-04-29 06:09:51 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #501: GFLOPs: 584.7654. Time: 395.9059 us. Best GFLOPs: 980.1472
2024-04-29 06:09:51 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #502: GFLOPs: 584.1827. Time: 396.3008 us. Best GFLOPs: 980.1472
2024-04-29 06:09:51 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #503: GFLOPs: 515.6418. Time: 448.9785 us. Best GFLOPs: 980.1472
2024-04-29 06:09:51 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #504: GFLOPs: 599.1881. Time: 386.3763 us. Best GFLOPs: 980.1472
2024-04-29 06:09:51 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #505: GFLOPs: 536.6491. Time: 431.4030 us. Best GFLOPs: 980.1472
2024-04-29 06:09:51 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #506: GFLOPs: 549.3490. Time: 421.4298 us. Best GFLOPs: 980.1472
2024-04-29 06:09:51 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #507: GFLOPs: 239.4248. Time: 966.9512 us. Best GFLOPs: 980.1472
2024-04-29 06:09:51 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #508: GFLOPs: 599.3744. Time: 386.2562 us. Best GFLOPs: 980.1472
2024-04-29 06:09:51 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #509: GFLOPs: 487.5676. Time: 474.8307 us. Best GFLOPs: 980.1472
2024-04-29 06:09:51 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #510: GFLOPs: 18.1107. Time: 12783.1374 us. Best GFLOPs: 980.1472
2024-04-29 06:09:51 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #511: GFLOPs: 3.3318. Time: 69485.8380 us. Best GFLOPs: 980.1472
2024-04-29 06:09:51 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #512: GFLOPs: 35.2611. Time: 6565.6560 us. Best GFLOPs: 980.1472
2024-04-29 06:30:30 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 06:30:32 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-29 06:30:36 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4391338)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x38dd208)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x4182678)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x6ddeb88)]: 0 failure(s)
2024-04-29 06:30:36 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-29 06:30:49 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4391338)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x38dd208)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x4182678)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x6ddeb88)]: 0 failure(s)
2024-04-29 06:31:03 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4391338)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x38dd208)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x4182678)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x6ddeb88)]: 0 failure(s)
2024-04-29 06:31:17 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4391338)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x38dd208)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x4182678)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x6ddeb88)]: 0 failure(s)
2024-04-29 06:31:31 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4391338)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x38dd208)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x4182678)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x6ddeb88)]: 0 failure(s)
2024-04-29 06:31:40 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9186  0.8743  0.8482  0.8482  0.8482  0.8376  0.8351  0.8290  0.8133  0.8001  0.7938  0.7805  0.7673  0.7620  0.7599  0.7503
[17 : 32]:	0.7476  0.7471  0.7471  0.7471  0.7368  0.7323  0.7281  0.7247  0.7175  0.7098  0.6924  0.6924  0.6888  0.6861  0.6861  0.6825
[33 : 48]:	0.6825  0.6812  0.6774  0.6773  0.6764  0.6732  0.6677  0.6677  0.6613  0.6526  0.6526  0.6497  0.6490  0.6490  0.6479  0.6471
[49 : 64]:	0.6453  0.6439  0.6419  0.6391  0.6391  0.6385  0.6365  0.6365  0.6355  0.6315  0.6294  0.6283  0.6277  0.6252  0.6250  0.6239
2024-04-29 06:31:40 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 06:31:40 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 06:33:13 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #513: GFLOPs: 449.5552. Time: 514.9803 us. Best GFLOPs: 980.1472
2024-04-29 06:33:13 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #514: GFLOPs: 964.4809. Time: 240.0380 us. Best GFLOPs: 980.1472
2024-04-29 06:33:13 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #515: GFLOPs: 856.1040. Time: 270.4252 us. Best GFLOPs: 980.1472
2024-04-29 06:33:13 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #516: GFLOPs: 869.3889. Time: 266.2929 us. Best GFLOPs: 980.1472
2024-04-29 06:33:13 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #517: GFLOPs: 837.5447. Time: 276.4176 us. Best GFLOPs: 980.1472
2024-04-29 06:33:13 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #518: GFLOPs: 863.8932. Time: 267.9869 us. Best GFLOPs: 980.1472
2024-04-29 06:33:13 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #519: GFLOPs: 782.8917. Time: 295.7140 us. Best GFLOPs: 980.1472
2024-04-29 06:33:13 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #520: GFLOPs: 910.4959. Time: 254.2703 us. Best GFLOPs: 980.1472
2024-04-29 06:33:13 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #521: GFLOPs: 846.5173. Time: 273.4877 us. Best GFLOPs: 980.1472
2024-04-29 06:33:13 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #522: GFLOPs: 815.9734. Time: 283.7250 us. Best GFLOPs: 980.1472
2024-04-29 06:33:13 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #523: GFLOPs: 845.1982. Time: 273.9145 us. Best GFLOPs: 980.1472
2024-04-29 06:33:13 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #524: GFLOPs: 815.9359. Time: 283.7380 us. Best GFLOPs: 980.1472
2024-04-29 06:33:13 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #525: GFLOPs: 772.5685. Time: 299.6654 us. Best GFLOPs: 980.1472
2024-04-29 06:33:13 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #526: GFLOPs: 799.2848. Time: 289.6490 us. Best GFLOPs: 980.1472
2024-04-29 06:33:13 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #527: GFLOPs: 849.8217. Time: 272.4243 us. Best GFLOPs: 980.1472
2024-04-29 06:33:13 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #528: GFLOPs: 519.4901. Time: 445.6525 us. Best GFLOPs: 980.1472
2024-04-29 06:33:13 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #529: GFLOPs: 937.1214. Time: 247.0460 us. Best GFLOPs: 980.1472
2024-04-29 06:33:13 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #530: GFLOPs: 851.5758. Time: 271.8631 us. Best GFLOPs: 980.1472
2024-04-29 06:33:13 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #531: GFLOPs: 811.9824. Time: 285.1196 us. Best GFLOPs: 980.1472
2024-04-29 06:33:13 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #532: GFLOPs: 680.3272. Time: 340.2952 us. Best GFLOPs: 980.1472
2024-04-29 06:33:13 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #533: GFLOPs: 683.2806. Time: 338.8243 us. Best GFLOPs: 980.1472
2024-04-29 06:33:13 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #534: GFLOPs: 137.2943. Time: 1686.2467 us. Best GFLOPs: 980.1472
2024-04-29 06:33:13 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #535: GFLOPs: 753.2809. Time: 307.3383 us. Best GFLOPs: 980.1472
2024-04-29 06:33:13 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #536: GFLOPs: 718.1646. Time: 322.3663 us. Best GFLOPs: 980.1472
2024-04-29 06:33:13 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #537: GFLOPs: 180.4498. Time: 1282.9725 us. Best GFLOPs: 980.1472
2024-04-29 06:33:13 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #538: GFLOPs: 512.7107. Time: 451.5452 us. Best GFLOPs: 980.1472
2024-04-29 06:33:13 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #539: GFLOPs: 669.1851. Time: 345.9612 us. Best GFLOPs: 980.1472
2024-04-29 06:33:13 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #540: GFLOPs: 383.3552. Time: 603.9101 us. Best GFLOPs: 980.1472
2024-04-29 06:33:13 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #541: GFLOPs: 821.6197. Time: 281.7752 us. Best GFLOPs: 980.1472
2024-04-29 06:33:13 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #542: GFLOPs: 668.4084. Time: 346.3632 us. Best GFLOPs: 980.1472
2024-04-29 06:33:13 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #543: GFLOPs: 750.2799. Time: 308.5676 us. Best GFLOPs: 980.1472
2024-04-29 06:33:13 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #544: GFLOPs: 777.4840. Time: 297.7708 us. Best GFLOPs: 980.1472
2024-04-29 06:33:13 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #545: GFLOPs: 389.9198. Time: 593.7427 us. Best GFLOPs: 980.1472
2024-04-29 06:33:13 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #546: GFLOPs: 395.9607. Time: 584.6845 us. Best GFLOPs: 980.1472
2024-04-29 06:33:13 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #547: GFLOPs: 418.3501. Time: 553.3932 us. Best GFLOPs: 980.1472
2024-04-29 06:33:13 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #548: GFLOPs: 806.5293. Time: 287.0473 us. Best GFLOPs: 980.1472
2024-04-29 06:33:13 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #549: GFLOPs: 866.4434. Time: 267.1981 us. Best GFLOPs: 980.1472
2024-04-29 06:33:13 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #550: GFLOPs: 756.5042. Time: 306.0288 us. Best GFLOPs: 980.1472
2024-04-29 06:33:13 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #551: GFLOPs: 641.9418. Time: 360.6434 us. Best GFLOPs: 980.1472
2024-04-29 06:33:13 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #552: GFLOPs: 647.1032. Time: 357.7669 us. Best GFLOPs: 980.1472
2024-04-29 06:33:13 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #553: GFLOPs: 575.1318. Time: 402.5374 us. Best GFLOPs: 980.1472
2024-04-29 06:33:13 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #554: GFLOPs: 639.0393. Time: 362.2814 us. Best GFLOPs: 980.1472
2024-04-29 06:33:13 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #555: GFLOPs: 693.9286. Time: 333.6252 us. Best GFLOPs: 980.1472
2024-04-29 06:33:13 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #556: GFLOPs: 680.2087. Time: 340.3545 us. Best GFLOPs: 980.1472
2024-04-29 06:33:13 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #557: GFLOPs: 660.3077. Time: 350.6124 us. Best GFLOPs: 980.1472
2024-04-29 06:33:13 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #558: GFLOPs: 662.4022. Time: 349.5038 us. Best GFLOPs: 980.1472
2024-04-29 06:33:13 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #559: GFLOPs: 633.2567. Time: 365.5896 us. Best GFLOPs: 980.1472
2024-04-29 06:33:13 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #560: GFLOPs: 355.2749. Time: 651.6421 us. Best GFLOPs: 980.1472
2024-04-29 06:33:13 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #561: GFLOPs: 423.3199. Time: 546.8962 us. Best GFLOPs: 980.1472
2024-04-29 06:33:13 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #562: GFLOPs: 633.5284. Time: 365.4328 us. Best GFLOPs: 980.1472
2024-04-29 06:33:13 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #563: GFLOPs: 584.5609. Time: 396.0444 us. Best GFLOPs: 980.1472
2024-04-29 06:33:13 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #564: GFLOPs: 460.1105. Time: 503.1662 us. Best GFLOPs: 980.1472
2024-04-29 06:33:13 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #565: GFLOPs: 643.9091. Time: 359.5415 us. Best GFLOPs: 980.1472
2024-04-29 06:33:13 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #566: GFLOPs: 709.7936. Time: 326.1682 us. Best GFLOPs: 980.1472
2024-04-29 06:33:13 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #567: GFLOPs: 147.6967. Time: 1567.4827 us. Best GFLOPs: 980.1472
2024-04-29 06:33:13 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #568: GFLOPs: 726.5088. Time: 318.6638 us. Best GFLOPs: 980.1472
2024-04-29 06:33:13 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #569: GFLOPs: 459.4382. Time: 503.9025 us. Best GFLOPs: 980.1472
2024-04-29 06:33:13 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #570: GFLOPs: 426.8530. Time: 542.3696 us. Best GFLOPs: 980.1472
2024-04-29 06:33:13 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #571: GFLOPs: 573.3950. Time: 403.7567 us. Best GFLOPs: 980.1472
2024-04-29 06:33:13 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #572: GFLOPs: 647.2641. Time: 357.6779 us. Best GFLOPs: 980.1472
2024-04-29 06:33:13 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #573: GFLOPs: 574.7983. Time: 402.7710 us. Best GFLOPs: 980.1472
2024-04-29 06:33:13 [INFO] [task_scheduler.cc:121] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #574: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(128)), "float32"), p1: T.Buffer((T.int64(4), T.int64(1), T.int64(3), T.int64(3), T.int64(128), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(32)), "float32"), p3: T.Buffer((T.int64(1), T.int64(4), T.int64(28), T.int64(28), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(4), T.int64(28), T.int64(28), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(128)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(4), T.int64(28), T.int64(28), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused in T.parallel(T.int64(392), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(6), T.int64(3), T.int64(128)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(7) * T.int64(4) + ax2)
                    v_i3 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(196) // T.int64(7) + ax3)
                    v_i4 = T.axis.spatial(T.int64(128), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(2), T.int64(4), T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(4), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(196) * T.int64(2) + oc_chunk_2_init + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(7) * T.int64(4) + oh_2_init + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(196) // T.int64(7) + ow_1 + ow_2_init + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2_init * T.int64(4) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(2), T.int64(3), T.int64(3), T.int64(1), T.int64(2), T.int64(4), T.int64(1), T.int64(8), T.int64(64), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                    for oc_block_3_fused in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(4), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(196) * T.int64(2) + oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(7) * T.int64(4) + oh_2 + oh_3)
                            v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(196) // T.int64(7) + ow_1 + ow_2 + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2 * T.int64(4) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(128), ic_0 * T.int64(64) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
                for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(2), T.int64(4)):
                    for ax3_ax4_fused in T.vectorized(T.int64(32)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(4), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(196) * T.int64(2) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(7) * T.int64(4) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(196) // T.int64(7))
                            v_ax4 = T.axis.spatial(T.int64(32), ax3_ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 1, 2, 1])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 7, 4, 1])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[28, 1, 1, 1])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[1, 1, 8, 4])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[2, 64])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[3, 1])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l50, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=7)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b69)
l85 = sch.fuse(l72, l73, l74, l75, l76, l77, l78, l79, preserve_unit_iters=True)
sch.parallel(loop=l85)
l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b70)
l105 = sch.fuse(l86, preserve_unit_iters=True)
sch.parallel(loop=l105)
l106 = sch.fuse(l104, preserve_unit_iters=True)
sch.vectorize(loop=l106)
sch.annotate(block_or_loop=l105, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l105, ann_key="pragma_unroll_explicit", ann_val=1)
l107, l108, l109, l110, l111, l112, l113, l114 = sch.get_loops(block=b71)
l115 = sch.fuse(l113, l114, preserve_unit_iters=True)
sch.vectorize(loop=l115)
b116 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135 = sch.get_loops(block=b116)
b136 = sch.decompose_reduction(block=b116, loop=l120)
2024-04-29 06:33:13 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #575: GFLOPs: 33.1545. Time: 6982.8227 us. Best GFLOPs: 980.1472
2024-04-29 06:33:13 [INFO] [task_scheduler.cc:121] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #576: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(128)), "float32"), p1: T.Buffer((T.int64(4), T.int64(1), T.int64(3), T.int64(3), T.int64(128), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(32)), "float32"), p3: T.Buffer((T.int64(1), T.int64(4), T.int64(28), T.int64(28), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(4), T.int64(28), T.int64(28), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(128)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(4), T.int64(28), T.int64(28), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused in T.parallel(T.int64(64), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(2), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(7), T.int64(4), T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(4), oc_chunk_1 * T.int64(2) + oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(16) * T.int64(7) + oh_1 * T.int64(7) + oh_2_init * T.int64(7) + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(16) // T.int64(8) * T.int64(14) + ow_1 * T.int64(7) + ow_2_init + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(8) * T.int64(4) + oc_block_1 * T.int64(4) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0 in T.grid(T.int64(128), T.int64(3), T.int64(3)):
                    for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(7), T.int64(7), T.int64(1)):
                        with T.block("data_pad"):
                            v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                            v_i2 = T.axis.spatial(T.int64(30), kh_0 + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(16) * T.int64(7) + ax2)
                            v_i3 = T.axis.spatial(T.int64(30), kw_0 + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(16) // T.int64(8) * T.int64(14) + ow_1 * T.int64(7) + ax3)
                            v_i4 = T.axis.spatial(T.int64(128), ic_0 + ax4)
                            T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                            T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                            data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                    for n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(7), T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(1)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(4), oc_chunk_1 * T.int64(2) + oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(16) * T.int64(7) + oh_1 * T.int64(7) + oh_2 * T.int64(7) + oh_3)
                            v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(16) // T.int64(8) * T.int64(14) + ow_1 * T.int64(7) + ow_2 + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(8) * T.int64(4) + oc_block_1 * T.int64(4) + oc_block_2 + oc_block_3)
                            v_ic = T.axis.reduce(T.int64(128), ic_0 + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(4), T.int64(7), T.int64(14)):
                for ax4_fused in T.vectorized(T.int64(4)):
                    with T.block("T_relu"):
                        v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                        v_ax2 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(16) * T.int64(7) + ax2)
                        v_ax3 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(16) // T.int64(8) * T.int64(14) + ax3)
                        v_ax4 = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(8) * T.int64(4) + ax4_fused)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 2, 2, 1])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[4, 1, 1, 7])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[2, 2, 7, 1])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[8, 1, 4, 1])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[128, 1])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[3, 1])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=12)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89 = sch.get_loops(block=b69)
l90 = sch.fuse(l72, l73, l74, l75, l76, preserve_unit_iters=True)
sch.parallel(loop=l90)
l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107, l108, l109, l110, l111, l112 = sch.get_loops(block=b70)
l113 = sch.fuse(l91, preserve_unit_iters=True)
sch.parallel(loop=l113)
sch.annotate(block_or_loop=l113, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l113, ann_key="pragma_unroll_explicit", ann_val=1)
l114, l115, l116, l117, l118, l119 = sch.get_loops(block=b71)
l120 = sch.fuse(l119, preserve_unit_iters=True)
sch.vectorize(loop=l120)
b121 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141, l142, l143 = sch.get_loops(block=b121)
b144 = sch.decompose_reduction(block=b121, loop=l128)
2024-04-29 07:31:21 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 07:31:22 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-29 07:31:27 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4391338)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x38dd208)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x4182678)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x6ddeb88)]: 0 failure(s)
2024-04-29 07:31:27 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-29 07:31:39 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4391338)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x38dd208)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x4182678)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x6ddeb88)]: 0 failure(s)
2024-04-29 07:31:53 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4391338)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x38dd208)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x4182678)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x6ddeb88)]: 0 failure(s)
2024-04-29 07:32:07 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4391338)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x38dd208)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x4182678)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x6ddeb88)]: 0 failure(s)
2024-04-29 07:32:21 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4391338)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x38dd208)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x4182678)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x6ddeb88)]: 0 failure(s)
2024-04-29 07:32:29 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9602  0.8710  0.8642  0.8545  0.8545  0.8197  0.8153  0.8151  0.8120  0.8030  0.8003  0.7845  0.7830  0.7830  0.7732  0.7723
[17 : 32]:	0.7648  0.7648  0.7641  0.7629  0.7629  0.7612  0.7441  0.7427  0.7424  0.7394  0.7322  0.7300  0.7293  0.7293  0.7275  0.7259
[33 : 48]:	0.7222  0.7222  0.7182  0.7146  0.7146  0.7146  0.7139  0.7053  0.6960  0.6952  0.6945  0.6904  0.6850  0.6798  0.6797  0.6777
[49 : 64]:	0.6760  0.6759  0.6755  0.6737  0.6717  0.6708  0.6706  0.6695  0.6687  0.6677  0.6677  0.6669  0.6668  0.6645  0.6632  0.6632
2024-04-29 07:32:30 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 07:32:30 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 07:34:06 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #577: GFLOPs: 494.6872. Time: 467.9968 us. Best GFLOPs: 980.1472
2024-04-29 07:34:06 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #578: GFLOPs: 431.4113. Time: 536.6388 us. Best GFLOPs: 980.1472
2024-04-29 07:34:06 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #579: GFLOPs: 807.3208. Time: 286.7659 us. Best GFLOPs: 980.1472
2024-04-29 07:34:06 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #580: GFLOPs: 854.8278. Time: 270.8289 us. Best GFLOPs: 980.1472
2024-04-29 07:34:06 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #581: GFLOPs: 841.7993. Time: 275.0205 us. Best GFLOPs: 980.1472
2024-04-29 07:34:06 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #582: GFLOPs: 527.8995. Time: 438.5533 us. Best GFLOPs: 980.1472
2024-04-29 07:34:06 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #583: GFLOPs: 948.9737. Time: 243.9605 us. Best GFLOPs: 980.1472
2024-04-29 07:34:06 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #584: GFLOPs: 780.5759. Time: 296.5914 us. Best GFLOPs: 980.1472
2024-04-29 07:34:06 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #585: GFLOPs: 413.4555. Time: 559.9444 us. Best GFLOPs: 980.1472
2024-04-29 07:34:06 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #586: GFLOPs: 785.9459. Time: 294.5649 us. Best GFLOPs: 980.1472
2024-04-29 07:34:06 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #587: GFLOPs: 853.6936. Time: 271.1887 us. Best GFLOPs: 980.1472
2024-04-29 07:34:06 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #588: GFLOPs: 847.7074. Time: 273.1037 us. Best GFLOPs: 980.1472
2024-04-29 07:34:06 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #589: GFLOPs: 811.2293. Time: 285.3843 us. Best GFLOPs: 980.1472
2024-04-29 07:34:06 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #590: GFLOPs: 777.9792. Time: 297.5813 us. Best GFLOPs: 980.1472
2024-04-29 07:34:06 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #591: GFLOPs: 815.6205. Time: 283.8478 us. Best GFLOPs: 980.1472
2024-04-29 07:34:06 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #592: GFLOPs: 906.4052. Time: 255.4178 us. Best GFLOPs: 980.1472
2024-04-29 07:34:06 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #593: GFLOPs: 732.4220. Time: 316.0911 us. Best GFLOPs: 980.1472
2024-04-29 07:34:06 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #594: GFLOPs: 821.2252. Time: 281.9106 us. Best GFLOPs: 980.1472
2024-04-29 07:34:06 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #595: GFLOPs: 913.4138. Time: 253.4580 us. Best GFLOPs: 980.1472
2024-04-29 07:34:06 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #596: GFLOPs: 674.2626. Time: 343.3559 us. Best GFLOPs: 980.1472
2024-04-29 07:34:06 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #597: GFLOPs: 715.9087. Time: 323.3821 us. Best GFLOPs: 980.1472
2024-04-29 07:34:06 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #598: GFLOPs: 717.6522. Time: 322.5964 us. Best GFLOPs: 980.1472
2024-04-29 07:34:06 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #599: GFLOPs: 140.2574. Time: 1650.6223 us. Best GFLOPs: 980.1472
2024-04-29 07:34:06 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #600: GFLOPs: 709.7680. Time: 326.1799 us. Best GFLOPs: 980.1472
2024-04-29 07:34:06 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #601: GFLOPs: 675.9535. Time: 342.4970 us. Best GFLOPs: 980.1472
2024-04-29 07:34:06 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #602: GFLOPs: 711.4170. Time: 325.4238 us. Best GFLOPs: 980.1472
2024-04-29 07:34:06 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #603: GFLOPs: 842.3381. Time: 274.8446 us. Best GFLOPs: 980.1472
2024-04-29 07:34:06 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #604: GFLOPs: 832.3873. Time: 278.1302 us. Best GFLOPs: 980.1472
2024-04-29 07:34:06 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #605: GFLOPs: 818.3220. Time: 282.9107 us. Best GFLOPs: 980.1472
2024-04-29 07:34:06 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #606: GFLOPs: 821.9123. Time: 281.6749 us. Best GFLOPs: 980.1472
2024-04-29 07:34:06 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #607: GFLOPs: 740.0811. Time: 312.8199 us. Best GFLOPs: 980.1472
2024-04-29 07:34:06 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #608: GFLOPs: 603.9304. Time: 383.3423 us. Best GFLOPs: 980.1472
2024-04-29 07:34:06 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #609: GFLOPs: 367.9615. Time: 629.1748 us. Best GFLOPs: 980.1472
2024-04-29 07:34:06 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #610: GFLOPs: 713.8658. Time: 324.3075 us. Best GFLOPs: 980.1472
2024-04-29 07:34:06 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #611: GFLOPs: 412.6806. Time: 560.9958 us. Best GFLOPs: 980.1472
2024-04-29 07:34:06 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #612: GFLOPs: 628.0525. Time: 368.6190 us. Best GFLOPs: 980.1472
2024-04-29 07:34:06 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #613: GFLOPs: 693.9251. Time: 333.6269 us. Best GFLOPs: 980.1472
2024-04-29 07:34:06 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #614: GFLOPs: 678.5910. Time: 341.1658 us. Best GFLOPs: 980.1472
2024-04-29 07:34:06 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #615: GFLOPs: 647.0920. Time: 357.7730 us. Best GFLOPs: 980.1472
2024-04-29 07:34:06 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #616: GFLOPs: 668.4613. Time: 346.3358 us. Best GFLOPs: 980.1472
2024-04-29 07:34:06 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #617: GFLOPs: 633.9455. Time: 365.1924 us. Best GFLOPs: 980.1472
2024-04-29 07:34:06 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #618: GFLOPs: 738.8654. Time: 313.3345 us. Best GFLOPs: 980.1472
2024-04-29 07:34:06 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #619: GFLOPs: 773.2584. Time: 299.3981 us. Best GFLOPs: 980.1472
2024-04-29 07:34:06 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #620: GFLOPs: 713.8914. Time: 324.2959 us. Best GFLOPs: 980.1472
2024-04-29 07:34:06 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #621: GFLOPs: 796.0930. Time: 290.8103 us. Best GFLOPs: 980.1472
2024-04-29 07:34:06 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #622: GFLOPs: 517.0668. Time: 447.7411 us. Best GFLOPs: 980.1472
2024-04-29 07:34:06 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #623: GFLOPs: 813.0272. Time: 284.7532 us. Best GFLOPs: 980.1472
2024-04-29 07:34:06 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #624: GFLOPs: 681.4445. Time: 339.7372 us. Best GFLOPs: 980.1472
2024-04-29 07:34:06 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #625: GFLOPs: 361.2056. Time: 640.9427 us. Best GFLOPs: 980.1472
2024-04-29 07:34:06 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #626: GFLOPs: 705.0355. Time: 328.3694 us. Best GFLOPs: 980.1472
2024-04-29 07:34:06 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #627: GFLOPs: 699.4156. Time: 331.0079 us. Best GFLOPs: 980.1472
2024-04-29 07:34:06 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #628: GFLOPs: 869.4301. Time: 266.2802 us. Best GFLOPs: 980.1472
2024-04-29 07:34:06 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #629: GFLOPs: 798.5407. Time: 289.9189 us. Best GFLOPs: 980.1472
2024-04-29 07:34:06 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #630: GFLOPs: 850.9392. Time: 272.0665 us. Best GFLOPs: 980.1472
2024-04-29 07:34:06 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #631: GFLOPs: 801.1188. Time: 288.9859 us. Best GFLOPs: 980.1472
2024-04-29 07:34:06 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #632: GFLOPs: 738.7513. Time: 313.3829 us. Best GFLOPs: 980.1472
2024-04-29 07:34:06 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #633: GFLOPs: 350.1197. Time: 661.2370 us. Best GFLOPs: 980.1472
2024-04-29 07:34:06 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #634: GFLOPs: 593.1646. Time: 390.2998 us. Best GFLOPs: 980.1472
2024-04-29 07:34:06 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #635: GFLOPs: 345.1277. Time: 670.8012 us. Best GFLOPs: 980.1472
2024-04-29 07:34:06 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #636: GFLOPs: 738.9015. Time: 313.3192 us. Best GFLOPs: 980.1472
2024-04-29 07:34:06 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #637: GFLOPs: 625.8768. Time: 369.9004 us. Best GFLOPs: 980.1472
2024-04-29 07:34:06 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #638: GFLOPs: 4.2915. Time: 53946.2220 us. Best GFLOPs: 980.1472
2024-04-29 07:34:06 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #639: GFLOPs: 54.9008. Time: 4216.9166 us. Best GFLOPs: 980.1472
2024-04-29 07:34:06 [INFO] [task_scheduler.cc:121] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #640: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(128)), "float32"), p1: T.Buffer((T.int64(4), T.int64(1), T.int64(3), T.int64(3), T.int64(128), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(32)), "float32"), p3: T.Buffer((T.int64(1), T.int64(4), T.int64(28), T.int64(28), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(4), T.int64(28), T.int64(28), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(128)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(4), T.int64(28), T.int64(28), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_fused_fused in T.parallel(T.int64(7), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(6), T.int64(30), T.int64(128)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_fused_fused * T.int64(4) + ax2)
                    v_i3, v_i4 = T.axis.remap("SS", [ax3, ax4])
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for ow_0, oc_block_0 in T.grid(T.int64(1), T.int64(1)):
                for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(4)):
                    for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(4), T.int64(4), T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                        for oc_block_3_fused_init in T.vectorized(T.int64(8)):
                            with T.block("conv2d_NCHWc_init"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                                v_oc_chunk = T.axis.spatial(T.int64(4), oc_chunk_1 * T.int64(4) + oc_chunk_2_init + oc_chunk_3_init)
                                v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_fused_fused * T.int64(4) + oh_1 * T.int64(4) + oh_2_init + oh_3_init)
                                v_ow = T.axis.spatial(T.int64(28), ow_0 * T.int64(28) + ow_1 * T.int64(28) + ow_2_init * T.int64(7) + ow_3_init)
                                v_oc_block = T.axis.spatial(T.int64(32), oc_block_0 * T.int64(32) + oc_block_1 * T.int64(8) + oc_block_2_init * T.int64(8) + oc_block_3_fused_init)
                                T.reads()
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                    for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(16), T.int64(3), T.int64(1), T.int64(1), T.int64(4), T.int64(4), T.int64(4), T.int64(1), T.int64(8), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                        for oc_block_3_fused in T.vectorized(T.int64(8)):
                            with T.block("conv2d_NCHWc_update"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                                v_oc_chunk = T.axis.spatial(T.int64(4), oc_chunk_1 * T.int64(4) + oc_chunk_2 + oc_chunk_3)
                                v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_fused_fused * T.int64(4) + oh_1 * T.int64(4) + oh_2 + oh_3)
                                v_ow = T.axis.spatial(T.int64(28), ow_0 * T.int64(28) + ow_1 * T.int64(28) + ow_2 * T.int64(7) + ow_3)
                                v_oc_block = T.axis.spatial(T.int64(32), oc_block_0 * T.int64(32) + oc_block_1 * T.int64(8) + oc_block_2 * T.int64(8) + oc_block_3_fused)
                                v_ic = T.axis.reduce(T.int64(128), ic_0 * T.int64(8) + ic_1)
                                v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                                v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                                T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(4), T.int64(4), T.int64(28)):
                    for ax4_fused in T.vectorized(T.int64(32)):
                        with T.block("T_relu"):
                            v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                            v_ax2 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_fused_fused * T.int64(4) + ax2)
                            v_ax3, v_ax4 = T.axis.remap("SS", [ax3, ax4_fused])
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 4, 1])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[7, 1, 4, 1])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 4, 7])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[1, 4, 1, 8])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[16, 8])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[1, 3])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=2)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79 = sch.get_loops(block=b69)
l80 = sch.fuse(l72, l73, l74, preserve_unit_iters=True)
sch.parallel(loop=l80)
l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b70)
l105 = sch.fuse(l81, preserve_unit_iters=True)
sch.parallel(loop=l105)
l106 = sch.fuse(l104, preserve_unit_iters=True)
sch.vectorize(loop=l106)
sch.annotate(block_or_loop=l105, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l105, ann_key="pragma_unroll_explicit", ann_val=1)
l107, l108, l109, l110, l111, l112, l113, l114 = sch.get_loops(block=b71)
l115 = sch.fuse(l114, preserve_unit_iters=True)
sch.vectorize(loop=l115)
b116 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140 = sch.get_loops(block=b116)
b141 = sch.decompose_reduction(block=b116, loop=l125)
2024-04-29 07:49:49 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 07:49:50 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-29 07:49:55 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4391338)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x38dd208)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x4182678)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x6ddeb88)]: 0 failure(s)
2024-04-29 07:49:55 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-29 07:50:08 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4391338)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x38dd208)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x4182678)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x6ddeb88)]: 0 failure(s)
2024-04-29 07:50:21 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4391338)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x38dd208)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x4182678)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x6ddeb88)]: 0 failure(s)
2024-04-29 07:50:35 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4391338)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x38dd208)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x4182678)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x6ddeb88)]: 0 failure(s)
2024-04-29 07:50:48 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4391338)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x38dd208)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x4182678)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x6ddeb88)]: 0 failure(s)
2024-04-29 07:50:57 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9020  0.8808  0.8632  0.8613  0.8540  0.8453  0.8430  0.8362  0.8362  0.8327  0.8284  0.8258  0.8241  0.8241  0.8183  0.8174
[17 : 32]:	0.8148  0.8104  0.8091  0.8091  0.8091  0.8049  0.8046  0.8007  0.7982  0.7914  0.7896  0.7896  0.7887  0.7852  0.7852  0.7847
[33 : 48]:	0.7756  0.7756  0.7727  0.7708  0.7702  0.7626  0.7623  0.7619  0.7578  0.7571  0.7542  0.7529  0.7491  0.7466  0.7464  0.7462
[49 : 64]:	0.7439  0.7439  0.7395  0.7341  0.7215  0.7196  0.7195  0.7183  0.7162  0.7157  0.7109  0.7109  0.7105  0.7098  0.7077  0.7077
2024-04-29 07:50:57 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 07:50:58 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 07:52:29 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #641: GFLOPs: 474.1957. Time: 488.2205 us. Best GFLOPs: 980.1472
2024-04-29 07:52:29 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #642: GFLOPs: 966.1064. Time: 239.6341 us. Best GFLOPs: 980.1472
2024-04-29 07:52:29 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #643: GFLOPs: 879.4014. Time: 263.2610 us. Best GFLOPs: 980.1472
2024-04-29 07:52:29 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #644: GFLOPs: 822.2658. Time: 281.5538 us. Best GFLOPs: 980.1472
2024-04-29 07:52:29 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #645: GFLOPs: 891.0540. Time: 259.8182 us. Best GFLOPs: 980.1472
2024-04-29 07:52:29 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #646: GFLOPs: 822.7665. Time: 281.3825 us. Best GFLOPs: 980.1472
2024-04-29 07:52:29 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #647: GFLOPs: 963.8163. Time: 240.2035 us. Best GFLOPs: 980.1472
2024-04-29 07:52:29 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #648: GFLOPs: 912.0207. Time: 253.8452 us. Best GFLOPs: 980.1472
2024-04-29 07:52:29 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #649: GFLOPs: 543.1039. Time: 426.2758 us. Best GFLOPs: 980.1472
2024-04-29 07:52:29 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #650: GFLOPs: 791.7304. Time: 292.4127 us. Best GFLOPs: 980.1472
2024-04-29 07:52:29 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #651: GFLOPs: 843.5231. Time: 274.4585 us. Best GFLOPs: 980.1472
2024-04-29 07:52:29 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #652: GFLOPs: 648.9898. Time: 356.7268 us. Best GFLOPs: 980.1472
2024-04-29 07:52:29 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #653: GFLOPs: 910.4938. Time: 254.2709 us. Best GFLOPs: 980.1472
2024-04-29 07:52:29 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #654: GFLOPs: 863.7360. Time: 268.0357 us. Best GFLOPs: 980.1472
2024-04-29 07:52:29 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #655: GFLOPs: 823.3592. Time: 281.1799 us. Best GFLOPs: 980.1472
2024-04-29 07:52:29 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #656: GFLOPs: 783.2914. Time: 295.5631 us. Best GFLOPs: 980.1472
2024-04-29 07:52:29 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #657: GFLOPs: 835.5360. Time: 277.0821 us. Best GFLOPs: 980.1472
2024-04-29 07:52:29 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #658: GFLOPs: 778.6240. Time: 297.3349 us. Best GFLOPs: 980.1472
2024-04-29 07:52:29 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #659: GFLOPs: 856.9630. Time: 270.1541 us. Best GFLOPs: 980.1472
2024-04-29 07:52:29 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #660: GFLOPs: 699.9298. Time: 330.7647 us. Best GFLOPs: 980.1472
2024-04-29 07:52:29 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #661: GFLOPs: 736.6279. Time: 314.2863 us. Best GFLOPs: 980.1472
2024-04-29 07:52:29 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #662: GFLOPs: 875.1193. Time: 264.5491 us. Best GFLOPs: 980.1472
2024-04-29 07:52:29 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #663: GFLOPs: 833.1770. Time: 277.8666 us. Best GFLOPs: 980.1472
2024-04-29 07:52:29 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #664: GFLOPs: 509.3410. Time: 454.5325 us. Best GFLOPs: 980.1472
2024-04-29 07:52:29 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #665: GFLOPs: 328.6163. Time: 704.5057 us. Best GFLOPs: 980.1472
2024-04-29 07:52:29 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #666: GFLOPs: 445.2128. Time: 520.0031 us. Best GFLOPs: 980.1472
2024-04-29 07:52:29 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #667: GFLOPs: 340.5312. Time: 679.8558 us. Best GFLOPs: 980.1472
2024-04-29 07:52:29 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #668: GFLOPs: 474.2306. Time: 488.1846 us. Best GFLOPs: 980.1472
2024-04-29 07:52:29 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #669: GFLOPs: 533.0196. Time: 434.3406 us. Best GFLOPs: 980.1472
2024-04-29 07:52:29 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #670: GFLOPs: 714.7744. Time: 323.8953 us. Best GFLOPs: 980.1472
2024-04-29 07:52:29 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #671: GFLOPs: 745.3780. Time: 310.5969 us. Best GFLOPs: 980.1472
2024-04-29 07:52:29 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #672: GFLOPs: 851.9301. Time: 271.7501 us. Best GFLOPs: 980.1472
2024-04-29 07:52:29 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #673: GFLOPs: 762.2660. Time: 303.7156 us. Best GFLOPs: 980.1472
2024-04-29 07:52:29 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #674: GFLOPs: 822.5616. Time: 281.4526 us. Best GFLOPs: 980.1472
2024-04-29 07:52:29 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #675: GFLOPs: 761.0280. Time: 304.2097 us. Best GFLOPs: 980.1472
2024-04-29 07:52:29 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #676: GFLOPs: 864.5149. Time: 267.7942 us. Best GFLOPs: 980.1472
2024-04-29 07:52:29 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #677: GFLOPs: 846.0073. Time: 273.6526 us. Best GFLOPs: 980.1472
2024-04-29 07:52:29 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #678: GFLOPs: 702.0445. Time: 329.7684 us. Best GFLOPs: 980.1472
2024-04-29 07:52:29 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #679: GFLOPs: 945.4437. Time: 244.8713 us. Best GFLOPs: 980.1472
2024-04-29 07:52:29 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #680: GFLOPs: 798.1684. Time: 290.0542 us. Best GFLOPs: 980.1472
2024-04-29 07:52:29 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #681: GFLOPs: 735.1311. Time: 314.9262 us. Best GFLOPs: 980.1472
2024-04-29 07:52:29 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #682: GFLOPs: 660.4347. Time: 350.5450 us. Best GFLOPs: 980.1472
2024-04-29 07:52:29 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #683: GFLOPs: 753.2704. Time: 307.3426 us. Best GFLOPs: 980.1472
2024-04-29 07:52:29 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #684: GFLOPs: 655.8090. Time: 353.0175 us. Best GFLOPs: 980.1472
2024-04-29 07:52:29 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #685: GFLOPs: 809.6192. Time: 285.9518 us. Best GFLOPs: 980.1472
2024-04-29 07:52:29 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #686: GFLOPs: 627.0470. Time: 369.2101 us. Best GFLOPs: 980.1472
2024-04-29 07:52:29 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #687: GFLOPs: 718.1565. Time: 322.3699 us. Best GFLOPs: 980.1472
2024-04-29 07:52:29 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #688: GFLOPs: 66.0789. Time: 3503.5703 us. Best GFLOPs: 980.1472
2024-04-29 07:52:29 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #689: GFLOPs: 658.2968. Time: 351.6834 us. Best GFLOPs: 980.1472
2024-04-29 07:52:29 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #690: GFLOPs: 755.9826. Time: 306.2399 us. Best GFLOPs: 980.1472
2024-04-29 07:52:29 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #691: GFLOPs: 686.5776. Time: 337.1972 us. Best GFLOPs: 980.1472
2024-04-29 07:52:29 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #692: GFLOPs: 745.1929. Time: 310.6740 us. Best GFLOPs: 980.1472
2024-04-29 07:52:29 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #693: GFLOPs: 894.8017. Time: 258.7300 us. Best GFLOPs: 980.1472
2024-04-29 07:52:29 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #694: GFLOPs: 326.7811. Time: 708.4623 us. Best GFLOPs: 980.1472
2024-04-29 07:52:29 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #695: GFLOPs: 815.5686. Time: 283.8658 us. Best GFLOPs: 980.1472
2024-04-29 07:52:29 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #696: GFLOPs: 751.5278. Time: 308.0552 us. Best GFLOPs: 980.1472
2024-04-29 07:52:29 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #697: GFLOPs: 406.7817. Time: 569.1310 us. Best GFLOPs: 980.1472
2024-04-29 07:52:29 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #698: GFLOPs: 830.2233. Time: 278.8552 us. Best GFLOPs: 980.1472
2024-04-29 07:52:29 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #699: GFLOPs: 659.4028. Time: 351.0936 us. Best GFLOPs: 980.1472
2024-04-29 07:52:29 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #700: GFLOPs: 691.4559. Time: 334.8183 us. Best GFLOPs: 980.1472
2024-04-29 07:52:29 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #701: GFLOPs: 799.4811. Time: 289.5779 us. Best GFLOPs: 980.1472
2024-04-29 07:52:29 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #702: GFLOPs: 142.3084. Time: 1626.8330 us. Best GFLOPs: 980.1472
2024-04-29 07:52:29 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #703: GFLOPs: 1.6364. Time: 141473.7480 us. Best GFLOPs: 980.1472
2024-04-29 07:52:29 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #704: GFLOPs: 3.4797. Time: 66532.1993 us. Best GFLOPs: 980.1472
2024-04-29 08:04:02 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 08:04:03 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-29 08:04:07 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4391338)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x38dd208)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x4182678)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x6ddeb88)]: 0 failure(s)
2024-04-29 08:04:07 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-29 08:04:20 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4391338)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x38dd208)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x4182678)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x6ddeb88)]: 0 failure(s)
2024-04-29 08:04:33 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4391338)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x38dd208)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x4182678)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x6ddeb88)]: 0 failure(s)
2024-04-29 08:04:47 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4391338)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x38dd208)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x4182678)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x6ddeb88)]: 0 failure(s)
2024-04-29 08:05:01 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4391338)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x38dd208)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x4182678)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x6ddeb88)]: 0 failure(s)
2024-04-29 08:05:09 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9242  0.8953  0.8923  0.8737  0.8721  0.8662  0.8658  0.8636  0.8608  0.8589  0.8573  0.8545  0.8545  0.8522  0.8491  0.8491
[17 : 32]:	0.8475  0.8446  0.8422  0.8421  0.8383  0.8359  0.8333  0.8333  0.8297  0.8260  0.8229  0.8130  0.8118  0.8118  0.8085  0.7969
[33 : 48]:	0.7956  0.7940  0.7940  0.7933  0.7928  0.7928  0.7904  0.7901  0.7875  0.7856  0.7682  0.7655  0.7559  0.7492  0.7414  0.7400
[49 : 64]:	0.7381  0.7345  0.7304  0.7304  0.7204  0.7192  0.7192  0.7168  0.7151  0.7150  0.7112  0.7104  0.7085  0.7059  0.7058  0.7048
2024-04-29 08:05:09 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 08:05:09 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 08:06:37 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #705: GFLOPs: 939.1600. Time: 246.5097 us. Best GFLOPs: 980.1472
2024-04-29 08:06:37 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #706: GFLOPs: 832.5677. Time: 278.0700 us. Best GFLOPs: 980.1472
2024-04-29 08:06:37 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #707: GFLOPs: 962.3364. Time: 240.5729 us. Best GFLOPs: 980.1472
2024-04-29 08:06:37 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #708: GFLOPs: 754.6481. Time: 306.7815 us. Best GFLOPs: 980.1472
2024-04-29 08:06:37 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #709: GFLOPs: 687.7824. Time: 336.6066 us. Best GFLOPs: 980.1472
2024-04-29 08:06:37 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #710: GFLOPs: 896.2831. Time: 258.3024 us. Best GFLOPs: 980.1472
2024-04-29 08:06:37 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #711: GFLOPs: 895.2496. Time: 258.6006 us. Best GFLOPs: 980.1472
2024-04-29 08:06:37 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #712: GFLOPs: 824.0098. Time: 280.9579 us. Best GFLOPs: 980.1472
2024-04-29 08:06:37 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #713: GFLOPs: 951.6271. Time: 243.2802 us. Best GFLOPs: 980.1472
2024-04-29 08:06:37 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #714: GFLOPs: 791.3808. Time: 292.5419 us. Best GFLOPs: 980.1472
2024-04-29 08:06:37 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #715: GFLOPs: 833.1729. Time: 277.8680 us. Best GFLOPs: 980.1472
2024-04-29 08:06:37 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #716: GFLOPs: 589.5948. Time: 392.6630 us. Best GFLOPs: 980.1472
2024-04-29 08:06:37 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #717: GFLOPs: 630.4618. Time: 367.2103 us. Best GFLOPs: 980.1472
2024-04-29 08:06:37 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #718: GFLOPs: 792.8060. Time: 292.0160 us. Best GFLOPs: 980.1472
2024-04-29 08:06:37 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #719: GFLOPs: 814.2340. Time: 284.3311 us. Best GFLOPs: 980.1472
2024-04-29 08:06:37 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #720: GFLOPs: 826.9700. Time: 279.9522 us. Best GFLOPs: 980.1472
2024-04-29 08:06:37 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #721: GFLOPs: 790.5855. Time: 292.8362 us. Best GFLOPs: 980.1472
2024-04-29 08:06:37 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #722: GFLOPs: 853.1813. Time: 271.3515 us. Best GFLOPs: 980.1472
2024-04-29 08:06:37 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #723: GFLOPs: 743.8435. Time: 311.2376 us. Best GFLOPs: 980.1472
2024-04-29 08:06:37 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #724: GFLOPs: 836.4505. Time: 276.7792 us. Best GFLOPs: 980.1472
2024-04-29 08:06:37 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #725: GFLOPs: 872.0579. Time: 265.4779 us. Best GFLOPs: 980.1472
2024-04-29 08:06:37 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #726: GFLOPs: 885.3850. Time: 261.4818 us. Best GFLOPs: 980.1472
2024-04-29 08:06:37 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #727: GFLOPs: 854.5731. Time: 270.9096 us. Best GFLOPs: 980.1472
2024-04-29 08:06:37 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #728: GFLOPs: 889.0864. Time: 260.3932 us. Best GFLOPs: 980.1472
2024-04-29 08:06:37 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #729: GFLOPs: 856.1673. Time: 270.4052 us. Best GFLOPs: 980.1472
2024-04-29 08:06:37 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #730: GFLOPs: 790.8424. Time: 292.7411 us. Best GFLOPs: 980.1472
2024-04-29 08:06:37 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #731: GFLOPs: 933.1218. Time: 248.1049 us. Best GFLOPs: 980.1472
2024-04-29 08:06:37 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #732: GFLOPs: 809.9507. Time: 285.8348 us. Best GFLOPs: 980.1472
2024-04-29 08:06:37 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #733: GFLOPs: 813.9956. Time: 284.4144 us. Best GFLOPs: 980.1472
2024-04-29 08:06:37 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #734: GFLOPs: 818.1690. Time: 282.9636 us. Best GFLOPs: 980.1472
2024-04-29 08:06:37 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #735: GFLOPs: 839.5182. Time: 275.7678 us. Best GFLOPs: 980.1472
2024-04-29 08:06:37 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #736: GFLOPs: 802.1393. Time: 288.6183 us. Best GFLOPs: 980.1472
2024-04-29 08:06:37 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #737: GFLOPs: 641.1843. Time: 361.0695 us. Best GFLOPs: 980.1472
2024-04-29 08:06:37 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #738: GFLOPs: 722.1992. Time: 320.5654 us. Best GFLOPs: 980.1472
2024-04-29 08:06:37 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #739: GFLOPs: 804.8714. Time: 287.6386 us. Best GFLOPs: 980.1472
2024-04-29 08:06:37 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #740: GFLOPs: 742.9669. Time: 311.6048 us. Best GFLOPs: 980.1472
2024-04-29 08:06:37 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #741: GFLOPs: 895.2130. Time: 258.6111 us. Best GFLOPs: 980.1472
2024-04-29 08:06:37 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #742: GFLOPs: 741.6919. Time: 312.1405 us. Best GFLOPs: 980.1472
2024-04-29 08:06:37 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #743: GFLOPs: 807.7180. Time: 286.6249 us. Best GFLOPs: 980.1472
2024-04-29 08:06:37 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #744: GFLOPs: 896.0850. Time: 258.3595 us. Best GFLOPs: 980.1472
2024-04-29 08:06:37 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #745: GFLOPs: 775.3899. Time: 298.5750 us. Best GFLOPs: 980.1472
2024-04-29 08:06:37 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #746: GFLOPs: 484.8869. Time: 477.4558 us. Best GFLOPs: 980.1472
2024-04-29 08:06:37 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #747: GFLOPs: 509.9180. Time: 454.0182 us. Best GFLOPs: 980.1472
2024-04-29 08:06:37 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #748: GFLOPs: 770.0269. Time: 300.6545 us. Best GFLOPs: 980.1472
2024-04-29 08:06:37 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #749: GFLOPs: 633.6262. Time: 365.3764 us. Best GFLOPs: 980.1472
2024-04-29 08:06:37 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #750: GFLOPs: 466.3822. Time: 496.3998 us. Best GFLOPs: 980.1472
2024-04-29 08:06:37 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #751: GFLOPs: 643.5418. Time: 359.7467 us. Best GFLOPs: 980.1472
2024-04-29 08:06:37 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #752: GFLOPs: 753.1643. Time: 307.3859 us. Best GFLOPs: 980.1472
2024-04-29 08:06:37 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #753: GFLOPs: 606.9395. Time: 381.4418 us. Best GFLOPs: 980.1472
2024-04-29 08:06:37 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #754: GFLOPs: 814.8801. Time: 284.1057 us. Best GFLOPs: 980.1472
2024-04-29 08:06:37 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #755: GFLOPs: 822.3647. Time: 281.5200 us. Best GFLOPs: 980.1472
2024-04-29 08:06:37 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #756: GFLOPs: 464.6169. Time: 498.2859 us. Best GFLOPs: 980.1472
2024-04-29 08:06:37 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #757: GFLOPs: 810.3614. Time: 285.6899 us. Best GFLOPs: 980.1472
2024-04-29 08:06:37 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #758: GFLOPs: 775.3887. Time: 298.5755 us. Best GFLOPs: 980.1472
2024-04-29 08:06:37 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #759: GFLOPs: 481.9584. Time: 480.3569 us. Best GFLOPs: 980.1472
2024-04-29 08:06:37 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #760: GFLOPs: 489.2062. Time: 473.2402 us. Best GFLOPs: 980.1472
2024-04-29 08:06:37 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #761: GFLOPs: 753.1758. Time: 307.3812 us. Best GFLOPs: 980.1472
2024-04-29 08:06:37 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #762: GFLOPs: 660.2704. Time: 350.6322 us. Best GFLOPs: 980.1472
2024-04-29 08:06:37 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #763: GFLOPs: 806.8568. Time: 286.9308 us. Best GFLOPs: 980.1472
2024-04-29 08:06:37 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #764: GFLOPs: 795.7426. Time: 290.9384 us. Best GFLOPs: 980.1472
2024-04-29 08:06:37 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #765: GFLOPs: 744.0780. Time: 311.1395 us. Best GFLOPs: 980.1472
2024-04-29 08:06:37 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #766: GFLOPs: 56.2298. Time: 4117.2511 us. Best GFLOPs: 980.1472
2024-04-29 08:06:37 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #767: GFLOPs: 34.1958. Time: 6770.1855 us. Best GFLOPs: 980.1472
2024-04-29 08:06:37 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #768: GFLOPs: 33.7261. Time: 6864.4685 us. Best GFLOPs: 980.1472
2024-04-29 08:25:35 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 08:25:36 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-29 08:25:41 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4391338)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x38dd208)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x4182678)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x6ddeb88)]: 0 failure(s)
2024-04-29 08:25:41 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-29 08:25:54 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4391338)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x38dd208)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x4182678)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x6ddeb88)]: 0 failure(s)
2024-04-29 08:26:07 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4391338)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x38dd208)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x4182678)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x6ddeb88)]: 0 failure(s)
2024-04-29 08:26:21 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4391338)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x38dd208)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x4182678)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x6ddeb88)]: 0 failure(s)
2024-04-29 08:26:34 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4391338)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x38dd208)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x4182678)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x6ddeb88)]: 0 failure(s)
2024-04-29 08:26:42 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9293  0.9281  0.9096  0.9055  0.8852  0.8841  0.8740  0.8571  0.8421  0.8401  0.8380  0.8379  0.8314  0.8298  0.8294  0.8263
[17 : 32]:	0.8263  0.8263  0.8263  0.8260  0.8234  0.8202  0.8196  0.8188  0.8166  0.8160  0.8157  0.8149  0.8141  0.8103  0.8103  0.8020
[33 : 48]:	0.8015  0.7946  0.7910  0.7876  0.7854  0.7831  0.7801  0.7762  0.7711  0.7683  0.7679  0.7627  0.7590  0.7492  0.7442  0.7440
[49 : 64]:	0.7391  0.7389  0.7374  0.7362  0.7354  0.7341  0.7320  0.7276  0.7253  0.7208  0.7198  0.7170  0.7166  0.7166  0.7159  0.7156
2024-04-29 08:26:43 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 08:26:43 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 08:28:19 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #769: GFLOPs: 920.4242. Time: 251.5276 us. Best GFLOPs: 980.1472
2024-04-29 08:28:19 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #770: GFLOPs: 742.7522. Time: 311.6949 us. Best GFLOPs: 980.1472
2024-04-29 08:28:19 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #771: GFLOPs: 937.0126. Time: 247.0746 us. Best GFLOPs: 980.1472
2024-04-29 08:28:19 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #772: GFLOPs: 741.6643. Time: 312.1521 us. Best GFLOPs: 980.1472
2024-04-29 08:28:19 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #773: GFLOPs: 851.0944. Time: 272.0169 us. Best GFLOPs: 980.1472
2024-04-29 08:28:19 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #774: GFLOPs: 840.2786. Time: 275.5182 us. Best GFLOPs: 980.1472
2024-04-29 08:28:19 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #775: GFLOPs: 862.0635. Time: 268.5557 us. Best GFLOPs: 980.1472
2024-04-29 08:28:19 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #776: GFLOPs: 845.8277. Time: 273.7107 us. Best GFLOPs: 980.1472
2024-04-29 08:28:19 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #777: GFLOPs: 871.7981. Time: 265.5570 us. Best GFLOPs: 980.1472
2024-04-29 08:28:19 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #778: GFLOPs: 899.2331. Time: 257.4550 us. Best GFLOPs: 980.1472
2024-04-29 08:28:19 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #779: GFLOPs: 961.8605. Time: 240.6919 us. Best GFLOPs: 980.1472
2024-04-29 08:28:19 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #780: GFLOPs: 749.0229. Time: 309.0854 us. Best GFLOPs: 980.1472
2024-04-29 08:28:19 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #781: GFLOPs: 687.7658. Time: 336.6147 us. Best GFLOPs: 980.1472
2024-04-29 08:28:19 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #782: GFLOPs: 804.7347. Time: 287.6874 us. Best GFLOPs: 980.1472
2024-04-29 08:28:19 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #783: GFLOPs: 822.8710. Time: 281.3467 us. Best GFLOPs: 980.1472
2024-04-29 08:28:19 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #784: GFLOPs: 572.4929. Time: 404.3929 us. Best GFLOPs: 980.1472
2024-04-29 08:28:19 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #785: GFLOPs: 746.0867. Time: 310.3018 us. Best GFLOPs: 980.1472
2024-04-29 08:28:19 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #786: GFLOPs: 834.8829. Time: 277.2988 us. Best GFLOPs: 980.1472
2024-04-29 08:28:19 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #787: GFLOPs: 583.9746. Time: 396.4420 us. Best GFLOPs: 980.1472
2024-04-29 08:28:19 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #788: GFLOPs: 758.3270. Time: 305.2932 us. Best GFLOPs: 980.1472
2024-04-29 08:28:19 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #789: GFLOPs: 536.0577. Time: 431.8790 us. Best GFLOPs: 980.1472
2024-04-29 08:28:19 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #790: GFLOPs: 693.5263. Time: 333.8187 us. Best GFLOPs: 980.1472
2024-04-29 08:28:19 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #791: GFLOPs: 714.7192. Time: 323.9203 us. Best GFLOPs: 980.1472
2024-04-29 08:28:19 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #792: GFLOPs: 815.4065. Time: 283.9223 us. Best GFLOPs: 980.1472
2024-04-29 08:28:19 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #793: GFLOPs: 855.1834. Time: 270.7163 us. Best GFLOPs: 980.1472
2024-04-29 08:28:19 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #794: GFLOPs: 680.1742. Time: 340.3717 us. Best GFLOPs: 980.1472
2024-04-29 08:28:19 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #795: GFLOPs: 844.2042. Time: 274.2370 us. Best GFLOPs: 980.1472
2024-04-29 08:28:19 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #796: GFLOPs: 655.6378. Time: 353.1097 us. Best GFLOPs: 980.1472
2024-04-29 08:28:19 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #797: GFLOPs: 704.6309. Time: 328.5579 us. Best GFLOPs: 980.1472
2024-04-29 08:28:19 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #798: GFLOPs: 855.4801. Time: 270.6224 us. Best GFLOPs: 980.1472
2024-04-29 08:28:19 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #799: GFLOPs: 821.8862. Time: 281.6838 us. Best GFLOPs: 980.1472
2024-04-29 08:28:19 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #800: GFLOPs: 785.0785. Time: 294.8903 us. Best GFLOPs: 980.1472
2024-04-29 08:28:19 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #801: GFLOPs: 841.4745. Time: 275.1266 us. Best GFLOPs: 980.1472
2024-04-29 08:28:19 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #802: GFLOPs: 667.0518. Time: 347.0676 us. Best GFLOPs: 980.1472
2024-04-29 08:28:19 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #803: GFLOPs: 833.3482. Time: 277.8095 us. Best GFLOPs: 980.1472
2024-04-29 08:28:19 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #804: GFLOPs: 642.6617. Time: 360.2394 us. Best GFLOPs: 980.1472
2024-04-29 08:28:19 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #805: GFLOPs: 833.9450. Time: 277.6107 us. Best GFLOPs: 980.1472
2024-04-29 08:28:19 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #806: GFLOPs: 630.5000. Time: 367.1881 us. Best GFLOPs: 980.1472
2024-04-29 08:28:19 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #807: GFLOPs: 842.9608. Time: 274.6416 us. Best GFLOPs: 980.1472
2024-04-29 08:28:19 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #808: GFLOPs: 831.8691. Time: 278.3035 us. Best GFLOPs: 980.1472
2024-04-29 08:28:19 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #809: GFLOPs: 728.8399. Time: 317.6446 us. Best GFLOPs: 980.1472
2024-04-29 08:28:19 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #810: GFLOPs: 613.1381. Time: 377.5855 us. Best GFLOPs: 980.1472
2024-04-29 08:28:19 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #811: GFLOPs: 816.6209. Time: 283.5001 us. Best GFLOPs: 980.1472
2024-04-29 08:28:19 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #812: GFLOPs: 672.4585. Time: 344.2771 us. Best GFLOPs: 980.1472
2024-04-29 08:28:19 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #813: GFLOPs: 770.4529. Time: 300.4883 us. Best GFLOPs: 980.1472
2024-04-29 08:28:19 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #814: GFLOPs: 759.2971. Time: 304.9031 us. Best GFLOPs: 980.1472
2024-04-29 08:28:19 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #815: GFLOPs: 726.1950. Time: 318.8015 us. Best GFLOPs: 980.1472
2024-04-29 08:28:19 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #816: GFLOPs: 620.2388. Time: 373.2628 us. Best GFLOPs: 980.1472
2024-04-29 08:28:19 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #817: GFLOPs: 500.5384. Time: 462.5261 us. Best GFLOPs: 980.1472
2024-04-29 08:28:19 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #818: GFLOPs: 767.6983. Time: 301.5665 us. Best GFLOPs: 980.1472
2024-04-29 08:28:19 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #819: GFLOPs: 679.7395. Time: 340.5894 us. Best GFLOPs: 980.1472
2024-04-29 08:28:19 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #820: GFLOPs: 744.1426. Time: 311.1125 us. Best GFLOPs: 980.1472
2024-04-29 08:28:19 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #821: GFLOPs: 801.2208. Time: 288.9492 us. Best GFLOPs: 980.1472
2024-04-29 08:28:19 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #822: GFLOPs: 701.5581. Time: 329.9970 us. Best GFLOPs: 980.1472
2024-04-29 08:28:19 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #823: GFLOPs: 630.3327. Time: 367.2855 us. Best GFLOPs: 980.1472
2024-04-29 08:28:19 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #824: GFLOPs: 486.3465. Time: 476.0229 us. Best GFLOPs: 980.1472
2024-04-29 08:28:19 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #825: GFLOPs: 712.1097. Time: 325.1073 us. Best GFLOPs: 980.1472
2024-04-29 08:28:19 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #826: GFLOPs: 819.0870. Time: 282.6465 us. Best GFLOPs: 980.1472
2024-04-29 08:28:19 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #827: GFLOPs: 746.7772. Time: 310.0149 us. Best GFLOPs: 980.1472
2024-04-29 08:28:19 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #828: GFLOPs: 684.9196. Time: 338.0135 us. Best GFLOPs: 980.1472
2024-04-29 08:28:19 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #829: GFLOPs: 340.3006. Time: 680.3164 us. Best GFLOPs: 980.1472
2024-04-29 08:28:19 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #830: GFLOPs: 7.0412. Time: 32879.4170 us. Best GFLOPs: 980.1472
2024-04-29 08:28:19 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #831: GFLOPs: 6.3989. Time: 36180.0767 us. Best GFLOPs: 980.1472
2024-04-29 08:28:19 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #832: GFLOPs: 7.2221. Time: 32056.1080 us. Best GFLOPs: 980.1472
2024-04-29 08:44:09 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 08:44:10 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-29 08:44:15 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4391338)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x38dd208)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x4182678)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x6ddeb88)]: 0 failure(s)
2024-04-29 08:44:15 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-29 08:44:28 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4391338)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x38dd208)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x4182678)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x6ddeb88)]: 0 failure(s)
2024-04-29 08:44:41 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4391338)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x38dd208)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x4182678)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x6ddeb88)]: 0 failure(s)
2024-04-29 08:44:55 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4391338)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x38dd208)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x4182678)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x6ddeb88)]: 0 failure(s)
2024-04-29 08:45:08 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4391338)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x38dd208)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x4182678)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x6ddeb88)]: 0 failure(s)
2024-04-29 08:45:17 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.8915  0.8915  0.8915  0.8915  0.8908  0.8769  0.8769  0.8745  0.8645  0.8617  0.8575  0.8559  0.8483  0.8457  0.8417  0.8372
[17 : 32]:	0.8365  0.8359  0.8349  0.8349  0.8318  0.8303  0.8293  0.8282  0.8275  0.8253  0.8240  0.8240  0.8228  0.8189  0.8143  0.8140
[33 : 48]:	0.8098  0.8085  0.8085  0.8003  0.7951  0.7951  0.7895  0.7862  0.7810  0.7781  0.7781  0.7781  0.7719  0.7688  0.7642  0.7642
[49 : 64]:	0.7627  0.7606  0.7560  0.7547  0.7547  0.7507  0.7498  0.7490  0.7447  0.7395  0.7394  0.7374  0.7374  0.7374  0.7360  0.7360
2024-04-29 08:45:17 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 08:45:17 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 08:46:47 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #833: GFLOPs: 852.7417. Time: 271.4914 us. Best GFLOPs: 980.1472
2024-04-29 08:46:47 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #834: GFLOPs: 875.2835. Time: 264.4995 us. Best GFLOPs: 980.1472
2024-04-29 08:46:47 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #835: GFLOPs: 900.2472. Time: 257.1650 us. Best GFLOPs: 980.1472
2024-04-29 08:46:47 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #836: GFLOPs: 896.2956. Time: 258.2988 us. Best GFLOPs: 980.1472
2024-04-29 08:46:48 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #837: GFLOPs: 779.6841. Time: 296.9306 us. Best GFLOPs: 980.1472
2024-04-29 08:46:48 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #838: GFLOPs: 837.4612. Time: 276.4451 us. Best GFLOPs: 980.1472
2024-04-29 08:46:48 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #839: GFLOPs: 881.0886. Time: 262.7569 us. Best GFLOPs: 980.1472
2024-04-29 08:46:48 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #840: GFLOPs: 924.2384. Time: 250.4896 us. Best GFLOPs: 980.1472
2024-04-29 08:46:48 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #841: GFLOPs: 873.1094. Time: 265.1581 us. Best GFLOPs: 980.1472
2024-04-29 08:46:48 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #842: GFLOPs: 824.6685. Time: 280.7335 us. Best GFLOPs: 980.1472
2024-04-29 08:46:48 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #843: GFLOPs: 840.4956. Time: 275.4471 us. Best GFLOPs: 980.1472
2024-04-29 08:46:48 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #844: GFLOPs: 799.1235. Time: 289.7075 us. Best GFLOPs: 980.1472
2024-04-29 08:46:48 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #845: GFLOPs: 817.9250. Time: 283.0480 us. Best GFLOPs: 980.1472
2024-04-29 08:46:48 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #846: GFLOPs: 867.3450. Time: 266.9204 us. Best GFLOPs: 980.1472
2024-04-29 08:46:48 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #847: GFLOPs: 846.7114. Time: 273.4250 us. Best GFLOPs: 980.1472
2024-04-29 08:46:48 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #848: GFLOPs: 696.4283. Time: 332.4277 us. Best GFLOPs: 980.1472
2024-04-29 08:46:48 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #849: GFLOPs: 532.9080. Time: 434.4316 us. Best GFLOPs: 980.1472
2024-04-29 08:46:48 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #850: GFLOPs: 790.0147. Time: 293.0478 us. Best GFLOPs: 980.1472
2024-04-29 08:46:48 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #851: GFLOPs: 883.1314. Time: 262.1490 us. Best GFLOPs: 980.1472
2024-04-29 08:46:48 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #852: GFLOPs: 920.6109. Time: 251.4766 us. Best GFLOPs: 980.1472
2024-04-29 08:46:48 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #853: GFLOPs: 814.1369. Time: 284.3650 us. Best GFLOPs: 980.1472
2024-04-29 08:46:48 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #854: GFLOPs: 739.5357. Time: 313.0505 us. Best GFLOPs: 980.1472
2024-04-29 08:46:48 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #855: GFLOPs: 893.3026. Time: 259.1642 us. Best GFLOPs: 980.1472
2024-04-29 08:46:48 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #856: GFLOPs: 784.1208. Time: 295.2505 us. Best GFLOPs: 980.1472
2024-04-29 08:46:48 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #857: GFLOPs: 835.3475. Time: 277.1446 us. Best GFLOPs: 980.1472
2024-04-29 08:46:48 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #858: GFLOPs: 424.6390. Time: 545.1974 us. Best GFLOPs: 980.1472
2024-04-29 08:46:48 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #859: GFLOPs: 679.3427. Time: 340.7883 us. Best GFLOPs: 980.1472
2024-04-29 08:46:48 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #860: GFLOPs: 665.6581. Time: 347.7943 us. Best GFLOPs: 980.1472
2024-04-29 08:46:48 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #861: GFLOPs: 666.9084. Time: 347.1422 us. Best GFLOPs: 980.1472
2024-04-29 08:46:48 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #862: GFLOPs: 330.2703. Time: 700.9775 us. Best GFLOPs: 980.1472
2024-04-29 08:46:48 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #863: GFLOPs: 782.5434. Time: 295.8457 us. Best GFLOPs: 980.1472
2024-04-29 08:46:48 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #864: GFLOPs: 798.6058. Time: 289.8953 us. Best GFLOPs: 980.1472
2024-04-29 08:46:48 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #865: GFLOPs: 835.9509. Time: 276.9446 us. Best GFLOPs: 980.1472
2024-04-29 08:46:48 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #866: GFLOPs: 792.9888. Time: 291.9487 us. Best GFLOPs: 980.1472
2024-04-29 08:46:48 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #867: GFLOPs: 843.6169. Time: 274.4280 us. Best GFLOPs: 980.1472
2024-04-29 08:46:48 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #868: GFLOPs: 806.2828. Time: 287.1351 us. Best GFLOPs: 980.1472
2024-04-29 08:46:48 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #869: GFLOPs: 909.5873. Time: 254.5243 us. Best GFLOPs: 980.1472
2024-04-29 08:46:48 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #870: GFLOPs: 807.8563. Time: 286.5758 us. Best GFLOPs: 980.1472
2024-04-29 08:46:48 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #871: GFLOPs: 714.9212. Time: 323.8288 us. Best GFLOPs: 980.1472
2024-04-29 08:46:48 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #872: GFLOPs: 777.2405. Time: 297.8641 us. Best GFLOPs: 980.1472
2024-04-29 08:46:48 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #873: GFLOPs: 624.9769. Time: 370.4330 us. Best GFLOPs: 980.1472
2024-04-29 08:46:48 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #874: GFLOPs: 711.5775. Time: 325.3505 us. Best GFLOPs: 980.1472
2024-04-29 08:46:48 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #875: GFLOPs: 742.3809. Time: 311.8508 us. Best GFLOPs: 980.1472
2024-04-29 08:46:48 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #876: GFLOPs: 457.9472. Time: 505.5432 us. Best GFLOPs: 980.1472
2024-04-29 08:46:48 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #877: GFLOPs: 801.6270. Time: 288.8027 us. Best GFLOPs: 980.1472
2024-04-29 08:46:48 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #878: GFLOPs: 674.5926. Time: 343.1880 us. Best GFLOPs: 980.1472
2024-04-29 08:46:48 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #879: GFLOPs: 839.1074. Time: 275.9028 us. Best GFLOPs: 980.1472
2024-04-29 08:46:48 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #880: GFLOPs: 135.6895. Time: 1706.1902 us. Best GFLOPs: 980.1472
2024-04-29 08:46:48 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #881: GFLOPs: 868.3949. Time: 266.5977 us. Best GFLOPs: 980.1472
2024-04-29 08:46:48 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #882: GFLOPs: 478.3803. Time: 483.9498 us. Best GFLOPs: 980.1472
2024-04-29 08:46:48 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #883: GFLOPs: 711.8074. Time: 325.2454 us. Best GFLOPs: 980.1472
2024-04-29 08:46:48 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #884: GFLOPs: 689.9431. Time: 335.5524 us. Best GFLOPs: 980.1472
2024-04-29 08:46:48 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #885: GFLOPs: 624.8012. Time: 370.5372 us. Best GFLOPs: 980.1472
2024-04-29 08:46:48 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #886: GFLOPs: 713.8442. Time: 324.3174 us. Best GFLOPs: 980.1472
2024-04-29 08:46:48 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #887: GFLOPs: 734.8704. Time: 315.0380 us. Best GFLOPs: 980.1472
2024-04-29 08:46:48 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #888: GFLOPs: 814.6225. Time: 284.1955 us. Best GFLOPs: 980.1472
2024-04-29 08:46:48 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #889: GFLOPs: 692.5775. Time: 334.2760 us. Best GFLOPs: 980.1472
2024-04-29 08:46:48 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #890: GFLOPs: 541.7594. Time: 427.3337 us. Best GFLOPs: 980.1472
2024-04-29 08:46:48 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #891: GFLOPs: 806.3763. Time: 287.1018 us. Best GFLOPs: 980.1472
2024-04-29 08:46:48 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #892: GFLOPs: 634.7318. Time: 364.7400 us. Best GFLOPs: 980.1472
2024-04-29 08:46:48 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #893: GFLOPs: 684.9179. Time: 338.0143 us. Best GFLOPs: 980.1472
2024-04-29 08:46:48 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #894: GFLOPs: 55.6207. Time: 4162.3341 us. Best GFLOPs: 980.1472
2024-04-29 08:46:48 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #895: GFLOPs: 28.1981. Time: 8210.1985 us. Best GFLOPs: 980.1472
2024-04-29 08:46:48 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #896: GFLOPs: 20.9695. Time: 11040.4383 us. Best GFLOPs: 980.1472
2024-04-29 08:55:57 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 08:55:58 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-29 08:56:03 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4391338)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x38dd208)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x4182678)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x6ddeb88)]: 0 failure(s)
2024-04-29 08:56:03 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-29 08:56:16 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4391338)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x38dd208)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x4182678)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x6ddeb88)]: 0 failure(s)
2024-04-29 08:56:29 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4391338)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x38dd208)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x4182678)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x6ddeb88)]: 0 failure(s)
2024-04-29 08:56:43 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4391338)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x38dd208)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x4182678)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x6ddeb88)]: 0 failure(s)
2024-04-29 08:56:56 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4391338)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x38dd208)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x4182678)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x6ddeb88)]: 0 failure(s)
2024-04-29 08:57:05 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.8928  0.8928  0.8928  0.8826  0.8826  0.8797  0.8626  0.8626  0.8596  0.8596  0.8596  0.8446  0.8446  0.8446  0.8410  0.8390
[17 : 32]:	0.8304  0.8304  0.8299  0.8282  0.8282  0.8275  0.8275  0.8263  0.8261  0.8209  0.8139  0.8030  0.7902  0.7902  0.7867  0.7790
[33 : 48]:	0.7755  0.7709  0.7708  0.7707  0.7696  0.7580  0.7569  0.7523  0.7523  0.7453  0.7440  0.7361  0.7337  0.7299  0.7284  0.7272
[49 : 64]:	0.7264  0.7244  0.7208  0.7181  0.7127  0.7113  0.7081  0.7060  0.7036  0.7035  0.7021  0.7002  0.6919  0.6908  0.6905  0.6900
2024-04-29 08:57:05 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 08:57:06 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 08:58:40 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #897: GFLOPs: 481.3936. Time: 480.9205 us. Best GFLOPs: 980.1472
2024-04-29 08:58:40 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #898: GFLOPs: 910.9791. Time: 254.1354 us. Best GFLOPs: 980.1472
2024-04-29 08:58:40 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #899: GFLOPs: 876.2987. Time: 264.1931 us. Best GFLOPs: 980.1472
2024-04-29 08:58:40 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #900: GFLOPs: 792.6007. Time: 292.0917 us. Best GFLOPs: 980.1472
2024-04-29 08:58:40 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #901: GFLOPs: 918.8835. Time: 251.9493 us. Best GFLOPs: 980.1472
2024-04-29 08:58:40 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #902: GFLOPs: 868.6937. Time: 266.5060 us. Best GFLOPs: 980.1472
2024-04-29 08:58:40 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #903: GFLOPs: 883.5507. Time: 262.0246 us. Best GFLOPs: 980.1472
2024-04-29 08:58:40 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #904: GFLOPs: 777.2619. Time: 297.8559 us. Best GFLOPs: 980.1472
2024-04-29 08:58:40 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #905: GFLOPs: 920.1840. Time: 251.5932 us. Best GFLOPs: 980.1472
2024-04-29 08:58:40 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #906: GFLOPs: 809.1446. Time: 286.1195 us. Best GFLOPs: 980.1472
2024-04-29 08:58:40 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #907: GFLOPs: 844.4305. Time: 274.1635 us. Best GFLOPs: 980.1472
2024-04-29 08:58:40 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #908: GFLOPs: 705.1494. Time: 328.3163 us. Best GFLOPs: 980.1472
2024-04-29 08:58:40 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #909: GFLOPs: 731.9832. Time: 316.2806 us. Best GFLOPs: 980.1472
2024-04-29 08:58:40 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #910: GFLOPs: 531.2804. Time: 435.7625 us. Best GFLOPs: 980.1472
2024-04-29 08:58:40 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #911: GFLOPs: 803.9573. Time: 287.9656 us. Best GFLOPs: 980.1472
2024-04-29 08:58:40 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #912: GFLOPs: 523.1487. Time: 442.5359 us. Best GFLOPs: 980.1472
2024-04-29 08:58:40 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #913: GFLOPs: 545.4922. Time: 424.4095 us. Best GFLOPs: 980.1472
2024-04-29 08:58:40 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #914: GFLOPs: 772.8947. Time: 299.5390 us. Best GFLOPs: 980.1472
2024-04-29 08:58:40 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #915: GFLOPs: 808.3174. Time: 286.4123 us. Best GFLOPs: 980.1472
2024-04-29 08:58:40 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #916: GFLOPs: 780.5543. Time: 296.5996 us. Best GFLOPs: 980.1472
2024-04-29 08:58:40 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #917: GFLOPs: 807.2394. Time: 286.7948 us. Best GFLOPs: 980.1472
2024-04-29 08:58:40 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #918: GFLOPs: 782.4705. Time: 295.8732 us. Best GFLOPs: 980.1472
2024-04-29 08:58:40 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #919: GFLOPs: 801.2263. Time: 288.9472 us. Best GFLOPs: 980.1472
2024-04-29 08:58:40 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #920: GFLOPs: 732.7670. Time: 315.9423 us. Best GFLOPs: 980.1472
2024-04-29 08:58:40 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #921: GFLOPs: 799.6812. Time: 289.5054 us. Best GFLOPs: 980.1472
2024-04-29 08:58:40 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #922: GFLOPs: 771.5357. Time: 300.0666 us. Best GFLOPs: 980.1472
2024-04-29 08:58:40 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #923: GFLOPs: 647.3974. Time: 357.6043 us. Best GFLOPs: 980.1472
2024-04-29 08:58:40 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #924: GFLOPs: 677.5757. Time: 341.6770 us. Best GFLOPs: 980.1472
2024-04-29 08:58:40 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #925: GFLOPs: 746.7594. Time: 310.0223 us. Best GFLOPs: 980.1472
2024-04-29 08:58:40 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #926: GFLOPs: 712.6621. Time: 324.8553 us. Best GFLOPs: 980.1472
2024-04-29 08:58:40 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #927: GFLOPs: 802.4553. Time: 288.5046 us. Best GFLOPs: 980.1472
2024-04-29 08:58:40 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #928: GFLOPs: 711.7990. Time: 325.2492 us. Best GFLOPs: 980.1472
2024-04-29 08:58:40 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #929: GFLOPs: 198.4943. Time: 1166.3412 us. Best GFLOPs: 980.1472
2024-04-29 08:58:40 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #930: GFLOPs: 786.7801. Time: 294.2526 us. Best GFLOPs: 980.1472
2024-04-29 08:58:40 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #931: GFLOPs: 524.4397. Time: 441.4465 us. Best GFLOPs: 980.1472
2024-04-29 08:58:40 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #932: GFLOPs: 730.0017. Time: 317.1391 us. Best GFLOPs: 980.1472
2024-04-29 08:58:40 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #933: GFLOPs: 734.4329. Time: 315.2256 us. Best GFLOPs: 980.1472
2024-04-29 08:58:40 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #934: GFLOPs: 664.3951. Time: 348.4554 us. Best GFLOPs: 980.1472
2024-04-29 08:58:40 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #935: GFLOPs: 623.4089. Time: 371.3647 us. Best GFLOPs: 980.1472
2024-04-29 08:58:40 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #936: GFLOPs: 629.8092. Time: 367.5908 us. Best GFLOPs: 980.1472
2024-04-29 08:58:40 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #937: GFLOPs: 768.8253. Time: 301.1244 us. Best GFLOPs: 980.1472
2024-04-29 08:58:40 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #938: GFLOPs: 237.7986. Time: 973.5637 us. Best GFLOPs: 980.1472
2024-04-29 08:58:40 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #939: GFLOPs: 651.1804. Time: 355.5268 us. Best GFLOPs: 980.1472
2024-04-29 08:58:40 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #940: GFLOPs: 122.8364. Time: 1884.7194 us. Best GFLOPs: 980.1472
2024-04-29 08:58:40 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #941: GFLOPs: 875.9436. Time: 264.3002 us. Best GFLOPs: 980.1472
2024-04-29 08:58:40 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #942: GFLOPs: 552.2515. Time: 419.2149 us. Best GFLOPs: 980.1472
2024-04-29 08:58:40 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #943: GFLOPs: 745.8023. Time: 310.4202 us. Best GFLOPs: 980.1472
2024-04-29 08:58:40 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #944: GFLOPs: 746.4558. Time: 310.1484 us. Best GFLOPs: 980.1472
2024-04-29 08:58:40 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #945: GFLOPs: 171.1190. Time: 1352.9306 us. Best GFLOPs: 980.1472
2024-04-29 08:58:40 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #946: GFLOPs: 820.7811. Time: 282.0631 us. Best GFLOPs: 980.1472
2024-04-29 08:58:40 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #947: GFLOPs: 652.0367. Time: 355.0599 us. Best GFLOPs: 980.1472
2024-04-29 08:58:40 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #948: GFLOPs: 715.6278. Time: 323.5090 us. Best GFLOPs: 980.1472
2024-04-29 08:58:40 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #949: GFLOPs: 863.4216. Time: 268.1333 us. Best GFLOPs: 980.1472
2024-04-29 08:58:40 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #950: GFLOPs: 819.9163. Time: 282.3606 us. Best GFLOPs: 980.1472
2024-04-29 08:58:40 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #951: GFLOPs: 665.1777. Time: 348.0454 us. Best GFLOPs: 980.1472
2024-04-29 08:58:40 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #952: GFLOPs: 715.5976. Time: 323.5227 us. Best GFLOPs: 980.1472
2024-04-29 08:58:40 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #953: GFLOPs: 543.9109. Time: 425.6434 us. Best GFLOPs: 980.1472
2024-04-29 08:58:40 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #954: GFLOPs: 631.2876. Time: 366.7300 us. Best GFLOPs: 980.1472
2024-04-29 08:58:40 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #955: GFLOPs: 840.8234. Time: 275.3397 us. Best GFLOPs: 980.1472
2024-04-29 08:58:40 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #956: GFLOPs: 694.2520. Time: 333.4698 us. Best GFLOPs: 980.1472
2024-04-29 08:58:40 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #957: GFLOPs: 768.6654. Time: 301.1871 us. Best GFLOPs: 980.1472
2024-04-29 08:58:40 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #958: GFLOPs: 30.4231. Time: 7609.7552 us. Best GFLOPs: 980.1472
2024-04-29 08:58:40 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #959: GFLOPs: 7.0611. Time: 32787.1753 us. Best GFLOPs: 980.1472
2024-04-29 08:58:40 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #960: GFLOPs: 4.5360. Time: 51038.3210 us. Best GFLOPs: 980.1472
2024-04-29 09:33:41 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 09:33:42 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-29 09:33:47 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4391338)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x38dd208)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x4182678)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x6ddeb88)]: 0 failure(s)
2024-04-29 09:33:47 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-29 09:34:00 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4391338)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x38dd208)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x4182678)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x6ddeb88)]: 0 failure(s)
2024-04-29 09:34:13 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4391338)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x38dd208)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x4182678)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x6ddeb88)]: 0 failure(s)
2024-04-29 09:34:26 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4391338)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x38dd208)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x4182678)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x6ddeb88)]: 0 failure(s)
2024-04-29 09:34:39 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4391338)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x38dd208)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x4182678)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x6ddeb88)]: 0 failure(s)
2024-04-29 09:34:48 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9540  0.9540  0.9376  0.9373  0.9373  0.9074  0.8852  0.8852  0.8769  0.8668  0.8668  0.8651  0.8622  0.8598  0.8598  0.8598
[17 : 32]:	0.8437  0.8388  0.8346  0.8271  0.8237  0.8237  0.8211  0.8182  0.8174  0.8094  0.8076  0.8067  0.8047  0.8029  0.7960  0.7936
[33 : 48]:	0.7893  0.7770  0.7757  0.7666  0.7594  0.7578  0.7569  0.7560  0.7560  0.7516  0.7500  0.7476  0.7467  0.7431  0.7431  0.7415
[49 : 64]:	0.7396  0.7368  0.7235  0.7208  0.7183  0.7130  0.7130  0.7130  0.7107  0.7103  0.7048  0.7017  0.7006  0.7000  0.6997  0.6977
2024-04-29 09:34:48 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 09:34:48 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 09:36:21 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #961: GFLOPs: 486.1878. Time: 476.1782 us. Best GFLOPs: 980.1472
2024-04-29 09:36:21 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #962: GFLOPs: 467.5318. Time: 495.1793 us. Best GFLOPs: 980.1472
2024-04-29 09:36:21 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #963: GFLOPs: 860.1013. Time: 269.1684 us. Best GFLOPs: 980.1472
2024-04-29 09:36:21 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #964: GFLOPs: 907.8416. Time: 255.0137 us. Best GFLOPs: 980.1472
2024-04-29 09:36:21 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #965: GFLOPs: 907.8081. Time: 255.0231 us. Best GFLOPs: 980.1472
2024-04-29 09:36:21 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #966: GFLOPs: 853.0430. Time: 271.3955 us. Best GFLOPs: 980.1472
2024-04-29 09:36:21 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #967: GFLOPs: 884.8760. Time: 261.6322 us. Best GFLOPs: 980.1472
2024-04-29 09:36:21 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #968: GFLOPs: 887.9527. Time: 260.7257 us. Best GFLOPs: 980.1472
2024-04-29 09:36:21 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #969: GFLOPs: 919.3000. Time: 251.8352 us. Best GFLOPs: 980.1472
2024-04-29 09:36:21 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #970: GFLOPs: 649.5381. Time: 356.4257 us. Best GFLOPs: 980.1472
2024-04-29 09:36:21 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #971: GFLOPs: 680.3236. Time: 340.2970 us. Best GFLOPs: 980.1472
2024-04-29 09:36:21 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #972: GFLOPs: 966.0920. Time: 239.6377 us. Best GFLOPs: 980.1472
2024-04-29 09:36:21 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #973: GFLOPs: 858.6858. Time: 269.6121 us. Best GFLOPs: 980.1472
2024-04-29 09:36:21 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #974: GFLOPs: 667.5887. Time: 346.7884 us. Best GFLOPs: 980.1472
2024-04-29 09:36:21 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #975: GFLOPs: 476.4628. Time: 485.8974 us. Best GFLOPs: 980.1472
2024-04-29 09:36:21 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #976: GFLOPs: 677.9099. Time: 341.5086 us. Best GFLOPs: 980.1472
2024-04-29 09:36:21 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #977: GFLOPs: 896.7931. Time: 258.1555 us. Best GFLOPs: 980.1472
2024-04-29 09:36:21 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #978: GFLOPs: 862.3315. Time: 268.4722 us. Best GFLOPs: 980.1472
2024-04-29 09:36:21 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #979: GFLOPs: 776.4470. Time: 298.1685 us. Best GFLOPs: 980.1472
2024-04-29 09:36:21 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #980: GFLOPs: 530.1394. Time: 436.7004 us. Best GFLOPs: 980.1472
2024-04-29 09:36:21 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #981: GFLOPs: 845.3783. Time: 273.8562 us. Best GFLOPs: 980.1472
2024-04-29 09:36:21 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #982: GFLOPs: 824.6625. Time: 280.7355 us. Best GFLOPs: 980.1472
2024-04-29 09:36:21 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #983: GFLOPs: 896.3147. Time: 258.2933 us. Best GFLOPs: 980.1472
2024-04-29 09:36:21 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #984: GFLOPs: 828.2556. Time: 279.5176 us. Best GFLOPs: 980.1472
2024-04-29 09:36:21 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #985: GFLOPs: 797.3658. Time: 290.3461 us. Best GFLOPs: 980.1472
2024-04-29 09:36:21 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #986: GFLOPs: 796.8693. Time: 290.5270 us. Best GFLOPs: 980.1472
2024-04-29 09:36:21 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #987: GFLOPs: 570.9975. Time: 405.4519 us. Best GFLOPs: 980.1472
2024-04-29 09:36:21 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #988: GFLOPs: 859.5598. Time: 269.3379 us. Best GFLOPs: 980.1472
2024-04-29 09:36:21 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #989: GFLOPs: 688.9148. Time: 336.0533 us. Best GFLOPs: 980.1472
2024-04-29 09:36:21 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #990: GFLOPs: 826.5225. Time: 280.1038 us. Best GFLOPs: 980.1472
2024-04-29 09:36:21 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #991: GFLOPs: 642.6067. Time: 360.2702 us. Best GFLOPs: 980.1472
2024-04-29 09:36:21 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #992: GFLOPs: 858.2486. Time: 269.7494 us. Best GFLOPs: 980.1472
2024-04-29 09:36:21 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #993: GFLOPs: 793.0705. Time: 291.9186 us. Best GFLOPs: 980.1472
2024-04-29 09:36:21 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #994: GFLOPs: 788.3218. Time: 293.6771 us. Best GFLOPs: 980.1472
2024-04-29 09:36:21 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #995: GFLOPs: 665.0174. Time: 348.1293 us. Best GFLOPs: 980.1472
2024-04-29 09:36:21 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #996: GFLOPs: 836.2775. Time: 276.8364 us. Best GFLOPs: 980.1472
2024-04-29 09:36:21 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #997: GFLOPs: 856.0058. Time: 270.4562 us. Best GFLOPs: 980.1472
2024-04-29 09:36:21 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #998: GFLOPs: 811.9855. Time: 285.1185 us. Best GFLOPs: 980.1472
2024-04-29 09:36:21 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #999: GFLOPs: 824.6316. Time: 280.7460 us. Best GFLOPs: 980.1472
2024-04-29 09:36:21 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #1000: GFLOPs: 701.8071. Time: 329.8799 us. Best GFLOPs: 980.1472
2024-04-29 09:36:21 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #1001: GFLOPs: 874.7374. Time: 264.6646 us. Best GFLOPs: 980.1472
2024-04-29 09:36:21 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #1002: GFLOPs: 828.6335. Time: 279.3902 us. Best GFLOPs: 980.1472
2024-04-29 09:36:21 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #1003: GFLOPs: 415.1138. Time: 557.7074 us. Best GFLOPs: 980.1472
2024-04-29 09:36:21 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #1004: GFLOPs: 903.7999. Time: 256.1541 us. Best GFLOPs: 980.1472
2024-04-29 09:36:21 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #1005: GFLOPs: 706.4165. Time: 327.7274 us. Best GFLOPs: 980.1472
2024-04-29 09:36:21 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #1006: GFLOPs: 678.0282. Time: 341.4490 us. Best GFLOPs: 980.1472
2024-04-29 09:36:21 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #1007: GFLOPs: 899.2412. Time: 257.4527 us. Best GFLOPs: 980.1472
2024-04-29 09:36:21 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #1008: GFLOPs: 422.3409. Time: 548.1639 us. Best GFLOPs: 980.1472
2024-04-29 09:36:21 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #1009: GFLOPs: 689.2846. Time: 335.8730 us. Best GFLOPs: 980.1472
2024-04-29 09:36:21 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #1010: GFLOPs: 626.2920. Time: 369.6551 us. Best GFLOPs: 980.1472
2024-04-29 09:36:21 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #1011: GFLOPs: 761.4486. Time: 304.0416 us. Best GFLOPs: 980.1472
2024-04-29 09:36:21 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #1012: GFLOPs: 613.3982. Time: 377.4254 us. Best GFLOPs: 980.1472
2024-04-29 09:36:21 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #1013: GFLOPs: 615.1457. Time: 376.3532 us. Best GFLOPs: 980.1472
2024-04-29 09:36:21 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #1014: GFLOPs: 680.5601. Time: 340.1787 us. Best GFLOPs: 980.1472
2024-04-29 09:36:21 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #1015: GFLOPs: 612.0159. Time: 378.2779 us. Best GFLOPs: 980.1472
2024-04-29 09:36:21 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #1016: GFLOPs: 680.3524. Time: 340.2826 us. Best GFLOPs: 980.1472
2024-04-29 09:36:21 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #1017: GFLOPs: 841.6983. Time: 275.0535 us. Best GFLOPs: 980.1472
2024-04-29 09:36:21 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #1018: GFLOPs: 911.2629. Time: 254.0563 us. Best GFLOPs: 980.1472
2024-04-29 09:36:21 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #1019: GFLOPs: 597.4850. Time: 387.4776 us. Best GFLOPs: 980.1472
2024-04-29 09:36:21 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #1020: GFLOPs: 575.8139. Time: 402.0606 us. Best GFLOPs: 980.1472
2024-04-29 09:36:21 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #1021: GFLOPs: 614.4695. Time: 376.7674 us. Best GFLOPs: 980.1472
2024-04-29 09:36:21 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #1022: GFLOPs: 46.1243. Time: 5019.3027 us. Best GFLOPs: 980.1472
2024-04-29 09:36:21 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #1023: GFLOPs: 38.7817. Time: 5969.6237 us. Best GFLOPs: 980.1472
2024-04-29 09:36:21 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #1024: GFLOPs: 72.6602. Time: 3186.2307 us. Best GFLOPs: 980.1472
2024-04-29 09:51:13 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 09:51:14 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-29 09:51:18 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4391338)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x38dd208)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x4182678)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x6ddeb88)]: 0 failure(s)
2024-04-29 09:51:18 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-29 09:51:31 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4391338)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x38dd208)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x4182678)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x6ddeb88)]: 0 failure(s)
2024-04-29 09:51:44 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4391338)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x38dd208)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x4182678)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x6ddeb88)]: 0 failure(s)
2024-04-29 09:51:57 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4391338)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x38dd208)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x4182678)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x6ddeb88)]: 0 failure(s)
2024-04-29 09:52:10 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x4391338)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x38dd208)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x4182678)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x6ddeb88)]: 0 failure(s)
2024-04-29 09:52:19 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9028  0.9028  0.9028  0.9004  0.8947  0.8872  0.8866  0.8865  0.8802  0.8802  0.8802  0.8740  0.8603  0.8582  0.8582  0.8532
[17 : 32]:	0.8527  0.8402  0.8384  0.8362  0.8316  0.8306  0.8219  0.8166  0.8141  0.8049  0.7900  0.7828  0.7759  0.7669  0.7669  0.7648
[33 : 48]:	0.7623  0.7620  0.7613  0.7611  0.7609  0.7565  0.7501  0.7407  0.7401  0.7396  0.7385  0.7373  0.7368  0.7368  0.7281  0.7278
[49 : 64]:	0.7271  0.7219  0.7215  0.7162  0.7152  0.7127  0.7111  0.7104  0.7104  0.7098  0.7098  0.7098  0.7096  0.7074  0.7066  0.7060
2024-04-29 09:52:19 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 09:52:19 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 09:53:54 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #1025: GFLOPs: 478.1985. Time: 484.1338 us. Best GFLOPs: 980.1472
2024-04-29 09:53:54 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #1026: GFLOPs: 507.7086. Time: 455.9940 us. Best GFLOPs: 980.1472
2024-04-29 09:53:54 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #1027: GFLOPs: 735.2319. Time: 314.8831 us. Best GFLOPs: 980.1472
2024-04-29 09:53:54 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #1028: GFLOPs: 907.7281. Time: 255.0456 us. Best GFLOPs: 980.1472
2024-04-29 09:53:54 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #1029: GFLOPs: 848.9662. Time: 272.6988 us. Best GFLOPs: 980.1472
2024-04-29 09:53:54 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #1030: GFLOPs: 525.1980. Time: 440.8091 us. Best GFLOPs: 980.1472
2024-04-29 09:53:54 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #1031: GFLOPs: 860.6494. Time: 268.9969 us. Best GFLOPs: 980.1472
2024-04-29 09:53:54 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #1032: GFLOPs: 894.3819. Time: 258.8515 us. Best GFLOPs: 980.1472
2024-04-29 09:53:54 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #1033: GFLOPs: 866.6989. Time: 267.1194 us. Best GFLOPs: 980.1472
2024-04-29 09:53:54 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #1034: GFLOPs: 928.2030. Time: 249.4196 us. Best GFLOPs: 980.1472
2024-04-29 09:53:54 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #1035: GFLOPs: 853.3948. Time: 271.2837 us. Best GFLOPs: 980.1472
2024-04-29 09:53:54 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #1036: GFLOPs: 715.9357. Time: 323.3699 us. Best GFLOPs: 980.1472
2024-04-29 09:53:54 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #1037: GFLOPs: 867.9779. Time: 266.7257 us. Best GFLOPs: 980.1472
2024-04-29 09:53:54 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #1038: GFLOPs: 804.7373. Time: 287.6865 us. Best GFLOPs: 980.1472
2024-04-29 09:53:54 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #1039: GFLOPs: 936.2253. Time: 247.2824 us. Best GFLOPs: 980.1472
2024-04-29 09:53:54 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #1040: GFLOPs: 860.7065. Time: 268.9791 us. Best GFLOPs: 980.1472
2024-04-29 09:53:54 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #1041: GFLOPs: 808.6410. Time: 286.2977 us. Best GFLOPs: 980.1472
2024-04-29 09:53:54 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #1042: GFLOPs: 763.2418. Time: 303.3273 us. Best GFLOPs: 980.1472
2024-04-29 09:53:54 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #1043: GFLOPs: 782.4650. Time: 295.8753 us. Best GFLOPs: 980.1472
2024-04-29 09:53:54 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #1044: GFLOPs: 816.9819. Time: 283.3748 us. Best GFLOPs: 980.1472
2024-04-29 09:53:54 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #1045: GFLOPs: 822.8265. Time: 281.3619 us. Best GFLOPs: 980.1472
2024-04-29 09:53:54 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #1046: GFLOPs: 776.5810. Time: 298.1171 us. Best GFLOPs: 980.1472
2024-04-29 09:53:54 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #1047: GFLOPs: 821.0812. Time: 281.9600 us. Best GFLOPs: 980.1472
2024-04-29 09:53:54 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #1048: GFLOPs: 848.3816. Time: 272.8867 us. Best GFLOPs: 980.1472
2024-04-29 09:53:54 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #1049: GFLOPs: 784.3667. Time: 295.1579 us. Best GFLOPs: 980.1472
2024-04-29 09:53:54 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #1050: GFLOPs: 398.8358. Time: 580.4697 us. Best GFLOPs: 980.1472
2024-04-29 09:53:54 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #1051: GFLOPs: 117.8264. Time: 1964.8566 us. Best GFLOPs: 980.1472
2024-04-29 09:53:54 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #1052: GFLOPs: 757.5170. Time: 305.6196 us. Best GFLOPs: 980.1472
2024-04-29 09:53:54 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #1053: GFLOPs: 532.1121. Time: 435.0814 us. Best GFLOPs: 980.1472
2024-04-29 09:53:54 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #1054: GFLOPs: 626.1488. Time: 369.7397 us. Best GFLOPs: 980.1472
2024-04-29 09:53:54 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #1055: GFLOPs: 806.3120. Time: 287.1246 us. Best GFLOPs: 980.1472
2024-04-29 09:53:54 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #1056: GFLOPs: 610.8409. Time: 379.0055 us. Best GFLOPs: 980.1472
2024-04-29 09:53:54 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #1057: GFLOPs: 767.3657. Time: 301.6972 us. Best GFLOPs: 980.1472
2024-04-29 09:53:54 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #1058: GFLOPs: 772.2203. Time: 299.8005 us. Best GFLOPs: 980.1472
2024-04-29 09:53:54 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #1059: GFLOPs: 527.5490. Time: 438.8447 us. Best GFLOPs: 980.1472
2024-04-29 09:53:54 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #1060: GFLOPs: 792.5221. Time: 292.1206 us. Best GFLOPs: 980.1472
2024-04-29 09:53:54 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #1061: GFLOPs: 668.5090. Time: 346.3110 us. Best GFLOPs: 980.1472
2024-04-29 09:53:54 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #1062: GFLOPs: 770.9002. Time: 300.3139 us. Best GFLOPs: 980.1472
2024-04-29 09:53:54 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #1063: GFLOPs: 795.4164. Time: 291.0577 us. Best GFLOPs: 980.1472
2024-04-29 09:53:54 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #1064: GFLOPs: 843.5067. Time: 274.4638 us. Best GFLOPs: 980.1472
2024-04-29 09:53:54 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #1065: GFLOPs: 900.3364. Time: 257.1395 us. Best GFLOPs: 980.1472
2024-04-29 09:53:54 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #1066: GFLOPs: 681.4014. Time: 339.7587 us. Best GFLOPs: 980.1472
2024-04-29 09:53:54 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #1067: GFLOPs: 527.2871. Time: 439.0627 us. Best GFLOPs: 980.1472
2024-04-29 09:53:54 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #1068: GFLOPs: 783.3463. Time: 295.5424 us. Best GFLOPs: 980.1472
2024-04-29 09:53:54 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #1069: GFLOPs: 839.2088. Time: 275.8694 us. Best GFLOPs: 980.1472
2024-04-29 09:53:54 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #1070: GFLOPs: 824.6147. Time: 280.7518 us. Best GFLOPs: 980.1472
2024-04-29 09:53:54 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #1071: GFLOPs: 733.2425. Time: 315.7374 us. Best GFLOPs: 980.1472
2024-04-29 09:53:54 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #1072: GFLOPs: 733.3914. Time: 315.6733 us. Best GFLOPs: 980.1472
2024-04-29 09:53:54 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #1073: GFLOPs: 807.1073. Time: 286.8417 us. Best GFLOPs: 980.1472
2024-04-29 09:53:54 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #1074: GFLOPs: 626.1524. Time: 369.7376 us. Best GFLOPs: 980.1472
2024-04-29 09:53:54 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #1075: GFLOPs: 112.1523. Time: 2064.2654 us. Best GFLOPs: 980.1472
2024-04-29 09:53:54 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #1076: GFLOPs: 771.8276. Time: 299.9531 us. Best GFLOPs: 980.1472
2024-04-29 09:53:54 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #1077: GFLOPs: 743.7130. Time: 311.2922 us. Best GFLOPs: 980.1472
2024-04-29 09:53:54 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #1078: GFLOPs: 766.7627. Time: 301.9344 us. Best GFLOPs: 980.1472
2024-04-29 09:53:54 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #1079: GFLOPs: 781.6549. Time: 296.1820 us. Best GFLOPs: 980.1472
2024-04-29 09:53:54 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #1080: GFLOPs: 629.0866. Time: 368.0130 us. Best GFLOPs: 980.1472
2024-04-29 09:53:54 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #1081: GFLOPs: 615.5945. Time: 376.0788 us. Best GFLOPs: 980.1472
2024-04-29 09:53:54 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #1082: GFLOPs: 676.1310. Time: 342.4071 us. Best GFLOPs: 980.1472
2024-04-29 09:53:54 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #1083: GFLOPs: 653.5750. Time: 354.2242 us. Best GFLOPs: 980.1472
2024-04-29 09:53:54 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #1084: GFLOPs: 656.9687. Time: 352.3944 us. Best GFLOPs: 980.1472
2024-04-29 09:53:54 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #1085: GFLOPs: 860.2885. Time: 269.1098 us. Best GFLOPs: 980.1472
2024-04-29 09:53:54 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #1086: GFLOPs: 158.6270. Time: 1459.4749 us. Best GFLOPs: 980.1472
2024-04-29 09:53:54 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #1087: GFLOPs: 5.4776. Time: 42265.3180 us. Best GFLOPs: 980.1472
2024-04-29 09:53:54 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1] Trial #1088: GFLOPs: 50.8139. Time: 4556.0813 us. Best GFLOPs: 980.1472
