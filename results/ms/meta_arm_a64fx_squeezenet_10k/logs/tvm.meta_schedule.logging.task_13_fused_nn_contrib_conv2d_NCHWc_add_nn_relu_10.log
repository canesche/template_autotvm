2024-04-29 01:54:54 [INFO] [task_scheduler.cc:160] Initializing Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10"
2024-04-29 01:54:54 [INFO] [task_scheduler.cc:35] 
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(8), T.int64(27), T.int64(27), T.int64(4)), "float32"), p1: T.Buffer((T.int64(32), T.int64(8), T.int64(1), T.int64(1), T.int64(4), T.int64(4)), "float32"), p2: T.Buffer((T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(4)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(32), T.int64(27), T.int64(27), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(27), T.int64(27), T.int64(4)))
        T_add = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(27), T.int64(27), T.int64(4)))
        for n, oc_chunk, oh, ow, oc_block, ic, kh, kw in T.grid(T.int64(1), T.int64(32), T.int64(27), T.int64(27), T.int64(4), T.int64(32), T.int64(1), T.int64(1)):
            with T.block("conv2d_NCHWc"):
                v_n, v_oc_chunk, v_oh, v_ow, v_oc_block, v_ic, v_kh, v_kw = T.axis.remap("SSSSSRRR", [n, oc_chunk, oh, ow, oc_block, ic, kh, kw])
                T.reads(p0[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)], p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block])
                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                with T.init():
                    conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + p0[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)] * p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block]
        for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(32), T.int64(27), T.int64(27), T.int64(4)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                T.writes(T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4]
        for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(32), T.int64(27), T.int64(27), T.int64(4)):
            with T.block("T_relu"):
                v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                T.reads(T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
2024-04-29 01:54:54 [INFO] [task_scheduler.cc:164] Total 3 design space(s) generated
2024-04-29 01:54:54 [INFO] [task_scheduler.cc:170] Design space #0:
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(8), T.int64(27), T.int64(27), T.int64(4)), "float32"), p1: T.Buffer((T.int64(32), T.int64(8), T.int64(1), T.int64(1), T.int64(4), T.int64(4)), "float32"), p2: T.Buffer((T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(4)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(32), T.int64(27), T.int64(27), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel": 768, "meta_schedule.unroll_explicit": 16, "meta_schedule.vectorize": 64})
            conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(27), T.int64(27), T.int64(4)))
            for n_0, oc_chunk_0, oh_0, ow_0, oc_block_0, n_1, oc_chunk_1, oh_1, ow_1, oc_block_1, ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(1), T.int64(1), T.int64(3), T.int64(9), T.int64(2), T.int64(1), T.int64(1), T.int64(3), T.int64(3), T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(2), T.int64(8), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(3), T.int64(1), T.int64(1)):
                with T.block("conv2d_NCHWc"):
                    v_n = T.axis.spatial(T.int64(1), n_0 + n_1 + n_2 + n_3)
                    v_oc_chunk = T.axis.spatial(T.int64(32), oc_chunk_0 * T.int64(32) + oc_chunk_1 * T.int64(32) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                    v_oh = T.axis.spatial(T.int64(27), oh_0 * T.int64(9) + oh_1 * T.int64(3) + oh_2 * T.int64(3) + oh_3)
                    v_ow = T.axis.spatial(T.int64(27), ow_0 * T.int64(3) + ow_1 + ow_2 + ow_3)
                    v_oc_block = T.axis.spatial(T.int64(4), oc_block_0 * T.int64(2) + oc_block_1 * T.int64(2) + oc_block_2 + oc_block_3)
                    v_ic = T.axis.reduce(T.int64(32), ic_0 * T.int64(8) + ic_1)
                    v_kh = T.axis.reduce(T.int64(1), kh_0 + kh_1)
                    v_kw = T.axis.reduce(T.int64(1), kw_0 + kw_1)
                    T.reads(p0[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)], p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block])
                    T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                    T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                    with T.init():
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                    conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + p0[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)] * p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block]
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(32), T.int64(27), T.int64(27), T.int64(4)):
                with T.block("T_relu"):
                    v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                    T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                    T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b1 = sch.get_block(name="T_add", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l3, l4, l5, l6, l7, l8, l9, l10 = sch.get_loops(block=b0)
v11, v12, v13, v14 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l15, l16, l17, l18 = sch.split(loop=l3, factors=[v11, v12, v13, v14], preserve_unit_iters=True)
v19, v20, v21, v22 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 16, 2])
l23, l24, l25, l26 = sch.split(loop=l4, factors=[v19, v20, v21, v22], preserve_unit_iters=True)
v27, v28, v29, v30 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[3, 3, 1, 3])
l31, l32, l33, l34 = sch.split(loop=l5, factors=[v27, v28, v29, v30], preserve_unit_iters=True)
v35, v36, v37, v38 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[9, 3, 1, 1])
l39, l40, l41, l42 = sch.split(loop=l6, factors=[v35, v36, v37, v38], preserve_unit_iters=True)
v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[2, 1, 2, 1])
l47, l48, l49, l50 = sch.split(loop=l7, factors=[v43, v44, v45, v46], preserve_unit_iters=True)
v51, v52 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[4, 8])
l53, l54 = sch.split(loop=l8, factors=[v51, v52], preserve_unit_iters=True)
v55, v56 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[1, 1])
l57, l58 = sch.split(loop=l9, factors=[v55, v56], preserve_unit_iters=True)
v59, v60 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 1])
l61, l62 = sch.split(loop=l10, factors=[v59, v60], preserve_unit_iters=True)
sch.reorder(l15, l23, l31, l39, l47, l16, l24, l32, l40, l48, l53, l57, l61, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.vectorize", ann_val=64)
v63 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v63)
2024-04-29 01:54:54 [INFO] [task_scheduler.cc:170] Design space #1:
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(8), T.int64(27), T.int64(27), T.int64(4)), "float32"), p1: T.Buffer((T.int64(32), T.int64(8), T.int64(1), T.int64(1), T.int64(4), T.int64(4)), "float32"), p2: T.Buffer((T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(4)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(32), T.int64(27), T.int64(27), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel": 768, "meta_schedule.unroll_explicit": 0, "meta_schedule.vectorize": 64})
            conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(27), T.int64(27), T.int64(4)))
            for n_0, oc_chunk_0, oh_0, ow_0, oc_block_0, n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(3), T.int64(9), T.int64(2), T.int64(1), T.int64(1), T.int64(3), T.int64(3), T.int64(1)):
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(2), T.int64(8), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(3), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc"):
                        v_n = T.axis.spatial(T.int64(1), n_0 + n_1 + n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(32), oc_chunk_0 * T.int64(32) + oc_chunk_1 * T.int64(32) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(27), oh_0 * T.int64(9) + oh_1 * T.int64(3) + oh_2 * T.int64(3) + oh_3)
                        v_ow = T.axis.spatial(T.int64(27), ow_0 * T.int64(3) + ow_1 + ow_2 + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(4), oc_block_0 * T.int64(2) + oc_block_1 * T.int64(2) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(32), ic_0 * T.int64(8) + ic_1)
                        v_kh = T.axis.reduce(T.int64(1), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(1), kw_0 + kw_1)
                        T.reads(p0[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)], p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        with T.init():
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + p0[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)] * p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block]
                for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(32), T.int64(3), T.int64(1), T.int64(2)):
                    with T.block("T_relu"):
                        v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                        v_ax2 = T.axis.spatial(T.int64(27), oh_0 * T.int64(9) + oh_1 * T.int64(3) + ax2)
                        v_ax3 = T.axis.spatial(T.int64(27), ow_0 * T.int64(3) + ow_1 + ax3)
                        v_ax4 = T.axis.spatial(T.int64(4), oc_block_0 * T.int64(2) + ax4)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b1 = sch.get_block(name="T_add", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l3, l4, l5, l6, l7, l8, l9, l10 = sch.get_loops(block=b0)
v11, v12, v13, v14 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l15, l16, l17, l18 = sch.split(loop=l3, factors=[v11, v12, v13, v14], preserve_unit_iters=True)
v19, v20, v21, v22 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 16, 2])
l23, l24, l25, l26 = sch.split(loop=l4, factors=[v19, v20, v21, v22], preserve_unit_iters=True)
v27, v28, v29, v30 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[3, 3, 1, 3])
l31, l32, l33, l34 = sch.split(loop=l5, factors=[v27, v28, v29, v30], preserve_unit_iters=True)
v35, v36, v37, v38 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[9, 3, 1, 1])
l39, l40, l41, l42 = sch.split(loop=l6, factors=[v35, v36, v37, v38], preserve_unit_iters=True)
v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[2, 1, 2, 1])
l47, l48, l49, l50 = sch.split(loop=l7, factors=[v43, v44, v45, v46], preserve_unit_iters=True)
v51, v52 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[4, 8])
l53, l54 = sch.split(loop=l8, factors=[v51, v52], preserve_unit_iters=True)
v55, v56 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[1, 1])
l57, l58 = sch.split(loop=l9, factors=[v55, v56], preserve_unit_iters=True)
v59, v60 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 1])
l61, l62 = sch.split(loop=l10, factors=[v59, v60], preserve_unit_iters=True)
sch.reorder(l15, l23, l31, l39, l47, l16, l24, l32, l40, l48, l53, l57, l61, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50)
b63, = sch.get_consumers(block=b0)
sch.reverse_compute_at(block=b63, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
2024-04-29 01:54:54 [INFO] [task_scheduler.cc:170] Design space #2:
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(8), T.int64(27), T.int64(27), T.int64(4)), "float32"), p1: T.Buffer((T.int64(32), T.int64(8), T.int64(1), T.int64(1), T.int64(4), T.int64(4)), "float32"), p2: T.Buffer((T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(4)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(32), T.int64(27), T.int64(27), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel": 768, "meta_schedule.unroll_explicit": 0, "meta_schedule.vectorize": 64})
            conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(27), T.int64(27), T.int64(4)))
            for n_0, oc_chunk_0, oh_0, ow_0, oc_block_0 in T.grid(T.int64(1), T.int64(1), T.int64(3), T.int64(9), T.int64(2)):
                for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1, ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(1), T.int64(1), T.int64(3), T.int64(3), T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(2), T.int64(8), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(3), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc"):
                        v_n = T.axis.spatial(T.int64(1), n_0 + n_1 + n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(32), oc_chunk_0 * T.int64(32) + oc_chunk_1 * T.int64(32) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(27), oh_0 * T.int64(9) + oh_1 * T.int64(3) + oh_2 * T.int64(3) + oh_3)
                        v_ow = T.axis.spatial(T.int64(27), ow_0 * T.int64(3) + ow_1 + ow_2 + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(4), oc_block_0 * T.int64(2) + oc_block_1 * T.int64(2) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(32), ic_0 * T.int64(8) + ic_1)
                        v_kh = T.axis.reduce(T.int64(1), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(1), kw_0 + kw_1)
                        T.reads(p0[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)], p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        with T.init():
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + p0[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)] * p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block]
                for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(32), T.int64(9), T.int64(3), T.int64(2)):
                    with T.block("T_relu"):
                        v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                        v_ax2 = T.axis.spatial(T.int64(27), oh_0 * T.int64(9) + ax2)
                        v_ax3 = T.axis.spatial(T.int64(27), ow_0 * T.int64(3) + ax3)
                        v_ax4 = T.axis.spatial(T.int64(4), oc_block_0 * T.int64(2) + ax4)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b1 = sch.get_block(name="T_add", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l3, l4, l5, l6, l7, l8, l9, l10 = sch.get_loops(block=b0)
v11, v12, v13, v14 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l15, l16, l17, l18 = sch.split(loop=l3, factors=[v11, v12, v13, v14], preserve_unit_iters=True)
v19, v20, v21, v22 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 16, 2])
l23, l24, l25, l26 = sch.split(loop=l4, factors=[v19, v20, v21, v22], preserve_unit_iters=True)
v27, v28, v29, v30 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[3, 3, 1, 3])
l31, l32, l33, l34 = sch.split(loop=l5, factors=[v27, v28, v29, v30], preserve_unit_iters=True)
v35, v36, v37, v38 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[9, 3, 1, 1])
l39, l40, l41, l42 = sch.split(loop=l6, factors=[v35, v36, v37, v38], preserve_unit_iters=True)
v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[2, 1, 2, 1])
l47, l48, l49, l50 = sch.split(loop=l7, factors=[v43, v44, v45, v46], preserve_unit_iters=True)
v51, v52 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[4, 8])
l53, l54 = sch.split(loop=l8, factors=[v51, v52], preserve_unit_iters=True)
v55, v56 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[1, 1])
l57, l58 = sch.split(loop=l9, factors=[v55, v56], preserve_unit_iters=True)
v59, v60 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 1])
l61, l62 = sch.split(loop=l10, factors=[v59, v60], preserve_unit_iters=True)
sch.reorder(l15, l23, l31, l39, l47, l16, l24, l32, l40, l48, l53, l57, l61, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50)
b63, = sch.get_consumers(block=b0)
sch.reverse_compute_at(block=b63, loop=l47, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
2024-04-29 02:14:58 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 02:14:58 [INFO] [evolutionary_search.cc:715] Picked top 0 candidate(s) from database
2024-04-29 02:15:01 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x344f188)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3841258)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x348e4f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x39b3f88)]: 0 failure(s)
2024-04-29 02:15:01 [INFO] [evolutionary_search.cc:723] Sampled 512 candidate(s)
2024-04-29 02:15:04 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x344f188)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3841258)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x348e4f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x39b3f88)]: 0 failure(s)
2024-04-29 02:15:07 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x344f188)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3841258)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x348e4f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x39b3f88)]: 0 failure(s)
2024-04-29 02:15:10 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x344f188)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3841258)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x348e4f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x39b3f88)]: 0 failure(s)
2024-04-29 02:15:13 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x344f188)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3841258)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x348e4f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x39b3f88)]: 0 failure(s)
2024-04-29 02:15:13 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9997  0.9993  0.9990  0.9990  0.9989  0.9982  0.9976  0.9974  0.9971  0.9967  0.9966  0.9958  0.9953  0.9948  0.9947  0.9946
[17 : 32]:	0.9944  0.9940  0.9936  0.9928  0.9918  0.9918  0.9909  0.9909  0.9868  0.9866  0.9865  0.9864  0.9859  0.9859  0.9856  0.9848
[33 : 48]:	0.9846  0.9843  0.9843  0.9843  0.9828  0.9827  0.9826  0.9826  0.9824  0.9803  0.9801  0.9799  0.9794  0.9794  0.9794  0.9788
[49 : 64]:	0.9784  0.9780  0.9777  0.9763  0.9751  0.9748  0.9741  0.9735  0.9732  0.9724  0.9724  0.9722  0.9717  0.9705  0.9701  0.9688
2024-04-29 02:15:14 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 02:15:14 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 02:32:27 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #1: GFLOPs: 42.8579. Time: 143.6980 us. Best GFLOPs: 42.8579
2024-04-29 02:32:27 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #2: GFLOPs: 45.4496. Time: 135.5037 us. Best GFLOPs: 45.4496
2024-04-29 02:32:27 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #3: GFLOPs: 18.9857. Time: 324.3798 us. Best GFLOPs: 45.4496
2024-04-29 02:32:27 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #4: GFLOPs: 53.0477. Time: 116.0955 us. Best GFLOPs: 53.0477
2024-04-29 02:32:27 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #5: GFLOPs: 0.9953. Time: 6187.5777 us. Best GFLOPs: 53.0477
2024-04-29 02:32:27 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #6: GFLOPs: 23.8718. Time: 257.9859 us. Best GFLOPs: 53.0477
2024-04-29 02:32:27 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #7: GFLOPs: 46.6806. Time: 131.9304 us. Best GFLOPs: 53.0477
2024-04-29 02:32:27 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #8: GFLOPs: 99.8394. Time: 61.6850 us. Best GFLOPs: 99.8394
2024-04-29 02:32:27 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #9: GFLOPs: 13.5666. Time: 453.9540 us. Best GFLOPs: 99.8394
2024-04-29 02:32:27 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #10: GFLOPs: 16.8673. Time: 365.1204 us. Best GFLOPs: 99.8394
2024-04-29 02:32:27 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #11: GFLOPs: 28.8028. Time: 213.8194 us. Best GFLOPs: 99.8394
2024-04-29 02:32:27 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #12: GFLOPs: 66.2560. Time: 92.9514 us. Best GFLOPs: 99.8394
2024-04-29 02:32:27 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #13: GFLOPs: 49.2672. Time: 125.0039 us. Best GFLOPs: 99.8394
2024-04-29 02:32:27 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #14: GFLOPs: 56.7045. Time: 108.6086 us. Best GFLOPs: 99.8394
2024-04-29 02:32:27 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #15: GFLOPs: 18.0856. Time: 340.5247 us. Best GFLOPs: 99.8394
2024-04-29 02:32:27 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #16: GFLOPs: 21.0272. Time: 292.8874 us. Best GFLOPs: 99.8394
2024-04-29 02:32:27 [INFO] [task_scheduler.cc:121] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #17: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(8), T.int64(27), T.int64(27), T.int64(4)), "float32"), p1: T.Buffer((T.int64(32), T.int64(8), T.int64(1), T.int64(1), T.int64(4), T.int64(4)), "float32"), p2: T.Buffer((T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(4)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(32), T.int64(27), T.int64(27), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(27), T.int64(27), T.int64(4)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused in T.parallel(T.int64(6), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(4), T.int64(1), T.int64(2), T.int64(9), T.int64(27), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused // T.int64(3) * T.int64(16) + oc_chunk_1 * T.int64(4) + oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(27), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused % T.int64(3) * T.int64(9) + oh_1 * T.int64(9) + oh_2_init * T.int64(9) + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(27), ow_1 * T.int64(27) + ow_2_init * T.int64(27) + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(4), oc_block_1 * T.int64(4) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(4), T.int64(32), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(9), T.int64(27), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused // T.int64(3) * T.int64(16) + oc_chunk_1 * T.int64(4) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(27), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused % T.int64(3) * T.int64(9) + oh_1 * T.int64(9) + oh_2 * T.int64(9) + oh_3)
                        v_ow = T.axis.spatial(T.int64(27), ow_1 * T.int64(27) + ow_2 * T.int64(27) + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(4), oc_block_1 * T.int64(4) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(32), ic_0 * T.int64(32) + ic_1)
                        v_kh = T.axis.reduce(T.int64(1), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(1), kw_0 + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], p0[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)], p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + p0[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)] * p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(16), T.int64(9), T.int64(27)):
                for ax4_fused in T.vectorized(T.int64(4)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused // T.int64(3) * T.int64(16) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(27), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused % T.int64(3) * T.int64(9) + ax2)
                        v_ax3, v_ax4 = T.axis.remap("SS", [ax3, ax4_fused])
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b1 = sch.get_block(name="T_add", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l3, l4, l5, l6, l7, l8, l9, l10 = sch.get_loops(block=b0)
v11, v12, v13, v14 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l15, l16, l17, l18 = sch.split(loop=l3, factors=[v11, v12, v13, v14], preserve_unit_iters=True)
v19, v20, v21, v22 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[2, 4, 2, 2])
l23, l24, l25, l26 = sch.split(loop=l4, factors=[v19, v20, v21, v22], preserve_unit_iters=True)
v27, v28, v29, v30 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[3, 1, 1, 9])
l31, l32, l33, l34 = sch.split(loop=l5, factors=[v27, v28, v29, v30], preserve_unit_iters=True)
v35, v36, v37, v38 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 1, 27])
l39, l40, l41, l42 = sch.split(loop=l6, factors=[v35, v36, v37, v38], preserve_unit_iters=True)
v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 4, 1])
l47, l48, l49, l50 = sch.split(loop=l7, factors=[v43, v44, v45, v46], preserve_unit_iters=True)
v51, v52 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[1, 32])
l53, l54 = sch.split(loop=l8, factors=[v51, v52], preserve_unit_iters=True)
v55, v56 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[1, 1])
l57, l58 = sch.split(loop=l9, factors=[v55, v56], preserve_unit_iters=True)
v59, v60 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 1])
l61, l62 = sch.split(loop=l10, factors=[v59, v60], preserve_unit_iters=True)
sch.reorder(l15, l23, l31, l39, l47, l16, l24, l32, l40, l48, l53, l57, l61, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50)
b63, = sch.get_consumers(block=b0)
sch.reverse_compute_at(block=b63, loop=l47, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
sch.enter_postproc()
b65 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b65, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b65, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b65, ann_key="meta_schedule.unroll_explicit")
b66, b67 = sch.get_child_blocks(b65)
l68, l69, l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93 = sch.get_loops(block=b66)
l94 = sch.fuse(l68, l69, l70, l71, l72, preserve_unit_iters=True)
sch.parallel(loop=l94)
sch.annotate(block_or_loop=l94, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l94, ann_key="pragma_unroll_explicit", ann_val=1)
l95, l96, l97, l98, l99, l100 = sch.get_loops(block=b67)
l101 = sch.fuse(l100, preserve_unit_iters=True)
sch.vectorize(loop=l101)
b102 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l103, l104, l105, l106, l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124 = sch.get_loops(block=b102)
b125 = sch.decompose_reduction(block=b102, loop=l109)
2024-04-29 02:32:27 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #18: GFLOPs: 1.2663. Time: 4863.5435 us. Best GFLOPs: 99.8394
2024-04-29 02:32:27 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #19: GFLOPs: 18.4586. Time: 333.6441 us. Best GFLOPs: 99.8394
2024-04-29 02:32:27 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #20: GFLOPs: 66.3088. Time: 92.8774 us. Best GFLOPs: 99.8394
2024-04-29 02:32:27 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #21: GFLOPs: 37.2017. Time: 165.5461 us. Best GFLOPs: 99.8394
2024-04-29 02:32:27 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #22: GFLOPs: 61.4652. Time: 100.1965 us. Best GFLOPs: 99.8394
2024-04-29 02:32:27 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #23: GFLOPs: 64.2326. Time: 95.8795 us. Best GFLOPs: 99.8394
2024-04-29 02:32:27 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #24: GFLOPs: 18.5194. Time: 332.5475 us. Best GFLOPs: 99.8394
2024-04-29 02:32:27 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #25: GFLOPs: 10.7524. Time: 572.7629 us. Best GFLOPs: 99.8394
2024-04-29 02:32:27 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #26: GFLOPs: 2.0670. Time: 2979.5366 us. Best GFLOPs: 99.8394
2024-04-29 02:32:27 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #27: GFLOPs: 38.2301. Time: 161.0926 us. Best GFLOPs: 99.8394
2024-04-29 02:32:27 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #28: GFLOPs: 3.8896. Time: 1583.3384 us. Best GFLOPs: 99.8394
2024-04-29 02:32:27 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #29: GFLOPs: 30.2359. Time: 203.6845 us. Best GFLOPs: 99.8394
2024-04-29 02:32:27 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #30: GFLOPs: 11.8825. Time: 518.2931 us. Best GFLOPs: 99.8394
2024-04-29 02:32:27 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #31: GFLOPs: 69.0552. Time: 89.1836 us. Best GFLOPs: 99.8394
2024-04-29 02:32:27 [INFO] [task_scheduler.cc:121] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #32: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(8), T.int64(27), T.int64(27), T.int64(4)), "float32"), p1: T.Buffer((T.int64(32), T.int64(8), T.int64(1), T.int64(1), T.int64(4), T.int64(4)), "float32"), p2: T.Buffer((T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(4)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(32), T.int64(27), T.int64(27), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(27), T.int64(27), T.int64(4)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused in T.parallel(T.int64(18), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(8), T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(2), T.int64(9), T.int64(1)):
                for oc_block_3_fused_init in T.vectorized(T.int64(4)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused // T.int64(9) * T.int64(16) + oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(27), oh_2_init * T.int64(9) + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(27), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(9) * T.int64(3) + ow_2_init + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(4), oc_block_2_init * T.int64(4) + oc_block_3_fused_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
            for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(8), T.int64(3), T.int64(3), T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(9), T.int64(1)):
                for oc_block_3_fused in T.vectorized(T.int64(4)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused // T.int64(9) * T.int64(16) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(27), oh_2 * T.int64(9) + oh_3)
                        v_ow = T.axis.spatial(T.int64(27), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(9) * T.int64(3) + ow_2 + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(4), oc_block_2 * T.int64(4) + oc_block_3_fused)
                        v_ic = T.axis.reduce(T.int64(32), ic_0 * T.int64(8) + ic_1)
                        v_kh = T.axis.reduce(T.int64(1), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(1), kw_0 + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], p0[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)], p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + p0[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)] * p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block]
            for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(16), T.int64(27)):
                for ax3_ax4_fused in T.vectorized(T.int64(12)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused // T.int64(9) * T.int64(16) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(27), ax2)
                        v_ax3 = T.axis.spatial(T.int64(27), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(9) * T.int64(3) + ax3_ax4_fused // T.int64(4))
                        v_ax4 = T.axis.spatial(T.int64(4), ax3_ax4_fused % T.int64(4))
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b1 = sch.get_block(name="T_add", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l3, l4, l5, l6, l7, l8, l9, l10 = sch.get_loops(block=b0)
v11, v12, v13, v14 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l15, l16, l17, l18 = sch.split(loop=l3, factors=[v11, v12, v13, v14], preserve_unit_iters=True)
v19, v20, v21, v22 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[2, 1, 8, 2])
l23, l24, l25, l26 = sch.split(loop=l4, factors=[v19, v20, v21, v22], preserve_unit_iters=True)
v27, v28, v29, v30 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 3, 9])
l31, l32, l33, l34 = sch.split(loop=l5, factors=[v27, v28, v29, v30], preserve_unit_iters=True)
v35, v36, v37, v38 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[3, 3, 3, 1])
l39, l40, l41, l42 = sch.split(loop=l6, factors=[v35, v36, v37, v38], preserve_unit_iters=True)
v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 1, 4])
l47, l48, l49, l50 = sch.split(loop=l7, factors=[v43, v44, v45, v46], preserve_unit_iters=True)
v51, v52 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[4, 8])
l53, l54 = sch.split(loop=l8, factors=[v51, v52], preserve_unit_iters=True)
v55, v56 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[1, 1])
l57, l58 = sch.split(loop=l9, factors=[v55, v56], preserve_unit_iters=True)
v59, v60 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 1])
l61, l62 = sch.split(loop=l10, factors=[v59, v60], preserve_unit_iters=True)
sch.reorder(l15, l23, l31, l39, l47, l16, l24, l32, l40, l48, l53, l57, l61, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50)
b63, = sch.get_consumers(block=b0)
sch.reverse_compute_at(block=b63, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
sch.enter_postproc()
b65 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b65, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b65, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b65, ann_key="meta_schedule.unroll_explicit")
b66, b67 = sch.get_child_blocks(b65)
l68, l69, l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93 = sch.get_loops(block=b66)
l94 = sch.fuse(l68, l69, l70, l71, l72, l73, l74, l75, l76, l77, preserve_unit_iters=True)
sch.parallel(loop=l94)
l95 = sch.fuse(l93, preserve_unit_iters=True)
sch.vectorize(loop=l95)
sch.annotate(block_or_loop=l94, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l94, ann_key="pragma_unroll_explicit", ann_val=1)
l96, l97, l98, l99, l100, l101 = sch.get_loops(block=b67)
l102 = sch.fuse(l100, l101, preserve_unit_iters=True)
sch.vectorize(loop=l102)
b103 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l104, l105, l106, l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117, l118, l119, l120 = sch.get_loops(block=b103)
b121 = sch.decompose_reduction(block=b103, loop=l105)
2024-04-29 02:32:27 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #33: GFLOPs: 24.9563. Time: 246.7754 us. Best GFLOPs: 99.8394
2024-04-29 02:32:27 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #34: GFLOPs: 65.8423. Time: 93.5355 us. Best GFLOPs: 99.8394
2024-04-29 02:32:27 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #35: GFLOPs: 45.1737. Time: 136.3314 us. Best GFLOPs: 99.8394
2024-04-29 02:32:27 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #36: GFLOPs: 31.3257. Time: 196.5987 us. Best GFLOPs: 99.8394
2024-04-29 02:32:27 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #37: GFLOPs: 50.1650. Time: 122.7667 us. Best GFLOPs: 99.8394
2024-04-29 02:32:27 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #38: GFLOPs: 42.7470. Time: 144.0709 us. Best GFLOPs: 99.8394
2024-04-29 02:32:27 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #39: GFLOPs: 58.1488. Time: 105.9110 us. Best GFLOPs: 99.8394
2024-04-29 02:32:27 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #40: GFLOPs: 29.9630. Time: 205.5402 us. Best GFLOPs: 99.8394
2024-04-29 02:32:27 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #41: GFLOPs: 7.8838. Time: 781.1681 us. Best GFLOPs: 99.8394
2024-04-29 02:32:27 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #42: GFLOPs: 2.4106. Time: 2554.7711 us. Best GFLOPs: 99.8394
2024-04-29 02:32:27 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #43: GFLOPs: 72.7220. Time: 84.6867 us. Best GFLOPs: 99.8394
2024-04-29 02:32:27 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #44: GFLOPs: 8.7735. Time: 701.9513 us. Best GFLOPs: 99.8394
2024-04-29 02:32:27 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #45: GFLOPs: 40.4881. Time: 152.1087 us. Best GFLOPs: 99.8394
2024-04-29 02:32:27 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #46: GFLOPs: 27.3026. Time: 225.5679 us. Best GFLOPs: 99.8394
2024-04-29 02:32:27 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #47: GFLOPs: 10.9158. Time: 564.1893 us. Best GFLOPs: 99.8394
2024-04-29 02:32:27 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #48: GFLOPs: 8.4372. Time: 729.9360 us. Best GFLOPs: 99.8394
2024-04-29 02:32:27 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #49: GFLOPs: 29.6180. Time: 207.9343 us. Best GFLOPs: 99.8394
2024-04-29 02:32:27 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #50: GFLOPs: 34.6722. Time: 177.6233 us. Best GFLOPs: 99.8394
2024-04-29 02:32:27 [INFO] [task_scheduler.cc:121] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #51: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(8), T.int64(27), T.int64(27), T.int64(4)), "float32"), p1: T.Buffer((T.int64(32), T.int64(8), T.int64(1), T.int64(1), T.int64(4), T.int64(4)), "float32"), p2: T.Buffer((T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(4)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(32), T.int64(27), T.int64(27), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(27), T.int64(27), T.int64(4)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused in T.parallel(T.int64(6), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(2), T.int64(9), T.int64(27)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(2)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused // T.int64(3) * T.int64(16) + oc_chunk_1 * T.int64(4) + oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(27), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused % T.int64(3) * T.int64(9) + oh_1 * T.int64(9) + oh_2_init * T.int64(9) + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(27), ow_1 * T.int64(27) + ow_2_init * T.int64(27) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(4), oc_block_1 * T.int64(4) + oc_block_2_init * T.int64(2) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(8), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(2), T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(9), T.int64(27)):
                    for oc_block_3_fused in T.vectorized(T.int64(2)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused // T.int64(3) * T.int64(16) + oc_chunk_1 * T.int64(4) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(27), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused % T.int64(3) * T.int64(9) + oh_1 * T.int64(9) + oh_2 * T.int64(9) + oh_3)
                            v_ow = T.axis.spatial(T.int64(27), ow_1 * T.int64(27) + ow_2 * T.int64(27) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(4), oc_block_1 * T.int64(4) + oc_block_2 * T.int64(2) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(32), ic_0 * T.int64(4) + ic_1)
                            v_kh = T.axis.reduce(T.int64(1), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(1), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], p0[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)], p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + p0[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)] * p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(16), T.int64(9), T.int64(27)):
                for ax4_fused in T.vectorized(T.int64(4)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused // T.int64(3) * T.int64(16) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(27), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused % T.int64(3) * T.int64(9) + ax2)
                        v_ax3, v_ax4 = T.axis.remap("SS", [ax3, ax4_fused])
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b1 = sch.get_block(name="T_add", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l3, l4, l5, l6, l7, l8, l9, l10 = sch.get_loops(block=b0)
v11, v12, v13, v14 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l15, l16, l17, l18 = sch.split(loop=l3, factors=[v11, v12, v13, v14], preserve_unit_iters=True)
v19, v20, v21, v22 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[2, 4, 2, 2])
l23, l24, l25, l26 = sch.split(loop=l4, factors=[v19, v20, v21, v22], preserve_unit_iters=True)
v27, v28, v29, v30 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[3, 1, 1, 9])
l31, l32, l33, l34 = sch.split(loop=l5, factors=[v27, v28, v29, v30], preserve_unit_iters=True)
v35, v36, v37, v38 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 1, 27])
l39, l40, l41, l42 = sch.split(loop=l6, factors=[v35, v36, v37, v38], preserve_unit_iters=True)
v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 2, 2])
l47, l48, l49, l50 = sch.split(loop=l7, factors=[v43, v44, v45, v46], preserve_unit_iters=True)
v51, v52 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[8, 4])
l53, l54 = sch.split(loop=l8, factors=[v51, v52], preserve_unit_iters=True)
v55, v56 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[1, 1])
l57, l58 = sch.split(loop=l9, factors=[v55, v56], preserve_unit_iters=True)
v59, v60 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 1])
l61, l62 = sch.split(loop=l10, factors=[v59, v60], preserve_unit_iters=True)
sch.reorder(l15, l23, l31, l39, l47, l16, l24, l32, l40, l48, l53, l57, l61, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50)
b63, = sch.get_consumers(block=b0)
sch.reverse_compute_at(block=b63, loop=l47, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
sch.enter_postproc()
b65 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b65, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b65, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b65, ann_key="meta_schedule.unroll_explicit")
b66, b67 = sch.get_child_blocks(b65)
l68, l69, l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93 = sch.get_loops(block=b66)
l94 = sch.fuse(l68, l69, l70, l71, l72, preserve_unit_iters=True)
sch.parallel(loop=l94)
l95 = sch.fuse(l93, preserve_unit_iters=True)
sch.vectorize(loop=l95)
sch.annotate(block_or_loop=l94, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l94, ann_key="pragma_unroll_explicit", ann_val=1)
l96, l97, l98, l99, l100, l101 = sch.get_loops(block=b67)
l102 = sch.fuse(l101, preserve_unit_iters=True)
sch.vectorize(loop=l102)
b103 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l104, l105, l106, l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125 = sch.get_loops(block=b103)
b126 = sch.decompose_reduction(block=b103, loop=l110)
2024-04-29 02:32:27 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #52: GFLOPs: 46.5695. Time: 132.2451 us. Best GFLOPs: 99.8394
2024-04-29 02:32:27 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #53: GFLOPs: 26.6313. Time: 231.2542 us. Best GFLOPs: 99.8394
2024-04-29 02:32:27 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #54: GFLOPs: 32.1449. Time: 191.5888 us. Best GFLOPs: 99.8394
2024-04-29 02:32:27 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #55: GFLOPs: 18.3039. Time: 336.4638 us. Best GFLOPs: 99.8394
2024-04-29 02:32:27 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #56: GFLOPs: 25.7731. Time: 238.9539 us. Best GFLOPs: 99.8394
2024-04-29 02:32:27 [INFO] [task_scheduler.cc:121] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #57: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(8), T.int64(27), T.int64(27), T.int64(4)), "float32"), p1: T.Buffer((T.int64(32), T.int64(8), T.int64(1), T.int64(1), T.int64(4), T.int64(4)), "float32"), p2: T.Buffer((T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(4)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(32), T.int64(27), T.int64(27), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(27), T.int64(27), T.int64(4)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused in T.parallel(T.int64(54), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(16), T.int64(1), T.int64(3), T.int64(2), T.int64(1), T.int64(1), T.int64(3), T.int64(3), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused // T.int64(27) * T.int64(16) + oc_chunk_1 * T.int64(16) + oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(27), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused % T.int64(27) // T.int64(3) * T.int64(3) + oh_1 * T.int64(3) + oh_2_init * T.int64(3) + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(27), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused % T.int64(3) * T.int64(9) + ow_1 * T.int64(9) + ow_2_init * T.int64(3) + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(4), oc_block_1 * T.int64(2) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(16), T.int64(1), T.int64(3), T.int64(2), T.int64(8), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(3), T.int64(3), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused // T.int64(27) * T.int64(16) + oc_chunk_1 * T.int64(16) + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(27), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused % T.int64(27) // T.int64(3) * T.int64(3) + oh_1 * T.int64(3) + oh_2 * T.int64(3) + oh_3)
                        v_ow = T.axis.spatial(T.int64(27), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused % T.int64(3) * T.int64(9) + ow_1 * T.int64(9) + ow_2 * T.int64(3) + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(4), oc_block_1 * T.int64(2) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(32), ic_0 * T.int64(8) + ic_1)
                        v_kh = T.axis.reduce(T.int64(1), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(1), kw_0 + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], p0[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)], p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + p0[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)] * p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block]
            for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(16), T.int64(3)):
                for ax3_ax4_fused in T.vectorized(T.int64(36)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused // T.int64(27) * T.int64(16) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(27), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused % T.int64(27) // T.int64(3) * T.int64(3) + ax2)
                        v_ax3 = T.axis.spatial(T.int64(27), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused % T.int64(3) * T.int64(9) + ax3_ax4_fused // T.int64(4))
                        v_ax4 = T.axis.spatial(T.int64(4), ax3_ax4_fused % T.int64(4))
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b1 = sch.get_block(name="T_add", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l3, l4, l5, l6, l7, l8, l9, l10 = sch.get_loops(block=b0)
v11, v12, v13, v14 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l15, l16, l17, l18 = sch.split(loop=l3, factors=[v11, v12, v13, v14], preserve_unit_iters=True)
v19, v20, v21, v22 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[2, 1, 16, 1])
l23, l24, l25, l26 = sch.split(loop=l4, factors=[v19, v20, v21, v22], preserve_unit_iters=True)
v27, v28, v29, v30 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[9, 1, 1, 3])
l31, l32, l33, l34 = sch.split(loop=l5, factors=[v27, v28, v29, v30], preserve_unit_iters=True)
v35, v36, v37, v38 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[3, 1, 3, 3])
l39, l40, l41, l42 = sch.split(loop=l6, factors=[v35, v36, v37, v38], preserve_unit_iters=True)
v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 2, 2, 1])
l47, l48, l49, l50 = sch.split(loop=l7, factors=[v43, v44, v45, v46], preserve_unit_iters=True)
v51, v52 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[4, 8])
l53, l54 = sch.split(loop=l8, factors=[v51, v52], preserve_unit_iters=True)
v55, v56 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[1, 1])
l57, l58 = sch.split(loop=l9, factors=[v55, v56], preserve_unit_iters=True)
v59, v60 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 1])
l61, l62 = sch.split(loop=l10, factors=[v59, v60], preserve_unit_iters=True)
sch.reorder(l15, l23, l31, l39, l47, l16, l24, l32, l40, l48, l53, l57, l61, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50)
b63, = sch.get_consumers(block=b0)
sch.reverse_compute_at(block=b63, loop=l47, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
sch.enter_postproc()
b65 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b65, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b65, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b65, ann_key="meta_schedule.unroll_explicit")
b66, b67 = sch.get_child_blocks(b65)
l68, l69, l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93 = sch.get_loops(block=b66)
l94 = sch.fuse(l68, l69, l70, l71, l72, preserve_unit_iters=True)
sch.parallel(loop=l94)
sch.annotate(block_or_loop=l94, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l94, ann_key="pragma_unroll_explicit", ann_val=1)
l95, l96, l97, l98, l99, l100 = sch.get_loops(block=b67)
l101 = sch.fuse(l99, l100, preserve_unit_iters=True)
sch.vectorize(loop=l101)
b102 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l103, l104, l105, l106, l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124 = sch.get_loops(block=b102)
b125 = sch.decompose_reduction(block=b102, loop=l109)
2024-04-29 02:32:27 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #58: GFLOPs: 43.5714. Time: 141.3450 us. Best GFLOPs: 99.8394
2024-04-29 02:32:27 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #59: GFLOPs: 76.7190. Time: 80.2747 us. Best GFLOPs: 99.8394
2024-04-29 02:32:27 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #60: GFLOPs: 75.5981. Time: 81.4649 us. Best GFLOPs: 99.8394
2024-04-29 02:32:27 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #61: GFLOPs: 1.1048. Time: 5574.2424 us. Best GFLOPs: 99.8394
2024-04-29 02:32:27 [INFO] [task_scheduler.cc:121] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #62: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(8), T.int64(27), T.int64(27), T.int64(4)), "float32"), p1: T.Buffer((T.int64(32), T.int64(8), T.int64(1), T.int64(1), T.int64(4), T.int64(4)), "float32"), p2: T.Buffer((T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(4)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(32), T.int64(27), T.int64(27), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(27), T.int64(27), T.int64(4)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused in T.parallel(T.int64(2), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(2), T.int64(27), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(8), T.int64(1), T.int64(27)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(2)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(32), oc_chunk_1 * T.int64(16) + oc_chunk_2_init * T.int64(8) + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(27), oh_1 + oh_2_init + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(27), ow_1 * T.int64(27) + ow_2_init * T.int64(27) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(4), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused * T.int64(2) + oc_block_1 * T.int64(2) + oc_block_2_init * T.int64(2) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(16), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(8), T.int64(1), T.int64(27)):
                    for oc_block_3_fused in T.vectorized(T.int64(2)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(32), oc_chunk_1 * T.int64(16) + oc_chunk_2 * T.int64(8) + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(27), oh_1 + oh_2 + oh_3)
                            v_ow = T.axis.spatial(T.int64(27), ow_1 * T.int64(27) + ow_2 * T.int64(27) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(4), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused * T.int64(2) + oc_block_1 * T.int64(2) + oc_block_2 * T.int64(2) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(32), ic_0 * T.int64(2) + ic_1)
                            v_kh = T.axis.reduce(T.int64(1), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(1), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], p0[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)], p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + p0[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)] * p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(32), T.int64(27), T.int64(27)):
                for ax4_fused in T.vectorized(T.int64(2)):
                    with T.block("T_relu"):
                        v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                        v_ax4 = T.axis.spatial(T.int64(4), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused * T.int64(2) + ax4_fused)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b1 = sch.get_block(name="T_add", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l3, l4, l5, l6, l7, l8, l9, l10 = sch.get_loops(block=b0)
v11, v12, v13, v14 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l15, l16, l17, l18 = sch.split(loop=l3, factors=[v11, v12, v13, v14], preserve_unit_iters=True)
v19, v20, v21, v22 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 2, 2, 8])
l23, l24, l25, l26 = sch.split(loop=l4, factors=[v19, v20, v21, v22], preserve_unit_iters=True)
v27, v28, v29, v30 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 27, 1, 1])
l31, l32, l33, l34 = sch.split(loop=l5, factors=[v27, v28, v29, v30], preserve_unit_iters=True)
v35, v36, v37, v38 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 1, 27])
l39, l40, l41, l42 = sch.split(loop=l6, factors=[v35, v36, v37, v38], preserve_unit_iters=True)
v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[2, 1, 1, 2])
l47, l48, l49, l50 = sch.split(loop=l7, factors=[v43, v44, v45, v46], preserve_unit_iters=True)
v51, v52 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[16, 2])
l53, l54 = sch.split(loop=l8, factors=[v51, v52], preserve_unit_iters=True)
v55, v56 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[1, 1])
l57, l58 = sch.split(loop=l9, factors=[v55, v56], preserve_unit_iters=True)
v59, v60 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 1])
l61, l62 = sch.split(loop=l10, factors=[v59, v60], preserve_unit_iters=True)
sch.reorder(l15, l23, l31, l39, l47, l16, l24, l32, l40, l48, l53, l57, l61, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50)
b63, = sch.get_consumers(block=b0)
sch.reverse_compute_at(block=b63, loop=l47, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
sch.enter_postproc()
b65 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b65, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b65, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b65, ann_key="meta_schedule.unroll_explicit")
b66, b67 = sch.get_child_blocks(b65)
l68, l69, l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93 = sch.get_loops(block=b66)
l94 = sch.fuse(l68, l69, l70, l71, l72, preserve_unit_iters=True)
sch.parallel(loop=l94)
l95 = sch.fuse(l93, preserve_unit_iters=True)
sch.vectorize(loop=l95)
sch.annotate(block_or_loop=l94, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l94, ann_key="pragma_unroll_explicit", ann_val=1)
l96, l97, l98, l99, l100, l101 = sch.get_loops(block=b67)
l102 = sch.fuse(l101, preserve_unit_iters=True)
sch.vectorize(loop=l102)
b103 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l104, l105, l106, l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125 = sch.get_loops(block=b103)
b126 = sch.decompose_reduction(block=b103, loop=l110)
2024-04-29 02:32:27 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #63: GFLOPs: 11.3080. Time: 544.6233 us. Best GFLOPs: 99.8394
2024-04-29 02:32:27 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #64: GFLOPs: 42.1946. Time: 145.9570 us. Best GFLOPs: 99.8394
2024-04-29 02:56:35 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 02:56:35 [INFO] [evolutionary_search.cc:715] Picked top 59 candidate(s) from database
2024-04-29 02:56:37 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x344f188)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3841258)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x348e4f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x39b3f88)]: 0 failure(s)
2024-04-29 02:56:37 [INFO] [evolutionary_search.cc:723] Sampled 453 candidate(s)
2024-04-29 02:56:42 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x344f188)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3841258)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x348e4f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x39b3f88)]: 0 failure(s)
2024-04-29 02:56:48 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x344f188)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3841258)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x348e4f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x39b3f88)]: 0 failure(s)
2024-04-29 02:56:53 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x344f188)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3841258)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x348e4f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x39b3f88)]: 0 failure(s)
2024-04-29 02:56:58 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x344f188)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3841258)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x348e4f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x39b3f88)]: 0 failure(s)
2024-04-29 02:57:01 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9270  0.9252  0.7737  0.7730  0.7703  0.7691  0.7546  0.7534  0.7534  0.7522  0.7472  0.7440  0.7405  0.7363  0.7295  0.7277
[17 : 32]:	0.7276  0.7251  0.7235  0.7223  0.7191  0.7162  0.7160  0.7156  0.7111  0.7108  0.7105  0.7097  0.7062  0.7055  0.7027  0.7016
[33 : 48]:	0.6995  0.6985  0.6978  0.6977  0.6970  0.6968  0.6950  0.6939  0.6921  0.6891  0.6853  0.6844  0.6809  0.6791  0.6789  0.6780
[49 : 64]:	0.6776  0.6728  0.6724  0.6706  0.6683  0.6679  0.6675  0.6669  0.6655  0.6609  0.6608  0.6605  0.6600  0.6594  0.6584  0.6567
2024-04-29 02:57:02 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 02:57:02 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 02:58:21 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #65: GFLOPs: 59.2759. Time: 103.8970 us. Best GFLOPs: 99.8394
2024-04-29 02:58:21 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #66: GFLOPs: 91.6948. Time: 67.1640 us. Best GFLOPs: 99.8394
2024-04-29 02:58:21 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #67: GFLOPs: 99.4485. Time: 61.9275 us. Best GFLOPs: 99.8394
2024-04-29 02:58:21 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #68: GFLOPs: 87.3540. Time: 70.5015 us. Best GFLOPs: 99.8394
2024-04-29 02:58:21 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #69: GFLOPs: 73.9141. Time: 83.3209 us. Best GFLOPs: 99.8394
2024-04-29 02:58:21 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #70: GFLOPs: 85.2974. Time: 72.2014 us. Best GFLOPs: 99.8394
2024-04-29 02:58:21 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #71: GFLOPs: 75.8547. Time: 81.1893 us. Best GFLOPs: 99.8394
2024-04-29 02:58:21 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #72: GFLOPs: 55.9386. Time: 110.0955 us. Best GFLOPs: 99.8394
2024-04-29 02:58:21 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #73: GFLOPs: 48.4520. Time: 127.1070 us. Best GFLOPs: 99.8394
2024-04-29 02:58:21 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #74: GFLOPs: 149.2771. Time: 41.2561 us. Best GFLOPs: 149.2771
2024-04-29 02:58:21 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #75: GFLOPs: 94.8032. Time: 64.9619 us. Best GFLOPs: 149.2771
2024-04-29 02:58:21 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #76: GFLOPs: 82.6054. Time: 74.5544 us. Best GFLOPs: 149.2771
2024-04-29 02:58:21 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #77: GFLOPs: 109.3484. Time: 56.3208 us. Best GFLOPs: 149.2771
2024-04-29 02:58:21 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #78: GFLOPs: 39.8887. Time: 154.3943 us. Best GFLOPs: 149.2771
2024-04-29 02:58:21 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #79: GFLOPs: 105.7808. Time: 58.2203 us. Best GFLOPs: 149.2771
2024-04-29 02:58:21 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #80: GFLOPs: 84.6951. Time: 72.7148 us. Best GFLOPs: 149.2771
2024-04-29 02:58:21 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #81: GFLOPs: 88.3226. Time: 69.7284 us. Best GFLOPs: 149.2771
2024-04-29 02:58:21 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #82: GFLOPs: 82.1948. Time: 74.9268 us. Best GFLOPs: 149.2771
2024-04-29 02:58:21 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #83: GFLOPs: 85.5074. Time: 72.0241 us. Best GFLOPs: 149.2771
2024-04-29 02:58:21 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #84: GFLOPs: 75.9074. Time: 81.1330 us. Best GFLOPs: 149.2771
2024-04-29 02:58:21 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #85: GFLOPs: 132.5721. Time: 46.4547 us. Best GFLOPs: 149.2771
2024-04-29 02:58:21 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #86: GFLOPs: 117.2300. Time: 52.5343 us. Best GFLOPs: 149.2771
2024-04-29 02:58:21 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #87: GFLOPs: 43.7776. Time: 140.6790 us. Best GFLOPs: 149.2771
2024-04-29 02:58:21 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #88: GFLOPs: 37.8837. Time: 162.5659 us. Best GFLOPs: 149.2771
2024-04-29 02:58:21 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #89: GFLOPs: 59.3273. Time: 103.8071 us. Best GFLOPs: 149.2771
2024-04-29 02:58:21 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #90: GFLOPs: 83.2808. Time: 73.9497 us. Best GFLOPs: 149.2771
2024-04-29 02:58:21 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #91: GFLOPs: 41.3791. Time: 148.8333 us. Best GFLOPs: 149.2771
2024-04-29 02:58:21 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #92: GFLOPs: 85.5271. Time: 72.0075 us. Best GFLOPs: 149.2771
2024-04-29 02:58:21 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #93: GFLOPs: 92.4706. Time: 66.6005 us. Best GFLOPs: 149.2771
2024-04-29 02:58:21 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #94: GFLOPs: 96.2404. Time: 63.9918 us. Best GFLOPs: 149.2771
2024-04-29 02:58:21 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #95: GFLOPs: 48.4949. Time: 126.9945 us. Best GFLOPs: 149.2771
2024-04-29 02:58:21 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #96: GFLOPs: 51.5937. Time: 119.3672 us. Best GFLOPs: 149.2771
2024-04-29 02:58:21 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #97: GFLOPs: 34.7253. Time: 177.3518 us. Best GFLOPs: 149.2771
2024-04-29 02:58:21 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #98: GFLOPs: 87.0264. Time: 70.7669 us. Best GFLOPs: 149.2771
2024-04-29 02:58:21 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #99: GFLOPs: 82.4270. Time: 74.7157 us. Best GFLOPs: 149.2771
2024-04-29 02:58:21 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #100: GFLOPs: 70.2353. Time: 87.6851 us. Best GFLOPs: 149.2771
2024-04-29 02:58:21 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #101: GFLOPs: 132.7193. Time: 46.4031 us. Best GFLOPs: 149.2771
2024-04-29 02:58:21 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #102: GFLOPs: 70.5012. Time: 87.3544 us. Best GFLOPs: 149.2771
2024-04-29 02:58:21 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #103: GFLOPs: 77.6594. Time: 79.3026 us. Best GFLOPs: 149.2771
2024-04-29 02:58:21 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #104: GFLOPs: 84.6820. Time: 72.7261 us. Best GFLOPs: 149.2771
2024-04-29 02:58:21 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #105: GFLOPs: 116.6360. Time: 52.8018 us. Best GFLOPs: 149.2771
2024-04-29 02:58:21 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #106: GFLOPs: 114.9776. Time: 53.5634 us. Best GFLOPs: 149.2771
2024-04-29 02:58:21 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #107: GFLOPs: 105.7655. Time: 58.2288 us. Best GFLOPs: 149.2771
2024-04-29 02:58:21 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #108: GFLOPs: 111.8863. Time: 55.0433 us. Best GFLOPs: 149.2771
2024-04-29 02:58:21 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #109: GFLOPs: 50.8473. Time: 121.1193 us. Best GFLOPs: 149.2771
2024-04-29 02:58:21 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #110: GFLOPs: 71.0042. Time: 86.7356 us. Best GFLOPs: 149.2771
2024-04-29 02:58:21 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #111: GFLOPs: 82.5828. Time: 74.5747 us. Best GFLOPs: 149.2771
2024-04-29 02:58:21 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #112: GFLOPs: 70.8181. Time: 86.9635 us. Best GFLOPs: 149.2771
2024-04-29 02:58:21 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #113: GFLOPs: 42.1906. Time: 145.9706 us. Best GFLOPs: 149.2771
2024-04-29 02:58:21 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #114: GFLOPs: 28.7864. Time: 213.9414 us. Best GFLOPs: 149.2771
2024-04-29 02:58:21 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #115: GFLOPs: 42.4642. Time: 145.0301 us. Best GFLOPs: 149.2771
2024-04-29 02:58:21 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #116: GFLOPs: 79.6061. Time: 77.3633 us. Best GFLOPs: 149.2771
2024-04-29 02:58:21 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #117: GFLOPs: 86.6225. Time: 71.0969 us. Best GFLOPs: 149.2771
2024-04-29 02:58:21 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #118: GFLOPs: 106.1779. Time: 58.0026 us. Best GFLOPs: 149.2771
2024-04-29 02:58:21 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #119: GFLOPs: 93.9472. Time: 65.5538 us. Best GFLOPs: 149.2771
2024-04-29 02:58:21 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #120: GFLOPs: 135.7480. Time: 45.3678 us. Best GFLOPs: 149.2771
2024-04-29 02:58:21 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #121: GFLOPs: 34.3706. Time: 179.1818 us. Best GFLOPs: 149.2771
2024-04-29 02:58:21 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #122: GFLOPs: 83.9568. Time: 73.3543 us. Best GFLOPs: 149.2771
2024-04-29 02:58:21 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #123: GFLOPs: 98.6044. Time: 62.4576 us. Best GFLOPs: 149.2771
2024-04-29 02:58:21 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #124: GFLOPs: 67.0750. Time: 91.8166 us. Best GFLOPs: 149.2771
2024-04-29 02:58:21 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #125: GFLOPs: 75.1592. Time: 81.9406 us. Best GFLOPs: 149.2771
2024-04-29 02:58:21 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #126: GFLOPs: 63.9596. Time: 96.2888 us. Best GFLOPs: 149.2771
2024-04-29 02:58:21 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #127: GFLOPs: 12.5235. Time: 491.7643 us. Best GFLOPs: 149.2771
2024-04-29 02:58:21 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #128: GFLOPs: 88.5831. Time: 69.5234 us. Best GFLOPs: 149.2771
2024-04-29 04:03:54 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 04:03:55 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-29 04:03:57 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x344f188)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3841258)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x348e4f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x39b3f88)]: 0 failure(s)
2024-04-29 04:03:57 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-29 04:04:02 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x344f188)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3841258)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x348e4f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x39b3f88)]: 0 failure(s)
2024-04-29 04:04:07 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x344f188)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3841258)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x348e4f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x39b3f88)]: 0 failure(s)
2024-04-29 04:04:13 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x344f188)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3841258)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x348e4f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x39b3f88)]: 0 failure(s)
2024-04-29 04:04:18 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x344f188)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3841258)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x348e4f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x39b3f88)]: 0 failure(s)
2024-04-29 04:04:21 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9336  0.8505  0.8020  0.7931  0.7775  0.7751  0.7751  0.7751  0.7698  0.7640  0.7596  0.7583  0.7561  0.7533  0.7442  0.7386
[17 : 32]:	0.7318  0.7263  0.7259  0.7243  0.7239  0.7175  0.7151  0.7078  0.7041  0.7012  0.6973  0.6947  0.6922  0.6885  0.6866  0.6843
[33 : 48]:	0.6843  0.6810  0.6792  0.6776  0.6773  0.6769  0.6736  0.6729  0.6697  0.6693  0.6672  0.6656  0.6554  0.6553  0.6546  0.6511
[49 : 64]:	0.6502  0.6500  0.6481  0.6479  0.6475  0.6395  0.6395  0.6377  0.6371  0.6361  0.6353  0.6351  0.6342  0.6329  0.6328  0.6317
2024-04-29 04:04:21 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 04:04:21 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 04:05:45 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #129: GFLOPs: 159.8202. Time: 38.5345 us. Best GFLOPs: 159.8202
2024-04-29 04:05:45 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #130: GFLOPs: 138.5589. Time: 44.4475 us. Best GFLOPs: 159.8202
2024-04-29 04:05:45 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #131: GFLOPs: 71.2638. Time: 86.4197 us. Best GFLOPs: 159.8202
2024-04-29 04:05:45 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #132: GFLOPs: 117.4813. Time: 52.4219 us. Best GFLOPs: 159.8202
2024-04-29 04:05:45 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #133: GFLOPs: 79.6245. Time: 77.3455 us. Best GFLOPs: 159.8202
2024-04-29 04:05:45 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #134: GFLOPs: 116.5940. Time: 52.8208 us. Best GFLOPs: 159.8202
2024-04-29 04:05:45 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #135: GFLOPs: 78.2878. Time: 78.6660 us. Best GFLOPs: 159.8202
2024-04-29 04:05:45 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #136: GFLOPs: 78.4275. Time: 78.5259 us. Best GFLOPs: 159.8202
2024-04-29 04:05:45 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #137: GFLOPs: 102.6631. Time: 59.9884 us. Best GFLOPs: 159.8202
2024-04-29 04:05:45 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #138: GFLOPs: 98.5354. Time: 62.5013 us. Best GFLOPs: 159.8202
2024-04-29 04:05:45 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #139: GFLOPs: 160.6166. Time: 38.3434 us. Best GFLOPs: 160.6166
2024-04-29 04:05:45 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #140: GFLOPs: 79.5402. Time: 77.4274 us. Best GFLOPs: 160.6166
2024-04-29 04:05:45 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #141: GFLOPs: 112.1855. Time: 54.8965 us. Best GFLOPs: 160.6166
2024-04-29 04:05:45 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #142: GFLOPs: 103.8225. Time: 59.3184 us. Best GFLOPs: 160.6166
2024-04-29 04:05:45 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #143: GFLOPs: 116.6500. Time: 52.7955 us. Best GFLOPs: 160.6166
2024-04-29 04:05:45 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #144: GFLOPs: 137.8685. Time: 44.6700 us. Best GFLOPs: 160.6166
2024-04-29 04:05:45 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #145: GFLOPs: 61.0122. Time: 100.9404 us. Best GFLOPs: 160.6166
2024-04-29 04:05:45 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #146: GFLOPs: 97.2619. Time: 63.3197 us. Best GFLOPs: 160.6166
2024-04-29 04:05:45 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #147: GFLOPs: 93.9843. Time: 65.5278 us. Best GFLOPs: 160.6166
2024-04-29 04:05:45 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #148: GFLOPs: 113.4459. Time: 54.2866 us. Best GFLOPs: 160.6166
2024-04-29 04:05:45 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #149: GFLOPs: 71.8265. Time: 85.7426 us. Best GFLOPs: 160.6166
2024-04-29 04:05:45 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #150: GFLOPs: 48.2615. Time: 127.6087 us. Best GFLOPs: 160.6166
2024-04-29 04:05:45 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #151: GFLOPs: 136.8306. Time: 45.0089 us. Best GFLOPs: 160.6166
2024-04-29 04:05:45 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #152: GFLOPs: 78.6035. Time: 78.3501 us. Best GFLOPs: 160.6166
2024-04-29 04:05:45 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #153: GFLOPs: 119.4551. Time: 51.5557 us. Best GFLOPs: 160.6166
2024-04-29 04:05:45 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #154: GFLOPs: 76.4209. Time: 80.5878 us. Best GFLOPs: 160.6166
2024-04-29 04:05:45 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #155: GFLOPs: 56.7891. Time: 108.4467 us. Best GFLOPs: 160.6166
2024-04-29 04:05:45 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #156: GFLOPs: 76.3430. Time: 80.6701 us. Best GFLOPs: 160.6166
2024-04-29 04:05:45 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #157: GFLOPs: 129.6365. Time: 47.5066 us. Best GFLOPs: 160.6166
2024-04-29 04:05:45 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #158: GFLOPs: 113.2440. Time: 54.3834 us. Best GFLOPs: 160.6166
2024-04-29 04:05:45 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #159: GFLOPs: 115.6088. Time: 53.2710 us. Best GFLOPs: 160.6166
2024-04-29 04:05:45 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #160: GFLOPs: 73.9018. Time: 83.3348 us. Best GFLOPs: 160.6166
2024-04-29 04:05:45 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #161: GFLOPs: 77.0962. Time: 79.8819 us. Best GFLOPs: 160.6166
2024-04-29 04:05:45 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #162: GFLOPs: 89.6563. Time: 68.6911 us. Best GFLOPs: 160.6166
2024-04-29 04:05:45 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #163: GFLOPs: 115.5558. Time: 53.2954 us. Best GFLOPs: 160.6166
2024-04-29 04:05:45 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #164: GFLOPs: 143.3308. Time: 42.9677 us. Best GFLOPs: 160.6166
2024-04-29 04:05:45 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #165: GFLOPs: 73.3819. Time: 83.9252 us. Best GFLOPs: 160.6166
2024-04-29 04:05:45 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #166: GFLOPs: 90.5933. Time: 67.9807 us. Best GFLOPs: 160.6166
2024-04-29 04:05:45 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #167: GFLOPs: 69.4258. Time: 88.7075 us. Best GFLOPs: 160.6166
2024-04-29 04:05:45 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #168: GFLOPs: 106.9560. Time: 57.5806 us. Best GFLOPs: 160.6166
2024-04-29 04:05:45 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #169: GFLOPs: 130.2182. Time: 47.2944 us. Best GFLOPs: 160.6166
2024-04-29 04:05:45 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #170: GFLOPs: 92.4354. Time: 66.6259 us. Best GFLOPs: 160.6166
2024-04-29 04:05:45 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #171: GFLOPs: 106.8542. Time: 57.6355 us. Best GFLOPs: 160.6166
2024-04-29 04:05:45 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #172: GFLOPs: 153.2665. Time: 40.1822 us. Best GFLOPs: 160.6166
2024-04-29 04:05:45 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #173: GFLOPs: 97.3981. Time: 63.2311 us. Best GFLOPs: 160.6166
2024-04-29 04:05:45 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #174: GFLOPs: 86.7025. Time: 71.0313 us. Best GFLOPs: 160.6166
2024-04-29 04:05:45 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #175: GFLOPs: 122.4902. Time: 50.2782 us. Best GFLOPs: 160.6166
2024-04-29 04:05:45 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #176: GFLOPs: 111.4346. Time: 55.2664 us. Best GFLOPs: 160.6166
2024-04-29 04:05:45 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #177: GFLOPs: 114.1987. Time: 53.9287 us. Best GFLOPs: 160.6166
2024-04-29 04:05:45 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #178: GFLOPs: 115.0535. Time: 53.5281 us. Best GFLOPs: 160.6166
2024-04-29 04:05:45 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #179: GFLOPs: 102.4182. Time: 60.1318 us. Best GFLOPs: 160.6166
2024-04-29 04:05:45 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #180: GFLOPs: 143.6612. Time: 42.8689 us. Best GFLOPs: 160.6166
2024-04-29 04:05:45 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #181: GFLOPs: 58.7988. Time: 104.7400 us. Best GFLOPs: 160.6166
2024-04-29 04:05:45 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #182: GFLOPs: 164.9282. Time: 37.3410 us. Best GFLOPs: 164.9282
2024-04-29 04:05:45 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #183: GFLOPs: 133.8555. Time: 46.0093 us. Best GFLOPs: 164.9282
2024-04-29 04:05:45 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #184: GFLOPs: 53.4309. Time: 115.2628 us. Best GFLOPs: 164.9282
2024-04-29 04:05:45 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #185: GFLOPs: 171.4370. Time: 35.9234 us. Best GFLOPs: 171.4370
2024-04-29 04:05:45 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #186: GFLOPs: 113.6340. Time: 54.1968 us. Best GFLOPs: 171.4370
2024-04-29 04:05:45 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #187: GFLOPs: 85.9020. Time: 71.6932 us. Best GFLOPs: 171.4370
2024-04-29 04:05:45 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #188: GFLOPs: 81.3848. Time: 75.6725 us. Best GFLOPs: 171.4370
2024-04-29 04:05:45 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #189: GFLOPs: 99.1815. Time: 62.0941 us. Best GFLOPs: 171.4370
2024-04-29 04:05:45 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #190: GFLOPs: 26.4911. Time: 232.4779 us. Best GFLOPs: 171.4370
2024-04-29 04:05:45 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #191: GFLOPs: 62.7721. Time: 98.1104 us. Best GFLOPs: 171.4370
2024-04-29 04:05:45 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #192: GFLOPs: 3.2366. Time: 1902.7922 us. Best GFLOPs: 171.4370
2024-04-29 05:08:14 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 05:08:14 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-29 05:08:16 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x344f188)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3841258)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x348e4f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x39b3f88)]: 0 failure(s)
2024-04-29 05:08:16 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-29 05:08:22 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x344f188)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3841258)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x348e4f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x39b3f88)]: 0 failure(s)
2024-04-29 05:08:27 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x344f188)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3841258)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x348e4f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x39b3f88)]: 0 failure(s)
2024-04-29 05:08:32 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x344f188)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3841258)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x348e4f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x39b3f88)]: 0 failure(s)
2024-04-29 05:08:38 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x344f188)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3841258)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x348e4f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x39b3f88)]: 0 failure(s)
2024-04-29 05:08:41 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9347  0.9227  0.8998  0.8938  0.8938  0.8938  0.8845  0.8843  0.8636  0.8636  0.8636  0.8627  0.8587  0.8477  0.8416  0.8392
[17 : 32]:	0.8319  0.8290  0.8285  0.8273  0.8204  0.8141  0.8084  0.7991  0.7935  0.7915  0.7895  0.7887  0.7874  0.7834  0.7834  0.7758
[33 : 48]:	0.7724  0.7720  0.7675  0.7666  0.7658  0.7649  0.7636  0.7634  0.7611  0.7534  0.7461  0.7459  0.7450  0.7444  0.7422  0.7400
[49 : 64]:	0.7393  0.7358  0.7342  0.7342  0.7246  0.7167  0.7152  0.7142  0.7136  0.7136  0.7132  0.7096  0.7094  0.7078  0.7072  0.7063
2024-04-29 05:08:41 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 05:08:41 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 05:10:21 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #193: GFLOPs: 86.8165. Time: 70.9380 us. Best GFLOPs: 171.4370
2024-04-29 05:10:21 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #194: GFLOPs: 56.3971. Time: 109.2005 us. Best GFLOPs: 171.4370
2024-04-29 05:10:21 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #195: GFLOPs: 85.3018. Time: 72.1977 us. Best GFLOPs: 171.4370
2024-04-29 05:10:21 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #196: GFLOPs: 170.6806. Time: 36.0826 us. Best GFLOPs: 171.4370
2024-04-29 05:10:21 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #197: GFLOPs: 161.2800. Time: 38.1857 us. Best GFLOPs: 171.4370
2024-04-29 05:10:21 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #198: GFLOPs: 173.2350. Time: 35.5505 us. Best GFLOPs: 173.2350
2024-04-29 05:10:21 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #199: GFLOPs: 106.6317. Time: 57.7558 us. Best GFLOPs: 173.2350
2024-04-29 05:10:21 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #200: GFLOPs: 169.6915. Time: 36.2929 us. Best GFLOPs: 173.2350
2024-04-29 05:10:21 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #201: GFLOPs: 107.7422. Time: 57.1604 us. Best GFLOPs: 173.2350
2024-04-29 05:10:21 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #202: GFLOPs: 95.9148. Time: 64.2090 us. Best GFLOPs: 173.2350
2024-04-29 05:10:21 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #203: GFLOPs: 109.6671. Time: 56.1571 us. Best GFLOPs: 173.2350
2024-04-29 05:10:21 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #204: GFLOPs: 119.5880. Time: 51.4984 us. Best GFLOPs: 173.2350
2024-04-29 05:10:21 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #205: GFLOPs: 128.9538. Time: 47.7581 us. Best GFLOPs: 173.2350
2024-04-29 05:10:21 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #206: GFLOPs: 126.0575. Time: 48.8554 us. Best GFLOPs: 173.2350
2024-04-29 05:10:21 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #207: GFLOPs: 120.2199. Time: 51.2277 us. Best GFLOPs: 173.2350
2024-04-29 05:10:21 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #208: GFLOPs: 170.3074. Time: 36.1616 us. Best GFLOPs: 173.2350
2024-04-29 05:10:21 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #209: GFLOPs: 167.1165. Time: 36.8521 us. Best GFLOPs: 173.2350
2024-04-29 05:10:21 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #210: GFLOPs: 116.7740. Time: 52.7394 us. Best GFLOPs: 173.2350
2024-04-29 05:10:21 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #211: GFLOPs: 110.7232. Time: 55.6215 us. Best GFLOPs: 173.2350
2024-04-29 05:10:21 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #212: GFLOPs: 161.4988. Time: 38.1340 us. Best GFLOPs: 173.2350
2024-04-29 05:10:21 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #213: GFLOPs: 112.9284. Time: 54.5354 us. Best GFLOPs: 173.2350
2024-04-29 05:10:21 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #214: GFLOPs: 134.3994. Time: 45.8231 us. Best GFLOPs: 173.2350
2024-04-29 05:10:21 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #215: GFLOPs: 170.7030. Time: 36.0778 us. Best GFLOPs: 173.2350
2024-04-29 05:10:21 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #216: GFLOPs: 155.3886. Time: 39.6335 us. Best GFLOPs: 173.2350
2024-04-29 05:10:21 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #217: GFLOPs: 57.6726. Time: 106.7854 us. Best GFLOPs: 173.2350
2024-04-29 05:10:21 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #218: GFLOPs: 160.6089. Time: 38.3453 us. Best GFLOPs: 173.2350
2024-04-29 05:10:21 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #219: GFLOPs: 99.6661. Time: 61.7922 us. Best GFLOPs: 173.2350
2024-04-29 05:10:21 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #220: GFLOPs: 86.9856. Time: 70.8001 us. Best GFLOPs: 173.2350
2024-04-29 05:10:21 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #221: GFLOPs: 149.9467. Time: 41.0719 us. Best GFLOPs: 173.2350
2024-04-29 05:10:21 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #222: GFLOPs: 143.2617. Time: 42.9884 us. Best GFLOPs: 173.2350
2024-04-29 05:10:21 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #223: GFLOPs: 152.8029. Time: 40.3041 us. Best GFLOPs: 173.2350
2024-04-29 05:10:21 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #224: GFLOPs: 152.2568. Time: 40.4487 us. Best GFLOPs: 173.2350
2024-04-29 05:10:21 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #225: GFLOPs: 134.4869. Time: 45.7932 us. Best GFLOPs: 173.2350
2024-04-29 05:10:21 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #226: GFLOPs: 175.4895. Time: 35.0938 us. Best GFLOPs: 175.4895
2024-04-29 05:10:21 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #227: GFLOPs: 105.1738. Time: 58.5563 us. Best GFLOPs: 175.4895
2024-04-29 05:10:21 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #228: GFLOPs: 91.0231. Time: 67.6597 us. Best GFLOPs: 175.4895
2024-04-29 05:10:21 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #229: GFLOPs: 184.0472. Time: 33.4620 us. Best GFLOPs: 184.0472
2024-04-29 05:10:21 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #230: GFLOPs: 64.0774. Time: 96.1118 us. Best GFLOPs: 184.0472
2024-04-29 05:10:21 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #231: GFLOPs: 115.4104. Time: 53.3625 us. Best GFLOPs: 184.0472
2024-04-29 05:10:21 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #232: GFLOPs: 147.1495. Time: 41.8526 us. Best GFLOPs: 184.0472
2024-04-29 05:10:21 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #233: GFLOPs: 163.1992. Time: 37.7367 us. Best GFLOPs: 184.0472
2024-04-29 05:10:21 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #234: GFLOPs: 57.5709. Time: 106.9741 us. Best GFLOPs: 184.0472
2024-04-29 05:10:21 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #235: GFLOPs: 105.8152. Time: 58.2014 us. Best GFLOPs: 184.0472
2024-04-29 05:10:21 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #236: GFLOPs: 120.0820. Time: 51.2866 us. Best GFLOPs: 184.0472
2024-04-29 05:10:21 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #237: GFLOPs: 125.5167. Time: 49.0659 us. Best GFLOPs: 184.0472
2024-04-29 05:10:21 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #238: GFLOPs: 172.0090. Time: 35.8039 us. Best GFLOPs: 184.0472
2024-04-29 05:10:21 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #239: GFLOPs: 161.8402. Time: 38.0535 us. Best GFLOPs: 184.0472
2024-04-29 05:10:21 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #240: GFLOPs: 92.7794. Time: 66.3789 us. Best GFLOPs: 184.0472
2024-04-29 05:10:21 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #241: GFLOPs: 103.9589. Time: 59.2407 us. Best GFLOPs: 184.0472
2024-04-29 05:10:21 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #242: GFLOPs: 61.6221. Time: 99.9413 us. Best GFLOPs: 184.0472
2024-04-29 05:10:21 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #243: GFLOPs: 150.6558. Time: 40.8786 us. Best GFLOPs: 184.0472
2024-04-29 05:10:21 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #244: GFLOPs: 158.7442. Time: 38.7957 us. Best GFLOPs: 184.0472
2024-04-29 05:10:21 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #245: GFLOPs: 156.4324. Time: 39.3690 us. Best GFLOPs: 184.0472
2024-04-29 05:10:21 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #246: GFLOPs: 75.1159. Time: 81.9879 us. Best GFLOPs: 184.0472
2024-04-29 05:10:21 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #247: GFLOPs: 208.1334. Time: 29.5896 us. Best GFLOPs: 208.1334
2024-04-29 05:10:21 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #248: GFLOPs: 54.7130. Time: 112.5619 us. Best GFLOPs: 208.1334
2024-04-29 05:10:21 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #249: GFLOPs: 61.4187. Time: 100.2723 us. Best GFLOPs: 208.1334
2024-04-29 05:10:21 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #250: GFLOPs: 112.6139. Time: 54.6877 us. Best GFLOPs: 208.1334
2024-04-29 05:10:21 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #251: GFLOPs: 134.5285. Time: 45.7791 us. Best GFLOPs: 208.1334
2024-04-29 05:10:21 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #252: GFLOPs: 102.3854. Time: 60.1511 us. Best GFLOPs: 208.1334
2024-04-29 05:10:21 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #253: GFLOPs: 115.9991. Time: 53.0917 us. Best GFLOPs: 208.1334
2024-04-29 05:10:21 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #254: GFLOPs: 76.8820. Time: 80.1045 us. Best GFLOPs: 208.1334
2024-04-29 05:10:21 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #255: GFLOPs: 27.9929. Time: 220.0055 us. Best GFLOPs: 208.1334
2024-04-29 05:10:21 [INFO] [task_scheduler.cc:121] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #256: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(8), T.int64(27), T.int64(27), T.int64(4)), "float32"), p1: T.Buffer((T.int64(32), T.int64(8), T.int64(1), T.int64(1), T.int64(4), T.int64(4)), "float32"), p2: T.Buffer((T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(4)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(32), T.int64(27), T.int64(27), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(27), T.int64(27), T.int64(4)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused in T.parallel(T.int64(9), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(32), T.int64(1), T.int64(9), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(3), T.int64(1)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(32), oc_chunk_1 + oc_chunk_2_init + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(27), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused // T.int64(3) * T.int64(9) + oh_1 * T.int64(9) + oh_2_init * T.int64(3) + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(27), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused % T.int64(3) * T.int64(9) + ow_1 + ow_2_init + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(4), oc_block_1 * T.int64(4) + oc_block_2_init * T.int64(4) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(3), T.int64(1)):
                    for oc_block_3_fused in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(32), oc_chunk_1 + oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(27), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused // T.int64(3) * T.int64(9) + oh_1 * T.int64(9) + oh_2 * T.int64(3) + oh_3)
                            v_ow = T.axis.spatial(T.int64(27), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused % T.int64(3) * T.int64(9) + ow_1 + ow_2 + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(4), oc_block_1 * T.int64(4) + oc_block_2 * T.int64(4) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(32), ic_0 * T.int64(8) + ic_1)
                            v_kh = T.axis.reduce(T.int64(1), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(1), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], p0[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)], p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + p0[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)] * p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block]
            for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(32), T.int64(9)):
                for ax3_ax4_fused in T.vectorized(T.int64(36)):
                    with T.block("T_relu"):
                        v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                        v_ax2 = T.axis.spatial(T.int64(27), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused // T.int64(3) * T.int64(9) + ax2)
                        v_ax3 = T.axis.spatial(T.int64(27), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused % T.int64(3) * T.int64(9) + ax3_ax4_fused // T.int64(4))
                        v_ax4 = T.axis.spatial(T.int64(4), ax3_ax4_fused % T.int64(4))
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b1 = sch.get_block(name="T_add", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l3, l4, l5, l6, l7, l8, l9, l10 = sch.get_loops(block=b0)
v11, v12, v13, v14 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l15, l16, l17, l18 = sch.split(loop=l3, factors=[v11, v12, v13, v14], preserve_unit_iters=True)
v19, v20, v21, v22 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 32, 1, 1])
l23, l24, l25, l26 = sch.split(loop=l4, factors=[v19, v20, v21, v22], preserve_unit_iters=True)
v27, v28, v29, v30 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[3, 1, 3, 3])
l31, l32, l33, l34 = sch.split(loop=l5, factors=[v27, v28, v29, v30], preserve_unit_iters=True)
v35, v36, v37, v38 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[3, 9, 1, 1])
l39, l40, l41, l42 = sch.split(loop=l6, factors=[v35, v36, v37, v38], preserve_unit_iters=True)
v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 1, 4])
l47, l48, l49, l50 = sch.split(loop=l7, factors=[v43, v44, v45, v46], preserve_unit_iters=True)
v51, v52 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[4, 8])
l53, l54 = sch.split(loop=l8, factors=[v51, v52], preserve_unit_iters=True)
v55, v56 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[1, 1])
l57, l58 = sch.split(loop=l9, factors=[v55, v56], preserve_unit_iters=True)
v59, v60 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 1])
l61, l62 = sch.split(loop=l10, factors=[v59, v60], preserve_unit_iters=True)
sch.reorder(l15, l23, l31, l39, l47, l16, l24, l32, l40, l48, l53, l57, l61, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50)
b63, = sch.get_consumers(block=b0)
sch.reverse_compute_at(block=b63, loop=l47, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
sch.enter_postproc()
b65 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b65, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b65, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b65, ann_key="meta_schedule.unroll_explicit")
b66, b67 = sch.get_child_blocks(b65)
l68, l69, l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93 = sch.get_loops(block=b66)
l94 = sch.fuse(l68, l69, l70, l71, l72, preserve_unit_iters=True)
sch.parallel(loop=l94)
l95 = sch.fuse(l93, preserve_unit_iters=True)
sch.vectorize(loop=l95)
sch.annotate(block_or_loop=l94, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l94, ann_key="pragma_unroll_explicit", ann_val=1)
l96, l97, l98, l99, l100, l101 = sch.get_loops(block=b67)
l102 = sch.fuse(l100, l101, preserve_unit_iters=True)
sch.vectorize(loop=l102)
b103 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l104, l105, l106, l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125 = sch.get_loops(block=b103)
b126 = sch.decompose_reduction(block=b103, loop=l110)
2024-04-29 05:36:58 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 05:36:59 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-29 05:37:01 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x344f188)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3841258)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x348e4f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x39b3f88)]: 0 failure(s)
2024-04-29 05:37:01 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-29 05:37:06 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x344f188)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3841258)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x348e4f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x39b3f88)]: 0 failure(s)
2024-04-29 05:37:12 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x344f188)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3841258)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x348e4f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x39b3f88)]: 0 failure(s)
2024-04-29 05:37:17 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x344f188)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3841258)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x348e4f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x39b3f88)]: 0 failure(s)
2024-04-29 05:37:23 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x344f188)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3841258)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x348e4f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x39b3f88)]: 0 failure(s)
2024-04-29 05:37:26 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9200  0.8912  0.8155  0.8069  0.8069  0.7859  0.7843  0.7834  0.7798  0.7779  0.7765  0.7735  0.7723  0.7711  0.7598  0.7588
[17 : 32]:	0.7588  0.7588  0.7565  0.7508  0.7508  0.7501  0.7371  0.7292  0.7276  0.7274  0.7130  0.7115  0.7115  0.7109  0.7108  0.7100
[33 : 48]:	0.7095  0.7066  0.7062  0.7062  0.7030  0.6996  0.6989  0.6948  0.6940  0.6911  0.6878  0.6853  0.6839  0.6832  0.6830  0.6830
[49 : 64]:	0.6830  0.6825  0.6778  0.6746  0.6743  0.6732  0.6722  0.6722  0.6698  0.6681  0.6677  0.6668  0.6660  0.6631  0.6619  0.6614
2024-04-29 05:37:26 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 05:37:26 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 05:38:46 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #257: GFLOPs: 63.5921. Time: 96.8452 us. Best GFLOPs: 208.1334
2024-04-29 05:38:46 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #258: GFLOPs: 162.7314. Time: 37.8451 us. Best GFLOPs: 208.1334
2024-04-29 05:38:46 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #259: GFLOPs: 181.4292. Time: 33.9449 us. Best GFLOPs: 208.1334
2024-04-29 05:38:46 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #260: GFLOPs: 132.7164. Time: 46.4041 us. Best GFLOPs: 208.1334
2024-04-29 05:38:46 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #261: GFLOPs: 153.4363. Time: 40.1378 us. Best GFLOPs: 208.1334
2024-04-29 05:38:46 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #262: GFLOPs: 155.5789. Time: 39.5850 us. Best GFLOPs: 208.1334
2024-04-29 05:38:46 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #263: GFLOPs: 158.9246. Time: 38.7517 us. Best GFLOPs: 208.1334
2024-04-29 05:38:46 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #264: GFLOPs: 175.9542. Time: 35.0011 us. Best GFLOPs: 208.1334
2024-04-29 05:38:46 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #265: GFLOPs: 168.2887. Time: 36.5954 us. Best GFLOPs: 208.1334
2024-04-29 05:38:46 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #266: GFLOPs: 156.0742. Time: 39.4594 us. Best GFLOPs: 208.1334
2024-04-29 05:38:46 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #267: GFLOPs: 140.7846. Time: 43.7448 us. Best GFLOPs: 208.1334
2024-04-29 05:38:46 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #268: GFLOPs: 100.2844. Time: 61.4113 us. Best GFLOPs: 208.1334
2024-04-29 05:38:46 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #269: GFLOPs: 168.6589. Time: 36.5151 us. Best GFLOPs: 208.1334
2024-04-29 05:38:46 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #270: GFLOPs: 143.4354. Time: 42.9363 us. Best GFLOPs: 208.1334
2024-04-29 05:38:46 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #271: GFLOPs: 149.0501. Time: 41.3189 us. Best GFLOPs: 208.1334
2024-04-29 05:38:46 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #272: GFLOPs: 110.7967. Time: 55.5846 us. Best GFLOPs: 208.1334
2024-04-29 05:38:46 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #273: GFLOPs: 162.8567. Time: 37.8160 us. Best GFLOPs: 208.1334
2024-04-29 05:38:46 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #274: GFLOPs: 161.9729. Time: 38.0224 us. Best GFLOPs: 208.1334
2024-04-29 05:38:46 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #275: GFLOPs: 126.9479. Time: 48.5128 us. Best GFLOPs: 208.1334
2024-04-29 05:38:46 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #276: GFLOPs: 160.1536. Time: 38.4543 us. Best GFLOPs: 208.1334
2024-04-29 05:38:46 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #277: GFLOPs: 143.3268. Time: 42.9689 us. Best GFLOPs: 208.1334
2024-04-29 05:38:46 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #278: GFLOPs: 100.0640. Time: 61.5465 us. Best GFLOPs: 208.1334
2024-04-29 05:38:46 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #279: GFLOPs: 164.0948. Time: 37.5307 us. Best GFLOPs: 208.1334
2024-04-29 05:38:46 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #280: GFLOPs: 100.1062. Time: 61.5206 us. Best GFLOPs: 208.1334
2024-04-29 05:38:46 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #281: GFLOPs: 159.5668. Time: 38.5957 us. Best GFLOPs: 208.1334
2024-04-29 05:38:46 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #282: GFLOPs: 171.2954. Time: 35.9531 us. Best GFLOPs: 208.1334
2024-04-29 05:38:46 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #283: GFLOPs: 155.9699. Time: 39.4858 us. Best GFLOPs: 208.1334
2024-04-29 05:38:46 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #284: GFLOPs: 144.5899. Time: 42.5935 us. Best GFLOPs: 208.1334
2024-04-29 05:38:46 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #285: GFLOPs: 131.3422. Time: 46.8897 us. Best GFLOPs: 208.1334
2024-04-29 05:38:46 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #286: GFLOPs: 97.7629. Time: 62.9952 us. Best GFLOPs: 208.1334
2024-04-29 05:38:46 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #287: GFLOPs: 171.4134. Time: 35.9283 us. Best GFLOPs: 208.1334
2024-04-29 05:38:46 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #288: GFLOPs: 112.9169. Time: 54.5409 us. Best GFLOPs: 208.1334
2024-04-29 05:38:46 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #289: GFLOPs: 128.5008. Time: 47.9265 us. Best GFLOPs: 208.1334
2024-04-29 05:38:46 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #290: GFLOPs: 148.7709. Time: 41.3965 us. Best GFLOPs: 208.1334
2024-04-29 05:38:46 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #291: GFLOPs: 162.6821. Time: 37.8566 us. Best GFLOPs: 208.1334
2024-04-29 05:38:46 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #292: GFLOPs: 147.0094. Time: 41.8925 us. Best GFLOPs: 208.1334
2024-04-29 05:38:46 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #293: GFLOPs: 141.8809. Time: 43.4068 us. Best GFLOPs: 208.1334
2024-04-29 05:38:46 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #294: GFLOPs: 175.7932. Time: 35.0332 us. Best GFLOPs: 208.1334
2024-04-29 05:38:46 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #295: GFLOPs: 128.3111. Time: 47.9973 us. Best GFLOPs: 208.1334
2024-04-29 05:38:46 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #296: GFLOPs: 163.9375. Time: 37.5667 us. Best GFLOPs: 208.1334
2024-04-29 05:38:46 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #297: GFLOPs: 120.2163. Time: 51.2292 us. Best GFLOPs: 208.1334
2024-04-29 05:38:46 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #298: GFLOPs: 122.5238. Time: 50.2644 us. Best GFLOPs: 208.1334
2024-04-29 05:38:46 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #299: GFLOPs: 140.7060. Time: 43.7692 us. Best GFLOPs: 208.1334
2024-04-29 05:38:46 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #300: GFLOPs: 133.1543. Time: 46.2516 us. Best GFLOPs: 208.1334
2024-04-29 05:38:46 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #301: GFLOPs: 172.5948. Time: 35.6824 us. Best GFLOPs: 208.1334
2024-04-29 05:38:46 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #302: GFLOPs: 107.3921. Time: 57.3468 us. Best GFLOPs: 208.1334
2024-04-29 05:38:46 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #303: GFLOPs: 146.5653. Time: 42.0195 us. Best GFLOPs: 208.1334
2024-04-29 05:38:46 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #304: GFLOPs: 172.8431. Time: 35.6311 us. Best GFLOPs: 208.1334
2024-04-29 05:38:46 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #305: GFLOPs: 150.2532. Time: 40.9881 us. Best GFLOPs: 208.1334
2024-04-29 05:38:46 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #306: GFLOPs: 161.2889. Time: 38.1836 us. Best GFLOPs: 208.1334
2024-04-29 05:38:46 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #307: GFLOPs: 127.4798. Time: 48.3103 us. Best GFLOPs: 208.1334
2024-04-29 05:38:46 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #308: GFLOPs: 114.8488. Time: 53.6235 us. Best GFLOPs: 208.1334
2024-04-29 05:38:46 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #309: GFLOPs: 141.9861. Time: 43.3746 us. Best GFLOPs: 208.1334
2024-04-29 05:38:46 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #310: GFLOPs: 102.4449. Time: 60.1161 us. Best GFLOPs: 208.1334
2024-04-29 05:38:46 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #311: GFLOPs: 120.3302. Time: 51.1808 us. Best GFLOPs: 208.1334
2024-04-29 05:38:46 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #312: GFLOPs: 144.3833. Time: 42.6545 us. Best GFLOPs: 208.1334
2024-04-29 05:38:46 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #313: GFLOPs: 111.0335. Time: 55.4661 us. Best GFLOPs: 208.1334
2024-04-29 05:38:46 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #314: GFLOPs: 118.3121. Time: 52.0538 us. Best GFLOPs: 208.1334
2024-04-29 05:38:46 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #315: GFLOPs: 146.1221. Time: 42.1469 us. Best GFLOPs: 208.1334
2024-04-29 05:38:46 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #316: GFLOPs: 116.7215. Time: 52.7631 us. Best GFLOPs: 208.1334
2024-04-29 05:38:46 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #317: GFLOPs: 119.0059. Time: 51.7503 us. Best GFLOPs: 208.1334
2024-04-29 05:38:46 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #318: GFLOPs: 67.7537. Time: 90.8967 us. Best GFLOPs: 208.1334
2024-04-29 05:38:46 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #319: GFLOPs: 47.0476. Time: 130.9013 us. Best GFLOPs: 208.1334
2024-04-29 05:38:46 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #320: GFLOPs: 43.3610. Time: 142.0306 us. Best GFLOPs: 208.1334
2024-04-29 07:03:19 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 07:03:20 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-29 07:03:22 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x344f188)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3841258)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x348e4f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x39b3f88)]: 0 failure(s)
2024-04-29 07:03:22 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-29 07:03:27 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x344f188)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3841258)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x348e4f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x39b3f88)]: 0 failure(s)
2024-04-29 07:03:33 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x344f188)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3841258)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x348e4f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x39b3f88)]: 0 failure(s)
2024-04-29 07:03:38 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x344f188)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3841258)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x348e4f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x39b3f88)]: 0 failure(s)
2024-04-29 07:03:43 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x344f188)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3841258)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x348e4f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x39b3f88)]: 0 failure(s)
2024-04-29 07:03:46 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.8446  0.8169  0.8169  0.8137  0.8137  0.8105  0.8083  0.7983  0.7983  0.7913  0.7881  0.7842  0.7792  0.7792  0.7718  0.7718
[17 : 32]:	0.7717  0.7687  0.7654  0.7645  0.7645  0.7612  0.7597  0.7597  0.7579  0.7579  0.7558  0.7552  0.7541  0.7529  0.7516  0.7507
[33 : 48]:	0.7461  0.7449  0.7449  0.7441  0.7397  0.7396  0.7387  0.7379  0.7342  0.7342  0.7330  0.7319  0.7293  0.7244  0.7235  0.7225
[49 : 64]:	0.7209  0.7204  0.7180  0.7180  0.7174  0.7164  0.7155  0.7145  0.7101  0.7092  0.7079  0.7057  0.7057  0.7057  0.7039  0.7009
2024-04-29 07:03:47 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 07:03:47 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 07:05:09 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #321: GFLOPs: 92.9065. Time: 66.2881 us. Best GFLOPs: 208.1334
2024-04-29 07:05:09 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #322: GFLOPs: 87.7126. Time: 70.2133 us. Best GFLOPs: 208.1334
2024-04-29 07:05:09 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #323: GFLOPs: 170.8283. Time: 36.0514 us. Best GFLOPs: 208.1334
2024-04-29 07:05:09 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #324: GFLOPs: 178.9145. Time: 34.4220 us. Best GFLOPs: 208.1334
2024-04-29 07:05:09 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #325: GFLOPs: 170.6886. Time: 36.0809 us. Best GFLOPs: 208.1334
2024-04-29 07:05:09 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #326: GFLOPs: 167.0826. Time: 36.8596 us. Best GFLOPs: 208.1334
2024-04-29 07:05:09 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #327: GFLOPs: 136.5310. Time: 45.1076 us. Best GFLOPs: 208.1334
2024-04-29 07:05:09 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #328: GFLOPs: 102.8231. Time: 59.8950 us. Best GFLOPs: 208.1334
2024-04-29 07:05:09 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #329: GFLOPs: 182.4910. Time: 33.7474 us. Best GFLOPs: 208.1334
2024-04-29 07:05:09 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #330: GFLOPs: 81.2122. Time: 75.8334 us. Best GFLOPs: 208.1334
2024-04-29 07:05:09 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #331: GFLOPs: 65.6441. Time: 93.8179 us. Best GFLOPs: 208.1334
2024-04-29 07:05:09 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #332: GFLOPs: 80.3961. Time: 76.6031 us. Best GFLOPs: 208.1334
2024-04-29 07:05:09 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #333: GFLOPs: 83.5498. Time: 73.7116 us. Best GFLOPs: 208.1334
2024-04-29 07:05:09 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #334: GFLOPs: 88.9538. Time: 69.2336 us. Best GFLOPs: 208.1334
2024-04-29 07:05:09 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #335: GFLOPs: 164.8778. Time: 37.3525 us. Best GFLOPs: 208.1334
2024-04-29 07:05:09 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #336: GFLOPs: 174.3837. Time: 35.3163 us. Best GFLOPs: 208.1334
2024-04-29 07:05:09 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #337: GFLOPs: 167.7140. Time: 36.7208 us. Best GFLOPs: 208.1334
2024-04-29 07:05:09 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #338: GFLOPs: 106.3799. Time: 57.8924 us. Best GFLOPs: 208.1334
2024-04-29 07:05:09 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #339: GFLOPs: 163.9082. Time: 37.5734 us. Best GFLOPs: 208.1334
2024-04-29 07:05:09 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #340: GFLOPs: 147.8748. Time: 41.6473 us. Best GFLOPs: 208.1334
2024-04-29 07:05:09 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #341: GFLOPs: 90.2952. Time: 68.2051 us. Best GFLOPs: 208.1334
2024-04-29 07:05:09 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #342: GFLOPs: 156.9496. Time: 39.2393 us. Best GFLOPs: 208.1334
2024-04-29 07:05:09 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #343: GFLOPs: 109.6381. Time: 56.1720 us. Best GFLOPs: 208.1334
2024-04-29 07:05:09 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #344: GFLOPs: 165.6456. Time: 37.1793 us. Best GFLOPs: 208.1334
2024-04-29 07:05:09 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #345: GFLOPs: 114.0914. Time: 53.9795 us. Best GFLOPs: 208.1334
2024-04-29 07:05:09 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #346: GFLOPs: 126.1727. Time: 48.8108 us. Best GFLOPs: 208.1334
2024-04-29 07:05:09 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #347: GFLOPs: 140.6570. Time: 43.7845 us. Best GFLOPs: 208.1334
2024-04-29 07:05:09 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #348: GFLOPs: 163.6867. Time: 37.6243 us. Best GFLOPs: 208.1334
2024-04-29 07:05:09 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #349: GFLOPs: 174.6490. Time: 35.2627 us. Best GFLOPs: 208.1334
2024-04-29 07:05:09 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #350: GFLOPs: 155.3550. Time: 39.6421 us. Best GFLOPs: 208.1334
2024-04-29 07:05:09 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #351: GFLOPs: 98.7371. Time: 62.3736 us. Best GFLOPs: 208.1334
2024-04-29 07:05:09 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #352: GFLOPs: 83.2353. Time: 73.9902 us. Best GFLOPs: 208.1334
2024-04-29 07:05:09 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #353: GFLOPs: 152.0879. Time: 40.4936 us. Best GFLOPs: 208.1334
2024-04-29 07:05:09 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #354: GFLOPs: 165.4681. Time: 37.2192 us. Best GFLOPs: 208.1334
2024-04-29 07:05:09 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #355: GFLOPs: 133.4970. Time: 46.1328 us. Best GFLOPs: 208.1334
2024-04-29 07:05:09 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #356: GFLOPs: 91.2933. Time: 67.4594 us. Best GFLOPs: 208.1334
2024-04-29 07:05:09 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #357: GFLOPs: 160.9835. Time: 38.2560 us. Best GFLOPs: 208.1334
2024-04-29 07:05:09 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #358: GFLOPs: 149.0513. Time: 41.3186 us. Best GFLOPs: 208.1334
2024-04-29 07:05:09 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #359: GFLOPs: 100.9653. Time: 60.9971 us. Best GFLOPs: 208.1334
2024-04-29 07:05:09 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #360: GFLOPs: 156.7992. Time: 39.2769 us. Best GFLOPs: 208.1334
2024-04-29 07:05:09 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #361: GFLOPs: 128.6322. Time: 47.8775 us. Best GFLOPs: 208.1334
2024-04-29 07:05:09 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #362: GFLOPs: 136.0828. Time: 45.2562 us. Best GFLOPs: 208.1334
2024-04-29 07:05:09 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #363: GFLOPs: 141.1294. Time: 43.6379 us. Best GFLOPs: 208.1334
2024-04-29 07:05:09 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #364: GFLOPs: 141.4111. Time: 43.5510 us. Best GFLOPs: 208.1334
2024-04-29 07:05:09 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #365: GFLOPs: 114.1557. Time: 53.9491 us. Best GFLOPs: 208.1334
2024-04-29 07:05:09 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #366: GFLOPs: 122.2857. Time: 50.3623 us. Best GFLOPs: 208.1334
2024-04-29 07:05:09 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #367: GFLOPs: 183.3439. Time: 33.5904 us. Best GFLOPs: 208.1334
2024-04-29 07:05:09 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #368: GFLOPs: 155.7579. Time: 39.5395 us. Best GFLOPs: 208.1334
2024-04-29 07:05:09 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #369: GFLOPs: 121.8933. Time: 50.5244 us. Best GFLOPs: 208.1334
2024-04-29 07:05:09 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #370: GFLOPs: 185.3642. Time: 33.2243 us. Best GFLOPs: 208.1334
2024-04-29 07:05:09 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #371: GFLOPs: 144.0027. Time: 42.7672 us. Best GFLOPs: 208.1334
2024-04-29 07:05:09 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #372: GFLOPs: 145.5229. Time: 42.3204 us. Best GFLOPs: 208.1334
2024-04-29 07:05:09 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #373: GFLOPs: 144.8485. Time: 42.5175 us. Best GFLOPs: 208.1334
2024-04-29 07:05:09 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #374: GFLOPs: 102.9904. Time: 59.7977 us. Best GFLOPs: 208.1334
2024-04-29 07:05:09 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #375: GFLOPs: 138.0228. Time: 44.6201 us. Best GFLOPs: 208.1334
2024-04-29 07:05:09 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #376: GFLOPs: 155.6010. Time: 39.5794 us. Best GFLOPs: 208.1334
2024-04-29 07:05:09 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #377: GFLOPs: 138.8271. Time: 44.3616 us. Best GFLOPs: 208.1334
2024-04-29 07:05:09 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #378: GFLOPs: 142.6154. Time: 43.1832 us. Best GFLOPs: 208.1334
2024-04-29 07:05:09 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #379: GFLOPs: 166.0925. Time: 37.0793 us. Best GFLOPs: 208.1334
2024-04-29 07:05:09 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #380: GFLOPs: 107.4793. Time: 57.3003 us. Best GFLOPs: 208.1334
2024-04-29 07:05:09 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #381: GFLOPs: 136.1662. Time: 45.2285 us. Best GFLOPs: 208.1334
2024-04-29 07:05:09 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #382: GFLOPs: 17.1581. Time: 358.9318 us. Best GFLOPs: 208.1334
2024-04-29 07:05:09 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #383: GFLOPs: 41.3816. Time: 148.8242 us. Best GFLOPs: 208.1334
2024-04-29 07:05:09 [INFO] [task_scheduler.cc:131] [Task #13: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #384: GFLOPs: 26.8106. Time: 229.7074 us. Best GFLOPs: 208.1334
