2024-04-28 07:24:28 [INFO] [task_scheduler.cc:160] Initializing Task #3: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
2024-04-28 07:24:28 [INFO] [task_scheduler.cc:35] 
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(112), T.int64(112), T.int64(32)), "float32"), p1: T.Buffer((T.int64(2), T.int64(2), T.int64(3), T.int64(3), T.int64(32), T.int64(64)), "float32"), p2: T.Buffer((T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(64)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(2), T.int64(112), T.int64(112), T.int64(64)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(114), T.int64(114), T.int64(32)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(112), T.int64(112), T.int64(64)))
        T_add = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(112), T.int64(112), T.int64(64)))
        for i0, i1, i2, i3, i4 in T.grid(T.int64(1), T.int64(2), T.int64(114), T.int64(114), T.int64(32)):
            with T.block("data_pad"):
                v_i0, v_i1, v_i2, v_i3, v_i4 = T.axis.remap("SSSSS", [i0, i1, i2, i3, i4])
                T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(113) and T.int64(1) <= v_i3 and v_i3 < T.int64(113), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
        for n, oc_chunk, oh, ow, oc_block, ic, kh, kw in T.grid(T.int64(1), T.int64(2), T.int64(112), T.int64(112), T.int64(64), T.int64(64), T.int64(3), T.int64(3)):
            with T.block("conv2d_NCHWc"):
                v_n, v_oc_chunk, v_oh, v_ow, v_oc_block, v_ic, v_kh, v_kw = T.axis.remap("SSSSSRRR", [n, oc_chunk, oh, ow, oc_block, ic, kh, kw])
                T.reads(data_pad[v_n, v_ic // T.int64(32), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(32)], p1[v_oc_chunk, v_ic // T.int64(32), v_kh, v_kw, v_ic % T.int64(32), v_oc_block])
                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                with T.init():
                    conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(32), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(32)] * p1[v_oc_chunk, v_ic // T.int64(32), v_kh, v_kw, v_ic % T.int64(32), v_oc_block]
        for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(2), T.int64(112), T.int64(112), T.int64(64)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                T.writes(T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4]
        for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(2), T.int64(112), T.int64(112), T.int64(64)):
            with T.block("T_relu"):
                v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                T.reads(T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
2024-04-28 07:24:29 [INFO] [task_scheduler.cc:164] Total 3 design space(s) generated
2024-04-28 07:24:29 [INFO] [task_scheduler.cc:170] Design space #0:
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(112), T.int64(112), T.int64(32)), "float32"), p1: T.Buffer((T.int64(2), T.int64(2), T.int64(3), T.int64(3), T.int64(32), T.int64(64)), "float32"), p2: T.Buffer((T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(64)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(2), T.int64(112), T.int64(112), T.int64(64)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel": 768, "meta_schedule.unroll_explicit": 0, "meta_schedule.vectorize": 64})
            data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(114), T.int64(114), T.int64(32)))
            conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(112), T.int64(112), T.int64(64)))
            for i0, i1, i2, i3, i4 in T.grid(T.int64(1), T.int64(2), T.int64(114), T.int64(114), T.int64(32)):
                with T.block("data_pad"):
                    v_i0, v_i1, v_i2, v_i3, v_i4 = T.axis.remap("SSSSS", [i0, i1, i2, i3, i4])
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(113) and T.int64(1) <= v_i3 and v_i3 < T.int64(113), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for n_0, oc_chunk_0, oh_0, ow_0, oc_block_0, n_1, oc_chunk_1, oh_1, ow_1, oc_block_1, ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(7), T.int64(2), T.int64(4), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(16), T.int64(56), T.int64(4), T.int64(32), T.int64(3), T.int64(3), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(2)):
                with T.block("conv2d_NCHWc"):
                    v_n = T.axis.spatial(T.int64(1), n_0 + n_1 + n_2 + n_3)
                    v_oc_chunk = T.axis.spatial(T.int64(2), oc_chunk_0 * T.int64(2) + oc_chunk_1 * T.int64(2) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                    v_oh = T.axis.spatial(T.int64(112), oh_0 * T.int64(112) + oh_1 * T.int64(16) + oh_2 + oh_3)
                    v_ow = T.axis.spatial(T.int64(112), ow_0 * T.int64(112) + ow_1 * T.int64(56) + ow_2 + ow_3)
                    v_oc_block = T.axis.spatial(T.int64(64), oc_block_0 * T.int64(32) + oc_block_1 * T.int64(8) + oc_block_2 * T.int64(2) + oc_block_3)
                    v_ic = T.axis.reduce(T.int64(64), ic_0 * T.int64(32) + ic_1)
                    v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                    v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                    T.reads(data_pad[v_n, v_ic // T.int64(32), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(32)], p1[v_oc_chunk, v_ic // T.int64(32), v_kh, v_kw, v_ic % T.int64(32), v_oc_block])
                    T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                    T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                    with T.init():
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                    conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(32), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(32)] * p1[v_oc_chunk, v_ic // T.int64(32), v_kh, v_kw, v_ic % T.int64(32), v_oc_block]
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(2), T.int64(112), T.int64(112), T.int64(64)):
                with T.block("T_relu"):
                    v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                    T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                    T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 2])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 7, 16, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 2, 56, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[2, 4, 4, 2])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[2, 32])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
l65 = sch.sample_compute_location(block=b0, decision=-1)
sch.compute_at(block=b0, loop=l65, preserve_unit_loops=True, index=-1)
2024-04-28 07:24:29 [INFO] [task_scheduler.cc:170] Design space #1:
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(112), T.int64(112), T.int64(32)), "float32"), p1: T.Buffer((T.int64(2), T.int64(2), T.int64(3), T.int64(3), T.int64(32), T.int64(64)), "float32"), p2: T.Buffer((T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(64)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(2), T.int64(112), T.int64(112), T.int64(64)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel": 768, "meta_schedule.unroll_explicit": 16, "meta_schedule.vectorize": 64})
            conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(112), T.int64(112), T.int64(64)))
            for n_0, oc_chunk_0, oh_0, ow_0, oc_block_0, n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(7), T.int64(2), T.int64(4)):
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(16), T.int64(56), T.int64(4), T.int64(32), T.int64(3), T.int64(3), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(2)):
                    with T.block("conv2d_NCHWc"):
                        v_n = T.axis.spatial(T.int64(1), n_0 + n_1 + n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(2), oc_chunk_0 * T.int64(2) + oc_chunk_1 * T.int64(2) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(112), oh_0 * T.int64(112) + oh_1 * T.int64(16) + oh_2 + oh_3)
                        v_ow = T.axis.spatial(T.int64(112), ow_0 * T.int64(112) + ow_1 * T.int64(56) + ow_2 + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(64), oc_block_0 * T.int64(32) + oc_block_1 * T.int64(8) + oc_block_2 * T.int64(2) + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(64), ic_0 * T.int64(32) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                        T.reads(p0[v_n, v_ic // T.int64(32), v_oh + v_kh - T.int64(1), v_ow + v_kw - T.int64(1), v_ic % T.int64(32)], p1[v_oc_chunk, v_ic // T.int64(32), v_kh, v_kw, v_ic % T.int64(32), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        with T.init():
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + T.if_then_else(T.int64(1) <= v_oh + v_kh and v_oh + v_kh < T.int64(113) and T.int64(1) <= v_ow + v_kw and v_ow + v_kw < T.int64(113), p0[v_n, v_ic // T.int64(32), v_oh + v_kh - T.int64(1), v_ow + v_kw - T.int64(1), v_ic % T.int64(32)], T.float32(0)) * p1[v_oc_chunk, v_ic // T.int64(32), v_kh, v_kw, v_ic % T.int64(32), v_oc_block]
                for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(2), T.int64(16), T.int64(56), T.int64(8)):
                    with T.block("T_relu"):
                        v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                        v_ax2 = T.axis.spatial(T.int64(112), oh_1 * T.int64(16) + ax2)
                        v_ax3 = T.axis.spatial(T.int64(112), ow_1 * T.int64(56) + ax3)
                        v_ax4 = T.axis.spatial(T.int64(64), oc_block_0 * T.int64(32) + oc_block_1 * T.int64(8) + ax4)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 2])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 7, 16, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 2, 56, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[2, 4, 4, 2])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[2, 32])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=-2)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
2024-04-28 07:24:29 [INFO] [task_scheduler.cc:170] Design space #2:
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(112), T.int64(112), T.int64(32)), "float32"), p1: T.Buffer((T.int64(2), T.int64(2), T.int64(3), T.int64(3), T.int64(32), T.int64(64)), "float32"), p2: T.Buffer((T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(64)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(2), T.int64(112), T.int64(112), T.int64(64)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel": 768, "meta_schedule.unroll_explicit": 16, "meta_schedule.vectorize": 64})
            data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(114), T.int64(114), T.int64(32)))
            conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(112), T.int64(112), T.int64(64)))
            for n_0, oc_chunk_0, oh_0, ow_0, oc_block_0 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2)):
                for n_1, oc_chunk_1, oh_1 in T.grid(T.int64(1), T.int64(1), T.int64(7)):
                    for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(2), T.int64(18), T.int64(114), T.int64(32)):
                        with T.block("data_pad"):
                            v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                            v_i2 = T.axis.spatial(T.int64(114), oh_1 * T.int64(16) + ax2)
                            v_i3, v_i4 = T.axis.remap("SS", [ax3, ax4])
                            T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                            T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                            data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(113) and T.int64(1) <= v_i3 and v_i3 < T.int64(113), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                    for ow_1, oc_block_1, ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(2), T.int64(4), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(16), T.int64(56), T.int64(4), T.int64(32), T.int64(3), T.int64(3), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(2)):
                        with T.block("conv2d_NCHWc"):
                            v_n = T.axis.spatial(T.int64(1), n_0 + n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(2), oc_chunk_0 * T.int64(2) + oc_chunk_1 * T.int64(2) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(112), oh_0 * T.int64(112) + oh_1 * T.int64(16) + oh_2 + oh_3)
                            v_ow = T.axis.spatial(T.int64(112), ow_0 * T.int64(112) + ow_1 * T.int64(56) + ow_2 + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(64), oc_block_0 * T.int64(32) + oc_block_1 * T.int64(8) + oc_block_2 * T.int64(2) + oc_block_3)
                            v_ic = T.axis.reduce(T.int64(64), ic_0 * T.int64(32) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                            T.reads(data_pad[v_n, v_ic // T.int64(32), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(32)], p1[v_oc_chunk, v_ic // T.int64(32), v_kh, v_kw, v_ic % T.int64(32), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            with T.init():
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(32), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(32)] * p1[v_oc_chunk, v_ic // T.int64(32), v_kh, v_kw, v_ic % T.int64(32), v_oc_block]
                for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(2), T.int64(112), T.int64(112), T.int64(32)):
                    with T.block("T_relu"):
                        v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                        v_ax4 = T.axis.spatial(T.int64(64), oc_block_0 * T.int64(32) + ax4)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 2])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 7, 16, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 2, 56, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[2, 4, 4, 2])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[2, 32])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=7)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
2024-04-28 07:29:34 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-28 07:29:34 [INFO] [evolutionary_search.cc:715] Picked top 0 candidate(s) from database
2024-04-28 07:29:40 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x6741138)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x30bcd18)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x38311e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x32ad8b8)]: 0 failure(s)
2024-04-28 07:29:40 [INFO] [evolutionary_search.cc:723] Sampled 512 candidate(s)
2024-04-28 07:29:47 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x6741138)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x30bcd18)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x38311e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x32ad8b8)]: 0 failure(s)
2024-04-28 07:29:53 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x6741138)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x30bcd18)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x38311e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x32ad8b8)]: 0 failure(s)
2024-04-28 07:29:59 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x6741138)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x30bcd18)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x38311e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x32ad8b8)]: 0 failure(s)
2024-04-28 07:30:06 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x6741138)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x30bcd18)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x38311e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x32ad8b8)]: 0 failure(s)
2024-04-28 07:30:07 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	1.0000  0.9969  0.9969  0.9967  0.9955  0.9953  0.9942  0.9934  0.9925  0.9918  0.9914  0.9904  0.9898  0.9897  0.9889  0.9887
[17 : 32]:	0.9881  0.9879  0.9869  0.9863  0.9861  0.9860  0.9845  0.9842  0.9840  0.9834  0.9833  0.9833  0.9831  0.9827  0.9825  0.9824
[33 : 48]:	0.9824  0.9821  0.9819  0.9817  0.9816  0.9814  0.9791  0.9788  0.9786  0.9786  0.9773  0.9766  0.9762  0.9755  0.9754  0.9746
[49 : 64]:	0.9733  0.9729  0.9725  0.9719  0.9719  0.9708  0.9698  0.9698  0.9695  0.9690  0.9687  0.9685  0.9685  0.9679  0.9674  0.9673
2024-04-28 07:30:07 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-28 07:30:07 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-28 08:27:07 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #1: GFLOPs: 39.3047. Time: 47141.9410 us. Best GFLOPs: 39.3047
2024-04-28 08:27:07 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #2: GFLOPs: 41.3308. Time: 44830.9477 us. Best GFLOPs: 41.3308
2024-04-28 08:27:07 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #3: GFLOPs: 88.4147. Time: 20956.9038 us. Best GFLOPs: 88.4147
2024-04-28 08:27:07 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #4: GFLOPs: 228.2658. Time: 8117.2871 us. Best GFLOPs: 228.2658
2024-04-28 08:27:07 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #5: GFLOPs: 51.8560. Time: 35731.6370 us. Best GFLOPs: 228.2658
2024-04-28 08:27:07 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #6: GFLOPs: 39.4727. Time: 46941.2540 us. Best GFLOPs: 228.2658
2024-04-28 08:27:07 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #7: GFLOPs: 27.2722. Time: 67940.9200 us. Best GFLOPs: 228.2658
2024-04-28 08:27:07 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #8: GFLOPs: 39.4066. Time: 47020.0653 us. Best GFLOPs: 228.2658
2024-04-28 08:27:07 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #9: GFLOPs: 473.1465. Time: 3916.1219 us. Best GFLOPs: 473.1465
2024-04-28 08:27:07 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #10: GFLOPs: 26.9741. Time: 68691.7293 us. Best GFLOPs: 473.1465
2024-04-28 08:27:07 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #11: GFLOPs: 40.1928. Time: 46100.3360 us. Best GFLOPs: 473.1465
2024-04-28 08:27:07 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #12: GFLOPs: 76.4995. Time: 24221.0684 us. Best GFLOPs: 473.1465
2024-04-28 08:27:07 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #13: GFLOPs: 452.5515. Time: 4094.3391 us. Best GFLOPs: 473.1465
2024-04-28 08:27:07 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #14: GFLOPs: 7.2373. Time: 256020.0243 us. Best GFLOPs: 473.1465
2024-04-28 08:27:07 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #15: GFLOPs: 10.5288. Time: 175984.7223 us. Best GFLOPs: 473.1465
2024-04-28 08:27:07 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #16: GFLOPs: 6.6556. Time: 278398.2407 us. Best GFLOPs: 473.1465
2024-04-28 08:27:07 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #17: GFLOPs: 26.6091. Time: 69633.9923 us. Best GFLOPs: 473.1465
2024-04-28 08:27:07 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #18: GFLOPs: 6.5933. Time: 281027.6660 us. Best GFLOPs: 473.1465
2024-04-28 08:27:07 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #19: GFLOPs: 75.4274. Time: 24565.3382 us. Best GFLOPs: 473.1465
2024-04-28 08:27:07 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #20: GFLOPs: 3.7849. Time: 489548.5937 us. Best GFLOPs: 473.1465
2024-04-28 08:27:07 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #21: GFLOPs: 68.0527. Time: 27227.4368 us. Best GFLOPs: 473.1465
2024-04-28 08:27:07 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #22: GFLOPs: 109.7349. Time: 16885.2300 us. Best GFLOPs: 473.1465
2024-04-28 08:27:07 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #23: GFLOPs: 5.3750. Time: 344728.5797 us. Best GFLOPs: 473.1465
2024-04-28 08:27:07 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #24: GFLOPs: 124.4883. Time: 14884.1188 us. Best GFLOPs: 473.1465
2024-04-28 08:27:07 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #25: GFLOPs: 24.0561. Time: 77024.2203 us. Best GFLOPs: 473.1465
2024-04-28 08:27:07 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #26: GFLOPs: 12.5587. Time: 147538.6443 us. Best GFLOPs: 473.1465
2024-04-28 08:27:07 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #27: GFLOPs: 86.4666. Time: 21429.0862 us. Best GFLOPs: 473.1465
2024-04-28 08:27:07 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #28: GFLOPs: 8.1710. Time: 226763.9457 us. Best GFLOPs: 473.1465
2024-04-28 08:27:07 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #29: GFLOPs: 131.4285. Time: 14098.1546 us. Best GFLOPs: 473.1465
2024-04-28 08:27:07 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #30: GFLOPs: 104.5752. Time: 17718.3375 us. Best GFLOPs: 473.1465
2024-04-28 08:27:07 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #31: GFLOPs: 9.4620. Time: 195824.6747 us. Best GFLOPs: 473.1465
2024-04-28 08:27:07 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #32: GFLOPs: 92.2626. Time: 20082.8928 us. Best GFLOPs: 473.1465
2024-04-28 08:27:07 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #33: GFLOPs: 143.7467. Time: 12890.0326 us. Best GFLOPs: 473.1465
2024-04-28 08:27:07 [INFO] [task_scheduler.cc:121] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #34: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(112), T.int64(112), T.int64(32)), "float32"), p1: T.Buffer((T.int64(2), T.int64(2), T.int64(3), T.int64(3), T.int64(32), T.int64(64)), "float32"), p2: T.Buffer((T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(64)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(2), T.int64(112), T.int64(112), T.int64(64)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(114), T.int64(114), T.int64(32)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(112), T.int64(112), T.int64(64)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused in T.parallel(T.int64(448), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(8), T.int64(14), T.int64(8), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(1)):
                with T.block("conv2d_NCHWc_init"):
                    v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                    v_oc_chunk = T.axis.spatial(T.int64(2), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(56) // T.int64(28) + oc_chunk_2_init + oc_chunk_3_init)
                    v_oh = T.axis.spatial(T.int64(112), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(224) * T.int64(56) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(28) // T.int64(4) * T.int64(8) + oh_2_init + oh_3_init)
                    v_ow = T.axis.spatial(T.int64(112), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(4) // T.int64(2) * T.int64(56) + ow_2_init * T.int64(4) + ow_3_init)
                    v_oc_block = T.axis.spatial(T.int64(64), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(224) // T.int64(56) * T.int64(16) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(2) * T.int64(8) + oc_block_2_init + oc_block_3_init)
                    T.reads()
                    T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                    T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                    conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
            for ic_0 in range(T.int64(64)):
                for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(10), T.int64(58), T.int64(1)):
                    with T.block("data_pad"):
                        v_i0 = T.axis.spatial(T.int64(1), ax0)
                        v_i1 = T.axis.spatial(T.int64(2), ic_0 // T.int64(32) + ax1)
                        v_i2 = T.axis.spatial(T.int64(114), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(224) * T.int64(56) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(28) // T.int64(4) * T.int64(8) + ax2)
                        v_i3 = T.axis.spatial(T.int64(114), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(4) // T.int64(2) * T.int64(56) + ax3)
                        v_i4 = T.axis.spatial(T.int64(32), ic_0 % T.int64(32) + ax4)
                        T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                        T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                        data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(113) and T.int64(1) <= v_i3 and v_i3 < T.int64(113), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                for kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(8), T.int64(14), T.int64(8), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(2), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(56) // T.int64(28) + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(112), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(224) * T.int64(56) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(28) // T.int64(4) * T.int64(8) + oh_2 + oh_3)
                        v_ow = T.axis.spatial(T.int64(112), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(4) // T.int64(2) * T.int64(56) + ow_2 * T.int64(4) + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(64), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(224) // T.int64(56) * T.int64(16) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(2) * T.int64(8) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(64), ic_0 + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(32), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(32)], p1[v_oc_chunk, v_ic // T.int64(32), v_kh, v_kw, v_ic % T.int64(32), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(32), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(32)] * p1[v_oc_chunk, v_ic // T.int64(32), v_kh, v_kw, v_ic % T.int64(32), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(8), T.int64(56)):
                for ax4_fused in T.vectorized(T.int64(8)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(2), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(56) // T.int64(28) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(112), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(224) * T.int64(56) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(28) // T.int64(4) * T.int64(8) + ax2)
                        v_ax3 = T.axis.spatial(T.int64(112), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(4) // T.int64(2) * T.int64(56) + ax3)
                        v_ax4 = T.axis.spatial(T.int64(64), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(224) // T.int64(56) * T.int64(16) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(2) * T.int64(8) + ax4_fused)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 2, 1, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 7, 8, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 2, 14, 4])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[4, 2, 8, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[64, 1])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=10)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86 = sch.get_loops(block=b68)
l87 = sch.fuse(l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, preserve_unit_iters=True)
sch.parallel(loop=l87)
l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b69)
l105 = sch.fuse(l88, preserve_unit_iters=True)
sch.parallel(loop=l105)
sch.annotate(block_or_loop=l105, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l105, ann_key="pragma_unroll_explicit", ann_val=1)
l106, l107, l108, l109, l110, l111 = sch.get_loops(block=b70)
l112 = sch.fuse(l111, preserve_unit_iters=True)
sch.vectorize(loop=l112)
b113 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130 = sch.get_loops(block=b113)
b131 = sch.decompose_reduction(block=b113, loop=l115)
2024-04-28 08:27:07 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #35: GFLOPs: 12.3862. Time: 149593.8897 us. Best GFLOPs: 473.1465
2024-04-28 08:27:07 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #36: GFLOPs: 26.4137. Time: 70149.1680 us. Best GFLOPs: 473.1465
2024-04-28 08:27:07 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #37: GFLOPs: 2.5825. Time: 717494.0630 us. Best GFLOPs: 473.1465
2024-04-28 08:27:07 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #38: GFLOPs: 5.9924. Time: 309209.1993 us. Best GFLOPs: 473.1465
2024-04-28 08:27:07 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #39: GFLOPs: 45.0975. Time: 41086.5027 us. Best GFLOPs: 473.1465
2024-04-28 08:27:07 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #40: GFLOPs: 129.3119. Time: 14328.9163 us. Best GFLOPs: 473.1465
2024-04-28 08:27:07 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #41: GFLOPs: 40.1020. Time: 46204.6980 us. Best GFLOPs: 473.1465
2024-04-28 08:27:07 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #42: GFLOPs: 20.8272. Time: 88965.4093 us. Best GFLOPs: 473.1465
2024-04-28 08:27:07 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #43: GFLOPs: 183.0434. Time: 10122.7304 us. Best GFLOPs: 473.1465
2024-04-28 08:27:07 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #44: GFLOPs: 81.1468. Time: 22833.9182 us. Best GFLOPs: 473.1465
2024-04-28 08:27:07 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #45: GFLOPs: 54.2904. Time: 34129.3927 us. Best GFLOPs: 473.1465
2024-04-28 08:27:07 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #46: GFLOPs: 83.2667. Time: 22252.5762 us. Best GFLOPs: 473.1465
2024-04-28 08:27:07 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #47: GFLOPs: 20.2487. Time: 91507.2267 us. Best GFLOPs: 473.1465
2024-04-28 08:27:07 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #48: GFLOPs: 2.1004. Time: 882179.0800 us. Best GFLOPs: 473.1465
2024-04-28 08:27:07 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #49: GFLOPs: 11.5550. Time: 160355.3190 us. Best GFLOPs: 473.1465
2024-04-28 08:27:07 [INFO] [task_scheduler.cc:121] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #50: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(112), T.int64(112), T.int64(32)), "float32"), p1: T.Buffer((T.int64(2), T.int64(2), T.int64(3), T.int64(3), T.int64(32), T.int64(64)), "float32"), p2: T.Buffer((T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(64)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(2), T.int64(112), T.int64(112), T.int64(64)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(114), T.int64(114), T.int64(32)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(112), T.int64(112), T.int64(64)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused in T.parallel(T.int64(112), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(4), T.int64(4), T.int64(1), T.int64(1), T.int64(2), T.int64(28)):
                for oc_block_3_fused_init in T.vectorized(T.int64(8)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(2), oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(112), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(56) * T.int64(56) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(28) * T.int64(2) + oh_2_init * T.int64(2) + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(112), ow_2_init * T.int64(28) + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(64), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(56) // T.int64(28) * T.int64(32) + oc_block_2_init * T.int64(8) + oc_block_3_fused_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
            for ic_0, kh_0, kw_0 in T.grid(T.int64(64), T.int64(3), T.int64(3)):
                for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(2), T.int64(112), T.int64(1)):
                    with T.block("data_pad"):
                        v_i0 = T.axis.spatial(T.int64(1), ax0)
                        v_i1 = T.axis.spatial(T.int64(2), ic_0 // T.int64(32) + ax1)
                        v_i2 = T.axis.spatial(T.int64(114), kh_0 + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(56) * T.int64(56) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(28) * T.int64(2) + ax2)
                        v_i3 = T.axis.spatial(T.int64(114), kw_0 + ax3)
                        v_i4 = T.axis.spatial(T.int64(32), ic_0 % T.int64(32) + ax4)
                        T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                        T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                        data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(113) and T.int64(1) <= v_i3 and v_i3 < T.int64(113), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                for n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(4), T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(28)):
                    for oc_block_3_fused in T.vectorized(T.int64(8)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(2), oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(112), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(56) * T.int64(56) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(28) * T.int64(2) + oh_2 * T.int64(2) + oh_3)
                            v_ow = T.axis.spatial(T.int64(112), ow_2 * T.int64(28) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(64), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(56) // T.int64(28) * T.int64(32) + oc_block_2 * T.int64(8) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(64), ic_0 + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(32), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(32)], p1[v_oc_chunk, v_ic // T.int64(32), v_kh, v_kw, v_ic % T.int64(32), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(32), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(32)] * p1[v_oc_chunk, v_ic // T.int64(32), v_kh, v_kw, v_ic % T.int64(32), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(2), T.int64(2), T.int64(112)):
                for ax4_fused in T.vectorized(T.int64(32)):
                    with T.block("T_relu"):
                        v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                        v_ax2 = T.axis.spatial(T.int64(112), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(56) * T.int64(56) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(28) * T.int64(2) + ax2)
                        v_ax3 = T.axis.spatial(T.int64(112), ax3)
                        v_ax4 = T.axis.spatial(T.int64(64), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(56) // T.int64(28) * T.int64(32) + ax4_fused)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 2, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 28, 1, 2])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 4, 28])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[2, 1, 4, 8])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[64, 1])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=12)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88 = sch.get_loops(block=b68)
l89 = sch.fuse(l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, preserve_unit_iters=True)
sch.parallel(loop=l89)
l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106 = sch.get_loops(block=b69)
l107 = sch.fuse(l90, preserve_unit_iters=True)
sch.parallel(loop=l107)
l108 = sch.fuse(l106, preserve_unit_iters=True)
sch.vectorize(loop=l108)
sch.annotate(block_or_loop=l107, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l107, ann_key="pragma_unroll_explicit", ann_val=1)
l109, l110, l111, l112, l113, l114 = sch.get_loops(block=b70)
l115 = sch.fuse(l114, preserve_unit_iters=True)
sch.vectorize(loop=l115)
b116 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133 = sch.get_loops(block=b116)
b134 = sch.decompose_reduction(block=b116, loop=l118)
2024-04-28 08:27:07 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #51: GFLOPs: 20.8318. Time: 88945.8060 us. Best GFLOPs: 473.1465
2024-04-28 08:27:07 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #52: GFLOPs: 2.7249. Time: 679976.7823 us. Best GFLOPs: 473.1465
2024-04-28 08:27:07 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #53: GFLOPs: 103.9832. Time: 17819.2250 us. Best GFLOPs: 473.1465
2024-04-28 08:27:07 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #54: GFLOPs: 110.4070. Time: 16782.4420 us. Best GFLOPs: 473.1465
2024-04-28 08:27:07 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #55: GFLOPs: 26.4038. Time: 70175.4840 us. Best GFLOPs: 473.1465
2024-04-28 08:27:07 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #56: GFLOPs: 110.6042. Time: 16752.5287 us. Best GFLOPs: 473.1465
2024-04-28 08:27:07 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #57: GFLOPs: 309.5596. Time: 5985.5982 us. Best GFLOPs: 473.1465
2024-04-28 08:27:07 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #58: GFLOPs: 228.3211. Time: 8115.3219 us. Best GFLOPs: 473.1465
2024-04-28 08:27:07 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #59: GFLOPs: 100.9824. Time: 18348.7357 us. Best GFLOPs: 473.1465
2024-04-28 08:27:07 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #60: GFLOPs: 67.3674. Time: 27504.3933 us. Best GFLOPs: 473.1465
2024-04-28 08:27:07 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #61: GFLOPs: 55.3650. Time: 33466.9823 us. Best GFLOPs: 473.1465
2024-04-28 08:27:07 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #62: GFLOPs: 93.3435. Time: 19850.3400 us. Best GFLOPs: 473.1465
2024-04-28 08:27:07 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #63: GFLOPs: 103.0692. Time: 17977.2293 us. Best GFLOPs: 473.1465
2024-04-28 08:27:07 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #64: GFLOPs: 56.5224. Time: 32781.6845 us. Best GFLOPs: 473.1465
2024-04-28 08:58:27 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-28 08:58:28 [INFO] [evolutionary_search.cc:715] Picked top 62 candidate(s) from database
2024-04-28 08:58:33 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x6741138)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x30bcd18)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x38311e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x32ad8b8)]: 0 failure(s)
2024-04-28 08:58:33 [INFO] [evolutionary_search.cc:723] Sampled 450 candidate(s)
2024-04-28 08:58:46 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x6741138)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x30bcd18)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x38311e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x32ad8b8)]: 0 failure(s)
2024-04-28 08:58:59 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x6741138)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x30bcd18)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x38311e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x32ad8b8)]: 0 failure(s)
2024-04-28 08:59:13 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x6741138)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x30bcd18)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x38311e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x32ad8b8)]: 0 failure(s)
2024-04-28 08:59:26 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x6741138)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x30bcd18)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x38311e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x32ad8b8)]: 0 failure(s)
2024-04-28 08:59:34 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9869  0.9869  0.9869  0.9869  0.9869  0.9543  0.9398  0.9398  0.9398  0.9398  0.9371  0.9340  0.9340  0.9340  0.9340  0.9246
[17 : 32]:	0.9224  0.9195  0.9195  0.9195  0.9195  0.9157  0.9157  0.9118  0.9100  0.8974  0.8954  0.8930  0.8875  0.8787  0.8723  0.8723
[33 : 48]:	0.8616  0.8542  0.8542  0.8508  0.8480  0.8405  0.8405  0.8405  0.8405  0.8405  0.8353  0.8222  0.8217  0.8193  0.8122  0.8111
[49 : 64]:	0.8111  0.8047  0.8030  0.8018  0.7993  0.7957  0.7912  0.7895  0.7895  0.7895  0.7895  0.7895  0.7829  0.7814  0.7788  0.7788
2024-04-28 08:59:34 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-28 08:59:34 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-28 09:01:13 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #65: GFLOPs: 190.8693. Time: 9707.6878 us. Best GFLOPs: 473.1465
2024-04-28 09:01:13 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #66: GFLOPs: 424.4907. Time: 4364.9937 us. Best GFLOPs: 473.1465
2024-04-28 09:01:13 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #67: GFLOPs: 446.5606. Time: 4149.2673 us. Best GFLOPs: 473.1465
2024-04-28 09:01:13 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #68: GFLOPs: 407.4477. Time: 4547.5763 us. Best GFLOPs: 473.1465
2024-04-28 09:01:13 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #69: GFLOPs: 469.5807. Time: 3945.8593 us. Best GFLOPs: 473.1465
2024-04-28 09:01:13 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #70: GFLOPs: 142.3407. Time: 13017.3513 us. Best GFLOPs: 473.1465
2024-04-28 09:01:13 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #71: GFLOPs: 507.1817. Time: 3653.3242 us. Best GFLOPs: 507.1817
2024-04-28 09:01:13 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #72: GFLOPs: 509.3311. Time: 3637.9075 us. Best GFLOPs: 509.3311
2024-04-28 09:01:13 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #73: GFLOPs: 536.1709. Time: 3455.7999 us. Best GFLOPs: 536.1709
2024-04-28 09:01:13 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #74: GFLOPs: 543.0213. Time: 3412.2039 us. Best GFLOPs: 543.0213
2024-04-28 09:01:13 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #75: GFLOPs: 142.5080. Time: 13002.0685 us. Best GFLOPs: 543.0213
2024-04-28 09:01:13 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #76: GFLOPs: 397.3613. Time: 4663.0088 us. Best GFLOPs: 543.0213
2024-04-28 09:01:13 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #77: GFLOPs: 463.0600. Time: 4001.4242 us. Best GFLOPs: 543.0213
2024-04-28 09:01:13 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #78: GFLOPs: 473.6850. Time: 3911.6695 us. Best GFLOPs: 543.0213
2024-04-28 09:01:13 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #79: GFLOPs: 398.0365. Time: 4655.0991 us. Best GFLOPs: 543.0213
2024-04-28 09:01:13 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #80: GFLOPs: 399.3983. Time: 4639.2270 us. Best GFLOPs: 543.0213
2024-04-28 09:01:13 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #81: GFLOPs: 266.9389. Time: 6941.2872 us. Best GFLOPs: 543.0213
2024-04-28 09:01:13 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #82: GFLOPs: 480.0663. Time: 3859.6740 us. Best GFLOPs: 543.0213
2024-04-28 09:01:13 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #83: GFLOPs: 159.6652. Time: 11604.9039 us. Best GFLOPs: 543.0213
2024-04-28 09:01:13 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #84: GFLOPs: 476.5722. Time: 3887.9718 us. Best GFLOPs: 543.0213
2024-04-28 09:01:13 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #85: GFLOPs: 210.8015. Time: 8789.7819 us. Best GFLOPs: 543.0213
2024-04-28 09:01:13 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #86: GFLOPs: 256.9124. Time: 7212.1824 us. Best GFLOPs: 543.0213
2024-04-28 09:01:13 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #87: GFLOPs: 202.3413. Time: 9157.2982 us. Best GFLOPs: 543.0213
2024-04-28 09:01:13 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #88: GFLOPs: 412.8491. Time: 4488.0793 us. Best GFLOPs: 543.0213
2024-04-28 09:01:13 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #89: GFLOPs: 250.0236. Time: 7410.8991 us. Best GFLOPs: 543.0213
2024-04-28 09:01:13 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #90: GFLOPs: 390.1304. Time: 4749.4357 us. Best GFLOPs: 543.0213
2024-04-28 09:01:13 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #91: GFLOPs: 428.6737. Time: 4322.4001 us. Best GFLOPs: 543.0213
2024-04-28 09:01:13 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #92: GFLOPs: 151.3976. Time: 12238.6326 us. Best GFLOPs: 543.0213
2024-04-28 09:01:13 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #93: GFLOPs: 401.7266. Time: 4612.3392 us. Best GFLOPs: 543.0213
2024-04-28 09:01:13 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #94: GFLOPs: 728.8281. Time: 2542.2994 us. Best GFLOPs: 728.8281
2024-04-28 09:01:13 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #95: GFLOPs: 430.1647. Time: 4307.4182 us. Best GFLOPs: 728.8281
2024-04-28 09:01:13 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #96: GFLOPs: 429.0588. Time: 4318.5209 us. Best GFLOPs: 728.8281
2024-04-28 09:01:13 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #97: GFLOPs: 44.8805. Time: 41285.1520 us. Best GFLOPs: 728.8281
2024-04-28 09:01:13 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #98: GFLOPs: 326.8770. Time: 5668.4913 us. Best GFLOPs: 728.8281
2024-04-28 09:01:13 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #99: GFLOPs: 279.3777. Time: 6632.2366 us. Best GFLOPs: 728.8281
2024-04-28 09:01:13 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #100: GFLOPs: 232.8477. Time: 7957.5598 us. Best GFLOPs: 728.8281
2024-04-28 09:01:13 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #101: GFLOPs: 186.0712. Time: 9958.0140 us. Best GFLOPs: 728.8281
2024-04-28 09:01:13 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #102: GFLOPs: 424.7472. Time: 4362.3575 us. Best GFLOPs: 728.8281
2024-04-28 09:01:13 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #103: GFLOPs: 508.4555. Time: 3644.1719 us. Best GFLOPs: 728.8281
2024-04-28 09:01:13 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #104: GFLOPs: 385.6441. Time: 4804.6877 us. Best GFLOPs: 728.8281
2024-04-28 09:01:13 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #105: GFLOPs: 505.6393. Time: 3664.4686 us. Best GFLOPs: 728.8281
2024-04-28 09:01:13 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #106: GFLOPs: 444.1132. Time: 4172.1329 us. Best GFLOPs: 728.8281
2024-04-28 09:01:13 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #107: GFLOPs: 147.0038. Time: 12604.4276 us. Best GFLOPs: 728.8281
2024-04-28 09:01:13 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #108: GFLOPs: 366.0362. Time: 5062.0655 us. Best GFLOPs: 728.8281
2024-04-28 09:01:13 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #109: GFLOPs: 838.0063. Time: 2211.0804 us. Best GFLOPs: 838.0063
2024-04-28 09:01:13 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #110: GFLOPs: 430.4101. Time: 4304.9627 us. Best GFLOPs: 838.0063
2024-04-28 09:01:13 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #111: GFLOPs: 503.7316. Time: 3678.3467 us. Best GFLOPs: 838.0063
2024-04-28 09:01:13 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #112: GFLOPs: 419.4549. Time: 4417.3980 us. Best GFLOPs: 838.0063
2024-04-28 09:01:13 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #113: GFLOPs: 396.7992. Time: 4669.6147 us. Best GFLOPs: 838.0063
2024-04-28 09:01:13 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #114: GFLOPs: 45.8182. Time: 40440.2070 us. Best GFLOPs: 838.0063
2024-04-28 09:01:13 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #115: GFLOPs: 461.7894. Time: 4012.4337 us. Best GFLOPs: 838.0063
2024-04-28 09:01:13 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #116: GFLOPs: 269.9874. Time: 6862.9106 us. Best GFLOPs: 838.0063
2024-04-28 09:01:13 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #117: GFLOPs: 120.6908. Time: 15352.4454 us. Best GFLOPs: 838.0063
2024-04-28 09:01:13 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #118: GFLOPs: 269.5818. Time: 6873.2367 us. Best GFLOPs: 838.0063
2024-04-28 09:01:13 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #119: GFLOPs: 185.8436. Time: 9970.2060 us. Best GFLOPs: 838.0063
2024-04-28 09:01:13 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #120: GFLOPs: 312.7612. Time: 5924.3252 us. Best GFLOPs: 838.0063
2024-04-28 09:01:13 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #121: GFLOPs: 47.9656. Time: 38629.7253 us. Best GFLOPs: 838.0063
2024-04-28 09:01:13 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #122: GFLOPs: 49.4546. Time: 37466.6947 us. Best GFLOPs: 838.0063
2024-04-28 09:01:13 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #123: GFLOPs: 310.0015. Time: 5977.0662 us. Best GFLOPs: 838.0063
2024-04-28 09:01:13 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #124: GFLOPs: 307.5477. Time: 6024.7541 us. Best GFLOPs: 838.0063
2024-04-28 09:01:13 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #125: GFLOPs: 195.5071. Time: 9477.4038 us. Best GFLOPs: 838.0063
2024-04-28 09:01:13 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #126: GFLOPs: 116.6947. Time: 15878.1847 us. Best GFLOPs: 838.0063
2024-04-28 09:01:13 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #127: GFLOPs: 26.3470. Time: 70326.7453 us. Best GFLOPs: 838.0063
2024-04-28 09:01:13 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #128: GFLOPs: 747.1045. Time: 2480.1072 us. Best GFLOPs: 838.0063
2024-04-28 10:30:20 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-28 10:30:21 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-28 10:30:26 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x6741138)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x30bcd18)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x38311e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x32ad8b8)]: 0 failure(s)
2024-04-28 10:30:26 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-28 10:30:39 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x6741138)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x30bcd18)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x38311e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x32ad8b8)]: 0 failure(s)
2024-04-28 10:30:52 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x6741138)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x30bcd18)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x38311e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x32ad8b8)]: 0 failure(s)
2024-04-28 10:31:05 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x6741138)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x30bcd18)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x38311e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x32ad8b8)]: 0 failure(s)
2024-04-28 10:31:18 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x6741138)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x30bcd18)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x38311e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x32ad8b8)]: 0 failure(s)
2024-04-28 10:31:25 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9987  0.9987  0.9981  0.9981  0.9981  0.9185  0.9185  0.8671  0.8597  0.8498  0.8492  0.8376  0.8376  0.8205  0.8202  0.8200
[17 : 32]:	0.8186  0.8144  0.8144  0.8144  0.8138  0.8045  0.8036  0.7965  0.7965  0.7877  0.7852  0.7798  0.7796  0.7790  0.7747  0.7747
[33 : 48]:	0.7743  0.7730  0.7545  0.7486  0.7455  0.7353  0.7338  0.7336  0.7311  0.7311  0.7299  0.7265  0.7221  0.7161  0.7143  0.7142
[49 : 64]:	0.7142  0.7140  0.7140  0.7123  0.7122  0.7122  0.7024  0.7007  0.6990  0.6990  0.6981  0.6935  0.6921  0.6921  0.6920  0.6920
2024-04-28 10:31:25 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-28 10:31:25 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-28 10:33:14 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #129: GFLOPs: 799.4299. Time: 2317.7760 us. Best GFLOPs: 838.0063
2024-04-28 10:33:14 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #130: GFLOPs: 861.4202. Time: 2150.9819 us. Best GFLOPs: 861.4202
2024-04-28 10:33:14 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #131: GFLOPs: 371.1467. Time: 4992.3635 us. Best GFLOPs: 861.4202
2024-04-28 10:33:14 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #132: GFLOPs: 689.5025. Time: 2687.2991 us. Best GFLOPs: 861.4202
2024-04-28 10:33:14 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #133: GFLOPs: 693.9291. Time: 2670.1564 us. Best GFLOPs: 861.4202
2024-04-28 10:33:14 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #134: GFLOPs: 795.2764. Time: 2329.8809 us. Best GFLOPs: 861.4202
2024-04-28 10:33:14 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #135: GFLOPs: 641.3685. Time: 2888.9779 us. Best GFLOPs: 861.4202
2024-04-28 10:33:14 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #136: GFLOPs: 549.4268. Time: 3372.4226 us. Best GFLOPs: 861.4202
2024-04-28 10:33:14 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #137: GFLOPs: 610.8002. Time: 3033.5603 us. Best GFLOPs: 861.4202
2024-04-28 10:33:14 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #138: GFLOPs: 594.7963. Time: 3115.1832 us. Best GFLOPs: 861.4202
2024-04-28 10:33:14 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #139: GFLOPs: 618.7636. Time: 2994.5191 us. Best GFLOPs: 861.4202
2024-04-28 10:33:14 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #140: GFLOPs: 675.3210. Time: 2743.7312 us. Best GFLOPs: 861.4202
2024-04-28 10:33:14 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #141: GFLOPs: 648.7556. Time: 2856.0824 us. Best GFLOPs: 861.4202
2024-04-28 10:33:14 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #142: GFLOPs: 359.1302. Time: 5159.4083 us. Best GFLOPs: 861.4202
2024-04-28 10:33:14 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #143: GFLOPs: 624.2983. Time: 2967.9713 us. Best GFLOPs: 861.4202
2024-04-28 10:33:14 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #144: GFLOPs: 553.4658. Time: 3347.8118 us. Best GFLOPs: 861.4202
2024-04-28 10:33:14 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #145: GFLOPs: 819.8082. Time: 2260.1620 us. Best GFLOPs: 861.4202
2024-04-28 10:33:14 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #146: GFLOPs: 789.1756. Time: 2347.8922 us. Best GFLOPs: 861.4202
2024-04-28 10:33:14 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #147: GFLOPs: 687.8122. Time: 2693.9029 us. Best GFLOPs: 861.4202
2024-04-28 10:33:14 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #148: GFLOPs: 570.5719. Time: 3247.4425 us. Best GFLOPs: 861.4202
2024-04-28 10:33:14 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #149: GFLOPs: 620.6247. Time: 2985.5392 us. Best GFLOPs: 861.4202
2024-04-28 10:33:14 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #150: GFLOPs: 835.3322. Time: 2218.1585 us. Best GFLOPs: 861.4202
2024-04-28 10:33:14 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #151: GFLOPs: 279.7019. Time: 6624.5502 us. Best GFLOPs: 861.4202
2024-04-28 10:33:14 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #152: GFLOPs: 874.4627. Time: 2118.9004 us. Best GFLOPs: 874.4627
2024-04-28 10:33:14 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #153: GFLOPs: 844.2368. Time: 2194.7625 us. Best GFLOPs: 874.4627
2024-04-28 10:33:14 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #154: GFLOPs: 573.7048. Time: 3229.7084 us. Best GFLOPs: 874.4627
2024-04-28 10:33:14 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #155: GFLOPs: 511.5754. Time: 3621.9476 us. Best GFLOPs: 874.4627
2024-04-28 10:33:14 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #156: GFLOPs: 580.8773. Time: 3189.8292 us. Best GFLOPs: 874.4627
2024-04-28 10:33:14 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #157: GFLOPs: 696.1281. Time: 2661.7218 us. Best GFLOPs: 874.4627
2024-04-28 10:33:14 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #158: GFLOPs: 578.1619. Time: 3204.8104 us. Best GFLOPs: 874.4627
2024-04-28 10:33:14 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #159: GFLOPs: 539.6588. Time: 3433.4643 us. Best GFLOPs: 874.4627
2024-04-28 10:33:14 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #160: GFLOPs: 472.1607. Time: 3924.2982 us. Best GFLOPs: 874.4627
2024-04-28 10:33:14 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #161: GFLOPs: 271.1955. Time: 6832.3387 us. Best GFLOPs: 874.4627
2024-04-28 10:33:14 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #162: GFLOPs: 456.6553. Time: 4057.5449 us. Best GFLOPs: 874.4627
2024-04-28 10:33:14 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #163: GFLOPs: 832.4357. Time: 2225.8767 us. Best GFLOPs: 874.4627
2024-04-28 10:33:14 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #164: GFLOPs: 848.5441. Time: 2183.6218 us. Best GFLOPs: 874.4627
2024-04-28 10:33:14 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #165: GFLOPs: 569.1364. Time: 3255.6330 us. Best GFLOPs: 874.4627
2024-04-28 10:33:14 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #166: GFLOPs: 431.5539. Time: 4293.5525 us. Best GFLOPs: 874.4627
2024-04-28 10:33:14 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #167: GFLOPs: 809.4986. Time: 2288.9470 us. Best GFLOPs: 874.4627
2024-04-28 10:33:14 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #168: GFLOPs: 408.0990. Time: 4540.3187 us. Best GFLOPs: 874.4627
2024-04-28 10:33:14 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #169: GFLOPs: 813.7148. Time: 2277.0868 us. Best GFLOPs: 874.4627
2024-04-28 10:33:14 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #170: GFLOPs: 836.2394. Time: 2215.7522 us. Best GFLOPs: 874.4627
2024-04-28 10:33:14 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #171: GFLOPs: 713.2244. Time: 2597.9192 us. Best GFLOPs: 874.4627
2024-04-28 10:33:14 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #172: GFLOPs: 463.7102. Time: 3995.8129 us. Best GFLOPs: 874.4627
2024-04-28 10:33:14 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #173: GFLOPs: 278.5734. Time: 6651.3862 us. Best GFLOPs: 874.4627
2024-04-28 10:33:14 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #174: GFLOPs: 615.4110. Time: 3010.8323 us. Best GFLOPs: 874.4627
2024-04-28 10:33:14 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #175: GFLOPs: 564.3312. Time: 3283.3545 us. Best GFLOPs: 874.4627
2024-04-28 10:33:14 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #176: GFLOPs: 629.3475. Time: 2944.1594 us. Best GFLOPs: 874.4627
2024-04-28 10:33:14 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #177: GFLOPs: 585.8967. Time: 3162.5015 us. Best GFLOPs: 874.4627
2024-04-28 10:33:14 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #178: GFLOPs: 618.4405. Time: 2996.0832 us. Best GFLOPs: 874.4627
2024-04-28 10:33:14 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #179: GFLOPs: 585.9614. Time: 3162.1525 us. Best GFLOPs: 874.4627
2024-04-28 10:33:14 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #180: GFLOPs: 648.3884. Time: 2857.6996 us. Best GFLOPs: 874.4627
2024-04-28 10:33:14 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #181: GFLOPs: 782.2961. Time: 2368.5395 us. Best GFLOPs: 874.4627
2024-04-28 10:33:14 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #182: GFLOPs: 688.2018. Time: 2692.3780 us. Best GFLOPs: 874.4627
2024-04-28 10:33:14 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #183: GFLOPs: 539.3365. Time: 3435.5164 us. Best GFLOPs: 874.4627
2024-04-28 10:33:14 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #184: GFLOPs: 322.9935. Time: 5736.6458 us. Best GFLOPs: 874.4627
2024-04-28 10:33:14 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #185: GFLOPs: 883.8644. Time: 2096.3614 us. Best GFLOPs: 883.8644
2024-04-28 10:33:14 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #186: GFLOPs: 919.8291. Time: 2014.3952 us. Best GFLOPs: 919.8291
2024-04-28 10:33:14 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #187: GFLOPs: 447.7190. Time: 4138.5320 us. Best GFLOPs: 919.8291
2024-04-28 10:33:14 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #188: GFLOPs: 507.7110. Time: 3649.5156 us. Best GFLOPs: 919.8291
2024-04-28 10:33:14 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #189: GFLOPs: 498.9494. Time: 3713.6014 us. Best GFLOPs: 919.8291
2024-04-28 10:33:14 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #190: GFLOPs: 65.9529. Time: 28094.2913 us. Best GFLOPs: 919.8291
2024-04-28 10:33:14 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #191: GFLOPs: 46.6165. Time: 39747.7153 us. Best GFLOPs: 919.8291
2024-04-28 10:33:14 [INFO] [task_scheduler.cc:121] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #192: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(112), T.int64(112), T.int64(32)), "float32"), p1: T.Buffer((T.int64(2), T.int64(2), T.int64(3), T.int64(3), T.int64(32), T.int64(64)), "float32"), p2: T.Buffer((T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(64)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(2), T.int64(112), T.int64(112), T.int64(64)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(114), T.int64(114), T.int64(32)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(112), T.int64(112), T.int64(64)))
        for n_0_oc_chunk_0_oh_0_ow_0_fused_fused in T.parallel(T.int64(7), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(2), T.int64(114), T.int64(18)):
                for ax4_fused in T.vectorized(T.int64(32)):
                    with T.block("data_pad"):
                        v_i0, v_i1, v_i2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                        v_i3 = T.axis.spatial(T.int64(114), n_0_oc_chunk_0_oh_0_ow_0_fused_fused * T.int64(16) + ax3)
                        v_i4 = T.axis.spatial(T.int64(32), ax4_fused)
                        T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                        T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                        data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(113) and T.int64(1) <= v_i3 and v_i3 < T.int64(113), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oc_block_0, n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(8)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(1), T.int64(2), T.int64(2), T.int64(2), T.int64(1), T.int64(2), T.int64(56), T.int64(8)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(2), oc_chunk_1 * T.int64(2) + oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(112), oh_1 * T.int64(112) + oh_2_init * T.int64(56) + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(112), n_0_oc_chunk_0_oh_0_ow_0_fused_fused * T.int64(16) + ow_1 * T.int64(16) + ow_2_init * T.int64(8) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(64), oc_block_0 * T.int64(64) + oc_block_1 * T.int64(8) + oc_block_2_init * T.int64(4) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(4), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(2), T.int64(2), T.int64(16), T.int64(1), T.int64(3), T.int64(1), T.int64(2), T.int64(56), T.int64(8)):
                    for oc_block_3_fused in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(2), oc_chunk_1 * T.int64(2) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(112), oh_1 * T.int64(112) + oh_2 * T.int64(56) + oh_3)
                            v_ow = T.axis.spatial(T.int64(112), n_0_oc_chunk_0_oh_0_ow_0_fused_fused * T.int64(16) + ow_1 * T.int64(16) + ow_2 * T.int64(8) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(64), oc_block_0 * T.int64(64) + oc_block_1 * T.int64(8) + oc_block_2 * T.int64(4) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(64), ic_0 * T.int64(16) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(32), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(32)], p1[v_oc_chunk, v_ic // T.int64(32), v_kh, v_kw, v_ic % T.int64(32), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(32), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(32)] * p1[v_oc_chunk, v_ic // T.int64(32), v_kh, v_kw, v_ic % T.int64(32), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(2), T.int64(112), T.int64(16)):
                    for ax4_fused in T.vectorized(T.int64(8)):
                        with T.block("T_relu"):
                            v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                            v_ax3 = T.axis.spatial(T.int64(112), n_0_oc_chunk_0_oh_0_ow_0_fused_fused * T.int64(16) + ax3)
                            v_ax4 = T.axis.spatial(T.int64(64), oc_block_1 * T.int64(8) + ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 2])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 2, 56])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[7, 1, 2, 8])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 8, 2, 4])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[4, 16])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=3)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79 = sch.get_loops(block=b68)
l80 = sch.fuse(l71, l72, l73, l74, preserve_unit_iters=True)
sch.parallel(loop=l80)
l81 = sch.fuse(l79, preserve_unit_iters=True)
sch.vectorize(loop=l81)
l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b69)
l105 = sch.fuse(l82, preserve_unit_iters=True)
sch.parallel(loop=l105)
l106 = sch.fuse(l104, preserve_unit_iters=True)
sch.vectorize(loop=l106)
sch.annotate(block_or_loop=l105, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l105, ann_key="pragma_unroll_explicit", ann_val=1)
l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117, l118 = sch.get_loops(block=b70)
l119 = sch.fuse(l118, preserve_unit_iters=True)
sch.vectorize(loop=l119)
b120 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141, l142, l143 = sch.get_loops(block=b120)
b144 = sch.decompose_reduction(block=b120, loop=l128)
2024-04-28 10:47:21 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-28 10:47:22 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-28 10:47:27 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x6741138)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x30bcd18)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x38311e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x32ad8b8)]: 0 failure(s)
2024-04-28 10:47:27 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-28 10:47:39 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x6741138)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x30bcd18)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x38311e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x32ad8b8)]: 0 failure(s)
2024-04-28 10:47:52 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x6741138)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x30bcd18)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x38311e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x32ad8b8)]: 0 failure(s)
2024-04-28 10:48:03 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x6741138)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x30bcd18)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x38311e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x32ad8b8)]: 0 failure(s)
2024-04-28 10:48:15 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x6741138)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x30bcd18)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x38311e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x32ad8b8)]: 0 failure(s)
2024-04-28 10:48:22 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9910  0.9581  0.9520  0.9520  0.9441  0.9441  0.9279  0.9150  0.9128  0.9128  0.9009  0.8987  0.8959  0.8959  0.8848  0.8848
[17 : 32]:	0.8787  0.8780  0.8776  0.8734  0.8731  0.8731  0.8731  0.8666  0.8625  0.8625  0.8538  0.8509  0.8507  0.8503  0.8444  0.8439
[33 : 48]:	0.8428  0.8422  0.8378  0.8368  0.8357  0.8357  0.8348  0.8345  0.8259  0.8248  0.8244  0.8147  0.8146  0.8145  0.8086  0.8064
[49 : 64]:	0.8064  0.8064  0.8062  0.8034  0.8030  0.7998  0.7988  0.7973  0.7969  0.7958  0.7946  0.7922  0.7922  0.7897  0.7876  0.7856
2024-04-28 10:48:22 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-28 10:48:22 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-28 10:50:02 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #193: GFLOPs: 716.2568. Time: 2586.9206 us. Best GFLOPs: 919.8291
2024-04-28 10:50:02 [INFO] [task_scheduler.cc:121] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #194: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(112), T.int64(112), T.int64(32)), "float32"), p1: T.Buffer((T.int64(2), T.int64(2), T.int64(3), T.int64(3), T.int64(32), T.int64(64)), "float32"), p2: T.Buffer((T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(64)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(2), T.int64(112), T.int64(112), T.int64(64)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(114), T.int64(114), T.int64(32)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(112), T.int64(112), T.int64(64)))
        for i0_i1_i2_i3_fused in T.parallel(T.int64(25992)):
            for i4_fused in T.vectorized(T.int64(32)):
                with T.block("data_pad"):
                    v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_i1 = T.axis.spatial(T.int64(2), i0_i1_i2_i3_fused // T.int64(12996))
                    v_i2 = T.axis.spatial(T.int64(114), i0_i1_i2_i3_fused % T.int64(12996) // T.int64(114))
                    v_i3 = T.axis.spatial(T.int64(114), i0_i1_i2_i3_fused % T.int64(114))
                    v_i4 = T.axis.spatial(T.int64(32), i4_fused)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(113) and T.int64(1) <= v_i3 and v_i3 < T.int64(113), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused in T.parallel(T.int64(112), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(7), T.int64(4), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(64), T.int64(1), T.int64(1), T.int64(2), T.int64(2), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(2), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused // T.int64(56) + oc_chunk_1 + oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(112), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused % T.int64(56) // T.int64(7) * T.int64(14) + oh_1 * T.int64(2) + oh_2_init * T.int64(2) + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(112), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused % T.int64(7) * T.int64(16) + ow_1 * T.int64(4) + ow_2_init * T.int64(2) + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(64), oc_block_1 * T.int64(64) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(32), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(64), T.int64(2), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(2), T.int64(2), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(2), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused // T.int64(56) + oc_chunk_1 + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(112), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused % T.int64(56) // T.int64(7) * T.int64(14) + oh_1 * T.int64(2) + oh_2 * T.int64(2) + oh_3)
                        v_ow = T.axis.spatial(T.int64(112), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused % T.int64(7) * T.int64(16) + ow_1 * T.int64(4) + ow_2 * T.int64(2) + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(64), oc_block_1 * T.int64(64) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(64), ic_0 * T.int64(2) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(32), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(32)], p1[v_oc_chunk, v_ic // T.int64(32), v_kh, v_kw, v_ic % T.int64(32), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(32), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(32)] * p1[v_oc_chunk, v_ic // T.int64(32), v_kh, v_kw, v_ic % T.int64(32), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(14), T.int64(16)):
                for ax4_fused in T.vectorized(T.int64(64)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(2), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused // T.int64(56) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(112), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused % T.int64(56) // T.int64(7) * T.int64(14) + ax2)
                        v_ax3 = T.axis.spatial(T.int64(112), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused % T.int64(7) * T.int64(16) + ax3)
                        v_ax4 = T.axis.spatial(T.int64(64), ax4_fused)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[2, 1, 1, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[8, 7, 1, 2])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[7, 4, 2, 2])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 64, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[32, 2])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=-1)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75 = sch.get_loops(block=b68)
l76 = sch.fuse(l71, l72, l73, l74, preserve_unit_iters=True)
sch.parallel(loop=l76)
l77 = sch.fuse(l75, preserve_unit_iters=True)
sch.vectorize(loop=l77)
l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l78, l79, l80, l81, l82, preserve_unit_iters=True)
sch.parallel(loop=l104)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109, l110 = sch.get_loops(block=b70)
l111 = sch.fuse(l110, preserve_unit_iters=True)
sch.vectorize(loop=l111)
b112 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l113, l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134 = sch.get_loops(block=b112)
b135 = sch.decompose_reduction(block=b112, loop=l119)
2024-04-28 10:50:02 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #195: GFLOPs: 253.1775. Time: 7318.5792 us. Best GFLOPs: 919.8291
2024-04-28 10:50:02 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #196: GFLOPs: 255.5846. Time: 7249.6509 us. Best GFLOPs: 919.8291
2024-04-28 10:50:02 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #197: GFLOPs: 582.4421. Time: 3181.2595 us. Best GFLOPs: 919.8291
2024-04-28 10:50:03 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #198: GFLOPs: 694.9545. Time: 2666.2168 us. Best GFLOPs: 919.8291
2024-04-28 10:50:03 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #199: GFLOPs: 650.4081. Time: 2848.8256 us. Best GFLOPs: 919.8291
2024-04-28 10:50:03 [INFO] [task_scheduler.cc:121] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #200: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(112), T.int64(112), T.int64(32)), "float32"), p1: T.Buffer((T.int64(2), T.int64(2), T.int64(3), T.int64(3), T.int64(32), T.int64(64)), "float32"), p2: T.Buffer((T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(64)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(2), T.int64(112), T.int64(112), T.int64(64)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(114), T.int64(114), T.int64(32)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(112), T.int64(112), T.int64(64)))
        for i0_i1_i2_i3_fused in T.parallel(T.int64(25992)):
            for i4_fused in T.vectorized(T.int64(32)):
                with T.block("data_pad"):
                    v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_i1 = T.axis.spatial(T.int64(2), i0_i1_i2_i3_fused // T.int64(12996))
                    v_i2 = T.axis.spatial(T.int64(114), i0_i1_i2_i3_fused % T.int64(12996) // T.int64(114))
                    v_i3 = T.axis.spatial(T.int64(114), i0_i1_i2_i3_fused % T.int64(114))
                    v_i4 = T.axis.spatial(T.int64(32), i4_fused)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(113) and T.int64(1) <= v_i3 and v_i3 < T.int64(113), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused in T.parallel(T.int64(112), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(7), T.int64(4), T.int64(2)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(32), T.int64(1), T.int64(1), T.int64(2), T.int64(2), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(2), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused // T.int64(56) + oc_chunk_1 + oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(112), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused % T.int64(56) // T.int64(7) * T.int64(14) + oh_1 * T.int64(2) + oh_2_init * T.int64(2) + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(112), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused % T.int64(7) * T.int64(16) + ow_1 * T.int64(4) + ow_2_init * T.int64(2) + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(64), oc_block_1 * T.int64(32) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(32), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(32), T.int64(2), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(2), T.int64(2), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(2), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused // T.int64(56) + oc_chunk_1 + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(112), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused % T.int64(56) // T.int64(7) * T.int64(14) + oh_1 * T.int64(2) + oh_2 * T.int64(2) + oh_3)
                        v_ow = T.axis.spatial(T.int64(112), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused % T.int64(7) * T.int64(16) + ow_1 * T.int64(4) + ow_2 * T.int64(2) + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(64), oc_block_1 * T.int64(32) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(64), ic_0 * T.int64(2) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(32), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(32)], p1[v_oc_chunk, v_ic // T.int64(32), v_kh, v_kw, v_ic % T.int64(32), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(32), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(32)] * p1[v_oc_chunk, v_ic // T.int64(32), v_kh, v_kw, v_ic % T.int64(32), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(14), T.int64(16)):
                for ax4_fused in T.vectorized(T.int64(64)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(2), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused // T.int64(56) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(112), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused % T.int64(56) // T.int64(7) * T.int64(14) + ax2)
                        v_ax3 = T.axis.spatial(T.int64(112), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused % T.int64(7) * T.int64(16) + ax3)
                        v_ax4 = T.axis.spatial(T.int64(64), ax4_fused)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[2, 1, 1, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[8, 7, 1, 2])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[7, 4, 2, 2])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 2, 32, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[32, 2])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=-1)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75 = sch.get_loops(block=b68)
l76 = sch.fuse(l71, l72, l73, l74, preserve_unit_iters=True)
sch.parallel(loop=l76)
l77 = sch.fuse(l75, preserve_unit_iters=True)
sch.vectorize(loop=l77)
l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l78, l79, l80, l81, l82, preserve_unit_iters=True)
sch.parallel(loop=l104)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109, l110 = sch.get_loops(block=b70)
l111 = sch.fuse(l110, preserve_unit_iters=True)
sch.vectorize(loop=l111)
b112 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l113, l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134 = sch.get_loops(block=b112)
b135 = sch.decompose_reduction(block=b112, loop=l119)
2024-04-28 10:50:03 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #201: GFLOPs: 1156.2749. Time: 1602.4731 us. Best GFLOPs: 1156.2749
2024-04-28 10:50:03 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #202: GFLOPs: 1287.6474. Time: 1438.9804 us. Best GFLOPs: 1287.6474
2024-04-28 10:50:03 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #203: GFLOPs: 684.7153. Time: 2706.0873 us. Best GFLOPs: 1287.6474
2024-04-28 10:50:03 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #204: GFLOPs: 1028.5799. Time: 1801.4150 us. Best GFLOPs: 1287.6474
2024-04-28 10:50:03 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #205: GFLOPs: 469.4858. Time: 3946.6570 us. Best GFLOPs: 1287.6474
2024-04-28 10:50:03 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #206: GFLOPs: 502.9950. Time: 3683.7329 us. Best GFLOPs: 1287.6474
2024-04-28 10:50:03 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #207: GFLOPs: 691.3745. Time: 2680.0226 us. Best GFLOPs: 1287.6474
2024-04-28 10:50:03 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #208: GFLOPs: 722.7631. Time: 2563.6332 us. Best GFLOPs: 1287.6474
2024-04-28 10:50:03 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #209: GFLOPs: 811.7977. Time: 2282.4644 us. Best GFLOPs: 1287.6474
2024-04-28 10:50:03 [INFO] [task_scheduler.cc:121] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #210: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(112), T.int64(112), T.int64(32)), "float32"), p1: T.Buffer((T.int64(2), T.int64(2), T.int64(3), T.int64(3), T.int64(32), T.int64(64)), "float32"), p2: T.Buffer((T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(64)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(2), T.int64(112), T.int64(112), T.int64(64)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(114), T.int64(114), T.int64(32)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(112), T.int64(112), T.int64(64)))
        for i0_i1_i2_i3_fused in T.parallel(T.int64(25992)):
            for i4_fused in T.vectorized(T.int64(32)):
                with T.block("data_pad"):
                    v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_i1 = T.axis.spatial(T.int64(2), i0_i1_i2_i3_fused // T.int64(12996))
                    v_i2 = T.axis.spatial(T.int64(114), i0_i1_i2_i3_fused % T.int64(12996) // T.int64(114))
                    v_i3 = T.axis.spatial(T.int64(114), i0_i1_i2_i3_fused % T.int64(114))
                    v_i4 = T.axis.spatial(T.int64(32), i4_fused)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(113) and T.int64(1) <= v_i3 and v_i3 < T.int64(113), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused in T.parallel(T.int64(112), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(7), T.int64(4), T.int64(2)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(32), T.int64(1), T.int64(1), T.int64(2), T.int64(2), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(2), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused // T.int64(56) + oc_chunk_1 + oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(112), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused % T.int64(56) // T.int64(7) * T.int64(14) + oh_1 * T.int64(2) + oh_2_init * T.int64(2) + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(112), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused % T.int64(7) * T.int64(16) + ow_1 * T.int64(4) + ow_2_init * T.int64(2) + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(64), oc_block_1 * T.int64(32) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(64), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(32), T.int64(1), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(2), T.int64(2), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(2), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused // T.int64(56) + oc_chunk_1 + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(112), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused % T.int64(56) // T.int64(7) * T.int64(14) + oh_1 * T.int64(2) + oh_2 * T.int64(2) + oh_3)
                        v_ow = T.axis.spatial(T.int64(112), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused % T.int64(7) * T.int64(16) + ow_1 * T.int64(4) + ow_2 * T.int64(2) + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(64), oc_block_1 * T.int64(32) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(64), ic_0 + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(32), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(32)], p1[v_oc_chunk, v_ic // T.int64(32), v_kh, v_kw, v_ic % T.int64(32), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(32), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(32)] * p1[v_oc_chunk, v_ic // T.int64(32), v_kh, v_kw, v_ic % T.int64(32), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(14), T.int64(16)):
                for ax4_fused in T.vectorized(T.int64(64)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(2), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused // T.int64(56) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(112), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused % T.int64(56) // T.int64(7) * T.int64(14) + ax2)
                        v_ax3 = T.axis.spatial(T.int64(112), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused % T.int64(7) * T.int64(16) + ax3)
                        v_ax4 = T.axis.spatial(T.int64(64), ax4_fused)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[2, 1, 1, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[8, 7, 1, 2])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[7, 4, 2, 2])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 2, 32, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[64, 1])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=-1)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75 = sch.get_loops(block=b68)
l76 = sch.fuse(l71, l72, l73, l74, preserve_unit_iters=True)
sch.parallel(loop=l76)
l77 = sch.fuse(l75, preserve_unit_iters=True)
sch.vectorize(loop=l77)
l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l78, l79, l80, l81, l82, preserve_unit_iters=True)
sch.parallel(loop=l104)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109, l110 = sch.get_loops(block=b70)
l111 = sch.fuse(l110, preserve_unit_iters=True)
sch.vectorize(loop=l111)
b112 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l113, l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134 = sch.get_loops(block=b112)
b135 = sch.decompose_reduction(block=b112, loop=l119)
2024-04-28 10:50:03 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #211: GFLOPs: 1054.5259. Time: 1757.0922 us. Best GFLOPs: 1287.6474
2024-04-28 10:50:03 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #212: GFLOPs: 1145.9458. Time: 1616.9171 us. Best GFLOPs: 1287.6474
2024-04-28 10:50:03 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #213: GFLOPs: 231.5184. Time: 8003.2475 us. Best GFLOPs: 1287.6474
2024-04-28 10:50:03 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #214: GFLOPs: 223.8216. Time: 8278.4645 us. Best GFLOPs: 1287.6474
2024-04-28 10:50:03 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #215: GFLOPs: 240.7244. Time: 7697.1822 us. Best GFLOPs: 1287.6474
2024-04-28 10:50:03 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #216: GFLOPs: 688.8789. Time: 2689.7317 us. Best GFLOPs: 1287.6474
2024-04-28 10:50:03 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #217: GFLOPs: 837.8153. Time: 2211.5846 us. Best GFLOPs: 1287.6474
2024-04-28 10:50:03 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #218: GFLOPs: 862.7127. Time: 2147.7594 us. Best GFLOPs: 1287.6474
2024-04-28 10:50:03 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #219: GFLOPs: 242.6513. Time: 7636.0561 us. Best GFLOPs: 1287.6474
2024-04-28 10:50:03 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #220: GFLOPs: 1113.0172. Time: 1664.7535 us. Best GFLOPs: 1287.6474
2024-04-28 10:50:03 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #221: GFLOPs: 866.8594. Time: 2137.4854 us. Best GFLOPs: 1287.6474
2024-04-28 10:50:03 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #222: GFLOPs: 990.9241. Time: 1869.8701 us. Best GFLOPs: 1287.6474
2024-04-28 10:50:03 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #223: GFLOPs: 862.5879. Time: 2148.0701 us. Best GFLOPs: 1287.6474
2024-04-28 10:50:03 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #224: GFLOPs: 635.6497. Time: 2914.9692 us. Best GFLOPs: 1287.6474
2024-04-28 10:50:03 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #225: GFLOPs: 675.2596. Time: 2743.9806 us. Best GFLOPs: 1287.6474
2024-04-28 10:50:03 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #226: GFLOPs: 842.7605. Time: 2198.6071 us. Best GFLOPs: 1287.6474
2024-04-28 10:50:03 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #227: GFLOPs: 722.4786. Time: 2564.6425 us. Best GFLOPs: 1287.6474
2024-04-28 10:50:03 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #228: GFLOPs: 1155.1353. Time: 1604.0539 us. Best GFLOPs: 1287.6474
2024-04-28 10:50:03 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #229: GFLOPs: 230.8300. Time: 8027.1155 us. Best GFLOPs: 1287.6474
2024-04-28 10:50:03 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #230: GFLOPs: 229.8865. Time: 8060.0600 us. Best GFLOPs: 1287.6474
2024-04-28 10:50:03 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #231: GFLOPs: 841.1268. Time: 2202.8776 us. Best GFLOPs: 1287.6474
2024-04-28 10:50:03 [INFO] [task_scheduler.cc:121] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #232: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(112), T.int64(112), T.int64(32)), "float32"), p1: T.Buffer((T.int64(2), T.int64(2), T.int64(3), T.int64(3), T.int64(32), T.int64(64)), "float32"), p2: T.Buffer((T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(64)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(2), T.int64(112), T.int64(112), T.int64(64)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(114), T.int64(114), T.int64(32)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(112), T.int64(112), T.int64(64)))
        for i0_i1_i2_i3_fused in T.parallel(T.int64(25992)):
            for i4_fused in T.vectorized(T.int64(32)):
                with T.block("data_pad"):
                    v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_i1 = T.axis.spatial(T.int64(2), i0_i1_i2_i3_fused // T.int64(12996))
                    v_i2 = T.axis.spatial(T.int64(114), i0_i1_i2_i3_fused % T.int64(12996) // T.int64(114))
                    v_i3 = T.axis.spatial(T.int64(114), i0_i1_i2_i3_fused % T.int64(114))
                    v_i4 = T.axis.spatial(T.int64(32), i4_fused)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(113) and T.int64(1) <= v_i3 and v_i3 < T.int64(113), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused in T.parallel(T.int64(392), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(4), T.int64(2)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(32), T.int64(1), T.int64(1), T.int64(2), T.int64(2), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(2), oc_chunk_1 + oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(112), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused // T.int64(7) * T.int64(2) + oh_1 * T.int64(2) + oh_2_init * T.int64(2) + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(112), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused % T.int64(7) * T.int64(16) + ow_1 * T.int64(4) + ow_2_init * T.int64(2) + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(64), oc_block_1 * T.int64(32) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(64), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(32), T.int64(1), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(2), T.int64(2), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(2), oc_chunk_1 + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(112), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused // T.int64(7) * T.int64(2) + oh_1 * T.int64(2) + oh_2 * T.int64(2) + oh_3)
                        v_ow = T.axis.spatial(T.int64(112), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused % T.int64(7) * T.int64(16) + ow_1 * T.int64(4) + ow_2 * T.int64(2) + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(64), oc_block_1 * T.int64(32) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(64), ic_0 + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(32), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(32)], p1[v_oc_chunk, v_ic // T.int64(32), v_kh, v_kw, v_ic % T.int64(32), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(32), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(32)] * p1[v_oc_chunk, v_ic // T.int64(32), v_kh, v_kw, v_ic % T.int64(32), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(2), T.int64(2), T.int64(16)):
                for ax4_fused in T.vectorized(T.int64(64)):
                    with T.block("T_relu"):
                        v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                        v_ax2 = T.axis.spatial(T.int64(112), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused // T.int64(7) * T.int64(2) + ax2)
                        v_ax3 = T.axis.spatial(T.int64(112), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused % T.int64(7) * T.int64(16) + ax3)
                        v_ax4 = T.axis.spatial(T.int64(64), ax4_fused)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 2, 1, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[56, 1, 1, 2])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[7, 4, 2, 2])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 2, 32, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[64, 1])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=-1)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75 = sch.get_loops(block=b68)
l76 = sch.fuse(l71, l72, l73, l74, preserve_unit_iters=True)
sch.parallel(loop=l76)
l77 = sch.fuse(l75, preserve_unit_iters=True)
sch.vectorize(loop=l77)
l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l78, l79, l80, l81, l82, preserve_unit_iters=True)
sch.parallel(loop=l104)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109, l110 = sch.get_loops(block=b70)
l111 = sch.fuse(l110, preserve_unit_iters=True)
sch.vectorize(loop=l111)
b112 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l113, l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134 = sch.get_loops(block=b112)
b135 = sch.decompose_reduction(block=b112, loop=l119)
2024-04-28 10:50:03 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #233: GFLOPs: 783.4099. Time: 2365.1723 us. Best GFLOPs: 1287.6474
2024-04-28 10:50:03 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #234: GFLOPs: 867.7225. Time: 2135.3592 us. Best GFLOPs: 1287.6474
2024-04-28 10:50:03 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #235: GFLOPs: 432.7544. Time: 4281.6414 us. Best GFLOPs: 1287.6474
2024-04-28 10:50:03 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #236: GFLOPs: 701.8987. Time: 2639.8385 us. Best GFLOPs: 1287.6474
2024-04-28 10:50:03 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #237: GFLOPs: 743.8642. Time: 2490.9106 us. Best GFLOPs: 1287.6474
2024-04-28 10:50:03 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #238: GFLOPs: 656.9237. Time: 2820.5701 us. Best GFLOPs: 1287.6474
2024-04-28 10:50:03 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #239: GFLOPs: 662.7386. Time: 2795.8224 us. Best GFLOPs: 1287.6474
2024-04-28 10:50:03 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #240: GFLOPs: 792.3000. Time: 2338.6334 us. Best GFLOPs: 1287.6474
2024-04-28 10:50:03 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #241: GFLOPs: 815.5409. Time: 2271.9881 us. Best GFLOPs: 1287.6474
2024-04-28 10:50:03 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #242: GFLOPs: 778.0302. Time: 2381.5264 us. Best GFLOPs: 1287.6474
2024-04-28 10:50:03 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #243: GFLOPs: 931.3312. Time: 1989.5171 us. Best GFLOPs: 1287.6474
2024-04-28 10:50:03 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #244: GFLOPs: 970.1857. Time: 1909.8398 us. Best GFLOPs: 1287.6474
2024-04-28 10:50:03 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #245: GFLOPs: 681.9788. Time: 2716.9458 us. Best GFLOPs: 1287.6474
2024-04-28 10:50:03 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #246: GFLOPs: 591.9719. Time: 3130.0462 us. Best GFLOPs: 1287.6474
2024-04-28 10:50:03 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #247: GFLOPs: 881.7071. Time: 2101.4909 us. Best GFLOPs: 1287.6474
2024-04-28 10:50:03 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #248: GFLOPs: 734.3961. Time: 2523.0246 us. Best GFLOPs: 1287.6474
2024-04-28 10:50:03 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #249: GFLOPs: 473.9697. Time: 3909.3200 us. Best GFLOPs: 1287.6474
2024-04-28 10:50:03 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #250: GFLOPs: 1001.8459. Time: 1849.4854 us. Best GFLOPs: 1287.6474
2024-04-28 10:50:03 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #251: GFLOPs: 720.9393. Time: 2570.1185 us. Best GFLOPs: 1287.6474
2024-04-28 10:50:03 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #252: GFLOPs: 1031.8924. Time: 1795.6322 us. Best GFLOPs: 1287.6474
2024-04-28 10:50:03 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #253: GFLOPs: 1042.8855. Time: 1776.7045 us. Best GFLOPs: 1287.6474
2024-04-28 10:50:03 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #254: GFLOPs: 31.6201. Time: 58598.7250 us. Best GFLOPs: 1287.6474
2024-04-28 10:50:03 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #255: GFLOPs: 36.8132. Time: 50332.4423 us. Best GFLOPs: 1287.6474
2024-04-28 10:50:03 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #256: GFLOPs: 10.7288. Time: 172703.7123 us. Best GFLOPs: 1287.6474
2024-04-28 10:59:50 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-28 10:59:51 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-28 10:59:56 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x6741138)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x30bcd18)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x38311e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x32ad8b8)]: 0 failure(s)
2024-04-28 10:59:56 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-28 11:00:09 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x6741138)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x30bcd18)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x38311e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x32ad8b8)]: 0 failure(s)
2024-04-28 11:00:21 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x6741138)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x30bcd18)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x38311e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x32ad8b8)]: 0 failure(s)
2024-04-28 11:00:33 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x6741138)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x30bcd18)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x38311e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x32ad8b8)]: 0 failure(s)
2024-04-28 11:00:44 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x6741138)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x30bcd18)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x38311e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x32ad8b8)]: 0 failure(s)
2024-04-28 11:00:51 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9143  0.9143  0.9011  0.8514  0.8293  0.8262  0.8262  0.8103  0.8046  0.8046  0.8038  0.8036  0.8017  0.7996  0.7996  0.7927
[17 : 32]:	0.7906  0.7888  0.7888  0.7848  0.7793  0.7792  0.7792  0.7687  0.7685  0.7647  0.7563  0.7532  0.7532  0.7532  0.7522  0.7447
[33 : 48]:	0.7430  0.7430  0.7430  0.7395  0.7395  0.7378  0.7361  0.7310  0.7289  0.7264  0.7231  0.7224  0.7218  0.7218  0.7163  0.7130
[49 : 64]:	0.7111  0.7111  0.7026  0.7024  0.6969  0.6951  0.6948  0.6948  0.6920  0.6880  0.6872  0.6853  0.6849  0.6828  0.6818  0.6791
2024-04-28 11:00:51 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-28 11:00:51 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-28 11:02:37 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #257: GFLOPs: 632.9322. Time: 2927.4846 us. Best GFLOPs: 1287.6474
2024-04-28 11:02:37 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #258: GFLOPs: 547.5240. Time: 3384.1429 us. Best GFLOPs: 1287.6474
2024-04-28 11:02:37 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #259: GFLOPs: 1122.9811. Time: 1649.9826 us. Best GFLOPs: 1287.6474
2024-04-28 11:02:37 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #260: GFLOPs: 1153.1037. Time: 1606.8800 us. Best GFLOPs: 1287.6474
2024-04-28 11:02:37 [INFO] [task_scheduler.cc:121] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #261: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(112), T.int64(112), T.int64(32)), "float32"), p1: T.Buffer((T.int64(2), T.int64(2), T.int64(3), T.int64(3), T.int64(32), T.int64(64)), "float32"), p2: T.Buffer((T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(64)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(2), T.int64(112), T.int64(112), T.int64(64)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(114), T.int64(114), T.int64(32)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(112), T.int64(112), T.int64(64)))
        for i0_i1_i2_i3_fused in T.parallel(T.int64(25992)):
            for i4_fused in T.vectorized(T.int64(32)):
                with T.block("data_pad"):
                    v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_i1 = T.axis.spatial(T.int64(2), i0_i1_i2_i3_fused // T.int64(12996))
                    v_i2 = T.axis.spatial(T.int64(114), i0_i1_i2_i3_fused % T.int64(12996) // T.int64(114))
                    v_i3 = T.axis.spatial(T.int64(114), i0_i1_i2_i3_fused % T.int64(114))
                    v_i4 = T.axis.spatial(T.int64(32), i4_fused)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(113) and T.int64(1) <= v_i3 and v_i3 < T.int64(113), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused in T.parallel(T.int64(224), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(2), T.int64(64), T.int64(1), T.int64(1), T.int64(2), T.int64(2), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(2), oc_chunk_1 * T.int64(2) + oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(112), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused // T.int64(28) * T.int64(14) + oh_1 * T.int64(2) + oh_2_init * T.int64(2) + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(112), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused % T.int64(28) * T.int64(4) + ow_1 * T.int64(4) + ow_2_init * T.int64(2) + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(64), oc_block_1 * T.int64(64) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(32), T.int64(3), T.int64(3), T.int64(1), T.int64(2), T.int64(1), T.int64(2), T.int64(64), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(2), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(2), oc_chunk_1 * T.int64(2) + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(112), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused // T.int64(28) * T.int64(14) + oh_1 * T.int64(2) + oh_2 * T.int64(2) + oh_3)
                        v_ow = T.axis.spatial(T.int64(112), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused % T.int64(28) * T.int64(4) + ow_1 * T.int64(4) + ow_2 * T.int64(2) + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(64), oc_block_1 * T.int64(64) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(64), ic_0 * T.int64(2) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(32), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(32)], p1[v_oc_chunk, v_ic // T.int64(32), v_kh, v_kw, v_ic % T.int64(32), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(32), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(32)] * p1[v_oc_chunk, v_ic // T.int64(32), v_kh, v_kw, v_ic % T.int64(32), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(2), T.int64(14), T.int64(4)):
                for ax4_fused in T.vectorized(T.int64(64)):
                    with T.block("T_relu"):
                        v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                        v_ax2 = T.axis.spatial(T.int64(112), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused // T.int64(28) * T.int64(14) + ax2)
                        v_ax3 = T.axis.spatial(T.int64(112), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused % T.int64(28) * T.int64(4) + ax3)
                        v_ax4 = T.axis.spatial(T.int64(64), ax4_fused)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 2, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[8, 7, 1, 2])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[28, 1, 2, 2])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 64, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[32, 2])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=-1)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75 = sch.get_loops(block=b68)
l76 = sch.fuse(l71, l72, l73, l74, preserve_unit_iters=True)
sch.parallel(loop=l76)
l77 = sch.fuse(l75, preserve_unit_iters=True)
sch.vectorize(loop=l77)
l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l78, l79, l80, l81, l82, preserve_unit_iters=True)
sch.parallel(loop=l104)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109, l110 = sch.get_loops(block=b70)
l111 = sch.fuse(l110, preserve_unit_iters=True)
sch.vectorize(loop=l111)
b112 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l113, l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134 = sch.get_loops(block=b112)
b135 = sch.decompose_reduction(block=b112, loop=l119)
2024-04-28 11:02:37 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #262: GFLOPs: 917.9019. Time: 2018.6246 us. Best GFLOPs: 1287.6474
2024-04-28 11:02:37 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #263: GFLOPs: 1151.3795. Time: 1609.2863 us. Best GFLOPs: 1287.6474
2024-04-28 11:02:37 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #264: GFLOPs: 922.5182. Time: 2008.5233 us. Best GFLOPs: 1287.6474
2024-04-28 11:02:37 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #265: GFLOPs: 1007.5727. Time: 1838.9733 us. Best GFLOPs: 1287.6474
2024-04-28 11:02:37 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #266: GFLOPs: 1134.6781. Time: 1632.9736 us. Best GFLOPs: 1287.6474
2024-04-28 11:02:37 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #267: GFLOPs: 796.5927. Time: 2326.0309 us. Best GFLOPs: 1287.6474
2024-04-28 11:02:37 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #268: GFLOPs: 1173.7326. Time: 1578.6384 us. Best GFLOPs: 1287.6474
2024-04-28 11:02:37 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #269: GFLOPs: 1121.5832. Time: 1652.0391 us. Best GFLOPs: 1287.6474
2024-04-28 11:02:37 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #270: GFLOPs: 937.7171. Time: 1975.9683 us. Best GFLOPs: 1287.6474
2024-04-28 11:02:37 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #271: GFLOPs: 970.7416. Time: 1908.7462 us. Best GFLOPs: 1287.6474
2024-04-28 11:02:37 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #272: GFLOPs: 896.3468. Time: 2067.1680 us. Best GFLOPs: 1287.6474
2024-04-28 11:02:37 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #273: GFLOPs: 1019.6945. Time: 1817.1122 us. Best GFLOPs: 1287.6474
2024-04-28 11:02:37 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #274: GFLOPs: 847.5558. Time: 2186.1680 us. Best GFLOPs: 1287.6474
2024-04-28 11:02:37 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #275: GFLOPs: 848.2700. Time: 2184.3273 us. Best GFLOPs: 1287.6474
2024-04-28 11:02:37 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #276: GFLOPs: 985.6211. Time: 1879.9307 us. Best GFLOPs: 1287.6474
2024-04-28 11:02:37 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #277: GFLOPs: 1216.9734. Time: 1522.5471 us. Best GFLOPs: 1287.6474
2024-04-28 11:02:37 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #278: GFLOPs: 845.5772. Time: 2191.2833 us. Best GFLOPs: 1287.6474
2024-04-28 11:02:37 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #279: GFLOPs: 844.8156. Time: 2193.2588 us. Best GFLOPs: 1287.6474
2024-04-28 11:02:37 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #280: GFLOPs: 1132.4936. Time: 1636.1234 us. Best GFLOPs: 1287.6474
2024-04-28 11:02:37 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #281: GFLOPs: 873.1552. Time: 2122.0734 us. Best GFLOPs: 1287.6474
2024-04-28 11:02:37 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #282: GFLOPs: 995.9958. Time: 1860.3485 us. Best GFLOPs: 1287.6474
2024-04-28 11:02:37 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #283: GFLOPs: 915.7839. Time: 2023.2932 us. Best GFLOPs: 1287.6474
2024-04-28 11:02:37 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #284: GFLOPs: 1001.0726. Time: 1850.9141 us. Best GFLOPs: 1287.6474
2024-04-28 11:02:37 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #285: GFLOPs: 825.4150. Time: 2244.8095 us. Best GFLOPs: 1287.6474
2024-04-28 11:02:37 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #286: GFLOPs: 994.4069. Time: 1863.3211 us. Best GFLOPs: 1287.6474
2024-04-28 11:02:37 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #287: GFLOPs: 887.3134. Time: 2088.2128 us. Best GFLOPs: 1287.6474
2024-04-28 11:02:37 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #288: GFLOPs: 937.5232. Time: 1976.3769 us. Best GFLOPs: 1287.6474
2024-04-28 11:02:37 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #289: GFLOPs: 955.5277. Time: 1939.1372 us. Best GFLOPs: 1287.6474
2024-04-28 11:02:37 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #290: GFLOPs: 787.6408. Time: 2352.4674 us. Best GFLOPs: 1287.6474
2024-04-28 11:02:37 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #291: GFLOPs: 991.7889. Time: 1868.2395 us. Best GFLOPs: 1287.6474
2024-04-28 11:02:37 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #292: GFLOPs: 837.3510. Time: 2212.8107 us. Best GFLOPs: 1287.6474
2024-04-28 11:02:37 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #293: GFLOPs: 402.1262. Time: 4607.7562 us. Best GFLOPs: 1287.6474
2024-04-28 11:02:37 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #294: GFLOPs: 961.6367. Time: 1926.8184 us. Best GFLOPs: 1287.6474
2024-04-28 11:02:37 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #295: GFLOPs: 770.3633. Time: 2405.2278 us. Best GFLOPs: 1287.6474
2024-04-28 11:02:37 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #296: GFLOPs: 948.6755. Time: 1953.1434 us. Best GFLOPs: 1287.6474
2024-04-28 11:02:37 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #297: GFLOPs: 491.1992. Time: 3772.1956 us. Best GFLOPs: 1287.6474
2024-04-28 11:02:37 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #298: GFLOPs: 979.9052. Time: 1890.8965 us. Best GFLOPs: 1287.6474
2024-04-28 11:02:37 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #299: GFLOPs: 972.1642. Time: 1905.9530 us. Best GFLOPs: 1287.6474
2024-04-28 11:02:37 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #300: GFLOPs: 700.2853. Time: 2645.9208 us. Best GFLOPs: 1287.6474
2024-04-28 11:02:37 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #301: GFLOPs: 955.6335. Time: 1938.9226 us. Best GFLOPs: 1287.6474
2024-04-28 11:02:37 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #302: GFLOPs: 988.6264. Time: 1874.2159 us. Best GFLOPs: 1287.6474
2024-04-28 11:02:37 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #303: GFLOPs: 964.4857. Time: 1921.1268 us. Best GFLOPs: 1287.6474
2024-04-28 11:02:37 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #304: GFLOPs: 743.2301. Time: 2493.0358 us. Best GFLOPs: 1287.6474
2024-04-28 11:02:37 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #305: GFLOPs: 1032.1476. Time: 1795.1884 us. Best GFLOPs: 1287.6474
2024-04-28 11:02:37 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #306: GFLOPs: 1025.1997. Time: 1807.3545 us. Best GFLOPs: 1287.6474
2024-04-28 11:02:37 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #307: GFLOPs: 933.7409. Time: 1984.3827 us. Best GFLOPs: 1287.6474
2024-04-28 11:02:37 [INFO] [task_scheduler.cc:121] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #308: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(112), T.int64(112), T.int64(32)), "float32"), p1: T.Buffer((T.int64(2), T.int64(2), T.int64(3), T.int64(3), T.int64(32), T.int64(64)), "float32"), p2: T.Buffer((T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(64)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(2), T.int64(112), T.int64(112), T.int64(64)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(114), T.int64(114), T.int64(32)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(112), T.int64(112), T.int64(64)))
        for i0_i1_i2_i3_fused in T.parallel(T.int64(25992)):
            for i4_fused in T.vectorized(T.int64(32)):
                with T.block("data_pad"):
                    v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_i1 = T.axis.spatial(T.int64(2), i0_i1_i2_i3_fused // T.int64(12996))
                    v_i2 = T.axis.spatial(T.int64(114), i0_i1_i2_i3_fused % T.int64(12996) // T.int64(114))
                    v_i3 = T.axis.spatial(T.int64(114), i0_i1_i2_i3_fused % T.int64(114))
                    v_i4 = T.axis.spatial(T.int64(32), i4_fused)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(113) and T.int64(1) <= v_i3 and v_i3 < T.int64(113), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused in T.parallel(T.int64(112), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(2), T.int64(64), T.int64(1), T.int64(1), T.int64(4), T.int64(2), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(2), oc_chunk_1 * T.int64(2) + oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(112), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused // T.int64(28) * T.int64(28) + oh_1 * T.int64(4) + oh_2_init * T.int64(4) + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(112), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused % T.int64(28) * T.int64(4) + ow_1 * T.int64(4) + ow_2_init * T.int64(2) + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(64), oc_block_1 * T.int64(64) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(64), T.int64(1), T.int64(3), T.int64(1), T.int64(2), T.int64(1), T.int64(2), T.int64(64), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(2), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(2), oc_chunk_1 * T.int64(2) + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(112), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused // T.int64(28) * T.int64(28) + oh_1 * T.int64(4) + oh_2 * T.int64(4) + oh_3)
                        v_ow = T.axis.spatial(T.int64(112), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused % T.int64(28) * T.int64(4) + ow_1 * T.int64(4) + ow_2 * T.int64(2) + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(64), oc_block_1 * T.int64(64) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(64), ic_0 + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(32), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(32)], p1[v_oc_chunk, v_ic // T.int64(32), v_kh, v_kw, v_ic % T.int64(32), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(32), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(32)] * p1[v_oc_chunk, v_ic // T.int64(32), v_kh, v_kw, v_ic % T.int64(32), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(2), T.int64(28), T.int64(4)):
                for ax4_fused in T.vectorized(T.int64(64)):
                    with T.block("T_relu"):
                        v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                        v_ax2 = T.axis.spatial(T.int64(112), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused // T.int64(28) * T.int64(28) + ax2)
                        v_ax3 = T.axis.spatial(T.int64(112), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused % T.int64(28) * T.int64(4) + ax3)
                        v_ax4 = T.axis.spatial(T.int64(64), ax4_fused)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 2, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[4, 7, 1, 4])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[28, 1, 2, 2])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 64, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[64, 1])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=-1)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75 = sch.get_loops(block=b68)
l76 = sch.fuse(l71, l72, l73, l74, preserve_unit_iters=True)
sch.parallel(loop=l76)
l77 = sch.fuse(l75, preserve_unit_iters=True)
sch.vectorize(loop=l77)
l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l78, l79, l80, l81, l82, preserve_unit_iters=True)
sch.parallel(loop=l104)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109, l110 = sch.get_loops(block=b70)
l111 = sch.fuse(l110, preserve_unit_iters=True)
sch.vectorize(loop=l111)
b112 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l113, l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134 = sch.get_loops(block=b112)
b135 = sch.decompose_reduction(block=b112, loop=l119)
2024-04-28 11:02:37 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #309: GFLOPs: 741.8867. Time: 2497.5502 us. Best GFLOPs: 1287.6474
2024-04-28 11:02:37 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #310: GFLOPs: 733.5153. Time: 2526.0540 us. Best GFLOPs: 1287.6474
2024-04-28 11:02:37 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #311: GFLOPs: 1053.9071. Time: 1758.1240 us. Best GFLOPs: 1287.6474
2024-04-28 11:02:37 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #312: GFLOPs: 1054.6182. Time: 1756.9385 us. Best GFLOPs: 1287.6474
2024-04-28 11:02:37 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #313: GFLOPs: 918.2390. Time: 2017.8836 us. Best GFLOPs: 1287.6474
2024-04-28 11:02:37 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #314: GFLOPs: 822.0902. Time: 2253.8880 us. Best GFLOPs: 1287.6474
2024-04-28 11:02:37 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #315: GFLOPs: 841.9885. Time: 2200.6230 us. Best GFLOPs: 1287.6474
2024-04-28 11:02:37 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #316: GFLOPs: 861.2186. Time: 2151.4856 us. Best GFLOPs: 1287.6474
2024-04-28 11:02:37 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #317: GFLOPs: 1134.5923. Time: 1633.0970 us. Best GFLOPs: 1287.6474
2024-04-28 11:02:37 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #318: GFLOPs: 106.8379. Time: 17343.0925 us. Best GFLOPs: 1287.6474
2024-04-28 11:02:37 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #319: GFLOPs: 78.0763. Time: 23731.8960 us. Best GFLOPs: 1287.6474
2024-04-28 11:02:37 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #320: GFLOPs: 36.1976. Time: 51188.4163 us. Best GFLOPs: 1287.6474
2024-04-28 12:02:38 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-28 12:02:40 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-28 12:02:44 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x6741138)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x30bcd18)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x38311e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x32ad8b8)]: 0 failure(s)
2024-04-28 12:02:44 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-28 12:02:57 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x6741138)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x30bcd18)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x38311e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x32ad8b8)]: 0 failure(s)
2024-04-28 12:03:09 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x6741138)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x30bcd18)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x38311e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x32ad8b8)]: 0 failure(s)
2024-04-28 12:03:21 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x6741138)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x30bcd18)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x38311e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x32ad8b8)]: 0 failure(s)
2024-04-28 12:03:32 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x6741138)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x30bcd18)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x38311e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x32ad8b8)]: 0 failure(s)
2024-04-28 12:03:39 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.8892  0.8659  0.8579  0.8545  0.8498  0.8498  0.8479  0.8422  0.8387  0.8387  0.8341  0.8308  0.8304  0.8274  0.8229  0.8201
[17 : 32]:	0.8201  0.8183  0.8146  0.8128  0.8014  0.7998  0.7985  0.7985  0.7985  0.7944  0.7927  0.7879  0.7867  0.7841  0.7841  0.7818
[33 : 48]:	0.7802  0.7800  0.7783  0.7772  0.7761  0.7751  0.7745  0.7745  0.7743  0.7730  0.7730  0.7699  0.7697  0.7689  0.7685  0.7642
[49 : 64]:	0.7630  0.7620  0.7612  0.7603  0.7563  0.7562  0.7525  0.7510  0.7497  0.7497  0.7493  0.7454  0.7451  0.7438  0.7415  0.7412
2024-04-28 12:03:39 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-28 12:03:39 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-28 12:05:27 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #321: GFLOPs: 1045.0408. Time: 1773.0402 us. Best GFLOPs: 1287.6474
2024-04-28 12:05:27 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #322: GFLOPs: 547.6132. Time: 3383.5911 us. Best GFLOPs: 1287.6474
2024-04-28 12:05:27 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #323: GFLOPs: 1169.7960. Time: 1583.9508 us. Best GFLOPs: 1287.6474
2024-04-28 12:05:27 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #324: GFLOPs: 1244.1575. Time: 1489.2804 us. Best GFLOPs: 1287.6474
2024-04-28 12:05:27 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #325: GFLOPs: 1222.3207. Time: 1515.8864 us. Best GFLOPs: 1287.6474
2024-04-28 12:05:27 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #326: GFLOPs: 1184.5498. Time: 1564.2224 us. Best GFLOPs: 1287.6474
2024-04-28 12:05:27 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #327: GFLOPs: 1052.0898. Time: 1761.1608 us. Best GFLOPs: 1287.6474
2024-04-28 12:05:27 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #328: GFLOPs: 1329.0364. Time: 1394.1674 us. Best GFLOPs: 1329.0364
2024-04-28 12:05:27 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #329: GFLOPs: 1202.4175. Time: 1540.9783 us. Best GFLOPs: 1329.0364
2024-04-28 12:05:27 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #330: GFLOPs: 1203.6272. Time: 1539.4296 us. Best GFLOPs: 1329.0364
2024-04-28 12:05:27 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #331: GFLOPs: 1138.4579. Time: 1627.5519 us. Best GFLOPs: 1329.0364
2024-04-28 12:05:27 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #332: GFLOPs: 1004.6367. Time: 1844.3477 us. Best GFLOPs: 1329.0364
2024-04-28 12:05:27 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #333: GFLOPs: 947.3840. Time: 1955.8059 us. Best GFLOPs: 1329.0364
2024-04-28 12:05:27 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #334: GFLOPs: 1188.7867. Time: 1558.6474 us. Best GFLOPs: 1329.0364
2024-04-28 12:05:27 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #335: GFLOPs: 1247.0385. Time: 1485.8397 us. Best GFLOPs: 1329.0364
2024-04-28 12:05:27 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #336: GFLOPs: 1049.0874. Time: 1766.2011 us. Best GFLOPs: 1329.0364
2024-04-28 12:05:27 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #337: GFLOPs: 941.2927. Time: 1968.4625 us. Best GFLOPs: 1329.0364
2024-04-28 12:05:27 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #338: GFLOPs: 944.8938. Time: 1960.9605 us. Best GFLOPs: 1329.0364
2024-04-28 12:05:27 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #339: GFLOPs: 1178.6327. Time: 1572.0753 us. Best GFLOPs: 1329.0364
2024-04-28 12:05:27 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #340: GFLOPs: 864.0085. Time: 2144.5384 us. Best GFLOPs: 1329.0364
2024-04-28 12:05:27 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #341: GFLOPs: 1405.4479. Time: 1318.3693 us. Best GFLOPs: 1405.4479
2024-04-28 12:05:27 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #342: GFLOPs: 940.2075. Time: 1970.7345 us. Best GFLOPs: 1405.4479
2024-04-28 12:05:27 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #343: GFLOPs: 1261.2339. Time: 1469.1164 us. Best GFLOPs: 1405.4479
2024-04-28 12:05:27 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #344: GFLOPs: 1349.7157. Time: 1372.8072 us. Best GFLOPs: 1405.4479
2024-04-28 12:05:27 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #345: GFLOPs: 1339.2173. Time: 1383.5688 us. Best GFLOPs: 1405.4479
2024-04-28 12:05:27 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #346: GFLOPs: 1107.3856. Time: 1673.2196 us. Best GFLOPs: 1405.4479
2024-04-28 12:05:27 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #347: GFLOPs: 1039.8159. Time: 1781.9494 us. Best GFLOPs: 1405.4479
2024-04-28 12:05:27 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #348: GFLOPs: 1077.6275. Time: 1719.4247 us. Best GFLOPs: 1405.4479
2024-04-28 12:05:27 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #349: GFLOPs: 1125.6045. Time: 1646.1372 us. Best GFLOPs: 1405.4479
2024-04-28 12:05:27 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #350: GFLOPs: 1018.5015. Time: 1819.2406 us. Best GFLOPs: 1405.4479
2024-04-28 12:05:27 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #351: GFLOPs: 1102.0384. Time: 1681.3383 us. Best GFLOPs: 1405.4479
2024-04-28 12:05:27 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #352: GFLOPs: 839.1757. Time: 2207.9993 us. Best GFLOPs: 1405.4479
2024-04-28 12:05:27 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #353: GFLOPs: 723.1122. Time: 2562.3953 us. Best GFLOPs: 1405.4479
2024-04-28 12:05:27 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #354: GFLOPs: 923.5742. Time: 2006.2268 us. Best GFLOPs: 1405.4479
2024-04-28 12:05:27 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #355: GFLOPs: 1201.3118. Time: 1542.3966 us. Best GFLOPs: 1405.4479
2024-04-28 12:05:27 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #356: GFLOPs: 877.9134. Time: 2110.5719 us. Best GFLOPs: 1405.4479
2024-04-28 12:05:27 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #357: GFLOPs: 1068.1006. Time: 1734.7610 us. Best GFLOPs: 1405.4479
2024-04-28 12:05:27 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #358: GFLOPs: 1022.8569. Time: 1811.4942 us. Best GFLOPs: 1405.4479
2024-04-28 12:05:27 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #359: GFLOPs: 1072.7389. Time: 1727.2603 us. Best GFLOPs: 1405.4479
2024-04-28 12:05:27 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #360: GFLOPs: 998.9538. Time: 1854.8398 us. Best GFLOPs: 1405.4479
2024-04-28 12:05:27 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #361: GFLOPs: 815.2669. Time: 2272.7517 us. Best GFLOPs: 1405.4479
2024-04-28 12:05:27 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #362: GFLOPs: 1111.2608. Time: 1667.3848 us. Best GFLOPs: 1405.4479
2024-04-28 12:05:27 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #363: GFLOPs: 1126.6291. Time: 1644.6400 us. Best GFLOPs: 1405.4479
2024-04-28 12:05:27 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #364: GFLOPs: 992.9295. Time: 1866.0935 us. Best GFLOPs: 1405.4479
2024-04-28 12:05:27 [INFO] [task_scheduler.cc:121] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #365: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(112), T.int64(112), T.int64(32)), "float32"), p1: T.Buffer((T.int64(2), T.int64(2), T.int64(3), T.int64(3), T.int64(32), T.int64(64)), "float32"), p2: T.Buffer((T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(64)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(2), T.int64(112), T.int64(112), T.int64(64)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(114), T.int64(114), T.int64(32)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(112), T.int64(112), T.int64(64)))
        for i0_i1_i2_i3_fused in T.parallel(T.int64(25992)):
            for i4_fused in T.vectorized(T.int64(32)):
                with T.block("data_pad"):
                    v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_i1 = T.axis.spatial(T.int64(2), i0_i1_i2_i3_fused // T.int64(12996))
                    v_i2 = T.axis.spatial(T.int64(114), i0_i1_i2_i3_fused % T.int64(12996) // T.int64(114))
                    v_i3 = T.axis.spatial(T.int64(114), i0_i1_i2_i3_fused % T.int64(114))
                    v_i4 = T.axis.spatial(T.int64(32), i4_fused)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(113) and T.int64(1) <= v_i3 and v_i3 < T.int64(113), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused in T.parallel(T.int64(112), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(8), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(64), T.int64(1), T.int64(1), T.int64(2), T.int64(2), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(2), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused // T.int64(56) + oc_chunk_1 + oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(112), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused % T.int64(56) // T.int64(7) * T.int64(14) + oh_1 * T.int64(14) + oh_2_init * T.int64(2) + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(112), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused % T.int64(7) * T.int64(16) + ow_1 * T.int64(2) + ow_2_init * T.int64(2) + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(64), oc_block_1 * T.int64(64) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(32), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(64), T.int64(2), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(2), T.int64(2), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(2), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused // T.int64(56) + oc_chunk_1 + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(112), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused % T.int64(56) // T.int64(7) * T.int64(14) + oh_1 * T.int64(14) + oh_2 * T.int64(2) + oh_3)
                        v_ow = T.axis.spatial(T.int64(112), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused % T.int64(7) * T.int64(16) + ow_1 * T.int64(2) + ow_2 * T.int64(2) + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(64), oc_block_1 * T.int64(64) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(64), ic_0 * T.int64(2) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(32), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(32)], p1[v_oc_chunk, v_ic // T.int64(32), v_kh, v_kw, v_ic % T.int64(32), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(32), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(32)] * p1[v_oc_chunk, v_ic // T.int64(32), v_kh, v_kw, v_ic % T.int64(32), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(14), T.int64(16)):
                for ax4_fused in T.vectorized(T.int64(64)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(2), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused // T.int64(56) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(112), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused % T.int64(56) // T.int64(7) * T.int64(14) + ax2)
                        v_ax3 = T.axis.spatial(T.int64(112), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused % T.int64(7) * T.int64(16) + ax3)
                        v_ax4 = T.axis.spatial(T.int64(64), ax4_fused)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[2, 1, 1, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[8, 1, 7, 2])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[7, 8, 1, 2])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 64, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[32, 2])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=-1)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75 = sch.get_loops(block=b68)
l76 = sch.fuse(l71, l72, l73, l74, preserve_unit_iters=True)
sch.parallel(loop=l76)
l77 = sch.fuse(l75, preserve_unit_iters=True)
sch.vectorize(loop=l77)
l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l78, l79, l80, l81, l82, preserve_unit_iters=True)
sch.parallel(loop=l104)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109, l110 = sch.get_loops(block=b70)
l111 = sch.fuse(l110, preserve_unit_iters=True)
sch.vectorize(loop=l111)
b112 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l113, l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134 = sch.get_loops(block=b112)
b135 = sch.decompose_reduction(block=b112, loop=l119)
2024-04-28 12:05:27 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #366: GFLOPs: 1042.3893. Time: 1777.5502 us. Best GFLOPs: 1405.4479
2024-04-28 12:05:27 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #367: GFLOPs: 1119.2626. Time: 1655.4643 us. Best GFLOPs: 1405.4479
2024-04-28 12:05:27 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #368: GFLOPs: 1058.9679. Time: 1749.7220 us. Best GFLOPs: 1405.4479
2024-04-28 12:05:27 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #369: GFLOPs: 897.5031. Time: 2064.5047 us. Best GFLOPs: 1405.4479
2024-04-28 12:05:27 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #370: GFLOPs: 944.4371. Time: 1961.9087 us. Best GFLOPs: 1405.4479
2024-04-28 12:05:27 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #371: GFLOPs: 1218.3757. Time: 1520.7947 us. Best GFLOPs: 1405.4479
2024-04-28 12:05:27 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #372: GFLOPs: 877.3348. Time: 2111.9638 us. Best GFLOPs: 1405.4479
2024-04-28 12:05:27 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #373: GFLOPs: 1192.2988. Time: 1554.0562 us. Best GFLOPs: 1405.4479
2024-04-28 12:05:27 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #374: GFLOPs: 1022.8480. Time: 1811.5099 us. Best GFLOPs: 1405.4479
2024-04-28 12:05:27 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #375: GFLOPs: 1028.4682. Time: 1801.6108 us. Best GFLOPs: 1405.4479
2024-04-28 12:05:27 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #376: GFLOPs: 787.3544. Time: 2353.3230 us. Best GFLOPs: 1405.4479
2024-04-28 12:05:27 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #377: GFLOPs: 990.5608. Time: 1870.5558 us. Best GFLOPs: 1405.4479
2024-04-28 12:05:27 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #378: GFLOPs: 690.6893. Time: 2682.6814 us. Best GFLOPs: 1405.4479
2024-04-28 12:05:27 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #379: GFLOPs: 1216.6856. Time: 1522.9072 us. Best GFLOPs: 1405.4479
2024-04-28 12:05:27 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #380: GFLOPs: 1120.8872. Time: 1653.0650 us. Best GFLOPs: 1405.4479
2024-04-28 12:05:27 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #381: GFLOPs: 915.2959. Time: 2024.3720 us. Best GFLOPs: 1405.4479
2024-04-28 12:05:27 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #382: GFLOPs: 67.2066. Time: 27570.1888 us. Best GFLOPs: 1405.4479
2024-04-28 12:05:27 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #383: GFLOPs: 122.4556. Time: 15131.1984 us. Best GFLOPs: 1405.4479
2024-04-28 12:05:27 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #384: GFLOPs: 14.8930. Time: 124413.7737 us. Best GFLOPs: 1405.4479
2024-04-28 12:48:34 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-28 12:48:35 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-28 12:48:40 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x6741138)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x30bcd18)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x38311e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x32ad8b8)]: 0 failure(s)
2024-04-28 12:48:40 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-28 12:48:53 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x6741138)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x30bcd18)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x38311e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x32ad8b8)]: 0 failure(s)
2024-04-28 12:49:05 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x6741138)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x30bcd18)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x38311e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x32ad8b8)]: 0 failure(s)
2024-04-28 12:49:17 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x6741138)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x30bcd18)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x38311e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x32ad8b8)]: 0 failure(s)
2024-04-28 12:49:28 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x6741138)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x30bcd18)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x38311e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x32ad8b8)]: 0 failure(s)
2024-04-28 12:49:35 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.8898  0.8896  0.8795  0.8795  0.8672  0.8624  0.8547  0.8547  0.8544  0.8471  0.8471  0.8351  0.8319  0.8177  0.8177  0.8174
[17 : 32]:	0.8164  0.8134  0.8116  0.8025  0.7916  0.7890  0.7831  0.7781  0.7748  0.7746  0.7713  0.7707  0.7670  0.7665  0.7665  0.7620
[33 : 48]:	0.7614  0.7614  0.7564  0.7550  0.7512  0.7509  0.7509  0.7476  0.7466  0.7444  0.7432  0.7385  0.7348  0.7329  0.7327  0.7323
[49 : 64]:	0.7318  0.7318  0.7318  0.7317  0.7303  0.7292  0.7284  0.7276  0.7276  0.7265  0.7257  0.7257  0.7225  0.7224  0.7223  0.7213
2024-04-28 12:49:35 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-28 12:49:35 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-28 12:51:40 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #385: GFLOPs: 1423.2375. Time: 1301.8905 us. Best GFLOPs: 1423.2375
2024-04-28 12:51:40 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #386: GFLOPs: 1375.6722. Time: 1346.9047 us. Best GFLOPs: 1423.2375
2024-04-28 12:51:40 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #387: GFLOPs: 1207.3875. Time: 1534.6351 us. Best GFLOPs: 1423.2375
2024-04-28 12:51:40 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #388: GFLOPs: 1176.2886. Time: 1575.2081 us. Best GFLOPs: 1423.2375
2024-04-28 12:51:40 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #389: GFLOPs: 571.5352. Time: 3241.9687 us. Best GFLOPs: 1423.2375
2024-04-28 12:51:40 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #390: GFLOPs: 1289.3617. Time: 1437.0671 us. Best GFLOPs: 1423.2375
2024-04-28 12:51:40 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #391: GFLOPs: 1192.3789. Time: 1553.9518 us. Best GFLOPs: 1423.2375
2024-04-28 12:51:40 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #392: GFLOPs: 1166.0883. Time: 1588.9871 us. Best GFLOPs: 1423.2375
2024-04-28 12:51:40 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #393: GFLOPs: 952.1063. Time: 1946.1055 us. Best GFLOPs: 1423.2375
2024-04-28 12:51:40 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #394: GFLOPs: 1077.4486. Time: 1719.7102 us. Best GFLOPs: 1423.2375
2024-04-28 12:51:40 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #395: GFLOPs: 1264.5238. Time: 1465.2941 us. Best GFLOPs: 1423.2375
2024-04-28 12:51:40 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #396: GFLOPs: 866.2821. Time: 2138.9099 us. Best GFLOPs: 1423.2375
2024-04-28 12:51:40 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #397: GFLOPs: 1122.1976. Time: 1651.1346 us. Best GFLOPs: 1423.2375
2024-04-28 12:51:40 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #398: GFLOPs: 1144.9887. Time: 1618.2686 us. Best GFLOPs: 1423.2375
2024-04-28 12:51:40 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #399: GFLOPs: 1133.2125. Time: 1635.0855 us. Best GFLOPs: 1423.2375
2024-04-28 12:51:40 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #400: GFLOPs: 1166.9330. Time: 1587.8369 us. Best GFLOPs: 1423.2375
2024-04-28 12:51:40 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #401: GFLOPs: 1217.3389. Time: 1522.0899 us. Best GFLOPs: 1423.2375
2024-04-28 12:51:40 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #402: GFLOPs: 957.8661. Time: 1934.4032 us. Best GFLOPs: 1423.2375
2024-04-28 12:51:40 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #403: GFLOPs: 1143.0761. Time: 1620.9764 us. Best GFLOPs: 1423.2375
2024-04-28 12:51:40 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #404: GFLOPs: 640.6784. Time: 2892.0897 us. Best GFLOPs: 1423.2375
2024-04-28 12:51:40 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #405: GFLOPs: 1193.9065. Time: 1551.9636 us. Best GFLOPs: 1423.2375
2024-04-28 12:51:40 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #406: GFLOPs: 1028.3177. Time: 1801.8743 us. Best GFLOPs: 1423.2375
2024-04-28 12:51:40 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #407: GFLOPs: 1142.8727. Time: 1621.2648 us. Best GFLOPs: 1423.2375
2024-04-28 12:51:40 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #408: GFLOPs: 1070.8124. Time: 1730.3678 us. Best GFLOPs: 1423.2375
2024-04-28 12:51:40 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #409: GFLOPs: 1331.2427. Time: 1391.8569 us. Best GFLOPs: 1423.2375
2024-04-28 12:51:40 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #410: GFLOPs: 1249.4846. Time: 1482.9309 us. Best GFLOPs: 1423.2375
2024-04-28 12:51:40 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #411: GFLOPs: 1211.2770. Time: 1529.7073 us. Best GFLOPs: 1423.2375
2024-04-28 12:51:40 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #412: GFLOPs: 999.4514. Time: 1853.9164 us. Best GFLOPs: 1423.2375
2024-04-28 12:51:40 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #413: GFLOPs: 1149.6213. Time: 1611.7475 us. Best GFLOPs: 1423.2375
2024-04-28 12:51:40 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #414: GFLOPs: 853.1647. Time: 2171.7956 us. Best GFLOPs: 1423.2375
2024-04-28 12:51:40 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #415: GFLOPs: 878.2458. Time: 2109.7731 us. Best GFLOPs: 1423.2375
2024-04-28 12:51:40 [INFO] [task_scheduler.cc:121] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #416: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(112), T.int64(112), T.int64(32)), "float32"), p1: T.Buffer((T.int64(2), T.int64(2), T.int64(3), T.int64(3), T.int64(32), T.int64(64)), "float32"), p2: T.Buffer((T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(64)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(2), T.int64(112), T.int64(112), T.int64(64)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(114), T.int64(114), T.int64(32)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(112), T.int64(112), T.int64(64)))
        for n_0_oc_chunk_0_oh_0_ow_0_fused_fused in T.parallel(T.int64(224), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(2), T.int64(16), T.int64(10)):
                for ax4_fused in T.vectorized(T.int64(32)):
                    with T.block("data_pad"):
                        v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                        v_i2 = T.axis.spatial(T.int64(114), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(112) // T.int64(14) * T.int64(14) + ax2)
                        v_i3 = T.axis.spatial(T.int64(114), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(14) * T.int64(8) + ax3)
                        v_i4 = T.axis.spatial(T.int64(32), ax4_fused)
                        T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                        T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                        data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(113) and T.int64(1) <= v_i3 and v_i3 < T.int64(113), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oc_block_0 in range(T.int64(1)):
                for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(1)):
                    for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(64), T.int64(1), T.int64(1), T.int64(2), T.int64(2), T.int64(1)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(2), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(112) + oc_chunk_1 + oc_chunk_2_init + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(112), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(112) // T.int64(14) * T.int64(14) + oh_1 * T.int64(2) + oh_2_init * T.int64(2) + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(112), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(14) * T.int64(8) + ow_1 * T.int64(8) + ow_2_init * T.int64(2) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(64), oc_block_0 * T.int64(64) + oc_block_1 * T.int64(64) + oc_block_2_init + oc_block_3_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                    for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(64), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(64), T.int64(1), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(2), T.int64(2), T.int64(1)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(2), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(112) + oc_chunk_1 + oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(112), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(112) // T.int64(14) * T.int64(14) + oh_1 * T.int64(2) + oh_2 * T.int64(2) + oh_3)
                            v_ow = T.axis.spatial(T.int64(112), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(14) * T.int64(8) + ow_1 * T.int64(8) + ow_2 * T.int64(2) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(64), oc_block_0 * T.int64(64) + oc_block_1 * T.int64(64) + oc_block_2 + oc_block_3)
                            v_ic = T.axis.reduce(T.int64(64), ic_0 + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(32), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(32)], p1[v_oc_chunk, v_ic // T.int64(32), v_kh, v_kw, v_ic % T.int64(32), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(32), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(32)] * p1[v_oc_chunk, v_ic // T.int64(32), v_kh, v_kw, v_ic % T.int64(32), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(14), T.int64(8)):
                    for ax4_fused in T.vectorized(T.int64(64)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(2), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(112) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(112), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(112) // T.int64(14) * T.int64(14) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(112), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(14) * T.int64(8) + ax3)
                            v_ax4 = T.axis.spatial(T.int64(64), ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[2, 1, 1, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[8, 7, 1, 2])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[14, 1, 4, 2])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 64, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[64, 1])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=3)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79 = sch.get_loops(block=b68)
l80 = sch.fuse(l71, l72, l73, l74, preserve_unit_iters=True)
sch.parallel(loop=l80)
l81 = sch.fuse(l79, preserve_unit_iters=True)
sch.vectorize(loop=l81)
l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b69)
l105 = sch.fuse(l82, preserve_unit_iters=True)
sch.parallel(loop=l105)
sch.annotate(block_or_loop=l105, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l105, ann_key="pragma_unroll_explicit", ann_val=1)
l106, l107, l108, l109, l110, l111, l112 = sch.get_loops(block=b70)
l113 = sch.fuse(l112, preserve_unit_iters=True)
sch.vectorize(loop=l113)
b114 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137 = sch.get_loops(block=b114)
b138 = sch.decompose_reduction(block=b114, loop=l122)
2024-04-28 12:51:40 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #417: GFLOPs: 1138.0650. Time: 1628.1138 us. Best GFLOPs: 1423.2375
2024-04-28 12:51:40 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #418: GFLOPs: 1322.4035. Time: 1401.1603 us. Best GFLOPs: 1423.2375
2024-04-28 12:51:40 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #419: GFLOPs: 666.4763. Time: 2780.1427 us. Best GFLOPs: 1423.2375
2024-04-28 12:51:40 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #420: GFLOPs: 1086.6921. Time: 1705.0822 us. Best GFLOPs: 1423.2375
2024-04-28 12:51:40 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #421: GFLOPs: 655.8521. Time: 2825.1788 us. Best GFLOPs: 1423.2375
2024-04-28 12:51:40 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #422: GFLOPs: 1018.1007. Time: 1819.9568 us. Best GFLOPs: 1423.2375
2024-04-28 12:51:40 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #423: GFLOPs: 1033.4175. Time: 1792.9824 us. Best GFLOPs: 1423.2375
2024-04-28 12:51:40 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #424: GFLOPs: 1022.7247. Time: 1811.7283 us. Best GFLOPs: 1423.2375
2024-04-28 12:51:40 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #425: GFLOPs: 860.3441. Time: 2153.6723 us. Best GFLOPs: 1423.2375
2024-04-28 12:51:40 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #426: GFLOPs: 1061.5216. Time: 1745.5126 us. Best GFLOPs: 1423.2375
2024-04-28 12:51:40 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #427: GFLOPs: 1174.0832. Time: 1578.1669 us. Best GFLOPs: 1423.2375
2024-04-28 12:51:40 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #428: GFLOPs: 1247.5571. Time: 1485.2221 us. Best GFLOPs: 1423.2375
2024-04-28 12:51:40 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #429: GFLOPs: 941.4335. Time: 1968.1681 us. Best GFLOPs: 1423.2375
2024-04-28 12:51:40 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #430: GFLOPs: 1192.1359. Time: 1554.2685 us. Best GFLOPs: 1423.2375
2024-04-28 12:51:40 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #431: GFLOPs: 1072.0494. Time: 1728.3712 us. Best GFLOPs: 1423.2375
2024-04-28 12:51:40 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #432: GFLOPs: 1050.4198. Time: 1763.9608 us. Best GFLOPs: 1423.2375
2024-04-28 12:51:40 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #433: GFLOPs: 1079.7219. Time: 1716.0895 us. Best GFLOPs: 1423.2375
2024-04-28 12:51:40 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #434: GFLOPs: 1285.5437. Time: 1441.3352 us. Best GFLOPs: 1423.2375
2024-04-28 12:51:40 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #435: GFLOPs: 1083.0759. Time: 1710.7751 us. Best GFLOPs: 1423.2375
2024-04-28 12:51:40 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #436: GFLOPs: 873.6680. Time: 2120.8277 us. Best GFLOPs: 1423.2375
2024-04-28 12:51:40 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #437: GFLOPs: 869.0389. Time: 2132.1246 us. Best GFLOPs: 1423.2375
2024-04-28 12:51:40 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #438: GFLOPs: 798.0844. Time: 2321.6835 us. Best GFLOPs: 1423.2375
2024-04-28 12:51:40 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #439: GFLOPs: 784.1747. Time: 2362.8655 us. Best GFLOPs: 1423.2375
2024-04-28 12:51:40 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #440: GFLOPs: 1232.9473. Time: 1502.8212 us. Best GFLOPs: 1423.2375
2024-04-28 12:51:40 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #441: GFLOPs: 877.4099. Time: 2111.7829 us. Best GFLOPs: 1423.2375
2024-04-28 12:51:40 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #442: GFLOPs: 957.0630. Time: 1936.0265 us. Best GFLOPs: 1423.2375
2024-04-28 12:51:40 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #443: GFLOPs: 1034.2437. Time: 1791.5500 us. Best GFLOPs: 1423.2375
2024-04-28 12:51:40 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #444: GFLOPs: 1299.2851. Time: 1426.0914 us. Best GFLOPs: 1423.2375
2024-04-28 12:51:40 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #445: GFLOPs: 1013.3927. Time: 1828.4119 us. Best GFLOPs: 1423.2375
2024-04-28 12:51:40 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #446: GFLOPs: 1.3941. Time: 1329093.0467 us. Best GFLOPs: 1423.2375
2024-04-28 12:51:40 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #447: GFLOPs: 69.2390. Time: 26760.9147 us. Best GFLOPs: 1423.2375
2024-04-28 12:51:40 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #448: GFLOPs: 9.5317. Time: 194393.3543 us. Best GFLOPs: 1423.2375
2024-04-28 14:25:32 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-28 14:25:33 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-28 14:25:38 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x6741138)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x30bcd18)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x38311e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x32ad8b8)]: 0 failure(s)
2024-04-28 14:25:38 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-28 14:25:50 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x6741138)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x30bcd18)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x38311e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x32ad8b8)]: 0 failure(s)
2024-04-28 14:26:02 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x6741138)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x30bcd18)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x38311e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x32ad8b8)]: 0 failure(s)
2024-04-28 14:26:14 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x6741138)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x30bcd18)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x38311e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x32ad8b8)]: 0 failure(s)
2024-04-28 14:26:25 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x6741138)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x30bcd18)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x38311e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x32ad8b8)]: 0 failure(s)
2024-04-28 14:26:32 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.8859  0.8684  0.8649  0.8504  0.8494  0.8414  0.8325  0.8325  0.8268  0.8247  0.8210  0.8210  0.8164  0.8164  0.8151  0.8151
[17 : 32]:	0.8151  0.8151  0.8149  0.8149  0.8149  0.8149  0.8145  0.8141  0.8134  0.8103  0.7991  0.7979  0.7956  0.7939  0.7939  0.7939
[33 : 48]:	0.7918  0.7906  0.7906  0.7879  0.7830  0.7791  0.7791  0.7790  0.7751  0.7727  0.7726  0.7699  0.7699  0.7690  0.7676  0.7667
[49 : 64]:	0.7663  0.7644  0.7631  0.7631  0.7621  0.7606  0.7595  0.7590  0.7576  0.7576  0.7459  0.7453  0.7452  0.7452  0.7444  0.7425
2024-04-28 14:26:32 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-28 14:26:32 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-28 14:28:21 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #449: GFLOPs: 657.8654. Time: 2816.5328 us. Best GFLOPs: 1423.2375
2024-04-28 14:28:21 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #450: GFLOPs: 659.6068. Time: 2809.0969 us. Best GFLOPs: 1423.2375
2024-04-28 14:28:21 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #451: GFLOPs: 1145.4457. Time: 1617.6230 us. Best GFLOPs: 1423.2375
2024-04-28 14:28:21 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #452: GFLOPs: 1290.9916. Time: 1435.2528 us. Best GFLOPs: 1423.2375
2024-04-28 14:28:21 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #453: GFLOPs: 950.0555. Time: 1950.3064 us. Best GFLOPs: 1423.2375
2024-04-28 14:28:21 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #454: GFLOPs: 1313.2948. Time: 1410.8785 us. Best GFLOPs: 1423.2375
2024-04-28 14:28:21 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #455: GFLOPs: 1246.4744. Time: 1486.5122 us. Best GFLOPs: 1423.2375
2024-04-28 14:28:21 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #456: GFLOPs: 1033.8330. Time: 1792.2617 us. Best GFLOPs: 1423.2375
2024-04-28 14:28:21 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #457: GFLOPs: 1001.5293. Time: 1850.0700 us. Best GFLOPs: 1423.2375
2024-04-28 14:28:21 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #458: GFLOPs: 1127.0397. Time: 1644.0409 us. Best GFLOPs: 1423.2375
2024-04-28 14:28:21 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #459: GFLOPs: 1273.4171. Time: 1455.0608 us. Best GFLOPs: 1423.2375
2024-04-28 14:28:21 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #460: GFLOPs: 1018.3551. Time: 1819.5022 us. Best GFLOPs: 1423.2375
2024-04-28 14:28:21 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #461: GFLOPs: 983.7389. Time: 1883.5276 us. Best GFLOPs: 1423.2375
2024-04-28 14:28:21 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #462: GFLOPs: 1295.0914. Time: 1430.7093 us. Best GFLOPs: 1423.2375
2024-04-28 14:28:21 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #463: GFLOPs: 1176.0090. Time: 1575.5826 us. Best GFLOPs: 1423.2375
2024-04-28 14:28:21 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #464: GFLOPs: 1363.2393. Time: 1359.1886 us. Best GFLOPs: 1423.2375
2024-04-28 14:28:21 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #465: GFLOPs: 1318.0958. Time: 1405.7395 us. Best GFLOPs: 1423.2375
2024-04-28 14:28:21 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #466: GFLOPs: 1340.3569. Time: 1382.3925 us. Best GFLOPs: 1423.2375
2024-04-28 14:28:21 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #467: GFLOPs: 1238.8758. Time: 1495.6296 us. Best GFLOPs: 1423.2375
2024-04-28 14:28:21 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #468: GFLOPs: 1094.5185. Time: 1692.8899 us. Best GFLOPs: 1423.2375
2024-04-28 14:28:21 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #469: GFLOPs: 1003.0680. Time: 1847.2319 us. Best GFLOPs: 1423.2375
2024-04-28 14:28:21 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #470: GFLOPs: 1171.7124. Time: 1581.3602 us. Best GFLOPs: 1423.2375
2024-04-28 14:28:21 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #471: GFLOPs: 1099.6154. Time: 1685.0431 us. Best GFLOPs: 1423.2375
2024-04-28 14:28:21 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #472: GFLOPs: 1191.1734. Time: 1555.5245 us. Best GFLOPs: 1423.2375
2024-04-28 14:28:21 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #473: GFLOPs: 1312.1212. Time: 1412.1403 us. Best GFLOPs: 1423.2375
2024-04-28 14:28:21 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #474: GFLOPs: 1134.8734. Time: 1632.6926 us. Best GFLOPs: 1423.2375
2024-04-28 14:28:21 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #475: GFLOPs: 1184.4799. Time: 1564.3147 us. Best GFLOPs: 1423.2375
2024-04-28 14:28:21 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #476: GFLOPs: 1177.3540. Time: 1573.7827 us. Best GFLOPs: 1423.2375
2024-04-28 14:28:21 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #477: GFLOPs: 1215.4400. Time: 1524.4679 us. Best GFLOPs: 1423.2375
2024-04-28 14:28:21 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #478: GFLOPs: 1308.1104. Time: 1416.4701 us. Best GFLOPs: 1423.2375
2024-04-28 14:28:21 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #479: GFLOPs: 986.5902. Time: 1878.0841 us. Best GFLOPs: 1423.2375
2024-04-28 14:28:21 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #480: GFLOPs: 1313.7623. Time: 1410.3764 us. Best GFLOPs: 1423.2375
2024-04-28 14:28:21 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #481: GFLOPs: 1070.7769. Time: 1730.4253 us. Best GFLOPs: 1423.2375
2024-04-28 14:28:21 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #482: GFLOPs: 1071.1028. Time: 1729.8987 us. Best GFLOPs: 1423.2375
2024-04-28 14:28:21 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #483: GFLOPs: 1115.2958. Time: 1661.3523 us. Best GFLOPs: 1423.2375
2024-04-28 14:28:21 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #484: GFLOPs: 849.6739. Time: 2180.7182 us. Best GFLOPs: 1423.2375
2024-04-28 14:28:21 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #485: GFLOPs: 1204.8727. Time: 1537.8383 us. Best GFLOPs: 1423.2375
2024-04-28 14:28:21 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #486: GFLOPs: 1140.3511. Time: 1624.8499 us. Best GFLOPs: 1423.2375
2024-04-28 14:28:21 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #487: GFLOPs: 1108.5852. Time: 1671.4091 us. Best GFLOPs: 1423.2375
2024-04-28 14:28:21 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #488: GFLOPs: 1003.8804. Time: 1845.7371 us. Best GFLOPs: 1423.2375
2024-04-28 14:28:21 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #489: GFLOPs: 882.5609. Time: 2099.4578 us. Best GFLOPs: 1423.2375
2024-04-28 14:28:21 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #490: GFLOPs: 1170.7462. Time: 1582.6652 us. Best GFLOPs: 1423.2375
2024-04-28 14:28:21 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #491: GFLOPs: 1173.9993. Time: 1578.2798 us. Best GFLOPs: 1423.2375
2024-04-28 14:28:21 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #492: GFLOPs: 1113.8663. Time: 1663.4845 us. Best GFLOPs: 1423.2375
2024-04-28 14:28:21 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #493: GFLOPs: 937.3411. Time: 1976.7611 us. Best GFLOPs: 1423.2375
2024-04-28 14:28:21 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #494: GFLOPs: 914.4370. Time: 2026.2733 us. Best GFLOPs: 1423.2375
2024-04-28 14:28:21 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #495: GFLOPs: 1138.4350. Time: 1627.5846 us. Best GFLOPs: 1423.2375
2024-04-28 14:28:21 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #496: GFLOPs: 1009.6331. Time: 1835.2205 us. Best GFLOPs: 1423.2375
2024-04-28 14:28:21 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #497: GFLOPs: 1229.1093. Time: 1507.5139 us. Best GFLOPs: 1423.2375
2024-04-28 14:28:21 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #498: GFLOPs: 1134.8559. Time: 1632.7178 us. Best GFLOPs: 1423.2375
2024-04-28 14:28:21 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #499: GFLOPs: 1191.6595. Time: 1554.8900 us. Best GFLOPs: 1423.2375
2024-04-28 14:28:21 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #500: GFLOPs: 900.8619. Time: 2056.8074 us. Best GFLOPs: 1423.2375
2024-04-28 14:28:21 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #501: GFLOPs: 1192.0366. Time: 1554.3980 us. Best GFLOPs: 1423.2375
2024-04-28 14:28:21 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #502: GFLOPs: 1147.0608. Time: 1615.3454 us. Best GFLOPs: 1423.2375
2024-04-28 14:28:21 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #503: GFLOPs: 1230.4121. Time: 1505.9177 us. Best GFLOPs: 1423.2375
2024-04-28 14:28:21 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #504: GFLOPs: 1019.9604. Time: 1816.6386 us. Best GFLOPs: 1423.2375
2024-04-28 14:28:21 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #505: GFLOPs: 447.4821. Time: 4140.7232 us. Best GFLOPs: 1423.2375
2024-04-28 14:28:21 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #506: GFLOPs: 740.6663. Time: 2501.6654 us. Best GFLOPs: 1423.2375
2024-04-28 14:28:21 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #507: GFLOPs: 122.9658. Time: 15068.4100 us. Best GFLOPs: 1423.2375
2024-04-28 14:28:21 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #508: GFLOPs: 1043.6510. Time: 1775.4013 us. Best GFLOPs: 1423.2375
2024-04-28 14:28:21 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #509: GFLOPs: 991.0141. Time: 1869.7002 us. Best GFLOPs: 1423.2375
2024-04-28 14:28:21 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #510: GFLOPs: 10.8403. Time: 170927.3827 us. Best GFLOPs: 1423.2375
2024-04-28 14:28:21 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #511: GFLOPs: 101.9850. Time: 18168.3518 us. Best GFLOPs: 1423.2375
2024-04-28 14:28:21 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #512: GFLOPs: 64.8067. Time: 28591.1588 us. Best GFLOPs: 1423.2375
2024-04-28 14:37:10 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-28 14:37:11 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-28 14:37:16 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x6741138)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x30bcd18)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x38311e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x32ad8b8)]: 0 failure(s)
2024-04-28 14:37:16 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-28 14:37:29 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x6741138)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x30bcd18)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x38311e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x32ad8b8)]: 0 failure(s)
2024-04-28 14:37:41 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x6741138)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x30bcd18)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x38311e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x32ad8b8)]: 0 failure(s)
2024-04-28 14:37:52 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x6741138)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x30bcd18)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x38311e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x32ad8b8)]: 0 failure(s)
2024-04-28 14:38:04 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x6741138)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x30bcd18)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x38311e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x32ad8b8)]: 0 failure(s)
2024-04-28 14:38:11 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.8879  0.8830  0.8721  0.8721  0.8721  0.8721  0.8673  0.8673  0.8650  0.8552  0.8406  0.8401  0.8301  0.8278  0.8246  0.8236
[17 : 32]:	0.8218  0.8211  0.8211  0.8211  0.8204  0.8199  0.8199  0.8180  0.8169  0.8131  0.8129  0.8100  0.8080  0.8063  0.8063  0.8030
[33 : 48]:	0.8027  0.8004  0.8004  0.7978  0.7971  0.7971  0.7971  0.7964  0.7890  0.7836  0.7836  0.7836  0.7836  0.7836  0.7829  0.7826
[49 : 64]:	0.7820  0.7796  0.7795  0.7767  0.7766  0.7752  0.7752  0.7717  0.7713  0.7682  0.7682  0.7666  0.7666  0.7664  0.7651  0.7651
2024-04-28 14:38:11 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-28 14:38:11 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-28 14:40:00 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #513: GFLOPs: 972.3544. Time: 1905.5802 us. Best GFLOPs: 1423.2375
2024-04-28 14:40:00 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #514: GFLOPs: 1226.6170. Time: 1510.5769 us. Best GFLOPs: 1423.2375
2024-04-28 14:40:00 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #515: GFLOPs: 965.2784. Time: 1919.5491 us. Best GFLOPs: 1423.2375
2024-04-28 14:40:00 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #516: GFLOPs: 1390.2049. Time: 1332.8247 us. Best GFLOPs: 1423.2375
2024-04-28 14:40:00 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #517: GFLOPs: 1422.4894. Time: 1302.5752 us. Best GFLOPs: 1423.2375
2024-04-28 14:40:00 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #518: GFLOPs: 1316.3665. Time: 1407.5862 us. Best GFLOPs: 1423.2375
2024-04-28 14:40:00 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #519: GFLOPs: 1269.5618. Time: 1459.4795 us. Best GFLOPs: 1423.2375
2024-04-28 14:40:00 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #520: GFLOPs: 1337.8457. Time: 1384.9873 us. Best GFLOPs: 1423.2375
2024-04-28 14:40:00 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #521: GFLOPs: 1285.0043. Time: 1441.9402 us. Best GFLOPs: 1423.2375
2024-04-28 14:40:00 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #522: GFLOPs: 1175.6371. Time: 1576.0810 us. Best GFLOPs: 1423.2375
2024-04-28 14:40:00 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #523: GFLOPs: 1232.3413. Time: 1503.5602 us. Best GFLOPs: 1423.2375
2024-04-28 14:40:00 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #524: GFLOPs: 1198.3196. Time: 1546.2480 us. Best GFLOPs: 1423.2375
2024-04-28 14:40:00 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #525: GFLOPs: 1096.8763. Time: 1689.2510 us. Best GFLOPs: 1423.2375
2024-04-28 14:40:00 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #526: GFLOPs: 1203.1863. Time: 1539.9937 us. Best GFLOPs: 1423.2375
2024-04-28 14:40:00 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #527: GFLOPs: 1068.6980. Time: 1733.7913 us. Best GFLOPs: 1423.2375
2024-04-28 14:40:00 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #528: GFLOPs: 1159.7532. Time: 1597.6669 us. Best GFLOPs: 1423.2375
2024-04-28 14:40:00 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #529: GFLOPs: 1150.4895. Time: 1610.5313 us. Best GFLOPs: 1423.2375
2024-04-28 14:40:00 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #530: GFLOPs: 1372.2956. Time: 1350.2188 us. Best GFLOPs: 1423.2375
2024-04-28 14:40:00 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #531: GFLOPs: 1197.1375. Time: 1547.7749 us. Best GFLOPs: 1423.2375
2024-04-28 14:40:00 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #532: GFLOPs: 977.5879. Time: 1895.3787 us. Best GFLOPs: 1423.2375
2024-04-28 14:40:00 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #533: GFLOPs: 1132.0381. Time: 1636.7818 us. Best GFLOPs: 1423.2375
2024-04-28 14:40:00 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #534: GFLOPs: 1107.4087. Time: 1673.1847 us. Best GFLOPs: 1423.2375
2024-04-28 14:40:00 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #535: GFLOPs: 1134.0316. Time: 1633.9045 us. Best GFLOPs: 1423.2375
2024-04-28 14:40:00 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #536: GFLOPs: 1172.5774. Time: 1580.1937 us. Best GFLOPs: 1423.2375
2024-04-28 14:40:00 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #537: GFLOPs: 1216.9199. Time: 1522.6140 us. Best GFLOPs: 1423.2375
2024-04-28 14:40:00 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #538: GFLOPs: 1294.0216. Time: 1431.8921 us. Best GFLOPs: 1423.2375
2024-04-28 14:40:00 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #539: GFLOPs: 1102.2044. Time: 1681.0850 us. Best GFLOPs: 1423.2375
2024-04-28 14:40:00 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #540: GFLOPs: 1123.6516. Time: 1648.9981 us. Best GFLOPs: 1423.2375
2024-04-28 14:40:00 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #541: GFLOPs: 957.3450. Time: 1935.4561 us. Best GFLOPs: 1423.2375
2024-04-28 14:40:00 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #542: GFLOPs: 1271.5221. Time: 1457.2294 us. Best GFLOPs: 1423.2375
2024-04-28 14:40:00 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #543: GFLOPs: 1213.7649. Time: 1526.5718 us. Best GFLOPs: 1423.2375
2024-04-28 14:40:00 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #544: GFLOPs: 1108.5794. Time: 1671.4179 us. Best GFLOPs: 1423.2375
2024-04-28 14:40:00 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #545: GFLOPs: 1037.2485. Time: 1786.3601 us. Best GFLOPs: 1423.2375
2024-04-28 14:40:00 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #546: GFLOPs: 1352.0150. Time: 1370.4724 us. Best GFLOPs: 1423.2375
2024-04-28 14:40:00 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #547: GFLOPs: 1191.4525. Time: 1555.1601 us. Best GFLOPs: 1423.2375
2024-04-28 14:40:00 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #548: GFLOPs: 1112.4964. Time: 1665.5329 us. Best GFLOPs: 1423.2375
2024-04-28 14:40:00 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #549: GFLOPs: 1315.3796. Time: 1408.6422 us. Best GFLOPs: 1423.2375
2024-04-28 14:40:00 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #550: GFLOPs: 1225.9036. Time: 1511.4559 us. Best GFLOPs: 1423.2375
2024-04-28 14:40:00 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #551: GFLOPs: 1030.8158. Time: 1797.5076 us. Best GFLOPs: 1423.2375
2024-04-28 14:40:00 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #552: GFLOPs: 1256.5850. Time: 1474.5515 us. Best GFLOPs: 1423.2375
2024-04-28 14:40:00 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #553: GFLOPs: 1153.7856. Time: 1605.9304 us. Best GFLOPs: 1423.2375
2024-04-28 14:40:00 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #554: GFLOPs: 973.9534. Time: 1902.4517 us. Best GFLOPs: 1423.2375
2024-04-28 14:40:00 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #555: GFLOPs: 1143.3495. Time: 1620.5888 us. Best GFLOPs: 1423.2375
2024-04-28 14:40:00 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #556: GFLOPs: 1200.2627. Time: 1543.7448 us. Best GFLOPs: 1423.2375
2024-04-28 14:40:00 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #557: GFLOPs: 1331.7367. Time: 1391.3406 us. Best GFLOPs: 1423.2375
2024-04-28 14:40:00 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #558: GFLOPs: 955.5161. Time: 1939.1608 us. Best GFLOPs: 1423.2375
2024-04-28 14:40:00 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #559: GFLOPs: 1117.5822. Time: 1657.9536 us. Best GFLOPs: 1423.2375
2024-04-28 14:40:00 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #560: GFLOPs: 1504.7320. Time: 1231.3816 us. Best GFLOPs: 1504.7320
2024-04-28 14:40:00 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #561: GFLOPs: 306.6984. Time: 6041.4373 us. Best GFLOPs: 1504.7320
2024-04-28 14:40:00 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #562: GFLOPs: 1246.5357. Time: 1486.4390 us. Best GFLOPs: 1504.7320
2024-04-28 14:40:00 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #563: GFLOPs: 937.6210. Time: 1976.1710 us. Best GFLOPs: 1504.7320
2024-04-28 14:40:00 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #564: GFLOPs: 1248.8839. Time: 1483.6441 us. Best GFLOPs: 1504.7320
2024-04-28 14:40:00 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #565: GFLOPs: 1228.1712. Time: 1508.6653 us. Best GFLOPs: 1504.7320
2024-04-28 14:40:00 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #566: GFLOPs: 1264.4595. Time: 1465.3686 us. Best GFLOPs: 1504.7320
2024-04-28 14:40:00 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #567: GFLOPs: 1099.1489. Time: 1685.7583 us. Best GFLOPs: 1504.7320
2024-04-28 14:40:00 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #568: GFLOPs: 937.2631. Time: 1976.9255 us. Best GFLOPs: 1504.7320
2024-04-28 14:40:00 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #569: GFLOPs: 968.4041. Time: 1913.3534 us. Best GFLOPs: 1504.7320
2024-04-28 14:40:00 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #570: GFLOPs: 1007.1205. Time: 1839.7990 us. Best GFLOPs: 1504.7320
2024-04-28 14:40:00 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #571: GFLOPs: 947.4936. Time: 1955.5797 us. Best GFLOPs: 1504.7320
2024-04-28 14:40:00 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #572: GFLOPs: 1186.4541. Time: 1561.7117 us. Best GFLOPs: 1504.7320
2024-04-28 14:40:00 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #573: GFLOPs: 1187.3692. Time: 1560.5082 us. Best GFLOPs: 1504.7320
2024-04-28 14:40:00 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #574: GFLOPs: 64.2562. Time: 28836.0978 us. Best GFLOPs: 1504.7320
2024-04-28 14:40:00 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #575: GFLOPs: 54.9057. Time: 33746.9160 us. Best GFLOPs: 1504.7320
2024-04-28 14:40:00 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #576: GFLOPs: 15.8170. Time: 117145.8693 us. Best GFLOPs: 1504.7320
2024-04-28 15:48:53 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-28 15:48:55 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-28 15:48:59 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x6741138)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x30bcd18)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x38311e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x32ad8b8)]: 0 failure(s)
2024-04-28 15:48:59 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-28 15:49:12 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x6741138)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x30bcd18)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x38311e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x32ad8b8)]: 0 failure(s)
2024-04-28 15:49:24 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x6741138)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x30bcd18)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x38311e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x32ad8b8)]: 0 failure(s)
2024-04-28 15:49:35 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x6741138)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x30bcd18)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x38311e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x32ad8b8)]: 0 failure(s)
2024-04-28 15:49:47 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x6741138)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x30bcd18)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x38311e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x32ad8b8)]: 0 failure(s)
2024-04-28 15:49:54 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.8300  0.8188  0.8185  0.8185  0.8185  0.8170  0.8165  0.8152  0.8130  0.8130  0.8118  0.8092  0.8039  0.7944  0.7920  0.7918
[17 : 32]:	0.7893  0.7822  0.7797  0.7792  0.7773  0.7740  0.7719  0.7716  0.7674  0.7674  0.7651  0.7651  0.7650  0.7635  0.7635  0.7629
[33 : 48]:	0.7617  0.7617  0.7608  0.7576  0.7517  0.7514  0.7514  0.7514  0.7514  0.7508  0.7503  0.7503  0.7498  0.7481  0.7481  0.7477
[49 : 64]:	0.7466  0.7457  0.7438  0.7421  0.7414  0.7414  0.7410  0.7390  0.7390  0.7371  0.7353  0.7353  0.7333  0.7318  0.7303  0.7283
2024-04-28 15:49:54 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-28 15:49:54 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-28 15:51:47 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #577: GFLOPs: 1286.3544. Time: 1440.4268 us. Best GFLOPs: 1504.7320
2024-04-28 15:51:47 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #578: GFLOPs: 1376.0394. Time: 1346.5452 us. Best GFLOPs: 1504.7320
2024-04-28 15:51:47 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #579: GFLOPs: 1082.2400. Time: 1712.0966 us. Best GFLOPs: 1504.7320
2024-04-28 15:51:47 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #580: GFLOPs: 1094.4351. Time: 1693.0190 us. Best GFLOPs: 1504.7320
2024-04-28 15:51:47 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #581: GFLOPs: 1271.0608. Time: 1457.7583 us. Best GFLOPs: 1504.7320
2024-04-28 15:51:47 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #582: GFLOPs: 1257.8673. Time: 1473.0484 us. Best GFLOPs: 1504.7320
2024-04-28 15:51:47 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #583: GFLOPs: 987.9845. Time: 1875.4336 us. Best GFLOPs: 1504.7320
2024-04-28 15:51:47 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #584: GFLOPs: 1146.6391. Time: 1615.9394 us. Best GFLOPs: 1504.7320
2024-04-28 15:51:47 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #585: GFLOPs: 1335.8505. Time: 1387.0559 us. Best GFLOPs: 1504.7320
2024-04-28 15:51:47 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #586: GFLOPs: 1353.8114. Time: 1368.6539 us. Best GFLOPs: 1504.7320
2024-04-28 15:51:47 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #587: GFLOPs: 1264.5720. Time: 1465.2382 us. Best GFLOPs: 1504.7320
2024-04-28 15:51:47 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #588: GFLOPs: 956.3163. Time: 1937.5381 us. Best GFLOPs: 1504.7320
2024-04-28 15:51:47 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #589: GFLOPs: 1189.3877. Time: 1557.8599 us. Best GFLOPs: 1504.7320
2024-04-28 15:51:47 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #590: GFLOPs: 1170.8327. Time: 1582.5483 us. Best GFLOPs: 1504.7320
2024-04-28 15:51:47 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #591: GFLOPs: 122.0237. Time: 15184.7484 us. Best GFLOPs: 1504.7320
2024-04-28 15:51:47 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #592: GFLOPs: 1214.5845. Time: 1525.5417 us. Best GFLOPs: 1504.7320
2024-04-28 15:51:47 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #593: GFLOPs: 1004.5064. Time: 1844.5868 us. Best GFLOPs: 1504.7320
2024-04-28 15:51:47 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #594: GFLOPs: 1089.6360. Time: 1700.4755 us. Best GFLOPs: 1504.7320
2024-04-28 15:51:47 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #595: GFLOPs: 1110.1677. Time: 1669.0266 us. Best GFLOPs: 1504.7320
2024-04-28 15:51:47 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #596: GFLOPs: 1239.6866. Time: 1494.6514 us. Best GFLOPs: 1504.7320
2024-04-28 15:51:47 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #597: GFLOPs: 1210.3790. Time: 1530.8422 us. Best GFLOPs: 1504.7320
2024-04-28 15:51:47 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #598: GFLOPs: 1207.0253. Time: 1535.0957 us. Best GFLOPs: 1504.7320
2024-04-28 15:51:47 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #599: GFLOPs: 1399.6188. Time: 1323.8600 us. Best GFLOPs: 1504.7320
2024-04-28 15:51:47 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #600: GFLOPs: 917.0844. Time: 2020.4240 us. Best GFLOPs: 1504.7320
2024-04-28 15:51:47 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #601: GFLOPs: 1180.0569. Time: 1570.1780 us. Best GFLOPs: 1504.7320
2024-04-28 15:51:47 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #602: GFLOPs: 1158.7260. Time: 1599.0832 us. Best GFLOPs: 1504.7320
2024-04-28 15:51:47 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #603: GFLOPs: 753.0126. Time: 2460.6487 us. Best GFLOPs: 1504.7320
2024-04-28 15:51:47 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #604: GFLOPs: 747.2587. Time: 2479.5956 us. Best GFLOPs: 1504.7320
2024-04-28 15:51:47 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #605: GFLOPs: 1228.4534. Time: 1508.3188 us. Best GFLOPs: 1504.7320
2024-04-28 15:51:47 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #606: GFLOPs: 1013.4345. Time: 1828.3365 us. Best GFLOPs: 1504.7320
2024-04-28 15:51:47 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #607: GFLOPs: 1350.6847. Time: 1371.8222 us. Best GFLOPs: 1504.7320
2024-04-28 15:51:47 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #608: GFLOPs: 1380.3126. Time: 1342.3766 us. Best GFLOPs: 1504.7320
2024-04-28 15:51:47 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #609: GFLOPs: 1045.8456. Time: 1771.6757 us. Best GFLOPs: 1504.7320
2024-04-28 15:51:47 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #610: GFLOPs: 1136.0742. Time: 1630.9668 us. Best GFLOPs: 1504.7320
2024-04-28 15:51:47 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #611: GFLOPs: 1212.0357. Time: 1528.7498 us. Best GFLOPs: 1504.7320
2024-04-28 15:51:47 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #612: GFLOPs: 1079.9482. Time: 1715.7299 us. Best GFLOPs: 1504.7320
2024-04-28 15:51:47 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #613: GFLOPs: 998.9385. Time: 1854.8683 us. Best GFLOPs: 1504.7320
2024-04-28 15:51:47 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #614: GFLOPs: 1153.4305. Time: 1606.4248 us. Best GFLOPs: 1504.7320
2024-04-28 15:51:47 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #615: GFLOPs: 1230.9998. Time: 1505.1987 us. Best GFLOPs: 1504.7320
2024-04-28 15:51:47 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #616: GFLOPs: 1082.2701. Time: 1712.0489 us. Best GFLOPs: 1504.7320
2024-04-28 15:51:47 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #617: GFLOPs: 1086.7625. Time: 1704.9717 us. Best GFLOPs: 1504.7320
2024-04-28 15:51:47 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #618: GFLOPs: 1106.9161. Time: 1673.9293 us. Best GFLOPs: 1504.7320
2024-04-28 15:51:47 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #619: GFLOPs: 1114.1311. Time: 1663.0891 us. Best GFLOPs: 1504.7320
2024-04-28 15:51:47 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #620: GFLOPs: 1307.6500. Time: 1416.9689 us. Best GFLOPs: 1504.7320
2024-04-28 15:51:47 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #621: GFLOPs: 1027.9190. Time: 1802.5732 us. Best GFLOPs: 1504.7320
2024-04-28 15:51:47 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #622: GFLOPs: 1158.0230. Time: 1600.0540 us. Best GFLOPs: 1504.7320
2024-04-28 15:51:47 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #623: GFLOPs: 1311.0254. Time: 1413.3207 us. Best GFLOPs: 1504.7320
2024-04-28 15:51:47 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #624: GFLOPs: 1303.4729. Time: 1421.5097 us. Best GFLOPs: 1504.7320
2024-04-28 15:51:47 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #625: GFLOPs: 1171.0658. Time: 1582.2333 us. Best GFLOPs: 1504.7320
2024-04-28 15:51:47 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #626: GFLOPs: 1308.3997. Time: 1416.1569 us. Best GFLOPs: 1504.7320
2024-04-28 15:51:47 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #627: GFLOPs: 1283.9014. Time: 1443.1788 us. Best GFLOPs: 1504.7320
2024-04-28 15:51:47 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #628: GFLOPs: 1274.7493. Time: 1453.5402 us. Best GFLOPs: 1504.7320
2024-04-28 15:51:47 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #629: GFLOPs: 1268.5838. Time: 1460.6046 us. Best GFLOPs: 1504.7320
2024-04-28 15:51:47 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #630: GFLOPs: 1326.2763. Time: 1397.0689 us. Best GFLOPs: 1504.7320
2024-04-28 15:51:47 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #631: GFLOPs: 1107.9955. Time: 1672.2986 us. Best GFLOPs: 1504.7320
2024-04-28 15:51:47 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #632: GFLOPs: 1168.3270. Time: 1585.9425 us. Best GFLOPs: 1504.7320
2024-04-28 15:51:47 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #633: GFLOPs: 1146.8470. Time: 1615.6465 us. Best GFLOPs: 1504.7320
2024-04-28 15:51:47 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #634: GFLOPs: 856.0678. Time: 2164.4306 us. Best GFLOPs: 1504.7320
2024-04-28 15:51:47 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #635: GFLOPs: 1129.8176. Time: 1639.9987 us. Best GFLOPs: 1504.7320
2024-04-28 15:51:47 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #636: GFLOPs: 920.4418. Time: 2013.0543 us. Best GFLOPs: 1504.7320
2024-04-28 15:51:47 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #637: GFLOPs: 1330.9430. Time: 1392.1703 us. Best GFLOPs: 1504.7320
2024-04-28 15:51:47 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #638: GFLOPs: 108.5909. Time: 17063.1103 us. Best GFLOPs: 1504.7320
2024-04-28 15:51:47 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #639: GFLOPs: 19.6761. Time: 94170.1497 us. Best GFLOPs: 1504.7320
2024-04-28 15:51:47 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #640: GFLOPs: 25.8502. Time: 71678.3837 us. Best GFLOPs: 1504.7320
2024-04-28 16:38:25 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-28 16:38:27 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-28 16:38:31 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x6741138)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x30bcd18)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x38311e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x32ad8b8)]: 0 failure(s)
2024-04-28 16:38:31 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-28 16:38:44 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x6741138)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x30bcd18)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x38311e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x32ad8b8)]: 0 failure(s)
2024-04-28 16:38:56 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x6741138)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x30bcd18)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x38311e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x32ad8b8)]: 0 failure(s)
2024-04-28 16:39:07 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x6741138)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x30bcd18)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x38311e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x32ad8b8)]: 0 failure(s)
2024-04-28 16:39:19 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x6741138)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x30bcd18)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x38311e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x32ad8b8)]: 0 failure(s)
2024-04-28 16:39:26 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.8839  0.8839  0.8755  0.8715  0.8598  0.8529  0.8418  0.8357  0.8357  0.8295  0.8276  0.8254  0.8240  0.8140  0.8121  0.8067
[17 : 32]:	0.8017  0.8001  0.7989  0.7988  0.7975  0.7948  0.7885  0.7881  0.7877  0.7868  0.7864  0.7864  0.7864  0.7848  0.7833  0.7816
[33 : 48]:	0.7798  0.7788  0.7788  0.7787  0.7774  0.7772  0.7721  0.7721  0.7718  0.7673  0.7639  0.7624  0.7615  0.7613  0.7582  0.7542
[49 : 64]:	0.7531  0.7529  0.7494  0.7474  0.7468  0.7447  0.7414  0.7389  0.7384  0.7365  0.7356  0.7319  0.7310  0.7294  0.7289  0.7287
2024-04-28 16:39:26 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-28 16:39:26 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-28 16:41:24 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #641: GFLOPs: 1315.7359. Time: 1408.2608 us. Best GFLOPs: 1504.7320
2024-04-28 16:41:24 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #642: GFLOPs: 1183.8748. Time: 1565.1142 us. Best GFLOPs: 1504.7320
2024-04-28 16:41:24 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #643: GFLOPs: 723.4640. Time: 2561.1494 us. Best GFLOPs: 1504.7320
2024-04-28 16:41:24 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #644: GFLOPs: 1470.9896. Time: 1259.6278 us. Best GFLOPs: 1504.7320
2024-04-28 16:41:24 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #645: GFLOPs: 1088.7597. Time: 1701.8442 us. Best GFLOPs: 1504.7320
2024-04-28 16:41:24 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #646: GFLOPs: 965.1040. Time: 1919.8960 us. Best GFLOPs: 1504.7320
2024-04-28 16:41:24 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #647: GFLOPs: 1024.9945. Time: 1807.7164 us. Best GFLOPs: 1504.7320
2024-04-28 16:41:24 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #648: GFLOPs: 974.1383. Time: 1902.0906 us. Best GFLOPs: 1504.7320
2024-04-28 16:41:24 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #649: GFLOPs: 1177.9821. Time: 1572.9436 us. Best GFLOPs: 1504.7320
2024-04-28 16:41:24 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #650: GFLOPs: 1013.3491. Time: 1828.4907 us. Best GFLOPs: 1504.7320
2024-04-28 16:41:24 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #651: GFLOPs: 1389.0996. Time: 1333.8852 us. Best GFLOPs: 1504.7320
2024-04-28 16:41:24 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #652: GFLOPs: 1149.9172. Time: 1611.3328 us. Best GFLOPs: 1504.7320
2024-04-28 16:41:24 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #653: GFLOPs: 1210.6026. Time: 1530.5595 us. Best GFLOPs: 1504.7320
2024-04-28 16:41:24 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #654: GFLOPs: 1191.5467. Time: 1555.0371 us. Best GFLOPs: 1504.7320
2024-04-28 16:41:24 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #655: GFLOPs: 1336.2617. Time: 1386.6290 us. Best GFLOPs: 1504.7320
2024-04-28 16:41:24 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #656: GFLOPs: 1185.6784. Time: 1562.7334 us. Best GFLOPs: 1504.7320
2024-04-28 16:41:24 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #657: GFLOPs: 1157.3639. Time: 1600.9651 us. Best GFLOPs: 1504.7320
2024-04-28 16:41:24 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #658: GFLOPs: 1232.2081. Time: 1503.7227 us. Best GFLOPs: 1504.7320
2024-04-28 16:41:24 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #659: GFLOPs: 1109.7456. Time: 1669.6614 us. Best GFLOPs: 1504.7320
2024-04-28 16:41:24 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #660: GFLOPs: 1036.6557. Time: 1787.3816 us. Best GFLOPs: 1504.7320
2024-04-28 16:41:24 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #661: GFLOPs: 1302.5577. Time: 1422.5084 us. Best GFLOPs: 1504.7320
2024-04-28 16:41:24 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #662: GFLOPs: 1214.4165. Time: 1525.7527 us. Best GFLOPs: 1504.7320
2024-04-28 16:41:24 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #663: GFLOPs: 1258.2518. Time: 1472.5982 us. Best GFLOPs: 1504.7320
2024-04-28 16:41:24 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #664: GFLOPs: 1030.7363. Time: 1797.6464 us. Best GFLOPs: 1504.7320
2024-04-28 16:41:24 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #665: GFLOPs: 917.0436. Time: 2020.5139 us. Best GFLOPs: 1504.7320
2024-04-28 16:41:24 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #666: GFLOPs: 1065.7892. Time: 1738.5233 us. Best GFLOPs: 1504.7320
2024-04-28 16:41:24 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #667: GFLOPs: 113.9213. Time: 16264.7299 us. Best GFLOPs: 1504.7320
2024-04-28 16:41:24 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #668: GFLOPs: 113.6151. Time: 16308.5693 us. Best GFLOPs: 1504.7320
2024-04-28 16:41:24 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #669: GFLOPs: 113.9330. Time: 16263.0656 us. Best GFLOPs: 1504.7320
2024-04-28 16:41:24 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #670: GFLOPs: 1196.7462. Time: 1548.2809 us. Best GFLOPs: 1504.7320
2024-04-28 16:41:24 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #671: GFLOPs: 1111.9882. Time: 1666.2941 us. Best GFLOPs: 1504.7320
2024-04-28 16:41:24 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #672: GFLOPs: 1112.7277. Time: 1665.1867 us. Best GFLOPs: 1504.7320
2024-04-28 16:41:24 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #673: GFLOPs: 1194.8549. Time: 1550.7316 us. Best GFLOPs: 1504.7320
2024-04-28 16:41:24 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #674: GFLOPs: 1116.4354. Time: 1659.6566 us. Best GFLOPs: 1504.7320
2024-04-28 16:41:24 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #675: GFLOPs: 1022.4025. Time: 1812.2993 us. Best GFLOPs: 1504.7320
2024-04-28 16:41:24 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #676: GFLOPs: 1273.0744. Time: 1455.4525 us. Best GFLOPs: 1504.7320
2024-04-28 16:41:24 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #677: GFLOPs: 1217.0229. Time: 1522.4852 us. Best GFLOPs: 1504.7320
2024-04-28 16:41:24 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #678: GFLOPs: 1228.4067. Time: 1508.3761 us. Best GFLOPs: 1504.7320
2024-04-28 16:41:24 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #679: GFLOPs: 1035.1220. Time: 1790.0300 us. Best GFLOPs: 1504.7320
2024-04-28 16:41:24 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #680: GFLOPs: 136.4153. Time: 13582.7804 us. Best GFLOPs: 1504.7320
2024-04-28 16:41:24 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #681: GFLOPs: 1189.1131. Time: 1558.2196 us. Best GFLOPs: 1504.7320
2024-04-28 16:41:24 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #682: GFLOPs: 830.6542. Time: 2230.6506 us. Best GFLOPs: 1504.7320
2024-04-28 16:41:24 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #683: GFLOPs: 1219.7775. Time: 1519.0469 us. Best GFLOPs: 1504.7320
2024-04-28 16:41:24 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #684: GFLOPs: 1185.1199. Time: 1563.4699 us. Best GFLOPs: 1504.7320
2024-04-28 16:41:24 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #685: GFLOPs: 1017.2103. Time: 1821.5500 us. Best GFLOPs: 1504.7320
2024-04-28 16:41:24 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #686: GFLOPs: 939.0200. Time: 1973.2268 us. Best GFLOPs: 1504.7320
2024-04-28 16:41:24 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #687: GFLOPs: 1193.4662. Time: 1552.5361 us. Best GFLOPs: 1504.7320
2024-04-28 16:41:24 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #688: GFLOPs: 966.3472. Time: 1917.4261 us. Best GFLOPs: 1504.7320
2024-04-28 16:41:24 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #689: GFLOPs: 1165.6338. Time: 1589.6068 us. Best GFLOPs: 1504.7320
2024-04-28 16:41:24 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #690: GFLOPs: 1143.7656. Time: 1619.9992 us. Best GFLOPs: 1504.7320
2024-04-28 16:41:24 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #691: GFLOPs: 1274.7177. Time: 1453.5762 us. Best GFLOPs: 1504.7320
2024-04-28 16:41:24 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #692: GFLOPs: 828.3170. Time: 2236.9447 us. Best GFLOPs: 1504.7320
2024-04-28 16:41:24 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #693: GFLOPs: 1304.5444. Time: 1420.3421 us. Best GFLOPs: 1504.7320
2024-04-28 16:41:24 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #694: GFLOPs: 1194.8195. Time: 1550.7776 us. Best GFLOPs: 1504.7320
2024-04-28 16:41:24 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #695: GFLOPs: 1074.4697. Time: 1724.4780 us. Best GFLOPs: 1504.7320
2024-04-28 16:41:24 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #696: GFLOPs: 1282.6267. Time: 1444.6131 us. Best GFLOPs: 1504.7320
2024-04-28 16:41:24 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #697: GFLOPs: 1234.5289. Time: 1500.8959 us. Best GFLOPs: 1504.7320
2024-04-28 16:41:24 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #698: GFLOPs: 1253.5403. Time: 1478.1330 us. Best GFLOPs: 1504.7320
2024-04-28 16:41:24 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #699: GFLOPs: 1307.9501. Time: 1416.6437 us. Best GFLOPs: 1504.7320
2024-04-28 16:41:24 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #700: GFLOPs: 1045.2552. Time: 1772.6765 us. Best GFLOPs: 1504.7320
2024-04-28 16:41:24 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #701: GFLOPs: 118.4373. Time: 15644.5540 us. Best GFLOPs: 1504.7320
2024-04-28 16:41:24 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #702: GFLOPs: 15.5390. Time: 119241.4970 us. Best GFLOPs: 1504.7320
2024-04-28 16:41:24 [INFO] [task_scheduler.cc:121] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #703: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(112), T.int64(112), T.int64(32)), "float32"), p1: T.Buffer((T.int64(2), T.int64(2), T.int64(3), T.int64(3), T.int64(32), T.int64(64)), "float32"), p2: T.Buffer((T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(64)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(2), T.int64(112), T.int64(112), T.int64(64)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(114), T.int64(114), T.int64(32)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(112), T.int64(112), T.int64(64)))
        for n_0_oc_chunk_0_fused_fused in T.parallel(T.int64(2), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(2), T.int64(114), T.int64(114)):
                for ax4_fused in T.vectorized(T.int64(32)):
                    with T.block("data_pad"):
                        v_i0, v_i1, v_i2, v_i3, v_i4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4_fused])
                        T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                        T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                        data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(113) and T.int64(1) <= v_i3 and v_i3 < T.int64(113), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oh_0, ow_0, oc_block_0 in T.grid(T.int64(2), T.int64(4), T.int64(16)):
                for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(2), T.int64(2)):
                    for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(14), T.int64(7)):
                        for oc_block_3_fused_init in T.vectorized(T.int64(2)):
                            with T.block("conv2d_NCHWc_init"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                                v_oc_chunk = T.axis.spatial(T.int64(2), n_0_oc_chunk_0_fused_fused + oc_chunk_1 + oc_chunk_2_init + oc_chunk_3_init)
                                v_oh = T.axis.spatial(T.int64(112), oh_0 * T.int64(56) + oh_1 * T.int64(14) + oh_2_init * T.int64(14) + oh_3_init)
                                v_ow = T.axis.spatial(T.int64(112), ow_0 * T.int64(28) + ow_1 * T.int64(14) + ow_2_init * T.int64(7) + ow_3_init)
                                v_oc_block = T.axis.spatial(T.int64(64), oc_block_0 * T.int64(4) + oc_block_1 * T.int64(2) + oc_block_2_init * T.int64(2) + oc_block_3_fused_init)
                                T.reads()
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                    for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(32), T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(14), T.int64(7)):
                        for oc_block_3_fused in T.vectorized(T.int64(2)):
                            with T.block("conv2d_NCHWc_update"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                                v_oc_chunk = T.axis.spatial(T.int64(2), n_0_oc_chunk_0_fused_fused + oc_chunk_1 + oc_chunk_2 + oc_chunk_3)
                                v_oh = T.axis.spatial(T.int64(112), oh_0 * T.int64(56) + oh_1 * T.int64(14) + oh_2 * T.int64(14) + oh_3)
                                v_ow = T.axis.spatial(T.int64(112), ow_0 * T.int64(28) + ow_1 * T.int64(14) + ow_2 * T.int64(7) + ow_3)
                                v_oc_block = T.axis.spatial(T.int64(64), oc_block_0 * T.int64(4) + oc_block_1 * T.int64(2) + oc_block_2 * T.int64(2) + oc_block_3_fused)
                                v_ic = T.axis.reduce(T.int64(64), ic_0 * T.int64(2) + ic_1)
                                v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                                v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                                T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(32), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(32)], p1[v_oc_chunk, v_ic // T.int64(32), v_kh, v_kw, v_ic % T.int64(32), v_oc_block])
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(32), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(32)] * p1[v_oc_chunk, v_ic // T.int64(32), v_kh, v_kw, v_ic % T.int64(32), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(56), T.int64(28)):
                    for ax4_fused in T.vectorized(T.int64(4)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(2), n_0_oc_chunk_0_fused_fused + ax1)
                            v_ax2 = T.axis.spatial(T.int64(112), oh_0 * T.int64(56) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(112), ow_0 * T.int64(28) + ax3)
                            v_ax4 = T.axis.spatial(T.int64(64), oc_block_0 * T.int64(4) + ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[2, 1, 1, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 4, 1, 14])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[4, 2, 2, 7])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[16, 2, 1, 2])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[32, 2])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=1)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77 = sch.get_loops(block=b68)
l78 = sch.fuse(l71, l72, preserve_unit_iters=True)
sch.parallel(loop=l78)
l79 = sch.fuse(l77, preserve_unit_iters=True)
sch.vectorize(loop=l79)
l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b69)
l105 = sch.fuse(l80, preserve_unit_iters=True)
sch.parallel(loop=l105)
l106 = sch.fuse(l104, preserve_unit_iters=True)
sch.vectorize(loop=l106)
sch.annotate(block_or_loop=l105, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l105, ann_key="pragma_unroll_explicit", ann_val=1)
l107, l108, l109, l110, l111, l112, l113, l114, l115 = sch.get_loops(block=b70)
l116 = sch.fuse(l115, preserve_unit_iters=True)
sch.vectorize(loop=l116)
b117 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141, l142 = sch.get_loops(block=b117)
b143 = sch.decompose_reduction(block=b117, loop=l127)
2024-04-28 16:41:24 [INFO] [task_scheduler.cc:121] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #704: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(112), T.int64(112), T.int64(32)), "float32"), p1: T.Buffer((T.int64(2), T.int64(2), T.int64(3), T.int64(3), T.int64(32), T.int64(64)), "float32"), p2: T.Buffer((T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(64)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(2), T.int64(112), T.int64(112), T.int64(64)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(114), T.int64(114), T.int64(32)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(112), T.int64(112), T.int64(64)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused in T.parallel(T.int64(16), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1 in T.grid(T.int64(1), T.int64(1), T.int64(14)):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(2), T.int64(10), T.int64(30)):
                    for ax4_fused in T.vectorized(T.int64(32)):
                        with T.block("data_pad"):
                            v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                            v_i2 = T.axis.spatial(T.int64(114), oh_1 * T.int64(8) + ax2)
                            v_i3 = T.axis.spatial(T.int64(114), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(8) // T.int64(2) * T.int64(28) + ax3)
                            v_i4 = T.axis.spatial(T.int64(32), ax4_fused)
                            T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                            T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                            data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(113) and T.int64(1) <= v_i3 and v_i3 < T.int64(113), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                for ow_1, oc_block_1 in T.grid(T.int64(28), T.int64(8)):
                    for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(2), T.int64(1)):
                        for oc_block_3_fused_init in T.vectorized(T.int64(2)):
                            with T.block("conv2d_NCHWc_init"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                                v_oc_chunk = T.axis.spatial(T.int64(2), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(8) + oc_chunk_1 + oc_chunk_2_init + oc_chunk_3_init)
                                v_oh = T.axis.spatial(T.int64(112), oh_1 * T.int64(8) + oh_2_init * T.int64(2) + oh_3_init)
                                v_ow = T.axis.spatial(T.int64(112), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(8) // T.int64(2) * T.int64(28) + ow_1 + ow_2_init + ow_3_init)
                                v_oc_block = T.axis.spatial(T.int64(64), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(2) * T.int64(32) + oc_block_1 * T.int64(4) + oc_block_2_init * T.int64(2) + oc_block_3_fused_init)
                                T.reads()
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                    for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(8), T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(4), T.int64(1), T.int64(2), T.int64(8), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1)):
                        for oc_block_3_fused in T.vectorized(T.int64(2)):
                            with T.block("conv2d_NCHWc_update"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                                v_oc_chunk = T.axis.spatial(T.int64(2), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(8) + oc_chunk_1 + oc_chunk_2 + oc_chunk_3)
                                v_oh = T.axis.spatial(T.int64(112), oh_1 * T.int64(8) + oh_2 * T.int64(2) + oh_3)
                                v_ow = T.axis.spatial(T.int64(112), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(8) // T.int64(2) * T.int64(28) + ow_1 + ow_2 + ow_3)
                                v_oc_block = T.axis.spatial(T.int64(64), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(2) * T.int64(32) + oc_block_1 * T.int64(4) + oc_block_2 * T.int64(2) + oc_block_3_fused)
                                v_ic = T.axis.reduce(T.int64(64), ic_0 * T.int64(8) + ic_1)
                                v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                                v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                                T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(32), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(32)], p1[v_oc_chunk, v_ic // T.int64(32), v_kh, v_kw, v_ic % T.int64(32), v_oc_block])
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(32), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(32)] * p1[v_oc_chunk, v_ic // T.int64(32), v_kh, v_kw, v_ic % T.int64(32), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(112), T.int64(28)):
                for ax4_fused in T.vectorized(T.int64(32)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(2), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(8) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(112), ax2)
                        v_ax3 = T.axis.spatial(T.int64(112), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(8) // T.int64(2) * T.int64(28) + ax3)
                        v_ax4 = T.axis.spatial(T.int64(64), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(2) * T.int64(32) + ax4_fused)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[2, 1, 1, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 14, 4, 2])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[4, 28, 1, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[2, 8, 2, 2])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[8, 8])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=7)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83 = sch.get_loops(block=b68)
l84 = sch.fuse(l71, l72, l73, l74, l75, preserve_unit_iters=True)
sch.parallel(loop=l84)
l85 = sch.fuse(l83, preserve_unit_iters=True)
sch.vectorize(loop=l85)
l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107 = sch.get_loops(block=b69)
l108 = sch.fuse(l86, preserve_unit_iters=True)
sch.parallel(loop=l108)
l109 = sch.fuse(l107, preserve_unit_iters=True)
sch.vectorize(loop=l109)
sch.annotate(block_or_loop=l108, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l108, ann_key="pragma_unroll_explicit", ann_val=1)
l110, l111, l112, l113, l114, l115 = sch.get_loops(block=b70)
l116 = sch.fuse(l115, preserve_unit_iters=True)
sch.vectorize(loop=l116)
b117 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139 = sch.get_loops(block=b117)
b140 = sch.decompose_reduction(block=b117, loop=l124)
2024-04-28 17:10:16 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-28 17:10:18 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-28 17:10:23 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x6741138)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x30bcd18)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x38311e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x32ad8b8)]: 0 failure(s)
2024-04-28 17:10:23 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-28 17:10:35 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x6741138)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x30bcd18)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x38311e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x32ad8b8)]: 0 failure(s)
2024-04-28 17:10:47 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x6741138)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x30bcd18)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x38311e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x32ad8b8)]: 0 failure(s)
2024-04-28 17:10:59 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x6741138)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x30bcd18)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x38311e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x32ad8b8)]: 0 failure(s)
2024-04-28 17:11:11 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x6741138)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x30bcd18)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x38311e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x32ad8b8)]: 0 failure(s)
2024-04-28 17:11:17 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.8619  0.8619  0.8450  0.8450  0.8450  0.8228  0.8222  0.8103  0.8080  0.8080  0.8047  0.8002  0.7977  0.7966  0.7920  0.7920
[17 : 32]:	0.7906  0.7878  0.7878  0.7870  0.7836  0.7772  0.7772  0.7766  0.7727  0.7669  0.7669  0.7650  0.7639  0.7590  0.7571  0.7545
[33 : 48]:	0.7545  0.7535  0.7535  0.7433  0.7420  0.7359  0.7356  0.7352  0.7318  0.7314  0.7314  0.7258  0.7246  0.7241  0.7198  0.7194
[49 : 64]:	0.7194  0.7194  0.7193  0.7183  0.7177  0.7166  0.7150  0.7127  0.7126  0.7103  0.7102  0.7096  0.7082  0.7063  0.7060  0.7060
2024-04-28 17:11:18 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-28 17:11:18 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-28 17:13:24 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #705: GFLOPs: 1406.7209. Time: 1317.1762 us. Best GFLOPs: 1504.7320
2024-04-28 17:13:24 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #706: GFLOPs: 1345.4791. Time: 1377.1298 us. Best GFLOPs: 1504.7320
2024-04-28 17:13:24 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #707: GFLOPs: 1518.8454. Time: 1219.9394 us. Best GFLOPs: 1518.8454
2024-04-28 17:13:24 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #708: GFLOPs: 1258.6855. Time: 1472.0908 us. Best GFLOPs: 1518.8454
2024-04-28 17:13:24 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #709: GFLOPs: 1352.4948. Time: 1369.9863 us. Best GFLOPs: 1518.8454
2024-04-28 17:13:24 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #710: GFLOPs: 1441.6836. Time: 1285.2330 us. Best GFLOPs: 1518.8454
2024-04-28 17:13:24 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #711: GFLOPs: 1021.9963. Time: 1813.0196 us. Best GFLOPs: 1518.8454
2024-04-28 17:13:24 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #712: GFLOPs: 646.5134. Time: 2865.9877 us. Best GFLOPs: 1518.8454
2024-04-28 17:13:24 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #713: GFLOPs: 915.6194. Time: 2023.6568 us. Best GFLOPs: 1518.8454
2024-04-28 17:13:24 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #714: GFLOPs: 1116.0016. Time: 1660.3017 us. Best GFLOPs: 1518.8454
2024-04-28 17:13:24 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #715: GFLOPs: 1201.8320. Time: 1541.7291 us. Best GFLOPs: 1518.8454
2024-04-28 17:13:24 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #716: GFLOPs: 1217.6657. Time: 1521.6815 us. Best GFLOPs: 1518.8454
2024-04-28 17:13:24 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #717: GFLOPs: 791.1730. Time: 2341.9649 us. Best GFLOPs: 1518.8454
2024-04-28 17:13:24 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #718: GFLOPs: 1216.1229. Time: 1523.6119 us. Best GFLOPs: 1518.8454
2024-04-28 17:13:24 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #719: GFLOPs: 1319.5373. Time: 1404.2039 us. Best GFLOPs: 1518.8454
2024-04-28 17:13:24 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #720: GFLOPs: 1339.8871. Time: 1382.8772 us. Best GFLOPs: 1518.8454
2024-04-28 17:13:24 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #721: GFLOPs: 150.4922. Time: 12312.2650 us. Best GFLOPs: 1518.8454
2024-04-28 17:13:24 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #722: GFLOPs: 1247.1892. Time: 1485.6602 us. Best GFLOPs: 1518.8454
2024-04-28 17:13:24 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #723: GFLOPs: 1231.4818. Time: 1504.6095 us. Best GFLOPs: 1518.8454
2024-04-28 17:13:24 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #724: GFLOPs: 1205.4573. Time: 1537.0925 us. Best GFLOPs: 1518.8454
2024-04-28 17:13:24 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #725: GFLOPs: 1296.0585. Time: 1429.6417 us. Best GFLOPs: 1518.8454
2024-04-28 17:13:24 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #726: GFLOPs: 1418.0891. Time: 1306.6170 us. Best GFLOPs: 1518.8454
2024-04-28 17:13:24 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #727: GFLOPs: 1213.9126. Time: 1526.3861 us. Best GFLOPs: 1518.8454
2024-04-28 17:13:24 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #728: GFLOPs: 1169.0403. Time: 1584.9747 us. Best GFLOPs: 1518.8454
2024-04-28 17:13:24 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #729: GFLOPs: 1365.9997. Time: 1356.4420 us. Best GFLOPs: 1518.8454
2024-04-28 17:13:24 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #730: GFLOPs: 821.9188. Time: 2254.3581 us. Best GFLOPs: 1518.8454
2024-04-28 17:13:24 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #731: GFLOPs: 1114.1768. Time: 1663.0209 us. Best GFLOPs: 1518.8454
2024-04-28 17:13:24 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #732: GFLOPs: 1280.0716. Time: 1447.4966 us. Best GFLOPs: 1518.8454
2024-04-28 17:13:24 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #733: GFLOPs: 1236.8533. Time: 1498.0753 us. Best GFLOPs: 1518.8454
2024-04-28 17:13:24 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #734: GFLOPs: 735.4989. Time: 2519.2413 us. Best GFLOPs: 1518.8454
2024-04-28 17:13:24 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #735: GFLOPs: 1007.6654. Time: 1838.8041 us. Best GFLOPs: 1518.8454
2024-04-28 17:13:24 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #736: GFLOPs: 1068.4950. Time: 1734.1207 us. Best GFLOPs: 1518.8454
2024-04-28 17:13:24 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #737: GFLOPs: 1239.0915. Time: 1495.3693 us. Best GFLOPs: 1518.8454
2024-04-28 17:13:24 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #738: GFLOPs: 1026.4237. Time: 1805.1992 us. Best GFLOPs: 1518.8454
2024-04-28 17:13:24 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #739: GFLOPs: 935.0376. Time: 1981.6309 us. Best GFLOPs: 1518.8454
2024-04-28 17:13:24 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #740: GFLOPs: 1199.8914. Time: 1544.2226 us. Best GFLOPs: 1518.8454
2024-04-28 17:13:24 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #741: GFLOPs: 1265.1759. Time: 1464.5389 us. Best GFLOPs: 1518.8454
2024-04-28 17:13:24 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #742: GFLOPs: 1159.0717. Time: 1598.6063 us. Best GFLOPs: 1518.8454
2024-04-28 17:13:24 [INFO] [task_scheduler.cc:121] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #743: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(112), T.int64(112), T.int64(32)), "float32"), p1: T.Buffer((T.int64(2), T.int64(2), T.int64(3), T.int64(3), T.int64(32), T.int64(64)), "float32"), p2: T.Buffer((T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(64)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(2), T.int64(112), T.int64(112), T.int64(64)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(114), T.int64(114), T.int64(32)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(112), T.int64(112), T.int64(64)))
        for n_0_oc_chunk_0_oh_0_ow_0_fused_fused in T.parallel(T.int64(224), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(2), T.int64(16), T.int64(6)):
                for ax4_fused in T.vectorized(T.int64(32)):
                    with T.block("data_pad"):
                        v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                        v_i2 = T.axis.spatial(T.int64(114), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(28) * T.int64(14) + ax2)
                        v_i3 = T.axis.spatial(T.int64(114), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(28) * T.int64(4) + ax3)
                        v_i4 = T.axis.spatial(T.int64(32), ax4_fused)
                        T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                        T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                        data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(113) and T.int64(1) <= v_i3 and v_i3 < T.int64(113), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oc_block_0 in range(T.int64(1)):
                for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(2), T.int64(7), T.int64(1), T.int64(1)):
                    for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(64), T.int64(1), T.int64(1), T.int64(2), T.int64(4), T.int64(1)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(2), oc_chunk_1 + oc_chunk_2_init + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(112), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(28) * T.int64(14) + oh_1 * T.int64(2) + oh_2_init * T.int64(2) + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(112), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(28) * T.int64(4) + ow_1 * T.int64(4) + ow_2_init * T.int64(4) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(64), oc_block_0 * T.int64(64) + oc_block_1 * T.int64(64) + oc_block_2_init + oc_block_3_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                    for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(32), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(64), T.int64(2), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(2), T.int64(4), T.int64(1)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(2), oc_chunk_1 + oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(112), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(28) * T.int64(14) + oh_1 * T.int64(2) + oh_2 * T.int64(2) + oh_3)
                            v_ow = T.axis.spatial(T.int64(112), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(28) * T.int64(4) + ow_1 * T.int64(4) + ow_2 * T.int64(4) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(64), oc_block_0 * T.int64(64) + oc_block_1 * T.int64(64) + oc_block_2 + oc_block_3)
                            v_ic = T.axis.reduce(T.int64(64), ic_0 * T.int64(2) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(32), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(32)], p1[v_oc_chunk, v_ic // T.int64(32), v_kh, v_kw, v_ic % T.int64(32), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(32), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(32)] * p1[v_oc_chunk, v_ic // T.int64(32), v_kh, v_kw, v_ic % T.int64(32), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(2), T.int64(14), T.int64(4)):
                    for ax4_fused in T.vectorized(T.int64(64)):
                        with T.block("T_relu"):
                            v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                            v_ax2 = T.axis.spatial(T.int64(112), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(28) * T.int64(14) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(112), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(28) * T.int64(4) + ax3)
                            v_ax4 = T.axis.spatial(T.int64(64), ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 2, 1, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[8, 7, 1, 2])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[28, 1, 1, 4])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 64, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[32, 2])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=3)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79 = sch.get_loops(block=b68)
l80 = sch.fuse(l71, l72, l73, l74, preserve_unit_iters=True)
sch.parallel(loop=l80)
l81 = sch.fuse(l79, preserve_unit_iters=True)
sch.vectorize(loop=l81)
l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b69)
l105 = sch.fuse(l82, preserve_unit_iters=True)
sch.parallel(loop=l105)
sch.annotate(block_or_loop=l105, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l105, ann_key="pragma_unroll_explicit", ann_val=1)
l106, l107, l108, l109, l110, l111, l112 = sch.get_loops(block=b70)
l113 = sch.fuse(l112, preserve_unit_iters=True)
sch.vectorize(loop=l113)
b114 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137 = sch.get_loops(block=b114)
b138 = sch.decompose_reduction(block=b114, loop=l122)
2024-04-28 17:13:24 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #744: GFLOPs: 1156.2260. Time: 1602.5407 us. Best GFLOPs: 1518.8454
2024-04-28 17:13:24 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #745: GFLOPs: 1100.9917. Time: 1682.9368 us. Best GFLOPs: 1518.8454
2024-04-28 17:13:24 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #746: GFLOPs: 1095.4986. Time: 1691.3754 us. Best GFLOPs: 1518.8454
2024-04-28 17:13:24 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #747: GFLOPs: 1301.4794. Time: 1423.6870 us. Best GFLOPs: 1518.8454
2024-04-28 17:13:24 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #748: GFLOPs: 1165.8544. Time: 1589.3059 us. Best GFLOPs: 1518.8454
2024-04-28 17:13:24 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #749: GFLOPs: 1076.9874. Time: 1720.4467 us. Best GFLOPs: 1518.8454
2024-04-28 17:13:24 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #750: GFLOPs: 1177.4423. Time: 1573.6647 us. Best GFLOPs: 1518.8454
2024-04-28 17:13:24 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #751: GFLOPs: 1089.9025. Time: 1700.0597 us. Best GFLOPs: 1518.8454
2024-04-28 17:13:24 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #752: GFLOPs: 1069.6870. Time: 1732.1884 us. Best GFLOPs: 1518.8454
2024-04-28 17:13:24 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #753: GFLOPs: 1049.9146. Time: 1764.8096 us. Best GFLOPs: 1518.8454
2024-04-28 17:13:24 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #754: GFLOPs: 1069.4086. Time: 1732.6393 us. Best GFLOPs: 1518.8454
2024-04-28 17:13:24 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #755: GFLOPs: 1276.4958. Time: 1451.5514 us. Best GFLOPs: 1518.8454
2024-04-28 17:13:24 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #756: GFLOPs: 1255.3398. Time: 1476.0142 us. Best GFLOPs: 1518.8454
2024-04-28 17:13:24 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #757: GFLOPs: 1176.7607. Time: 1574.5761 us. Best GFLOPs: 1518.8454
2024-04-28 17:13:24 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #758: GFLOPs: 943.9467. Time: 1962.9279 us. Best GFLOPs: 1518.8454
2024-04-28 17:13:24 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #759: GFLOPs: 136.8698. Time: 13537.6740 us. Best GFLOPs: 1518.8454
2024-04-28 17:13:24 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #760: GFLOPs: 1115.0531. Time: 1661.7140 us. Best GFLOPs: 1518.8454
2024-04-28 17:13:24 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #761: GFLOPs: 1209.3730. Time: 1532.1157 us. Best GFLOPs: 1518.8454
2024-04-28 17:13:24 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #762: GFLOPs: 899.8709. Time: 2059.0723 us. Best GFLOPs: 1518.8454
2024-04-28 17:13:24 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #763: GFLOPs: 127.8375. Time: 14494.1720 us. Best GFLOPs: 1518.8454
2024-04-28 17:13:24 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #764: GFLOPs: 913.6327. Time: 2028.0571 us. Best GFLOPs: 1518.8454
2024-04-28 17:13:24 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #765: GFLOPs: 1152.7184. Time: 1607.4172 us. Best GFLOPs: 1518.8454
2024-04-28 17:13:24 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #766: GFLOPs: 149.7276. Time: 12375.1350 us. Best GFLOPs: 1518.8454
2024-04-28 17:13:24 [INFO] [task_scheduler.cc:121] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #767: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(112), T.int64(112), T.int64(32)), "float32"), p1: T.Buffer((T.int64(2), T.int64(2), T.int64(3), T.int64(3), T.int64(32), T.int64(64)), "float32"), p2: T.Buffer((T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(64)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(2), T.int64(112), T.int64(112), T.int64(64)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(114), T.int64(114), T.int64(32)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(112), T.int64(112), T.int64(64)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused in T.parallel(T.int64(8), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(8), T.int64(4), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(7), T.int64(28)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(2)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(2), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(4) + oc_chunk_1 + oc_chunk_2_init + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(112), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(4) // T.int64(2) * T.int64(56) + oh_1 * T.int64(7) + oh_2_init * T.int64(7) + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(112), ow_1 * T.int64(28) + ow_2_init * T.int64(28) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(64), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(2) * T.int64(32) + oc_block_1 * T.int64(32) + oc_block_2_init * T.int64(2) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0 in T.grid(T.int64(16), T.int64(3), T.int64(3)):
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(7), T.int64(28)):
                        for ax4_fused in T.vectorized(T.int64(4)):
                            with T.block("data_pad"):
                                v_i0 = T.axis.spatial(T.int64(1), ax0)
                                v_i1 = T.axis.spatial(T.int64(2), ic_0 // T.int64(8) + ax1)
                                v_i2 = T.axis.spatial(T.int64(114), kh_0 + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(4) // T.int64(2) * T.int64(56) + oh_1 * T.int64(7) + ax2)
                                v_i3 = T.axis.spatial(T.int64(114), kw_0 + ow_1 * T.int64(28) + ax3)
                                v_i4 = T.axis.spatial(T.int64(32), ic_0 % T.int64(8) * T.int64(4) + ax4_fused)
                                T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                                T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                                data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(113) and T.int64(1) <= v_i3 and v_i3 < T.int64(113), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                    for n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(16), T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(28)):
                        for oc_block_3_fused in T.vectorized(T.int64(2)):
                            with T.block("conv2d_NCHWc_update"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                                v_oc_chunk = T.axis.spatial(T.int64(2), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(4) + oc_chunk_1 + oc_chunk_2 + oc_chunk_3)
                                v_oh = T.axis.spatial(T.int64(112), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(4) // T.int64(2) * T.int64(56) + oh_1 * T.int64(7) + oh_2 * T.int64(7) + oh_3)
                                v_ow = T.axis.spatial(T.int64(112), ow_1 * T.int64(28) + ow_2 * T.int64(28) + ow_3)
                                v_oc_block = T.axis.spatial(T.int64(64), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(2) * T.int64(32) + oc_block_1 * T.int64(32) + oc_block_2 * T.int64(2) + oc_block_3_fused)
                                v_ic = T.axis.reduce(T.int64(64), ic_0 * T.int64(4) + ic_1)
                                v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                                v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                                T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(32), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(32)], p1[v_oc_chunk, v_ic // T.int64(32), v_kh, v_kw, v_ic % T.int64(32), v_oc_block])
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(32), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(32)] * p1[v_oc_chunk, v_ic // T.int64(32), v_kh, v_kw, v_ic % T.int64(32), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(56), T.int64(112)):
                for ax4_fused in T.vectorized(T.int64(32)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(2), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(4) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(112), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(4) // T.int64(2) * T.int64(56) + ax2)
                        v_ax3 = T.axis.spatial(T.int64(112), ax3)
                        v_ax4 = T.axis.spatial(T.int64(64), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(2) * T.int64(32) + ax4_fused)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[2, 1, 1, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 8, 1, 7])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 4, 1, 28])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[2, 1, 16, 2])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[16, 4])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=12)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88 = sch.get_loops(block=b68)
l89 = sch.fuse(l71, l72, l73, l74, l75, preserve_unit_iters=True)
sch.parallel(loop=l89)
l90 = sch.fuse(l88, preserve_unit_iters=True)
sch.vectorize(loop=l90)
l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107, l108, l109, l110, l111, l112 = sch.get_loops(block=b69)
l113 = sch.fuse(l91, preserve_unit_iters=True)
sch.parallel(loop=l113)
l114 = sch.fuse(l112, preserve_unit_iters=True)
sch.vectorize(loop=l114)
sch.annotate(block_or_loop=l113, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l113, ann_key="pragma_unroll_explicit", ann_val=1)
l115, l116, l117, l118, l119, l120 = sch.get_loops(block=b70)
l121 = sch.fuse(l120, preserve_unit_iters=True)
sch.vectorize(loop=l121)
b122 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141, l142, l143, l144 = sch.get_loops(block=b122)
b145 = sch.decompose_reduction(block=b122, loop=l129)
2024-04-28 17:13:24 [INFO] [task_scheduler.cc:131] [Task #3: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #768: GFLOPs: 1.7413. Time: 1064082.6247 us. Best GFLOPs: 1518.8454
