2024-04-28 07:24:52 [INFO] [task_scheduler.cc:160] Initializing Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4"
2024-04-28 07:24:52 [INFO] [task_scheduler.cc:35] 
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(256)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(3), T.int64(3), T.int64(256), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(28), T.int64(28), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(256)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(28), T.int64(28), T.int64(32)))
        T_add = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(28), T.int64(28), T.int64(32)))
        for i0, i1, i2, i3, i4 in T.grid(T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(256)):
            with T.block("data_pad"):
                v_i0, v_i1, v_i2, v_i3, v_i4 = T.axis.remap("SSSSS", [i0, i1, i2, i3, i4])
                T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
        for n, oc_chunk, oh, ow, oc_block, ic, kh, kw in T.grid(T.int64(1), T.int64(16), T.int64(28), T.int64(28), T.int64(32), T.int64(256), T.int64(3), T.int64(3)):
            with T.block("conv2d_NCHWc"):
                v_n, v_oc_chunk, v_oh, v_ow, v_oc_block, v_ic, v_kh, v_kw = T.axis.remap("SSSSSRRR", [n, oc_chunk, oh, ow, oc_block, ic, kh, kw])
                T.reads(data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)], p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block])
                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                with T.init():
                    conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)] * p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block]
        for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(16), T.int64(28), T.int64(28), T.int64(32)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                T.writes(T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4]
        for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(16), T.int64(28), T.int64(28), T.int64(32)):
            with T.block("T_relu"):
                v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                T.reads(T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
2024-04-28 07:24:52 [INFO] [task_scheduler.cc:164] Total 3 design space(s) generated
2024-04-28 07:24:52 [INFO] [task_scheduler.cc:170] Design space #0:
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(256)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(3), T.int64(3), T.int64(256), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(28), T.int64(28), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel": 768, "meta_schedule.unroll_explicit": 0, "meta_schedule.vectorize": 64})
            conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(28), T.int64(28), T.int64(32)))
            for n_0, oc_chunk_0, oh_0, ow_0, oc_block_0, n_1, oc_chunk_1, oh_1, ow_1, oc_block_1, ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(1), T.int64(2), T.int64(2), T.int64(2), T.int64(32), T.int64(1), T.int64(2), T.int64(7), T.int64(2), T.int64(1), T.int64(128), T.int64(3), T.int64(3), T.int64(1), T.int64(4), T.int64(2), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1)):
                with T.block("conv2d_NCHWc"):
                    v_n = T.axis.spatial(T.int64(1), n_0 + n_1 + n_2 + n_3)
                    v_oc_chunk = T.axis.spatial(T.int64(16), oc_chunk_0 * T.int64(8) + oc_chunk_1 * T.int64(4) + oc_chunk_2 + oc_chunk_3)
                    v_oh = T.axis.spatial(T.int64(28), oh_0 * T.int64(14) + oh_1 * T.int64(2) + oh_2 + oh_3)
                    v_ow = T.axis.spatial(T.int64(28), ow_0 * T.int64(14) + ow_1 * T.int64(7) + ow_2 * T.int64(7) + ow_3)
                    v_oc_block = T.axis.spatial(T.int64(32), oc_block_0 + oc_block_1 + oc_block_2 + oc_block_3)
                    v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(2) + ic_1)
                    v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                    v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                    T.reads(p0[v_n, v_ic // T.int64(256), v_oh + v_kh - T.int64(1), v_ow + v_kw - T.int64(1), v_ic % T.int64(256)], p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block])
                    T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                    T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                    with T.init():
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                    conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + T.if_then_else(T.int64(1) <= v_oh + v_kh and v_oh + v_kh < T.int64(29) and T.int64(1) <= v_ow + v_kw and v_ow + v_kw < T.int64(29), p0[v_n, v_ic // T.int64(256), v_oh + v_kh - T.int64(1), v_ow + v_kw - T.int64(1), v_ic % T.int64(256)], T.float32(0)) * p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block]
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(16), T.int64(28), T.int64(28), T.int64(32)):
                with T.block("T_relu"):
                    v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                    T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                    T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[2, 2, 4, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 7, 2, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[2, 2, 1, 7])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[32, 1, 1, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[128, 2])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
l65 = sch.sample_compute_location(block=b0, decision=-2)
sch.compute_at(block=b0, loop=l65, preserve_unit_loops=True, index=-1)
2024-04-28 07:24:52 [INFO] [task_scheduler.cc:170] Design space #1:
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(256)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(3), T.int64(3), T.int64(256), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(28), T.int64(28), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel": 768, "meta_schedule.unroll_explicit": 512, "meta_schedule.vectorize": 64})
            data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(256)))
            conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(28), T.int64(28), T.int64(32)))
            for n_0, oc_chunk_0, oh_0, ow_0, oc_block_0, n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(2), T.int64(2), T.int64(2), T.int64(32), T.int64(1), T.int64(2), T.int64(7), T.int64(2), T.int64(1)):
                for ic_0 in range(T.int64(128)):
                    for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(9), T.int64(2)):
                        with T.block("data_pad"):
                            v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                            v_i2 = T.axis.spatial(T.int64(30), oh_0 * T.int64(14) + oh_1 * T.int64(2) + ax2)
                            v_i3 = T.axis.spatial(T.int64(30), ow_0 * T.int64(14) + ow_1 * T.int64(7) + ax3)
                            v_i4 = T.axis.spatial(T.int64(256), ic_0 * T.int64(2) + ax4)
                            T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                            T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                            data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                    for kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(3), T.int64(3), T.int64(1), T.int64(4), T.int64(2), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1)):
                        with T.block("conv2d_NCHWc"):
                            v_n = T.axis.spatial(T.int64(1), n_0 + n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(16), oc_chunk_0 * T.int64(8) + oc_chunk_1 * T.int64(4) + oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(28), oh_0 * T.int64(14) + oh_1 * T.int64(2) + oh_2 + oh_3)
                            v_ow = T.axis.spatial(T.int64(28), ow_0 * T.int64(14) + ow_1 * T.int64(7) + ow_2 * T.int64(7) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(32), oc_block_0 + oc_block_1 + oc_block_2 + oc_block_3)
                            v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(2) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)], p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            with T.init():
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)] * p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block]
                for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(4), T.int64(2), T.int64(7), T.int64(1)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(16), oc_chunk_0 * T.int64(8) + oc_chunk_1 * T.int64(4) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(28), oh_0 * T.int64(14) + oh_1 * T.int64(2) + ax2)
                        v_ax3 = T.axis.spatial(T.int64(28), ow_0 * T.int64(14) + ow_1 * T.int64(7) + ax3)
                        v_ax4 = T.axis.spatial(T.int64(32), oc_block_0 + ax4)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[2, 2, 4, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 7, 2, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[2, 2, 1, 7])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[32, 1, 1, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[128, 2])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=10)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
2024-04-28 07:24:52 [INFO] [task_scheduler.cc:170] Design space #2:
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(256)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(3), T.int64(3), T.int64(256), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(28), T.int64(28), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel": 768, "meta_schedule.unroll_explicit": 512, "meta_schedule.vectorize": 64})
            conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(28), T.int64(28), T.int64(32)))
            for n_0, oc_chunk_0, oh_0, ow_0, oc_block_0 in T.grid(T.int64(1), T.int64(2), T.int64(2), T.int64(2), T.int64(32)):
                for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1, ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(1), T.int64(2), T.int64(7), T.int64(2), T.int64(1), T.int64(128), T.int64(3), T.int64(3), T.int64(1), T.int64(4), T.int64(2), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1)):
                    with T.block("conv2d_NCHWc"):
                        v_n = T.axis.spatial(T.int64(1), n_0 + n_1 + n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(16), oc_chunk_0 * T.int64(8) + oc_chunk_1 * T.int64(4) + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(28), oh_0 * T.int64(14) + oh_1 * T.int64(2) + oh_2 + oh_3)
                        v_ow = T.axis.spatial(T.int64(28), ow_0 * T.int64(14) + ow_1 * T.int64(7) + ow_2 * T.int64(7) + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_0 + oc_block_1 + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(2) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                        T.reads(p0[v_n, v_ic // T.int64(256), v_oh + v_kh - T.int64(1), v_ow + v_kw - T.int64(1), v_ic % T.int64(256)], p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        with T.init():
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + T.if_then_else(T.int64(1) <= v_oh + v_kh and v_oh + v_kh < T.int64(29) and T.int64(1) <= v_ow + v_kw and v_ow + v_kw < T.int64(29), p0[v_n, v_ic // T.int64(256), v_oh + v_kh - T.int64(1), v_ow + v_kw - T.int64(1), v_ic % T.int64(256)], T.float32(0)) * p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block]
                for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(8), T.int64(14), T.int64(14), T.int64(1)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(16), oc_chunk_0 * T.int64(8) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(28), oh_0 * T.int64(14) + ax2)
                        v_ax3 = T.axis.spatial(T.int64(28), ow_0 * T.int64(14) + ax3)
                        v_ax4 = T.axis.spatial(T.int64(32), oc_block_0 + ax4)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[2, 2, 4, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 7, 2, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[2, 2, 1, 7])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[32, 1, 1, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[128, 2])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=-2)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
2024-04-28 07:44:48 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-28 07:44:48 [INFO] [evolutionary_search.cc:715] Picked top 0 candidate(s) from database
2024-04-28 07:44:54 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35c37e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x31a6de8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x9b6ad08)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x350b3f8)]: 0 failure(s)
2024-04-28 07:44:54 [INFO] [evolutionary_search.cc:723] Sampled 512 candidate(s)
2024-04-28 07:45:00 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35c37e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x31a6de8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x9b6ad08)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x350b3f8)]: 0 failure(s)
2024-04-28 07:45:06 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35c37e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x31a6de8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x9b6ad08)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x350b3f8)]: 0 failure(s)
2024-04-28 07:45:12 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35c37e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x31a6de8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x9b6ad08)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x350b3f8)]: 0 failure(s)
2024-04-28 07:45:19 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35c37e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x31a6de8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x9b6ad08)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x350b3f8)]: 0 failure(s)
2024-04-28 07:45:20 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9997  0.9993  0.9992  0.9991  0.9981  0.9976  0.9976  0.9971  0.9954  0.9952  0.9952  0.9950  0.9942  0.9940  0.9936  0.9934
[17 : 32]:	0.9933  0.9931  0.9916  0.9907  0.9905  0.9904  0.9899  0.9899  0.9890  0.9887  0.9885  0.9885  0.9882  0.9882  0.9879  0.9876
[33 : 48]:	0.9875  0.9870  0.9837  0.9834  0.9824  0.9823  0.9802  0.9799  0.9799  0.9797  0.9793  0.9793  0.9787  0.9784  0.9776  0.9772
[49 : 64]:	0.9771  0.9761  0.9755  0.9750  0.9749  0.9745  0.9733  0.9726  0.9724  0.9702  0.9699  0.9697  0.9697  0.9693  0.9692  0.9688
2024-04-28 07:45:20 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-28 07:45:20 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-28 08:27:21 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #1: GFLOPs: 29.8200. Time: 62055.3207 us. Best GFLOPs: 29.8200
2024-04-28 08:27:21 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #2: GFLOPs: 28.7310. Time: 64407.4383 us. Best GFLOPs: 29.8200
2024-04-28 08:27:21 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #3: GFLOPs: 181.1736. Time: 10213.9088 us. Best GFLOPs: 181.1736
2024-04-28 08:27:21 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #4: GFLOPs: 137.1287. Time: 13494.5586 us. Best GFLOPs: 181.1736
2024-04-28 08:27:21 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #5: GFLOPs: 40.7327. Time: 45430.1263 us. Best GFLOPs: 181.1736
2024-04-28 08:27:21 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #6: GFLOPs: 25.2171. Time: 73382.2837 us. Best GFLOPs: 181.1736
2024-04-28 08:27:21 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #7: GFLOPs: 60.5542. Time: 30559.2290 us. Best GFLOPs: 181.1736
2024-04-28 08:27:21 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #8: GFLOPs: 77.4119. Time: 23904.4678 us. Best GFLOPs: 181.1736
2024-04-28 08:27:21 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #9: GFLOPs: 88.5204. Time: 20904.6820 us. Best GFLOPs: 181.1736
2024-04-28 08:27:21 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #10: GFLOPs: 12.4037. Time: 149189.1627 us. Best GFLOPs: 181.1736
2024-04-28 08:27:21 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #11: GFLOPs: 8.5500. Time: 216432.8500 us. Best GFLOPs: 181.1736
2024-04-28 08:27:21 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #12: GFLOPs: 42.7495. Time: 43286.8160 us. Best GFLOPs: 181.1736
2024-04-28 08:27:21 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #13: GFLOPs: 30.4400. Time: 60791.4057 us. Best GFLOPs: 181.1736
2024-04-28 08:27:21 [INFO] [task_scheduler.cc:121] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #14: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(256)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(3), T.int64(3), T.int64(256), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(28), T.int64(28), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(28), T.int64(28), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused in T.parallel(T.int64(112), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(28), T.int64(2), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(4), T.int64(1), T.int64(1)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(8)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused // T.int64(28) * T.int64(4) + oc_chunk_1 * T.int64(4) + oc_chunk_2_init * T.int64(4) + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(28), oh_1 + oh_2_init + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused % T.int64(28) // T.int64(2) * T.int64(2) + ow_1 + ow_2_init + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused % T.int64(2) * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2_init * T.int64(8) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(8), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(32), T.int64(3), T.int64(1), T.int64(1), T.int64(4), T.int64(1), T.int64(1)):
                    for oc_block_3_fused in T.vectorized(T.int64(8)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused // T.int64(28) * T.int64(4) + oc_chunk_1 * T.int64(4) + oc_chunk_2 * T.int64(4) + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(28), oh_1 + oh_2 + oh_3)
                            v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused % T.int64(28) // T.int64(2) * T.int64(2) + ow_1 + ow_2 + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused % T.int64(2) * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2 * T.int64(8) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(32) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], p0[v_n, v_ic // T.int64(256), v_oh + v_kh - T.int64(1), v_ow + v_kw - T.int64(1), v_ic % T.int64(256)], p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + T.if_then_else(T.int64(1) <= v_oh + v_kh and v_oh + v_kh < T.int64(29) and T.int64(1) <= v_ow + v_kw and v_ow + v_kw < T.int64(29), p0[v_n, v_ic // T.int64(256), v_oh + v_kh - T.int64(1), v_ow + v_kw - T.int64(1), v_ic % T.int64(256)], T.float32(0)) * p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(4), T.int64(28), T.int64(2)):
                for ax4_fused in T.vectorized(T.int64(16)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused // T.int64(28) * T.int64(4) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(28), ax2)
                        v_ax3 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused % T.int64(28) // T.int64(2) * T.int64(2) + ax3)
                        v_ax4 = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused % T.int64(2) * T.int64(16) + ax4_fused)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[4, 1, 1, 4])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 28, 1, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[14, 2, 1, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[2, 1, 2, 8])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[8, 32])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=-2)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69 = sch.get_child_blocks(b67)
l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95 = sch.get_loops(block=b68)
l96 = sch.fuse(l70, l71, l72, l73, l74, preserve_unit_iters=True)
sch.parallel(loop=l96)
l97 = sch.fuse(l95, preserve_unit_iters=True)
sch.vectorize(loop=l97)
sch.annotate(block_or_loop=l96, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l96, ann_key="pragma_unroll_explicit", ann_val=1)
l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l103, preserve_unit_iters=True)
sch.vectorize(loop=l104)
b105 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l106, l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127 = sch.get_loops(block=b105)
b128 = sch.decompose_reduction(block=b105, loop=l112)
2024-04-28 08:27:21 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #15: GFLOPs: 101.3603. Time: 18256.5560 us. Best GFLOPs: 181.1736
2024-04-28 08:27:21 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #16: GFLOPs: 3.2471. Time: 569886.9950 us. Best GFLOPs: 181.1736
2024-04-28 08:27:21 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #17: GFLOPs: 81.0386. Time: 22834.6954 us. Best GFLOPs: 181.1736
2024-04-28 08:27:21 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #18: GFLOPs: 1.3470. Time: 1373831.4820 us. Best GFLOPs: 181.1736
2024-04-28 08:27:21 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #19: GFLOPs: 6.5445. Time: 282754.7047 us. Best GFLOPs: 181.1736
2024-04-28 08:27:21 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #20: GFLOPs: 52.5711. Time: 35199.7593 us. Best GFLOPs: 181.1736
2024-04-28 08:27:21 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #21: GFLOPs: 51.1941. Time: 36146.5990 us. Best GFLOPs: 181.1736
2024-04-28 08:27:21 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #22: GFLOPs: 2.0049. Time: 922992.5740 us. Best GFLOPs: 181.1736
2024-04-28 08:27:21 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #23: GFLOPs: 125.7147. Time: 14719.7626 us. Best GFLOPs: 181.1736
2024-04-28 08:27:21 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #24: GFLOPs: 63.6486. Time: 29073.5458 us. Best GFLOPs: 181.1736
2024-04-28 08:27:21 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #25: GFLOPs: 59.3969. Time: 31154.6595 us. Best GFLOPs: 181.1736
2024-04-28 08:27:21 [INFO] [task_scheduler.cc:121] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #26: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(256)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(3), T.int64(3), T.int64(256), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(28), T.int64(28), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(28), T.int64(28), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused in T.parallel(T.int64(112), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(28), T.int64(2), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(8)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused // T.int64(28) * T.int64(4) + oc_chunk_1 * T.int64(4) + oc_chunk_2_init + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(28), oh_1 + oh_2_init + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused % T.int64(28) // T.int64(2) * T.int64(2) + ow_1 + ow_2_init + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused % T.int64(2) * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2_init * T.int64(8) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(8), T.int64(1), T.int64(3), T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(2), T.int64(32), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                    for oc_block_3_fused in T.vectorized(T.int64(8)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused // T.int64(28) * T.int64(4) + oc_chunk_1 * T.int64(4) + oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(28), oh_1 + oh_2 + oh_3)
                            v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused % T.int64(28) // T.int64(2) * T.int64(2) + ow_1 + ow_2 + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused % T.int64(2) * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2 * T.int64(8) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(32) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], p0[v_n, v_ic // T.int64(256), v_oh + v_kh - T.int64(1), v_ow + v_kw - T.int64(1), v_ic % T.int64(256)], p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + T.if_then_else(T.int64(1) <= v_oh + v_kh and v_oh + v_kh < T.int64(29) and T.int64(1) <= v_ow + v_kw and v_ow + v_kw < T.int64(29), p0[v_n, v_ic // T.int64(256), v_oh + v_kh - T.int64(1), v_ow + v_kw - T.int64(1), v_ic % T.int64(256)], T.float32(0)) * p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(4), T.int64(28), T.int64(2)):
                for ax4_fused in T.vectorized(T.int64(16)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused // T.int64(28) * T.int64(4) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(28), ax2)
                        v_ax3 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused % T.int64(28) // T.int64(2) * T.int64(2) + ax3)
                        v_ax4 = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused % T.int64(2) * T.int64(16) + ax4_fused)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[4, 1, 4, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 28, 1, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[14, 2, 1, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[2, 1, 2, 8])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[8, 32])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=-2)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69 = sch.get_child_blocks(b67)
l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95 = sch.get_loops(block=b68)
l96 = sch.fuse(l70, l71, l72, l73, l74, preserve_unit_iters=True)
sch.parallel(loop=l96)
l97 = sch.fuse(l95, preserve_unit_iters=True)
sch.vectorize(loop=l97)
sch.annotate(block_or_loop=l96, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l96, ann_key="pragma_unroll_explicit", ann_val=1)
l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l103, preserve_unit_iters=True)
sch.vectorize(loop=l104)
b105 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l106, l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127 = sch.get_loops(block=b105)
b128 = sch.decompose_reduction(block=b105, loop=l112)
2024-04-28 08:27:21 [INFO] [task_scheduler.cc:121] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #27: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(256)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(3), T.int64(3), T.int64(256), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(28), T.int64(28), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(256)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(28), T.int64(28), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused in T.parallel(T.int64(16), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(30), T.int64(16), T.int64(256)):
                with T.block("data_pad"):
                    v_i0, v_i1, v_i2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                    v_i3 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(8) * T.int64(14) + ax3)
                    v_i4 = T.axis.spatial(T.int64(256), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(14), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(2), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(14), T.int64(1)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(16), oc_chunk_1 * T.int64(8) + oc_chunk_2_init * T.int64(4) + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(28), oh_1 * T.int64(28) + oh_2_init * T.int64(14) + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(8) * T.int64(14) + ow_1 + ow_2_init + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(8) * T.int64(4) + oc_block_1 * T.int64(4) + oc_block_2_init * T.int64(4) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(2), T.int64(1), T.int64(1), T.int64(64), T.int64(3), T.int64(3), T.int64(1), T.int64(4), T.int64(14), T.int64(1)):
                    for oc_block_3_fused in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(16), oc_chunk_1 * T.int64(8) + oc_chunk_2 * T.int64(4) + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(28), oh_1 * T.int64(28) + oh_2 * T.int64(14) + oh_3)
                            v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(8) * T.int64(14) + ow_1 + ow_2 + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(8) * T.int64(4) + oc_block_1 * T.int64(4) + oc_block_2 * T.int64(4) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(64) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)], p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)] * p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block]
        for ax0_ax1_ax2_ax3_ax4_fused_0 in T.parallel(T.int64(6272)):
            for ax0_ax1_ax2_ax3_ax4_fused_1 in T.vectorized(T.int64(64)):
                with T.block("T_relu"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) // T.int64(25088))
                    v_ax2 = T.axis.spatial(T.int64(28), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(25088) // T.int64(896))
                    v_ax3 = T.axis.spatial(T.int64(28), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(896) // T.int64(32))
                    v_ax4 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(32))
                    T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                    T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 2, 2, 4])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 2, 14])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[2, 14, 1, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[8, 1, 1, 4])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[4, 64])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
l65 = sch.sample_compute_location(block=b0, decision=4)
sch.compute_at(block=b0, loop=l65, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b66 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.unroll_explicit")
b67, b68, b69 = sch.get_child_blocks(b66)
l70, l71, l72, l73, l74, l75, l76, l77, l78, l79 = sch.get_loops(block=b67)
l80 = sch.fuse(l70, l71, l72, l73, l74, preserve_unit_iters=True)
sch.parallel(loop=l80)
l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102 = sch.get_loops(block=b68)
l103 = sch.fuse(l81, preserve_unit_iters=True)
sch.parallel(loop=l103)
l104 = sch.fuse(l102, preserve_unit_iters=True)
sch.vectorize(loop=l104)
sch.annotate(block_or_loop=l103, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l103, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109 = sch.get_loops(block=b69)
l110 = sch.fuse(l105, l106, l107, l108, l109, preserve_unit_iters=True)
l111, l112 = sch.split(loop=l110, factors=[None, 64], preserve_unit_iters=True)
sch.parallel(loop=l111)
sch.vectorize(loop=l112)
b113 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135 = sch.get_loops(block=b113)
b136 = sch.decompose_reduction(block=b113, loop=l120)
2024-04-28 08:27:21 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #28: GFLOPs: 62.5635. Time: 29577.7798 us. Best GFLOPs: 181.1736
2024-04-28 08:27:21 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #29: GFLOPs: 97.0114. Time: 19074.9803 us. Best GFLOPs: 181.1736
2024-04-28 08:27:21 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #30: GFLOPs: 8.6279. Time: 214478.6930 us. Best GFLOPs: 181.1736
2024-04-28 08:27:21 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #31: GFLOPs: 32.1622. Time: 57536.2260 us. Best GFLOPs: 181.1736
2024-04-28 08:27:21 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #32: GFLOPs: 118.1211. Time: 15666.0526 us. Best GFLOPs: 181.1736
2024-04-28 08:27:21 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #33: GFLOPs: 3.0522. Time: 606289.9450 us. Best GFLOPs: 181.1736
2024-04-28 08:27:21 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #34: GFLOPs: 67.0084. Time: 27615.8080 us. Best GFLOPs: 181.1736
2024-04-28 08:27:21 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #35: GFLOPs: 18.7845. Time: 98511.6153 us. Best GFLOPs: 181.1736
2024-04-28 08:27:21 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #36: GFLOPs: 31.1929. Time: 59324.0600 us. Best GFLOPs: 181.1736
2024-04-28 08:27:21 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #37: GFLOPs: 211.8684. Time: 8734.1528 us. Best GFLOPs: 211.8684
2024-04-28 08:27:21 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #38: GFLOPs: 25.6686. Time: 72091.7080 us. Best GFLOPs: 211.8684
2024-04-28 08:27:21 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #39: GFLOPs: 62.4176. Time: 29646.9608 us. Best GFLOPs: 211.8684
2024-04-28 08:27:21 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #40: GFLOPs: 15.2184. Time: 121595.5817 us. Best GFLOPs: 211.8684
2024-04-28 08:27:21 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #41: GFLOPs: 33.4150. Time: 55379.0287 us. Best GFLOPs: 211.8684
2024-04-28 08:27:21 [INFO] [task_scheduler.cc:121] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #42: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(256)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(3), T.int64(3), T.int64(256), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(28), T.int64(28), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(256)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(28), T.int64(28), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused in T.parallel(T.int64(112), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(3), T.int64(30), T.int64(256)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(56) * T.int64(14) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(14) + ax2)
                    v_i3, v_i4 = T.axis.remap("SS", [ax3, ax4])
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(16), T.int64(1), T.int64(2), T.int64(8), T.int64(1), T.int64(1), T.int64(1), T.int64(14), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(16), oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(56) * T.int64(14) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(14) + oh_2_init + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(28), ow_1 * T.int64(28) + ow_2_init * T.int64(14) + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(56) // T.int64(14) * T.int64(8) + oc_block_1 * T.int64(8) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(64), T.int64(3), T.int64(3), T.int64(1), T.int64(16), T.int64(1), T.int64(2), T.int64(8), T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(14), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(16), oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(56) * T.int64(14) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(14) + oh_2 + oh_3)
                        v_ow = T.axis.spatial(T.int64(28), ow_1 * T.int64(28) + ow_2 * T.int64(14) + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(56) // T.int64(14) * T.int64(8) + oc_block_1 * T.int64(8) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(4) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)], p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)] * p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(16), T.int64(1), T.int64(28)):
                    for ax4_fused in T.vectorized(T.int64(8)):
                        with T.block("T_relu"):
                            v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                            v_ax2 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(56) * T.int64(14) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(14) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(28), ax3)
                            v_ax4 = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(56) // T.int64(14) * T.int64(8) + ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 16, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 14, 1, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 2, 14])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[4, 1, 8, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[64, 4])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=7)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83 = sch.get_loops(block=b68)
l84 = sch.fuse(l71, l72, l73, l74, l75, l76, l77, l78, preserve_unit_iters=True)
sch.parallel(loop=l84)
l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l85, preserve_unit_iters=True)
sch.parallel(loop=l104)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109, l110, l111, l112 = sch.get_loops(block=b70)
l113 = sch.fuse(l112, preserve_unit_iters=True)
sch.vectorize(loop=l113)
b114 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133 = sch.get_loops(block=b114)
b134 = sch.decompose_reduction(block=b114, loop=l118)
2024-04-28 08:27:21 [INFO] [task_scheduler.cc:121] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #43: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(256)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(3), T.int64(3), T.int64(256), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(28), T.int64(28), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(256)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(28), T.int64(28), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused in T.parallel(T.int64(56), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(6), T.int64(30), T.int64(256)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(28) // T.int64(4) * T.int64(4) + ax2)
                    v_i3, v_i4 = T.axis.remap("SS", [ax3, ax4])
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(14), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(8), T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(8)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(28) * T.int64(8) + oc_chunk_1 * T.int64(8) + oc_chunk_2_init + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(28) // T.int64(4) * T.int64(4) + oh_1 * T.int64(4) + oh_2_init + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(28), ow_1 * T.int64(2) + ow_2_init * T.int64(2) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(4) * T.int64(8) + oc_block_1 * T.int64(8) + oc_block_2_init * T.int64(8) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(8), T.int64(1), T.int64(3), T.int64(1), T.int64(8), T.int64(4), T.int64(1), T.int64(1), T.int64(32), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2)):
                    for oc_block_3_fused in T.vectorized(T.int64(8)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(28) * T.int64(8) + oc_chunk_1 * T.int64(8) + oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(28) // T.int64(4) * T.int64(4) + oh_1 * T.int64(4) + oh_2 + oh_3)
                            v_ow = T.axis.spatial(T.int64(28), ow_1 * T.int64(2) + ow_2 * T.int64(2) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(4) * T.int64(8) + oc_block_1 * T.int64(8) + oc_block_2 * T.int64(8) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(32) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)], p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)] * p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(8), T.int64(4), T.int64(28)):
                for ax4_fused in T.vectorized(T.int64(8)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(28) * T.int64(8) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(28) // T.int64(4) * T.int64(4) + ax2)
                        v_ax3 = T.axis.spatial(T.int64(28), ax3)
                        v_ax4 = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(4) * T.int64(8) + ax4_fused)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[2, 1, 8, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[7, 1, 4, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 14, 1, 2])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[4, 1, 1, 8])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[8, 32])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=4)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80 = sch.get_loops(block=b68)
l81 = sch.fuse(l71, l72, l73, l74, l75, preserve_unit_iters=True)
sch.parallel(loop=l81)
l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l82, preserve_unit_iters=True)
sch.parallel(loop=l104)
l105 = sch.fuse(l103, preserve_unit_iters=True)
sch.vectorize(loop=l105)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l106, l107, l108, l109, l110, l111 = sch.get_loops(block=b70)
l112 = sch.fuse(l111, preserve_unit_iters=True)
sch.vectorize(loop=l112)
b113 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135 = sch.get_loops(block=b113)
b136 = sch.decompose_reduction(block=b113, loop=l120)
2024-04-28 08:27:21 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #44: GFLOPs: 97.9211. Time: 18897.7705 us. Best GFLOPs: 211.8684
2024-04-28 08:27:21 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #45: GFLOPs: 62.8373. Time: 29448.9073 us. Best GFLOPs: 211.8684
2024-04-28 08:27:21 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #46: GFLOPs: 25.7638. Time: 71825.3000 us. Best GFLOPs: 211.8684
2024-04-28 08:27:21 [INFO] [task_scheduler.cc:121] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #47: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(256)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(3), T.int64(3), T.int64(256), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(28), T.int64(28), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(256)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(28), T.int64(28), T.int64(32)))
        for i0_i1_i2_i3_fused in T.parallel(T.int64(900)):
            for i4 in range(T.int64(256)):
                with T.block("data_pad"):
                    v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_i1 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_i2 = T.axis.spatial(T.int64(30), i0_i1_i2_i3_fused // T.int64(30))
                    v_i3 = T.axis.spatial(T.int64(30), i0_i1_i2_i3_fused % T.int64(30))
                    v_i4 = T.axis.spatial(T.int64(256), i4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused in T.parallel(T.int64(28), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(16)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(4), T.int64(7), T.int64(1), T.int64(2), T.int64(1), T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(16), oc_chunk_1 * T.int64(16) + oc_chunk_2_init * T.int64(4) + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(28), oh_1 * T.int64(28) + oh_2_init * T.int64(4) + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused + ow_1 + ow_2_init + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(2) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(256), T.int64(3), T.int64(1), T.int64(1), T.int64(4), T.int64(7), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(3), T.int64(1), T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(16), oc_chunk_1 * T.int64(16) + oc_chunk_2 * T.int64(4) + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(28), oh_1 * T.int64(28) + oh_2 * T.int64(4) + oh_3)
                        v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused + ow_1 + ow_2 + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(2) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(256), ic_0 + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)], p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)] * p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block]
            for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(16), T.int64(28)):
                for ax3_ax4_fused in T.vectorized(T.int64(32)):
                    with T.block("T_relu"):
                        v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused, ax3_ax4_fused])
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 4, 4])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 7, 4])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[28, 1, 1, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 16, 2, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[256, 1])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=-1)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75 = sch.get_loops(block=b68)
l76 = sch.fuse(l71, l72, l73, l74, preserve_unit_iters=True)
sch.parallel(loop=l76)
l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102 = sch.get_loops(block=b69)
l103 = sch.fuse(l77, l78, l79, l80, l81, preserve_unit_iters=True)
sch.parallel(loop=l103)
sch.annotate(block_or_loop=l103, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l103, ann_key="pragma_unroll_explicit", ann_val=1)
l104, l105, l106, l107, l108, l109 = sch.get_loops(block=b70)
l110 = sch.fuse(l108, l109, preserve_unit_iters=True)
sch.vectorize(loop=l110)
b111 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l112, l113, l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133 = sch.get_loops(block=b111)
b134 = sch.decompose_reduction(block=b111, loop=l118)
2024-04-28 08:27:21 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #48: GFLOPs: 8.8043. Time: 210180.7150 us. Best GFLOPs: 211.8684
2024-04-28 08:27:21 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #49: GFLOPs: 12.8727. Time: 143753.2953 us. Best GFLOPs: 211.8684
2024-04-28 08:27:21 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #50: GFLOPs: 32.0795. Time: 57684.5320 us. Best GFLOPs: 211.8684
2024-04-28 08:27:21 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #51: GFLOPs: 53.9442. Time: 34303.8073 us. Best GFLOPs: 211.8684
2024-04-28 08:27:21 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #52: GFLOPs: 3.1474. Time: 587946.2447 us. Best GFLOPs: 211.8684
2024-04-28 08:27:21 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #53: GFLOPs: 35.8818. Time: 51571.8597 us. Best GFLOPs: 211.8684
2024-04-28 08:27:21 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #54: GFLOPs: 43.8110. Time: 42238.0180 us. Best GFLOPs: 211.8684
2024-04-28 08:27:21 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #55: GFLOPs: 2.7572. Time: 671148.7797 us. Best GFLOPs: 211.8684
2024-04-28 08:27:21 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #56: GFLOPs: 5.1574. Time: 358805.7287 us. Best GFLOPs: 211.8684
2024-04-28 08:27:21 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #57: GFLOPs: 16.3872. Time: 112922.8117 us. Best GFLOPs: 211.8684
2024-04-28 08:27:21 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #58: GFLOPs: 1.2824. Time: 1443004.0160 us. Best GFLOPs: 211.8684
2024-04-28 08:27:21 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #59: GFLOPs: 3.1502. Time: 587423.1037 us. Best GFLOPs: 211.8684
2024-04-28 08:27:21 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #60: GFLOPs: 24.3705. Time: 75931.6177 us. Best GFLOPs: 211.8684
2024-04-28 08:27:21 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #61: GFLOPs: 43.9669. Time: 42088.3087 us. Best GFLOPs: 211.8684
2024-04-28 08:27:21 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #62: GFLOPs: 27.8876. Time: 66355.2520 us. Best GFLOPs: 211.8684
2024-04-28 08:27:21 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #63: GFLOPs: 42.1606. Time: 43891.5230 us. Best GFLOPs: 211.8684
2024-04-28 08:27:21 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #64: GFLOPs: 22.3412. Time: 82828.5073 us. Best GFLOPs: 211.8684
2024-04-28 08:39:51 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-28 08:39:52 [INFO] [evolutionary_search.cc:715] Picked top 58 candidate(s) from database
2024-04-28 08:39:57 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35c37e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x31a6de8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x9b6ad08)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x350b3f8)]: 0 failure(s)
2024-04-28 08:39:57 [INFO] [evolutionary_search.cc:723] Sampled 454 candidate(s)
2024-04-28 08:40:13 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35c37e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x31a6de8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x9b6ad08)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x350b3f8)]: 0 failure(s)
2024-04-28 08:40:26 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35c37e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x31a6de8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x9b6ad08)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x350b3f8)]: 0 failure(s)
2024-04-28 08:40:39 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35c37e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x31a6de8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x9b6ad08)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x350b3f8)]: 0 failure(s)
2024-04-28 08:40:52 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35c37e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x31a6de8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x9b6ad08)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x350b3f8)]: 0 failure(s)
2024-04-28 08:41:00 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9794  0.9794  0.9332  0.8799  0.8779  0.8398  0.7982  0.7742  0.7729  0.7721  0.7634  0.7582  0.7582  0.7582  0.7539  0.7521
[17 : 32]:	0.7487  0.7366  0.7362  0.7218  0.7210  0.7156  0.7149  0.7099  0.7076  0.7004  0.6997  0.6997  0.6997  0.6997  0.6997  0.6985
[33 : 48]:	0.6933  0.6842  0.6809  0.6809  0.6803  0.6708  0.6672  0.6618  0.6615  0.6600  0.6586  0.6489  0.6436  0.6425  0.6402  0.6398
[49 : 64]:	0.6393  0.6358  0.6347  0.6326  0.6325  0.6195  0.6195  0.6195  0.6195  0.6156  0.6128  0.6119  0.6110  0.6100  0.6100  0.6100
2024-04-28 08:41:00 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-28 08:41:00 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-28 08:43:20 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #65: GFLOPs: 212.2177. Time: 8719.7778 us. Best GFLOPs: 212.2177
2024-04-28 08:43:20 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #66: GFLOPs: 165.0571. Time: 11211.2132 us. Best GFLOPs: 212.2177
2024-04-28 08:43:20 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #67: GFLOPs: 154.9925. Time: 11939.2316 us. Best GFLOPs: 212.2177
2024-04-28 08:43:20 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #68: GFLOPs: 178.2446. Time: 10381.7480 us. Best GFLOPs: 212.2177
2024-04-28 08:43:20 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #69: GFLOPs: 169.1192. Time: 10941.9299 us. Best GFLOPs: 212.2177
2024-04-28 08:43:20 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #70: GFLOPs: 170.5405. Time: 10850.7422 us. Best GFLOPs: 212.2177
2024-04-28 08:43:20 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #71: GFLOPs: 141.6783. Time: 13061.2165 us. Best GFLOPs: 212.2177
2024-04-28 08:43:20 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #72: GFLOPs: 135.9422. Time: 13612.3386 us. Best GFLOPs: 212.2177
2024-04-28 08:43:20 [INFO] [task_scheduler.cc:121] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #73: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(256)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(3), T.int64(3), T.int64(256), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(28), T.int64(28), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(256)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(28), T.int64(28), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_fused_fused in T.parallel(T.int64(196), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(6), T.int64(4), T.int64(256)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(98) // T.int64(14) * T.int64(4) + ax2)
                    v_i3 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(14) * T.int64(2) + ax3)
                    v_i4 = T.axis.spatial(T.int64(256), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oc_block_0, n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(1), T.int64(4), T.int64(1), T.int64(2), T.int64(1), T.int64(2)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(8)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(98) * T.int64(8) + oc_chunk_1 * T.int64(2) + oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(98) // T.int64(14) * T.int64(4) + oh_1 * T.int64(4) + oh_2_init + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(14) * T.int64(2) + ow_1 * T.int64(2) + ow_2_init * T.int64(2) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(32), oc_block_0 * T.int64(32) + oc_block_1 * T.int64(32) + oc_block_2_init * T.int64(8) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(128), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(1), T.int64(4), T.int64(2), T.int64(3), T.int64(3), T.int64(1), T.int64(2), T.int64(1), T.int64(2)):
                    for oc_block_3_fused in T.vectorized(T.int64(8)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(98) * T.int64(8) + oc_chunk_1 * T.int64(2) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(98) // T.int64(14) * T.int64(4) + oh_1 * T.int64(4) + oh_2 + oh_3)
                            v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(14) * T.int64(2) + ow_1 * T.int64(2) + ow_2 * T.int64(2) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(32), oc_block_0 * T.int64(32) + oc_block_1 * T.int64(32) + oc_block_2 * T.int64(8) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(2) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)], p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)] * p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block]
                for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(2), T.int64(4)):
                    for ax3_ax4_fused in T.vectorized(T.int64(64)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(98) * T.int64(8) + oc_chunk_1 * T.int64(2) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(98) // T.int64(14) * T.int64(4) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(14) * T.int64(2) + ax3_ax4_fused // T.int64(32))
                            v_ax4 = T.axis.spatial(T.int64(32), ax3_ax4_fused % T.int64(32))
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[2, 4, 1, 2])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[7, 1, 4, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[14, 1, 1, 2])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 4, 8])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[128, 2])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=3)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79 = sch.get_loops(block=b68)
l80 = sch.fuse(l71, l72, l73, l74, preserve_unit_iters=True)
sch.parallel(loop=l80)
l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l81, preserve_unit_iters=True)
sch.parallel(loop=l104)
l105 = sch.fuse(l103, preserve_unit_iters=True)
sch.vectorize(loop=l105)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l106, l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117 = sch.get_loops(block=b70)
l118 = sch.fuse(l116, l117, preserve_unit_iters=True)
sch.vectorize(loop=l118)
b119 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141, l142 = sch.get_loops(block=b119)
b143 = sch.decompose_reduction(block=b119, loop=l127)
2024-04-28 08:43:20 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #74: GFLOPs: 326.8347. Time: 5661.8548 us. Best GFLOPs: 326.8347
2024-04-28 08:43:20 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #75: GFLOPs: 26.0434. Time: 71054.2490 us. Best GFLOPs: 326.8347
2024-04-28 08:43:20 [INFO] [task_scheduler.cc:121] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #76: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(256)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(3), T.int64(3), T.int64(256), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(28), T.int64(28), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(256)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(28), T.int64(28), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_fused_fused in T.parallel(T.int64(196), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(6), T.int64(4), T.int64(256)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(98) // T.int64(14) * T.int64(4) + ax2)
                    v_i3 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(14) * T.int64(2) + ax3)
                    v_i4 = T.axis.spatial(T.int64(256), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oc_block_0, n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(2), T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(1), T.int64(2), T.int64(1), T.int64(2), T.int64(1), T.int64(2)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(8)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(98) * T.int64(8) + oc_chunk_1 * T.int64(2) + oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(98) // T.int64(14) * T.int64(4) + oh_1 * T.int64(4) + oh_2_init + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(14) * T.int64(2) + ow_1 * T.int64(2) + ow_2_init * T.int64(2) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(32), oc_block_0 * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2_init * T.int64(8) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(16), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(4), T.int64(1), T.int64(2), T.int64(16), T.int64(3), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(2)):
                    for oc_block_3_fused in T.vectorized(T.int64(8)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(98) * T.int64(8) + oc_chunk_1 * T.int64(2) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(98) // T.int64(14) * T.int64(4) + oh_1 * T.int64(4) + oh_2 + oh_3)
                            v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(14) * T.int64(2) + ow_1 * T.int64(2) + ow_2 * T.int64(2) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(32), oc_block_0 * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2 * T.int64(8) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(16) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)], p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)] * p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(2), T.int64(4), T.int64(2)):
                    for ax4_fused in T.vectorized(T.int64(16)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(98) * T.int64(8) + oc_chunk_1 * T.int64(2) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(98) // T.int64(14) * T.int64(4) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(14) * T.int64(2) + ax3)
                            v_ax4 = T.axis.spatial(T.int64(32), oc_block_0 * T.int64(16) + ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[2, 4, 1, 2])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[7, 1, 4, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[14, 1, 1, 2])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[2, 1, 2, 8])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[16, 16])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=3)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79 = sch.get_loops(block=b68)
l80 = sch.fuse(l71, l72, l73, l74, preserve_unit_iters=True)
sch.parallel(loop=l80)
l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l81, preserve_unit_iters=True)
sch.parallel(loop=l104)
l105 = sch.fuse(l103, preserve_unit_iters=True)
sch.vectorize(loop=l105)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l106, l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117 = sch.get_loops(block=b70)
l118 = sch.fuse(l117, preserve_unit_iters=True)
sch.vectorize(loop=l118)
b119 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141, l142 = sch.get_loops(block=b119)
b143 = sch.decompose_reduction(block=b119, loop=l127)
2024-04-28 08:43:20 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #77: GFLOPs: 53.5665. Time: 34545.6990 us. Best GFLOPs: 326.8347
2024-04-28 08:43:20 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #78: GFLOPs: 147.0536. Time: 12583.7856 us. Best GFLOPs: 326.8347
2024-04-28 08:43:20 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #79: GFLOPs: 199.3589. Time: 9282.2073 us. Best GFLOPs: 326.8347
2024-04-28 08:43:20 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #80: GFLOPs: 106.4671. Time: 17380.8665 us. Best GFLOPs: 326.8347
2024-04-28 08:43:20 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #81: GFLOPs: 123.7378. Time: 14954.9307 us. Best GFLOPs: 326.8347
2024-04-28 08:43:20 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #82: GFLOPs: 26.1761. Time: 70693.8427 us. Best GFLOPs: 326.8347
2024-04-28 08:43:20 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #83: GFLOPs: 90.2554. Time: 20502.8356 us. Best GFLOPs: 326.8347
2024-04-28 08:43:20 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #84: GFLOPs: 142.7625. Time: 12962.0273 us. Best GFLOPs: 326.8347
2024-04-28 08:43:20 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #85: GFLOPs: 147.5891. Time: 12538.1299 us. Best GFLOPs: 326.8347
2024-04-28 08:43:20 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #86: GFLOPs: 405.9761. Time: 4558.1272 us. Best GFLOPs: 405.9761
2024-04-28 08:43:20 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #87: GFLOPs: 96.9310. Time: 19090.7963 us. Best GFLOPs: 405.9761
2024-04-28 08:43:20 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #88: GFLOPs: 141.7746. Time: 13052.3400 us. Best GFLOPs: 405.9761
2024-04-28 08:43:20 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #89: GFLOPs: 138.8211. Time: 13330.0449 us. Best GFLOPs: 405.9761
2024-04-28 08:43:20 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #90: GFLOPs: 13.2775. Time: 139370.2033 us. Best GFLOPs: 405.9761
2024-04-28 08:43:20 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #91: GFLOPs: 110.7222. Time: 16712.9197 us. Best GFLOPs: 405.9761
2024-04-28 08:43:20 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #92: GFLOPs: 122.8541. Time: 15062.5140 us. Best GFLOPs: 405.9761
2024-04-28 08:43:20 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #93: GFLOPs: 48.0244. Time: 38532.2705 us. Best GFLOPs: 405.9761
2024-04-28 08:43:20 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #94: GFLOPs: 88.0133. Time: 21025.1286 us. Best GFLOPs: 405.9761
2024-04-28 08:43:20 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #95: GFLOPs: 82.9743. Time: 22301.9708 us. Best GFLOPs: 405.9761
2024-04-28 08:43:20 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #96: GFLOPs: 98.4827. Time: 18790.0177 us. Best GFLOPs: 405.9761
2024-04-28 08:43:20 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #97: GFLOPs: 75.1763. Time: 24615.3516 us. Best GFLOPs: 405.9761
2024-04-28 08:43:20 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #98: GFLOPs: 84.2575. Time: 21962.3210 us. Best GFLOPs: 405.9761
2024-04-28 08:43:20 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #99: GFLOPs: 112.8238. Time: 16401.5933 us. Best GFLOPs: 405.9761
2024-04-28 08:43:20 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #100: GFLOPs: 75.6102. Time: 24474.1050 us. Best GFLOPs: 405.9761
2024-04-28 08:43:20 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #101: GFLOPs: 190.6755. Time: 9704.9229 us. Best GFLOPs: 405.9761
2024-04-28 08:43:20 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #102: GFLOPs: 79.2636. Time: 23346.0452 us. Best GFLOPs: 405.9761
2024-04-28 08:43:20 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #103: GFLOPs: 26.9546. Time: 68652.0470 us. Best GFLOPs: 405.9761
2024-04-28 08:43:20 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #104: GFLOPs: 32.4727. Time: 56985.9757 us. Best GFLOPs: 405.9761
2024-04-28 08:43:20 [INFO] [task_scheduler.cc:121] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #105: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(256)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(3), T.int64(3), T.int64(256), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(28), T.int64(28), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(256)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(28), T.int64(28), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused in T.parallel(T.int64(448), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(16), T.int64(6), T.int64(256)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(224) * T.int64(14) + ax2)
                    v_i3 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(224) // T.int64(32) * T.int64(4) + ax3)
                    v_i4 = T.axis.spatial(T.int64(256), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(2), T.int64(4), T.int64(16), T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(1)):
                with T.block("conv2d_NCHWc_init"):
                    v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                    v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(32) // T.int64(2) + oc_chunk_2_init + oc_chunk_3_init)
                    v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(224) * T.int64(14) + oh_2_init * T.int64(7) + oh_3_init)
                    v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(224) // T.int64(32) * T.int64(4) + ow_2_init + ow_3_init)
                    v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(2) * T.int64(16) + oc_block_2_init + oc_block_3_init)
                    T.reads()
                    T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                    T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                    conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
            for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(4), T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(2), T.int64(4), T.int64(16), T.int64(64), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(1)):
                with T.block("conv2d_NCHWc_update"):
                    v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                    v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(32) // T.int64(2) + oc_chunk_2 + oc_chunk_3)
                    v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(224) * T.int64(14) + oh_2 * T.int64(7) + oh_3)
                    v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(224) // T.int64(32) * T.int64(4) + ow_2 + ow_3)
                    v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(2) * T.int64(16) + oc_block_2 + oc_block_3)
                    v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(64) + ic_1)
                    v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                    v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                    T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)], p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block])
                    T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                    T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                    conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)] * p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(14), T.int64(4)):
                for ax4_fused in T.vectorized(T.int64(16)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(32) // T.int64(2) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(224) * T.int64(14) + ax2)
                        v_ax3 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(224) // T.int64(32) * T.int64(4) + ax3)
                        v_ax4 = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(2) * T.int64(16) + ax4_fused)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 16, 1, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 1, 2, 7])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[7, 1, 4, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 2, 16, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[4, 64])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=9)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85 = sch.get_loops(block=b68)
l86 = sch.fuse(l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, preserve_unit_iters=True)
sch.parallel(loop=l86)
l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l87, preserve_unit_iters=True)
sch.parallel(loop=l104)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109, l110 = sch.get_loops(block=b70)
l111 = sch.fuse(l110, preserve_unit_iters=True)
sch.vectorize(loop=l111)
b112 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l113, l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129 = sch.get_loops(block=b112)
b130 = sch.decompose_reduction(block=b112, loop=l114)
2024-04-28 08:43:20 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #106: GFLOPs: 124.7672. Time: 14831.5529 us. Best GFLOPs: 405.9761
2024-04-28 08:43:20 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #107: GFLOPs: 118.6398. Time: 15597.5534 us. Best GFLOPs: 405.9761
2024-04-28 08:43:20 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #108: GFLOPs: 123.0840. Time: 15034.3736 us. Best GFLOPs: 405.9761
2024-04-28 08:43:20 [INFO] [task_scheduler.cc:121] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #109: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(256)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(3), T.int64(3), T.int64(256), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(28), T.int64(28), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(256)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(28), T.int64(28), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused in T.parallel(T.int64(28), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(30), T.int64(256)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(14) * T.int64(2) + ax2)
                    v_i3, v_i4 = T.axis.remap("SS", [ax3, ax4])
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(8)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(4), T.int64(2), T.int64(14), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(2)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(14) * T.int64(8) + oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(14) * T.int64(2) + oh_2_init + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(28), ow_1 * T.int64(28) + ow_2_init * T.int64(2) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(4) + oc_block_2_init * T.int64(4) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(4), T.int64(3), T.int64(3), T.int64(1), T.int64(4), T.int64(2), T.int64(14), T.int64(1), T.int64(64), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(2)):
                    for oc_block_3_fused in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(14) * T.int64(8) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(14) * T.int64(2) + oh_2 + oh_3)
                            v_ow = T.axis.spatial(T.int64(28), ow_1 * T.int64(28) + ow_2 * T.int64(2) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(4) + oc_block_2 * T.int64(4) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(64) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)], p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)] * p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block]
        for ax0_ax1_ax2_ax3_ax4_fused_0 in T.parallel(T.int64(6272)):
            for ax0_ax1_ax2_ax3_ax4_fused_1 in T.vectorized(T.int64(64)):
                with T.block("T_relu"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) // T.int64(25088))
                    v_ax2 = T.axis.spatial(T.int64(28), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(25088) // T.int64(896))
                    v_ax3 = T.axis.spatial(T.int64(28), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(896) // T.int64(32))
                    v_ax4 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(32))
                    T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                    T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 2, 4, 2])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 14, 2, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 14, 2])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 8, 1, 4])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[4, 64])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
l65 = sch.sample_compute_location(block=b0, decision=7)
sch.compute_at(block=b0, loop=l65, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b66 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.unroll_explicit")
b67, b68, b69 = sch.get_child_blocks(b66)
l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82 = sch.get_loops(block=b67)
l83 = sch.fuse(l70, l71, l72, l73, l74, l75, l76, l77, preserve_unit_iters=True)
sch.parallel(loop=l83)
l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102 = sch.get_loops(block=b68)
l103 = sch.fuse(l84, preserve_unit_iters=True)
sch.parallel(loop=l103)
l104 = sch.fuse(l102, preserve_unit_iters=True)
sch.vectorize(loop=l104)
sch.annotate(block_or_loop=l103, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l103, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109 = sch.get_loops(block=b69)
l110 = sch.fuse(l105, l106, l107, l108, l109, preserve_unit_iters=True)
l111, l112 = sch.split(loop=l110, factors=[None, 64], preserve_unit_iters=True)
sch.parallel(loop=l111)
sch.vectorize(loop=l112)
b113 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132 = sch.get_loops(block=b113)
b133 = sch.decompose_reduction(block=b113, loop=l117)
2024-04-28 08:43:20 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #110: GFLOPs: 90.0467. Time: 20550.3474 us. Best GFLOPs: 405.9761
2024-04-28 08:43:20 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #111: GFLOPs: 27.3972. Time: 67542.9540 us. Best GFLOPs: 405.9761
2024-04-28 08:43:20 [INFO] [task_scheduler.cc:121] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #112: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(256)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(3), T.int64(3), T.int64(256), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(28), T.int64(28), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(256)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(28), T.int64(28), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused in T.parallel(T.int64(448), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(16), T.int64(6), T.int64(256)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(112) // T.int64(56) * T.int64(14) + ax2)
                    v_i3 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(56) // T.int64(8) * T.int64(4) + ax3)
                    v_i4 = T.axis.spatial(T.int64(256), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(16), T.int64(1), T.int64(1), T.int64(14), T.int64(1), T.int64(1)):
                with T.block("conv2d_NCHWc_init"):
                    v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                    v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(112) * T.int64(4) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(8) // T.int64(2) + oc_chunk_2_init + oc_chunk_3_init)
                    v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(112) // T.int64(56) * T.int64(14) + oh_2_init * T.int64(14) + oh_3_init)
                    v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(56) // T.int64(8) * T.int64(4) + ow_2_init + ow_3_init)
                    v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(2) * T.int64(16) + oc_block_2_init + oc_block_3_init)
                    T.reads()
                    T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                    T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                    conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
            for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(8), T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(16), T.int64(32), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(14), T.int64(1), T.int64(1)):
                with T.block("conv2d_NCHWc_update"):
                    v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                    v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(112) * T.int64(4) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(8) // T.int64(2) + oc_chunk_2 + oc_chunk_3)
                    v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(112) // T.int64(56) * T.int64(14) + oh_2 * T.int64(14) + oh_3)
                    v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(56) // T.int64(8) * T.int64(4) + ow_2 + ow_3)
                    v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(2) * T.int64(16) + oc_block_2 + oc_block_3)
                    v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(32) + ic_1)
                    v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                    v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                    T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)], p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block])
                    T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                    T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                    conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)] * p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(14), T.int64(4)):
                for ax4_fused in T.vectorized(T.int64(16)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(112) * T.int64(4) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(8) // T.int64(2) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(112) // T.int64(56) * T.int64(14) + ax2)
                        v_ax3 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(56) // T.int64(8) * T.int64(4) + ax3)
                        v_ax4 = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(2) * T.int64(16) + ax4_fused)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[4, 4, 1, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 1, 1, 14])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[7, 1, 4, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 2, 16, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[8, 32])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=9)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85 = sch.get_loops(block=b68)
l86 = sch.fuse(l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, preserve_unit_iters=True)
sch.parallel(loop=l86)
l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l87, preserve_unit_iters=True)
sch.parallel(loop=l104)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109, l110 = sch.get_loops(block=b70)
l111 = sch.fuse(l110, preserve_unit_iters=True)
sch.vectorize(loop=l111)
b112 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l113, l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129 = sch.get_loops(block=b112)
b130 = sch.decompose_reduction(block=b112, loop=l114)
2024-04-28 08:43:20 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #113: GFLOPs: 111.6591. Time: 16572.6891 us. Best GFLOPs: 405.9761
2024-04-28 08:43:20 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #114: GFLOPs: 104.9140. Time: 17638.1610 us. Best GFLOPs: 405.9761
2024-04-28 08:43:20 [INFO] [task_scheduler.cc:121] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #115: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(256)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(3), T.int64(3), T.int64(256), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(28), T.int64(28), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(256)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(28), T.int64(28), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused in T.parallel(T.int64(448), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(9), T.int64(6), T.int64(256)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(224) * T.int64(14) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(2) * T.int64(7) + ax2)
                    v_i3 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(224) // T.int64(32) * T.int64(4) + ax3)
                    v_i4 = T.axis.spatial(T.int64(256), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(32) // T.int64(2) + oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(224) * T.int64(14) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(2) * T.int64(7) + oh_2_init + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(224) // T.int64(32) * T.int64(4) + ow_1 * T.int64(4) + ow_2_init * T.int64(4) + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(32), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(32), T.int64(8), T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(32) // T.int64(2) + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(224) * T.int64(14) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(2) * T.int64(7) + oh_2 + oh_3)
                        v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(224) // T.int64(32) * T.int64(4) + ow_1 * T.int64(4) + ow_2 * T.int64(4) + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(8) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)], p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)] * p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(7), T.int64(4)):
                    for ax4_fused in T.vectorized(T.int64(32)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(32) // T.int64(2) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(224) * T.int64(14) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(2) * T.int64(7) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(224) // T.int64(32) * T.int64(4) + ax3)
                            v_ax4 = T.axis.spatial(T.int64(32), ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 16, 1, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 2, 7, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[7, 1, 1, 4])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 32, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[32, 8])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=7)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83 = sch.get_loops(block=b68)
l84 = sch.fuse(l71, l72, l73, l74, l75, l76, l77, l78, preserve_unit_iters=True)
sch.parallel(loop=l84)
l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l85, preserve_unit_iters=True)
sch.parallel(loop=l104)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109, l110, l111, l112 = sch.get_loops(block=b70)
l113 = sch.fuse(l112, preserve_unit_iters=True)
sch.vectorize(loop=l113)
b114 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133 = sch.get_loops(block=b114)
b134 = sch.decompose_reduction(block=b114, loop=l118)
2024-04-28 08:43:20 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #116: GFLOPs: 5.8055. Time: 318747.9913 us. Best GFLOPs: 405.9761
2024-04-28 08:43:20 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #117: GFLOPs: 114.7629. Time: 16124.4641 us. Best GFLOPs: 405.9761
2024-04-28 08:43:20 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #118: GFLOPs: 278.4076. Time: 6646.6972 us. Best GFLOPs: 405.9761
2024-04-28 08:43:20 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #119: GFLOPs: 226.6929. Time: 8162.9862 us. Best GFLOPs: 405.9761
2024-04-28 08:43:20 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #120: GFLOPs: 275.9200. Time: 6706.6209 us. Best GFLOPs: 405.9761
2024-04-28 08:43:20 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #121: GFLOPs: 199.3393. Time: 9283.1228 us. Best GFLOPs: 405.9761
2024-04-28 08:43:20 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #122: GFLOPs: 114.1338. Time: 16213.3430 us. Best GFLOPs: 405.9761
2024-04-28 08:43:20 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #123: GFLOPs: 148.9627. Time: 12422.5157 us. Best GFLOPs: 405.9761
2024-04-28 08:43:20 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #124: GFLOPs: 225.4342. Time: 8208.5639 us. Best GFLOPs: 405.9761
2024-04-28 08:43:20 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #125: GFLOPs: 448.7773. Time: 4123.4055 us. Best GFLOPs: 448.7773
2024-04-28 08:43:20 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #126: GFLOPs: 1.5171. Time: 1219749.4327 us. Best GFLOPs: 448.7773
2024-04-28 08:43:20 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #127: GFLOPs: 38.1474. Time: 48508.9740 us. Best GFLOPs: 448.7773
2024-04-28 08:43:20 [INFO] [task_scheduler.cc:121] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #128: Error in running:
LocalRunner: Timeout, killed after 30 seconds

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(256)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(3), T.int64(3), T.int64(256), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(28), T.int64(28), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(256)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(28), T.int64(28), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_fused_fused in T.parallel(T.int64(4), annotations={"pragma_auto_unroll_max_step": 16, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(30), T.int64(16), T.int64(256)):
                with T.block("data_pad"):
                    v_i0, v_i1, v_i2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                    v_i3 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(2) * T.int64(14) + ax3)
                    v_i4 = T.axis.spatial(T.int64(256), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oc_block_0 in range(T.int64(4)):
                for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(14), T.int64(14), T.int64(8)):
                    for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(2), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(1)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(2) * T.int64(8) + oc_chunk_1 * T.int64(8) + oc_chunk_2_init * T.int64(4) + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(28), oh_1 * T.int64(2) + oh_2_init + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(2) * T.int64(14) + ow_1 + ow_2_init + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(32), oc_block_0 * T.int64(8) + oc_block_1 + oc_block_2_init + oc_block_3_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                    for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(32), T.int64(1), T.int64(3), T.int64(1), T.int64(2), T.int64(2), T.int64(1), T.int64(1), T.int64(8), T.int64(3), T.int64(1), T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(1)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(2) * T.int64(8) + oc_chunk_1 * T.int64(8) + oc_chunk_2 * T.int64(4) + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(28), oh_1 * T.int64(2) + oh_2 + oh_3)
                            v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(2) * T.int64(14) + ow_1 + ow_2 + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(32), oc_block_0 * T.int64(8) + oc_block_1 + oc_block_2 + oc_block_3)
                            v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(8) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)], p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)] * p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(8), T.int64(28), T.int64(14)):
                    for ax4_fused in T.vectorized(T.int64(8)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(2) * T.int64(8) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(28), ax2)
                            v_ax3 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(2) * T.int64(14) + ax3)
                            v_ax4 = T.axis.spatial(T.int64(32), oc_block_0 * T.int64(8) + ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[2, 1, 2, 4])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 14, 2, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[2, 14, 1, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[4, 8, 1, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[32, 8])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=3)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79 = sch.get_loops(block=b68)
l80 = sch.fuse(l71, l72, l73, l74, preserve_unit_iters=True)
sch.parallel(loop=l80)
l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l81, preserve_unit_iters=True)
sch.parallel(loop=l104)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=16)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109, l110, l111 = sch.get_loops(block=b70)
l112 = sch.fuse(l111, preserve_unit_iters=True)
sch.vectorize(loop=l112)
b113 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136 = sch.get_loops(block=b113)
b137 = sch.decompose_reduction(block=b113, loop=l121)
2024-04-28 09:25:23 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-28 09:25:24 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-28 09:25:29 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35c37e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x31a6de8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x9b6ad08)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x350b3f8)]: 0 failure(s)
2024-04-28 09:25:29 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-28 09:25:56 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35c37e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x31a6de8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x9b6ad08)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x350b3f8)]: 0 failure(s)
2024-04-28 09:26:08 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35c37e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x31a6de8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x9b6ad08)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x350b3f8)]: 0 failure(s)
2024-04-28 09:26:21 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35c37e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x31a6de8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x9b6ad08)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x350b3f8)]: 0 failure(s)
2024-04-28 09:26:34 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35c37e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x31a6de8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x9b6ad08)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x350b3f8)]: 0 failure(s)
2024-04-28 09:26:41 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9724  0.9499  0.9421  0.9421  0.9242  0.9242  0.9242  0.8810  0.8661  0.8067  0.8067  0.8067  0.8067  0.8067  0.8067  0.8067
[17 : 32]:	0.8067  0.8067  0.8067  0.8067  0.8067  0.8067  0.8067  0.8067  0.8067  0.8067  0.8039  0.7818  0.7771  0.7771  0.7612  0.7502
[33 : 48]:	0.7502  0.7502  0.7502  0.7502  0.7494  0.7454  0.7366  0.7330  0.7295  0.7295  0.7204  0.7202  0.7199  0.7192  0.7170  0.7135
[49 : 64]:	0.7046  0.7018  0.6970  0.6952  0.6922  0.6912  0.6903  0.6890  0.6782  0.6746  0.6736  0.6699  0.6648  0.6639  0.6610  0.6580
2024-04-28 09:26:41 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-28 09:26:41 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-28 09:28:37 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #129: GFLOPs: 249.7534. Time: 7409.2726 us. Best GFLOPs: 448.7773
2024-04-28 09:28:37 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #130: GFLOPs: 186.2541. Time: 9935.3039 us. Best GFLOPs: 448.7773
2024-04-28 09:28:37 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #131: GFLOPs: 247.7829. Time: 7468.1950 us. Best GFLOPs: 448.7773
2024-04-28 09:28:37 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #132: GFLOPs: 256.8881. Time: 7203.4890 us. Best GFLOPs: 448.7773
2024-04-28 09:28:37 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #133: GFLOPs: 439.3982. Time: 4211.4213 us. Best GFLOPs: 448.7773
2024-04-28 09:28:37 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #134: GFLOPs: 451.9140. Time: 4094.7853 us. Best GFLOPs: 451.9140
2024-04-28 09:28:37 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #135: GFLOPs: 442.1974. Time: 4184.7625 us. Best GFLOPs: 451.9140
2024-04-28 09:28:37 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #136: GFLOPs: 171.7243. Time: 10775.9409 us. Best GFLOPs: 451.9140
2024-04-28 09:28:37 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #137: GFLOPs: 132.8699. Time: 13927.0863 us. Best GFLOPs: 451.9140
2024-04-28 09:28:37 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #138: GFLOPs: 270.2984. Time: 6846.1045 us. Best GFLOPs: 451.9140
2024-04-28 09:28:37 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #139: GFLOPs: 248.6772. Time: 7441.3359 us. Best GFLOPs: 451.9140
2024-04-28 09:28:37 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #140: GFLOPs: 71.1022. Time: 26025.7933 us. Best GFLOPs: 451.9140
2024-04-28 09:28:37 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #141: GFLOPs: 274.9083. Time: 6731.3026 us. Best GFLOPs: 451.9140
2024-04-28 09:28:37 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #142: GFLOPs: 253.0723. Time: 7312.1031 us. Best GFLOPs: 451.9140
2024-04-28 09:28:37 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #143: GFLOPs: 95.2406. Time: 19429.6467 us. Best GFLOPs: 451.9140
2024-04-28 09:28:37 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #144: GFLOPs: 106.6101. Time: 17357.5625 us. Best GFLOPs: 451.9140
2024-04-28 09:28:37 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #145: GFLOPs: 334.4675. Time: 5532.6474 us. Best GFLOPs: 451.9140
2024-04-28 09:28:37 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #146: GFLOPs: 248.5130. Time: 7446.2526 us. Best GFLOPs: 451.9140
2024-04-28 09:28:37 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #147: GFLOPs: 224.4427. Time: 8244.8260 us. Best GFLOPs: 451.9140
2024-04-28 09:28:37 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #148: GFLOPs: 94.3602. Time: 19610.9217 us. Best GFLOPs: 451.9140
2024-04-28 09:28:37 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #149: GFLOPs: 492.8086. Time: 3754.9891 us. Best GFLOPs: 492.8086
2024-04-28 09:28:37 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #150: GFLOPs: 222.5706. Time: 8314.1733 us. Best GFLOPs: 492.8086
2024-04-28 09:28:37 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #151: GFLOPs: 130.4261. Time: 14188.0447 us. Best GFLOPs: 492.8086
2024-04-28 09:28:37 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #152: GFLOPs: 159.5155. Time: 11600.6943 us. Best GFLOPs: 492.8086
2024-04-28 09:28:37 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #153: GFLOPs: 93.9635. Time: 19693.7132 us. Best GFLOPs: 492.8086
2024-04-28 09:28:37 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #154: GFLOPs: 249.8338. Time: 7406.8862 us. Best GFLOPs: 492.8086
2024-04-28 09:28:37 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #155: GFLOPs: 192.7289. Time: 9601.5218 us. Best GFLOPs: 492.8086
2024-04-28 09:28:37 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #156: GFLOPs: 66.7877. Time: 27707.0802 us. Best GFLOPs: 492.8086
2024-04-28 09:28:37 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #157: GFLOPs: 361.8835. Time: 5113.4990 us. Best GFLOPs: 492.8086
2024-04-28 09:28:37 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #158: GFLOPs: 362.0110. Time: 5111.6986 us. Best GFLOPs: 492.8086
2024-04-28 09:28:37 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #159: GFLOPs: 94.4118. Time: 19600.2065 us. Best GFLOPs: 492.8086
2024-04-28 09:28:37 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #160: GFLOPs: 185.3896. Time: 9981.6303 us. Best GFLOPs: 492.8086
2024-04-28 09:28:37 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #161: GFLOPs: 118.1138. Time: 15667.0129 us. Best GFLOPs: 492.8086
2024-04-28 09:28:37 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #162: GFLOPs: 236.6811. Time: 7818.4993 us. Best GFLOPs: 492.8086
2024-04-28 09:28:37 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #163: GFLOPs: 237.0692. Time: 7805.6998 us. Best GFLOPs: 492.8086
2024-04-28 09:28:37 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #164: GFLOPs: 187.6903. Time: 9859.2782 us. Best GFLOPs: 492.8086
2024-04-28 09:28:37 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #165: GFLOPs: 453.9053. Time: 4076.8218 us. Best GFLOPs: 492.8086
2024-04-28 09:28:37 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #166: GFLOPs: 217.1739. Time: 8520.7776 us. Best GFLOPs: 492.8086
2024-04-28 09:28:37 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #167: GFLOPs: 16.1933. Time: 114274.9207 us. Best GFLOPs: 492.8086
2024-04-28 09:28:37 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #168: GFLOPs: 182.1227. Time: 10160.6820 us. Best GFLOPs: 492.8086
2024-04-28 09:28:37 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #169: GFLOPs: 148.5461. Time: 12457.3481 us. Best GFLOPs: 492.8086
2024-04-28 09:28:37 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #170: GFLOPs: 168.9519. Time: 10952.7688 us. Best GFLOPs: 492.8086
2024-04-28 09:28:37 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #171: GFLOPs: 311.5488. Time: 5939.6499 us. Best GFLOPs: 492.8086
2024-04-28 09:28:37 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #172: GFLOPs: 272.5938. Time: 6788.4543 us. Best GFLOPs: 492.8086
2024-04-28 09:28:37 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #173: GFLOPs: 258.3640. Time: 7162.3398 us. Best GFLOPs: 492.8086
2024-04-28 09:28:37 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #174: GFLOPs: 409.3936. Time: 4520.0772 us. Best GFLOPs: 492.8086
2024-04-28 09:28:37 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #175: GFLOPs: 148.3400. Time: 12474.6573 us. Best GFLOPs: 492.8086
2024-04-28 09:28:37 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #176: GFLOPs: 297.9890. Time: 6209.9299 us. Best GFLOPs: 492.8086
2024-04-28 09:28:37 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #177: GFLOPs: 130.4745. Time: 14182.7784 us. Best GFLOPs: 492.8086
2024-04-28 09:28:37 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #178: GFLOPs: 57.2912. Time: 32299.7327 us. Best GFLOPs: 492.8086
2024-04-28 09:28:37 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #179: GFLOPs: 156.3314. Time: 11836.9762 us. Best GFLOPs: 492.8086
2024-04-28 09:28:37 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #180: GFLOPs: 178.1465. Time: 10387.4659 us. Best GFLOPs: 492.8086
2024-04-28 09:28:37 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #181: GFLOPs: 216.8471. Time: 8533.6195 us. Best GFLOPs: 492.8086
2024-04-28 09:28:37 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #182: GFLOPs: 90.6861. Time: 20405.4438 us. Best GFLOPs: 492.8086
2024-04-28 09:28:37 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #183: GFLOPs: 82.8298. Time: 22340.8732 us. Best GFLOPs: 492.8086
2024-04-28 09:28:37 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #184: GFLOPs: 198.2166. Time: 9335.6990 us. Best GFLOPs: 492.8086
2024-04-28 09:28:37 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #185: GFLOPs: 142.5606. Time: 12980.3849 us. Best GFLOPs: 492.8086
2024-04-28 09:28:37 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #186: GFLOPs: 465.3463. Time: 3976.5885 us. Best GFLOPs: 492.8086
2024-04-28 09:28:37 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #187: GFLOPs: 95.1898. Time: 19440.0220 us. Best GFLOPs: 492.8086
2024-04-28 09:28:37 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #188: GFLOPs: 196.3787. Time: 9423.0714 us. Best GFLOPs: 492.8086
2024-04-28 09:28:37 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #189: GFLOPs: 311.2683. Time: 5945.0036 us. Best GFLOPs: 492.8086
2024-04-28 09:28:37 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #190: GFLOPs: 15.4005. Time: 120157.5133 us. Best GFLOPs: 492.8086
2024-04-28 09:28:37 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #191: GFLOPs: 1.6701. Time: 1108010.6230 us. Best GFLOPs: 492.8086
2024-04-28 09:28:37 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #192: GFLOPs: 5.1121. Time: 361980.9463 us. Best GFLOPs: 492.8086
2024-04-28 10:13:06 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-28 10:13:07 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-28 10:13:11 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35c37e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x31a6de8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x9b6ad08)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x350b3f8)]: 0 failure(s)
2024-04-28 10:13:11 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-28 10:13:24 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35c37e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x31a6de8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x9b6ad08)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x350b3f8)]: 0 failure(s)
2024-04-28 10:13:36 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35c37e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x31a6de8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x9b6ad08)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x350b3f8)]: 0 failure(s)
2024-04-28 10:13:49 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35c37e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x31a6de8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x9b6ad08)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x350b3f8)]: 0 failure(s)
2024-04-28 10:14:01 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35c37e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x31a6de8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x9b6ad08)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x350b3f8)]: 0 failure(s)
2024-04-28 10:14:08 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9109  0.9109  0.9109  0.8822  0.8681  0.8681  0.8681  0.8681  0.8221  0.8110  0.8097  0.8048  0.8010  0.7929  0.7818  0.7784
[17 : 32]:	0.7784  0.7724  0.7724  0.7677  0.7671  0.7622  0.7562  0.7542  0.7525  0.7447  0.7358  0.7309  0.7295  0.7257  0.7240  0.7240
[33 : 48]:	0.7225  0.7223  0.7223  0.7223  0.7205  0.7152  0.7152  0.7151  0.7095  0.7055  0.7051  0.7041  0.7034  0.6952  0.6952  0.6952
[49 : 64]:	0.6947  0.6946  0.6946  0.6933  0.6932  0.6867  0.6859  0.6830  0.6830  0.6830  0.6830  0.6828  0.6819  0.6808  0.6798  0.6776
2024-04-28 10:14:08 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-28 10:14:08 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-28 10:15:38 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #193: GFLOPs: 458.7541. Time: 4033.7316 us. Best GFLOPs: 492.8086
2024-04-28 10:15:38 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #194: GFLOPs: 460.4746. Time: 4018.6598 us. Best GFLOPs: 492.8086
2024-04-28 10:15:38 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #195: GFLOPs: 457.7166. Time: 4042.8750 us. Best GFLOPs: 492.8086
2024-04-28 10:15:38 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #196: GFLOPs: 553.2418. Time: 3344.8137 us. Best GFLOPs: 553.2418
2024-04-28 10:15:38 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #197: GFLOPs: 451.5219. Time: 4098.3416 us. Best GFLOPs: 553.2418
2024-04-28 10:15:38 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #198: GFLOPs: 449.6430. Time: 4115.4671 us. Best GFLOPs: 553.2418
2024-04-28 10:15:38 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #199: GFLOPs: 448.4949. Time: 4126.0022 us. Best GFLOPs: 553.2418
2024-04-28 10:15:38 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #200: GFLOPs: 450.1543. Time: 4110.7924 us. Best GFLOPs: 553.2418
2024-04-28 10:15:38 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #201: GFLOPs: 260.5308. Time: 7102.7709 us. Best GFLOPs: 553.2418
2024-04-28 10:15:38 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #202: GFLOPs: 334.9116. Time: 5525.3109 us. Best GFLOPs: 553.2418
2024-04-28 10:15:38 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #203: GFLOPs: 684.8595. Time: 2702.0006 us. Best GFLOPs: 684.8595
2024-04-28 10:15:38 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #204: GFLOPs: 102.1326. Time: 18118.5170 us. Best GFLOPs: 684.8595
2024-04-28 10:15:38 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #205: GFLOPs: 565.9505. Time: 3269.7046 us. Best GFLOPs: 684.8595
2024-04-28 10:15:38 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #206: GFLOPs: 163.8041. Time: 11296.9767 us. Best GFLOPs: 684.8595
2024-04-28 10:15:38 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #207: GFLOPs: 574.6729. Time: 3220.0767 us. Best GFLOPs: 684.8595
2024-04-28 10:15:38 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #208: GFLOPs: 456.1449. Time: 4056.8046 us. Best GFLOPs: 684.8595
2024-04-28 10:15:38 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #209: GFLOPs: 459.3756. Time: 4028.2741 us. Best GFLOPs: 684.8595
2024-04-28 10:15:38 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #210: GFLOPs: 369.3007. Time: 5010.7972 us. Best GFLOPs: 684.8595
2024-04-28 10:15:38 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #211: GFLOPs: 369.1829. Time: 5012.3962 us. Best GFLOPs: 684.8595
2024-04-28 10:15:38 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #212: GFLOPs: 441.6511. Time: 4189.9384 us. Best GFLOPs: 684.8595
2024-04-28 10:15:38 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #213: GFLOPs: 263.2241. Time: 7030.0963 us. Best GFLOPs: 684.8595
2024-04-28 10:15:38 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #214: GFLOPs: 407.6066. Time: 4539.8942 us. Best GFLOPs: 684.8595
2024-04-28 10:15:38 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #215: GFLOPs: 354.4166. Time: 5221.2309 us. Best GFLOPs: 684.8595
2024-04-28 10:15:38 [INFO] [task_scheduler.cc:121] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #216: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(256)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(3), T.int64(3), T.int64(256), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(28), T.int64(28), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(256)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(28), T.int64(28), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused in T.parallel(T.int64(196), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(2), T.int64(2), T.int64(2), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(4), T.int64(1), T.int64(2), T.int64(2), T.int64(1)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(8)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(98) * T.int64(8) + oc_chunk_1 * T.int64(4) + oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(98) // T.int64(14) * T.int64(4) + oh_1 * T.int64(2) + oh_2_init * T.int64(2) + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(14) * T.int64(2) + ow_1 + ow_2_init + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2_init * T.int64(8) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0 in T.grid(T.int64(16), T.int64(3), T.int64(3)):
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(2), T.int64(1)):
                        for ax4_fused in T.vectorized(T.int64(16)):
                            with T.block("data_pad"):
                                v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                                v_i2 = T.axis.spatial(T.int64(30), kh_0 + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(98) // T.int64(14) * T.int64(4) + oh_1 * T.int64(2) + ax2)
                                v_i3 = T.axis.spatial(T.int64(30), ow_1 + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(14) * T.int64(2) + kw_0 + ax3)
                                v_i4 = T.axis.spatial(T.int64(256), ic_0 * T.int64(16) + ax4_fused)
                                T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                                T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                                data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                    for n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(4), T.int64(16), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(2), T.int64(1)):
                        for oc_block_3_fused in T.vectorized(T.int64(8)):
                            with T.block("conv2d_NCHWc_update"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                                v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(98) * T.int64(8) + oc_chunk_1 * T.int64(4) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                                v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(98) // T.int64(14) * T.int64(4) + oh_1 * T.int64(2) + oh_2 * T.int64(2) + oh_3)
                                v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(14) * T.int64(2) + ow_1 + ow_2 + ow_3)
                                v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2 * T.int64(8) + oc_block_3_fused)
                                v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(16) + ic_1)
                                v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                                v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                                T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)], p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block])
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)] * p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block]
            for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(8), T.int64(4)):
                for ax3_ax4_fused in T.vectorized(T.int64(64)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(98) * T.int64(8) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(98) // T.int64(14) * T.int64(4) + ax2)
                        v_ax3 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(14) * T.int64(2) + ax3_ax4_fused // T.int64(32))
                        v_ax4 = T.axis.spatial(T.int64(32), ax3_ax4_fused % T.int64(32))
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[2, 2, 2, 2])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[7, 2, 1, 2])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[14, 2, 1, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 4, 8])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[16, 16])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=12)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88 = sch.get_loops(block=b68)
l89 = sch.fuse(l71, l72, l73, l74, l75, preserve_unit_iters=True)
sch.parallel(loop=l89)
l90 = sch.fuse(l88, preserve_unit_iters=True)
sch.vectorize(loop=l90)
l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107, l108, l109, l110, l111, l112 = sch.get_loops(block=b69)
l113 = sch.fuse(l91, preserve_unit_iters=True)
sch.parallel(loop=l113)
l114 = sch.fuse(l112, preserve_unit_iters=True)
sch.vectorize(loop=l114)
sch.annotate(block_or_loop=l113, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l113, ann_key="pragma_unroll_explicit", ann_val=1)
l115, l116, l117, l118, l119, l120 = sch.get_loops(block=b70)
l121 = sch.fuse(l119, l120, preserve_unit_iters=True)
sch.vectorize(loop=l121)
b122 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141, l142, l143, l144 = sch.get_loops(block=b122)
b145 = sch.decompose_reduction(block=b122, loop=l129)
2024-04-28 10:15:38 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #217: GFLOPs: 140.4308. Time: 13177.2470 us. Best GFLOPs: 684.8595
2024-04-28 10:15:38 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #218: GFLOPs: 173.3155. Time: 10677.0059 us. Best GFLOPs: 684.8595
2024-04-28 10:15:38 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #219: GFLOPs: 443.9551. Time: 4168.1934 us. Best GFLOPs: 684.8595
2024-04-28 10:15:38 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #220: GFLOPs: 353.8897. Time: 5229.0050 us. Best GFLOPs: 684.8595
2024-04-28 10:15:38 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #221: GFLOPs: 432.9582. Time: 4274.0636 us. Best GFLOPs: 684.8595
2024-04-28 10:15:38 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #222: GFLOPs: 256.4574. Time: 7215.5878 us. Best GFLOPs: 684.8595
2024-04-28 10:15:38 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #223: GFLOPs: 363.7115. Time: 5087.7981 us. Best GFLOPs: 684.8595
2024-04-28 10:15:38 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #224: GFLOPs: 352.9412. Time: 5243.0572 us. Best GFLOPs: 684.8595
2024-04-28 10:15:38 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #225: GFLOPs: 451.0597. Time: 4102.5406 us. Best GFLOPs: 684.8595
2024-04-28 10:15:38 [INFO] [task_scheduler.cc:121] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #226: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(256)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(3), T.int64(3), T.int64(256), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(28), T.int64(28), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(256)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(28), T.int64(28), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused in T.parallel(T.int64(196), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(2), T.int64(2), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(4), T.int64(1), T.int64(2), T.int64(2), T.int64(2)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(8)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(98) * T.int64(8) + oc_chunk_1 * T.int64(4) + oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(98) // T.int64(14) * T.int64(4) + oh_1 * T.int64(2) + oh_2_init * T.int64(2) + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(14) * T.int64(2) + ow_1 * T.int64(2) + ow_2_init * T.int64(2) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2_init * T.int64(8) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0 in T.grid(T.int64(16), T.int64(3)):
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(2), T.int64(4)):
                        for ax4_fused in T.vectorized(T.int64(16)):
                            with T.block("data_pad"):
                                v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                                v_i2 = T.axis.spatial(T.int64(30), kh_0 + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(98) // T.int64(14) * T.int64(4) + oh_1 * T.int64(2) + ax2)
                                v_i3 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(14) * T.int64(2) + ax3)
                                v_i4 = T.axis.spatial(T.int64(256), ic_0 * T.int64(16) + ax4_fused)
                                T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                                T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                                data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                    for kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(3), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(4), T.int64(16), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(2), T.int64(2)):
                        for oc_block_3_fused in T.vectorized(T.int64(8)):
                            with T.block("conv2d_NCHWc_update"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                                v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(98) * T.int64(8) + oc_chunk_1 * T.int64(4) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                                v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(98) // T.int64(14) * T.int64(4) + oh_1 * T.int64(2) + oh_2 * T.int64(2) + oh_3)
                                v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(14) * T.int64(2) + ow_1 * T.int64(2) + ow_2 * T.int64(2) + ow_3)
                                v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2 * T.int64(8) + oc_block_3_fused)
                                v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(16) + ic_1)
                                v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                                v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                                T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)], p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block])
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)] * p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block]
            for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(8), T.int64(4)):
                for ax3_ax4_fused in T.vectorized(T.int64(64)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(98) * T.int64(8) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(98) // T.int64(14) * T.int64(4) + ax2)
                        v_ax3 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(14) * T.int64(2) + ax3_ax4_fused // T.int64(32))
                        v_ax4 = T.axis.spatial(T.int64(32), ax3_ax4_fused % T.int64(32))
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[2, 2, 2, 2])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[7, 2, 1, 2])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[14, 1, 1, 2])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 4, 8])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[16, 16])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=11)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87 = sch.get_loops(block=b68)
l88 = sch.fuse(l71, l72, l73, l74, l75, preserve_unit_iters=True)
sch.parallel(loop=l88)
l89 = sch.fuse(l87, preserve_unit_iters=True)
sch.vectorize(loop=l89)
l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107, l108, l109, l110, l111 = sch.get_loops(block=b69)
l112 = sch.fuse(l90, preserve_unit_iters=True)
sch.parallel(loop=l112)
l113 = sch.fuse(l111, preserve_unit_iters=True)
sch.vectorize(loop=l113)
sch.annotate(block_or_loop=l112, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l112, ann_key="pragma_unroll_explicit", ann_val=1)
l114, l115, l116, l117, l118, l119 = sch.get_loops(block=b70)
l120 = sch.fuse(l118, l119, preserve_unit_iters=True)
sch.vectorize(loop=l120)
b121 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141, l142, l143 = sch.get_loops(block=b121)
b144 = sch.decompose_reduction(block=b121, loop=l128)
2024-04-28 10:15:38 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #227: GFLOPs: 173.0454. Time: 10693.6732 us. Best GFLOPs: 684.8595
2024-04-28 10:15:38 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #228: GFLOPs: 177.8518. Time: 10404.6811 us. Best GFLOPs: 684.8595
2024-04-28 10:15:38 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #229: GFLOPs: 231.7340. Time: 7985.4090 us. Best GFLOPs: 684.8595
2024-04-28 10:15:38 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #230: GFLOPs: 415.7402. Time: 4451.0753 us. Best GFLOPs: 684.8595
2024-04-28 10:15:38 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #231: GFLOPs: 415.4457. Time: 4454.2306 us. Best GFLOPs: 684.8595
2024-04-28 10:15:38 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #232: GFLOPs: 489.6621. Time: 3779.1184 us. Best GFLOPs: 684.8595
2024-04-28 10:15:38 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #233: GFLOPs: 417.2172. Time: 4435.3181 us. Best GFLOPs: 684.8595
2024-04-28 10:15:38 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #234: GFLOPs: 379.7152. Time: 4873.3658 us. Best GFLOPs: 684.8595
2024-04-28 10:15:38 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #235: GFLOPs: 324.3207. Time: 5705.7432 us. Best GFLOPs: 684.8595
2024-04-28 10:15:38 [INFO] [task_scheduler.cc:121] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #236: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(256)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(3), T.int64(3), T.int64(256), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(28), T.int64(28), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(256)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(28), T.int64(28), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused in T.parallel(T.int64(196), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(2), T.int64(2), T.int64(1), T.int64(4), T.int64(1), T.int64(2), T.int64(2), T.int64(2)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(8)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(98) * T.int64(8) + oc_chunk_1 * T.int64(4) + oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(98) // T.int64(14) * T.int64(4) + oh_1 * T.int64(4) + oh_2_init * T.int64(2) + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(14) * T.int64(2) + ow_1 * T.int64(2) + ow_2_init * T.int64(2) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2_init * T.int64(8) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0 in T.grid(T.int64(16), T.int64(3), T.int64(3)):
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(2)):
                        for ax4_fused in T.vectorized(T.int64(16)):
                            with T.block("data_pad"):
                                v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                                v_i2 = T.axis.spatial(T.int64(30), kh_0 + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(98) // T.int64(14) * T.int64(4) + ax2)
                                v_i3 = T.axis.spatial(T.int64(30), kw_0 + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(14) * T.int64(2) + ax3)
                                v_i4 = T.axis.spatial(T.int64(256), ic_0 * T.int64(16) + ax4_fused)
                                T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                                T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                                data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                    for n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(1), T.int64(2), T.int64(2), T.int64(1), T.int64(4), T.int64(16), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(2), T.int64(2)):
                        for oc_block_3_fused in T.vectorized(T.int64(8)):
                            with T.block("conv2d_NCHWc_update"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                                v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(98) * T.int64(8) + oc_chunk_1 * T.int64(4) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                                v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(98) // T.int64(14) * T.int64(4) + oh_1 * T.int64(4) + oh_2 * T.int64(2) + oh_3)
                                v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(14) * T.int64(2) + ow_1 * T.int64(2) + ow_2 * T.int64(2) + ow_3)
                                v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2 * T.int64(8) + oc_block_3_fused)
                                v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(16) + ic_1)
                                v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                                v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                                T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)], p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block])
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)] * p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block]
            for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(8), T.int64(4)):
                for ax3_ax4_fused in T.vectorized(T.int64(64)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(98) * T.int64(8) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(98) // T.int64(14) * T.int64(4) + ax2)
                        v_ax3 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(14) * T.int64(2) + ax3_ax4_fused // T.int64(32))
                        v_ax4 = T.axis.spatial(T.int64(32), ax3_ax4_fused % T.int64(32))
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[2, 2, 2, 2])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[7, 1, 2, 2])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[14, 1, 1, 2])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 4, 8])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[16, 16])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=12)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88 = sch.get_loops(block=b68)
l89 = sch.fuse(l71, l72, l73, l74, l75, preserve_unit_iters=True)
sch.parallel(loop=l89)
l90 = sch.fuse(l88, preserve_unit_iters=True)
sch.vectorize(loop=l90)
l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107, l108, l109, l110, l111, l112 = sch.get_loops(block=b69)
l113 = sch.fuse(l91, preserve_unit_iters=True)
sch.parallel(loop=l113)
l114 = sch.fuse(l112, preserve_unit_iters=True)
sch.vectorize(loop=l114)
sch.annotate(block_or_loop=l113, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l113, ann_key="pragma_unroll_explicit", ann_val=1)
l115, l116, l117, l118, l119, l120 = sch.get_loops(block=b70)
l121 = sch.fuse(l119, l120, preserve_unit_iters=True)
sch.vectorize(loop=l121)
b122 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141, l142, l143, l144 = sch.get_loops(block=b122)
b145 = sch.decompose_reduction(block=b122, loop=l129)
2024-04-28 10:15:38 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #237: GFLOPs: 570.8393. Time: 3241.7017 us. Best GFLOPs: 684.8595
2024-04-28 10:15:38 [INFO] [task_scheduler.cc:121] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #238: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(256)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(3), T.int64(3), T.int64(256), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(28), T.int64(28), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(256)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(28), T.int64(28), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused in T.parallel(T.int64(196), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(2), T.int64(2), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(4), T.int64(1), T.int64(2), T.int64(2), T.int64(2)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(8)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(98) * T.int64(8) + oc_chunk_1 * T.int64(4) + oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(98) // T.int64(14) * T.int64(4) + oh_1 * T.int64(2) + oh_2_init * T.int64(2) + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(14) * T.int64(2) + ow_1 * T.int64(2) + ow_2_init * T.int64(2) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2_init * T.int64(8) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0 in range(T.int64(16)):
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                        for ax4_fused in T.vectorized(T.int64(16)):
                            with T.block("data_pad"):
                                v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                                v_i2 = T.axis.spatial(T.int64(30), oh_1 * T.int64(2) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(98) // T.int64(14) * T.int64(4) + ax2)
                                v_i3 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(14) * T.int64(2) + ax3)
                                v_i4 = T.axis.spatial(T.int64(256), ic_0 * T.int64(16) + ax4_fused)
                                T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                                T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                                data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                    for kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(3), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(4), T.int64(16), T.int64(1), T.int64(3), T.int64(1), T.int64(2), T.int64(2), T.int64(2)):
                        for oc_block_3_fused in T.vectorized(T.int64(8)):
                            with T.block("conv2d_NCHWc_update"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                                v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(98) * T.int64(8) + oc_chunk_1 * T.int64(4) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                                v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(98) // T.int64(14) * T.int64(4) + oh_1 * T.int64(2) + oh_2 * T.int64(2) + oh_3)
                                v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(14) * T.int64(2) + ow_1 * T.int64(2) + ow_2 * T.int64(2) + ow_3)
                                v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2 * T.int64(8) + oc_block_3_fused)
                                v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(16) + ic_1)
                                v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                                v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                                T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)], p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block])
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)] * p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block]
            for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(8), T.int64(4)):
                for ax3_ax4_fused in T.vectorized(T.int64(64)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(98) * T.int64(8) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(98) // T.int64(14) * T.int64(4) + ax2)
                        v_ax3 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(14) * T.int64(2) + ax3_ax4_fused // T.int64(32))
                        v_ax4 = T.axis.spatial(T.int64(32), ax3_ax4_fused % T.int64(32))
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[2, 2, 2, 2])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[7, 2, 1, 2])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[14, 1, 1, 2])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 4, 8])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[16, 16])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=10)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86 = sch.get_loops(block=b68)
l87 = sch.fuse(l71, l72, l73, l74, l75, preserve_unit_iters=True)
sch.parallel(loop=l87)
l88 = sch.fuse(l86, preserve_unit_iters=True)
sch.vectorize(loop=l88)
l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107, l108, l109, l110 = sch.get_loops(block=b69)
l111 = sch.fuse(l89, preserve_unit_iters=True)
sch.parallel(loop=l111)
l112 = sch.fuse(l110, preserve_unit_iters=True)
sch.vectorize(loop=l112)
sch.annotate(block_or_loop=l111, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l111, ann_key="pragma_unroll_explicit", ann_val=1)
l113, l114, l115, l116, l117, l118 = sch.get_loops(block=b70)
l119 = sch.fuse(l117, l118, preserve_unit_iters=True)
sch.vectorize(loop=l119)
b120 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141, l142 = sch.get_loops(block=b120)
b143 = sch.decompose_reduction(block=b120, loop=l127)
2024-04-28 10:15:38 [INFO] [task_scheduler.cc:121] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #239: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(256)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(3), T.int64(3), T.int64(256), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(28), T.int64(28), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(256)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(28), T.int64(28), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused in T.parallel(T.int64(196), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(2), T.int64(2), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(4), T.int64(1), T.int64(2), T.int64(2), T.int64(2)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(8)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(98) * T.int64(8) + oc_chunk_1 * T.int64(4) + oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(98) // T.int64(14) * T.int64(4) + oh_1 * T.int64(2) + oh_2_init * T.int64(2) + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(14) * T.int64(2) + ow_1 * T.int64(2) + ow_2_init * T.int64(2) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2_init * T.int64(8) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0 in range(T.int64(16)):
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                        for ax4_fused in T.vectorized(T.int64(16)):
                            with T.block("data_pad"):
                                v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                                v_i2 = T.axis.spatial(T.int64(30), oh_1 * T.int64(2) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(98) // T.int64(14) * T.int64(4) + ax2)
                                v_i3 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(14) * T.int64(2) + ax3)
                                v_i4 = T.axis.spatial(T.int64(256), ic_0 * T.int64(16) + ax4_fused)
                                T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                                T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                                data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                    for kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(1), T.int64(3), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(4), T.int64(16), T.int64(3), T.int64(1), T.int64(1), T.int64(2), T.int64(2), T.int64(2)):
                        for oc_block_3_fused in T.vectorized(T.int64(8)):
                            with T.block("conv2d_NCHWc_update"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                                v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(98) * T.int64(8) + oc_chunk_1 * T.int64(4) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                                v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(98) // T.int64(14) * T.int64(4) + oh_1 * T.int64(2) + oh_2 * T.int64(2) + oh_3)
                                v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(14) * T.int64(2) + ow_1 * T.int64(2) + ow_2 * T.int64(2) + ow_3)
                                v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2 * T.int64(8) + oc_block_3_fused)
                                v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(16) + ic_1)
                                v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                                v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                                T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)], p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block])
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)] * p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block]
            for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(8), T.int64(4)):
                for ax3_ax4_fused in T.vectorized(T.int64(64)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(98) * T.int64(8) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(98) // T.int64(14) * T.int64(4) + ax2)
                        v_ax3 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(14) * T.int64(2) + ax3_ax4_fused // T.int64(32))
                        v_ax4 = T.axis.spatial(T.int64(32), ax3_ax4_fused % T.int64(32))
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[2, 2, 2, 2])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[7, 2, 1, 2])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[14, 1, 1, 2])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 4, 8])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[16, 16])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=10)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86 = sch.get_loops(block=b68)
l87 = sch.fuse(l71, l72, l73, l74, l75, preserve_unit_iters=True)
sch.parallel(loop=l87)
l88 = sch.fuse(l86, preserve_unit_iters=True)
sch.vectorize(loop=l88)
l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107, l108, l109, l110 = sch.get_loops(block=b69)
l111 = sch.fuse(l89, preserve_unit_iters=True)
sch.parallel(loop=l111)
l112 = sch.fuse(l110, preserve_unit_iters=True)
sch.vectorize(loop=l112)
sch.annotate(block_or_loop=l111, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l111, ann_key="pragma_unroll_explicit", ann_val=1)
l113, l114, l115, l116, l117, l118 = sch.get_loops(block=b70)
l119 = sch.fuse(l117, l118, preserve_unit_iters=True)
sch.vectorize(loop=l119)
b120 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141, l142 = sch.get_loops(block=b120)
b143 = sch.decompose_reduction(block=b120, loop=l127)
2024-04-28 10:15:38 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #240: GFLOPs: 100.0255. Time: 18500.1887 us. Best GFLOPs: 684.8595
2024-04-28 10:15:38 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #241: GFLOPs: 316.9794. Time: 5837.8906 us. Best GFLOPs: 684.8595
2024-04-28 10:15:38 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #242: GFLOPs: 346.6466. Time: 5338.2629 us. Best GFLOPs: 684.8595
2024-04-28 10:15:39 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #243: GFLOPs: 346.4258. Time: 5341.6656 us. Best GFLOPs: 684.8595
2024-04-28 10:15:39 [INFO] [task_scheduler.cc:121] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #244: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(256)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(3), T.int64(3), T.int64(256), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(28), T.int64(28), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(256)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(28), T.int64(28), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused in T.parallel(T.int64(196), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(2), T.int64(2), T.int64(2), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(2), T.int64(1)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(32)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(98) * T.int64(8) + oc_chunk_1 * T.int64(4) + oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(98) // T.int64(14) * T.int64(4) + oh_1 * T.int64(2) + oh_2_init * T.int64(2) + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(14) * T.int64(2) + ow_1 + ow_2_init + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2_init * T.int64(32) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0 in T.grid(T.int64(16), T.int64(1), T.int64(3)):
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(1)):
                        for ax4_fused in T.vectorized(T.int64(16)):
                            with T.block("data_pad"):
                                v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                                v_i2 = T.axis.spatial(T.int64(30), oh_1 * T.int64(2) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(98) // T.int64(14) * T.int64(4) + ax2)
                                v_i3 = T.axis.spatial(T.int64(30), ow_1 + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(14) * T.int64(2) + kw_0 + ax3)
                                v_i4 = T.axis.spatial(T.int64(256), ic_0 * T.int64(16) + ax4_fused)
                                T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                                T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                                data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                    for n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(16), T.int64(3), T.int64(1), T.int64(1), T.int64(2), T.int64(2), T.int64(1)):
                        for oc_block_3_fused in T.vectorized(T.int64(32)):
                            with T.block("conv2d_NCHWc_update"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                                v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(98) * T.int64(8) + oc_chunk_1 * T.int64(4) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                                v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(98) // T.int64(14) * T.int64(4) + oh_1 * T.int64(2) + oh_2 * T.int64(2) + oh_3)
                                v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(14) * T.int64(2) + ow_1 + ow_2 + ow_3)
                                v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2 * T.int64(32) + oc_block_3_fused)
                                v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(16) + ic_1)
                                v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                                v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                                T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)], p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block])
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)] * p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block]
            for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(8), T.int64(4)):
                for ax3_ax4_fused in T.vectorized(T.int64(64)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(98) * T.int64(8) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(98) // T.int64(14) * T.int64(4) + ax2)
                        v_ax3 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(14) * T.int64(2) + ax3_ax4_fused // T.int64(32))
                        v_ax4 = T.axis.spatial(T.int64(32), ax3_ax4_fused % T.int64(32))
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[2, 2, 2, 2])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[7, 2, 1, 2])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[14, 2, 1, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 1, 32])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[16, 16])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=12)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88 = sch.get_loops(block=b68)
l89 = sch.fuse(l71, l72, l73, l74, l75, preserve_unit_iters=True)
sch.parallel(loop=l89)
l90 = sch.fuse(l88, preserve_unit_iters=True)
sch.vectorize(loop=l90)
l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107, l108, l109, l110, l111, l112 = sch.get_loops(block=b69)
l113 = sch.fuse(l91, preserve_unit_iters=True)
sch.parallel(loop=l113)
l114 = sch.fuse(l112, preserve_unit_iters=True)
sch.vectorize(loop=l114)
sch.annotate(block_or_loop=l113, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l113, ann_key="pragma_unroll_explicit", ann_val=1)
l115, l116, l117, l118, l119, l120 = sch.get_loops(block=b70)
l121 = sch.fuse(l119, l120, preserve_unit_iters=True)
sch.vectorize(loop=l121)
b122 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141, l142, l143, l144 = sch.get_loops(block=b122)
b145 = sch.decompose_reduction(block=b122, loop=l129)
2024-04-28 10:15:39 [INFO] [task_scheduler.cc:121] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #245: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(256)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(3), T.int64(3), T.int64(256), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(28), T.int64(28), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(256)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(28), T.int64(28), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused in T.parallel(T.int64(196), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(4), T.int64(2), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(1), T.int64(2), T.int64(2), T.int64(2)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(8)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(98) * T.int64(8) + oc_chunk_1 * T.int64(2) + oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(98) // T.int64(14) * T.int64(4) + oh_1 * T.int64(2) + oh_2_init * T.int64(2) + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(14) * T.int64(2) + ow_1 * T.int64(2) + ow_2_init * T.int64(2) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2_init * T.int64(8) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0 in T.grid(T.int64(16), T.int64(3)):
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(2), T.int64(4)):
                        for ax4_fused in T.vectorized(T.int64(16)):
                            with T.block("data_pad"):
                                v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                                v_i2 = T.axis.spatial(T.int64(30), kh_0 + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(98) // T.int64(14) * T.int64(4) + oh_1 * T.int64(2) + ax2)
                                v_i3 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(14) * T.int64(2) + ax3)
                                v_i4 = T.axis.spatial(T.int64(256), ic_0 * T.int64(16) + ax4_fused)
                                T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                                T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                                data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                    for kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(16), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(2), T.int64(2)):
                        for oc_block_3_fused in T.vectorized(T.int64(8)):
                            with T.block("conv2d_NCHWc_update"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                                v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(98) * T.int64(8) + oc_chunk_1 * T.int64(2) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                                v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(98) // T.int64(14) * T.int64(4) + oh_1 * T.int64(2) + oh_2 * T.int64(2) + oh_3)
                                v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(14) * T.int64(2) + ow_1 * T.int64(2) + ow_2 * T.int64(2) + ow_3)
                                v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2 * T.int64(8) + oc_block_3_fused)
                                v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(16) + ic_1)
                                v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                                v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                                T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)], p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block])
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)] * p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block]
            for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(8), T.int64(4)):
                for ax3_ax4_fused in T.vectorized(T.int64(64)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(98) * T.int64(8) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(98) // T.int64(14) * T.int64(4) + ax2)
                        v_ax3 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(14) * T.int64(2) + ax3_ax4_fused // T.int64(32))
                        v_ax4 = T.axis.spatial(T.int64(32), ax3_ax4_fused % T.int64(32))
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[2, 4, 1, 2])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[7, 2, 1, 2])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[14, 1, 1, 2])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 4, 8])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[16, 16])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=11)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87 = sch.get_loops(block=b68)
l88 = sch.fuse(l71, l72, l73, l74, l75, preserve_unit_iters=True)
sch.parallel(loop=l88)
l89 = sch.fuse(l87, preserve_unit_iters=True)
sch.vectorize(loop=l89)
l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107, l108, l109, l110, l111 = sch.get_loops(block=b69)
l112 = sch.fuse(l90, preserve_unit_iters=True)
sch.parallel(loop=l112)
l113 = sch.fuse(l111, preserve_unit_iters=True)
sch.vectorize(loop=l113)
sch.annotate(block_or_loop=l112, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l112, ann_key="pragma_unroll_explicit", ann_val=1)
l114, l115, l116, l117, l118, l119 = sch.get_loops(block=b70)
l120 = sch.fuse(l118, l119, preserve_unit_iters=True)
sch.vectorize(loop=l120)
b121 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141, l142, l143 = sch.get_loops(block=b121)
b144 = sch.decompose_reduction(block=b121, loop=l128)
2024-04-28 10:15:39 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #246: GFLOPs: 596.2617. Time: 3103.4880 us. Best GFLOPs: 684.8595
2024-04-28 10:15:39 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #247: GFLOPs: 392.9239. Time: 4709.5397 us. Best GFLOPs: 684.8595
2024-04-28 10:15:39 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #248: GFLOPs: 343.5325. Time: 5386.6538 us. Best GFLOPs: 684.8595
2024-04-28 10:15:39 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #249: GFLOPs: 327.3214. Time: 5653.4373 us. Best GFLOPs: 684.8595
2024-04-28 10:15:39 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #250: GFLOPs: 344.9714. Time: 5364.1865 us. Best GFLOPs: 684.8595
2024-04-28 10:15:39 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #251: GFLOPs: 326.4878. Time: 5667.8720 us. Best GFLOPs: 684.8595
2024-04-28 10:15:39 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #252: GFLOPs: 354.9951. Time: 5212.7223 us. Best GFLOPs: 684.8595
2024-04-28 10:15:39 [INFO] [task_scheduler.cc:121] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #253: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(256)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(3), T.int64(3), T.int64(256), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(28), T.int64(28), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(256)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(28), T.int64(28), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused in T.parallel(T.int64(196), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(2), T.int64(2), T.int64(1), T.int64(4), T.int64(1), T.int64(2), T.int64(2), T.int64(2)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(8)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(98) * T.int64(8) + oc_chunk_1 * T.int64(4) + oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(98) // T.int64(14) * T.int64(4) + oh_1 * T.int64(4) + oh_2_init * T.int64(2) + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(14) * T.int64(2) + ow_1 * T.int64(2) + ow_2_init * T.int64(2) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2_init * T.int64(8) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0 in T.grid(T.int64(16), T.int64(1), T.int64(3)):
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(6), T.int64(2)):
                        for ax4_fused in T.vectorized(T.int64(16)):
                            with T.block("data_pad"):
                                v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                                v_i2 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(98) // T.int64(14) * T.int64(4) + ax2)
                                v_i3 = T.axis.spatial(T.int64(30), kw_0 + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(14) * T.int64(2) + ax3)
                                v_i4 = T.axis.spatial(T.int64(256), ic_0 * T.int64(16) + ax4_fused)
                                T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                                T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                                data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                    for n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(1), T.int64(2), T.int64(2), T.int64(1), T.int64(4), T.int64(16), T.int64(3), T.int64(1), T.int64(1), T.int64(2), T.int64(2), T.int64(2)):
                        for oc_block_3_fused in T.vectorized(T.int64(8)):
                            with T.block("conv2d_NCHWc_update"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                                v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(98) * T.int64(8) + oc_chunk_1 * T.int64(4) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                                v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(98) // T.int64(14) * T.int64(4) + oh_1 * T.int64(4) + oh_2 * T.int64(2) + oh_3)
                                v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(14) * T.int64(2) + ow_1 * T.int64(2) + ow_2 * T.int64(2) + ow_3)
                                v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2 * T.int64(8) + oc_block_3_fused)
                                v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(16) + ic_1)
                                v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                                v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                                T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)], p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block])
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)] * p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block]
            for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(8), T.int64(4)):
                for ax3_ax4_fused in T.vectorized(T.int64(64)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(98) * T.int64(8) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(98) // T.int64(14) * T.int64(4) + ax2)
                        v_ax3 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(14) * T.int64(2) + ax3_ax4_fused // T.int64(32))
                        v_ax4 = T.axis.spatial(T.int64(32), ax3_ax4_fused % T.int64(32))
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[2, 2, 2, 2])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[7, 1, 2, 2])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[14, 1, 1, 2])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 4, 8])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[16, 16])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=12)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88 = sch.get_loops(block=b68)
l89 = sch.fuse(l71, l72, l73, l74, l75, preserve_unit_iters=True)
sch.parallel(loop=l89)
l90 = sch.fuse(l88, preserve_unit_iters=True)
sch.vectorize(loop=l90)
l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107, l108, l109, l110, l111, l112 = sch.get_loops(block=b69)
l113 = sch.fuse(l91, preserve_unit_iters=True)
sch.parallel(loop=l113)
l114 = sch.fuse(l112, preserve_unit_iters=True)
sch.vectorize(loop=l114)
sch.annotate(block_or_loop=l113, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l113, ann_key="pragma_unroll_explicit", ann_val=1)
l115, l116, l117, l118, l119, l120 = sch.get_loops(block=b70)
l121 = sch.fuse(l119, l120, preserve_unit_iters=True)
sch.vectorize(loop=l121)
b122 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141, l142, l143, l144 = sch.get_loops(block=b122)
b145 = sch.decompose_reduction(block=b122, loop=l129)
2024-04-28 10:15:39 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #254: GFLOPs: 26.0365. Time: 71072.9640 us. Best GFLOPs: 684.8595
2024-04-28 10:15:39 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #255: GFLOPs: 8.3340. Time: 222040.2190 us. Best GFLOPs: 684.8595
2024-04-28 10:15:39 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #256: GFLOPs: 32.9905. Time: 56091.5733 us. Best GFLOPs: 684.8595
2024-04-28 10:27:38 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-28 10:27:39 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-28 10:27:44 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35c37e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x31a6de8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x9b6ad08)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x350b3f8)]: 0 failure(s)
2024-04-28 10:27:44 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-28 10:27:57 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35c37e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x31a6de8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x9b6ad08)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x350b3f8)]: 0 failure(s)
2024-04-28 10:28:09 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35c37e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x31a6de8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x9b6ad08)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x350b3f8)]: 0 failure(s)
2024-04-28 10:28:21 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35c37e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x31a6de8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x9b6ad08)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x350b3f8)]: 0 failure(s)
2024-04-28 10:28:33 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35c37e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x31a6de8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x9b6ad08)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x350b3f8)]: 0 failure(s)
2024-04-28 10:28:40 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9720  0.9675  0.9509  0.9479  0.9479  0.8387  0.8381  0.8381  0.8278  0.8243  0.8243  0.8106  0.8063  0.8049  0.8012  0.7986
[17 : 32]:	0.7689  0.7660  0.7584  0.7545  0.7531  0.7473  0.7333  0.7316  0.7284  0.7248  0.7218  0.7218  0.7218  0.7189  0.7179  0.7172
[33 : 48]:	0.7136  0.7100  0.7080  0.7076  0.7051  0.7007  0.7003  0.6947  0.6946  0.6882  0.6848  0.6843  0.6818  0.6780  0.6780  0.6745
[49 : 64]:	0.6714  0.6694  0.6681  0.6679  0.6676  0.6666  0.6658  0.6632  0.6621  0.6590  0.6590  0.6585  0.6579  0.6559  0.6544  0.6528
2024-04-28 10:28:40 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-28 10:28:40 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-28 10:30:20 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #257: GFLOPs: 678.0047. Time: 2729.3186 us. Best GFLOPs: 684.8595
2024-04-28 10:30:20 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #258: GFLOPs: 706.7941. Time: 2618.1472 us. Best GFLOPs: 706.7941
2024-04-28 10:30:20 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #259: GFLOPs: 625.5306. Time: 2958.2742 us. Best GFLOPs: 706.7941
2024-04-28 10:30:20 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #260: GFLOPs: 620.7967. Time: 2980.8325 us. Best GFLOPs: 706.7941
2024-04-28 10:30:20 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #261: GFLOPs: 630.7478. Time: 2933.8048 us. Best GFLOPs: 706.7941
2024-04-28 10:30:20 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #262: GFLOPs: 637.2942. Time: 2903.6683 us. Best GFLOPs: 706.7941
2024-04-28 10:30:20 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #263: GFLOPs: 655.8063. Time: 2821.7033 us. Best GFLOPs: 706.7941
2024-04-28 10:30:20 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #264: GFLOPs: 645.9331. Time: 2864.8335 us. Best GFLOPs: 706.7941
2024-04-28 10:30:20 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #265: GFLOPs: 565.1745. Time: 3274.1941 us. Best GFLOPs: 706.7941
2024-04-28 10:30:20 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #266: GFLOPs: 415.3119. Time: 4455.6655 us. Best GFLOPs: 706.7941
2024-04-28 10:30:20 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #267: GFLOPs: 412.1076. Time: 4490.3095 us. Best GFLOPs: 706.7941
2024-04-28 10:30:20 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #268: GFLOPs: 575.7573. Time: 3214.0119 us. Best GFLOPs: 706.7941
2024-04-28 10:30:20 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #269: GFLOPs: 564.6415. Time: 3277.2848 us. Best GFLOPs: 706.7941
2024-04-28 10:30:20 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #270: GFLOPs: 732.9548. Time: 2524.6997 us. Best GFLOPs: 732.9548
2024-04-28 10:30:20 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #271: GFLOPs: 607.0238. Time: 3048.4649 us. Best GFLOPs: 732.9548
2024-04-28 10:30:20 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #272: GFLOPs: 555.5018. Time: 3331.2061 us. Best GFLOPs: 732.9548
2024-04-28 10:30:20 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #273: GFLOPs: 214.5113. Time: 8626.5428 us. Best GFLOPs: 732.9548
2024-04-28 10:30:20 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #274: GFLOPs: 422.6746. Time: 4378.0506 us. Best GFLOPs: 732.9548
2024-04-28 10:30:20 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #275: GFLOPs: 562.5828. Time: 3289.2773 us. Best GFLOPs: 732.9548
2024-04-28 10:30:20 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #276: GFLOPs: 638.3064. Time: 2899.0637 us. Best GFLOPs: 732.9548
2024-04-28 10:30:20 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #277: GFLOPs: 319.4167. Time: 5793.3437 us. Best GFLOPs: 732.9548
2024-04-28 10:30:20 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #278: GFLOPs: 421.5886. Time: 4389.3282 us. Best GFLOPs: 732.9548
2024-04-28 10:30:20 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #279: GFLOPs: 649.3882. Time: 2849.5911 us. Best GFLOPs: 732.9548
2024-04-28 10:30:20 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #280: GFLOPs: 653.0755. Time: 2833.5024 us. Best GFLOPs: 732.9548
2024-04-28 10:30:20 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #281: GFLOPs: 572.1355. Time: 3234.3576 us. Best GFLOPs: 732.9548
2024-04-28 10:30:20 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #282: GFLOPs: 522.3766. Time: 3542.4462 us. Best GFLOPs: 732.9548
2024-04-28 10:30:20 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #283: GFLOPs: 602.6939. Time: 3070.3658 us. Best GFLOPs: 732.9548
2024-04-28 10:30:20 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #284: GFLOPs: 572.3809. Time: 3232.9708 us. Best GFLOPs: 732.9548
2024-04-28 10:30:20 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #285: GFLOPs: 578.6722. Time: 3197.8226 us. Best GFLOPs: 732.9548
2024-04-28 10:30:20 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #286: GFLOPs: 638.7679. Time: 2896.9691 us. Best GFLOPs: 732.9548
2024-04-28 10:30:20 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #287: GFLOPs: 772.2361. Time: 2396.2760 us. Best GFLOPs: 772.2361
2024-04-28 10:30:20 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #288: GFLOPs: 625.3751. Time: 2959.0095 us. Best GFLOPs: 772.2361
2024-04-28 10:30:20 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #289: GFLOPs: 354.4264. Time: 5221.0865 us. Best GFLOPs: 772.2361
2024-04-28 10:30:20 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #290: GFLOPs: 725.6659. Time: 2550.0589 us. Best GFLOPs: 772.2361
2024-04-28 10:30:20 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #291: GFLOPs: 579.6240. Time: 3192.5712 us. Best GFLOPs: 772.2361
2024-04-28 10:30:20 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #292: GFLOPs: 655.5211. Time: 2822.9311 us. Best GFLOPs: 772.2361
2024-04-28 10:30:20 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #293: GFLOPs: 427.2594. Time: 4331.0708 us. Best GFLOPs: 772.2361
2024-04-28 10:30:20 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #294: GFLOPs: 529.4458. Time: 3495.1471 us. Best GFLOPs: 772.2361
2024-04-28 10:30:20 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #295: GFLOPs: 115.4229. Time: 16032.2726 us. Best GFLOPs: 772.2361
2024-04-28 10:30:20 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #296: GFLOPs: 480.1825. Time: 3853.7244 us. Best GFLOPs: 772.2361
2024-04-28 10:30:20 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #297: GFLOPs: 637.2122. Time: 2904.0417 us. Best GFLOPs: 772.2361
2024-04-28 10:30:20 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #298: GFLOPs: 434.7008. Time: 4256.9296 us. Best GFLOPs: 772.2361
2024-04-28 10:30:20 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #299: GFLOPs: 432.9928. Time: 4273.7224 us. Best GFLOPs: 772.2361
2024-04-28 10:30:20 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #300: GFLOPs: 418.2335. Time: 4424.5397 us. Best GFLOPs: 772.2361
2024-04-28 10:30:20 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #301: GFLOPs: 249.5156. Time: 7416.3321 us. Best GFLOPs: 772.2361
2024-04-28 10:30:20 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #302: GFLOPs: 235.6294. Time: 7853.3955 us. Best GFLOPs: 772.2361
2024-04-28 10:30:20 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #303: GFLOPs: 238.9826. Time: 7743.2042 us. Best GFLOPs: 772.2361
2024-04-28 10:30:20 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #304: GFLOPs: 263.1980. Time: 7030.7941 us. Best GFLOPs: 772.2361
2024-04-28 10:30:20 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #305: GFLOPs: 351.1235. Time: 5270.1993 us. Best GFLOPs: 772.2361
2024-04-28 10:30:20 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #306: GFLOPs: 549.8620. Time: 3365.3730 us. Best GFLOPs: 772.2361
2024-04-28 10:30:20 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #307: GFLOPs: 549.5926. Time: 3367.0227 us. Best GFLOPs: 772.2361
2024-04-28 10:30:20 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #308: GFLOPs: 635.6761. Time: 2911.0593 us. Best GFLOPs: 772.2361
2024-04-28 10:30:20 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #309: GFLOPs: 601.1243. Time: 3078.3830 us. Best GFLOPs: 772.2361
2024-04-28 10:30:20 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #310: GFLOPs: 588.8393. Time: 3142.6076 us. Best GFLOPs: 772.2361
2024-04-28 10:30:20 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #311: GFLOPs: 434.4788. Time: 4259.1047 us. Best GFLOPs: 772.2361
2024-04-28 10:30:20 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #312: GFLOPs: 582.4395. Time: 3177.1382 us. Best GFLOPs: 772.2361
2024-04-28 10:30:20 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #313: GFLOPs: 429.8600. Time: 4304.8688 us. Best GFLOPs: 772.2361
2024-04-28 10:30:20 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #314: GFLOPs: 327.3584. Time: 5652.7987 us. Best GFLOPs: 772.2361
2024-04-28 10:30:20 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #315: GFLOPs: 424.4437. Time: 4359.8034 us. Best GFLOPs: 772.2361
2024-04-28 10:30:20 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #316: GFLOPs: 523.9098. Time: 3532.0788 us. Best GFLOPs: 772.2361
2024-04-28 10:30:20 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #317: GFLOPs: 615.2107. Time: 3007.8978 us. Best GFLOPs: 772.2361
2024-04-28 10:30:20 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #318: GFLOPs: 21.4845. Time: 86131.2410 us. Best GFLOPs: 772.2361
2024-04-28 10:30:20 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #319: GFLOPs: 42.7734. Time: 43262.6423 us. Best GFLOPs: 772.2361
2024-04-28 10:30:20 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #320: GFLOPs: 51.0619. Time: 36240.1497 us. Best GFLOPs: 772.2361
2024-04-28 10:54:14 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-28 10:54:15 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-28 10:54:20 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35c37e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x31a6de8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x9b6ad08)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x350b3f8)]: 0 failure(s)
2024-04-28 10:54:20 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-28 10:54:32 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35c37e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x31a6de8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x9b6ad08)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x350b3f8)]: 0 failure(s)
2024-04-28 10:54:44 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35c37e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x31a6de8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x9b6ad08)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x350b3f8)]: 0 failure(s)
2024-04-28 10:54:56 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35c37e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x31a6de8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x9b6ad08)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x350b3f8)]: 0 failure(s)
2024-04-28 10:55:07 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35c37e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x31a6de8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x9b6ad08)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x350b3f8)]: 0 failure(s)
2024-04-28 10:55:13 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9762  0.9762  0.9563  0.9137  0.9132  0.9063  0.9063  0.9053  0.9037  0.8948  0.8795  0.8795  0.8795  0.8795  0.8773  0.8761
[17 : 32]:	0.8702  0.8580  0.8580  0.8542  0.8542  0.8481  0.8445  0.8393  0.8374  0.8363  0.8363  0.8353  0.8348  0.8269  0.8260  0.8252
[33 : 48]:	0.8252  0.8252  0.8252  0.8251  0.8251  0.8238  0.8234  0.8233  0.8227  0.8213  0.8206  0.8183  0.8178  0.8175  0.8168  0.8166
[49 : 64]:	0.8155  0.8146  0.8138  0.8138  0.8138  0.8138  0.8135  0.8130  0.8130  0.8128  0.8120  0.8114  0.8085  0.8074  0.8004  0.8000
2024-04-28 10:55:14 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-28 10:55:14 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-28 10:56:30 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #321: GFLOPs: 375.3943. Time: 4929.4587 us. Best GFLOPs: 772.2361
2024-04-28 10:56:30 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #322: GFLOPs: 727.9739. Time: 2541.9742 us. Best GFLOPs: 772.2361
2024-04-28 10:56:30 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #323: GFLOPs: 730.3805. Time: 2533.5984 us. Best GFLOPs: 772.2361
2024-04-28 10:56:30 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #324: GFLOPs: 713.7612. Time: 2592.5911 us. Best GFLOPs: 772.2361
2024-04-28 10:56:30 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #325: GFLOPs: 768.5921. Time: 2407.6372 us. Best GFLOPs: 772.2361
2024-04-28 10:56:30 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #326: GFLOPs: 719.0398. Time: 2573.5584 us. Best GFLOPs: 772.2361
2024-04-28 10:56:30 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #327: GFLOPs: 384.5602. Time: 4811.9672 us. Best GFLOPs: 772.2361
2024-04-28 10:56:30 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #328: GFLOPs: 761.3285. Time: 2430.6078 us. Best GFLOPs: 772.2361
2024-04-28 10:56:30 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #329: GFLOPs: 781.4370. Time: 2368.0615 us. Best GFLOPs: 781.4370
2024-04-28 10:56:30 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #330: GFLOPs: 769.8535. Time: 2403.6921 us. Best GFLOPs: 781.4370
2024-04-28 10:56:30 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #331: GFLOPs: 703.8091. Time: 2629.2512 us. Best GFLOPs: 781.4370
2024-04-28 10:56:30 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #332: GFLOPs: 446.4622. Time: 4144.7870 us. Best GFLOPs: 781.4370
2024-04-28 10:56:30 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #333: GFLOPs: 646.2643. Time: 2863.3656 us. Best GFLOPs: 781.4370
2024-04-28 10:56:30 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #334: GFLOPs: 701.5578. Time: 2637.6883 us. Best GFLOPs: 781.4370
2024-04-28 10:56:30 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #335: GFLOPs: 655.0578. Time: 2824.9275 us. Best GFLOPs: 781.4370
2024-04-28 10:56:30 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #336: GFLOPs: 739.1812. Time: 2503.4334 us. Best GFLOPs: 781.4370
2024-04-28 10:56:30 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #337: GFLOPs: 459.7948. Time: 4024.6017 us. Best GFLOPs: 781.4370
2024-04-28 10:56:30 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #338: GFLOPs: 715.0951. Time: 2587.7551 us. Best GFLOPs: 781.4370
2024-04-28 10:56:30 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #339: GFLOPs: 721.3359. Time: 2565.3663 us. Best GFLOPs: 781.4370
2024-04-28 10:56:30 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #340: GFLOPs: 805.6474. Time: 2296.8991 us. Best GFLOPs: 805.6474
2024-04-28 10:56:30 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #341: GFLOPs: 780.1459. Time: 2371.9806 us. Best GFLOPs: 805.6474
2024-04-28 10:56:30 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #342: GFLOPs: 551.0958. Time: 3357.8391 us. Best GFLOPs: 805.6474
2024-04-28 10:56:30 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #343: GFLOPs: 533.1313. Time: 3470.9853 us. Best GFLOPs: 805.6474
2024-04-28 10:56:30 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #344: GFLOPs: 626.0972. Time: 2955.5966 us. Best GFLOPs: 805.6474
2024-04-28 10:56:30 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #345: GFLOPs: 643.8506. Time: 2874.0998 us. Best GFLOPs: 805.6474
2024-04-28 10:56:30 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #346: GFLOPs: 606.2939. Time: 3052.1353 us. Best GFLOPs: 805.6474
2024-04-28 10:56:30 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #347: GFLOPs: 640.2541. Time: 2890.2446 us. Best GFLOPs: 805.6474
2024-04-28 10:56:30 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #348: GFLOPs: 627.3484. Time: 2949.7022 us. Best GFLOPs: 805.6474
2024-04-28 10:56:30 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #349: GFLOPs: 727.9072. Time: 2542.2070 us. Best GFLOPs: 805.6474
2024-04-28 10:56:30 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #350: GFLOPs: 751.3354. Time: 2462.9358 us. Best GFLOPs: 805.6474
2024-04-28 10:56:30 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #351: GFLOPs: 584.0671. Time: 3168.2848 us. Best GFLOPs: 805.6474
2024-04-28 10:56:30 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #352: GFLOPs: 649.3092. Time: 2849.9377 us. Best GFLOPs: 805.6474
2024-04-28 10:56:30 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #353: GFLOPs: 640.1136. Time: 2890.8789 us. Best GFLOPs: 805.6474
2024-04-28 10:56:30 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #354: GFLOPs: 643.9333. Time: 2873.7306 us. Best GFLOPs: 805.6474
2024-04-28 10:56:30 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #355: GFLOPs: 646.2731. Time: 2863.3265 us. Best GFLOPs: 805.6474
2024-04-28 10:56:30 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #356: GFLOPs: 678.5984. Time: 2726.9310 us. Best GFLOPs: 805.6474
2024-04-28 10:56:30 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #357: GFLOPs: 664.4217. Time: 2785.1149 us. Best GFLOPs: 805.6474
2024-04-28 10:56:30 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #358: GFLOPs: 673.4804. Time: 2747.6538 us. Best GFLOPs: 805.6474
2024-04-28 10:56:30 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #359: GFLOPs: 257.7757. Time: 7178.6850 us. Best GFLOPs: 805.6474
2024-04-28 10:56:30 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #360: GFLOPs: 750.5671. Time: 2465.4568 us. Best GFLOPs: 805.6474
2024-04-28 10:56:30 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #361: GFLOPs: 569.1906. Time: 3251.0918 us. Best GFLOPs: 805.6474
2024-04-28 10:56:30 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #362: GFLOPs: 617.1669. Time: 2998.3640 us. Best GFLOPs: 805.6474
2024-04-28 10:56:30 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #363: GFLOPs: 481.1389. Time: 3846.0634 us. Best GFLOPs: 805.6474
2024-04-28 10:56:30 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #364: GFLOPs: 648.0597. Time: 2855.4328 us. Best GFLOPs: 805.6474
2024-04-28 10:56:30 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #365: GFLOPs: 691.7184. Time: 2675.2084 us. Best GFLOPs: 805.6474
2024-04-28 10:56:30 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #366: GFLOPs: 602.1285. Time: 3073.2492 us. Best GFLOPs: 805.6474
2024-04-28 10:56:30 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #367: GFLOPs: 628.2211. Time: 2945.6045 us. Best GFLOPs: 805.6474
2024-04-28 10:56:30 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #368: GFLOPs: 636.5734. Time: 2906.9559 us. Best GFLOPs: 805.6474
2024-04-28 10:56:30 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #369: GFLOPs: 697.4019. Time: 2653.4067 us. Best GFLOPs: 805.6474
2024-04-28 10:56:30 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #370: GFLOPs: 605.6161. Time: 3055.5508 us. Best GFLOPs: 805.6474
2024-04-28 10:56:30 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #371: GFLOPs: 598.6887. Time: 3090.9068 us. Best GFLOPs: 805.6474
2024-04-28 10:56:30 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #372: GFLOPs: 593.4803. Time: 3118.0328 us. Best GFLOPs: 805.6474
2024-04-28 10:56:30 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #373: GFLOPs: 606.3300. Time: 3051.9535 us. Best GFLOPs: 805.6474
2024-04-28 10:56:30 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #374: GFLOPs: 635.1699. Time: 2913.3793 us. Best GFLOPs: 805.6474
2024-04-28 10:56:30 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #375: GFLOPs: 611.6885. Time: 3025.2176 us. Best GFLOPs: 805.6474
2024-04-28 10:56:30 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #376: GFLOPs: 436.1832. Time: 4242.4623 us. Best GFLOPs: 805.6474
2024-04-28 10:56:30 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #377: GFLOPs: 665.2830. Time: 2781.5092 us. Best GFLOPs: 805.6474
2024-04-28 10:56:30 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #378: GFLOPs: 778.3705. Time: 2377.3907 us. Best GFLOPs: 805.6474
2024-04-28 10:56:30 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #379: GFLOPs: 623.5112. Time: 2967.8549 us. Best GFLOPs: 805.6474
2024-04-28 10:56:30 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #380: GFLOPs: 634.6885. Time: 2915.5891 us. Best GFLOPs: 805.6474
2024-04-28 10:56:30 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #381: GFLOPs: 690.6266. Time: 2679.4374 us. Best GFLOPs: 805.6474
2024-04-28 10:56:30 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #382: GFLOPs: 133.7101. Time: 13839.5741 us. Best GFLOPs: 805.6474
2024-04-28 10:56:30 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #383: GFLOPs: 18.7454. Time: 98717.0337 us. Best GFLOPs: 805.6474
2024-04-28 10:56:30 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #384: GFLOPs: 12.9459. Time: 142940.6053 us. Best GFLOPs: 805.6474
2024-04-28 11:42:06 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-28 11:42:07 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-28 11:42:12 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35c37e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x31a6de8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x9b6ad08)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x350b3f8)]: 0 failure(s)
2024-04-28 11:42:12 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-28 11:42:24 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35c37e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x31a6de8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x9b6ad08)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x350b3f8)]: 0 failure(s)
2024-04-28 11:42:36 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35c37e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x31a6de8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x9b6ad08)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x350b3f8)]: 0 failure(s)
2024-04-28 11:42:48 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35c37e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x31a6de8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x9b6ad08)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x350b3f8)]: 0 failure(s)
2024-04-28 11:42:59 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35c37e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x31a6de8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x9b6ad08)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x350b3f8)]: 0 failure(s)
2024-04-28 11:43:06 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9805  0.9218  0.9187  0.9187  0.9115  0.9058  0.9058  0.9013  0.8982  0.8946  0.8930  0.8919  0.8871  0.8841  0.8841  0.8817
[17 : 32]:	0.8792  0.8769  0.8731  0.8689  0.8641  0.8641  0.8641  0.8579  0.8532  0.8527  0.8461  0.8458  0.8438  0.8408  0.8385  0.8338
[33 : 48]:	0.8318  0.8306  0.8296  0.8250  0.8248  0.8232  0.8232  0.8216  0.8209  0.8206  0.8196  0.8194  0.8188  0.8140  0.8137  0.8120
[49 : 64]:	0.8111  0.8094  0.8082  0.8077  0.8052  0.8052  0.8052  0.8052  0.8048  0.8045  0.8039  0.8009  0.7981  0.7981  0.7953  0.7952
2024-04-28 11:43:06 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-28 11:43:06 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-28 11:44:49 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #385: GFLOPs: 748.1377. Time: 2473.4629 us. Best GFLOPs: 805.6474
2024-04-28 11:44:49 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #386: GFLOPs: 771.3051. Time: 2399.1685 us. Best GFLOPs: 805.6474
2024-04-28 11:44:49 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #387: GFLOPs: 749.5958. Time: 2468.6516 us. Best GFLOPs: 805.6474
2024-04-28 11:44:49 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #388: GFLOPs: 746.8122. Time: 2477.8530 us. Best GFLOPs: 805.6474
2024-04-28 11:44:49 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #389: GFLOPs: 808.8423. Time: 2287.8264 us. Best GFLOPs: 808.8423
2024-04-28 11:44:49 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #390: GFLOPs: 746.4568. Time: 2479.0327 us. Best GFLOPs: 808.8423
2024-04-28 11:44:49 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #391: GFLOPs: 737.6680. Time: 2508.5687 us. Best GFLOPs: 808.8423
2024-04-28 11:44:49 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #392: GFLOPs: 783.5076. Time: 2361.8033 us. Best GFLOPs: 808.8423
2024-04-28 11:44:49 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #393: GFLOPs: 722.2469. Time: 2562.1307 us. Best GFLOPs: 808.8423
2024-04-28 11:44:49 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #394: GFLOPs: 156.3776. Time: 11833.4773 us. Best GFLOPs: 808.8423
2024-04-28 11:44:49 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #395: GFLOPs: 765.4440. Time: 2417.5393 us. Best GFLOPs: 808.8423
2024-04-28 11:44:49 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #396: GFLOPs: 776.4707. Time: 2383.2075 us. Best GFLOPs: 808.8423
2024-04-28 11:44:49 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #397: GFLOPs: 432.4147. Time: 4279.4358 us. Best GFLOPs: 808.8423
2024-04-28 11:44:49 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #398: GFLOPs: 229.0407. Time: 8079.3085 us. Best GFLOPs: 808.8423
2024-04-28 11:44:49 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #399: GFLOPs: 728.5706. Time: 2539.8923 us. Best GFLOPs: 808.8423
2024-04-28 11:44:49 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #400: GFLOPs: 735.0585. Time: 2517.4742 us. Best GFLOPs: 808.8423
2024-04-28 11:44:49 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #401: GFLOPs: 1092.3773. Time: 1694.0034 us. Best GFLOPs: 1092.3773
2024-04-28 11:44:49 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #402: GFLOPs: 790.9166. Time: 2339.6790 us. Best GFLOPs: 1092.3773
2024-04-28 11:44:49 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #403: GFLOPs: 644.1000. Time: 2872.9870 us. Best GFLOPs: 1092.3773
2024-04-28 11:44:49 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #404: GFLOPs: 633.0747. Time: 2923.0213 us. Best GFLOPs: 1092.3773
2024-04-28 11:44:49 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #405: GFLOPs: 799.3121. Time: 2315.1042 us. Best GFLOPs: 1092.3773
2024-04-28 11:44:49 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #406: GFLOPs: 462.5885. Time: 4000.2962 us. Best GFLOPs: 1092.3773
2024-04-28 11:44:49 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #407: GFLOPs: 799.4324. Time: 2314.7560 us. Best GFLOPs: 1092.3773
2024-04-28 11:44:49 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #408: GFLOPs: 779.6613. Time: 2373.4549 us. Best GFLOPs: 1092.3773
2024-04-28 11:44:49 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #409: GFLOPs: 941.3069. Time: 1965.8741 us. Best GFLOPs: 1092.3773
2024-04-28 11:44:49 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #410: GFLOPs: 748.6763. Time: 2471.6836 us. Best GFLOPs: 1092.3773
2024-04-28 11:44:49 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #411: GFLOPs: 672.0851. Time: 2753.3579 us. Best GFLOPs: 1092.3773
2024-04-28 11:44:49 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #412: GFLOPs: 116.7883. Time: 15844.8347 us. Best GFLOPs: 1092.3773
2024-04-28 11:44:49 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #413: GFLOPs: 729.7141. Time: 2535.9122 us. Best GFLOPs: 1092.3773
2024-04-28 11:44:49 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #414: GFLOPs: 783.1692. Time: 2362.8240 us. Best GFLOPs: 1092.3773
2024-04-28 11:44:49 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #415: GFLOPs: 715.7128. Time: 2585.5217 us. Best GFLOPs: 1092.3773
2024-04-28 11:44:49 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #416: GFLOPs: 709.0484. Time: 2609.8229 us. Best GFLOPs: 1092.3773
2024-04-28 11:44:49 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #417: GFLOPs: 583.1208. Time: 3173.4262 us. Best GFLOPs: 1092.3773
2024-04-28 11:44:49 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #418: GFLOPs: 752.4202. Time: 2459.3850 us. Best GFLOPs: 1092.3773
2024-04-28 11:44:49 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #419: GFLOPs: 831.0331. Time: 2226.7355 us. Best GFLOPs: 1092.3773
2024-04-28 11:44:49 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #420: GFLOPs: 602.4978. Time: 3071.3653 us. Best GFLOPs: 1092.3773
2024-04-28 11:44:49 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #421: GFLOPs: 837.0159. Time: 2210.8192 us. Best GFLOPs: 1092.3773
2024-04-28 11:44:49 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #422: GFLOPs: 738.0313. Time: 2507.3337 us. Best GFLOPs: 1092.3773
2024-04-28 11:44:49 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #423: GFLOPs: 748.8357. Time: 2471.1572 us. Best GFLOPs: 1092.3773
2024-04-28 11:44:49 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #424: GFLOPs: 769.8891. Time: 2403.5812 us. Best GFLOPs: 1092.3773
2024-04-28 11:44:49 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #425: GFLOPs: 740.5502. Time: 2498.8055 us. Best GFLOPs: 1092.3773
2024-04-28 11:44:49 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #426: GFLOPs: 766.8795. Time: 2413.0140 us. Best GFLOPs: 1092.3773
2024-04-28 11:44:49 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #427: GFLOPs: 227.2086. Time: 8144.4566 us. Best GFLOPs: 1092.3773
2024-04-28 11:44:49 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #428: GFLOPs: 456.9742. Time: 4049.4426 us. Best GFLOPs: 1092.3773
2024-04-28 11:44:49 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #429: GFLOPs: 616.2218. Time: 3002.9624 us. Best GFLOPs: 1092.3773
2024-04-28 11:44:49 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #430: GFLOPs: 733.4238. Time: 2523.0853 us. Best GFLOPs: 1092.3773
2024-04-28 11:44:49 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #431: GFLOPs: 530.3457. Time: 3489.2164 us. Best GFLOPs: 1092.3773
2024-04-28 11:44:49 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #432: GFLOPs: 714.5394. Time: 2589.7675 us. Best GFLOPs: 1092.3773
2024-04-28 11:44:49 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #433: GFLOPs: 607.2460. Time: 3047.3498 us. Best GFLOPs: 1092.3773
2024-04-28 11:44:49 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #434: GFLOPs: 549.8832. Time: 3365.2434 us. Best GFLOPs: 1092.3773
2024-04-28 11:44:49 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #435: GFLOPs: 811.5400. Time: 2280.2214 us. Best GFLOPs: 1092.3773
2024-04-28 11:44:49 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #436: GFLOPs: 231.0321. Time: 8009.6712 us. Best GFLOPs: 1092.3773
2024-04-28 11:44:49 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #437: GFLOPs: 243.4567. Time: 7600.9039 us. Best GFLOPs: 1092.3773
2024-04-28 11:44:49 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #438: GFLOPs: 244.7316. Time: 7561.3083 us. Best GFLOPs: 1092.3773
2024-04-28 11:44:49 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #439: GFLOPs: 244.8023. Time: 7559.1246 us. Best GFLOPs: 1092.3773
2024-04-28 11:44:49 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #440: GFLOPs: 247.3435. Time: 7481.4626 us. Best GFLOPs: 1092.3773
2024-04-28 11:44:49 [INFO] [task_scheduler.cc:121] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #441: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(256)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(3), T.int64(3), T.int64(256), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(28), T.int64(28), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(256)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(28), T.int64(28), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused in T.parallel(T.int64(896), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(9), T.int64(4), T.int64(256)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(224) * T.int64(7) + ax2)
                    v_i3 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(224) // T.int64(112) * T.int64(14) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(7) * T.int64(2) + ax3)
                    v_i4 = T.axis.spatial(T.int64(256), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oc_block_1 in range(T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(112) // T.int64(7) + oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(224) * T.int64(7) + oh_2_init + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(224) // T.int64(112) * T.int64(14) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(7) * T.int64(2) + ow_2_init * T.int64(2) + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(256), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(32), T.int64(1), T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(112) // T.int64(7) + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(224) * T.int64(7) + oh_2 + oh_3)
                        v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(224) // T.int64(112) * T.int64(14) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(7) * T.int64(2) + ow_2 * T.int64(2) + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(256), ic_0 + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)], p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)] * p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block]
                for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(1), T.int64(7)):
                    for ax3_ax4_fused in T.vectorized(T.int64(64)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(112) // T.int64(7) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(224) * T.int64(7) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(224) // T.int64(112) * T.int64(14) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(7) * T.int64(2) + ax3_ax4_fused // T.int64(32))
                            v_ax4 = T.axis.spatial(T.int64(32), ax3_ax4_fused % T.int64(32))
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 16, 1, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[4, 1, 7, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[2, 7, 1, 2])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 32, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[256, 1])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=8)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b68)
l85 = sch.fuse(l71, l72, l73, l74, l75, l76, l77, l78, l79, preserve_unit_iters=True)
sch.parallel(loop=l85)
l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l86, preserve_unit_iters=True)
sch.parallel(loop=l104)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109, l110, l111 = sch.get_loops(block=b70)
l112 = sch.fuse(l110, l111, preserve_unit_iters=True)
sch.vectorize(loop=l112)
b113 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131 = sch.get_loops(block=b113)
b132 = sch.decompose_reduction(block=b113, loop=l116)
2024-04-28 11:44:49 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #442: GFLOPs: 502.9912. Time: 3678.9724 us. Best GFLOPs: 1092.3773
2024-04-28 11:44:49 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #443: GFLOPs: 538.0183. Time: 3439.4570 us. Best GFLOPs: 1092.3773
2024-04-28 11:44:49 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #444: GFLOPs: 519.5374. Time: 3561.8046 us. Best GFLOPs: 1092.3773
2024-04-28 11:44:49 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #445: GFLOPs: 651.1091. Time: 2842.0596 us. Best GFLOPs: 1092.3773
2024-04-28 11:44:49 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #446: GFLOPs: 29.6390. Time: 62434.2393 us. Best GFLOPs: 1092.3773
2024-04-28 11:44:49 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #447: GFLOPs: 6.3890. Time: 289638.4100 us. Best GFLOPs: 1092.3773
2024-04-28 11:44:49 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #448: GFLOPs: 20.3834. Time: 90784.1343 us. Best GFLOPs: 1092.3773
2024-04-28 12:05:27 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-28 12:05:28 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-28 12:05:33 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35c37e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x31a6de8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x9b6ad08)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x350b3f8)]: 0 failure(s)
2024-04-28 12:05:33 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-28 12:05:45 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35c37e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x31a6de8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x9b6ad08)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x350b3f8)]: 0 failure(s)
2024-04-28 12:05:56 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35c37e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x31a6de8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x9b6ad08)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x350b3f8)]: 0 failure(s)
2024-04-28 12:06:07 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35c37e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x31a6de8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x9b6ad08)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x350b3f8)]: 0 failure(s)
2024-04-28 12:06:19 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35c37e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x31a6de8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x9b6ad08)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x350b3f8)]: 0 failure(s)
2024-04-28 12:06:25 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.8048  0.8048  0.8048  0.7352  0.7199  0.7131  0.7056  0.7056  0.7044  0.7036  0.7036  0.7011  0.6968  0.6933  0.6933  0.6888
[17 : 32]:	0.6828  0.6826  0.6812  0.6798  0.6798  0.6798  0.6795  0.6750  0.6722  0.6710  0.6695  0.6693  0.6686  0.6685  0.6681  0.6667
[33 : 48]:	0.6665  0.6652  0.6648  0.6647  0.6633  0.6631  0.6631  0.6618  0.6603  0.6603  0.6600  0.6600  0.6585  0.6585  0.6579  0.6576
[49 : 64]:	0.6568  0.6564  0.6562  0.6551  0.6532  0.6532  0.6515  0.6498  0.6494  0.6492  0.6492  0.6489  0.6489  0.6477  0.6469  0.6465
2024-04-28 12:06:25 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-28 12:06:25 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-28 12:07:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #449: GFLOPs: 931.9882. Time: 1985.5303 us. Best GFLOPs: 1092.3773
2024-04-28 12:07:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #450: GFLOPs: 882.2225. Time: 2097.5330 us. Best GFLOPs: 1092.3773
2024-04-28 12:07:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #451: GFLOPs: 883.5372. Time: 2094.4119 us. Best GFLOPs: 1092.3773
2024-04-28 12:07:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #452: GFLOPs: 356.0846. Time: 5196.7726 us. Best GFLOPs: 1092.3773
2024-04-28 12:07:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #453: GFLOPs: 831.3952. Time: 2225.7658 us. Best GFLOPs: 1092.3773
2024-04-28 12:07:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #454: GFLOPs: 726.1395. Time: 2548.3957 us. Best GFLOPs: 1092.3773
2024-04-28 12:07:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #455: GFLOPs: 779.4599. Time: 2374.0682 us. Best GFLOPs: 1092.3773
2024-04-28 12:07:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #456: GFLOPs: 742.6518. Time: 2491.7342 us. Best GFLOPs: 1092.3773
2024-04-28 12:07:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #457: GFLOPs: 724.4974. Time: 2554.1720 us. Best GFLOPs: 1092.3773
2024-04-28 12:07:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #458: GFLOPs: 808.2379. Time: 2289.5374 us. Best GFLOPs: 1092.3773
2024-04-28 12:07:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #459: GFLOPs: 875.2903. Time: 2114.1454 us. Best GFLOPs: 1092.3773
2024-04-28 12:07:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #460: GFLOPs: 738.7454. Time: 2504.9102 us. Best GFLOPs: 1092.3773
2024-04-28 12:07:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #461: GFLOPs: 909.3898. Time: 2034.8709 us. Best GFLOPs: 1092.3773
2024-04-28 12:07:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #462: GFLOPs: 807.4867. Time: 2291.6673 us. Best GFLOPs: 1092.3773
2024-04-28 12:07:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #463: GFLOPs: 777.3926. Time: 2380.3815 us. Best GFLOPs: 1092.3773
2024-04-28 12:07:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #464: GFLOPs: 291.8970. Time: 6339.5336 us. Best GFLOPs: 1092.3773
2024-04-28 12:07:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #465: GFLOPs: 795.7717. Time: 2325.4043 us. Best GFLOPs: 1092.3773
2024-04-28 12:07:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #466: GFLOPs: 788.9333. Time: 2345.5607 us. Best GFLOPs: 1092.3773
2024-04-28 12:07:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #467: GFLOPs: 140.6722. Time: 13154.6294 us. Best GFLOPs: 1092.3773
2024-04-28 12:07:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #468: GFLOPs: 788.3132. Time: 2347.4058 us. Best GFLOPs: 1092.3773
2024-04-28 12:07:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #469: GFLOPs: 787.0680. Time: 2351.1193 us. Best GFLOPs: 1092.3773
2024-04-28 12:07:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #470: GFLOPs: 793.4316. Time: 2332.2625 us. Best GFLOPs: 1092.3773
2024-04-28 12:07:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #471: GFLOPs: 297.1048. Time: 6228.4114 us. Best GFLOPs: 1092.3773
2024-04-28 12:07:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #472: GFLOPs: 301.1185. Time: 6145.3919 us. Best GFLOPs: 1092.3773
2024-04-28 12:07:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #473: GFLOPs: 732.5483. Time: 2526.1008 us. Best GFLOPs: 1092.3773
2024-04-28 12:07:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #474: GFLOPs: 661.0440. Time: 2799.3459 us. Best GFLOPs: 1092.3773
2024-04-28 12:07:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #475: GFLOPs: 839.4513. Time: 2204.4054 us. Best GFLOPs: 1092.3773
2024-04-28 12:07:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #476: GFLOPs: 693.4310. Time: 2668.6013 us. Best GFLOPs: 1092.3773
2024-04-28 12:07:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #477: GFLOPs: 157.8384. Time: 11723.9567 us. Best GFLOPs: 1092.3773
2024-04-28 12:07:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #478: GFLOPs: 602.1594. Time: 3073.0914 us. Best GFLOPs: 1092.3773
2024-04-28 12:07:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #479: GFLOPs: 612.9057. Time: 3019.2097 us. Best GFLOPs: 1092.3773
2024-04-28 12:07:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #480: GFLOPs: 913.7540. Time: 2025.1522 us. Best GFLOPs: 1092.3773
2024-04-28 12:07:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #481: GFLOPs: 798.6809. Time: 2316.9338 us. Best GFLOPs: 1092.3773
2024-04-28 12:07:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #482: GFLOPs: 309.2020. Time: 5984.7314 us. Best GFLOPs: 1092.3773
2024-04-28 12:07:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #483: GFLOPs: 758.6876. Time: 2439.0685 us. Best GFLOPs: 1092.3773
2024-04-28 12:07:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #484: GFLOPs: 593.4050. Time: 3118.4283 us. Best GFLOPs: 1092.3773
2024-04-28 12:07:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #485: GFLOPs: 682.4924. Time: 2711.3721 us. Best GFLOPs: 1092.3773
2024-04-28 12:07:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #486: GFLOPs: 504.2922. Time: 3669.4815 us. Best GFLOPs: 1092.3773
2024-04-28 12:07:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #487: GFLOPs: 504.1982. Time: 3670.1654 us. Best GFLOPs: 1092.3773
2024-04-28 12:07:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #488: GFLOPs: 724.3945. Time: 2554.5348 us. Best GFLOPs: 1092.3773
2024-04-28 12:07:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #489: GFLOPs: 687.4389. Time: 2691.8624 us. Best GFLOPs: 1092.3773
2024-04-28 12:07:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #490: GFLOPs: 786.2207. Time: 2353.6533 us. Best GFLOPs: 1092.3773
2024-04-28 12:07:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #491: GFLOPs: 593.8886. Time: 3115.8889 us. Best GFLOPs: 1092.3773
2024-04-28 12:07:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #492: GFLOPs: 232.4038. Time: 7962.3948 us. Best GFLOPs: 1092.3773
2024-04-28 12:07:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #493: GFLOPs: 421.5796. Time: 4389.4219 us. Best GFLOPs: 1092.3773
2024-04-28 12:07:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #494: GFLOPs: 258.2484. Time: 7165.5454 us. Best GFLOPs: 1092.3773
2024-04-28 12:07:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #495: GFLOPs: 773.2946. Time: 2392.9959 us. Best GFLOPs: 1092.3773
2024-04-28 12:07:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #496: GFLOPs: 750.7846. Time: 2464.7427 us. Best GFLOPs: 1092.3773
2024-04-28 12:07:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #497: GFLOPs: 793.5056. Time: 2332.0450 us. Best GFLOPs: 1092.3773
2024-04-28 12:07:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #498: GFLOPs: 713.9341. Time: 2591.9631 us. Best GFLOPs: 1092.3773
2024-04-28 12:07:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #499: GFLOPs: 32.4337. Time: 57054.5057 us. Best GFLOPs: 1092.3773
2024-04-28 12:07:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #500: GFLOPs: 972.9736. Time: 1901.8922 us. Best GFLOPs: 1092.3773
2024-04-28 12:07:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #501: GFLOPs: 754.5096. Time: 2452.5742 us. Best GFLOPs: 1092.3773
2024-04-28 12:07:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #502: GFLOPs: 777.0931. Time: 2381.2987 us. Best GFLOPs: 1092.3773
2024-04-28 12:07:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #503: GFLOPs: 771.2752. Time: 2399.2616 us. Best GFLOPs: 1092.3773
2024-04-28 12:07:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #504: GFLOPs: 689.0258. Time: 2685.6626 us. Best GFLOPs: 1092.3773
2024-04-28 12:07:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #505: GFLOPs: 364.5980. Time: 5075.4275 us. Best GFLOPs: 1092.3773
2024-04-28 12:07:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #506: GFLOPs: 712.7460. Time: 2596.2839 us. Best GFLOPs: 1092.3773
2024-04-28 12:07:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #507: GFLOPs: 603.0670. Time: 3068.4667 us. Best GFLOPs: 1092.3773
2024-04-28 12:07:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #508: GFLOPs: 806.5501. Time: 2294.3286 us. Best GFLOPs: 1092.3773
2024-04-28 12:07:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #509: GFLOPs: 793.3996. Time: 2332.3567 us. Best GFLOPs: 1092.3773
2024-04-28 12:07:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #510: GFLOPs: 72.9322. Time: 25372.7497 us. Best GFLOPs: 1092.3773
2024-04-28 12:07:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #511: GFLOPs: 7.0066. Time: 264107.7687 us. Best GFLOPs: 1092.3773
2024-04-28 12:07:52 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #512: GFLOPs: 31.9679. Time: 57885.9003 us. Best GFLOPs: 1092.3773
2024-04-28 12:54:53 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-28 12:54:54 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-28 12:54:59 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35c37e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x31a6de8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x9b6ad08)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x350b3f8)]: 0 failure(s)
2024-04-28 12:54:59 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-28 12:55:11 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35c37e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x31a6de8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x9b6ad08)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x350b3f8)]: 0 failure(s)
2024-04-28 12:55:23 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35c37e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x31a6de8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x9b6ad08)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x350b3f8)]: 0 failure(s)
2024-04-28 12:55:34 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35c37e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x31a6de8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x9b6ad08)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x350b3f8)]: 0 failure(s)
2024-04-28 12:55:46 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35c37e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x31a6de8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x9b6ad08)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x350b3f8)]: 0 failure(s)
2024-04-28 12:55:52 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.8243  0.8243  0.8212  0.8102  0.8102  0.7863  0.7863  0.7863  0.7653  0.7646  0.7616  0.7610  0.7587  0.7584  0.7584  0.7497
[17 : 32]:	0.7452  0.7350  0.7350  0.7350  0.7343  0.7215  0.7186  0.7153  0.7102  0.7059  0.7057  0.7003  0.7003  0.6985  0.6945  0.6945
[33 : 48]:	0.6917  0.6858  0.6832  0.6832  0.6827  0.6825  0.6776  0.6776  0.6760  0.6749  0.6736  0.6729  0.6707  0.6702  0.6697  0.6681
[49 : 64]:	0.6655  0.6628  0.6612  0.6608  0.6599  0.6585  0.6585  0.6565  0.6550  0.6537  0.6536  0.6524  0.6512  0.6512  0.6413  0.6407
2024-04-28 12:55:52 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-28 12:55:52 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-28 12:57:59 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #513: GFLOPs: 466.4905. Time: 3966.8353 us. Best GFLOPs: 1092.3773
2024-04-28 12:57:59 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #514: GFLOPs: 851.2868. Time: 2173.7573 us. Best GFLOPs: 1092.3773
2024-04-28 12:57:59 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #515: GFLOPs: 862.0414. Time: 2146.6381 us. Best GFLOPs: 1092.3773
2024-04-28 12:57:59 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #516: GFLOPs: 1039.6236. Time: 1779.9624 us. Best GFLOPs: 1092.3773
2024-04-28 12:57:59 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #517: GFLOPs: 1041.2774. Time: 1777.1354 us. Best GFLOPs: 1092.3773
2024-04-28 12:57:59 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #518: GFLOPs: 741.7589. Time: 2494.7335 us. Best GFLOPs: 1092.3773
2024-04-28 12:57:59 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #519: GFLOPs: 766.9735. Time: 2412.7183 us. Best GFLOPs: 1092.3773
2024-04-28 12:57:59 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #520: GFLOPs: 795.5761. Time: 2325.9759 us. Best GFLOPs: 1092.3773
2024-04-28 12:57:59 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #521: GFLOPs: 162.1188. Time: 11414.4123 us. Best GFLOPs: 1092.3773
2024-04-28 12:57:59 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #522: GFLOPs: 158.0782. Time: 11706.1763 us. Best GFLOPs: 1092.3773
2024-04-28 12:57:59 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #523: GFLOPs: 1128.3745. Time: 1639.9617 us. Best GFLOPs: 1128.3745
2024-04-28 12:57:59 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #524: GFLOPs: 889.7993. Time: 2079.6722 us. Best GFLOPs: 1128.3745
2024-04-28 12:57:59 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #525: GFLOPs: 191.4490. Time: 9665.7113 us. Best GFLOPs: 1128.3745
2024-04-28 12:57:59 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #526: GFLOPs: 804.0955. Time: 2301.3321 us. Best GFLOPs: 1128.3745
2024-04-28 12:57:59 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #527: GFLOPs: 847.8215. Time: 2182.6422 us. Best GFLOPs: 1128.3745
2024-04-28 12:57:59 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #528: GFLOPs: 795.4271. Time: 2326.4117 us. Best GFLOPs: 1128.3745
2024-04-28 12:57:59 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #529: GFLOPs: 707.0756. Time: 2617.1046 us. Best GFLOPs: 1128.3745
2024-04-28 12:57:59 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #530: GFLOPs: 730.1825. Time: 2534.2854 us. Best GFLOPs: 1128.3745
2024-04-28 12:57:59 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #531: GFLOPs: 884.9148. Time: 2091.1515 us. Best GFLOPs: 1128.3745
2024-04-28 12:57:59 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #532: GFLOPs: 926.7613. Time: 1996.7288 us. Best GFLOPs: 1128.3745
2024-04-28 12:57:59 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #533: GFLOPs: 776.9955. Time: 2381.5978 us. Best GFLOPs: 1128.3745
2024-04-28 12:57:59 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #534: GFLOPs: 902.7150. Time: 2049.9170 us. Best GFLOPs: 1128.3745
2024-04-28 12:57:59 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #535: GFLOPs: 189.1606. Time: 9782.6443 us. Best GFLOPs: 1128.3745
2024-04-28 12:57:59 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #536: GFLOPs: 828.8797. Time: 2232.5205 us. Best GFLOPs: 1128.3745
2024-04-28 12:57:59 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #537: GFLOPs: 937.2212. Time: 1974.4440 us. Best GFLOPs: 1128.3745
2024-04-28 12:57:59 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #538: GFLOPs: 696.4258. Time: 2657.1258 us. Best GFLOPs: 1128.3745
2024-04-28 12:57:59 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #539: GFLOPs: 816.0661. Time: 2267.5746 us. Best GFLOPs: 1128.3745
2024-04-28 12:57:59 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #540: GFLOPs: 770.7019. Time: 2401.0461 us. Best GFLOPs: 1128.3745
2024-04-28 12:57:59 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #541: GFLOPs: 804.3269. Time: 2300.6701 us. Best GFLOPs: 1128.3745
2024-04-28 12:57:59 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #542: GFLOPs: 648.2817. Time: 2854.4548 us. Best GFLOPs: 1128.3745
2024-04-28 12:57:59 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #543: GFLOPs: 1001.7348. Time: 1847.2862 us. Best GFLOPs: 1128.3745
2024-04-28 12:57:59 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #544: GFLOPs: 389.6886. Time: 4748.6404 us. Best GFLOPs: 1128.3745
2024-04-28 12:57:59 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #545: GFLOPs: 304.6588. Time: 6073.9788 us. Best GFLOPs: 1128.3745
2024-04-28 12:57:59 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #546: GFLOPs: 807.6508. Time: 2291.2017 us. Best GFLOPs: 1128.3745
2024-04-28 12:57:59 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #547: GFLOPs: 740.5991. Time: 2498.6404 us. Best GFLOPs: 1128.3745
2024-04-28 12:57:59 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #548: GFLOPs: 726.0069. Time: 2548.8614 us. Best GFLOPs: 1128.3745
2024-04-28 12:57:59 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #549: GFLOPs: 837.2470. Time: 2210.2090 us. Best GFLOPs: 1128.3745
2024-04-28 12:57:59 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #550: GFLOPs: 712.7935. Time: 2596.1109 us. Best GFLOPs: 1128.3745
2024-04-28 12:57:59 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #551: GFLOPs: 768.0745. Time: 2409.2595 us. Best GFLOPs: 1128.3745
2024-04-28 12:57:59 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #552: GFLOPs: 775.3752. Time: 2386.5748 us. Best GFLOPs: 1128.3745
2024-04-28 12:57:59 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #553: GFLOPs: 764.2819. Time: 2421.2151 us. Best GFLOPs: 1128.3745
2024-04-28 12:57:59 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #554: GFLOPs: 626.8113. Time: 2952.2295 us. Best GFLOPs: 1128.3745
2024-04-28 12:57:59 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #555: GFLOPs: 903.0557. Time: 2049.1437 us. Best GFLOPs: 1128.3745
2024-04-28 12:57:59 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #556: GFLOPs: 821.1903. Time: 2253.4251 us. Best GFLOPs: 1128.3745
2024-04-28 12:57:59 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #557: GFLOPs: 896.0967. Time: 2065.0570 us. Best GFLOPs: 1128.3745
2024-04-28 12:57:59 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #558: GFLOPs: 721.5549. Time: 2564.5878 us. Best GFLOPs: 1128.3745
2024-04-28 12:57:59 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #559: GFLOPs: 774.2583. Time: 2390.0174 us. Best GFLOPs: 1128.3745
2024-04-28 12:57:59 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #560: GFLOPs: 699.6146. Time: 2645.0145 us. Best GFLOPs: 1128.3745
2024-04-28 12:57:59 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #561: GFLOPs: 741.4437. Time: 2495.7942 us. Best GFLOPs: 1128.3745
2024-04-28 12:57:59 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #562: GFLOPs: 747.8559. Time: 2474.3951 us. Best GFLOPs: 1128.3745
2024-04-28 12:57:59 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #563: GFLOPs: 874.7956. Time: 2115.3408 us. Best GFLOPs: 1128.3745
2024-04-28 12:57:59 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #564: GFLOPs: 706.6177. Time: 2618.8005 us. Best GFLOPs: 1128.3745
2024-04-28 12:57:59 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #565: GFLOPs: 381.6901. Time: 4848.1503 us. Best GFLOPs: 1128.3745
2024-04-28 12:57:59 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #566: GFLOPs: 732.0573. Time: 2527.7952 us. Best GFLOPs: 1128.3745
2024-04-28 12:57:59 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #567: GFLOPs: 607.3617. Time: 3046.7692 us. Best GFLOPs: 1128.3745
2024-04-28 12:57:59 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #568: GFLOPs: 700.3158. Time: 2642.3663 us. Best GFLOPs: 1128.3745
2024-04-28 12:57:59 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #569: GFLOPs: 1070.0478. Time: 1729.3534 us. Best GFLOPs: 1128.3745
2024-04-28 12:57:59 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #570: GFLOPs: 565.0166. Time: 3275.1090 us. Best GFLOPs: 1128.3745
2024-04-28 12:57:59 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #571: GFLOPs: 804.2527. Time: 2300.8824 us. Best GFLOPs: 1128.3745
2024-04-28 12:57:59 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #572: GFLOPs: 742.3299. Time: 2492.8146 us. Best GFLOPs: 1128.3745
2024-04-28 12:57:59 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #573: GFLOPs: 781.8781. Time: 2366.7257 us. Best GFLOPs: 1128.3745
2024-04-28 12:57:59 [INFO] [task_scheduler.cc:121] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #574: Error in running:
LocalRunner: Timeout, killed after 30 seconds

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(256)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(3), T.int64(3), T.int64(256), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(28), T.int64(28), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(256)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(28), T.int64(28), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused in T.parallel(T.int64(4), annotations={"pragma_auto_unroll_max_step": 16, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1, ow_1 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(2)):
                for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(16), T.int64(16), T.int64(256)):
                    with T.block("data_pad"):
                        v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                        v_i2 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(2) * T.int64(14) + ax2)
                        v_i3 = T.axis.spatial(T.int64(30), ow_1 * T.int64(14) + ax3)
                        v_i4 = T.axis.spatial(T.int64(256), ax4)
                        T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                        T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                        data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                for oc_block_1 in range(T.int64(4)):
                    for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(14), T.int64(8), T.int64(1), T.int64(8), T.int64(14), T.int64(1), T.int64(1)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(2) * T.int64(8) + oc_chunk_1 * T.int64(8) + oc_chunk_2_init * T.int64(8) + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(2) * T.int64(14) + oh_1 * T.int64(14) + oh_2_init * T.int64(14) + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(28), ow_1 * T.int64(14) + ow_2_init + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(8) + oc_block_2_init + oc_block_3_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                    for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(8), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(14), T.int64(8), T.int64(32), T.int64(3), T.int64(1), T.int64(1), T.int64(8), T.int64(14), T.int64(1), T.int64(1)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(2) * T.int64(8) + oc_chunk_1 * T.int64(8) + oc_chunk_2 * T.int64(8) + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(2) * T.int64(14) + oh_1 * T.int64(14) + oh_2 * T.int64(14) + oh_3)
                            v_ow = T.axis.spatial(T.int64(28), ow_1 * T.int64(14) + ow_2 + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(8) + oc_block_2 + oc_block_3)
                            v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(32) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)], p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)] * p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(8), T.int64(14), T.int64(28)):
                for ax4_fused in T.vectorized(T.int64(32)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(2) * T.int64(8) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(2) * T.int64(14) + ax2)
                        v_ax3, v_ax4 = T.axis.remap("SS", [ax3, ax4_fused])
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[2, 1, 1, 8])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 1, 1, 14])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 2, 14, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 4, 8, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[8, 32])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=8)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b68)
l85 = sch.fuse(l71, l72, l73, l74, l75, preserve_unit_iters=True)
sch.parallel(loop=l85)
l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107 = sch.get_loops(block=b69)
l108 = sch.fuse(l86, preserve_unit_iters=True)
sch.parallel(loop=l108)
sch.annotate(block_or_loop=l108, ann_key="pragma_auto_unroll_max_step", ann_val=16)
sch.annotate(block_or_loop=l108, ann_key="pragma_unroll_explicit", ann_val=1)
l109, l110, l111, l112, l113, l114 = sch.get_loops(block=b70)
l115 = sch.fuse(l114, preserve_unit_iters=True)
sch.vectorize(loop=l115)
b116 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138 = sch.get_loops(block=b116)
b139 = sch.decompose_reduction(block=b116, loop=l123)
2024-04-28 12:57:59 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #575: GFLOPs: 188.2438. Time: 9830.2896 us. Best GFLOPs: 1128.3745
2024-04-28 12:57:59 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #576: GFLOPs: 91.0244. Time: 20329.6186 us. Best GFLOPs: 1128.3745
2024-04-28 13:29:31 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-28 13:29:32 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-28 13:29:37 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35c37e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x31a6de8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x9b6ad08)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x350b3f8)]: 0 failure(s)
2024-04-28 13:29:37 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-28 13:29:49 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35c37e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x31a6de8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x9b6ad08)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x350b3f8)]: 0 failure(s)
2024-04-28 13:30:01 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35c37e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x31a6de8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x9b6ad08)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x350b3f8)]: 0 failure(s)
2024-04-28 13:30:12 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35c37e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x31a6de8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x9b6ad08)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x350b3f8)]: 0 failure(s)
2024-04-28 13:30:24 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35c37e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x31a6de8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x9b6ad08)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x350b3f8)]: 0 failure(s)
2024-04-28 13:30:30 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9391  0.9377  0.9368  0.9368  0.8854  0.8822  0.8568  0.8568  0.8496  0.8473  0.8407  0.8349  0.8349  0.8253  0.8142  0.7987
[17 : 32]:	0.7927  0.7927  0.7759  0.7732  0.7726  0.7664  0.7555  0.7543  0.7535  0.7519  0.7519  0.7494  0.7494  0.7456  0.7456  0.7409
[33 : 48]:	0.7397  0.7356  0.7324  0.7315  0.7314  0.7289  0.7289  0.7263  0.7262  0.7240  0.7157  0.7145  0.7139  0.7038  0.6992  0.6986
[49 : 64]:	0.6980  0.6969  0.6969  0.6969  0.6956  0.6956  0.6919  0.6901  0.6900  0.6898  0.6894  0.6886  0.6878  0.6875  0.6857  0.6857
2024-04-28 13:30:30 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-28 13:30:30 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-28 13:32:10 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #577: GFLOPs: 582.4089. Time: 3177.3054 us. Best GFLOPs: 1128.3745
2024-04-28 13:32:10 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #578: GFLOPs: 978.2127. Time: 1891.7060 us. Best GFLOPs: 1128.3745
2024-04-28 13:32:10 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #579: GFLOPs: 1087.3215. Time: 1701.8802 us. Best GFLOPs: 1128.3745
2024-04-28 13:32:10 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #580: GFLOPs: 1068.0889. Time: 1732.5252 us. Best GFLOPs: 1128.3745
2024-04-28 13:32:10 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #581: GFLOPs: 1021.5724. Time: 1811.4143 us. Best GFLOPs: 1128.3745
2024-04-28 13:32:10 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #582: GFLOPs: 1033.3706. Time: 1790.7330 us. Best GFLOPs: 1128.3745
2024-04-28 13:32:10 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #583: GFLOPs: 1002.0618. Time: 1846.6835 us. Best GFLOPs: 1128.3745
2024-04-28 13:32:10 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #584: GFLOPs: 1041.5114. Time: 1776.7361 us. Best GFLOPs: 1128.3745
2024-04-28 13:32:10 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #585: GFLOPs: 1088.0259. Time: 1700.7783 us. Best GFLOPs: 1128.3745
2024-04-28 13:32:10 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #586: GFLOPs: 1091.3986. Time: 1695.5225 us. Best GFLOPs: 1128.3745
2024-04-28 13:32:10 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #587: GFLOPs: 949.2782. Time: 1949.3663 us. Best GFLOPs: 1128.3745
2024-04-28 13:32:10 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #588: GFLOPs: 994.3113. Time: 1861.0780 us. Best GFLOPs: 1128.3745
2024-04-28 13:32:10 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #589: GFLOPs: 903.9345. Time: 2047.1515 us. Best GFLOPs: 1128.3745
2024-04-28 13:32:10 [INFO] [task_scheduler.cc:121] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #590: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(256)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(3), T.int64(3), T.int64(256), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(28), T.int64(28), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(256)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(28), T.int64(28), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused in T.parallel(T.int64(896), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(3), T.int64(16), T.int64(256)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(224) * T.int64(7) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(7) + ax2)
                    v_i3 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(224) // T.int64(112) * T.int64(14) + ax3)
                    v_i4 = T.axis.spatial(T.int64(256), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(32), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(112) // T.int64(7) + oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(224) * T.int64(7) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(7) + oh_2_init + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(224) // T.int64(112) * T.int64(14) + ow_1 * T.int64(14) + ow_2_init * T.int64(7) + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(128), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(32), T.int64(2), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(112) // T.int64(7) + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(224) * T.int64(7) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(7) + oh_2 + oh_3)
                        v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(224) // T.int64(112) * T.int64(14) + ow_1 * T.int64(14) + ow_2 * T.int64(7) + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(2) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)], p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)] * p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(14)):
                    for ax4_fused in T.vectorized(T.int64(32)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(112) // T.int64(7) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(224) * T.int64(7) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(7) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(224) // T.int64(112) * T.int64(14) + ax3)
                            v_ax4 = T.axis.spatial(T.int64(32), ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 16, 1, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[4, 7, 1, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[2, 1, 2, 7])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 32, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[128, 2])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=7)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83 = sch.get_loops(block=b68)
l84 = sch.fuse(l71, l72, l73, l74, l75, l76, l77, l78, preserve_unit_iters=True)
sch.parallel(loop=l84)
l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l85, preserve_unit_iters=True)
sch.parallel(loop=l104)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109, l110, l111, l112 = sch.get_loops(block=b70)
l113 = sch.fuse(l112, preserve_unit_iters=True)
sch.vectorize(loop=l113)
b114 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133 = sch.get_loops(block=b114)
b134 = sch.decompose_reduction(block=b114, loop=l118)
2024-04-28 13:32:10 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #591: GFLOPs: 993.4786. Time: 1862.6378 us. Best GFLOPs: 1128.3745
2024-04-28 13:32:10 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #592: GFLOPs: 871.0450. Time: 2124.4493 us. Best GFLOPs: 1128.3745
2024-04-28 13:32:10 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #593: GFLOPs: 1052.1541. Time: 1758.7642 us. Best GFLOPs: 1128.3745
2024-04-28 13:32:10 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #594: GFLOPs: 1059.2431. Time: 1746.9936 us. Best GFLOPs: 1128.3745
2024-04-28 13:32:10 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #595: GFLOPs: 925.6232. Time: 1999.1837 us. Best GFLOPs: 1128.3745
2024-04-28 13:32:10 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #596: GFLOPs: 954.9879. Time: 1937.7113 us. Best GFLOPs: 1128.3745
2024-04-28 13:32:10 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #597: GFLOPs: 949.4297. Time: 1949.0551 us. Best GFLOPs: 1128.3745
2024-04-28 13:32:10 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #598: GFLOPs: 868.0962. Time: 2131.6657 us. Best GFLOPs: 1128.3745
2024-04-28 13:32:10 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #599: GFLOPs: 920.2792. Time: 2010.7929 us. Best GFLOPs: 1128.3745
2024-04-28 13:32:10 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #600: GFLOPs: 1032.7802. Time: 1791.7567 us. Best GFLOPs: 1128.3745
2024-04-28 13:32:10 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #601: GFLOPs: 747.0043. Time: 2477.2159 us. Best GFLOPs: 1128.3745
2024-04-28 13:32:10 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #602: GFLOPs: 901.5070. Time: 2052.6640 us. Best GFLOPs: 1128.3745
2024-04-28 13:32:10 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #603: GFLOPs: 959.1165. Time: 1929.3704 us. Best GFLOPs: 1128.3745
2024-04-28 13:32:10 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #604: GFLOPs: 863.1330. Time: 2143.9233 us. Best GFLOPs: 1128.3745
2024-04-28 13:32:10 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #605: GFLOPs: 864.8972. Time: 2139.5501 us. Best GFLOPs: 1128.3745
2024-04-28 13:32:10 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #606: GFLOPs: 125.2893. Time: 14769.7476 us. Best GFLOPs: 1128.3745
2024-04-28 13:32:10 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #607: GFLOPs: 126.2446. Time: 14657.9770 us. Best GFLOPs: 1128.3745
2024-04-28 13:32:10 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #608: GFLOPs: 806.4832. Time: 2294.5189 us. Best GFLOPs: 1128.3745
2024-04-28 13:32:10 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #609: GFLOPs: 985.8572. Time: 1877.0375 us. Best GFLOPs: 1128.3745
2024-04-28 13:32:10 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #610: GFLOPs: 1128.2736. Time: 1640.1083 us. Best GFLOPs: 1128.3745
2024-04-28 13:32:10 [INFO] [task_scheduler.cc:121] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #611: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(256)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(3), T.int64(3), T.int64(256), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(28), T.int64(28), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(256)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(28), T.int64(28), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused in T.parallel(T.int64(224), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(3), T.int64(16), T.int64(256)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(56) * T.int64(7) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(7) + ax2)
                    v_i3 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(56) // T.int64(28) * T.int64(14) + ax3)
                    v_i4 = T.axis.spatial(T.int64(256), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(1), T.int64(14), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(28) // T.int64(7) * T.int64(4) + oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(56) * T.int64(7) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(7) + oh_2_init + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(56) // T.int64(28) * T.int64(14) + ow_1 * T.int64(14) + ow_2_init * T.int64(14) + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(256), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(32), T.int64(1), T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(14), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(28) // T.int64(7) * T.int64(4) + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(56) * T.int64(7) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(7) + oh_2 + oh_3)
                        v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(56) // T.int64(28) * T.int64(14) + ow_1 * T.int64(14) + ow_2 * T.int64(14) + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(256), ic_0 + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)], p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)] * p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(4), T.int64(1), T.int64(14)):
                    for ax4_fused in T.vectorized(T.int64(32)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(28) // T.int64(7) * T.int64(4) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(56) * T.int64(7) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(7) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(56) // T.int64(28) * T.int64(14) + ax3)
                            v_ax4 = T.axis.spatial(T.int64(32), ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 4, 4, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[4, 7, 1, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[2, 1, 1, 14])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 32, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[256, 1])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=7)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83 = sch.get_loops(block=b68)
l84 = sch.fuse(l71, l72, l73, l74, l75, l76, l77, l78, preserve_unit_iters=True)
sch.parallel(loop=l84)
l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l85, preserve_unit_iters=True)
sch.parallel(loop=l104)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109, l110, l111, l112 = sch.get_loops(block=b70)
l113 = sch.fuse(l112, preserve_unit_iters=True)
sch.vectorize(loop=l113)
b114 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133 = sch.get_loops(block=b114)
b134 = sch.decompose_reduction(block=b114, loop=l118)
2024-04-28 13:32:10 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #612: GFLOPs: 676.3877. Time: 2735.8434 us. Best GFLOPs: 1128.3745
2024-04-28 13:32:10 [INFO] [task_scheduler.cc:121] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #613: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(256)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(3), T.int64(3), T.int64(256), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(28), T.int64(28), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(256)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(28), T.int64(28), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused in T.parallel(T.int64(448), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(3), T.int64(16), T.int64(256)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(112) * T.int64(7) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(7) + ax2)
                    v_i3 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(112) // T.int64(56) * T.int64(14) + ax3)
                    v_i4 = T.axis.spatial(T.int64(256), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(2), T.int64(32), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(56) // T.int64(7) * T.int64(2) + oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(112) * T.int64(7) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(7) + oh_2_init + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(112) // T.int64(56) * T.int64(14) + ow_1 * T.int64(14) + ow_2_init * T.int64(7) + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(128), T.int64(3), T.int64(3), T.int64(1), T.int64(2), T.int64(1), T.int64(2), T.int64(32), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(56) // T.int64(7) * T.int64(2) + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(112) * T.int64(7) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(7) + oh_2 + oh_3)
                        v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(112) // T.int64(56) * T.int64(14) + ow_1 * T.int64(14) + ow_2 * T.int64(7) + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(2) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)], p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)] * p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(14)):
                    for ax4_fused in T.vectorized(T.int64(32)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(56) // T.int64(7) * T.int64(2) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(112) * T.int64(7) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(7) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(112) // T.int64(56) * T.int64(14) + ax3)
                            v_ax4 = T.axis.spatial(T.int64(32), ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 8, 2, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[4, 7, 1, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[2, 1, 2, 7])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 32, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[128, 2])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=7)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83 = sch.get_loops(block=b68)
l84 = sch.fuse(l71, l72, l73, l74, l75, l76, l77, l78, preserve_unit_iters=True)
sch.parallel(loop=l84)
l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l85, preserve_unit_iters=True)
sch.parallel(loop=l104)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109, l110, l111, l112 = sch.get_loops(block=b70)
l113 = sch.fuse(l112, preserve_unit_iters=True)
sch.vectorize(loop=l113)
b114 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133 = sch.get_loops(block=b114)
b134 = sch.decompose_reduction(block=b114, loop=l118)
2024-04-28 13:32:10 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #614: GFLOPs: 808.1070. Time: 2289.9083 us. Best GFLOPs: 1128.3745
2024-04-28 13:32:10 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #615: GFLOPs: 914.8672. Time: 2022.6879 us. Best GFLOPs: 1128.3745
2024-04-28 13:32:10 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #616: GFLOPs: 790.7427. Time: 2340.1934 us. Best GFLOPs: 1128.3745
2024-04-28 13:32:10 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #617: GFLOPs: 969.1936. Time: 1909.3099 us. Best GFLOPs: 1128.3745
2024-04-28 13:32:10 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #618: GFLOPs: 649.3937. Time: 2849.5669 us. Best GFLOPs: 1128.3745
2024-04-28 13:32:10 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #619: GFLOPs: 1004.6806. Time: 1841.8697 us. Best GFLOPs: 1128.3745
2024-04-28 13:32:10 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #620: GFLOPs: 829.6737. Time: 2230.3840 us. Best GFLOPs: 1128.3745
2024-04-28 13:32:10 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #621: GFLOPs: 825.3497. Time: 2242.0689 us. Best GFLOPs: 1128.3745
2024-04-28 13:32:10 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #622: GFLOPs: 762.3886. Time: 2427.2278 us. Best GFLOPs: 1128.3745
2024-04-28 13:32:10 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #623: GFLOPs: 820.2434. Time: 2256.0264 us. Best GFLOPs: 1128.3745
2024-04-28 13:32:10 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #624: GFLOPs: 789.1777. Time: 2344.8344 us. Best GFLOPs: 1128.3745
2024-04-28 13:32:10 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #625: GFLOPs: 778.1637. Time: 2378.0227 us. Best GFLOPs: 1128.3745
2024-04-28 13:32:10 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #626: GFLOPs: 800.5337. Time: 2311.5715 us. Best GFLOPs: 1128.3745
2024-04-28 13:32:10 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #627: GFLOPs: 821.4800. Time: 2252.6304 us. Best GFLOPs: 1128.3745
2024-04-28 13:32:10 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #628: GFLOPs: 972.3893. Time: 1903.0351 us. Best GFLOPs: 1128.3745
2024-04-28 13:32:10 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #629: GFLOPs: 488.0729. Time: 3791.4231 us. Best GFLOPs: 1128.3745
2024-04-28 13:32:10 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #630: GFLOPs: 90.9993. Time: 20335.2144 us. Best GFLOPs: 1128.3745
2024-04-28 13:32:10 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #631: GFLOPs: 751.4833. Time: 2462.4510 us. Best GFLOPs: 1128.3745
2024-04-28 13:32:10 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #632: GFLOPs: 663.7304. Time: 2788.0158 us. Best GFLOPs: 1128.3745
2024-04-28 13:32:10 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #633: GFLOPs: 92.0588. Time: 20101.1884 us. Best GFLOPs: 1128.3745
2024-04-28 13:32:10 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #634: GFLOPs: 682.5719. Time: 2711.0564 us. Best GFLOPs: 1128.3745
2024-04-28 13:32:10 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #635: GFLOPs: 937.1325. Time: 1974.6311 us. Best GFLOPs: 1128.3745
2024-04-28 13:32:10 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #636: GFLOPs: 741.9947. Time: 2493.9408 us. Best GFLOPs: 1128.3745
2024-04-28 13:32:10 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #637: GFLOPs: 664.0151. Time: 2786.8205 us. Best GFLOPs: 1128.3745
2024-04-28 13:32:10 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #638: GFLOPs: 128.5818. Time: 14391.5481 us. Best GFLOPs: 1128.3745
2024-04-28 13:32:10 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #639: GFLOPs: 25.4868. Time: 72605.7290 us. Best GFLOPs: 1128.3745
2024-04-28 13:32:10 [INFO] [task_scheduler.cc:121] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #640: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(256)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(3), T.int64(3), T.int64(256), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(28), T.int64(28), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(256)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(28), T.int64(28), T.int64(32)))
        for n_0_oc_chunk_0_fused_fused in T.parallel(T.int64(2), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(256)):
                with T.block("data_pad"):
                    v_i0, v_i1, v_i2, v_i3, v_i4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oh_0, ow_0, oc_block_0 in T.grid(T.int64(1), T.int64(2), T.int64(1)):
                for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1)):
                    for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(4), T.int64(4), T.int64(1), T.int64(32), T.int64(1), T.int64(2), T.int64(7), T.int64(2), T.int64(1)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_fused_fused * T.int64(8) + oc_chunk_1 * T.int64(8) + oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(28), oh_0 * T.int64(28) + oh_1 * T.int64(28) + oh_2_init * T.int64(7) + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(28), ow_0 * T.int64(14) + ow_1 * T.int64(2) + ow_2_init * T.int64(2) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(32), oc_block_0 * T.int64(32) + oc_block_1 * T.int64(32) + oc_block_2_init + oc_block_3_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                    for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(8), T.int64(3), T.int64(3), T.int64(1), T.int64(4), T.int64(4), T.int64(1), T.int64(32), T.int64(32), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(7), T.int64(2), T.int64(1)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_fused_fused * T.int64(8) + oc_chunk_1 * T.int64(8) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(28), oh_0 * T.int64(28) + oh_1 * T.int64(28) + oh_2 * T.int64(7) + oh_3)
                            v_ow = T.axis.spatial(T.int64(28), ow_0 * T.int64(14) + ow_1 * T.int64(2) + ow_2 * T.int64(2) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(32), oc_block_0 * T.int64(32) + oc_block_1 * T.int64(32) + oc_block_2 + oc_block_3)
                            v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(32) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)], p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)] * p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(8), T.int64(28), T.int64(14)):
                    for ax4_fused in T.vectorized(T.int64(32)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_fused_fused * T.int64(8) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(28), ax2)
                            v_ax3 = T.axis.spatial(T.int64(28), ow_0 * T.int64(14) + ax3)
                            v_ax4 = T.axis.spatial(T.int64(32), ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[2, 1, 4, 2])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 4, 7])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[2, 7, 1, 2])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 32, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[8, 32])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=1)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77 = sch.get_loops(block=b68)
l78 = sch.fuse(l71, l72, preserve_unit_iters=True)
sch.parallel(loop=l78)
l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l79, preserve_unit_iters=True)
sch.parallel(loop=l104)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109, l110, l111, l112, l113 = sch.get_loops(block=b70)
l114 = sch.fuse(l113, preserve_unit_iters=True)
sch.vectorize(loop=l114)
b115 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140 = sch.get_loops(block=b115)
b141 = sch.decompose_reduction(block=b115, loop=l125)
2024-04-28 14:47:30 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-28 14:47:31 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-28 14:47:35 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35c37e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x31a6de8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x9b6ad08)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x350b3f8)]: 0 failure(s)
2024-04-28 14:47:35 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-28 14:47:48 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35c37e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x31a6de8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x9b6ad08)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x350b3f8)]: 0 failure(s)
2024-04-28 14:48:00 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35c37e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x31a6de8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x9b6ad08)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x350b3f8)]: 0 failure(s)
2024-04-28 14:48:11 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35c37e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x31a6de8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x9b6ad08)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x350b3f8)]: 0 failure(s)
2024-04-28 14:48:23 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35c37e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x31a6de8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x9b6ad08)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x350b3f8)]: 0 failure(s)
2024-04-28 14:48:30 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9488  0.9439  0.9262  0.9257  0.9145  0.9095  0.8943  0.8941  0.8933  0.8881  0.8848  0.8824  0.8804  0.8778  0.8767  0.8726
[17 : 32]:	0.8715  0.8687  0.8620  0.8609  0.8585  0.8573  0.8554  0.8554  0.8549  0.8549  0.8545  0.8530  0.8530  0.8506  0.8474  0.8474
[33 : 48]:	0.8472  0.8453  0.8453  0.8429  0.8406  0.8333  0.8331  0.8331  0.8325  0.8317  0.8314  0.8314  0.8300  0.8264  0.8261  0.8227
[49 : 64]:	0.8142  0.8111  0.8069  0.8053  0.8038  0.8017  0.8011  0.8006  0.7900  0.7893  0.7867  0.7860  0.7839  0.7839  0.7806  0.7784
2024-04-28 14:48:30 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-28 14:48:30 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-28 14:50:18 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #641: GFLOPs: 1024.5398. Time: 1806.1679 us. Best GFLOPs: 1128.3745
2024-04-28 14:50:18 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #642: GFLOPs: 882.1334. Time: 2097.7450 us. Best GFLOPs: 1128.3745
2024-04-28 14:50:18 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #643: GFLOPs: 1005.6264. Time: 1840.1376 us. Best GFLOPs: 1128.3745
2024-04-28 14:50:18 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #644: GFLOPs: 830.2393. Time: 2228.8645 us. Best GFLOPs: 1128.3745
2024-04-28 14:50:18 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #645: GFLOPs: 1023.9892. Time: 1807.1391 us. Best GFLOPs: 1128.3745
2024-04-28 14:50:18 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #646: GFLOPs: 1046.8115. Time: 1767.7404 us. Best GFLOPs: 1128.3745
2024-04-28 14:50:18 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #647: GFLOPs: 1118.1685. Time: 1654.9302 us. Best GFLOPs: 1128.3745
2024-04-28 14:50:18 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #648: GFLOPs: 860.0375. Time: 2151.6397 us. Best GFLOPs: 1128.3745
2024-04-28 14:50:18 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #649: GFLOPs: 641.6283. Time: 2884.0541 us. Best GFLOPs: 1128.3745
2024-04-28 14:50:18 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #650: GFLOPs: 1063.9668. Time: 1739.2375 us. Best GFLOPs: 1128.3745
2024-04-28 14:50:18 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #651: GFLOPs: 943.9482. Time: 1960.3733 us. Best GFLOPs: 1128.3745
2024-04-28 14:50:18 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #652: GFLOPs: 979.7574. Time: 1888.7235 us. Best GFLOPs: 1128.3745
2024-04-28 14:50:18 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #653: GFLOPs: 862.4175. Time: 2145.7018 us. Best GFLOPs: 1128.3745
2024-04-28 14:50:18 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #654: GFLOPs: 926.6880. Time: 1996.8867 us. Best GFLOPs: 1128.3745
2024-04-28 14:50:18 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #655: GFLOPs: 869.5804. Time: 2128.0275 us. Best GFLOPs: 1128.3745
2024-04-28 14:50:18 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #656: GFLOPs: 774.3652. Time: 2389.6877 us. Best GFLOPs: 1128.3745
2024-04-28 14:50:18 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #657: GFLOPs: 954.4723. Time: 1938.7581 us. Best GFLOPs: 1128.3745
2024-04-28 14:50:18 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #658: GFLOPs: 878.4664. Time: 2106.5016 us. Best GFLOPs: 1128.3745
2024-04-28 14:50:18 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #659: GFLOPs: 438.0354. Time: 4224.5233 us. Best GFLOPs: 1128.3745
2024-04-28 14:50:18 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #660: GFLOPs: 546.0504. Time: 3388.8649 us. Best GFLOPs: 1128.3745
2024-04-28 14:50:18 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #661: GFLOPs: 511.7792. Time: 3615.7995 us. Best GFLOPs: 1128.3745
2024-04-28 14:50:18 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #662: GFLOPs: 172.4890. Time: 10728.1675 us. Best GFLOPs: 1128.3745
2024-04-28 14:50:18 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #663: GFLOPs: 992.5820. Time: 1864.3204 us. Best GFLOPs: 1128.3745
2024-04-28 14:50:18 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #664: GFLOPs: 834.4131. Time: 2217.7154 us. Best GFLOPs: 1128.3745
2024-04-28 14:50:18 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #665: GFLOPs: 522.8161. Time: 3539.4681 us. Best GFLOPs: 1128.3745
2024-04-28 14:50:18 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #666: GFLOPs: 996.5114. Time: 1856.9690 us. Best GFLOPs: 1128.3745
2024-04-28 14:50:18 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #667: GFLOPs: 972.1112. Time: 1903.5795 us. Best GFLOPs: 1128.3745
2024-04-28 14:50:18 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #668: GFLOPs: 919.1349. Time: 2013.2962 us. Best GFLOPs: 1128.3745
2024-04-28 14:50:18 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #669: GFLOPs: 782.6716. Time: 2364.3260 us. Best GFLOPs: 1128.3745
2024-04-28 14:50:18 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #670: GFLOPs: 478.2257. Time: 3869.4930 us. Best GFLOPs: 1128.3745
2024-04-28 14:50:18 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #671: GFLOPs: 948.2513. Time: 1951.4772 us. Best GFLOPs: 1128.3745
2024-04-28 14:50:18 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #672: GFLOPs: 953.2357. Time: 1941.2732 us. Best GFLOPs: 1128.3745
2024-04-28 14:50:18 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #673: GFLOPs: 1008.7643. Time: 1834.4136 us. Best GFLOPs: 1128.3745
2024-04-28 14:50:18 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #674: GFLOPs: 761.4776. Time: 2430.1318 us. Best GFLOPs: 1128.3745
2024-04-28 14:50:18 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #675: GFLOPs: 767.8332. Time: 2410.0166 us. Best GFLOPs: 1128.3745
2024-04-28 14:50:18 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #676: GFLOPs: 767.7497. Time: 2410.2790 us. Best GFLOPs: 1128.3745
2024-04-28 14:50:18 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #677: GFLOPs: 867.3822. Time: 2133.4205 us. Best GFLOPs: 1128.3745
2024-04-28 14:50:18 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #678: GFLOPs: 599.5986. Time: 3086.2164 us. Best GFLOPs: 1128.3745
2024-04-28 14:50:18 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #679: GFLOPs: 954.6021. Time: 1938.4945 us. Best GFLOPs: 1128.3745
2024-04-28 14:50:18 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #680: GFLOPs: 917.8200. Time: 2016.1806 us. Best GFLOPs: 1128.3745
2024-04-28 14:50:18 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #681: GFLOPs: 1245.1684. Time: 1486.1370 us. Best GFLOPs: 1245.1684
2024-04-28 14:50:18 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #682: GFLOPs: 938.5893. Time: 1971.5662 us. Best GFLOPs: 1245.1684
2024-04-28 14:50:18 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #683: GFLOPs: 1237.9420. Time: 1494.8122 us. Best GFLOPs: 1245.1684
2024-04-28 14:50:18 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #684: GFLOPs: 809.7554. Time: 2285.2467 us. Best GFLOPs: 1245.1684
2024-04-28 14:50:18 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #685: GFLOPs: 1046.5048. Time: 1768.2584 us. Best GFLOPs: 1245.1684
2024-04-28 14:50:18 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #686: GFLOPs: 634.5623. Time: 2916.1691 us. Best GFLOPs: 1245.1684
2024-04-28 14:50:18 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #687: GFLOPs: 162.6083. Time: 11380.0497 us. Best GFLOPs: 1245.1684
2024-04-28 14:50:18 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #688: GFLOPs: 497.2970. Time: 3721.0983 us. Best GFLOPs: 1245.1684
2024-04-28 14:50:18 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #689: GFLOPs: 603.8118. Time: 3064.6816 us. Best GFLOPs: 1245.1684
2024-04-28 14:50:18 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #690: GFLOPs: 972.8249. Time: 1902.1828 us. Best GFLOPs: 1245.1684
2024-04-28 14:50:18 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #691: GFLOPs: 862.0663. Time: 2146.5762 us. Best GFLOPs: 1245.1684
2024-04-28 14:50:18 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #692: GFLOPs: 943.5106. Time: 1961.2825 us. Best GFLOPs: 1245.1684
2024-04-28 14:50:18 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #693: GFLOPs: 751.6936. Time: 2461.7622 us. Best GFLOPs: 1245.1684
2024-04-28 14:50:18 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #694: GFLOPs: 807.6273. Time: 2291.2684 us. Best GFLOPs: 1245.1684
2024-04-28 14:50:18 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #695: GFLOPs: 998.8340. Time: 1852.6510 us. Best GFLOPs: 1245.1684
2024-04-28 14:50:18 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #696: GFLOPs: 951.6513. Time: 1944.5053 us. Best GFLOPs: 1245.1684
2024-04-28 14:50:18 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #697: GFLOPs: 837.7452. Time: 2208.8946 us. Best GFLOPs: 1245.1684
2024-04-28 14:50:18 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #698: GFLOPs: 929.2527. Time: 1991.3753 us. Best GFLOPs: 1245.1684
2024-04-28 14:50:18 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #699: GFLOPs: 851.6242. Time: 2172.8960 us. Best GFLOPs: 1245.1684
2024-04-28 14:50:18 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #700: GFLOPs: 1058.2371. Time: 1748.6543 us. Best GFLOPs: 1245.1684
2024-04-28 14:50:18 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #701: GFLOPs: 603.5932. Time: 3065.7917 us. Best GFLOPs: 1245.1684
2024-04-28 14:50:18 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #702: GFLOPs: 10.0714. Time: 183737.7490 us. Best GFLOPs: 1245.1684
2024-04-28 14:50:18 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #703: GFLOPs: 6.9539. Time: 266106.9823 us. Best GFLOPs: 1245.1684
2024-04-28 14:50:18 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #704: GFLOPs: 18.4524. Time: 100284.8293 us. Best GFLOPs: 1245.1684
2024-04-28 15:09:44 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-28 15:09:45 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-28 15:09:50 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35c37e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x31a6de8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x9b6ad08)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x350b3f8)]: 0 failure(s)
2024-04-28 15:09:50 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-28 15:10:02 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35c37e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x31a6de8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x9b6ad08)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x350b3f8)]: 0 failure(s)
2024-04-28 15:10:14 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35c37e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x31a6de8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x9b6ad08)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x350b3f8)]: 0 failure(s)
2024-04-28 15:10:26 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35c37e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x31a6de8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x9b6ad08)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x350b3f8)]: 0 failure(s)
2024-04-28 15:10:38 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35c37e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x31a6de8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x9b6ad08)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x350b3f8)]: 0 failure(s)
2024-04-28 15:10:45 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9595  0.9520  0.9396  0.9211  0.8995  0.8813  0.8764  0.8764  0.8665  0.8652  0.8580  0.8455  0.8422  0.8362  0.8350  0.8323
[17 : 32]:	0.8286  0.8240  0.8196  0.8064  0.8019  0.7984  0.7958  0.7934  0.7851  0.7846  0.7824  0.7824  0.7746  0.7723  0.7723  0.7700
[33 : 48]:	0.7681  0.7671  0.7671  0.7655  0.7655  0.7632  0.7614  0.7614  0.7613  0.7543  0.7522  0.7512  0.7504  0.7487  0.7472  0.7456
[49 : 64]:	0.7414  0.7379  0.7375  0.7338  0.7318  0.7255  0.7249  0.7238  0.7225  0.7191  0.7191  0.7187  0.7176  0.7159  0.7154  0.7151
2024-04-28 15:10:45 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-28 15:10:45 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-28 15:13:06 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #705: GFLOPs: 1173.7722. Time: 1576.5332 us. Best GFLOPs: 1245.1684
2024-04-28 15:13:06 [INFO] [task_scheduler.cc:121] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #706: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(256)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(3), T.int64(3), T.int64(256), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(28), T.int64(28), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(256)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(28), T.int64(28), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused in T.parallel(T.int64(224), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(3), T.int64(16), T.int64(256)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(28) + ax2)
                    v_i3 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(112) * T.int64(14) + ax3)
                    v_i4 = T.axis.spatial(T.int64(256), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(4), T.int64(1), T.int64(2), T.int64(32), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(112) // T.int64(28) * T.int64(4) + oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(28) + oh_2_init + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(112) * T.int64(14) + ow_1 * T.int64(14) + ow_2_init * T.int64(7) + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(128), T.int64(3), T.int64(1), T.int64(1), T.int64(4), T.int64(1), T.int64(2), T.int64(32), T.int64(2), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(112) // T.int64(28) * T.int64(4) + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(28) + oh_2 + oh_3)
                        v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(112) * T.int64(14) + ow_1 * T.int64(14) + ow_2 * T.int64(7) + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(2) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)], p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)] * p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(4), T.int64(1), T.int64(14)):
                    for ax4_fused in T.vectorized(T.int64(32)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(112) // T.int64(28) * T.int64(4) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(28) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(112) * T.int64(14) + ax3)
                            v_ax4 = T.axis.spatial(T.int64(32), ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 4, 4, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 28, 1, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[2, 1, 2, 7])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 32, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[128, 2])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=7)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83 = sch.get_loops(block=b68)
l84 = sch.fuse(l71, l72, l73, l74, l75, l76, l77, l78, preserve_unit_iters=True)
sch.parallel(loop=l84)
l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l85, preserve_unit_iters=True)
sch.parallel(loop=l104)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109, l110, l111, l112 = sch.get_loops(block=b70)
l113 = sch.fuse(l112, preserve_unit_iters=True)
sch.vectorize(loop=l113)
b114 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133 = sch.get_loops(block=b114)
b134 = sch.decompose_reduction(block=b114, loop=l118)
2024-04-28 15:13:06 [INFO] [task_scheduler.cc:121] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #707: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(256)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(3), T.int64(3), T.int64(256), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(28), T.int64(28), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(256)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(28), T.int64(28), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused in T.parallel(T.int64(224), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(3), T.int64(16), T.int64(256)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(112) * T.int64(14) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(14) + ax2)
                    v_i3 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(112) // T.int64(56) * T.int64(14) + ax3)
                    v_i4 = T.axis.spatial(T.int64(256), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(4), T.int64(1), T.int64(2), T.int64(32), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(56) // T.int64(14) * T.int64(4) + oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(112) * T.int64(14) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(14) + oh_2_init + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(112) // T.int64(56) * T.int64(14) + ow_1 * T.int64(14) + ow_2_init * T.int64(7) + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(128), T.int64(3), T.int64(1), T.int64(1), T.int64(4), T.int64(1), T.int64(2), T.int64(32), T.int64(2), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(56) // T.int64(14) * T.int64(4) + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(112) * T.int64(14) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(14) + oh_2 + oh_3)
                        v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(112) // T.int64(56) * T.int64(14) + ow_1 * T.int64(14) + ow_2 * T.int64(7) + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(2) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)], p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)] * p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(4), T.int64(1), T.int64(14)):
                    for ax4_fused in T.vectorized(T.int64(32)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(56) // T.int64(14) * T.int64(4) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(112) * T.int64(14) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(14) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(112) // T.int64(56) * T.int64(14) + ax3)
                            v_ax4 = T.axis.spatial(T.int64(32), ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 4, 4, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 14, 1, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[2, 1, 2, 7])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 32, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[128, 2])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=7)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83 = sch.get_loops(block=b68)
l84 = sch.fuse(l71, l72, l73, l74, l75, l76, l77, l78, preserve_unit_iters=True)
sch.parallel(loop=l84)
l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l85, preserve_unit_iters=True)
sch.parallel(loop=l104)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109, l110, l111, l112 = sch.get_loops(block=b70)
l113 = sch.fuse(l112, preserve_unit_iters=True)
sch.vectorize(loop=l113)
b114 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133 = sch.get_loops(block=b114)
b134 = sch.decompose_reduction(block=b114, loop=l118)
2024-04-28 15:13:06 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #708: GFLOPs: 784.7667. Time: 2358.0140 us. Best GFLOPs: 1245.1684
2024-04-28 15:13:06 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #709: GFLOPs: 1127.3586. Time: 1641.4395 us. Best GFLOPs: 1245.1684
2024-04-28 15:13:06 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #710: GFLOPs: 1027.5125. Time: 1800.9424 us. Best GFLOPs: 1245.1684
2024-04-28 15:13:06 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #711: GFLOPs: 848.9123. Time: 2179.8376 us. Best GFLOPs: 1245.1684
2024-04-28 15:13:06 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #712: GFLOPs: 815.5846. Time: 2268.9135 us. Best GFLOPs: 1245.1684
2024-04-28 15:13:06 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #713: GFLOPs: 959.4255. Time: 1928.7489 us. Best GFLOPs: 1245.1684
2024-04-28 15:13:06 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #714: GFLOPs: 1079.9045. Time: 1713.5689 us. Best GFLOPs: 1245.1684
2024-04-28 15:13:06 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #715: GFLOPs: 900.9137. Time: 2054.0157 us. Best GFLOPs: 1245.1684
2024-04-28 15:13:06 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #716: GFLOPs: 1104.8239. Time: 1674.9193 us. Best GFLOPs: 1245.1684
2024-04-28 15:13:06 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #717: GFLOPs: 1089.5578. Time: 1698.3871 us. Best GFLOPs: 1245.1684
2024-04-28 15:13:06 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #718: GFLOPs: 987.6130. Time: 1873.7003 us. Best GFLOPs: 1245.1684
2024-04-28 15:13:06 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #719: GFLOPs: 1045.8652. Time: 1769.3397 us. Best GFLOPs: 1245.1684
2024-04-28 15:13:06 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #720: GFLOPs: 1063.4305. Time: 1740.1146 us. Best GFLOPs: 1245.1684
2024-04-28 15:13:06 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #721: GFLOPs: 993.9798. Time: 1861.6986 us. Best GFLOPs: 1245.1684
2024-04-28 15:13:06 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #722: GFLOPs: 1103.3043. Time: 1677.2261 us. Best GFLOPs: 1245.1684
2024-04-28 15:13:06 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #723: GFLOPs: 980.5742. Time: 1887.1503 us. Best GFLOPs: 1245.1684
2024-04-28 15:13:06 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #724: GFLOPs: 1062.1806. Time: 1742.1622 us. Best GFLOPs: 1245.1684
2024-04-28 15:13:06 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #725: GFLOPs: 968.7077. Time: 1910.2676 us. Best GFLOPs: 1245.1684
2024-04-28 15:13:06 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #726: GFLOPs: 936.1576. Time: 1976.6873 us. Best GFLOPs: 1245.1684
2024-04-28 15:13:06 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #727: GFLOPs: 914.6669. Time: 2023.1309 us. Best GFLOPs: 1245.1684
2024-04-28 15:13:06 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #728: GFLOPs: 1025.6044. Time: 1804.2930 us. Best GFLOPs: 1245.1684
2024-04-28 15:13:06 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #729: GFLOPs: 976.4412. Time: 1895.1380 us. Best GFLOPs: 1245.1684
2024-04-28 15:13:06 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #730: GFLOPs: 617.9198. Time: 2994.7106 us. Best GFLOPs: 1245.1684
2024-04-28 15:13:06 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #731: GFLOPs: 1067.2850. Time: 1733.8301 us. Best GFLOPs: 1245.1684
2024-04-28 15:13:06 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #732: GFLOPs: 1048.0256. Time: 1765.6924 us. Best GFLOPs: 1245.1684
2024-04-28 15:13:06 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #733: GFLOPs: 968.4439. Time: 1910.7879 us. Best GFLOPs: 1245.1684
2024-04-28 15:13:06 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #734: GFLOPs: 1039.6710. Time: 1779.8813 us. Best GFLOPs: 1245.1684
2024-04-28 15:13:06 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #735: GFLOPs: 902.6912. Time: 2049.9711 us. Best GFLOPs: 1245.1684
2024-04-28 15:13:06 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #736: GFLOPs: 813.6509. Time: 2274.3056 us. Best GFLOPs: 1245.1684
2024-04-28 15:13:06 [INFO] [task_scheduler.cc:121] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #737: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(256)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(3), T.int64(3), T.int64(256), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(28), T.int64(28), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(256)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(28), T.int64(28), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused in T.parallel(T.int64(224), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(3), T.int64(16), T.int64(256)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(28) + ax2)
                    v_i3 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(112) * T.int64(14) + ax3)
                    v_i4 = T.axis.spatial(T.int64(256), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(4), T.int64(1), T.int64(2), T.int64(32), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(112) // T.int64(28) * T.int64(4) + oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(28) + oh_2_init + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(112) * T.int64(14) + ow_1 * T.int64(14) + ow_2_init * T.int64(7) + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(256), T.int64(3), T.int64(1), T.int64(1), T.int64(4), T.int64(1), T.int64(2), T.int64(32), T.int64(1), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(112) // T.int64(28) * T.int64(4) + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(28) + oh_2 + oh_3)
                        v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(112) * T.int64(14) + ow_1 * T.int64(14) + ow_2 * T.int64(7) + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(256), ic_0 + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)], p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)] * p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(4), T.int64(1), T.int64(14)):
                    for ax4_fused in T.vectorized(T.int64(32)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(112) // T.int64(28) * T.int64(4) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(28) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(112) * T.int64(14) + ax3)
                            v_ax4 = T.axis.spatial(T.int64(32), ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 4, 4, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 28, 1, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[2, 1, 2, 7])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 32, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[256, 1])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=7)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83 = sch.get_loops(block=b68)
l84 = sch.fuse(l71, l72, l73, l74, l75, l76, l77, l78, preserve_unit_iters=True)
sch.parallel(loop=l84)
l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l85, preserve_unit_iters=True)
sch.parallel(loop=l104)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109, l110, l111, l112 = sch.get_loops(block=b70)
l113 = sch.fuse(l112, preserve_unit_iters=True)
sch.vectorize(loop=l113)
b114 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133 = sch.get_loops(block=b114)
b134 = sch.decompose_reduction(block=b114, loop=l118)
2024-04-28 15:13:06 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #738: GFLOPs: 876.2900. Time: 2111.7334 us. Best GFLOPs: 1245.1684
2024-04-28 15:13:06 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #739: GFLOPs: 901.3981. Time: 2052.9119 us. Best GFLOPs: 1245.1684
2024-04-28 15:13:06 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #740: GFLOPs: 592.8872. Time: 3121.1515 us. Best GFLOPs: 1245.1684
2024-04-28 15:13:06 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #741: GFLOPs: 599.6777. Time: 3085.8091 us. Best GFLOPs: 1245.1684
2024-04-28 15:13:06 [INFO] [task_scheduler.cc:121] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #742: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(256)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(3), T.int64(3), T.int64(256), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(28), T.int64(28), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(256)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(28), T.int64(28), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused in T.parallel(T.int64(224), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(3), T.int64(16), T.int64(256)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(28) + ax2)
                    v_i3 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(112) * T.int64(14) + ax3)
                    v_i4 = T.axis.spatial(T.int64(256), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(4), T.int64(1), T.int64(2), T.int64(32), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(112) // T.int64(28) * T.int64(4) + oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(28) + oh_2_init + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(112) * T.int64(14) + ow_1 * T.int64(14) + ow_2_init * T.int64(7) + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(64), T.int64(3), T.int64(1), T.int64(1), T.int64(4), T.int64(1), T.int64(2), T.int64(32), T.int64(4), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(112) // T.int64(28) * T.int64(4) + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(28) + oh_2 + oh_3)
                        v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(112) * T.int64(14) + ow_1 * T.int64(14) + ow_2 * T.int64(7) + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(4) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)], p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)] * p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(4), T.int64(1), T.int64(14)):
                    for ax4_fused in T.vectorized(T.int64(32)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(112) // T.int64(28) * T.int64(4) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(28) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(112) * T.int64(14) + ax3)
                            v_ax4 = T.axis.spatial(T.int64(32), ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 4, 4, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 28, 1, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[2, 1, 2, 7])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 32, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[64, 4])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=7)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83 = sch.get_loops(block=b68)
l84 = sch.fuse(l71, l72, l73, l74, l75, l76, l77, l78, preserve_unit_iters=True)
sch.parallel(loop=l84)
l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l85, preserve_unit_iters=True)
sch.parallel(loop=l104)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109, l110, l111, l112 = sch.get_loops(block=b70)
l113 = sch.fuse(l112, preserve_unit_iters=True)
sch.vectorize(loop=l113)
b114 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133 = sch.get_loops(block=b114)
b134 = sch.decompose_reduction(block=b114, loop=l118)
2024-04-28 15:13:06 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #743: GFLOPs: 1029.9248. Time: 1796.7242 us. Best GFLOPs: 1245.1684
2024-04-28 15:13:06 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #744: GFLOPs: 887.6795. Time: 2084.6385 us. Best GFLOPs: 1245.1684
2024-04-28 15:13:06 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #745: GFLOPs: 892.7523. Time: 2072.7932 us. Best GFLOPs: 1245.1684
2024-04-28 15:13:06 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #746: GFLOPs: 942.3440. Time: 1963.7106 us. Best GFLOPs: 1245.1684
2024-04-28 15:13:06 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #747: GFLOPs: 875.0999. Time: 2114.6053 us. Best GFLOPs: 1245.1684
2024-04-28 15:13:06 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #748: GFLOPs: 809.7236. Time: 2285.3364 us. Best GFLOPs: 1245.1684
2024-04-28 15:13:06 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #749: GFLOPs: 948.3950. Time: 1951.1816 us. Best GFLOPs: 1245.1684
2024-04-28 15:13:06 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #750: GFLOPs: 904.5806. Time: 2045.6894 us. Best GFLOPs: 1245.1684
2024-04-28 15:13:06 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #751: GFLOPs: 851.8010. Time: 2172.4452 us. Best GFLOPs: 1245.1684
2024-04-28 15:13:06 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #752: GFLOPs: 620.9241. Time: 2980.2206 us. Best GFLOPs: 1245.1684
2024-04-28 15:13:06 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #753: GFLOPs: 887.9914. Time: 2083.9064 us. Best GFLOPs: 1245.1684
2024-04-28 15:13:06 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #754: GFLOPs: 865.5010. Time: 2138.0576 us. Best GFLOPs: 1245.1684
2024-04-28 15:13:06 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #755: GFLOPs: 933.0968. Time: 1983.1713 us. Best GFLOPs: 1245.1684
2024-04-28 15:13:06 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #756: GFLOPs: 892.4216. Time: 2073.5613 us. Best GFLOPs: 1245.1684
2024-04-28 15:13:06 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #757: GFLOPs: 897.2371. Time: 2062.4324 us. Best GFLOPs: 1245.1684
2024-04-28 15:13:06 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #758: GFLOPs: 792.8980. Time: 2333.8322 us. Best GFLOPs: 1245.1684
2024-04-28 15:13:06 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #759: GFLOPs: 327.0034. Time: 5658.9344 us. Best GFLOPs: 1245.1684
2024-04-28 15:13:06 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #760: GFLOPs: 904.1819. Time: 2046.5913 us. Best GFLOPs: 1245.1684
2024-04-28 15:13:06 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #761: GFLOPs: 739.4002. Time: 2502.6920 us. Best GFLOPs: 1245.1684
2024-04-28 15:13:06 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #762: GFLOPs: 85.3142. Time: 21690.3128 us. Best GFLOPs: 1245.1684
2024-04-28 15:13:06 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #763: GFLOPs: 88.1770. Time: 20986.0946 us. Best GFLOPs: 1245.1684
2024-04-28 15:13:06 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #764: GFLOPs: 947.1242. Time: 1953.7996 us. Best GFLOPs: 1245.1684
2024-04-28 15:13:06 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #765: GFLOPs: 692.7545. Time: 2671.2074 us. Best GFLOPs: 1245.1684
2024-04-28 15:13:06 [INFO] [task_scheduler.cc:121] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #766: Error in running:
LocalRunner: Timeout, killed after 30 seconds

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(256)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(3), T.int64(3), T.int64(256), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(28), T.int64(28), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(256)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(28), T.int64(28), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_fused_fused in T.parallel(T.int64(4), annotations={"pragma_auto_unroll_max_step": 64, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(16), T.int64(30), T.int64(256)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_fused_fused % T.int64(2) * T.int64(14) + ax2)
                    v_i3, v_i4 = T.axis.remap("SS", [ax3, ax4])
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for ow_0, oc_block_0, n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(28), T.int64(2)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(14), T.int64(1), T.int64(4), T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_fused_fused // T.int64(2) * T.int64(8) + oc_chunk_1 * T.int64(8) + oc_chunk_2_init * T.int64(8) + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_fused_fused % T.int64(2) * T.int64(14) + oh_1 * T.int64(14) + oh_2_init + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(28), ow_0 * T.int64(28) + ow_1 + ow_2_init + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_0 * T.int64(8) + oc_block_1 * T.int64(4) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(64), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(14), T.int64(1), T.int64(4), T.int64(4), T.int64(3), T.int64(1), T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_fused_fused // T.int64(2) * T.int64(8) + oc_chunk_1 * T.int64(8) + oc_chunk_2 * T.int64(8) + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_fused_fused % T.int64(2) * T.int64(14) + oh_1 * T.int64(14) + oh_2 + oh_3)
                        v_ow = T.axis.spatial(T.int64(28), ow_0 * T.int64(28) + ow_1 + ow_2 + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_0 * T.int64(8) + oc_block_1 * T.int64(4) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(4) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)], p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)] * p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block]
        for ax0_ax1_ax2_ax3_ax4_fused_0 in T.parallel(T.int64(6272)):
            for ax0_ax1_ax2_ax3_ax4_fused_1 in T.vectorized(T.int64(64)):
                with T.block("T_relu"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) // T.int64(25088))
                    v_ax2 = T.axis.spatial(T.int64(28), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(25088) // T.int64(896))
                    v_ax3 = T.axis.spatial(T.int64(28), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(896) // T.int64(32))
                    v_ax4 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(32))
                    T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                    T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[2, 1, 1, 8])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 1, 14, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 28, 1, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[4, 2, 4, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[64, 4])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
l65 = sch.sample_compute_location(block=b0, decision=2)
sch.compute_at(block=b0, loop=l65, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b66 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.unroll_explicit")
b67, b68, b69 = sch.get_child_blocks(b66)
l70, l71, l72, l73, l74, l75, l76, l77 = sch.get_loops(block=b67)
l78 = sch.fuse(l70, l71, l72, preserve_unit_iters=True)
sch.parallel(loop=l78)
l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102 = sch.get_loops(block=b68)
l103 = sch.fuse(l79, preserve_unit_iters=True)
sch.parallel(loop=l103)
sch.annotate(block_or_loop=l103, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l103, ann_key="pragma_unroll_explicit", ann_val=1)
l104, l105, l106, l107, l108 = sch.get_loops(block=b69)
l109 = sch.fuse(l104, l105, l106, l107, l108, preserve_unit_iters=True)
l110, l111 = sch.split(loop=l109, factors=[None, 64], preserve_unit_iters=True)
sch.parallel(loop=l110)
sch.vectorize(loop=l111)
b112 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l113, l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136 = sch.get_loops(block=b112)
b137 = sch.decompose_reduction(block=b112, loop=l121)
2024-04-28 15:13:06 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #767: GFLOPs: 7.5938. Time: 243685.6507 us. Best GFLOPs: 1245.1684
2024-04-28 15:13:06 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #768: GFLOPs: 5.3119. Time: 348364.4390 us. Best GFLOPs: 1245.1684
2024-04-28 16:04:08 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-28 16:04:09 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-28 16:04:14 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35c37e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x31a6de8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x9b6ad08)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x350b3f8)]: 0 failure(s)
2024-04-28 16:04:14 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-28 16:04:27 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35c37e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x31a6de8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x9b6ad08)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x350b3f8)]: 0 failure(s)
2024-04-28 16:04:39 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35c37e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x31a6de8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x9b6ad08)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x350b3f8)]: 0 failure(s)
2024-04-28 16:04:51 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35c37e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x31a6de8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x9b6ad08)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x350b3f8)]: 0 failure(s)
2024-04-28 16:05:03 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35c37e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x31a6de8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x9b6ad08)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x350b3f8)]: 0 failure(s)
2024-04-28 16:05:10 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.8499  0.8462  0.8434  0.8405  0.8282  0.8282  0.8277  0.8219  0.8158  0.8154  0.8107  0.8036  0.8007  0.7978  0.7889  0.7880
[17 : 32]:	0.7880  0.7849  0.7810  0.7810  0.7805  0.7801  0.7801  0.7753  0.7719  0.7691  0.7686  0.7647  0.7645  0.7640  0.7561  0.7541
[33 : 48]:	0.7541  0.7511  0.7501  0.7501  0.7501  0.7499  0.7494  0.7483  0.7465  0.7464  0.7464  0.7458  0.7439  0.7434  0.7424  0.7420
[49 : 64]:	0.7403  0.7387  0.7359  0.7353  0.7343  0.7329  0.7323  0.7323  0.7323  0.7301  0.7295  0.7295  0.7291  0.7281  0.7251  0.7235
2024-04-28 16:05:11 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-28 16:05:11 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-28 16:07:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #769: GFLOPs: 1114.2197. Time: 1660.7954 us. Best GFLOPs: 1245.1684
2024-04-28 16:07:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #770: GFLOPs: 902.0426. Time: 2051.4452 us. Best GFLOPs: 1245.1684
2024-04-28 16:07:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #771: GFLOPs: 1068.1143. Time: 1732.4840 us. Best GFLOPs: 1245.1684
2024-04-28 16:07:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #772: GFLOPs: 1028.7782. Time: 1798.7268 us. Best GFLOPs: 1245.1684
2024-04-28 16:07:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #773: GFLOPs: 1169.5115. Time: 1582.2768 us. Best GFLOPs: 1245.1684
2024-04-28 16:07:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #774: GFLOPs: 1070.1006. Time: 1729.2681 us. Best GFLOPs: 1245.1684
2024-04-28 16:07:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #775: GFLOPs: 897.0349. Time: 2062.8972 us. Best GFLOPs: 1245.1684
2024-04-28 16:07:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #776: GFLOPs: 922.1920. Time: 2006.6222 us. Best GFLOPs: 1245.1684
2024-04-28 16:07:03 [INFO] [task_scheduler.cc:121] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #777: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(256)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(3), T.int64(3), T.int64(256), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(28), T.int64(28), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(256)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(28), T.int64(28), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused in T.parallel(T.int64(896), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(3), T.int64(16), T.int64(256)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(224) * T.int64(7) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(14) // T.int64(2) + ax2)
                    v_i3 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(2) * T.int64(14) + ax3)
                    v_i4 = T.axis.spatial(T.int64(256), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oc_block_1 in range(T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(32), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(224) // T.int64(14) + oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(224) * T.int64(7) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(14) // T.int64(2) + oh_2_init + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(2) * T.int64(14) + ow_2_init * T.int64(7) + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(128), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(32), T.int64(2), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(224) // T.int64(14) + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(224) * T.int64(7) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(14) // T.int64(2) + oh_2 + oh_3)
                        v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(2) * T.int64(14) + ow_2 * T.int64(7) + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(2) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)], p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)] * p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(14)):
                    for ax4_fused in T.vectorized(T.int64(32)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(224) // T.int64(14) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(224) * T.int64(7) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(14) // T.int64(2) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(2) * T.int64(14) + ax3)
                            v_ax4 = T.axis.spatial(T.int64(32), ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 16, 1, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[4, 7, 1, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 2, 2, 7])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 32, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[128, 2])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=8)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b68)
l85 = sch.fuse(l71, l72, l73, l74, l75, l76, l77, l78, l79, preserve_unit_iters=True)
sch.parallel(loop=l85)
l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l86, preserve_unit_iters=True)
sch.parallel(loop=l104)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109, l110, l111 = sch.get_loops(block=b70)
l112 = sch.fuse(l111, preserve_unit_iters=True)
sch.vectorize(loop=l112)
b113 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131 = sch.get_loops(block=b113)
b132 = sch.decompose_reduction(block=b113, loop=l116)
2024-04-28 16:07:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #778: GFLOPs: 1007.2720. Time: 1837.1313 us. Best GFLOPs: 1245.1684
2024-04-28 16:07:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #779: GFLOPs: 1069.2092. Time: 1730.7099 us. Best GFLOPs: 1245.1684
2024-04-28 16:07:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #780: GFLOPs: 1009.7427. Time: 1832.6360 us. Best GFLOPs: 1245.1684
2024-04-28 16:07:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #781: GFLOPs: 1002.3926. Time: 1846.0739 us. Best GFLOPs: 1245.1684
2024-04-28 16:07:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #782: GFLOPs: 1012.1701. Time: 1828.2410 us. Best GFLOPs: 1245.1684
2024-04-28 16:07:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #783: GFLOPs: 1003.6250. Time: 1843.8070 us. Best GFLOPs: 1245.1684
2024-04-28 16:07:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #784: GFLOPs: 1033.6366. Time: 1790.2722 us. Best GFLOPs: 1245.1684
2024-04-28 16:07:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #785: GFLOPs: 963.0632. Time: 1921.4636 us. Best GFLOPs: 1245.1684
2024-04-28 16:07:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #786: GFLOPs: 980.0040. Time: 1888.2483 us. Best GFLOPs: 1245.1684
2024-04-28 16:07:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #787: GFLOPs: 887.2579. Time: 2085.6291 us. Best GFLOPs: 1245.1684
2024-04-28 16:07:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #788: GFLOPs: 881.1059. Time: 2100.1912 us. Best GFLOPs: 1245.1684
2024-04-28 16:07:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #789: GFLOPs: 404.0998. Time: 4579.2916 us. Best GFLOPs: 1245.1684
2024-04-28 16:07:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #790: GFLOPs: 854.6421. Time: 2165.2231 us. Best GFLOPs: 1245.1684
2024-04-28 16:07:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #791: GFLOPs: 861.0269. Time: 2149.1673 us. Best GFLOPs: 1245.1684
2024-04-28 16:07:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #792: GFLOPs: 1003.4785. Time: 1844.0762 us. Best GFLOPs: 1245.1684
2024-04-28 16:07:03 [INFO] [task_scheduler.cc:121] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #793: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(256)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(3), T.int64(3), T.int64(256), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(28), T.int64(28), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(256)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(28), T.int64(28), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused in T.parallel(T.int64(112), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(3), T.int64(16), T.int64(256)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(28) + ax2)
                    v_i3 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(56) // T.int64(28) * T.int64(14) + ax3)
                    v_i4 = T.axis.spatial(T.int64(256), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(1), T.int64(14), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(56) * T.int64(8) + oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(28) + oh_2_init + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(56) // T.int64(28) * T.int64(14) + ow_1 * T.int64(14) + ow_2_init * T.int64(14) + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(128), T.int64(3), T.int64(1), T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(32), T.int64(2), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(14), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(56) * T.int64(8) + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(28) + oh_2 + oh_3)
                        v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(56) // T.int64(28) * T.int64(14) + ow_1 * T.int64(14) + ow_2 * T.int64(14) + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(2) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)], p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)] * p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(8), T.int64(1), T.int64(14)):
                    for ax4_fused in T.vectorized(T.int64(32)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(56) * T.int64(8) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(28) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(56) // T.int64(28) * T.int64(14) + ax3)
                            v_ax4 = T.axis.spatial(T.int64(32), ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[2, 1, 8, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 28, 1, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[2, 1, 1, 14])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 32, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[128, 2])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=7)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83 = sch.get_loops(block=b68)
l84 = sch.fuse(l71, l72, l73, l74, l75, l76, l77, l78, preserve_unit_iters=True)
sch.parallel(loop=l84)
l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l85, preserve_unit_iters=True)
sch.parallel(loop=l104)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109, l110, l111, l112 = sch.get_loops(block=b70)
l113 = sch.fuse(l112, preserve_unit_iters=True)
sch.vectorize(loop=l113)
b114 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133 = sch.get_loops(block=b114)
b134 = sch.decompose_reduction(block=b114, loop=l118)
2024-04-28 16:07:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #794: GFLOPs: 908.3015. Time: 2037.3092 us. Best GFLOPs: 1245.1684
2024-04-28 16:07:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #795: GFLOPs: 1024.8577. Time: 1805.6076 us. Best GFLOPs: 1245.1684
2024-04-28 16:07:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #796: GFLOPs: 913.4800. Time: 2025.7596 us. Best GFLOPs: 1245.1684
2024-04-28 16:07:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #797: GFLOPs: 923.3295. Time: 2004.1501 us. Best GFLOPs: 1245.1684
2024-04-28 16:07:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #798: GFLOPs: 942.7760. Time: 1962.8107 us. Best GFLOPs: 1245.1684
2024-04-28 16:07:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #799: GFLOPs: 922.9471. Time: 2004.9805 us. Best GFLOPs: 1245.1684
2024-04-28 16:07:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #800: GFLOPs: 926.0085. Time: 1998.3520 us. Best GFLOPs: 1245.1684
2024-04-28 16:07:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #801: GFLOPs: 914.6724. Time: 2023.1188 us. Best GFLOPs: 1245.1684
2024-04-28 16:07:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #802: GFLOPs: 428.7449. Time: 4316.0648 us. Best GFLOPs: 1245.1684
2024-04-28 16:07:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #803: GFLOPs: 944.8864. Time: 1958.4267 us. Best GFLOPs: 1245.1684
2024-04-28 16:07:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #804: GFLOPs: 914.8972. Time: 2022.6216 us. Best GFLOPs: 1245.1684
2024-04-28 16:07:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #805: GFLOPs: 947.2863. Time: 1953.4653 us. Best GFLOPs: 1245.1684
2024-04-28 16:07:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #806: GFLOPs: 1054.7099. Time: 1754.5023 us. Best GFLOPs: 1245.1684
2024-04-28 16:07:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #807: GFLOPs: 985.9344. Time: 1876.8904 us. Best GFLOPs: 1245.1684
2024-04-28 16:07:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #808: GFLOPs: 917.7151. Time: 2016.4111 us. Best GFLOPs: 1245.1684
2024-04-28 16:07:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #809: GFLOPs: 868.0096. Time: 2131.8784 us. Best GFLOPs: 1245.1684
2024-04-28 16:07:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #810: GFLOPs: 936.4279. Time: 1976.1167 us. Best GFLOPs: 1245.1684
2024-04-28 16:07:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #811: GFLOPs: 958.7206. Time: 1930.1670 us. Best GFLOPs: 1245.1684
2024-04-28 16:07:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #812: GFLOPs: 959.8874. Time: 1927.8208 us. Best GFLOPs: 1245.1684
2024-04-28 16:07:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #813: GFLOPs: 1040.4283. Time: 1778.5857 us. Best GFLOPs: 1245.1684
2024-04-28 16:07:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #814: GFLOPs: 1116.6636. Time: 1657.1606 us. Best GFLOPs: 1245.1684
2024-04-28 16:07:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #815: GFLOPs: 904.4768. Time: 2045.9242 us. Best GFLOPs: 1245.1684
2024-04-28 16:07:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #816: GFLOPs: 691.7110. Time: 2675.2369 us. Best GFLOPs: 1245.1684
2024-04-28 16:07:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #817: GFLOPs: 956.1760. Time: 1935.3037 us. Best GFLOPs: 1245.1684
2024-04-28 16:07:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #818: GFLOPs: 854.0231. Time: 2166.7926 us. Best GFLOPs: 1245.1684
2024-04-28 16:07:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #819: GFLOPs: 766.0475. Time: 2415.6346 us. Best GFLOPs: 1245.1684
2024-04-28 16:07:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #820: GFLOPs: 805.3357. Time: 2297.7882 us. Best GFLOPs: 1245.1684
2024-04-28 16:07:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #821: GFLOPs: 992.4151. Time: 1864.6339 us. Best GFLOPs: 1245.1684
2024-04-28 16:07:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #822: GFLOPs: 1021.0071. Time: 1812.4173 us. Best GFLOPs: 1245.1684
2024-04-28 16:07:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #823: GFLOPs: 872.7268. Time: 2120.3552 us. Best GFLOPs: 1245.1684
2024-04-28 16:07:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #824: GFLOPs: 871.3390. Time: 2123.7324 us. Best GFLOPs: 1245.1684
2024-04-28 16:07:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #825: GFLOPs: 769.6105. Time: 2404.4511 us. Best GFLOPs: 1245.1684
2024-04-28 16:07:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #826: GFLOPs: 681.9813. Time: 2713.4040 us. Best GFLOPs: 1245.1684
2024-04-28 16:07:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #827: GFLOPs: 807.6237. Time: 2291.2787 us. Best GFLOPs: 1245.1684
2024-04-28 16:07:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #828: GFLOPs: 879.4512. Time: 2104.1426 us. Best GFLOPs: 1245.1684
2024-04-28 16:07:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #829: GFLOPs: 967.9047. Time: 1911.8523 us. Best GFLOPs: 1245.1684
2024-04-28 16:07:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #830: GFLOPs: 13.6160. Time: 135905.4173 us. Best GFLOPs: 1245.1684
2024-04-28 16:07:03 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #831: GFLOPs: 18.8738. Time: 98045.3090 us. Best GFLOPs: 1245.1684
2024-04-28 16:07:03 [INFO] [task_scheduler.cc:121] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #832: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(256)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(3), T.int64(3), T.int64(256), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(28), T.int64(28), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(256)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(28), T.int64(28), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused in T.parallel(T.int64(784), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(6), T.int64(256)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(196) // T.int64(14) * T.int64(2) + ax2)
                    v_i3 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(14) // T.int64(2) * T.int64(4) + ax3)
                    v_i4 = T.axis.spatial(T.int64(256), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(4)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(196) * T.int64(4) + oc_chunk_1 + oc_chunk_2_init + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(196) // T.int64(14) * T.int64(2) + oh_1 * T.int64(2) + oh_2_init + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(14) // T.int64(2) * T.int64(4) + ow_1 * T.int64(4) + ow_2_init * T.int64(4) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(2) * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2_init * T.int64(4) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(4), T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(4), T.int64(64), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(4)):
                    for oc_block_3_fused in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(196) * T.int64(4) + oc_chunk_1 + oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(196) // T.int64(14) * T.int64(2) + oh_1 * T.int64(2) + oh_2 + oh_3)
                            v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(14) // T.int64(2) * T.int64(4) + ow_1 * T.int64(4) + ow_2 * T.int64(4) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(2) * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2 * T.int64(4) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(64) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)], p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)] * p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(2), T.int64(4)):
                    for ax4_fused in T.vectorized(T.int64(16)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(196) * T.int64(4) + oc_chunk_1 + ax1)
                            v_ax2 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(196) // T.int64(14) * T.int64(2) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(14) // T.int64(2) * T.int64(4) + ax3)
                            v_ax4 = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(2) * T.int64(16) + ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[4, 4, 1, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[14, 1, 2, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[7, 1, 1, 4])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[2, 1, 4, 4])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[4, 64])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=4)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80 = sch.get_loops(block=b68)
l81 = sch.fuse(l71, l72, l73, l74, l75, preserve_unit_iters=True)
sch.parallel(loop=l81)
l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l82, preserve_unit_iters=True)
sch.parallel(loop=l104)
l105 = sch.fuse(l103, preserve_unit_iters=True)
sch.vectorize(loop=l105)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l106, l107, l108, l109, l110, l111, l112, l113, l114, l115, l116 = sch.get_loops(block=b70)
l117 = sch.fuse(l116, preserve_unit_iters=True)
sch.vectorize(loop=l117)
b118 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140 = sch.get_loops(block=b118)
b141 = sch.decompose_reduction(block=b118, loop=l125)
2024-04-28 16:44:27 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-28 16:44:29 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-28 16:44:33 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35c37e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x31a6de8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x9b6ad08)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x350b3f8)]: 0 failure(s)
2024-04-28 16:44:33 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-28 16:44:46 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35c37e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x31a6de8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x9b6ad08)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x350b3f8)]: 0 failure(s)
2024-04-28 16:44:58 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35c37e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x31a6de8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x9b6ad08)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x350b3f8)]: 0 failure(s)
2024-04-28 16:45:10 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35c37e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x31a6de8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x9b6ad08)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x350b3f8)]: 0 failure(s)
2024-04-28 16:45:23 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35c37e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x31a6de8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x9b6ad08)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x350b3f8)]: 0 failure(s)
2024-04-28 16:45:30 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.8943  0.8718  0.8718  0.8584  0.8316  0.8306  0.8287  0.8126  0.8102  0.8052  0.8016  0.7994  0.7986  0.7946  0.7922  0.7914
[17 : 32]:	0.7894  0.7890  0.7889  0.7868  0.7863  0.7863  0.7847  0.7830  0.7767  0.7740  0.7738  0.7704  0.7700  0.7690  0.7655  0.7633
[33 : 48]:	0.7633  0.7617  0.7595  0.7585  0.7557  0.7532  0.7475  0.7457  0.7435  0.7432  0.7429  0.7429  0.7399  0.7380  0.7380  0.7362
[49 : 64]:	0.7350  0.7350  0.7338  0.7338  0.7327  0.7327  0.7308  0.7304  0.7295  0.7290  0.7255  0.7230  0.7224  0.7221  0.7218  0.7202
2024-04-28 16:45:30 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-28 16:45:30 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-28 16:47:18 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #833: GFLOPs: 571.9887. Time: 3235.1878 us. Best GFLOPs: 1245.1684
2024-04-28 16:47:18 [INFO] [task_scheduler.cc:121] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #834: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(256)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(3), T.int64(3), T.int64(256), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(28), T.int64(28), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(256)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(28), T.int64(28), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_fused_fused in T.parallel(T.int64(224), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(3), T.int64(16), T.int64(256)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(56) // T.int64(2) + ax2)
                    v_i3 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(2) * T.int64(14) + ax3)
                    v_i4 = T.axis.spatial(T.int64(256), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oc_block_0, n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(1), T.int64(14), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(56) * T.int64(4) + oc_chunk_1 * T.int64(4) + oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(56) // T.int64(2) + oh_1 + oh_2_init + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(2) * T.int64(14) + ow_1 * T.int64(14) + ow_2_init * T.int64(14) + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_0 * T.int64(32) + oc_block_1 * T.int64(32) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(128), T.int64(3), T.int64(1), T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(32), T.int64(2), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(14), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(56) * T.int64(4) + oc_chunk_1 * T.int64(4) + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(56) // T.int64(2) + oh_1 + oh_2 + oh_3)
                        v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(2) * T.int64(14) + ow_1 * T.int64(14) + ow_2 * T.int64(14) + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_0 * T.int64(32) + oc_block_1 * T.int64(32) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(2) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)], p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)] * p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(4), T.int64(1), T.int64(14)):
                    for ax4_fused in T.vectorized(T.int64(32)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(56) * T.int64(4) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(56) // T.int64(2) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(2) * T.int64(14) + ax3)
                            v_ax4 = T.axis.spatial(T.int64(32), ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[4, 1, 4, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[28, 1, 1, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[2, 1, 1, 14])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 32, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[128, 2])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=3)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79 = sch.get_loops(block=b68)
l80 = sch.fuse(l71, l72, l73, l74, preserve_unit_iters=True)
sch.parallel(loop=l80)
l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l81, preserve_unit_iters=True)
sch.parallel(loop=l104)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109, l110, l111, l112, l113, l114, l115, l116 = sch.get_loops(block=b70)
l117 = sch.fuse(l116, preserve_unit_iters=True)
sch.vectorize(loop=l117)
b118 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141 = sch.get_loops(block=b118)
b142 = sch.decompose_reduction(block=b118, loop=l126)
2024-04-28 16:47:18 [INFO] [task_scheduler.cc:121] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #835: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(256)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(3), T.int64(3), T.int64(256), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(28), T.int64(28), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(30), T.int64(30), T.int64(256)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(28), T.int64(28), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused in T.parallel(T.int64(224), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(3), T.int64(16), T.int64(256)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(28) + ax2)
                    v_i3 = T.axis.spatial(T.int64(30), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(56) // T.int64(28) * T.int64(14) + ax3)
                    v_i4 = T.axis.spatial(T.int64(256), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(1), T.int64(14), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(56) * T.int64(4) + oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(28) + oh_2_init + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(56) // T.int64(28) * T.int64(14) + ow_1 * T.int64(14) + ow_2_init * T.int64(14) + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(128), T.int64(3), T.int64(1), T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(32), T.int64(2), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(14), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(56) * T.int64(4) + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(28) + oh_2 + oh_3)
                        v_ow = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(56) // T.int64(28) * T.int64(14) + ow_1 * T.int64(14) + ow_2 * T.int64(14) + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(32) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(2) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)], p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(256), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(256)] * p1[v_oc_chunk, v_ic // T.int64(256), v_kh, v_kw, v_ic % T.int64(256), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(4), T.int64(1), T.int64(14)):
                    for ax4_fused in T.vectorized(T.int64(32)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(56) * T.int64(4) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(28) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(28), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(56) // T.int64(28) * T.int64(14) + ax3)
                            v_ax4 = T.axis.spatial(T.int64(32), ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[4, 1, 4, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 28, 1, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[2, 1, 1, 14])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 32, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[128, 2])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=7)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83 = sch.get_loops(block=b68)
l84 = sch.fuse(l71, l72, l73, l74, l75, l76, l77, l78, preserve_unit_iters=True)
sch.parallel(loop=l84)
l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l85, preserve_unit_iters=True)
sch.parallel(loop=l104)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109, l110, l111, l112 = sch.get_loops(block=b70)
l113 = sch.fuse(l112, preserve_unit_iters=True)
sch.vectorize(loop=l113)
b114 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133 = sch.get_loops(block=b114)
b134 = sch.decompose_reduction(block=b114, loop=l118)
2024-04-28 16:47:18 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #836: GFLOPs: 1064.3961. Time: 1738.5359 us. Best GFLOPs: 1245.1684
2024-04-28 16:47:18 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #837: GFLOPs: 1120.8319. Time: 1650.9976 us. Best GFLOPs: 1245.1684
2024-04-28 16:47:18 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #838: GFLOPs: 1056.1128. Time: 1752.1717 us. Best GFLOPs: 1245.1684
2024-04-28 16:47:18 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #839: GFLOPs: 1006.9490. Time: 1837.7206 us. Best GFLOPs: 1245.1684
2024-04-28 16:47:18 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #840: GFLOPs: 1053.5963. Time: 1756.3566 us. Best GFLOPs: 1245.1684
2024-04-28 16:47:18 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #841: GFLOPs: 1129.1494. Time: 1638.8361 us. Best GFLOPs: 1245.1684
2024-04-28 16:47:18 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #842: GFLOPs: 973.5746. Time: 1900.7180 us. Best GFLOPs: 1245.1684
2024-04-28 16:47:18 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #843: GFLOPs: 1012.5461. Time: 1827.5620 us. Best GFLOPs: 1245.1684
2024-04-28 16:47:18 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #844: GFLOPs: 1001.9113. Time: 1846.9607 us. Best GFLOPs: 1245.1684
2024-04-28 16:47:18 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #845: GFLOPs: 959.3350. Time: 1928.9308 us. Best GFLOPs: 1245.1684
2024-04-28 16:47:18 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #846: GFLOPs: 157.0907. Time: 11779.7642 us. Best GFLOPs: 1245.1684
2024-04-28 16:47:18 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #847: GFLOPs: 1067.1755. Time: 1734.0080 us. Best GFLOPs: 1245.1684
2024-04-28 16:47:18 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #848: GFLOPs: 625.3360. Time: 2959.1946 us. Best GFLOPs: 1245.1684
2024-04-28 16:47:18 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #849: GFLOPs: 963.0391. Time: 1921.5116 us. Best GFLOPs: 1245.1684
2024-04-28 16:47:18 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #850: GFLOPs: 982.5940. Time: 1883.2711 us. Best GFLOPs: 1245.1684
2024-04-28 16:47:18 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #851: GFLOPs: 979.2553. Time: 1889.6920 us. Best GFLOPs: 1245.1684
2024-04-28 16:47:18 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #852: GFLOPs: 586.0047. Time: 3157.8091 us. Best GFLOPs: 1245.1684
2024-04-28 16:47:18 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #853: GFLOPs: 996.6993. Time: 1856.6190 us. Best GFLOPs: 1245.1684
2024-04-28 16:47:18 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #854: GFLOPs: 938.9259. Time: 1970.8593 us. Best GFLOPs: 1245.1684
2024-04-28 16:47:18 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #855: GFLOPs: 1036.9575. Time: 1784.5388 us. Best GFLOPs: 1245.1684
2024-04-28 16:47:18 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #856: GFLOPs: 1015.6115. Time: 1822.0459 us. Best GFLOPs: 1245.1684
2024-04-28 16:47:18 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #857: GFLOPs: 969.5648. Time: 1908.5789 us. Best GFLOPs: 1245.1684
2024-04-28 16:47:18 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #858: GFLOPs: 849.7532. Time: 2177.6803 us. Best GFLOPs: 1245.1684
2024-04-28 16:47:18 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #859: GFLOPs: 1063.0262. Time: 1740.7764 us. Best GFLOPs: 1245.1684
2024-04-28 16:47:18 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #860: GFLOPs: 997.3658. Time: 1855.3783 us. Best GFLOPs: 1245.1684
2024-04-28 16:47:18 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #861: GFLOPs: 998.3759. Time: 1853.5011 us. Best GFLOPs: 1245.1684
2024-04-28 16:47:18 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #862: GFLOPs: 949.4612. Time: 1948.9905 us. Best GFLOPs: 1245.1684
2024-04-28 16:47:18 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #863: GFLOPs: 966.1909. Time: 1915.2436 us. Best GFLOPs: 1245.1684
2024-04-28 16:47:18 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #864: GFLOPs: 958.7336. Time: 1930.1409 us. Best GFLOPs: 1245.1684
2024-04-28 16:47:18 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #865: GFLOPs: 950.2551. Time: 1947.3622 us. Best GFLOPs: 1245.1684
2024-04-28 16:47:18 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #866: GFLOPs: 925.7347. Time: 1998.9431 us. Best GFLOPs: 1245.1684
2024-04-28 16:47:18 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #867: GFLOPs: 982.6243. Time: 1883.2130 us. Best GFLOPs: 1245.1684
2024-04-28 16:47:18 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #868: GFLOPs: 823.3066. Time: 2247.6327 us. Best GFLOPs: 1245.1684
2024-04-28 16:47:18 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #869: GFLOPs: 930.6113. Time: 1988.4682 us. Best GFLOPs: 1245.1684
2024-04-28 16:47:18 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #870: GFLOPs: 929.3978. Time: 1991.0645 us. Best GFLOPs: 1245.1684
2024-04-28 16:47:18 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #871: GFLOPs: 162.2357. Time: 11406.1849 us. Best GFLOPs: 1245.1684
2024-04-28 16:47:18 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #872: GFLOPs: 854.9780. Time: 2164.3726 us. Best GFLOPs: 1245.1684
2024-04-28 16:47:18 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #873: GFLOPs: 859.1894. Time: 2153.7637 us. Best GFLOPs: 1245.1684
2024-04-28 16:47:18 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #874: GFLOPs: 932.6065. Time: 1984.2140 us. Best GFLOPs: 1245.1684
2024-04-28 16:47:18 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #875: GFLOPs: 972.1020. Time: 1903.5975 us. Best GFLOPs: 1245.1684
2024-04-28 16:47:18 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #876: GFLOPs: 1003.2240. Time: 1844.5441 us. Best GFLOPs: 1245.1684
2024-04-28 16:47:18 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #877: GFLOPs: 930.6729. Time: 1988.3364 us. Best GFLOPs: 1245.1684
2024-04-28 16:47:18 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #878: GFLOPs: 855.6638. Time: 2162.6377 us. Best GFLOPs: 1245.1684
2024-04-28 16:47:18 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #879: GFLOPs: 948.8410. Time: 1950.2646 us. Best GFLOPs: 1245.1684
2024-04-28 16:47:18 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #880: GFLOPs: 913.0836. Time: 2026.6391 us. Best GFLOPs: 1245.1684
2024-04-28 16:47:18 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #881: GFLOPs: 677.6262. Time: 2730.8431 us. Best GFLOPs: 1245.1684
2024-04-28 16:47:18 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #882: GFLOPs: 541.1126. Time: 3419.7888 us. Best GFLOPs: 1245.1684
2024-04-28 16:47:18 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #883: GFLOPs: 566.3527. Time: 3267.3822 us. Best GFLOPs: 1245.1684
2024-04-28 16:47:18 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #884: GFLOPs: 979.5975. Time: 1889.0318 us. Best GFLOPs: 1245.1684
2024-04-28 16:47:18 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #885: GFLOPs: 779.7306. Time: 2373.2439 us. Best GFLOPs: 1245.1684
2024-04-28 16:47:18 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #886: GFLOPs: 740.7994. Time: 2497.9650 us. Best GFLOPs: 1245.1684
2024-04-28 16:47:18 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #887: GFLOPs: 1009.3402. Time: 1833.3669 us. Best GFLOPs: 1245.1684
2024-04-28 16:47:18 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #888: GFLOPs: 964.4760. Time: 1918.6489 us. Best GFLOPs: 1245.1684
2024-04-28 16:47:18 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #889: GFLOPs: 164.6345. Time: 11239.9948 us. Best GFLOPs: 1245.1684
2024-04-28 16:47:18 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #890: GFLOPs: 841.9315. Time: 2197.9115 us. Best GFLOPs: 1245.1684
2024-04-28 16:47:18 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #891: GFLOPs: 829.2810. Time: 2231.4400 us. Best GFLOPs: 1245.1684
2024-04-28 16:47:18 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #892: GFLOPs: 879.1124. Time: 2104.9536 us. Best GFLOPs: 1245.1684
2024-04-28 16:47:18 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #893: GFLOPs: 1001.6351. Time: 1847.4702 us. Best GFLOPs: 1245.1684
2024-04-28 16:47:18 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #894: GFLOPs: 130.3196. Time: 14199.6397 us. Best GFLOPs: 1245.1684
2024-04-28 16:47:18 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #895: GFLOPs: 127.0739. Time: 14562.3247 us. Best GFLOPs: 1245.1684
2024-04-28 16:47:18 [INFO] [task_scheduler.cc:131] [Task #11: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4] Trial #896: GFLOPs: 250.3835. Time: 7390.6266 us. Best GFLOPs: 1245.1684
